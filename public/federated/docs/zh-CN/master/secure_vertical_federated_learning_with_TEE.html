

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>纵向联邦-基于可信执行环境的特征保护 &mdash; MindSpore master 文档</title>
  

  
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script src="_static/translations.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="next" title="纵向联邦-基于差分隐私的标签保护" href="secure_vertical_federated_learning_with_DP.html" />
    <link rel="prev" title="纵向联邦-基于信息混淆的特征保护" href="secure_vertical_federated_learning_with_EmbeddingDP.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="federated_install.html">获取MindSpore Federated</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_federated_server.html">横向联邦云侧部署</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_federated_client.html">横向联邦端侧部署</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_vfl.html">纵向联邦部署</a></li>
</ul>
<p class="caption"><span class="caption-text">横向应用实践</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="image_classfication_dataset_process.html">联邦学习图像分类数据集处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_classification_application.html">实现一个端云联邦的图像分类应用(x86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="sentiment_classification_application.html">实现一个端云情感分类应用(Android)</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_classification_application_in_cross_silo.html">实现一个云云联邦的图像分类应用(x86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="object_detection_application_in_cross_silo.html">实现一个云云联邦的目标检测应用(x86)</a></li>
</ul>
<p class="caption"><span class="caption-text">纵向应用实践</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="data_join.html">纵向联邦学习数据接入</a></li>
<li class="toctree-l1"><a class="reference internal" href="split_wnd_application.html">纵向联邦学习模型训练 - Wide&amp;Deep推荐应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="split_pangu_alpha_application.html">纵向联邦学习模型训练 - 盘古α大模型跨域训练</a></li>
</ul>
<p class="caption"><span class="caption-text">安全和隐私</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="local_differential_privacy_training_noise.html">横向联邦-局部差分隐私加噪训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="local_differential_privacy_training_signds.html">横向联邦-局部差分隐私SignDS训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="local_differential_privacy_eval_laplace.html">横向联邦-局部差分隐私推理结果保护</a></li>
<li class="toctree-l1"><a class="reference internal" href="pairwise_encryption_training.html">横向联邦-安全聚合训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="private_set_intersection.html">纵向联邦-隐私集合求交</a></li>
<li class="toctree-l1"><a class="reference internal" href="secure_vertical_federated_learning_with_EmbeddingDP.html">纵向联邦-基于信息混淆的特征保护</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">纵向联邦-基于可信执行环境的特征保护</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#背景">背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="#算法介绍">算法介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="#快速体验">快速体验</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#前置需要环境配置">前置需要&amp;环境配置</a></li>
<li class="toctree-l3"><a class="reference internal" href="#启动脚本">启动脚本</a></li>
<li class="toctree-l3"><a class="reference internal" href="#查看结果">查看结果</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#深度体验">深度体验</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#前置需要环境配置-1">前置需要&amp;环境配置</a></li>
<li class="toctree-l3"><a class="reference internal" href="#定义网络模型">定义网络模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#正向传播">正向传播</a></li>
<li class="toctree-l4"><a class="reference internal" href="#反向传播">反向传播</a></li>
<li class="toctree-l4"><a class="reference internal" href="#定义优化器">定义优化器</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#构建训练脚本">构建训练脚本</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#构建网络">构建网络</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="secure_vertical_federated_learning_with_DP.html">纵向联邦-基于差分隐私的标签保护</a></li>
</ul>
<p class="caption"><span class="caption-text">通信压缩</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="communication_compression.html">端云联邦学习通信压缩</a></li>
<li class="toctree-l1"><a class="reference internal" href="vfl_communication_compress.html">纵向联邦学习通信压缩</a></li>
</ul>
<p class="caption"><span class="caption-text">横向联邦API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="horizontal_server.html">联邦服务器</a></li>
<li class="toctree-l1"><a class="reference internal" href="cross_device.html">端侧客户端</a></li>
<li class="toctree-l1"><a class="reference internal" href="horizontal/cross_silo.html">云侧客户端</a></li>
</ul>
<p class="caption"><span class="caption-text">纵向联邦API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Data_Join.html">数据求交</a></li>
<li class="toctree-l1"><a class="reference internal" href="vertical/vertical_communicator.html">纵向联邦学习通信器</a></li>
<li class="toctree-l1"><a class="reference internal" href="vertical_federated_trainer.html">纵向联邦训练器</a></li>
</ul>
<p class="caption"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>纵向联邦-基于可信执行环境的特征保护</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/secure_vertical_federated_learning_with_TEE.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="纵向联邦-基于可信执行环境的特征保护">
<h1>纵向联邦-基于可信执行环境的特征保护<a class="headerlink" href="#纵向联邦-基于可信执行环境的特征保护" title="永久链接至标题">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/master/docs/federated/docs/source_zh_cn/secure_vertical_federated_learning_with_TEE.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.png"></a></p>
<p>注：这是一个实验特性，未来有可能被修改或删除。</p>
<div class="section" id="背景">
<h2>背景<a class="headerlink" href="#背景" title="永久链接至标题">¶</a></h2>
<p>纵向联邦学习（vFL）是联邦学习（FL）的一大重要分支。当不同的参与方拥有来自相同一批用户但属性不同的数据时，他们便可使用vFL进行协同训练。在vFL中，拥有属性的参与方都会持有一个下层网络（Bottom Model），他们分别将属性输入下层网络，得到中间结果（embedding），发送给拥有标签的参与方（简称leader方，如下图参与方B，而不拥有标签的被称作follower方，如下图参与方A），leader方使用embedding和标签来训练上层网络，再将算得的梯度回传给各个参与方用以训练下层网络。由此可见，vFL不需要任何参与方上传自己的原始数据即可协同训练模型。</p>
<p><img alt="image.png" src="_images/vfl_1.png" /></p>
<p>由于避免了直接上传原始数据，vFL在一定程度上保护了隐私安全（这也是vFL的核心目标之一），然而攻击者还是有可能从上传的embedding反推出用户信息，造成隐私安全隐患。在这样的背景下，我们需要对vFL在训练时传输的embedding和梯度提供更强的隐私保证来规避隐私安全风险。</p>
<p>可信执行环境（Trusted Execution Environment，TEE）是一种基于硬件的可信计算方案，通过使硬件中的整个计算过程相对于外界黑盒化，来保证计算过程的数据安全。在vFL中，我们使用TEE将网络中的关键层屏蔽，可以使该层计算难以被反推，从而保证vFL训练和推理过程的数据安全。</p>
</div>
<div class="section" id="算法介绍">
<h2>算法介绍<a class="headerlink" href="#算法介绍" title="永久链接至标题">¶</a></h2>
<p><img alt="image.png" src="_images/vfl_with_tee.png" /></p>
<p>如图，如果参与方A将中间结果<span class="math notranslate nohighlight">\(\alpha^{(A)}\)</span>直接发给参与方B，则参与方B很有可能用中间结果反推出参与方A的原始数据<span class="math notranslate nohighlight">\(X^{(A)}\)</span>。为了降低这样的风险，参与方A将Bottom Model计算得到的中间结果<span class="math notranslate nohighlight">\(\alpha^{(A)}\)</span>先进行加密得到<span class="math notranslate nohighlight">\(E(\alpha^{(A)})\)</span>，将<span class="math notranslate nohighlight">\(E(\alpha^{(A)})\)</span>传给参与方B，参与方B将<span class="math notranslate nohighlight">\(E(\alpha^{(A)})\)</span>输入到TEE中的Cut Layer层中，然后在TEE的内部解密出<span class="math notranslate nohighlight">\(\alpha^{(A)}\)</span>进行前向传播。上述的整个过程，对于B来说都是黑盒的。</p>
<p>反向传梯度时也类似，Cut Layer运算出梯度<span class="math notranslate nohighlight">\(\nabla\alpha^{(A)}\)</span>，加密成<span class="math notranslate nohighlight">\(E(\nabla\alpha^{(A)})\)</span>后再由参与方B传回给参与方A，然后参与方A解密成<span class="math notranslate nohighlight">\(\nabla\alpha^{(A)}\)</span>后继续做反向传播。</p>
</div>
<div class="section" id="快速体验">
<h2>快速体验<a class="headerlink" href="#快速体验" title="永久链接至标题">¶</a></h2>
<p>我们以<a class="reference external" href="https://gitee.com/mindspore/federated/tree/master/example/splitnn_criteo">Wide&amp;Deep纵向联邦学习案例</a>中的单进程案例为例，给出一个配置TEE保护的范例脚本。</p>
<div class="section" id="前置需要环境配置">
<h3>前置需要&amp;环境配置<a class="headerlink" href="#前置需要环境配置" title="永久链接至标题">¶</a></h3>
<ol>
<li><p>环境要求：</p>
<ul class="simple">
<li><p>处理器：需要支持Intel SGX（Intel Sofrware Guard Extensions）功能</p></li>
<li><p>操作系统：openEuler 20.03、openEuler 21.03 LTS SP2或更高版本</p></li>
</ul>
</li>
<li><p>安装SGX和SecGear（可以参考<a class="reference external" href="https://gitee.com/openeuler/secGear">secGear官网</a>）：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>sudo<span class="w"> </span>yum<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>cmake<span class="w"> </span>ocaml-dune<span class="w"> </span>linux-sgx-driver<span class="w"> </span>sgxsdk<span class="w"> </span>libsgx-launch<span class="w"> </span>libsgx-urts<span class="w"> </span>sgxssl
git<span class="w"> </span>clone<span class="w"> </span>https://gitee.com/openeuler/secGear.git
<span class="nb">cd</span><span class="w"> </span>secGear
<span class="nb">source</span><span class="w"> </span>/opt/intel/sgxsdk/environment<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">source</span><span class="w"> </span>environment
mkdir<span class="w"> </span>debug<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>debug<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>cmake<span class="w"> </span>..<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>make<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>make<span class="w"> </span>install
</pre></div>
</div>
</li>
<li><p>安装MindSpore1.8.1或更高版本，请参考<a class="reference external" href="https://www.mindspore.cn/install">MindSpore官网安装指引</a>。</p></li>
<li><p>下载federated仓</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://gitee.com/mindspore/federated.git
</pre></div>
</div>
</li>
<li><p>安装MindSpore Federated依赖Python库，请参考<a class="reference external" href="https://gitee.com/mindspore/federated/tree/master/example/splitnn_criteo">Wide&amp;Deep纵向联邦学习案例</a>。</p></li>
<li><p>为TEE编译安装MindSpore Federated（需要加入额外编译选项，表示是否使用SGX）：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>sh<span class="w"> </span>federated/build.sh<span class="w"> </span>-s<span class="w"> </span>on
pip<span class="w"> </span>install<span class="w"> </span>federated/build/packages/mindspore_federated-XXXXX.whl
</pre></div>
</div>
</li>
<li><p>准备criteo数据集，请参考<a class="reference external" href="https://gitee.com/mindspore/federated/tree/master/example/splitnn_criteo">Wide&amp;Deep纵向联邦学习案例</a>。</p></li>
</ol>
</div>
<div class="section" id="启动脚本">
<h3>启动脚本<a class="headerlink" href="#启动脚本" title="永久链接至标题">¶</a></h3>
<ol>
<li><p>进入脚本所在文件夹</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>federated/example/splitnn_criteo
</pre></div>
</div>
</li>
<li><p>运行脚本</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>sh<span class="w"> </span>run_vfl_train_local_tee.sh
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="查看结果">
<h3>查看结果<a class="headerlink" href="#查看结果" title="永久链接至标题">¶</a></h3>
<p>在训练日志<code class="docutils literal notranslate"><span class="pre">log_local_cpu_tee.txt</span></code>查看模型训练的loss变化：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">100</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.661822<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.662018
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">100</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.685003<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.685198
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">200</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.649380<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.649381
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">300</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.612189<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.612189
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">400</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.630079<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.630079
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">500</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.602897<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.602897
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">600</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.621647<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.621647
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">700</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.624762<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.624762
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">800</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.622042<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.622042
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">900</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.585274<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.585274
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">1000</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.590947<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.590947
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">1100</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.586775<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.586775
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">1200</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.597362<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.597362
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">1300</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.607390<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.607390
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">1400</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.584204<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.584204
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">1500</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.583618<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.583618
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">1600</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.573294<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.573294
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">1700</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.600686<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.600686
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">1800</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.585533<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.585533
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">1900</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.583466<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.583466
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">2000</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.560188<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.560188
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">2100</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.569232<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.569232
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">2200</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.591643<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.591643
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">2300</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.572473<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.572473
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">2400</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.582825<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.582825
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">2500</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.567196<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.567196
INFO:root:epoch<span class="w"> </span><span class="m">0</span><span class="w"> </span>step<span class="w"> </span><span class="m">2600</span>/41322<span class="w"> </span>wide_loss:<span class="w"> </span><span class="m">0</span>.602022<span class="w"> </span>deep_loss:<span class="w"> </span><span class="m">0</span>.602022
</pre></div>
</div>
</div>
</div>
<div class="section" id="深度体验">
<h2>深度体验<a class="headerlink" href="#深度体验" title="永久链接至标题">¶</a></h2>
<p>TEE层的正向传播、反向传播都需要调用它自己的函数而非通过MindSpore，因此在实现时和通常的vFL模型存在不同。</p>
<p>通常，vFL模型在训练的反向传播时，Top Model和Cut Layer是放在一起，由参与方B通过MindSpore一步求导、一步更新的；而含有TEE的网络在反向传播时，Top Model由参与方B基于MindSpore更新，而Cut Layer（TEE）是在接收到Top Model传回的梯度后，在它自己内部进行更新的，再将需要传回参与方A的梯度加密后传出给参与方B，整个过程都在TEE内部完成。</p>
<p>目前在MindSpore Federated中，上述功能是通过在<code class="docutils literal notranslate"><span class="pre">mindspore_federated.vfl_model.FLModel()</span></code>定义时传入<code class="docutils literal notranslate"><span class="pre">grad_network</span></code>来实现自定义的反向传播流程的。因此，要实现含有TEE的网络，用户可以在<code class="docutils literal notranslate"><span class="pre">grad_network</span></code>中定义好Top Model和Cut Layer的反向传播流程并传入<code class="docutils literal notranslate"><span class="pre">FLModel</span></code>即可，在反向传播时<code class="docutils literal notranslate"><span class="pre">FLModel</span></code>就会走用户自定义的训练流程。</p>
<p>我们以<a class="reference external" href="https://gitee.com/mindspore/federated/tree/master/example/splitnn_criteo">Wide&amp;Deep纵向联邦学习案例</a>中的单进程案例为例，介绍在纵向联邦模型中配置TEE保护的具体操作方法。介绍的内容主要针对使用TEE时配置上和通常情况下的不同点，相同点则会略过（关于vFL训练的详细介绍可以参见<a class="reference external" href="https://www.mindspore.cn/federated/docs/zh-CN/master/split_pangu_alpha_application.html">纵向联邦学习模型训练 - 盘古α大模型跨域训练</a>）。</p>
<div class="section" id="前置需要环境配置-1">
<h3>前置需要&amp;环境配置<a class="headerlink" href="#前置需要环境配置-1" title="永久链接至标题">¶</a></h3>
<p>参照<a class="reference external" href="#%E5%BF%AB%E9%80%9F%E4%BD%93%E9%AA%8C">快速体验</a>。</p>
</div>
<div class="section" id="定义网络模型">
<h3>定义网络模型<a class="headerlink" href="#定义网络模型" title="永久链接至标题">¶</a></h3>
<div class="section" id="正向传播">
<h4>正向传播<a class="headerlink" href="#正向传播" title="永久链接至标题">¶</a></h4>
<p>和通常的vFL训练相同，使用者需要基于MindSpore提供的<code class="docutils literal notranslate"><span class="pre">nn.Cell</span></code>（参见<a class="reference external" href="https://mindspore.cn/docs/zh-CN/master/api_python/nn/mindspore.nn.Cell.html#mindspore-nn-cell">mindspore.nn.Cell</a>）来开发训练网络。不同点则在于，在TEE所在的这一层，使用者需要在该类的<code class="docutils literal notranslate"><span class="pre">construct</span></code>函数中调用TEE前向传播的函数：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_federated._mindspore_federated</span> <span class="kn">import</span> <span class="n">init_tee_cut_layer</span><span class="p">,</span> <span class="n">backward_tee_cut_layer</span><span class="p">,</span> \
    <span class="n">encrypt_client_data</span><span class="p">,</span> <span class="n">secure_forward_tee_cut_layer</span>

<span class="k">class</span> <span class="nc">TeeLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    TEE layer of the leader net.</span>
<span class="sd">    Args:</span>
<span class="sd">        config (class): default config info.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TeeLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">init_tee_cut_layer</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">3.5e-4</span><span class="p">,</span> <span class="mf">1024.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">concat</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Concat</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Reshape</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wide_out0</span><span class="p">,</span> <span class="n">deep_out0</span><span class="p">,</span> <span class="n">wide_embedding</span><span class="p">,</span> <span class="n">deep_embedding</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert and encrypt the intermediate data&quot;&quot;&quot;</span>
        <span class="n">local_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">wide_out0</span><span class="p">,</span> <span class="n">deep_out0</span><span class="p">))</span>
        <span class="n">remote_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">wide_embedding</span><span class="p">,</span> <span class="n">deep_embedding</span><span class="p">))</span>
        <span class="n">aa</span> <span class="o">=</span> <span class="n">remote_emb</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">bb</span> <span class="o">=</span> <span class="n">local_emb</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">enc_aa</span><span class="p">,</span> <span class="n">enc_aa_len</span> <span class="o">=</span> <span class="n">encrypt_client_data</span><span class="p">(</span><span class="n">aa</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">aa</span><span class="p">))</span>
        <span class="n">enc_bb</span><span class="p">,</span> <span class="n">enc_bb_len</span> <span class="o">=</span> <span class="n">encrypt_client_data</span><span class="p">(</span><span class="n">bb</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">bb</span><span class="p">))</span>
        <span class="n">tee_output</span> <span class="o">=</span> <span class="n">secure_forward_tee_cut_layer</span><span class="p">(</span><span class="n">remote_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">remote_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                                  <span class="n">local_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">enc_aa</span><span class="p">,</span> <span class="n">enc_aa_len</span><span class="p">,</span> <span class="n">enc_bb</span><span class="p">,</span> <span class="n">enc_bb_len</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">tee_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">tee_output</span><span class="p">),</span> <span class="p">(</span><span class="n">remote_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">tee_output</span>
</pre></div>
</div>
</div>
<div class="section" id="反向传播">
<h4>反向传播<a class="headerlink" href="#反向传播" title="永久链接至标题">¶</a></h4>
<p>在通常的vfl模型中，反向传播是由<code class="docutils literal notranslate"><span class="pre">FLModel</span></code>类自动配置实现的，但在含有TEE的模型中，使用者需开发一个<code class="docutils literal notranslate"><span class="pre">grad_network</span></code>来定义反向传播流程。<code class="docutils literal notranslate"><span class="pre">grad_network</span></code>也基于<code class="docutils literal notranslate"><span class="pre">nn.Cell</span></code>，包括一个<code class="docutils literal notranslate"><span class="pre">__init__</span></code>函数和一个<code class="docutils literal notranslate"><span class="pre">construct</span></code>函数，初始化时，需要传入训练使用的网络，并且在<code class="docutils literal notranslate"><span class="pre">__init__</span></code>函数中定义：求导算子、Cut Layer之外网络的参数、loss函数、Cut Layer之外网络的优化器，示例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LeaderGradNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    grad_network of the leader party.</span>
<span class="sd">    Args:</span>
<span class="sd">        net (class): LeaderNet, which is the net of leader party.</span>
<span class="sd">        config (class): default config info.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">:</span> <span class="n">LeaderNet</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sens</span> <span class="o">=</span> <span class="mf">1024.0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">grad_op_param_sens</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">GradOperation</span><span class="p">(</span><span class="n">get_by_list</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sens_param</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grad_op_input_sens</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">GradOperation</span><span class="p">(</span><span class="n">get_all</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sens_param</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">params_head</span> <span class="o">=</span> <span class="n">ParameterTuple</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">head_layer</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params_bottom_deep</span> <span class="o">=</span> <span class="n">vfl_utils</span><span class="o">.</span><span class="n">get_params_by_name</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">bottom_net</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;deep&#39;</span><span class="p">,</span> <span class="s1">&#39;dense&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params_bottom_wide</span> <span class="o">=</span> <span class="n">vfl_utils</span><span class="o">.</span><span class="n">get_params_by_name</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">bottom_net</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;wide&#39;</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_net</span> <span class="o">=</span> <span class="n">HeadLossNet</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">head_layer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_net_l2</span> <span class="o">=</span> <span class="n">L2LossNet</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">bottom_net</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_head</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params_head</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">3.5e-4</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_bottom_deep</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params_bottom_deep</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">3.5e-4</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_bottom_wide</span> <span class="o">=</span> <span class="n">FTRL</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params_bottom_wide</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">5e-2</span><span class="p">,</span> <span class="n">l1</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="n">l2</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
                                          <span class="n">initial_accum</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sens</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">grad_network</span></code>的<code class="docutils literal notranslate"><span class="pre">construct</span></code>函数的输入是<code class="docutils literal notranslate"><span class="pre">local_data_batch</span></code>和<code class="docutils literal notranslate"><span class="pre">remote_data_batch</span></code>两个字典，在<code class="docutils literal notranslate"><span class="pre">construct</span></code>函数中首先需要从字典中提取相应的数据。接下来，除TEE外的其他层，需要分别调用MindSpore关于参数和关于输入的求导算子进行求导操作，并用优化器进行更新；TEE层则需要调用TEE的内置函数进行求导和更新，示例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">local_data_batch</span><span class="p">,</span> <span class="n">remote_data_batch</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The back propagation of the leader net.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># data processing</span>
    <span class="n">id_hldr</span> <span class="o">=</span> <span class="n">local_data_batch</span><span class="p">[</span><span class="s1">&#39;id_hldr&#39;</span><span class="p">]</span>
    <span class="n">wt_hldr</span> <span class="o">=</span> <span class="n">local_data_batch</span><span class="p">[</span><span class="s1">&#39;wt_hldr&#39;</span><span class="p">]</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">local_data_batch</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>
    <span class="n">wide_embedding</span> <span class="o">=</span> <span class="n">remote_data_batch</span><span class="p">[</span><span class="s1">&#39;wide_embedding&#39;</span><span class="p">]</span>
    <span class="n">deep_embedding</span> <span class="o">=</span> <span class="n">remote_data_batch</span><span class="p">[</span><span class="s1">&#39;deep_embedding&#39;</span><span class="p">]</span>

    <span class="c1"># forward</span>
    <span class="n">wide_out0</span><span class="p">,</span> <span class="n">deep_out0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">bottom_net</span><span class="p">(</span><span class="n">id_hldr</span><span class="p">,</span> <span class="n">wt_hldr</span><span class="p">)</span>
    <span class="n">local_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">wide_out0</span><span class="p">,</span> <span class="n">deep_out0</span><span class="p">))</span>
    <span class="n">remote_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">wide_embedding</span><span class="p">,</span> <span class="n">deep_embedding</span><span class="p">))</span>
    <span class="n">head_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">cut_layer</span><span class="p">(</span><span class="n">wide_out0</span><span class="p">,</span> <span class="n">deep_out0</span><span class="p">,</span> <span class="n">wide_embedding</span><span class="p">,</span> <span class="n">deep_embedding</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_net</span><span class="p">(</span><span class="n">head_input</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

    <span class="c1"># update of head net</span>
    <span class="n">sens</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Fill</span><span class="p">()(</span><span class="n">ops</span><span class="o">.</span><span class="n">DType</span><span class="p">()(</span><span class="n">loss</span><span class="p">),</span> <span class="n">ops</span><span class="o">.</span><span class="n">Shape</span><span class="p">()(</span><span class="n">loss</span><span class="p">),</span> <span class="mf">1024.0</span><span class="p">)</span>
    <span class="n">grad_head_input</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_op_input_sens</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_net</span><span class="p">)(</span><span class="n">head_input</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">sens</span><span class="p">)</span>
    <span class="n">grad_head_param</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_op_param_sens</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_net</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params_head</span><span class="p">)(</span><span class="n">head_input</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">sens</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_head</span><span class="p">(</span><span class="n">grad_head_param</span><span class="p">)</span>

    <span class="c1"># update of cut layer</span>

    <span class="n">tmp</span> <span class="o">=</span> <span class="n">grad_head_input</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">grad_input</span> <span class="o">=</span> <span class="n">backward_tee_cut_layer</span><span class="p">(</span><span class="n">remote_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">remote_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">local_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tmp</span><span class="p">)</span>
    <span class="n">grad_inputa</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">grad_input</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">remote_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">grad_inputb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">grad_input</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">local_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">grad_cutlayer_input</span> <span class="o">=</span> <span class="p">(</span><span class="n">grad_inputb</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">],</span> <span class="n">grad_inputb</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">grad_inputa</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">],</span> <span class="n">grad_inputa</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>

    <span class="c1"># update of bottom net</span>
    <span class="n">grad_bottom_wide</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_op_param_sens</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">bottom_net</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">params_bottom_wide</span><span class="p">)(</span><span class="n">id_hldr</span><span class="p">,</span> <span class="n">wt_hldr</span><span class="p">,</span>
                                                                        <span class="n">grad_cutlayer_input</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_bottom_wide</span><span class="p">(</span><span class="n">grad_bottom_wide</span><span class="p">)</span>
    <span class="n">grad_bottom_deep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_op_param_sens</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">bottom_net</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">params_bottom_deep</span><span class="p">)(</span><span class="n">id_hldr</span><span class="p">,</span> <span class="n">wt_hldr</span><span class="p">,</span>
                                                                        <span class="n">grad_cutlayer_input</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">grad_bottom_l2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_op_param_sens</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_net_l2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params_bottom_deep</span><span class="p">)(</span><span class="n">sens</span><span class="p">)</span>
    <span class="n">zipped</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">grad_bottom_deep</span><span class="p">,</span> <span class="n">grad_bottom_l2</span><span class="p">)</span>
    <span class="n">grad_bottom_deep</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">sum</span><span class="p">,</span> <span class="n">zipped</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_bottom_deep</span><span class="p">(</span><span class="n">grad_bottom_deep</span><span class="p">)</span>

    <span class="c1"># output the gradients for follower party</span>
    <span class="n">scales</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">scales</span><span class="p">[</span><span class="s1">&#39;wide_loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="nb">zip</span><span class="p">([</span><span class="s1">&#39;wide_embedding&#39;</span><span class="p">,</span> <span class="s1">&#39;deep_embedding&#39;</span><span class="p">],</span> <span class="n">grad_cutlayer_input</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]))</span>
    <span class="n">scales</span><span class="p">[</span><span class="s1">&#39;deep_loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scales</span><span class="p">[</span><span class="s1">&#39;wide_loss&#39;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">scales</span>
</pre></div>
</div>
</div>
<div class="section" id="定义优化器">
<h4>定义优化器<a class="headerlink" href="#定义优化器" title="永久链接至标题">¶</a></h4>
<p>定义优化器时，在yaml文件中就不需定义<code class="docutils literal notranslate"><span class="pre">grad_network</span></code>已涉及到的反向传播部分了，除此之外和通常的vfl模型定义优化器就没有区别了。</p>
</div>
</div>
<div class="section" id="构建训练脚本">
<h3>构建训练脚本<a class="headerlink" href="#构建训练脚本" title="永久链接至标题">¶</a></h3>
<div class="section" id="构建网络">
<h4>构建网络<a class="headerlink" href="#构建网络" title="永久链接至标题">¶</a></h4>
<p>与通常的vFL训练相同，用户需要使用MindSpore Federated提供的类，将自己构造好的网络封装成纵向联邦网络。详细的API文档可以参考<a class="reference external" href="https://gitee.com/mindspore/federated/blob/master/docs/api/api_python/vertical/vertical_federated_FLModel.rst">纵向联邦训练接口</a>。不同点则在于：构建leader方网络时，需要加上<code class="docutils literal notranslate"><span class="pre">grad_network</span></code>：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_federated</span> <span class="kn">import</span> <span class="n">FLModel</span><span class="p">,</span> <span class="n">FLYamlData</span>
<span class="kn">from</span> <span class="nn">network_config</span> <span class="kn">import</span> <span class="n">config</span>
<span class="kn">from</span> <span class="nn">wide_and_deep</span> <span class="kn">import</span> <span class="n">LeaderNet</span><span class="p">,</span> <span class="n">LeaderLossNet</span><span class="p">,</span> <span class="n">LeaderGradNet</span>


<span class="n">leader_base_net</span> <span class="o">=</span> <span class="n">LeaderNet</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">leader_train_net</span> <span class="o">=</span> <span class="n">LeaderLossNet</span><span class="p">(</span><span class="n">leader_base_net</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<span class="n">leader_grad_net</span> <span class="o">=</span> <span class="n">LeaderGradNet</span><span class="p">(</span><span class="n">leader_base_net</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>

<span class="n">leader_yaml_data</span> <span class="o">=</span> <span class="n">FLYamlData</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">leader_yaml_path</span><span class="p">)</span>
<span class="n">leader_fl_model</span> <span class="o">=</span> <span class="n">FLModel</span><span class="p">(</span><span class="n">yaml_data</span><span class="o">=</span><span class="n">leader_yaml_data</span><span class="p">,</span>
                          <span class="n">network</span><span class="o">=</span><span class="n">leader_base_net</span><span class="p">,</span>
                          <span class="n">grad_network</span><span class="o">=</span><span class="n">Leader_grad_net</span><span class="p">,</span>
                          <span class="n">train_network</span><span class="o">=</span><span class="n">leader_train_net</span><span class="p">)</span>
</pre></div>
</div>
<p>除了上述提到的内容之外，TEE训练的其他的部分都和通常的vFL训练完全一致，使用者在配置完成后便可让模型享受TEE的安全保证。</p>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="secure_vertical_federated_learning_with_DP.html" class="btn btn-neutral float-right" title="纵向联邦-基于差分隐私的标签保护" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="secure_vertical_federated_learning_with_EmbeddingDP.html" class="btn btn-neutral float-left" title="纵向联邦-基于信息混淆的特征保护" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>