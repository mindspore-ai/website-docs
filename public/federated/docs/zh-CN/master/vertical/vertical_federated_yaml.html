

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>模型训练yaml详细配置项 &mdash; MindSpore master 文档</title>
  

  
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/translations.js"></script>
        
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="FAQ" href="../faq.html" />
    <link rel="prev" title="模型训练接口" href="vertical_federated_FLModel.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../federated_install.html">获取MindSpore Federated</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy_federated_server.html">横向联邦云侧部署</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy_federated_client.html">横向联邦端侧部署</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy_vfl.html">纵向联邦部署</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">横向应用实践</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../image_classfication_dataset_process.html">联邦学习图像分类数据集处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../image_classification_application.html">实现一个端云联邦的图像分类应用(x86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sentiment_classification_application.html">实现一个端云情感分类应用(Android)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../image_classification_application_in_cross_silo.html">实现一个云云联邦的图像分类应用(x86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../object_detection_application_in_cross_silo.html">实现一个云云联邦的目标检测应用(x86)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">纵向应用实践</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../data_join.html">纵向联邦学习数据接入</a></li>
<li class="toctree-l1"><a class="reference internal" href="../split_wnd_application.html">纵向联邦学习模型训练 - Wide&amp;Deep推荐应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../split_pangu_alpha_application.html">纵向联邦学习模型训练 - 盘古α大模型跨域训练</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">安全和隐私</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../local_differential_privacy_training_noise.html">横向联邦-局部差分隐私加噪训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../local_differential_privacy_training_signds.html">横向联邦-局部差分隐私SignDS训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../local_differential_privacy_eval_laplace.html">横向联邦-局部差分隐私推理结果保护</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pairwise_encryption_training.html">横向联邦-安全聚合训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../private_set_intersection.html">纵向联邦-隐私集合求交</a></li>
<li class="toctree-l1"><a class="reference internal" href="../secure_vertical_federated_learning_with_EmbeddingDP.html">纵向联邦-基于信息混淆的特征保护</a></li>
<li class="toctree-l1"><a class="reference internal" href="../secure_vertical_federated_learning_with_TEE.html">纵向联邦-基于可信执行环境的特征保护</a></li>
<li class="toctree-l1"><a class="reference internal" href="../secure_vertical_federated_learning_with_DP.html">纵向联邦-基于差分隐私的标签保护</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">通信压缩</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../communication_compression.html">端云联邦学习通信压缩</a></li>
<li class="toctree-l1"><a class="reference internal" href="../vfl_communication_compress.html">纵向联邦学习通信压缩</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">横向联邦API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../horizontal_server.html">联邦服务器</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cross_device.html">端侧客户端</a></li>
<li class="toctree-l1"><a class="reference internal" href="../horizontal/cross_silo.html">云侧客户端</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">纵向联邦API参考</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../Data_Join.html">数据求交</a></li>
<li class="toctree-l1"><a class="reference internal" href="vertical_communicator.html">纵向联邦学习通信器</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../vertical_federated_trainer.html">纵向联邦训练器</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="vertical_federated_FLModel.html">模型训练接口</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">模型训练yaml详细配置项</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../vertical_federated_trainer.html">纵向联邦训练器</a> &raquo;</li>
      <li>模型训练yaml详细配置项</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/vertical/vertical_federated_yaml.md.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section class="tex2jax_ignore mathjax_ignore" id="模型训练yaml详细配置项">
<h1>模型训练yaml详细配置项<a class="headerlink" href="#模型训练yaml详细配置项" title="永久链接至标题"></a></h1>
<p>MindSpore-Federated纵向联邦学习框架采用yaml配置文件，配置纵向联邦学习模型的训练与推理流程，包括网络、优化器、算子等模块的输入/输出和超参数信息。yaml配置文件的详细信息参见下表：</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>功能分类</p></th>
<th class="head"><p>配置参数</p></th>
<th class="head"><p>参数类型</p></th>
<th class="head"><p>取值范围</p></th>
<th class="head"><p>是否必选</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>role</p></td>
<td><p>role</p></td>
<td><p>str</p></td>
<td><p>‘leader’ or ‘follower’</p></td>
<td><p>是</p></td>
</tr>
<tr class="row-odd"><td><p>model</p></td>
<td><p>train_net</p></td>
<td><p>dict</p></td>
<td><p></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>train_net.name</p></td>
<td><p>str</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>train_net.inputs</p></td>
<td><p>list</p></td>
<td><p></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>train_net.inputs.name</p></td>
<td><p>str</p></td>
<td><p></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>train_net.inputs.source</p></td>
<td><p>str</p></td>
<td><p>‘remote’ or ‘local’</p></td>
<td><p>是</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>train_net.inputs.compress_type</p></td>
<td><p>str</p></td>
<td><p>‘min_max’ or ‘bit_pack’ or ‘no_compress’</p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>train_net.inputs.bit_num</p></td>
<td><p>int</p></td>
<td><p>[1, 8]</p></td>
<td><p>否</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>train_net.outputs</p></td>
<td><p>list</p></td>
<td><p></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>train_net.outputs.name</p></td>
<td><p>str</p></td>
<td><p></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>train_net.outputs.destination</p></td>
<td><p>str</p></td>
<td><p>‘remote’ or ‘local’</p></td>
<td><p>是</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>train_net.outputs.compress_type</p></td>
<td><p>str</p></td>
<td><p>‘min_max’ or ‘bit_pack’ or ‘no_compress’</p></td>
<td><p>否</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>train_net.outputs.bit_num</p></td>
<td><p>int</p></td>
<td><p>[1, 8]</p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>eval_net</p></td>
<td><p>dict</p></td>
<td><p></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>eval_net.name</p></td>
<td><p>str</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>eval_net.inputs</p></td>
<td><p>list</p></td>
<td><p></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>eval_net.inputs.name</p></td>
<td><p>str</p></td>
<td><p></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>eval_net.inputs.source</p></td>
<td><p>str</p></td>
<td><p>‘remote’ or ‘local’</p></td>
<td><p>是</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>eval_net.inputs.compress_type</p></td>
<td><p>str</p></td>
<td><p>‘min_max’ or ‘bit_pack’ or ‘no_compress’</p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>eval_net.inputs.bit_num</p></td>
<td><p>int</p></td>
<td><p>[1, 8]</p></td>
<td><p>否</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>eval_net.outputs</p></td>
<td><p>list</p></td>
<td><p></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>eval_net.output.name</p></td>
<td><p>str</p></td>
<td><p></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>eval_net.output.destination</p></td>
<td><p>str</p></td>
<td><p>‘remote’ or ‘local’</p></td>
<td><p>是</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>eval_net.outputs.compress_type</p></td>
<td><p>str</p></td>
<td><p>‘min_max’ or ‘bit_pack’ or ‘no_compress’</p></td>
<td><p>否</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>eval_net.outputs.bit_num</p></td>
<td><p>int</p></td>
<td><p>[1, 8]</p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>eval_net.gt</p></td>
<td><p>str</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-even"><td><p>opts</p></td>
<td><p>type</p></td>
<td><p>str</p></td>
<td><p>mindspore.nn.optim内定义的优化器名称</p></td>
<td><p>是</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>grads</p></td>
<td><p>list</p></td>
<td><p></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>grads.inputs</p></td>
<td><p>list</p></td>
<td><p></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>grads.inputs.name</p></td>
<td><p>str</p></td>
<td><p></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>grads.output</p></td>
<td><p>dict</p></td>
<td><p></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>grads.output.name</p></td>
<td><p>str</p></td>
<td><p></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>grads.params</p></td>
<td><p>list</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>grads.params.name</p></td>
<td><p>str</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>grads.sens</p></td>
<td><p>union(float, int, str)</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>params</p></td>
<td><p>list</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>params.name</p></td>
<td><p>str</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>hyper_parameters</p></td>
<td><p>dict</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-even"><td><p>grad_scalers</p></td>
<td><p>inputs</p></td>
<td><p>list</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>inputs.name</p></td>
<td><p>str</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>output</p></td>
<td><p>dict</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>output.name</p></td>
<td><p>str</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>sens</p></td>
<td><p>union(float, int, str)</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p>dataset</p></td>
<td><p>name</p></td>
<td><p>str</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>features</p></td>
<td><p>list</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>labels</p></td>
<td><p>list</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-even"><td><p>hyper_parameters</p></td>
<td><p>epochs</p></td>
<td><p>int</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>batch_size</p></td>
<td><p>int</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>is_eval</p></td>
<td><p>bool</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p>privacy</p></td>
<td><p>label_dp</p></td>
<td><p>dict</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>label_dp.eps</p></td>
<td><p>float</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
<tr class="row-odd"><td><p>ckpt_path</p></td>
<td><p></p></td>
<td><p>str</p></td>
<td><p></p></td>
<td><p>否</p></td>
</tr>
</tbody>
</table>
<p>其中：</p>
<ul class="simple">
<li><p><strong>role</strong> (str) -  联邦学习参与方角色，必须是 <code class="docutils literal notranslate"><span class="pre">&quot;leader&quot;</span></code> 或 <code class="docutils literal notranslate"><span class="pre">&quot;follower&quot;</span></code>。默认值：<code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>train_net</strong> (dict) - 描述训练网络输入、输出等信息的数据结构。默认值：<code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>train_net.name</strong> (str) - 训练网络名称标识符。默认值：<code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>train_net.inputs</strong> (list) - 训练网络输入Tensor列表，每个元素均为描述一个输入Tensor的字典。元素的排列顺序和名称，必须与MindSpore建模的训练网络（nn.Cell）construct方法的输入Tensor顺序和名称保持一致。默认值：<code class="docutils literal notranslate"><span class="pre">[]</span></code>。</p></li>
<li><p><strong>train_net.inputs.name</strong> (str) - 训练网络输入Tensor名称，必须与MindSpore建模的训练网络（nn.Cell）的输入Tensor名称保持一致。默认值：<code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>train_net.inputs.source</strong>(str) - 训练网络输入Tensor的数据来源，必须是 <code class="docutils literal notranslate"><span class="pre">&quot;remote&quot;</span></code> 或 <code class="docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>，<code class="docutils literal notranslate"><span class="pre">&quot;remote&quot;</span></code> 代表数据来源于其它参与方的网络传输，<code class="docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code> 代表数据来源于本地。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>。</p></li>
<li><p><strong>train_net.inputs.compress_type</strong>(str) - 压缩类型，必须是 <code class="docutils literal notranslate"><span class="pre">&quot;min_max&quot;</span></code> 或 <code class="docutils literal notranslate"><span class="pre">&quot;bit_pack&quot;</span></code> 或 <code class="docutils literal notranslate"><span class="pre">&quot;no_compress&quot;</span></code>，<code class="docutils literal notranslate"><span class="pre">&quot;min_max&quot;</span></code> 代表采用最小最大量化通信压缩方法，<code class="docutils literal notranslate"><span class="pre">&quot;bit_pack&quot;</span></code> 代表采用比特打包通信压缩方法，<code class="docutils literal notranslate"><span class="pre">&quot;no_compress&quot;</span></code> 代表不采用通信压缩方法。</p></li>
<li><p><strong>train_net.inputs.bit_num</strong>(int) - 通信压缩算法中的比特数。</p></li>
<li><p><strong>train_net.outputs</strong>  - (list) - 训练网络输出Tensor列表，每个元素均为描述一个输出Tensor的字典。元素的排列顺序和名称，必须与MindSpore建模的训练网络（nn.Cell）的construct方法的返回值Tensor顺序和名称保持一致。默认值：<code class="docutils literal notranslate"><span class="pre">[]</span></code>。</p></li>
<li><p><strong>train_net.outputs.name</strong> (str) - 训练网络输出Tensor名称，必须与MindSpore建模的训练网络（nn.Cell）的输出Tensor名称保持一致。默认值：<code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>train_net.outputs.destination</strong>(str) - 训练网络输出Tensor的数据去向，必须是 <code class="docutils literal notranslate"><span class="pre">&quot;remote&quot;</span></code> 或 <code class="docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>，<code class="docutils literal notranslate"><span class="pre">&quot;remote&quot;</span></code> 代表数据将通过网络传输给其它参与方，<code class="docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code> 代表数据本地使用，不进行网络传输。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>。</p></li>
<li><p><strong>train_net.outputs.compress_type</strong>(str) - 压缩类型，必须是 <code class="docutils literal notranslate"><span class="pre">&quot;min_max&quot;</span></code> 或 <code class="docutils literal notranslate"><span class="pre">&quot;bit_pack&quot;或&quot;no_compress&quot;</span></code>，<code class="docutils literal notranslate"><span class="pre">&quot;min_max&quot;</span></code>代表采用最小最大量化通信压缩方法，<code class="docutils literal notranslate"><span class="pre">&quot;bit_pack&quot;</span></code> 代表采用比特打包通信压缩方法，<code class="docutils literal notranslate"><span class="pre">&quot;no_compress&quot;</span></code> 代表不采用通信压缩方法。</p></li>
<li><p><strong>train_net.outputs.bit_num</strong>(int) - 通信压缩算法中的比特数。</p></li>
<li><p><strong>eval_net</strong> (dict) - 描述评估网络输入、输出等信息的数据结构。默认值：<code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>eval_net.name</strong> (str) - 评估网络名称标识符。默认值：<code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>eval_net.inputs</strong> (list) - 评估网络输入Tensor列表，每个元素均为描述一个输入Tensor的字典。元素的排列顺序和名称，必须与MindSpore建模的评估网络（nn.Cell）construct方法的输入Tensor顺序和名称保持一致。默认值：<code class="docutils literal notranslate"><span class="pre">[]</span></code>。</p></li>
<li><p><strong>eval_net.inputs.name</strong> (str) - 评估网络输入Tensor名称，必须与MindSpore建模的训练网络（nn.Cell）的输入Tensor名称保持一致。默认值：<code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>eval_net.inputs.source</strong>(str) - 评估网络输入Tensor的数据来源，必须是 <code class="docutils literal notranslate"><span class="pre">&quot;remote&quot;</span></code> 或 <code class="docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>，<code class="docutils literal notranslate"><span class="pre">&quot;remote&quot;</span></code> 代表数据来源于其它参与方的网络传输，<code class="docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code> 代表数据来源于本地。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>。</p></li>
<li><p><strong>eval_net.inputs.compress_type</strong>(str) - 压缩类型，必须是 <code class="docutils literal notranslate"><span class="pre">&quot;min_max&quot;</span></code> 或 <code class="docutils literal notranslate"><span class="pre">&quot;bit_pack&quot;</span></code> 或 <code class="docutils literal notranslate"><span class="pre">&quot;no_compress&quot;</span></code>，<code class="docutils literal notranslate"><span class="pre">&quot;min_max&quot;</span></code> 代表采用最小最大量化通信压缩方法，<code class="docutils literal notranslate"><span class="pre">&quot;bit_pack&quot;</span></code> 代表采用比特打包通信压缩方法，<code class="docutils literal notranslate"><span class="pre">&quot;no_compress&quot;</span></code> 代表不采用通信压缩方法。</p></li>
<li><p><strong>eval_net.inputs.bit_num</strong>(int) - 通信压缩算法中的比特数。</p></li>
<li><p><strong>eval_net.outputs</strong>  - (list) - 评估网络输出Tensor列表，每个元素均为描述一个输出Tensor的字典。元素的排列顺序和名称，必须与MindSpore建模的评估网络（nn.Cell）的construct方法的返回值Tensor顺序和名称保持一致。默认值：<code class="docutils literal notranslate"><span class="pre">[]</span></code>。</p></li>
<li><p><strong>eval_net.outputs.name</strong> (str) - 评估网络输出Tensor名称，必须与MindSpore建模的评估网络（nn.Cell）的输出Tensor名称保持一致。默认值：<code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>eval_net.outputs.destination</strong>(str) - 评估网络输出Tensor的数据去向，必须是 <code class="docutils literal notranslate"><span class="pre">&quot;remote&quot;</span></code> 或 <code class="docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>，<code class="docutils literal notranslate"><span class="pre">&quot;remote&quot;</span></code> 代表数据将通过网络传输给其它参与方，<code class="docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code> 代表数据本地使用，不进行网络传输。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>。</p></li>
<li><p><strong>eval_net.outputs.compress_type</strong>(str) - 压缩类型，必须是 <code class="docutils literal notranslate"><span class="pre">&quot;min_max&quot;</span></code> 或 <code class="docutils literal notranslate"><span class="pre">&quot;bit_pack&quot;</span></code> 或 <code class="docutils literal notranslate"><span class="pre">&quot;no_compress&quot;</span></code>，<code class="docutils literal notranslate"><span class="pre">&quot;min_max&quot;</span></code> 代表采用最小最大量化通信压缩方法，<code class="docutils literal notranslate"><span class="pre">&quot;bit_pack&quot;</span></code> 代表采用比特打包通信压缩方法，<code class="docutils literal notranslate"><span class="pre">&quot;no_compress&quot;</span></code> 代表不采用通信压缩方法。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;min_max&quot;</span></code>。</p></li>
<li><p><strong>eval_net.outputs.bit_num</strong>(int) - 通信压缩算法中的比特数。</p></li>
<li><p><strong>eval_net.gt</strong>(str) - 评估网络输出对应的ground truth标签名称。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>type</strong> (str) - 优化器类型，需采用mindspore.nn.optim内定义的优化器，如 <code class="docutils literal notranslate"><span class="pre">&quot;Adam&quot;</span></code>，参考<a class="reference external" href="https://mindspore.cn/docs/zh-CN/master/api_python/mindspore.nn.html#%E4%BC%98%E5%8C%96%E5%99%A8">优化器</a>。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>grads</strong> (list) - 优化器关联的GradOperation列表，每个元素均为描述一个GradOperation算子的字典。默认值：<code class="docutils literal notranslate"><span class="pre">[]</span></code>。</p></li>
<li><p><strong>grads.inputs</strong> (list) - GradOperation算子的输入Tensor列表，每个元素均为描述一个输入Tensor的字典。默认值：<code class="docutils literal notranslate"><span class="pre">[]</span></code>。</p></li>
<li><p><strong>grads.inputs.name</strong> (str) - GradOperation算子的输入Tensor名称。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>grads.output</strong> (dict) - 描述GradOperation算子对应的网络输出Tensor的字典。默认值：<code class="docutils literal notranslate"><span class="pre">{}</span></code>。</p></li>
<li><p><strong>grads.output.name</strong> (str) - GradOperation算子对应的网络输出Tensor名称。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>grads.params</strong> (list) - GradOperation算子计算梯度值的训练网络参数列表，每个元素对应一个网络参数名称。如果为空，则将计算关联优化器所更新参数的梯度值。默认值：<code class="docutils literal notranslate"><span class="pre">[]</span></code>。</p></li>
<li><p><strong>grads.params.name</strong> (str) - GradOperation算子计算梯度值的训练网络参数名称。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>grads.sens</strong> (union(float, int, str)) - GradOperation算子计算网络参数梯度的加权系数，对应GradOperation算子的”灵敏度”（参考<a class="reference external" href="https://mindspore.cn/docs/zh-CN/master/api_python/ops/mindspore.ops.GradOperation.html?highlight=gradoperation">mindspore.ops.GradOperation</a>）。如果是float或int类型，则采用常量作为加权系数；如果是str类型，则从其它参与方经网络传输的加权系数中，解析名称与其对应的Tensor作为加权系数。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>params</strong> (list) - 优化器根据梯度计算结果，更新的训练网络参数列表，每个元素对应一个网络参数名称。如果为空，则优化器将更新训练为例的所有可训练参数。默认值：<code class="docutils literal notranslate"><span class="pre">[]</span></code>。</p></li>
<li><p><strong>params.name</strong> (str) - 优化器更新的训练网络的参数名称。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>hyper_parameters</strong> (dict) - 优化器超参数字典，参考type所指定的MindSpore优化器算子的超参数。默认值：<code class="docutils literal notranslate"><span class="pre">{}</span></code>。</p></li>
<li><p><strong>grad_scalers.inputs</strong> (list) - 用于计算梯度加权系数的GradOperation算子的输入Tensor列表，每个元素均为描述一个输入Tensor的字典。默认值：<code class="docutils literal notranslate"><span class="pre">[]</span></code>。</p></li>
<li><p><strong>grad_scalers.inputs.name</strong> (str) - 用于计算梯度加权系数的GradOperation算子的输入Tensor名称。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>grad_scalers.output</strong> (list) - 描述用于计算梯度加权系数的GradOperation算子对应的网络输出Tensor的字典.默认值：<code class="docutils literal notranslate"><span class="pre">{}</span></code>。</p></li>
<li><p><strong>grad_scalers.output.name</strong> (str) - 描述用于计算梯度加权系数的GradOperation算子对应的网络输出Tensor名称。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>grad_scalers.sens</strong> (str) - 描述用于计算梯度加权系数的GradOperation算子计算网络参数梯度的加权系数，对应GradOperation算子的”灵敏度”（参考<a class="reference external" href="https://mindspore.cn/docs/zh-CN/master/api_python/ops/mindspore.ops.GradOperation.html?highlight=gradoperation">mindspore.ops.GradOperation</a>）。如果是float或int类型，则采用常量作为加权系数；如果是str类型，则从其它参与方经网络传输的数据中，解析名称与其对应的Tensor作为加权系数。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>dataset.name</strong> (str) - 数据集名称。默认值： <code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code>。</p></li>
<li><p><strong>dataset.features</strong> (list) - 数据集特征列表，每个元素均为一个str类型的特征名称。默认值：<code class="docutils literal notranslate"><span class="pre">[]</span></code>。</p></li>
<li><p><strong>dataset.labels</strong> (list) - 数据集标签列表，每个元素均为一个str类型的标签名称。默认值：<code class="docutils literal notranslate"><span class="pre">[]</span></code>。</p></li>
<li><p><strong>epochs</strong> (int) - 训练的epoch数。默认值：<code class="docutils literal notranslate"><span class="pre">1</span></code>。</p></li>
<li><p><strong>batch_size</strong> (int) - 训练的数据batch size。默认值：<code class="docutils literal notranslate"><span class="pre">1</span></code>。</p></li>
<li><p><strong>is_eval</strong> (bool) - 训练完成后是否执行评估。默认值：<code class="docutils literal notranslate"><span class="pre">False</span></code>。</p></li>
<li><p><strong>label_dp</strong> (dict) - 差分隐私机制的配置参数。默认值：<code class="docutils literal notranslate"><span class="pre">{}</span></code>。</p></li>
<li><p><strong>label_dp.eps</strong> (float) - 差分隐私机制的eps参数。默认值：<code class="docutils literal notranslate"><span class="pre">1.0</span></code>。</p></li>
<li><p><strong>ckpt_path</strong> (str) - 保存训练网络checkpoint文件的路径。默认值：<code class="docutils literal notranslate"><span class="pre">&quot;./checkpoints&quot;</span></code>。</p></li>
</ul>
<p>以本项目所提供的<a class="reference external" href="https://gitee.com/mindspore/federated/tree/master/example/splitnn_criteo">纵向联邦学习模型训练 - Wide&amp;Deep推荐应用</a>为例，其基于Wide&amp;Deep模型和Criteo数据集，进行纵向联邦学习模型训练，其纵向联邦Leader参与方的yaml如下：</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">role</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">leader</span>
<span class="nt">model</span><span class="p">:</span><span class="w"> </span><span class="c1"># define the net of vFL party</span>
<span class="w">  </span><span class="nt">train_net</span><span class="p">:</span>
<span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">leader_loss_net</span>
<span class="w">    </span><span class="nt">inputs</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">id_hldr</span>
<span class="w">        </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">local</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wt_hldr</span>
<span class="w">        </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">local</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wide_embedding</span>
<span class="w">        </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">remote</span>
<span class="w">        </span><span class="nt">compress_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">min_max</span>
<span class="w">        </span><span class="nt">bit_num</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">deep_embedding</span>
<span class="w">        </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">remote</span>
<span class="w">        </span><span class="nt">compress_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">min_max</span>
<span class="w">        </span><span class="nt">bit_num</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">label</span>
<span class="w">        </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">local</span>
<span class="w">    </span><span class="nt">outputs</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">out</span>
<span class="w">        </span><span class="nt">destination</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">local</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wide_loss</span>
<span class="w">        </span><span class="nt">destination</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">local</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">deep_loss</span>
<span class="w">        </span><span class="nt">destination</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">local</span>
<span class="w">  </span><span class="nt">eval_net</span><span class="p">:</span>
<span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">leader_eval_net</span>
<span class="w">    </span><span class="nt">inputs</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">id_hldr</span>
<span class="w">        </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">local</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wt_hldr</span>
<span class="w">        </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">local</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wide_embedding</span>
<span class="w">        </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">remote</span>
<span class="w">        </span><span class="nt">compress_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">min_max</span>
<span class="w">        </span><span class="nt">bit_num</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">deep_embedding</span>
<span class="w">        </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">remote</span>
<span class="w">        </span><span class="nt">compress_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">min_max</span>
<span class="w">        </span><span class="nt">bit_num</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="w">    </span><span class="nt">outputs</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">logits</span>
<span class="w">        </span><span class="nt">destination</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">local</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pred_probs</span>
<span class="w">        </span><span class="nt">destination</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">local</span>
<span class="w">    </span><span class="nt">gt</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">label</span>
<span class="nt">opts</span><span class="p">:</span><span class="w"> </span><span class="c1"># define ms optimizer</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">FTRL</span>
<span class="w">    </span><span class="nt">grads</span><span class="p">:</span><span class="w"> </span><span class="c1"># define ms grad operations</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">inputs</span><span class="p">:</span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">id_hldr</span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wt_hldr</span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wide_embedding</span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">deep_embedding</span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">label</span>
<span class="w">        </span><span class="nt">output</span><span class="p">:</span>
<span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wide_loss</span>
<span class="w">        </span><span class="nt">sens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024.0</span>
<span class="w">        </span><span class="c1"># if not specify params, inherit params of optimizer</span>
<span class="w">    </span><span class="nt">params</span><span class="p">:</span><span class="w">  </span><span class="c1"># if not specify params, process all trainable params</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wide</span>
<span class="w">    </span><span class="nt">hyper_parameters</span><span class="p">:</span>
<span class="w">      </span><span class="nt">learning_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5.e-2</span>
<span class="w">      </span><span class="nt">l1</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.e-8</span>
<span class="w">      </span><span class="nt">l2</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.e-8</span>
<span class="w">      </span><span class="nt">initial_accum</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
<span class="w">      </span><span class="nt">loss_scale</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024.0</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Adam</span>
<span class="w">    </span><span class="nt">grads</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">inputs</span><span class="p">:</span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">id_hldr</span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wt_hldr</span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wide_embedding</span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">deep_embedding</span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">label</span>
<span class="w">        </span><span class="nt">output</span><span class="p">:</span>
<span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">deep_loss</span>
<span class="w">        </span><span class="nt">sens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024.0</span>
<span class="w">    </span><span class="nt">params</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">deep</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="w">    </span><span class="nt">hyper_parameters</span><span class="p">:</span>
<span class="w">      </span><span class="nt">learning_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3.5e-4</span>
<span class="w">      </span><span class="nt">eps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.e-8</span>
<span class="w">      </span><span class="nt">loss_scale</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024.0</span>
<span class="nt">grad_scalers</span><span class="p">:</span><span class="w"> </span><span class="c1"># define the grad scale calculator</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">inputs</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wide_embedding</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">deep_embedding</span>
<span class="w">    </span><span class="nt">output</span><span class="p">:</span>
<span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wide_loss</span>
<span class="w">    </span><span class="nt">sens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024.0</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">inputs</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wide_embedding</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">deep_embedding</span>
<span class="w">    </span><span class="nt">output</span><span class="p">:</span>
<span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">deep_loss</span>
<span class="w">    </span><span class="nt">sens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024.0</span>
<span class="nt">dataset</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">criteo</span>
<span class="w">  </span><span class="nt">features</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">id_hldr</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wt_hldr</span>
<span class="w">  </span><span class="nt">labels</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ctr</span>
<span class="nt">hyper_parameters</span><span class="p">:</span>
<span class="w">  </span><span class="nt">epochs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20</span>
<span class="w">  </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16000</span>
<span class="w">  </span><span class="nt">is_eval</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="nt">ckpt_path</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;./checkpoints&#39;</span>
</pre></div>
</div>
</section>


           </div>
           
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="vertical_federated_FLModel.html" class="btn btn-neutral float-left" title="模型训练接口" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="../faq.html" class="btn btn-neutral float-right" title="FAQ" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2022, MindSpore.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>