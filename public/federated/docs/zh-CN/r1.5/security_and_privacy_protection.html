

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>模型安全和隐私 &mdash; MindSpore master documentation</title>
  

  
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="实现一个云云联邦的目标检测应用(x86)" href="object_detection_application_in_cross_silo.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="federated_install.html">获取MindSpore Federated</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_federated_server.html">云侧部署</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_federated_client.html">端侧部署</a></li>
</ul>
<p class="caption"><span class="caption-text">应用实践</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="image_classification_application.html">实现一个端云联邦的图像分类应用(x86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="sentiment_classification_application.html">实现一个情感分类应用(Android)</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_classification_application_in_cross_silo.html">实现一个云云联邦的图像分类应用(x86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="object_detection_application_in_cross_silo.html">实现一个云云联邦的目标检测应用(x86)</a></li>
</ul>
<p class="caption"><span class="caption-text">安全和隐私</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">模型安全和隐私</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#ldp">基于LDP的安全聚合</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">原理概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">使用方式</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#mpc">基于MPC的安全聚合</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id4">原理概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">使用方式</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">参考文献</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>模型安全和隐私</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/security_and_privacy_protection.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="id1">
<h1>模型安全和隐私<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<!-- TOC -->
<ul class="simple">
<li><p><a class="reference external" href="#%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E5%92%8C%E9%9A%90%E7%A7%81">模型安全和隐私</a></p>
<ul>
<li><p><a class="reference external" href="#%E5%9F%BA%E4%BA%8Eldp%E7%9A%84%E5%AE%89%E5%85%A8%E8%81%9A%E5%90%88">基于LDP的安全聚合</a></p>
<ul>
<li><p><a class="reference external" href="#%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0">原理概述</a></p></li>
<li><p><a class="reference external" href="#%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F">使用方式</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#%E5%9F%BA%E4%BA%8Empc%E7%9A%84%E5%AE%89%E5%85%A8%E8%81%9A%E5%90%88">基于MPC的安全聚合</a></p>
<ul>
<li><p><a class="reference external" href="#%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0-1">原理概述</a></p></li>
<li><p><a class="reference external" href="#%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F-1">使用方式</a></p></li>
<li><p><a class="reference external" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE">参考文献</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- /TOC -->
<p><a href="https://gitee.com/mindspore/docs/blob/r1.5/docs/federated/docs/source_zh_cn/security_and_privacy_protection.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source.png"></a></p>
<p>联邦学习过程中，用户数据仅用于本地设备训练，不需要上传至中心服务器，可以避免用户个人数据的直接泄露。然而传统联邦学习框架中，模型以明文形式上云，仍然存在间接泄露用户隐私的风险。敌手获取到用户上传的明文模型后，可以通过重构、模型逆向等攻击恢复用户的个人训练数据，导致用户隐私泄露。</p>
<p>MindSpore Federated联邦学习框架，提供了基于本地差分隐私（LDP）和基于多方安全计算（MPC）的安全聚合算法，在本地模型上云前对其进行加噪或加扰。在保证模型可用性的前提下，解决横向联邦学习中的隐私泄露问题。</p>
<div class="section" id="ldp">
<h2>基于LDP的安全聚合<a class="headerlink" href="#ldp" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id2">
<h3>原理概述<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>差分隐私（differential privacy）是一种保护用户数据隐私的机制。差分隐私定义为：</p>
<div class="math notranslate nohighlight">
\[
Pr[\mathcal{K}(D)\in S] \le e^{\epsilon} Pr[\mathcal{K}(D’) \in S]+\delta​
\]</div>
<p>对于两个差别只有一条记录的数据集<span class="math notranslate nohighlight">\(D, D’\)</span>，通过随机算法<span class="math notranslate nohighlight">\(\mathcal{K}\)</span>，输出结果为集合<span class="math notranslate nohighlight">\(S\)</span>子集的概率满足上面公式。<span class="math notranslate nohighlight">\(\epsilon\)</span>为差分隐私预算，<span class="math notranslate nohighlight">\(\delta\)</span>扰动，<span class="math notranslate nohighlight">\(\epsilon\)</span>和<span class="math notranslate nohighlight">\(\delta\)</span>越小，说明<span class="math notranslate nohighlight">\(\mathcal{K}\)</span>在<span class="math notranslate nohighlight">\(D\)</span>和<span class="math notranslate nohighlight">\(D’\)</span>上输出的数据分布越接近。</p>
<p>在横向联邦学习中，假设客户端本地训练之后的模型权重矩阵是<span class="math notranslate nohighlight">\(W\)</span>，由于模型在训练过程中会“记住”训练集的特征，所以敌手可以借助<span class="math notranslate nohighlight">\(W\)</span>还原出用户的训练数据集[1]。</p>
<p>MindSpore Federated提供基于本地差分隐私的安全聚合算法，防止本地模型上云时泄露隐私数据。</p>
<p>MindSpore Federated客户端会生成一个与本地模型<span class="math notranslate nohighlight">\(W\)</span>相同维度的差分噪声矩阵<span class="math notranslate nohighlight">\(G\)</span>，然后将二者相加，得到一个满足差分隐私定义的权重<span class="math notranslate nohighlight">\(W_p\)</span>:</p>
<div class="math notranslate nohighlight">
\[
W_p=W+G
\]</div>
<p>MindSpore Federated客户端将加噪后的模型<span class="math notranslate nohighlight">\(W_p\)</span>上传至云侧服务器进行联邦聚合。噪声矩阵<span class="math notranslate nohighlight">\(G\)</span>相当于给原模型加上了一层掩码，在降低模型泄露敏感数据风险的同时，也会影响模型训练的收敛性。如何在模型隐私性和可用性之间取得更好的平衡，仍然是一个值得研究的问题。实验表明，当参与方的数量<span class="math notranslate nohighlight">\(n\)</span>足够大时（一般指1000以上），大部分噪声能够相互抵消，本地差分机制对聚合模型的精度和收敛性没有明显影响。</p>
</div>
<div class="section" id="id3">
<h3>使用方式<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>开启差分隐私训练的方式很简单，只需要在启动云侧服务时，使用<code class="docutils literal notranslate"><span class="pre">context.set_fl_context()</span></code>设置<code class="docutils literal notranslate"><span class="pre">encrypt_type='DP_ENCRYPT'</span></code>即可。</p>
<p>此外，为了控制隐私保护的效果，我们还提供了3个参数：<code class="docutils literal notranslate"><span class="pre">dp_eps</span></code>，<code class="docutils literal notranslate"><span class="pre">dp_delta</span></code>以及<code class="docutils literal notranslate"><span class="pre">dp_norm_clip</span></code>，它们也是通过<code class="docutils literal notranslate"><span class="pre">context.set_fl_context()</span></code>设置。</p>
<p><code class="docutils literal notranslate"><span class="pre">dp_eps</span></code>和<code class="docutils literal notranslate"><span class="pre">dp_norm_clip</span></code>的合法取值范围是大于0，<code class="docutils literal notranslate"><span class="pre">dp_delta</span></code>的合法取值范围是0&lt;<code class="docutils literal notranslate"><span class="pre">dp_delta</span></code>&lt;1。一般来说，<code class="docutils literal notranslate"><span class="pre">dp_eps</span></code>和<code class="docutils literal notranslate"><span class="pre">dp_delta</span></code>越小，隐私保护效果也越好，但是对模型收敛性的影响越大。建议<code class="docutils literal notranslate"><span class="pre">dp_delta</span></code>取成客户端数量的倒数，<code class="docutils literal notranslate"><span class="pre">dp_eps</span></code>大于50。</p>
<p><code class="docutils literal notranslate"><span class="pre">dp_norm_clip</span></code>是差分隐私机制对模型权重加噪前对权重大小的调整系数，会影响模型的收敛性，一般建议取0.5~2。</p>
</div>
</div>
<div class="section" id="mpc">
<h2>基于MPC的安全聚合<a class="headerlink" href="#mpc" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id4">
<h3>原理概述<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>尽管差分隐私技术可以适当保护用户数据隐私，但是当参与客户端数量比较少或者高斯噪声幅值较大时，模型精度会受较大影响。为了同时满足模型保护和模型收敛这两个要求，我们提供了基于MPC的安全聚合方案。</p>
<p>在这种训练模式下，假设参与的客户端集合为<span class="math notranslate nohighlight">\(U\)</span>，对于任意Federated-Client <span class="math notranslate nohighlight">\(u\)</span>和<span class="math notranslate nohighlight">\(v\)</span>，
它们会两两协商出一对随机扰动<span class="math notranslate nohighlight">\(p_{uv}\)</span>、<span class="math notranslate nohighlight">\(p_{vu}\)</span>，满足</p>
<div class="math notranslate nohighlight">
\[\begin{split}
p_{uv}=\begin{cases} -p_{vu}, &amp;u{\neq}v\\\\ 0, &amp;u=v \end{cases}
\end{split}\]</div>
<p>于是每个Federated-Client <span class="math notranslate nohighlight">\(u\)</span> 在上传模型至Server前，会在原模型权重<span class="math notranslate nohighlight">\(x_u\)</span>加上它与其它用户协商的扰动：</p>
<div class="math notranslate nohighlight">
\[
x_{encrypt}=x_u+\sum\limits_{v{\in}U}p_{uv}
\]</div>
<p>从而Federated-Server聚合结果<span class="math notranslate nohighlight">\(\overline{x}\)</span>为：</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\overline{x}&amp;=\sum\limits_{u{\in}U}(x_{u}+\sum\limits_{v{\in}U}p_{uv})\\\\
&amp;=\sum\limits_{u{\in}U}x_{u}+\sum\limits_{u{\in}U}\sum\limits_{v{\in}U}p_{uv}\\\\
&amp;=\sum\limits_{u{\in}U}x_{u}
\end{align}
\end{split}\]</div>
<p>上面的过程只是介绍了聚合算法的主要思想，基于MPC的聚合方案是精度无损的，代价是通讯轮次的增加。</p>
<p>如果您对算法的具体步骤感兴趣，可以参考原论文[2]。</p>
</div>
<div class="section" id="id5">
<h3>使用方式<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>与开启差分隐私训练相似，我们只需要在<code class="docutils literal notranslate"><span class="pre">context.set_fl_context()</span></code>中设置<code class="docutils literal notranslate"><span class="pre">encrypt_type='PW_ENCRYPT'</span></code>即可。</p>
<p>此外，与安全聚合训练相关的云侧环境参数还有<code class="docutils literal notranslate"><span class="pre">share_secrets_ratio</span></code>、<code class="docutils literal notranslate"><span class="pre">reconstruct_secrets_threshold</span></code>和<code class="docutils literal notranslate"><span class="pre">cipher_time_window</span></code>。</p>
<p><code class="docutils literal notranslate"><span class="pre">share_client_ratio</span></code>指代参与密钥碎片分享的客户端数量与参与联邦学习的客户端数量的比值，取值需要小于等于1。</p>
<p><code class="docutils literal notranslate"><span class="pre">reconstruct_secrets_threshold</span></code>指代参与密钥碎片恢复的客户端数量，取值需要小于参与密钥碎片分享的客户端数量。</p>
<p>通常为了保证系统安全，当不考虑Server和Client合谋的情况下，<code class="docutils literal notranslate"><span class="pre">reconstruct_secrets_threshold</span></code>需要大于联邦学习客户端数量的一半；当考虑Server和Client合谋，<code class="docutils literal notranslate"><span class="pre">reconstruct_secrets_threshold</span></code>需要大于联邦学习客户端数量的2/3。</p>
<p><code class="docutils literal notranslate"><span class="pre">cipher_time_window</span></code>指代安全聚合各通讯轮次的时长限制，主要用来保证某些客户端掉线的情况下，Server可以开始新一轮迭代。
需要注意的是，当前版本的安全聚合训练只支持<code class="docutils literal notranslate"><span class="pre">server_num=1</span></code>。</p>
</div>
<div class="section" id="id6">
<h3>参考文献<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>[1] Ligeng Zhu, Zhijian Liu, and Song Han. <a class="reference external" href="http://arxiv.org/pdf/1906.08935.pdf">Deep Leakage from Gradients</a>. NeurIPS, 2019.</p>
<p>[2] Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, et al. <a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3133956.3133982">Practical Secure Aggregationfor Privacy-Preserving Machine Learning</a>. NeurIPS, 2016.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="object_detection_application_in_cross_silo.html" class="btn btn-neutral float-left" title="实现一个云云联邦的目标检测应用(x86)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>