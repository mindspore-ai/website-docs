<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Applying the SCOP Algorithm &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Model Deployment Overview" href="../deployment/overview.html" />
    <link rel="prev" title="Pruning Algorithm Overview" href="overview.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation and Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing MindSpore Golden Stick</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quantization Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quantization/overview.html">Quantization Algorithm Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quantization/simqat.html">Applying the SimQAT Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quantization/slb.html">Applying the SLB Algorithm</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Pruning Algorithms</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Pruning Algorithm Overview</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Applying the SCOP Algorithm</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#background">Background</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pruning-method">Pruning Method</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scop-training">SCOP Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scop-training-example">SCOP Training Example</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#knockoff-data">Knockoff Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fine-tuning">Fine-tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loading-the-saved-model-for-evaluation">Loading the Saved Model for Evaluation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#exporting-a-pruned-model">Exporting a Pruned Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#summary">Summary</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#summary-of-training">Summary of Training</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deployment/overview.html">Model Deployment Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deployment/convert.html">MindSpore Golden Stick Network Conversion</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_gs.html">mindspore_gs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_gs.quantization.html">mindspore_gs.quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_gs.pruner.html">mindspore_gs.pruner</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Applying the SCOP Algorithm</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/pruner/scop.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="applying-the-scop-algorithm">
<h1>Applying the SCOP Algorithm<a class="headerlink" href="#applying-the-scop-algorithm" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/golden_stick/docs/source_en/pruner/scop.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.svg" /></a></p>
<section id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this headline"></a></h2>
<p>Deep learning models such as a convolutional neural network (CNN) have been widely applied to multiple fields such as computer vision and natural language processing and have achieved great success. Due to that a neural network has high requirements on a computing capability and memory, it is difficult to directly deploy a neural network with powerful performance on an edge device such as a mobile phone or a wearable device. Therefore, a model compression method such as neural network pruning is very important for deploying a model on an edge device.</p>
<section id="pruning-method">
<h3>Pruning Method<a class="headerlink" href="#pruning-method" title="Permalink to this headline"></a></h3>
<p>Neural network pruning is a general model compression method. It reduces the number of parameters and computation workload by removing some parameters from the neural network. It is classified into unstructured pruning and structured pruning. Take the convolutional neural network (CNN) as an example. Unstructured pruning is to remove some weights from the convolution kernel. Although it can achieve a high compression ratio, the actual acceleration depends on the special hardware design. It is difficult to obtain benefits on the Ascend, GPU, and CPU platforms. Structured pruning directly removes the complete convolution kernel from the CNN without damaging the network topology. It can directly accelerate model inference without specific software and hardware design.</p>
<p>Finding a redundant convolution kernel is a key step in structured pruning. There are two common methods: In the first method, no training data is required, and the importance of different convolution kernels is determined by defining some assumptions about importance of the convolution kernels. A typical assumption is that a convolution kernel with a small norm is not important, and cutting off some convolution kernels with small norm does not affect network performance too much. Another method is data driven, in which training data is introduced to learn importance of different convolution kernels. For example, an additional control coefficient is introduced for each convolution kernel, and importance of different convolution kernels is measured by learning their control coefficients. A convolution kernel that corresponds to a small control coefficient is considered unimportant.</p>
<p><img alt="" src="../_images/scop.png" /></p>
<p>A typical neural network pruning method: Reliable Neural Network Pruning (SCOP) based on Scientific Control is driven by data. It introduces knockoff features as a reference, sets up control experiments to reduce the interference of various irrelevant factors to the pruning process and improve the reliability of pruning results. As shown in the preceding figure, real data and knockoff data are input to the network at the same time to generate real features and knockoff features separately. If the knockoff feature corresponding to a convolution kernel suppresses the real feature, the convolution kernel is considered redundant and should be deleted.</p>
</section>
</section>
<section id="scop-training">
<h2>SCOP Training<a class="headerlink" href="#scop-training" title="Permalink to this headline"></a></h2>
<p>The data-driven SCOP introduces training data to learn importance of different convolution kernels, thereby improving pruning reliability.</p>
<p>Table 1: SCOP training specifications</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Specifications</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Hardware</p></td>
<td><p>GPU and Ascend AI 910 Processor hardware platforms</p></td>
</tr>
<tr class="row-odd"><td><p>Networks</p></td>
<td><p>ResNet series networks. For details, see <a class="reference external" href="https://gitee.com/mindspore/models/tree/master">https://gitee.com/mindspore/models/tree/master</a>.</p></td>
</tr>
<tr class="row-even"><td><p>Algorithms</p></td>
<td><p>Structured pruning algorithms</p></td>
</tr>
<tr class="row-odd"><td><p>Data types</p></td>
<td><p>The Ascend and the GPU platforms support pruning training on FP32 networks.</p></td>
</tr>
<tr class="row-even"><td><p>Running modes</p></td>
<td><p>Graph mode and PyNative mode</p></td>
</tr>
</tbody>
</table>
</section>
<section id="scop-training-example">
<h2>SCOP Training Example<a class="headerlink" href="#scop-training-example" title="Permalink to this headline"></a></h2>
<p>SCOP training consists of the knockoff and fine-tuning phases. In the knockoff phase, redundant convolution kernels are removed by using the knockoff feature. In the fine-tuning phase, the network is completely trained after the redundant convolution kernels are removed. The complete process is as follows:</p>
<ol class="arabic simple">
<li><p>Load the dataset and process data.</p></li>
<li><p>Initialize the ResNet-50.</p></li>
<li><p>Use PrunerKfCompressAlgo to replace nodes, define the optimizer and loss function, and perform training in the knockoff phase.</p></li>
<li><p>Use PrunerFtCompressAlgo to replace nodes, define the optimizer and loss function, perform training in the fine-tuning phase, and save the model.</p></li>
<li><p>Load the saved model for evaluation.</p></li>
</ol>
<p>Then, ResNet-50 is used as an example to describe steps related to SCOP training in detail.</p>
<blockquote>
<div><p>You can find the complete executable sample code here: <a class="reference external" href="https://gitee.com/mindspore/models/tree/master/official/cv/ResNet/golden_stick/pruner/scop">https://gitee.com/mindspore/models/tree/master/official/cv/ResNet/golden_stick/pruner/scop</a>.</p>
</div></blockquote>
<section id="knockoff-data">
<h3>Knockoff Data<a class="headerlink" href="#knockoff-data" title="Permalink to this headline"></a></h3>
<p>Initialize the ResNet-50, load the pre-trained model, replace nodes using PrunerKfCompressAlgo to obtain the network in the knockoff phase (For details, users can refer to <a class="reference external" href="https://gitee.com/mindspore/golden-stick/blob/master/mindspore_gs/pruner/scop/scop_pruner.py">API</a>), and train the network.（Note: dataset_sink_mode in Knockoff Data phase must be set to False, because SCOP will modify dataset in Knockoff Data phase）</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">LossMonitor</span><span class="p">,</span> <span class="n">TimeMonitor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">FixedLossScaleManager</span>
<span class="kn">from</span> <span class="nn">mindspore_gs</span> <span class="kn">import</span> <span class="n">PrunerKfCompressAlgo</span>
<span class="kn">from</span> <span class="nn">mindspore.models.resnet</span> <span class="kn">import</span> <span class="n">resnet50</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">load_checkpoint</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">pre_trained</span><span class="p">,</span> <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
<span class="n">algo_kf</span> <span class="o">=</span> <span class="n">PrunerKfCompressAlgo</span><span class="p">({})</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">algo_kf</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="c1"># Get konckoff stage network</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">get_lr</span><span class="p">(</span><span class="n">lr_init</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_init</span><span class="p">,</span>
            <span class="n">lr_end</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">lr_max</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_max_kf</span><span class="p">,</span>
            <span class="n">warmup_epochs</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">warmup_epochs</span><span class="p">,</span>
            <span class="n">total_epochs</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">epoch_kf</span><span class="p">,</span>
            <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span>
            <span class="n">lr_decay_mode</span><span class="o">=</span><span class="s1">&#39;cosine&#39;</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()),</span>
                        <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
                        <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                        <span class="n">loss_scale</span><span class="o">=</span><span class="mi">1024</span>
                        <span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="n">time_cb</span> <span class="o">=</span> <span class="n">TimeMonitor</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="n">step_size</span><span class="p">)</span>
<span class="n">loss_cb</span> <span class="o">=</span> <span class="n">LossMonitor</span><span class="p">()</span>
<span class="n">algo_cb_list</span> <span class="o">=</span> <span class="n">algo_kf</span><span class="o">.</span><span class="n">callbacks</span><span class="p">()</span>
<span class="n">cb</span> <span class="o">=</span> <span class="p">[</span><span class="n">loss_cb</span><span class="p">,</span> <span class="n">time_cb</span><span class="p">]</span>
<span class="n">cb</span> <span class="o">+=</span> <span class="n">algo_cb_list</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">epoch_kf</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">cb</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>The result is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>step_0: loss=3.5922117
step_1: loss=5.259112
step_2: loss=5.152421
step_3: loss=3.2383142
step_4: loss=5.3319235
step_5: loss=4.715785
</pre></div>
</div>
</section>
<section id="fine-tuning">
<h3>Fine-tuning<a class="headerlink" href="#fine-tuning" title="Permalink to this headline"></a></h3>
<p>Determine the redundant convolution kernels in the knockoff phase. Use PrunerFtCompressAlgo to replace nodes (For details, users can refer to <a class="reference external" href="https://gitee.com/mindspore/golden-stick/blob/master/mindspore_gs/pruner/scop/scop_pruner.py">API</a>) and delete redundant convolution kernels. Perform the complete training and save the model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_gs</span> <span class="kn">import</span> <span class="n">PrunerFtCompressAlgo</span>
<span class="o">...</span>

<span class="n">algo_ft</span> <span class="o">=</span> <span class="n">PrunerFtCompressAlgo</span><span class="p">(</span><span class="n">prune_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">prune_rate</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">algo_ft</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="c1"># Get Finetune stage network</span>
<span class="n">lr_ft_new</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">get_lr</span><span class="p">(</span><span class="n">lr_init</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_init</span><span class="p">,</span>
                             <span class="n">lr_end</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_ft_end</span><span class="p">,</span>
                             <span class="n">lr_max</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_ft_max</span><span class="p">,</span>
                             <span class="n">warmup_epochs</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">warmup_epochs</span><span class="p">,</span>
                             <span class="n">total_epochs</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">epochs_ft</span><span class="p">,</span>
                             <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">(),</span>
                             <span class="n">lr_decay_mode</span><span class="o">=</span><span class="s1">&#39;poly&#39;</span><span class="p">))</span>

<span class="n">optimizer_ft</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()),</span>
                           <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr_ft_new</span><span class="p">,</span>
                           <span class="n">momentum</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
                           <span class="n">loss_scale</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">loss_scale</span>
                          <span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;acc&quot;</span><span class="p">}</span>
<span class="n">loss_scale</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">drop_overflow_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model_ft</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer_ft</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">,</span>
                    <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
                    <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O2&quot;</span><span class="p">,</span> <span class="n">boost_level</span><span class="o">=</span><span class="s2">&quot;O0&quot;</span><span class="p">,</span> <span class="n">keep_batchnorm_fp32</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># Get Finetune stage model</span>

<span class="n">step_size</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>

<span class="n">time_cb</span> <span class="o">=</span> <span class="n">TimeMonitor</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="n">step_size</span><span class="p">)</span>
<span class="n">loss_cb</span> <span class="o">=</span> <span class="n">LossMonitor</span><span class="p">()</span>
<span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="mi">5</span> <span class="o">*</span> <span class="n">step_size</span><span class="p">,</span>
                             <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ckpt_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;resnet&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">output_path</span><span class="p">,</span>
                          <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
<span class="n">ft_cb</span> <span class="o">=</span> <span class="p">[</span><span class="n">time_cb</span><span class="p">,</span> <span class="n">loss_cb</span><span class="p">,</span> <span class="n">ckpt_cb</span><span class="p">]</span>
<span class="n">model_ft</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">epochs_ft</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">ft_cb</span><span class="p">,</span>
                <span class="n">sink_size</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">(),</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>The result is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 1 step: 1, loss is 1.776729941368103
epoch: 1 step: 2, loss is 2.481227159500122
epoch: 1 step: 3, loss is 2.010404586791992
epoch: 1 step: 4, loss is 1.852586030960083
epoch: 1 step: 5, loss is 1.4738214015960693
epoch: 1 step: 6, loss is 1.6637545824050903
epoch: 1 step: 7, loss is 1.7006491422653198
epoch: 1 step: 8, loss is 1.6532130241394043
epoch: 1 step: 9, loss is 1.5730770826339722
epoch: 1 step: 10, loss is 1.4364683628082275
epoch: 1 step: 11, loss is 1.572392225265503
</pre></div>
</div>
</section>
<section id="loading-the-saved-model-for-evaluation">
<h3>Loading the Saved Model for Evaluation<a class="headerlink" href="#loading-the-saved-model-for-evaluation" title="Permalink to this headline"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">set_context</span><span class="p">,</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span><span class="p">,</span> <span class="n">export</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">class_num</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">PrunerKfCompressAlgo</span><span class="p">({})</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">PrunerFtCompressAlgo</span><span class="p">({})</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

    <span class="c1"># load checkpoint</span>
    <span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">ckpt_path</span><span class="p">)</span>
    <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
    <span class="n">total_params</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">():</span>
        <span class="n">total_params</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;top_1_accuracy&#39;</span><span class="p">})</span>

    <span class="c1"># eval model</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;result:&quot;</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="s2">&quot;prune_rate=&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">prune_rate</span><span class="p">,</span> <span class="s2">&quot;ckpt=&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">checkpoint_file_path</span><span class="p">,</span> <span class="s2">&quot;params=&quot;</span><span class="p">,</span> <span class="n">total_params</span><span class="p">)</span>
</pre></div>
</div>
<p>The following are the accuracy (top_1_accuracy), pruning rate (prune_rate), model storage location (ckpt), and parameters (params) evaluated by the model:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>result:{&#39;top_1_accuracy&#39;: 0.9273838141025641} prune_rate=0.45 ckpt=~/resnet50_cifar10/train_parallel0/resnet-400_390.ckpt params=10587835
</pre></div>
</div>
</section>
</section>
<section id="exporting-a-pruned-model">
<h2>Exporting a Pruned Model<a class="headerlink" href="#exporting-a-pruned-model" title="Permalink to this headline"></a></h2>
<p>The quantization model deployed on the device-side hardware platform is in the general model format (such as AIR and MindIR). The export procedure is as follows:</p>
<ol class="arabic simple">
<li><p>Define a pruned network.</p></li>
<li><p>Load the checkpoint file saved during pruning-based training.</p></li>
<li><p>Export the pruned model.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">set_context</span><span class="p">,</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span><span class="p">,</span> <span class="n">export</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="c1"># define fusion network</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">class_num</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">PrunerKfCompressAlgo</span><span class="p">({})</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">PrunerFtCompressAlgo</span><span class="p">({})</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

    <span class="c1"># load quantization aware network checkpoint</span>
    <span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">ckpt_path</span><span class="p">)</span>
    <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>

    <span class="c1"># export network</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">image_height</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">image_width</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">export</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">&quot;ResNet_SCOP&quot;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;MINDIR&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>After the pruned model is exported, <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/infer/inference.html">use MindSpore for inference</a>.</p>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>indicates not test yet, NS indicates not supported yet.</p></li>
</ul>
</div></blockquote>
<section id="summary-of-training">
<h3>Summary of Training<a class="headerlink" href="#summary-of-training" title="Permalink to this headline"></a></h3>
<p>Training in graph mode based on <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/v1.9.0">MindSpore</a>，<a class="reference external" href="https://gitee.com/mindspore/golden-stick/tree/v0.2.0/">MindSpore Golden Stick</a>，<a class="reference external" href="https://gitee.com/mindspore/models/tree/r1.9/">MindSpore Models</a>.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>algorithm</p></th>
<th class="head"><p>network</p></th>
<th class="head"><p>dataset</p></th>
<th class="head"><p>CUDA11 Top1Acc</p></th>
<th class="head"><p>CUDA11 Top5Acc</p></th>
<th class="head"><p>Ascend910 Top1Acc</p></th>
<th class="head"><p>Ascend910 Top5Acc</p></th>
<th class="head"><p>pruning rate</p></th>
<th class="head"><p>parameter size(MB)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>baseline</p></td>
<td><p>resnet50</p></td>
<td><p>CIFAR10</p></td>
<td><p>94.20%</p></td>
<td><p>99.88%</p></td>
<td><p>-</p></td>
<td><p>-</p></td>
<td><p>NA</p></td>
<td><p>24</p></td>
</tr>
<tr class="row-odd"><td><p>SCOP</p></td>
<td><p>resnet50</p></td>
<td><p>CIFAR10</p></td>
<td><p>92.74%</p></td>
<td><p>-</p></td>
<td><p>92.84%</p></td>
<td><p>-</p></td>
<td><p>45%</p></td>
<td><p>11</p></td>
</tr>
<tr class="row-even"><td><p>baseline</p></td>
<td><p>resnet50</p></td>
<td><p>Imagenet2012</p></td>
<td><p>77.16%</p></td>
<td><p>93.47%</p></td>
<td><p>-</p></td>
<td><p>-</p></td>
<td><p>NA</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p>SCOP</p></td>
<td><p>resnet50</p></td>
<td><p>Imagenet2012</p></td>
<td><p>NS</p></td>
<td><p>NS</p></td>
<td><p>NS</p></td>
<td><p>NS</p></td>
<td><p>NS</p></td>
<td><p>NS</p></td>
</tr>
</tbody>
</table>
<p>It can be found that in the current task, compared with the original model, when the pruning rate is 45%, the model after SCOP greatly reduces the parameters of the model, and the accuracy loss is within 0.5%.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="overview.html" class="btn btn-neutral float-left" title="Pruning Algorithm Overview" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../deployment/overview.html" class="btn btn-neutral float-right" title="Model Deployment Overview" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>