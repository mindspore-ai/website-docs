

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Applying the SimQAT Algorithm &mdash; MindSpore master documentation</title>
  

  
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Applying the SLB Algorithm" href="slb.html" />
    <link rel="prev" title="Quantization Algorithm Overview" href="overview.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Installation and Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing MindSpore Golden Stick</a></li>
</ul>
<p class="caption"><span class="caption-text">Quantization Algorithms</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Quantization Algorithm Overview</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Applying the SimQAT Algorithm</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#background">Background</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#fake-quantization-node">Fake Quantization Node</a></li>
<li class="toctree-l3"><a class="reference internal" href="#batchnorm-folding">BatchNorm Folding</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#quantization-aware-training">Quantization Aware Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#quantization-aware-training-example">Quantization Aware Training Example</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#loading-a-dataset">Loading a Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-original-network">Defining the Original Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="#applying-the-quantization-algorithm">Applying the Quantization Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-optimizer,-loss-function,-and-training-callbacks">Defining the Optimizer, Loss Function, and Training Callbacks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training-the-network-and-saving-the-checkpoint-file">Training the network and saving the checkpoint file</a></li>
<li class="toctree-l3"><a class="reference internal" href="#evaluate-network-and-comparing-the-accuracy">Evaluate network and comparing the accuracy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#summary">Summary</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#summary-of-training">Summary of Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="#summary-of-deployment">Summary of Deployment</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="slb.html">Applying the SLB Algorithm</a></li>
</ul>
<p class="caption"><span class="caption-text">Pruning Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pruner/overview.html">Pruning Algorithm Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pruner/scop.html">Applying the SCOP Algorithm</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deployment/overview.html">Model Deployment Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deployment/convert.html">MindSpore Golden Stick Network Conversion</a></li>
</ul>
<p class="caption"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_gs.html">mindspore_gs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_gs.quantization.html">mindspore_gs.quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_gs.pruner.html">mindspore_gs.pruner</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Applying the SimQAT Algorithm</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/quantization/simqat.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="applying-the-simqat-algorithm">
<h1>Applying the SimQAT Algorithm<a class="headerlink" href="#applying-the-simqat-algorithm" title="Permalink to this headline">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/master/docs/golden_stick/docs/source_en/quantization/simqat.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png"></a></p>
<div class="section" id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h2>
<p>SimQAT is a basic quantization aware algorithm based on fake quantization nodes. Its principles come from Google’s <a class="reference external" href="https://arxiv.org/pdf/1806.08342.pdf">Quantizing deep convolutional networks for efficient inference: A whitepaper</a>.</p>
<div class="section" id="fake-quantization-node">
<h3>Fake Quantization Node<a class="headerlink" href="#fake-quantization-node" title="Permalink to this headline">¶</a></h3>
<p>A fake quantization node is a kind of node which is inserted into network during quantization aware training, and is used to search for network data distribution and feed back a loss in accuracy. The specific functions are as follows:</p>
<ul class="simple">
<li><p>Find the distribution of network data, that is, find the maximum and minimum values of the parameters to be quantized.</p></li>
<li><p>Simulate the accuracy loss of low-bit quantization, apply the loss to the network model, and transfer the loss to the loss function, so that the optimizer optimizes the loss value during training.</p></li>
</ul>
</div>
<div class="section" id="batchnorm-folding">
<h3>BatchNorm Folding<a class="headerlink" href="#batchnorm-folding" title="Permalink to this headline">¶</a></h3>
<p>To normalize the output data, the BatchNorm operator is added after the convolutional or fully connected layer. In the training phase, the BatchNorm operator is used as an independent operator to collect statistics on the output average value and variance (as shown in the left figure in the following figure). In the inference phase, the BatchNorm operator is integrated into the weight and bias. It is called BatchNorm folding (as shown in the right figure below).</p>
<p><img alt="" src="../_images/bnfold_in_infer.png" /></p>
<p>The formula for folding BatchNorm is as follows:</p>
<div class="math notranslate nohighlight">
\[y_{bn}=\operatorname{BN}\left(y_{cout}\right)=BN(w \cdot x+b)=\widehat{w} \cdot x+\widehat{b}\]</div>
<p>In quantization aware training, to accurately simulate the folding operation in inference, the paper [1] uses two sets of convolutions to calculate the current BatchNorm parameter, and uses the calculated parameter to normalize the weight value of the actual convolution (as shown in the left figure below). CorrectionMul is used for weight calibration, and mulFold is used for weight data specification. The weight calibration and weight data specification are further integrated in the MindSpore Golden Stick (as shown in the right figure below) to improve training performance.</p>
<p><img alt="" src="../_images/bnfold_in_train.png" /></p>
</div>
</div>
<div class="section" id="quantization-aware-training">
<h2>Quantization Aware Training<a class="headerlink" href="#quantization-aware-training" title="Permalink to this headline">¶</a></h2>
<p>MindSpore’s quantization aware training uses fake quantization nodes to simulate quantization operations. During the training, floating-point numbers are still used for computation, and network parameters are updated through backward propagation learning, so that the network parameters can better adapt to the loss caused by quantization. MindSpore adopts the solution in reference [1] for the quantization of weights and data.</p>
<p>Table 1: Quantization aware training specifications</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Specifications</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hardware</td>
<td>GPU</td>
</tr>
<tr>
<td>Networks</td>
<td>The supported networks include LeNet and ResNet-50. For details, see <a href="https://gitee.com/mindspore/models/tree/master">https://gitee.com/mindspore/models/tree/master</a>.</td>
</tr>
<tr>
<td>Algorithms</td>
<td>Asymmetric, symmetric, layer-by-layer, and channel-by-channel quantization algorithms.</td>
</tr>
<tr>
<td>Solutions</td>
<td>8-bit quantization solution</td>
</tr>
<tr>
<td>Data types</td>
<td>The GPU platform supports FP32.</td>
</tr>
<tr>
<td>Running modes</td>
<td>Graph mode and PyNative mode</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="quantization-aware-training-example">
<h2>Quantization Aware Training Example<a class="headerlink" href="#quantization-aware-training-example" title="Permalink to this headline">¶</a></h2>
<p>The procedure of quantization aware training is basically the same as that of common training. In the network construction phase, the quantization algorithm of the MindSpore Golden Stick is used to generate a quantization network. The complete process is as follows:</p>
<ol class="simple">
<li><p>Load the dataset and process data.</p></li>
<li><p>Define a network.</p></li>
<li><p>Define the MindSpore Golden Stick quantization algorithm and use the algorithm to generate a quantization network.</p></li>
<li><p>Define the optimizer, loss function, and callbacks.</p></li>
<li><p>Train the network and save the checkpoint file.</p></li>
<li><p>Evaluate the network and compare the accuracy after quantization.</p></li>
</ol>
<p>The following uses the LeNet5 as an example to describe these steps.</p>
<blockquote>
<div><p>For the complete code, see the <a class="reference external" href="https://gitee.com/mindspore/models/blob/master/research/cv/lenet/README.md#apply-algorithm-in-mindspore-golden-stick">LeNet model repository</a>.The <a class="reference external" href="https://gitee.com/mindspore/models/blob/master/research/cv/lenet/golden_stick/quantization/simqat/train.py">train.py</a> is the complete training code, and the <a class="reference external" href="https://gitee.com/mindspore/models/blob/master/research/cv/lenet/golden_stick/quantization/simqat/eval.py">eval.py</a> is the accuracy verification code.</p>
</div></blockquote>
<div class="section" id="loading-a-dataset">
<h3>Loading a Dataset<a class="headerlink" href="#loading-a-dataset" title="Permalink to this headline">¶</a></h3>
<p>Load MNIST dataset using MindData:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
<p>In the code, <code class="docutils literal notranslate"><span class="pre">create_dataset</span></code> is referenced from <a class="reference external" href="https://gitee.com/mindspore/models/blob/master/research/cv/lenet/src/dataset.py">dataset.py</a>.
<code class="docutils literal notranslate"><span class="pre">config.data_path</span></code> and <code class="docutils literal notranslate"><span class="pre">config.batch_size</span></code> are configured in the <a class="reference external" href="https://gitee.com/mindspore/models/blob/master/research/cv/lenet/golden_stick/quantization/simqat/lenet_mnist_config.yaml">configuration file</a>.</p>
</div>
<div class="section" id="defining-the-original-network">
<h3>Defining the Original Network<a class="headerlink" href="#defining-the-original-network" title="Permalink to this headline">¶</a></h3>
<p>Instantiate a LeNet5 network:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">src.lenet</span> <span class="kn">import</span> <span class="n">LeNet5</span>
<span class="o">...</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
</pre></div>
</div>
<p>The original network structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>LeNet5&lt;
  (conv1): Conv2d&lt;input_channels=1, output_channels=6, kernel_size=(5, 5), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW&gt;
  (conv2): Conv2d&lt;input_channels=6, output_channels=16, kernel_size=(5, 5), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW&gt;
  (relu): ReLU&lt;&gt;
  (max_pool2d): MaxPool2d&lt;kernel_size=2, stride=2, pad_mode=VALID&gt;
  (flatten): Flatten&lt;&gt;
  (fc1): Dense&lt;input_channels=400, output_channels=120, has_bias=True&gt;
  (fc2): Dense&lt;input_channels=120, output_channels=84, has_bias=True&gt;
  (fc3): Dense&lt;input_channels=84, output_channels=10, has_bias=True&gt;
  &gt;
</pre></div>
</div>
<p>For details about the ResNet-5 definition, see <a class="reference external" href="https://gitee.com/mindspore/models/blob/master/research/cv/lenet/src/lenet.py">lenet.py</a>.</p>
</div>
<div class="section" id="applying-the-quantization-algorithm">
<h3>Applying the Quantization Algorithm<a class="headerlink" href="#applying-the-quantization-algorithm" title="Permalink to this headline">¶</a></h3>
<p>After a network layer to be quantized is modified based on the original network definition, a network with fake quantization nodes is generated. This network is a quantization network. The <code class="docutils literal notranslate"><span class="pre">SimulatedQuantizationAwareTraining</span></code> class under the MindSpore Golden Stick is constructed and applied to the original network to convert the original network into a quantization network.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_gs</span> <span class="kn">import</span> <span class="n">SimulatedQuantizationAwareTraining</span> <span class="k">as</span> <span class="n">SimQAT</span>

<span class="o">...</span>
<span class="n">algo</span> <span class="o">=</span> <span class="n">SimQAT</span><span class="p">()</span>
<span class="n">quanted_network</span> <span class="o">=</span> <span class="n">algo</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">quanted_network</span><span class="p">)</span>
</pre></div>
</div>
<p>The quantized network structure is as follows. QuantizerWrapperCell is the encapsulation class of perceptual quantization training for the original Conv2d or Dense, including the original operator and pseudo-quantization nodes of input, output and weight.  Users can refer to <a class="reference external" href="https://www.mindspore.cn/golden_stick/docs/en/master/quantization/mindspore_gs.quantization.SimulatedQuantizationAwareTraining.html#mindspore_gs.quantization.SimulatedQuantizationAwareTraining">API</a> to modify the algorithm configuration, and verify that the algorithm is configured successfully by checking the QuantizeWrapperCell properties.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>LeNet5Opt&lt;
  (_handler):
  ...
  (Conv2dQuant): QuantizeWrapperCell&lt;
    (_handler): Conv2dQuant&lt;
      in_channels=1, out_channels=6, kernel_size=(5, 5), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False
      (fake_quant_weight): SimulatedFakeQuantizerPerChannel&lt;bit_num=8, symmetric=True, narrow_range=False, ema=False(0.999), per_channel=True(0, 6), quant_delay=0&gt;
      &gt;
    (_input_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    (_output_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    &gt;
  (Conv2dQuant_1): QuantizeWrapperCell&lt;
    (_handler): Conv2dQuant&lt;
      in_channels=6, out_channels=16, kernel_size=(5, 5), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False
      (fake_quant_weight): SimulatedFakeQuantizerPerChannel&lt;bit_num=8, symmetric=True, narrow_range=False, ema=False(0.999), per_channel=True(0, 16), quant_delay=0&gt;
      &gt;
    (_input_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    (_output_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    &gt;
  (DenseQuant): QuantizeWrapperCell&lt;
    (_handler): DenseQuant&lt;
      in_channels=400, out_channels=120, weight=Parameter (name=DenseQuant._handler.weight, shape=(120, 400), dtype=Float32, requires_grad=True), has_bias=True, bias=Parameter (name=DenseQuant._handler.bias, shape=(120,), dtype=Float32, requires_grad=True)
      (fake_quant_weight): SimulatedFakeQuantizerPerChannel&lt;bit_num=8, symmetric=True, narrow_range=False, ema=False(0.999), per_channel=True(0, 120), quant_delay=0&gt;
      &gt;
    (_input_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    (_output_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    &gt;
  (DenseQuant_1): QuantizeWrapperCell&lt;
    (_handler): DenseQuant&lt;
      in_channels=120, out_channels=84, weight=Parameter (name=DenseQuant_1._handler.weight, shape=(84, 120), dtype=Float32, requires_grad=True), has_bias=True, bias=Parameter (name=DenseQuant_1._handler.bias, shape=(84,), dtype=Float32, requires_grad=True)
      (fake_quant_weight): SimulatedFakeQuantizerPerChannel&lt;bit_num=8, symmetric=True, narrow_range=False, ema=False(0.999), per_channel=True(0, 84), quant_delay=0&gt;
      &gt;
    (_input_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    (_output_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    &gt;
  (DenseQuant_2): QuantizeWrapperCell&lt;
    (_handler): DenseQuant&lt;
      in_channels=84, out_channels=10, weight=Parameter (name=DenseQuant_2._handler.weight, shape=(10, 84), dtype=Float32, requires_grad=True), has_bias=True, bias=Parameter (name=DenseQuant_2._handler.bias, shape=(10,), dtype=Float32, requires_grad=True)
      (fake_quant_weight): SimulatedFakeQuantizerPerChannel&lt;bit_num=8, symmetric=True, narrow_range=False, ema=False(0.999), per_channel=True(0, 10), quant_delay=0&gt;
      &gt;
    (_input_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    (_output_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    &gt;
  &gt;
</pre></div>
</div>
</div>
<div class="section" id="defining-the-optimizer,-loss-function,-and-training-callbacks">
<h3>Defining the Optimizer, Loss Function, and Training Callbacks<a class="headerlink" href="#defining-the-optimizer,-loss-function,-and-training-callbacks" title="Permalink to this headline">¶</a></h3>
<p>Use Momentum as optimizer and SoftmaxCrossEntropyWithLogits as loss function for LeNet5 training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="n">net_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">config</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">momentum</span><span class="p">)</span>
<span class="n">time_cb</span> <span class="o">=</span> <span class="n">TimeMonitor</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="n">ds_train</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">())</span>
<span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">save_checkpoint_steps</span><span class="p">,</span>
                             <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">keep_checkpoint_max</span><span class="p">)</span>
<span class="n">ckpoint_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;checkpoint_lenet&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;./ckpt&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="training-the-network-and-saving-the-checkpoint-file">
<h3>Training the network and saving the checkpoint file<a class="headerlink" href="#training-the-network-and-saving-the-checkpoint-file" title="Permalink to this headline">¶</a></h3>
<p>Call <code class="docutils literal notranslate"><span class="pre">train</span></code> method of class <code class="docutils literal notranslate"><span class="pre">Model</span></code> to start training:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">,</span> <span class="n">net_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">Accuracy</span><span class="p">()})</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">epoch_size</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">time_cb</span><span class="p">,</span> <span class="n">ckpoint_cb</span><span class="p">,</span> <span class="n">LossMonitor</span><span class="p">()])</span>
</pre></div>
</div>
<p>The result is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch:1 step: 1875, loss is 0.1609785109
Train epoch time: 18172.836 ms, per step time: 9.692 ms
epoch:2 step: 1875, loss is 0.00334590533
Train epoch time: 8617.408 ms, per step time: 4.596 ms
epoch:3 step: 1875, loss is 0.00310735423
Train epoch time: 8526.766 ms, per step time: 4.548 ms
epoch:4 step: 1875, loss is 0.00962805934
Train epoch time: 8585.520 ms, per step time: 4.579 ms
epoch:5 step: 1875, loss is 0.00363082927
Train epoch time: 8512.096 ms, per step time: 4.540 ms
epoch:6 step: 1875, loss is 0.00169560452
Train epoch time: 8303.8515 ms, per step time: 4.429 ms
epoch:7 step: 1875, loss is 0.08799523115
Train epoch time: 8417.257 ms, per step time: 4.489 ms
epoch:8 step: 1875, loss is 0.0838107979
Train epoch time: 8416.146 ms, per step time: 4.489 ms
epoch:9 step: 1875, loss is 0.00722093607
Train epoch time: 8425.732 ms, per step time: 4.484 ms
epoch:10 step: 1875, loss is 0.00027961225
Train epoch time: 8544.641 ms, per step time: 4.552 ms
</pre></div>
</div>
</div>
<div class="section" id="evaluate-network-and-comparing-the-accuracy">
<h3>Evaluate network and comparing the accuracy<a class="headerlink" href="#evaluate-network-and-comparing-the-accuracy" title="Permalink to this headline">¶</a></h3>
<p>Obtain the accuracy of the common training network according to the steps in the <a class="reference external" href="https://gitee.com/mindspore/models/tree/master/research/cv/lenet">LeNet model repository</a>.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&#39;Accuracy&#39;:0.9842
</pre></div>
</div>
<p>Load the checkpoint file obtained in the previous step and evaluate accuracy of the quantized network.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">checkpoint_file_path</span><span class="p">)</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="n">ds_eval</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">ds_eval</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&#39;Accuracy&#39;:0.990484
</pre></div>
</div>
<p>The accuracy of LeNet5 does not decrease after quantization aware training.</p>
<blockquote>
<div><p>One effect of quantization aware training algorithms is to compress the model size, but the model size mentioned here refers to the size of the deployed model. The network here is not the final deployment model, and since fake-quantization nodes are added to the network, the checkpoint file size of the quantized network is slightly increased compared to the original network’s checkpoint file.</p>
</div></blockquote>
</div>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><ul class="simple">
<li><p>indicates not test yet, NS indicates not supported yet.</p></li>
</ul>
</div></blockquote>
<div class="section" id="summary-of-training">
<h3>Summary of Training<a class="headerlink" href="#summary-of-training" title="Permalink to this headline">¶</a></h3>
<p>Training in graph mode based on <a class="reference external" href="https://gitee.com/mindspore/mindspore/commit/1674f3f666997f49346c27c322ecac1bb7979ffa">MindSpore</a>, <a class="reference external" href="https://gitee.com/mindspore/golden-stick/commit/3c0557371204036ae82404d48c875e905be1ac69">MindSpore Golden Stick</a>, <a class="reference external" href="https://gitee.com/mindspore/models/commit/f20d3d46ea48a465b26462ef5c62a7d381a34828">MindSpore Models</a>.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>algorithm</th>
<th>network</th>
<th>dataset</th>
<th>CUDA11 Top1Acc</th>
<th>CUDA11 Top5Acc</th>
<th>Ascend910 Top1Acc</th>
<th>Ascend910 Top5Acc</th>
</tr>
</thead>
<tbody>
<tr>
<td>baseline</td>
<td>lenet</td>
<td>MNIST</td>
<td>98.82%</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>SimQAT</td>
<td>lenet</td>
<td>MNIST</td>
<td>98.94%</td>
<td>-</td>
<td>NS</td>
<td>-</td>
</tr>
<tr>
<td>baseline</td>
<td>resnet50</td>
<td>CIFAR10</td>
<td>94.20%</td>
<td>99.88%</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>SimQAT</td>
<td>resnet50</td>
<td>CIFAR10</td>
<td>95.04%</td>
<td>99.84%</td>
<td>NS</td>
<td>NS</td>
</tr>
<tr>
<td>baseline</td>
<td>resnet50</td>
<td>Imagenet2012</td>
<td>77.16%</td>
<td>93.47%</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>SimQAT</td>
<td>resnet50</td>
<td>Imagenet2012</td>
<td>76.95%</td>
<td>93.59%</td>
<td>NS</td>
<td>NS</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="summary-of-deployment">
<h3>Summary of Deployment<a class="headerlink" href="#summary-of-deployment" title="Permalink to this headline">¶</a></h3>
<p>Use the network trained on the CUDA11 for deployment test on different backends.</p>
<p>ARMCPU means the CPU of the Arm64 architecture. ARMCPU deployment test based on <a class="reference external" href="https://gitee.com/mindspore/mindspore/commit/1674f3f666997f49346c27c322ecac1bb7979ffa">MindSpore Lite</a>.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>algorithm</th>
<th>network</th>
<th>dataset</th>
<th>ARMCPU model size</th>
<th>ARMCPU Top1Acc</th>
<th>ARMCPU Performance</th>
<th>CUDA11 model size</th>
<th>CUDA11 Top1Acc</th>
<th>CUDA11 Performance</th>
<th>Ascend310 model size</th>
<th>Ascend310 Top1Acc</th>
<th>Ascend310 Performance</th>
</tr>
</thead>
<tbody>
<tr>
<td>baseline</td>
<td>lenet</td>
<td>MNIST</td>
<td>245kB</td>
<td>98.83%</td>
<td>87us</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>SimQAT</td>
<td>lenet</td>
<td>MNIST</td>
<td>241kB</td>
<td>98.95%</td>
<td>89us</td>
<td>NS</td>
<td>NS</td>
<td>NS</td>
<td>NS</td>
<td>NS</td>
<td>NS</td>
</tr>
<tr>
<td>baseline</td>
<td>resnet50</td>
<td>CIFAR10</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>SimQAT</td>
<td>resnet50</td>
<td>CIFAR10</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>NS</td>
<td>NS</td>
<td>NS</td>
<td>NS</td>
<td>NS</td>
<td>NS</td>
</tr>
<tr>
<td>baseline</td>
<td>resnet50</td>
<td>Imagenet2012</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>SimQAT</td>
<td>resnet50</td>
<td>Imagenet2012</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>NS</td>
<td>NS</td>
<td>NS</td>
<td>NS</td>
<td>NS</td>
<td>NS</td>
</tr>
</tbody>
</table>
<p>The SimQAT quantization algorithm can reduce the model size, improve the model inference performance and reduce the inference power consumption without or less accuracy degradation.</p>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p>[1] Jacob B, Kligys S, Chen B, et al. Quantization and training of neural networks for efficient integer-arithmetic-only inference[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 2704-2713.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="slb.html" class="btn btn-neutral float-right" title="Applying the SLB Algorithm" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="overview.html" class="btn btn-neutral float-left" title="Quantization Algorithm Overview" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>