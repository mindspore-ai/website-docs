

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>应用SCOP算法 &mdash; MindSpore master documentation</title>
  

  
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="mindspore_gs" href="../mindspore_gs.html" />
    <link rel="prev" title="剪枝算法概述" href="overview.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">安装MindSpore Golden Stick</a></li>
</ul>
<p class="caption"><span class="caption-text">量化算法</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quantization/overview.html">量化算法概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quantization/simqat.html">应用SimQAT算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quantization/slb.html">应用SLB算法</a></li>
</ul>
<p class="caption"><span class="caption-text">剪枝算法</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">剪枝算法概述</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">应用SCOP算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#背景">背景</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#剪枝方法">剪枝方法</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scop剪枝训练">SCOP剪枝训练</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scop剪枝训练示例">SCOP剪枝训练示例</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#knockoff-data阶段">Knockoff Data阶段</a></li>
<li class="toctree-l3"><a class="reference internal" href="#finetune阶段">Finetune阶段</a></li>
<li class="toctree-l3"><a class="reference internal" href="#加载保存的模型进行评估">加载保存的模型，进行评估</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scop剪枝效果">SCOP剪枝效果</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_gs.html">mindspore_gs</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>应用SCOP算法</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/pruner/scop.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="应用scop算法">
<h1>应用SCOP算法<a class="headerlink" href="#应用scop算法" title="Permalink to this headline">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.8/docs/golden_stick/docs/source_zh_cn/pruner/scop.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_source.png"></a></p>
<div class="section" id="背景">
<h2>背景<a class="headerlink" href="#背景" title="Permalink to this headline">¶</a></h2>
<p>卷积神经网络（CNN）等深度学习模型已在计算机视觉、自然语言处理等多个领域广泛应用并取得了巨大的成功，但由于神经网络对计算能力和内存要求很高，很难将性能强大的神经网络直接部署在手机、可穿戴设备等边缘设备上。因此，神经网络剪枝等模型压缩方法对模型在边缘设备上的部署十分重要。</p>
<div class="section" id="剪枝方法">
<h3>剪枝方法<a class="headerlink" href="#剪枝方法" title="Permalink to this headline">¶</a></h3>
<p>神经网络剪枝技术是一种通用的模型压缩方法，它通过去除神经网络中的部分参数来减少参数量和计算量，主要分为非结构化剪枝和结构化剪枝两类。以卷积神经网络（CNN）为例，非结构化剪枝是去除卷积核中的部分权值，尽管它可以实现很高的压缩比，但实际的加速依赖于特殊的硬件设计，难以在通用的Ascend、GPU、CPU平台上获得收益。而结构化剪枝直接去除CNN中完整的卷积核，不破坏网络的拓扑结构，无需特定的软件和硬件设计即可直接实现模型的推理加速。</p>
<p>发现冗余的卷积核是结构化剪枝的关键一步，常用的方法可分为两种：第一种方法不需要训练数据，通过定义一些卷积核重要性的假设，来判定不同卷积核的重要性。一个典型的假设是范数小的卷积核不重要，砍掉一些范数小的卷积核不会太多地影响网络的表现。 还有一类方法是数据驱动的方法，引入训练数据来学习不同卷积核的重要性。比如通过给每个卷积核引入额外的控制系数，学习这些控制系数，来度量不同卷积核的重要性，小的控制系数对应的卷积核被认为不重要。</p>
<p><img alt="" src="../_images/scop.png" /></p>
<p>一个典型的神经网络剪枝方法：基于科学控制法的神经网络剪枝（SCOP: Scientific Control for Reliable Neural Network Pruning）是在数据驱动下，通过引入高仿特征作为参照，通过设置对照实验来减少各种无关因素对剪枝过程的干扰，提高剪枝结果的可靠性。整体流程如上图所示，真实数据（Real data）和高仿数据（Knockoff data）同时输入到网络中，分别生成真实特征和高仿特征。如果一个卷积核对应的高仿特征抑制住了真实特征，则认为这个卷积核是冗余的，应当被删除。</p>
</div>
</div>
<div class="section" id="scop剪枝训练">
<h2>SCOP剪枝训练<a class="headerlink" href="#scop剪枝训练" title="Permalink to this headline">¶</a></h2>
<p>SCOP采用数据驱动的方式，通过引入训练数据学习不同卷积核的重要性，从而提高剪枝的可靠性。</p>
<p>表1：SCOP剪枝训练规格</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>规格</th>
<th>规格说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>硬件支持</td>
<td>GPU、Ascend AI 910处理器的硬件平台</td>
</tr>
<tr>
<td>网络支持</td>
<td>ResNet系列网络，具体请参见<a href="https://gitee.com/mindspore/models/tree/master">https://gitee.com/mindspore/models/tree/master</a>。</td>
</tr>
<tr>
<td>算法支持</td>
<td>结构化的剪枝算法。</td>
</tr>
<tr>
<td>数据类型支持</td>
<td>Ascend和GPU平台支持精度为FP32的网络进行剪枝训练。</td>
</tr>
<tr>
<td>运行模式支持</td>
<td>Graph模式和PyNative模式</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="scop剪枝训练示例">
<h2>SCOP剪枝训练示例<a class="headerlink" href="#scop剪枝训练示例" title="Permalink to this headline">¶</a></h2>
<p>SCOP训练分为Knockoff阶段和Finetune阶段，Knockoff阶段对应于前文介绍的通过高仿特征来去除冗余卷积核，Finetune阶段即在去掉冗余卷积核后完整训练网络，完整流程如下：</p>
<ol class="simple">
<li><p>加载数据集，处理数据。</p></li>
<li><p>初始化ResNet50网络。</p></li>
<li><p>通过PrunerKfCompressAlgo进行节点替换，定义优化器和损失函数，进行Knockoff阶段的训练。</p></li>
<li><p>通过PrunerFtCompressAlgo进行节点替换，定义优化器和损失函数，进行Finetune阶段的训练，并保存模型。</p></li>
<li><p>加载保存的模型，进行评估。</p></li>
</ol>
<p>接下来，以ResNet50网络为例，展开叙述SCOP剪枝训练的相关步骤。</p>
<blockquote>
<div><p>你可以在这里找到完整可运行的样例代码：<a class="reference external" href="https://gitee.com/mindspore/models/tree/r1.8/official/cv/resnet/golden_stick/pruner/scop">https://gitee.com/mindspore/models/tree/r1.8/official/cv/resnet/golden_stick/pruner/scop</a> 。</p>
</div></blockquote>
<div class="section" id="knockoff-data阶段">
<h3>Knockoff Data阶段<a class="headerlink" href="#knockoff-data阶段" title="Permalink to this headline">¶</a></h3>
<p>初始化ResNet50网络，加载预训练模型，通过PrunerKfCompressAlgo进行节点替换(详情用户可参考<a class="reference external" href="https://gitee.com/mindspore/golden-stick/blob/r0.1/mindspore_gs/pruner/scop/scop_pruner.py">API</a>)，得到Knockoff阶段的网络，并进行训练。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">LossMonitor</span><span class="p">,</span> <span class="n">TimeMonitor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">FixedLossScaleManager</span>
<span class="kn">from</span> <span class="nn">mindspore_gs</span> <span class="kn">import</span> <span class="n">PrunerKfCompressAlgo</span>
<span class="kn">from</span> <span class="nn">mindspore.models.resnet</span> <span class="kn">import</span> <span class="n">resnet50</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">load_checkpoint</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">pre_trained</span><span class="p">,</span> <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
<span class="n">algo_kf</span> <span class="o">=</span> <span class="n">PrunerKfCompressAlgo</span><span class="p">({})</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">algo_kf</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="c1"># Get konckoff stage network</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()),</span>
                        <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
                        <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                        <span class="n">loss_scale</span><span class="o">=</span><span class="mi">1024</span>
                        <span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">NetWithLossCell</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>
<span class="n">net_train_step</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_data</span><span class="o">.</span><span class="n">create_tuple_iterator</span><span class="p">()):</span>
        <span class="n">kf</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Randperm</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="n">kf</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])(</span><span class="n">Tensor</span><span class="p">([</span><span class="n">kf</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span> <span class="c1"># Random generate Knockoff data</span>
        <span class="n">kf_input</span> <span class="o">=</span> <span class="n">kf</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">kf</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">input_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">num_pgpu</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">config</span><span class="o">.</span><span class="n">ngpu</span>
        <span class="k">for</span> <span class="n">igpu</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">ngpu</span><span class="p">):</span>
            <span class="n">input_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">Concat</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)([</span><span class="n">data</span><span class="p">[</span><span class="n">igpu</span> <span class="o">*</span> <span class="n">num_pgpu</span><span class="p">:(</span><span class="n">igpu</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_pgpu</span><span class="p">],</span> <span class="n">kf_input</span><span class="p">[</span><span class="n">igpu</span> <span class="o">*</span> <span class="n">num_pgpu</span><span class="p">:(</span><span class="n">igpu</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_pgpu</span><span class="p">]]))</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Concat</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="n">input_list</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">net_train_step</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;step_</span><span class="si">{0}</span><span class="s1">: loss=</span><span class="si">{1}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>
</pre></div>
</div>
<p>运行结果如下:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>step_0: loss=3.5922117
step_1: loss=5.259112
step_2: loss=5.152421
step_3: loss=3.2383142
step_4: loss=5.3319235
step_5: loss=4.715785
</pre></div>
</div>
</div>
<div class="section" id="finetune阶段">
<h3>Finetune阶段<a class="headerlink" href="#finetune阶段" title="Permalink to this headline">¶</a></h3>
<p>通过Knockoff阶段确认冗余的卷积核，通过PrunerFtCompressAlgo进行节点替换(详情用户可参考<a class="reference external" href="https://gitee.com/mindspore/golden-stick/blob/r0.1/mindspore_gs/pruner/scop/scop_pruner.py">API</a>)删除冗余卷积核，进行完整的训练并保存模型。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_gs</span> <span class="kn">import</span> <span class="n">Kf_Conv2d</span>
<span class="o">...</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">nam</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">()):</span> <span class="c1"># Get name and content of each Cell on the network from net.cells_and_names()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">Kf_Conv2d</span><span class="p">):</span>
        <span class="n">module</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">bn</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">*</span> <span class="n">ops</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">()(</span><span class="n">module</span><span class="o">.</span><span class="n">kfscale</span><span class="o">.</span><span class="n">data</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">module</span><span class="o">.</span><span class="n">kfscale</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">nam</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">()):</span> <span class="c1"># Confirm redundant convolution kernel</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">Kf_Conv2d</span><span class="p">):</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sort</span><span class="p">()(</span><span class="n">module</span><span class="o">.</span><span class="n">score</span><span class="p">)</span>
        <span class="n">num_pruned_channel</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">prune_rate</span> <span class="o">*</span> <span class="n">module</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">module</span><span class="o">.</span><span class="n">out_index</span> <span class="o">=</span> <span class="n">index</span><span class="p">[</span><span class="n">num_pruned_channel</span><span class="p">:]</span>

<span class="n">algo_ft</span> <span class="o">=</span> <span class="n">PrunerFtCompressAlgo</span><span class="p">({})</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">algo_ft</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="c1"># Get Finetune stage network</span>
<span class="n">lr_ft_new</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">get_lr</span><span class="p">(</span><span class="n">lr_init</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_init</span><span class="p">,</span>
                             <span class="n">lr_end</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_ft_end</span><span class="p">,</span>
                             <span class="n">lr_max</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_ft_max</span><span class="p">,</span>
                             <span class="n">warmup_epochs</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">warmup_epochs</span><span class="p">,</span>
                             <span class="n">total_epochs</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">epochs_ft</span><span class="p">,</span>
                             <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">(),</span>
                             <span class="n">lr_decay_mode</span><span class="o">=</span><span class="s1">&#39;poly&#39;</span><span class="p">))</span>

<span class="n">optimizer_ft</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()),</span>
                           <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr_ft_new</span><span class="p">,</span>
                           <span class="n">momentum</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
                           <span class="n">loss_scale</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">loss_scale</span>
                          <span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;acc&quot;</span><span class="p">}</span>
<span class="n">loss_scale</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">drop_overflow_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model_ft</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer_ft</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">,</span>
                    <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
                    <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O2&quot;</span><span class="p">,</span> <span class="n">boost_level</span><span class="o">=</span><span class="s2">&quot;O0&quot;</span><span class="p">,</span> <span class="n">keep_batchnorm_fp32</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># Get Finetune stage model</span>

<span class="n">step_size</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>

<span class="n">time_cb</span> <span class="o">=</span> <span class="n">TimeMonitor</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="n">step_size</span><span class="p">)</span>
<span class="n">loss_cb</span> <span class="o">=</span> <span class="n">LossMonitor</span><span class="p">()</span>
<span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="mi">5</span> <span class="o">*</span> <span class="n">step_size</span><span class="p">,</span>
                             <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ckpt_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;resnet&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">output_path</span><span class="p">,</span>
                          <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
<span class="n">ft_cb</span> <span class="o">=</span> <span class="p">[</span><span class="n">time_cb</span><span class="p">,</span> <span class="n">loss_cb</span><span class="p">,</span> <span class="n">ckpt_cb</span><span class="p">]</span>
<span class="n">model_ft</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">epochs_ft</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">ft_cb</span><span class="p">,</span>
                <span class="n">sink_size</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">(),</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果如下:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 1 step: 1, loss is 1.776729941368103
epoch: 1 step: 2, loss is 2.481227159500122
epoch: 1 step: 3, loss is 2.010404586791992
epoch: 1 step: 4, loss is 1.852586030960083
epoch: 1 step: 5, loss is 1.4738214015960693
epoch: 1 step: 6, loss is 1.6637545824050903
epoch: 1 step: 7, loss is 1.7006491422653198
epoch: 1 step: 8, loss is 1.6532130241394043
epoch: 1 step: 9, loss is 1.5730770826339722
epoch: 1 step: 10, loss is 1.4364683628082275
epoch: 1 step: 11, loss is 1.572392225265503
</pre></div>
</div>
</div>
<div class="section" id="加载保存的模型进行评估">
<h3>加载保存的模型，进行评估<a class="headerlink" href="#加载保存的模型进行评估" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span><span class="p">,</span> <span class="n">export</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">class_num</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">PrunerKfCompressAlgo</span><span class="p">({})</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">PrunerFtCompressAlgo</span><span class="p">({})</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

    <span class="c1"># load checkpoint</span>
    <span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">ckpt_path</span><span class="p">)</span>
    <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
    <span class="n">total_params</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">():</span>
        <span class="n">total_params</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;top_1_accuracy&#39;</span><span class="p">})</span>

    <span class="c1"># eval model</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;result:&quot;</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="s2">&quot;prune_rate=&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">prune_rate</span><span class="p">,</span> <span class="s2">&quot;ckpt=&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">checkpoint_file_path</span><span class="p">,</span> <span class="s2">&quot;params=&quot;</span><span class="p">,</span> <span class="n">total_params</span><span class="p">)</span>
</pre></div>
</div>
<p>模型评估的精度(top_1_accuracy)、剪枝率(prune_rate)、模型存储位置(ckpt)及参数量(params)如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>result:{&#39;top_1_accuracy&#39;: 0.9273838141025641} prune_rate=0.45 ckpt=~/resnet50_cifar10/train_parallel0/resnet-400_390.ckpt params=10587835
</pre></div>
</div>
</div>
</div>
<div class="section" id="scop剪枝效果">
<h2>SCOP剪枝效果<a class="headerlink" href="#scop剪枝效果" title="Permalink to this headline">¶</a></h2>
<p>在Graph模式下，对ResNet50网络应用SCOP剪枝，并使用CIFAR-10数据集评估，实验结果如下表所示。可以发现，在当前任务中，与原始模型相比，在剪枝率45%的情况下，SCOP剪枝后的模型大幅降低了模型的参数量，精度损失在0.5%以内。</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Model</th>
<th>剪枝率</th>
<th>参数量(M)</th>
<th>准确率</th>
</tr>
</thead>
<tbody>
<tr>
<td>ResNet50</td>
<td>-</td>
<td>24</td>
<td>93.2%</td>
</tr>
<tr>
<td>SCOP剪枝ResNet50</td>
<td><strong>45%</strong></td>
<td><strong>11</strong></td>
<td><strong>92.7%</strong></td>
</tr>
</tbody>
</table></div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../mindspore_gs.html" class="btn btn-neutral float-right" title="mindspore_gs" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="overview.html" class="btn btn-neutral float-left" title="剪枝算法概述" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>