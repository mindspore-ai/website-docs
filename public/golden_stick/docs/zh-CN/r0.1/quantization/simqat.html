

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>应用SimQAT算法 &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="应用SLB算法" href="slb.html" />
    <link rel="prev" title="量化算法概述" href="overview.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">安装MindSpore Golden Stick</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">量化算法</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">量化算法概述</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">应用SimQAT算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#背景">背景</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#伪量化节点">伪量化节点</a></li>
<li class="toctree-l3"><a class="reference internal" href="#batchnorm折叠">BatchNorm折叠</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#感知量化训练">感知量化训练</a></li>
<li class="toctree-l2"><a class="reference internal" href="#感知量化训练示例">感知量化训练示例</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#加载数据集">加载数据集</a></li>
<li class="toctree-l3"><a class="reference internal" href="#定义原网络">定义原网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="#应用量化算法">应用量化算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="#定义优化器损失函数和训练的callbacks">定义优化器、损失函数和训练的callbacks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#训练网络保存checkpoint文件">训练网络，保存checkpoint文件</a></li>
<li class="toctree-l3"><a class="reference internal" href="#评估网络对比精度">评估网络，对比精度</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#总结">总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="#参考文献">参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="slb.html">应用SLB算法</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">剪枝算法</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pruner/overview.html">剪枝算法概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pruner/scop.html">应用SCOP算法</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_gs.html">mindspore_gs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>应用SimQAT算法</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/quantization/simqat.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="应用simqat算法">
<h1>应用SimQAT算法<a class="headerlink" href="#应用simqat算法" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.8/docs/golden_stick/docs/source_zh_cn/quantization/simqat.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_source.png"></a></p>
<section id="背景">
<h2>背景<a class="headerlink" href="#背景" title="Permalink to this headline"></a></h2>
<p>SimQAT是一种最基础的感知量化算法，其具体原理来源于谷歌的<a class="reference external" href="https://arxiv.org/pdf/1806.08342.pdf">量化白皮书</a>，是一种基于伪量化节点的感知量化算法。</p>
<section id="伪量化节点">
<h3>伪量化节点<a class="headerlink" href="#伪量化节点" title="Permalink to this headline"></a></h3>
<p>伪量化节点，是指感知量化训练时，往网络中插入的一类节点，其用途是寻找网络数据分布，并反馈损失精度，具体作用如下：</p>
<ul class="simple">
<li><p>找到参数的分布，即找到待量化参数的最大值和最小值；</p></li>
<li><p>模拟量化为低比特时的精度损失，把该损失作用到网络中，传递给损失函数，让优化器在训练过程中对该损失值进行优化。</p></li>
</ul>
</section>
<section id="batchnorm折叠">
<h3>BatchNorm折叠<a class="headerlink" href="#batchnorm折叠" title="Permalink to this headline"></a></h3>
<p>为了归一化输出数据，卷积或者全连接层后通常会加入BatchNorm算子，在训练阶段BatchNorm作为一个独立的算子，统计输出的均值和方差（如下左图），在推理阶段则将其融入权重和Bias中，称为BatchNorm折叠（如下右图）。</p>
<p><img alt="" src="../_images/bnfold_in_infer.png" /></p>
<p>BatchNorm折叠的公式如下：</p>
<div class="math notranslate nohighlight">
\[y_{bn}=\operatorname{BN}\left(y_{cout}\right)=BN(w \cdot x+b)=\widehat{w} \cdot x+\widehat{b}\]</div>
<p>在感知量化训练中，为精确模拟推理中的折叠操作，论文[1]使用两套卷积分别用于计算当前的BatchNorm参数，并用计算得到的参数归一化实际作用卷积的权重值（如下左图），其中CorrectionMul用于权重校正，MulFold用于权重数据归一化。在MindSpore Golden Stick中会进一步将权重校正和权重数据融合（如下右图），提升训练性能。</p>
<p><img alt="" src="../_images/bnfold_in_train.png" /></p>
</section>
</section>
<section id="感知量化训练">
<h2>感知量化训练<a class="headerlink" href="#感知量化训练" title="Permalink to this headline"></a></h2>
<p>MindSpore的感知量化训练是指在训练时使用伪量化节点来模拟量化操作，过程中仍然采用浮点数计算，并通过反向传播学习更新网络参数，使得网络参数更好地适应量化带来的损失。对于权值和数据的量化，MindSpore采用了参考文献[1]中的方案。</p>
<p>表1：感知量化训练规格</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>规格</p></th>
<th class="head"><p>规格说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>硬件支持</p></td>
<td><p>GPU</p></td>
</tr>
<tr class="row-odd"><td><p>网络支持</p></td>
<td><p>LeNet、ResNet50，具体请参见<a class="reference external" href="https://gitee.com/mindspore/models/tree/master">https://gitee.com/mindspore/models/tree/master</a>。</p></td>
</tr>
<tr class="row-even"><td><p>算法支持</p></td>
<td><p>支持非对称和对称的量化算法；支持逐层和逐通道的量化算法。</p></td>
</tr>
<tr class="row-odd"><td><p>方案支持</p></td>
<td><p>支持8比特的量化方案。</p></td>
</tr>
<tr class="row-even"><td><p>数据类型支持</p></td>
<td><p>GPU平台支持FP32。</p></td>
</tr>
<tr class="row-odd"><td><p>运行模式支持</p></td>
<td><p>Graph模式和PyNative模式</p></td>
</tr>
</tbody>
</table>
</section>
<section id="感知量化训练示例">
<h2>感知量化训练示例<a class="headerlink" href="#感知量化训练示例" title="Permalink to this headline"></a></h2>
<p>感知量化训练与一般训练步骤基本一致,在构造网络阶段需要应用MindSpore Golden Stick的量化算法生成量化网络，完整流程如下：</p>
<ol class="arabic simple">
<li><p>加载数据集，处理数据。</p></li>
<li><p>定义网络。</p></li>
<li><p>定义MindSpore Golden Stick量化算法，应用算法生成量化网络。</p></li>
<li><p>定义优化器、损失函数和callbacks。</p></li>
<li><p>训练网络，保存checkpoint文件。</p></li>
<li><p>评估网络，对比量化后精度。</p></li>
</ol>
<p>接下来以LeNet5网络为例，分别叙述这些步骤。</p>
<blockquote>
<div><p>完整代码见<a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.8/official/cv/lenet/README_CN.md#%E5%BA%94%E7%94%A8mindspore-golden-stick%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95">lenet模型仓</a>，其中<a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.8/official/cv/lenet/golden_stick/quantization/simqat/train.py">train.py</a> 为完整的训练代码，<a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.8/official/cv/lenet/golden_stick/quantization/simqat/eval.py">eval.py</a> 为精度验证代码。</p>
</div></blockquote>
<section id="加载数据集">
<h3>加载数据集<a class="headerlink" href="#加载数据集" title="Permalink to this headline"></a></h3>
<p>调用MindData加载数据集：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
<p>代码中create_dataset引用自<a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.8/official/cv/lenet/src/dataset.py">dataset.py</a>
，config.data_path和config.batch_size分别在<a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.8/official/cv/lenet/golden_stick/quantization/simqat/lenet_mnist_config.yaml">配置文件</a> 中配置，下同。</p>
</section>
<section id="定义原网络">
<h3>定义原网络<a class="headerlink" href="#定义原网络" title="Permalink to this headline"></a></h3>
<p>实例化LeNet5网络：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">src.lenet</span> <span class="kn">import</span> <span class="n">LeNet5</span>
<span class="o">...</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
</pre></div>
</div>
<p>原始网络结构如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>LeNet5&lt;
  (conv1): Conv2d&lt;input_channels=1, output_channels=6, kernel_size=(5, 5), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW&gt;
  (conv2): Conv2d&lt;input_channels=6, output_channels=16, kernel_size=(5, 5), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW&gt;
  (relu): ReLU&lt;&gt;
  (max_pool2d): MaxPool2d&lt;kernel_size=2, stride=2, pad_mode=VALID&gt;
  (flatten): Flatten&lt;&gt;
  (fc1): Dense&lt;input_channels=400, output_channels=120, has_bias=True&gt;
  (fc2): Dense&lt;input_channels=120, output_channels=84, has_bias=True&gt;
  (fc3): Dense&lt;input_channels=84, output_channels=10, has_bias=True&gt;
  &gt;
</pre></div>
</div>
<p>LeNet5网络定义见<a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.8/official/cv/lenet/src/lenet.py">lenet.py</a> 。</p>
</section>
<section id="应用量化算法">
<h3>应用量化算法<a class="headerlink" href="#应用量化算法" title="Permalink to this headline"></a></h3>
<p>量化网络是指在原网络定义的基础上，修改需要量化的网络层后生成的带有伪量化节点的网络，通过构造MindSpore Golden Stick下的<code class="docutils literal notranslate"><span class="pre">SimulatedQuantizationAwareTraining</span></code>类，并将其应用到原网络上将原网络转换为量化网络。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_gs</span> <span class="kn">import</span> <span class="n">SimulatedQuantizationAwareTraining</span> <span class="k">as</span> <span class="n">SimQAT</span>

<span class="o">...</span>
<span class="n">algo</span> <span class="o">=</span> <span class="n">SimQAT</span><span class="p">()</span>
<span class="n">quanted_network</span> <span class="o">=</span> <span class="n">algo</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">quanted_network</span><span class="p">)</span>
</pre></div>
</div>
<p>量化网络结构如下，其中QuantizerWrapperCell为感知量化训练对原有Conv2d或者Dense的封装类，包括了原有的算子以及输入输出和权重的伪量化节点，用户可以参考<a class="reference external" href="https://www.mindspore.cn/golden_stick/docs/zh-CN/r0.1/mindspore_gs.html#mindspore_gs.SimulatedQuantizationAwareTraining">API</a> 修改算法配置，并通过检查QuantizeWrapperCell的属性确认算法是否配置成功。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>LeNet5Opt&lt;
  (_handler):
  ...
  (Conv2dQuant): QuantizeWrapperCell&lt;
    (_handler): Conv2dQuant&lt;
      in_channels=1, out_channels=6, kernel_size=(5, 5), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False
      (fake_quant_weight): SimulatedFakeQuantizerPerChannel&lt;bit_num=8, symmetric=True, narrow_range=False, ema=False(0.999), per_channel=True(0, 6), quant_delay=0&gt;
      &gt;
    (_input_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    (_output_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    &gt;
  (Conv2dQuant_1): QuantizeWrapperCell&lt;
    (_handler): Conv2dQuant&lt;
      in_channels=6, out_channels=16, kernel_size=(5, 5), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False
      (fake_quant_weight): SimulatedFakeQuantizerPerChannel&lt;bit_num=8, symmetric=True, narrow_range=False, ema=False(0.999), per_channel=True(0, 16), quant_delay=0&gt;
      &gt;
    (_input_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    (_output_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    &gt;
  (DenseQuant): QuantizeWrapperCell&lt;
    (_handler): DenseQuant&lt;
      in_channels=400, out_channels=120, weight=Parameter (name=DenseQuant._handler.weight, shape=(120, 400), dtype=Float32, requires_grad=True), has_bias=True, bias=Parameter (name=DenseQuant._handler.bias, shape=(120,), dtype=Float32, requires_grad=True)
      (fake_quant_weight): SimulatedFakeQuantizerPerChannel&lt;bit_num=8, symmetric=True, narrow_range=False, ema=False(0.999), per_channel=True(0, 120), quant_delay=0&gt;
      &gt;
    (_input_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    (_output_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    &gt;
  (DenseQuant_1): QuantizeWrapperCell&lt;
    (_handler): DenseQuant&lt;
      in_channels=120, out_channels=84, weight=Parameter (name=DenseQuant_1._handler.weight, shape=(84, 120), dtype=Float32, requires_grad=True), has_bias=True, bias=Parameter (name=DenseQuant_1._handler.bias, shape=(84,), dtype=Float32, requires_grad=True)
      (fake_quant_weight): SimulatedFakeQuantizerPerChannel&lt;bit_num=8, symmetric=True, narrow_range=False, ema=False(0.999), per_channel=True(0, 84), quant_delay=0&gt;
      &gt;
    (_input_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    (_output_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    &gt;
  (DenseQuant_2): QuantizeWrapperCell&lt;
    (_handler): DenseQuant&lt;
      in_channels=84, out_channels=10, weight=Parameter (name=DenseQuant_2._handler.weight, shape=(10, 84), dtype=Float32, requires_grad=True), has_bias=True, bias=Parameter (name=DenseQuant_2._handler.bias, shape=(10,), dtype=Float32, requires_grad=True)
      (fake_quant_weight): SimulatedFakeQuantizerPerChannel&lt;bit_num=8, symmetric=True, narrow_range=False, ema=False(0.999), per_channel=True(0, 10), quant_delay=0&gt;
      &gt;
    (_input_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    (_output_quantizer): SimulatedFakeQuantizerPerLayer&lt;bit_num=8, symmetric=False, narrow_range=False, ema=False(0.999), per_channel=False, quant_delay=0&gt;
    &gt;
  &gt;
</pre></div>
</div>
</section>
<section id="定义优化器损失函数和训练的callbacks">
<h3>定义优化器、损失函数和训练的callbacks<a class="headerlink" href="#定义优化器损失函数和训练的callbacks" title="Permalink to this headline"></a></h3>
<p>使用Momentum作为LeNet5网络训练的优化器；使用SoftmaxCrossEntropyWithLogits作为LeNet5网络训练的损失函数：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="n">net_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">config</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">momentum</span><span class="p">)</span>
<span class="n">time_cb</span> <span class="o">=</span> <span class="n">TimeMonitor</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="n">ds_train</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">())</span>
<span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">save_checkpoint_steps</span><span class="p">,</span>
                             <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">keep_checkpoint_max</span><span class="p">)</span>
<span class="n">ckpoint_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;checkpoint_lenet&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;./ckpt&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="训练网络保存checkpoint文件">
<h3>训练网络，保存checkpoint文件<a class="headerlink" href="#训练网络保存checkpoint文件" title="Permalink to this headline"></a></h3>
<p>调用<code class="docutils literal notranslate"><span class="pre">Model</span></code>中的<code class="docutils literal notranslate"><span class="pre">train</span></code>接口开始训练模型：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">,</span> <span class="n">net_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">Accuracy</span><span class="p">()})</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">epoch_size</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">time_cb</span><span class="p">,</span> <span class="n">ckpoint_cb</span><span class="p">,</span> <span class="n">LossMonitor</span><span class="p">()])</span>
</pre></div>
</div>
<p>运行结果如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch:1 step: 1875, loss is 0.1609785109
Train epoch time: 18172.836 ms, per step time: 9.692 ms
epoch:2 step: 1875, loss is 0.00334590533
Train epoch time: 8617.408 ms, per step time: 4.596 ms
epoch:3 step: 1875, loss is 0.00310735423
Train epoch time: 8526.766 ms, per step time: 4.548 ms
epoch:4 step: 1875, loss is 0.00962805934
Train epoch time: 8585.520 ms, per step time: 4.579 ms
epoch:5 step: 1875, loss is 0.00363082927
Train epoch time: 8512.096 ms, per step time: 4.540 ms
epoch:6 step: 1875, loss is 0.00169560452
Train epoch time: 8303.8515 ms, per step time: 4.429 ms
epoch:7 step: 1875, loss is 0.08799523115
Train epoch time: 8417.257 ms, per step time: 4.489 ms
epoch:8 step: 1875, loss is 0.0838107979
Train epoch time: 8416.146 ms, per step time: 4.489 ms
epoch:9 step: 1875, loss is 0.00722093607
Train epoch time: 8425.732 ms, per step time: 4.484 ms
epoch:10 step: 1875, loss is 0.00027961225
Train epoch time: 8544.641 ms, per step time: 4.552 ms
</pre></div>
</div>
</section>
<section id="评估网络对比精度">
<h3>评估网络，对比精度<a class="headerlink" href="#评估网络对比精度" title="Permalink to this headline"></a></h3>
<p>按照<a class="reference external" href="https://gitee.com/mindspore/models/tree/r1.8/official/cv/lenet">lenet模型仓</a> 步骤获得普通训练的模型精度：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&#39;Accuracy&#39;:0.9842
</pre></div>
</div>
<p>加载上一步得到的checkpoint文件，并评估量化模型的精度。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">checkpoint_file_path</span><span class="p">)</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="n">ds_eval</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">ds_eval</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&#39;Accuracy&#39;:0.990484
</pre></div>
</div>
<p>LeNet5应用感知量化训练后精度未下降。</p>
<blockquote>
<div><p>感知量化算法的一个效果是压缩模型大小，但这里提到的模型大小是指部署模型的大小。此处的网络并非最终的部署模型，又由于网络中增加了伪量化节点，所以量化网络的checkpoint文件大小反而相较原始网路的略有增加。</p>
</div></blockquote>
</section>
</section>
<section id="总结">
<h2>总结<a class="headerlink" href="#总结" title="Permalink to this headline"></a></h2>
<p>本文主要介绍了量化的作用、常用量化算法的原理，并给出了示例介绍如何应用MindSpore Golden Stick中的感知量化算法。量化算法可以在精度不下降或者下降较少的前提下大幅降低模型尺寸，提升模型推理性能，欢迎使用MindSpore Golden Stick的感知量化训练功能！</p>
</section>
<section id="参考文献">
<h2>参考文献<a class="headerlink" href="#参考文献" title="Permalink to this headline"></a></h2>
<p>[1] Jacob B, Kligys S, Chen B, et al. Quantization and training of neural networks for efficient integer-arithmetic-only inference[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 2704-2713.</p>
</section>
</section>


           </div>
           
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="overview.html" class="btn btn-neutral float-left" title="量化算法概述" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="slb.html" class="btn btn-neutral float-right" title="应用SLB算法" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>