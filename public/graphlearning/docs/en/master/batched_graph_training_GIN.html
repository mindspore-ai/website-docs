

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Batched Graph Training Network &mdash; MindSpore master documentation</title>
  

  
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Spatio-Temporal Graph Training Network" href="spatio_temporal_graph_training_STGCN.html" />
    <link rel="prev" title="Entire Graph Training Network" href="full_training_of_GCN.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindspore_graphlearning_install.html">Install Graph Learning</a></li>
</ul>
<p class="caption"><span class="caption-text">Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="full_training_of_GCN.html">Entire Graph Training Network</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Batched Graph Training Network</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gin-principles">GIN Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="#defining-a-network-model">Defining a Network Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#constructing-a-dataset">Constructing a Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#defining-a-loss-function">Defining a Loss Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="#network-training-and-validation">Network Training and Validation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#setting-environment-variables">Setting Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-a-training-network">Defining a Training Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="#network-training-and-validation-1">Network Training and Validation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#executing-jobs-and-viewing-results">Executing Jobs and Viewing Results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#running-process">Running Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="#execution-results">Execution Results</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="spatio_temporal_graph_training_STGCN.html">Spatio-Temporal Graph Training Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="single_host_distributed_Graphsage.html">Single-host Distributed Training</a></li>
</ul>
<p class="caption"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.html">mindspore_gl</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.dataloader.html">mindspore_gl.dataloader</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.dataset.html">mindspore_gl.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.graph.html">mindspore_gl.graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.nn.html">mindspore_gl.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.sampling.html">mindspore_gl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.utils.html">mindspore_gl.utils</a></li>
</ul>
<p class="caption"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Batched Graph Training Network</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/batched_graph_training_GIN.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="batched-graph-training-network">
<h1>Batched Graph Training Network<a class="headerlink" href="#batched-graph-training-network" title="Permalink to this headline">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/master/docs/graphlearning/docs/source_en/batched_graph_training_GIN.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png"></a>
  </p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>In this example, it will show how to classify the social network with Graph Isomorphism Network.</p>
<p>GIN is inspired by the close connection between GNNs and the Weisfeiler-Lehman (WL) graph isomorphism test, a powerful test known to distinguish a broad class of graphs. GNN can have as large discriminative power as the WL test if the GNN’s aggregation scheme is highly expressive and can model injective functions.</p>
<p>IMDB-BINARY is a movie collaboration dataset that consists of the ego-networks of 1,000 actors/actresses who played roles in movies in IMDB. In each graph, nodes represent actors/actress, and there is an edge between them if they appear in the same movie. These graphs are derived from the Action and Romance genres.
Get batched graph data from the IMDB-BINARY dataset. Each graph is a movie composed of actors. The GIN is used to classify the graphs and predict the genres of the movie.</p>
<p>In the batched graph, multiple graphs can be trained at the same time, and the number of nodes/edges of each graph is different. mindspore_gl integrates the sub graph in the batch into a whole graph, and adds a virtual graph to unify the graph data to reduce memory consumption and speed up calculation.</p>
<blockquote>
<div><p>Download the complete sample code here: <a class="reference external" href="https://gitee.com/mindspore/graphlearning/tree/master/model_zoo/gin">GIN</a>.</p>
</div></blockquote>
</div>
<div class="section" id="gin-principles">
<h2>GIN Principles<a class="headerlink" href="#gin-principles" title="Permalink to this headline">¶</a></h2>
<p>Paper: <a class="reference external" href="https://arxiv.org/pdf/1810.00826.pdf">How Powerful are Graph Neural Networks?</a></p>
</div>
<div class="section" id="defining-a-network-model">
<h2>Defining a Network Model<a class="headerlink" href="#defining-a-network-model" title="Permalink to this headline">¶</a></h2>
<p>GINConv parses graph <code class="docutils literal notranslate"><span class="pre">g</span></code> into <code class="docutils literal notranslate"><span class="pre">BatchedGraph</span></code>, and <code class="docutils literal notranslate"><span class="pre">BatchedGraph</span></code> can support more graph operations than <code class="docutils literal notranslate"><span class="pre">Graph</span></code>. The input data is the whole graph, but when updating the node features of each subgraph, it can still find the corresponding neighbor nodes according to its own nodes, and will not connect to the nodes of other subgraphs.</p>
<p>mindspore_gl.nn implements GINConv, which can be directly imported for use. The code for implementing a multi-layer GinNet network using GINConv, batch normalization, and pooling is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GinNet</span><span class="p">(</span><span class="n">GNNCell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;GIN net&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">num_layers</span><span class="p">,</span>
                 <span class="n">num_mlp_layers</span><span class="p">,</span>
                 <span class="n">input_dim</span><span class="p">,</span>
                 <span class="n">hidden_dim</span><span class="p">,</span>
                 <span class="n">output_dim</span><span class="p">,</span>
                 <span class="n">final_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">learn_eps</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">graph_pooling_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">,</span>
                 <span class="n">neighbor_pooling_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span>
                 <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_dropout</span> <span class="o">=</span> <span class="n">final_dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">graph_pooling_type</span> <span class="o">=</span> <span class="n">graph_pooling_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_pooling_type</span> <span class="o">=</span> <span class="n">neighbor_pooling_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learn_eps</span> <span class="o">=</span> <span class="n">learn_eps</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mlps</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CellList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CellList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_norms</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CellList</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_pooling_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="s1">&#39;avg&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">SyntaxError</span><span class="p">(</span><span class="s2">&quot;graph pooling type not supported.&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">mlps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MLP</span><span class="p">(</span><span class="n">num_mlp_layers</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">mlps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MLP</span><span class="p">(</span><span class="n">num_mlp_layers</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">GINConv</span><span class="p">(</span><span class="n">ApplyNodeFunc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlps</span><span class="p">[</span><span class="n">layer</span><span class="p">]),</span> <span class="n">learn_eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learn_eps</span><span class="p">,</span>
                                      <span class="n">aggregation_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">neighbor_pooling_type</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_norms</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">linears_prediction</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CellList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">linears_prediction</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">linears_prediction</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_weight</span><span class="p">,</span> <span class="n">g</span><span class="p">:</span> <span class="n">BatchedGraph</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;construct function&quot;&quot;&quot;</span>
        <span class="n">hidden_rep</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">[</span><span class="n">layer</span><span class="p">](</span><span class="n">h</span><span class="p">,</span> <span class="n">edge_weight</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span>
            <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_norms</span><span class="p">[</span><span class="n">layer</span><span class="p">](</span><span class="n">h</span><span class="p">)</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()(</span><span class="n">h</span><span class="p">)</span>
            <span class="n">hidden_rep</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

        <span class="n">score_over_layer</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">layer</span><span class="p">,</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hidden_rep</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_pooling_type</span> <span class="o">==</span> <span class="s1">&#39;sum&#39;</span><span class="p">:</span>
                <span class="n">pooled_h</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">sum_nodes</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pooled_h</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">avg_nodes</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
            <span class="n">score_over_layer</span> <span class="o">=</span> <span class="n">score_over_layer</span> <span class="o">+</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_dropout</span><span class="p">)(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">linears_prediction</span><span class="p">[</span><span class="n">layer</span><span class="p">](</span><span class="n">pooled_h</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">score_over_layer</span>
</pre></div>
</div>
<p>For details about GINConv implementation, see the <a class="reference external" href="https://gitee.com/mindspore/graphlearning/blob/master/mindspore_gl/nn/conv/ginconv.py">API</a> code of mindspore_gl.nn.GINConv.</p>
</div>
<div class="section" id="constructing-a-dataset">
<h2>Constructing a Dataset<a class="headerlink" href="#constructing-a-dataset" title="Permalink to this headline">¶</a></h2>
<p>From mindspore_gl.dataset calls the dataset of IMDB-BINARY,the method can refer to <a class="reference external" href="https://www.mindspore.cn/graphlearning/docs/zh-CN/master/full_training_of_GCN.html#%E6%9E%84%E9%80%A0%E6%95%B0%E6%8D%AE%E9%9B%86">GCN</a>. Then use mindpoint_gl.dataloader.RandomBatchSampler defines a sampler and returns the sampling index.
MultiHomeGraphDataset obtains data from the dataset according to the sampling index, packages the data into a batch, and generates the dataset generator.
After building a generator, invoke the API of mindspore.dataset.GeneratorDataset to construct a dataloader.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">IMDBBinary</span><span class="p">(</span><span class="n">arguments</span><span class="o">.</span><span class="n">data_path</span><span class="p">)</span>
<span class="n">train_batch_sampler</span> <span class="o">=</span> <span class="n">RandomBatchSampler</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">train_graphs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">arguments</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">train_multi_graph_dataset</span> <span class="o">=</span> <span class="n">MultiHomoGraphDataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">arguments</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">train_batch_sampler</span><span class="p">)))</span>
<span class="n">test_batch_sampler</span> <span class="o">=</span> <span class="n">RandomBatchSampler</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">val_graphs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">arguments</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">test_multi_graph_dataset</span> <span class="o">=</span> <span class="n">MultiHomoGraphDataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">arguments</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">test_batch_sampler</span><span class="p">)))</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">train_multi_graph_dataset</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;row&#39;</span><span class="p">,</span> <span class="s1">&#39;col&#39;</span><span class="p">,</span> <span class="s1">&#39;node_count&#39;</span><span class="p">,</span> <span class="s1">&#39;edge_count&#39;</span><span class="p">,</span>
                                                                   <span class="s1">&#39;node_map_idx&#39;</span><span class="p">,</span> <span class="s1">&#39;edge_map_idx&#39;</span><span class="p">,</span> <span class="s1">&#39;graph_mask&#39;</span><span class="p">,</span>
                                                                   <span class="s1">&#39;batched_label&#39;</span><span class="p">,</span> <span class="s1">&#39;batched_node_feat&#39;</span><span class="p">,</span>
                                                                   <span class="s1">&#39;batched_edge_feat&#39;</span><span class="p">],</span>
                                       <span class="n">sampler</span><span class="o">=</span><span class="n">train_batch_sampler</span><span class="p">)</span>

<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">test_multi_graph_dataset</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;row&#39;</span><span class="p">,</span> <span class="s1">&#39;col&#39;</span><span class="p">,</span> <span class="s1">&#39;node_count&#39;</span><span class="p">,</span> <span class="s1">&#39;edge_count&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;node_map_idx&#39;</span><span class="p">,</span> <span class="s1">&#39;edge_map_idx&#39;</span><span class="p">,</span> <span class="s1">&#39;graph_mask&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;batched_label&#39;</span><span class="p">,</span> <span class="s1">&#39;batched_node_feat&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;batched_edge_feat&#39;</span><span class="p">],</span>
                                      <span class="n">sampler</span><span class="o">=</span><span class="n">test_batch_sampler</span><span class="p">)</span>
</pre></div>
</div>
<p>Use mindspore_gl.graph.BatchHomeGraph merges multiple sub-graphs into one whole graph. During model training, all graphs in the batch will be calculated in the form of whole graph.</p>
<p>To reduce the generation of calculation graphs and speed up calculation, the generator unifies the data of each batch to the same size during returning data.</p>
<p>Assume number of nodes is <code class="docutils literal notranslate"><span class="pre">node_size</span></code>and number of edges is <code class="docutils literal notranslate"><span class="pre">edge_size</span></code>, which is  satisfies that the sum of nodes and edges for all graph data in batch is less than or equal to <code class="docutils literal notranslate"><span class="pre">node_size</span> <span class="pre">*</span> <span class="pre">batch</span></code> and <code class="docutils literal notranslate"><span class="pre">edge_size</span> <span class="pre">*</span> <span class="pre">batch</span></code>.
Create a new virtual graph in the batch, so that the sum of nodes and edges in the batch is equal to <code class="docutils literal notranslate"><span class="pre">node_size</span> <span class="pre">*</span> <span class="pre">batch</span></code> and <code class="docutils literal notranslate"><span class="pre">edge_size</span> <span class="pre">*</span> <span class="pre">batch</span></code>.
When calculating loss, this graph will not participate in the calculation.</p>
<p>Call mindspore_gl.graph.PadArray2d to define the operation of node feature filling and edge feature filling, and set the node feature and edge feature on the virtual graph to 0.
Call mindspore_gl.graph.PadHomoGraph to define the operation of filling the nodes and edges on the graph structure, so that the number of nodes in the batch is equal to <code class="docutils literal notranslate"><span class="pre">node_size</span> <span class="pre">*</span> <span class="pre">batch</span></code>, and the number of edges is equal to <code class="docutils literal notranslate"><span class="pre">edge_size</span> <span class="pre">*</span> <span class="pre">batch</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MultiHomoGraphDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;MultiHomoGraph Dataset&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">CONST</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">edge_size</span><span class="o">=</span><span class="mi">350</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span> <span class="o">=</span> <span class="n">dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_length</span> <span class="o">=</span> <span class="n">length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_fn</span> <span class="o">=</span> <span class="n">BatchHomoGraph</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batched_edge_feat</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">node_size</span> <span class="o">*=</span> <span class="n">batch_size</span>
        <span class="n">edge_size</span> <span class="o">*=</span> <span class="n">batch_size</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">PadMode</span><span class="o">.</span><span class="n">CONST</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">node_feat_pad_op</span> <span class="o">=</span> <span class="n">PadArray2d</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">CONST</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="n">PadDirection</span><span class="o">.</span><span class="n">COL</span><span class="p">,</span>
                                               <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">node_size</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">node_feat_size</span><span class="p">),</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">edge_feat_pad_op</span> <span class="o">=</span> <span class="n">PadArray2d</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">CONST</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="n">PadDirection</span><span class="o">.</span><span class="n">COL</span><span class="p">,</span>
                                               <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">edge_size</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">edge_feat_size</span><span class="p">),</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_pad_op</span> <span class="o">=</span> <span class="n">PadHomoGraph</span><span class="p">(</span><span class="n">n_edge</span><span class="o">=</span><span class="n">edge_size</span><span class="p">,</span> <span class="n">n_node</span><span class="o">=</span><span class="n">node_size</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">CONST</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">node_feat_pad_op</span> <span class="o">=</span> <span class="n">PadArray2d</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="n">PadDirection</span><span class="o">.</span><span class="n">COL</span><span class="p">,</span>
                                               <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">edge_feat_pad_op</span> <span class="o">=</span> <span class="n">PadArray2d</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="n">PadDirection</span><span class="o">.</span><span class="n">COL</span><span class="p">,</span>
                                               <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_pad_op</span> <span class="o">=</span> <span class="n">PadHomoGraph</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">AUTO</span><span class="p">)</span>

        <span class="c1"># For Padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="kc">True</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_mask</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_graph_idx</span><span class="p">):</span>
        <span class="n">graph_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">feature_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_graph_idx</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">graph_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="p">[</span><span class="n">batch_graph_idx</span><span class="p">[</span><span class="n">idx</span><span class="p">]])</span>
            <span class="n">feature_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="o">.</span><span class="n">graph_node_feat</span><span class="p">(</span><span class="n">batch_graph_idx</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>

        <span class="c1"># Batch Graph</span>
        <span class="n">batch_graph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_fn</span><span class="p">(</span><span class="n">graph_list</span><span class="p">)</span>

        <span class="c1"># Pad Graph</span>
        <span class="n">batch_graph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_pad_op</span><span class="p">(</span><span class="n">batch_graph</span><span class="p">)</span>

        <span class="c1"># Batch Node Feat</span>
        <span class="n">batched_node_feat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">feature_list</span><span class="p">)</span>

        <span class="c1"># Pad NodeFeat</span>
        <span class="n">batched_node_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_feat_pad_op</span><span class="p">(</span><span class="n">batched_node_feat</span><span class="p">)</span>
        <span class="n">batched_label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="o">.</span><span class="n">graph_label</span><span class="p">[</span><span class="n">batch_graph_idx</span><span class="p">]</span>

        <span class="c1"># Pad Label</span>
        <span class="n">batched_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batched_label</span><span class="p">,</span> <span class="n">batched_label</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Get Edge Feat</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batched_edge_feat</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">batched_edge_feat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">batch_graph</span><span class="o">.</span><span class="n">edge_count</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">batched_edge_feat</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batched_edge_feat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">batch_graph</span><span class="o">.</span><span class="n">edge_count</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># Trigger Node_Map_Idx/Edge_Map_Idx Computation, Because It Is Lazily Computed</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">batch_graph</span><span class="o">.</span><span class="n">batch_meta</span><span class="o">.</span><span class="n">node_map_idx</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">batch_graph</span><span class="o">.</span><span class="n">batch_meta</span><span class="o">.</span><span class="n">edge_map_idx</span>

        <span class="n">np_graph_mask</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">np_graph_mask</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">constant_graph_mask</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np_graph_mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="n">batchedgraphfiled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_batched_graph_field</span><span class="p">(</span><span class="n">batch_graph</span><span class="p">,</span> <span class="n">constant_graph_mask</span><span class="p">)</span>
        <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">node_count</span><span class="p">,</span> <span class="n">edge_count</span><span class="p">,</span> <span class="n">node_map_idx</span><span class="p">,</span> <span class="n">edge_map_idx</span><span class="p">,</span> <span class="n">graph_mask</span> <span class="o">=</span> <span class="n">batchedgraphfiled</span><span class="o">.</span><span class="n">get_batched_graph</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">node_count</span><span class="p">,</span> <span class="n">edge_count</span><span class="p">,</span> <span class="n">node_map_idx</span><span class="p">,</span> <span class="n">edge_map_idx</span><span class="p">,</span> <span class="n">graph_mask</span><span class="p">,</span> <span class="n">batched_label</span><span class="p">,</span>\
               <span class="n">batched_node_feat</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batched_edge_feat</span><span class="p">[:</span><span class="n">batch_graph</span><span class="o">.</span><span class="n">edge_count</span><span class="p">,</span> <span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="section" id="defining-a-loss-function">
<h2>Defining a Loss Function<a class="headerlink" href="#defining-a-loss-function" title="Permalink to this headline">¶</a></h2>
<p>Since this is a classification task, the cross entropy can be used as the loss function, and the implementation method is similar to that of <a class="reference external" href="https://www.mindspore.cn/graphlearning/docs/en/master/full_training_of_GCN.html#defining-a-loss-function">GCN</a>.</p>
<p>Different from GCN, this tutorial is for graph classification. Therefore, when parsing batch graphs, the mindspore_gl.BatchedGraph interface is invoked.</p>
<p>The last value in <code class="docutils literal notranslate"><span class="pre">g.graph_mask</span></code> is the mask of the virtual graph, which is 0. Therefore, the last loss value is also 0.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LossNet</span><span class="p">(</span><span class="n">GNNCell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; LossNet definition &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_feat</span><span class="p">,</span> <span class="n">edge_weight</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">g</span><span class="p">:</span> <span class="n">BatchedGraph</span><span class="p">):</span>
        <span class="n">predict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">node_feat</span><span class="p">,</span> <span class="n">edge_weight</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">()(</span><span class="n">target</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()(</span><span class="n">loss</span> <span class="o">*</span> <span class="n">g</span><span class="o">.</span><span class="n">graph_mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
</div>
<div class="section" id="network-training-and-validation">
<h2>Network Training and Validation<a class="headerlink" href="#network-training-and-validation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="setting-environment-variables">
<h3>Setting Environment Variables<a class="headerlink" href="#setting-environment-variables" title="Permalink to this headline">¶</a></h3>
<p>The method of setting environment variables is similar to that of setting <a class="reference external" href="https://www.mindspore.cn/graphlearning/docs/en/master/full_training_of_GCN.html#setting-environment-variables">GCN</a>.</p>
</div>
<div class="section" id="defining-a-training-network">
<h3>Defining a Training Network<a class="headerlink" href="#defining-a-training-network" title="Permalink to this headline">¶</a></h3>
<p>Instantiation of the model body GinNet and LossNet and optimizer.
Input the LossNet instance and optimizer to mindspore.nn.TrainOneStepCell to construct a single-step training network train_net.
The implementation method is similar to that of the <a class="reference external" href="https://www.mindspore.cn/graphlearning/docs/en/master/full_training_of_GCN.html#defining-a-training-network">GCN</a>.</p>
</div>
<div class="section" id="network-training-and-validation-1">
<h3>Network Training and Validation<a class="headerlink" href="#network-training-and-validation-1" title="Permalink to this headline">¶</a></h3>
<p>Because the graph is trained in batch, the API invoked during graph composition is mindspore_gl.BatchedGraphField, which is different from mindspore_gl.GraphField. It added the parameters of <code class="docutils literal notranslate"><span class="pre">node_map_idx</span></code>, <code class="docutils literal notranslate"><span class="pre">edge_map_idx</span></code>, and <code class="docutils literal notranslate"><span class="pre">graph_mask</span></code>.
The <code class="docutils literal notranslate"><span class="pre">graph_mask</span></code> is the mask information of each graph in the batch. The last graph is the virtual graph. Therefore, in the <code class="docutils literal notranslate"><span class="pre">graph_mask</span></code>, the last value is 0 and the rest is 1.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_gl</span> <span class="kn">import</span> <span class="n">BatchedGraph</span><span class="p">,</span> <span class="n">BatchedGraphField</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
    <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">node_count</span><span class="p">,</span> <span class="n">edge_count</span><span class="p">,</span> <span class="n">node_map_idx</span><span class="p">,</span> <span class="n">edge_map_idx</span><span class="p">,</span> <span class="n">graph_mask</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">node_feat</span><span class="p">,</span> <span class="n">edge_feat</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">batch_homo</span> <span class="o">=</span> <span class="n">BatchedGraphField</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">node_count</span><span class="p">,</span> <span class="n">edge_count</span><span class="p">,</span> <span class="n">node_map_idx</span><span class="p">,</span> <span class="n">edge_map_idx</span><span class="p">,</span> <span class="n">graph_mask</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">node_feat</span><span class="p">,</span> <span class="n">edge_feat</span><span class="p">,</span> <span class="o">*</span><span class="n">batch_homo</span><span class="o">.</span><span class="n">get_batched_graph</span><span class="p">())</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="executing-jobs-and-viewing-results">
<h2>Executing Jobs and Viewing Results<a class="headerlink" href="#executing-jobs-and-viewing-results" title="Permalink to this headline">¶</a></h2>
<div class="section" id="running-process">
<h3>Running Process<a class="headerlink" href="#running-process" title="Permalink to this headline">¶</a></h3>
<p>After running the program, translate the code and start training.</p>
</div>
<div class="section" id="execution-results">
<h3>Execution Results<a class="headerlink" href="#execution-results" title="Permalink to this headline">¶</a></h3>
<p>Run the <a class="reference external" href="https://gitee.com/mindspore/graphlearning/blob/master/model_zoo/gin/trainval_imdb_binary.py">trainval_imdb_binary.py</a> script to start training.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>model_zoo/gin
python<span class="w"> </span>trainval_imdb_binary.py<span class="w"> </span>--data_path<span class="o">={</span>path<span class="o">}</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">{path}</span></code> indicates the dataset storage path.</p>
<p>The training result is as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>...
Epoch<span class="w"> </span><span class="m">52</span>,<span class="w"> </span>Time<span class="w"> </span><span class="m">3</span>.547<span class="w"> </span>s,<span class="w"> </span>Train<span class="w"> </span>loss<span class="w"> </span><span class="m">0</span>.49981827,<span class="w"> </span>Train<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.74219,<span class="w"> </span>Test<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.594
Epoch<span class="w"> </span><span class="m">53</span>,<span class="w"> </span>Time<span class="w"> </span><span class="m">3</span>.599<span class="w"> </span>s,<span class="w"> </span>Train<span class="w"> </span>loss<span class="w"> </span><span class="m">0</span>.5046462,<span class="w"> </span>Train<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.74219,<span class="w"> </span>Test<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.656
Epoch<span class="w"> </span><span class="m">54</span>,<span class="w"> </span>Time<span class="w"> </span><span class="m">3</span>.505<span class="w"> </span>s,<span class="w"> </span>Train<span class="w"> </span>loss<span class="w"> </span><span class="m">0</span>.49653444,<span class="w"> </span>Train<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.74777,<span class="w"> </span>Test<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.766
Epoch<span class="w"> </span><span class="m">55</span>,<span class="w"> </span>Time<span class="w"> </span><span class="m">3</span>.468<span class="w"> </span>s,<span class="w"> </span>Train<span class="w"> </span>loss<span class="w"> </span><span class="m">0</span>.49411067,<span class="w"> </span>Train<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.74219,<span class="w"> </span>Test<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.750
</pre></div>
</div>
<p>The best accuracy verified on IMDBBinary: 0.766</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="spatio_temporal_graph_training_STGCN.html" class="btn btn-neutral float-right" title="Spatio-Temporal Graph Training Network" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="full_training_of_GCN.html" class="btn btn-neutral float-left" title="Entire Graph Training Network" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>