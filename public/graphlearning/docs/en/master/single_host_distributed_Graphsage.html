<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Single-host Distributed Training &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="mindspore_gl" href="mindspore_gl.html" />
    <link rel="prev" title="Spatio-Temporal Graph Training Network" href="spatio_temporal_graph_training_STGCN.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindspore_graphlearning_install.html">Installing Graph Learning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="full_training_of_GCN.html">Entire Graph Training Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="batched_graph_training_GIN.html">Batched Graph Training Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="spatio_temporal_graph_training_STGCN.html">Spatio-Temporal Graph Training Network</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Single-host Distributed Training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#graphsage-principles">GraphSAGE Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="#setting-running-script">Setting Running Script</a></li>
<li class="toctree-l2"><a class="reference internal" href="#defining-a-network-model">Defining a Network Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#defining-a-loss-function">Defining a Loss Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="#constructing-a-dataset">Constructing a Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#network-training-and-validation">Network Training and Validation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#setting-environment-variables">Setting Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-a-training-network">Defining a Training Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="#network-training-and-validation-1">Network Training and Validation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#executing-jobs-and-viewing-results">Executing Jobs and Viewing Results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#running-process">Running Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="#execution-results">Execution Results</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.html">mindspore_gl</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.dataloader.html">mindspore_gl.dataloader</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.dataset.html">mindspore_gl.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.graph.html">mindspore_gl.graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.nn.html">mindspore_gl.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.sampling.html">mindspore_gl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.utils.html">mindspore_gl.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Single-host Distributed Training</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/single_host_distributed_Graphsage.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="single-host-distributed-training">
<h1>Single-host Distributed Training<a class="headerlink" href="#single-host-distributed-training" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/graphlearning/docs/source_en/single_host_distributed_Graphsage.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.svg" /></a>
  </p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>In this example, it will show how to do the single-host distributed training of GraphSAGE on large size graphs.</p>
<p>GraphSAGE is a general inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, GraphSAGE learns a function that generates embeddings by sampling and aggregating features from a node’s local neighborhood.</p>
<p>In the Reddit dataset, the authors sampled 50 large communities and constructed a post-to-post graph, linking posts if the same user commented on both posts. Each post is labeled as the community to which it belongs. The dataset contains a total of 232965 posts with an average degree of 492.</p>
<p>Since the Reddit dataset size is large, to reduce the GraphSAGE training time, in this example, distributed model training is performed on single-host to accelerate the model training.</p>
<blockquote>
<div><p>Download the complete sample code here: <a class="reference external" href="https://gitee.com/mindspore/graphlearning/tree/master/model_zoo/graphsage">GraphSAGE</a>.</p>
</div></blockquote>
</section>
<section id="graphsage-principles">
<h2>GraphSAGE Principles<a class="headerlink" href="#graphsage-principles" title="Permalink to this headline"></a></h2>
<p>Paper: <a class="reference external" href="https://proceedings.neurips.cc/paper/2017/file/5dd9db5e033da9c6fb5ba83c7a7ebea9-Paper.pdf">Inductive representation learning on large graphs</a></p>
</section>
<section id="setting-running-script">
<h2>Setting Running Script<a class="headerlink" href="#setting-running-script" title="Permalink to this headline"></a></h2>
<p>The invoking method of distributed training depending on the device.</p>
<p>On the GPU hardware platform, communication in MindSpore distributed parallel training uses NVIDIA’s collective communication library NVIDIA Collective Communication Library (NCCL for short).</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># GPU</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3,4,5,6,7
<span class="nb">export</span><span class="w"> </span><span class="nv">CUDA_NUM</span><span class="o">=</span><span class="m">8</span>
rm<span class="w"> </span>-rf<span class="w"> </span>device
mkdir<span class="w"> </span>device
cp<span class="w"> </span>-r<span class="w"> </span>src<span class="w"> </span>./device
cp<span class="w"> </span>distributed_trainval_reddit.py<span class="w"> </span>./device
<span class="nb">cd</span><span class="w"> </span>./device
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training&quot;</span>
mpirun<span class="w"> </span>--allow-run-as-root<span class="w"> </span>-n<span class="w"> </span><span class="si">${</span><span class="nv">CUDA_NUM</span><span class="si">}</span><span class="w"> </span>python3<span class="w"> </span>./distributed_trainval_reddit.py<span class="w"> </span>--data-path<span class="w"> </span><span class="si">${</span><span class="nv">DATA_PATH</span><span class="si">}</span><span class="w"> </span>--epochs<span class="w"> </span><span class="m">5</span><span class="w"> </span>&gt;<span class="w"> </span>train.log<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
</pre></div>
</div>
<p>The Huawei Collective Communication Library (HCCL) is used for the communication of MindSpore parallel distributed training and can be found in the Atlas 200/300/500 inference product software package. In addition, mindspore.communication.management encapsulates the collective communication API provided by the HCCL to help users configure distributed information.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ascend</span>
<span class="nv">RANK_TABLE_FILE</span><span class="o">=</span><span class="nv">$3</span>
<span class="w">  </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_TABLE_FILE</span><span class="o">=</span><span class="si">${</span><span class="nv">RANK_TABLE_FILE</span><span class="si">}</span>
<span class="w">  </span><span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span>i&lt;<span class="m">8</span><span class="p">;</span>i++<span class="o">))</span><span class="p">;</span>
<span class="w">  </span><span class="k">do</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span>$<span class="o">[</span>i+RANK_START<span class="o">]</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span>$<span class="o">[</span>i+RANK_START<span class="o">]</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="si">${</span><span class="nv">DEVICE_ID</span><span class="si">}</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span><span class="si">${</span><span class="nv">execute_path</span><span class="si">}</span>/device_<span class="nv">$RANK_ID</span>
<span class="w">    </span>mkdir<span class="w"> </span><span class="si">${</span><span class="nv">execute_path</span><span class="si">}</span>/device_<span class="nv">$RANK_ID</span>
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">execute_path</span><span class="si">}</span>/device_<span class="nv">$RANK_ID</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="nb">exit</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training&quot;</span>
<span class="w">    </span>python3<span class="w"> </span><span class="si">${</span><span class="nv">self_path</span><span class="si">}</span>/distributed_trainval_reddit.py<span class="w"> </span>--data-path<span class="w"> </span><span class="si">${</span><span class="nv">DATA_PATH</span><span class="si">}</span><span class="w"> </span>--epochs<span class="w"> </span><span class="m">2</span><span class="w"> </span>&gt;<span class="w"> </span>train<span class="nv">$RANK_ID</span>.log<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="w">  </span><span class="k">done</span>
</pre></div>
</div>
</section>
<section id="defining-a-network-model">
<h2>Defining a Network Model<a class="headerlink" href="#defining-a-network-model" title="Permalink to this headline"></a></h2>
<p>mindspore_gl.nn implements SAGEConv, which can be directly imported for use. You can also define your own convolutional layer. The code for implementing a two-layer GraphSAGE network using SAGEConv is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SAGENet</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;graphsage net&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_feat_size</span><span class="p">,</span> <span class="n">hidden_feat_size</span><span class="p">,</span> <span class="n">appr_feat_size</span><span class="p">,</span> <span class="n">out_feat_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">SAGEConv</span><span class="p">(</span><span class="n">in_feat_size</span><span class="p">,</span> <span class="n">hidden_feat_size</span><span class="p">,</span> <span class="n">aggregator_type</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">SAGEConv</span><span class="p">(</span><span class="n">hidden_feat_size</span><span class="p">,</span> <span class="n">appr_feat_size</span><span class="p">,</span> <span class="n">aggregator_type</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense_out</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">appr_feat_size</span><span class="p">,</span> <span class="n">out_feat_size</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                     <span class="n">weight_init</span><span class="o">=</span><span class="n">XavierUniform</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_feat</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_edges</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;graphsage net forward&quot;&quot;&quot;</span>
        <span class="n">node_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">node_feat</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">edges</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">edges</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_edges</span><span class="p">)</span>
        <span class="n">node_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">node_feat</span><span class="p">)</span>
        <span class="n">node_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">node_feat</span><span class="p">)</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">node_feat</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">edges</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">edges</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_edges</span><span class="p">)</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_out</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ret</span>
</pre></div>
</div>
<p>For details about SAGENet implementation, see the <a class="reference external" href="https://gitee.com/mindspore/graphlearning/blob/master/mindspore_gl/nn/conv/sageconv.py">API</a> code of mindspore_gl.nn.SAGEConv.</p>
</section>
<section id="defining-a-loss-function">
<h2>Defining a Loss Function<a class="headerlink" href="#defining-a-loss-function" title="Permalink to this headline"></a></h2>
<p>Because this task is a classification task, the cross entropy can be used as the loss function, and the implementation method is similar to that of <a class="reference external" href="https://www.mindspore.cn/graphlearning/docs/en/master/full_training_of_GCN.html#defining-a-loss-function">GCN</a>.</p>
</section>
<section id="constructing-a-dataset">
<h2>Constructing a Dataset<a class="headerlink" href="#constructing-a-dataset" title="Permalink to this headline"></a></h2>
<p>The following uses the <a class="reference external" href="https://data.dgl.ai/dataset/reddit.zip">Reddit</a> dataset as an example. Enter the data path to construct a data class.
The get_group_size is used to obtain the total number of processes for distributed training, and the get_rank is used to obtain the ID of the current process. The construction method of dataloader can refer to <a class="reference external" href="https://www.mindspore.cn/graphlearning/docs/en/master/batched_graph_training_GIN.html#constructing-a-dataset">GIN</a>.</p>
<p>Different from GIN, in this example, the sampler is mindpoint_gl.dataloader.DistributeRandomBatchSampler. In DistributeRandomBatchSampler, datasets can be split based on process ID to ensure that each process obtains different part of dataset batches.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_gl.dataset</span> <span class="kn">import</span> <span class="n">Reddit</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">get_rank</span><span class="p">,</span> <span class="n">get_group_size</span>

<span class="n">rank_id</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
<span class="n">world_size</span> <span class="o">=</span> <span class="n">get_group_size</span><span class="p">()</span>
<span class="n">graph_dataset</span> <span class="o">=</span> <span class="n">Reddit</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">data_path</span><span class="p">)</span>
<span class="n">train_sampler</span> <span class="o">=</span> <span class="n">DistributeRandomBatchSampler</span><span class="p">(</span><span class="n">rank_id</span><span class="p">,</span> <span class="n">world_size</span><span class="p">,</span> <span class="n">data_source</span><span class="o">=</span><span class="n">graph_dataset</span><span class="o">.</span><span class="n">train_nodes</span><span class="p">,</span>
                                             <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">test_sampler</span> <span class="o">=</span> <span class="n">RandomBatchSampler</span><span class="p">(</span><span class="n">data_source</span><span class="o">=</span><span class="n">graph_dataset</span><span class="o">.</span><span class="n">test_nodes</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">GraphSAGEDataset</span><span class="p">(</span><span class="n">graph_dataset</span><span class="p">,</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">train_sampler</span><span class="p">)),</span> <span class="n">single_size</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">GraphSAGEDataset</span><span class="p">(</span><span class="n">graph_dataset</span><span class="p">,</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">test_sampler</span><span class="p">)),</span> <span class="n">single_size</span><span class="p">)</span>
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;seeds_idx&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;nid_feat&#39;</span><span class="p">,</span> <span class="s1">&#39;edges&#39;</span><span class="p">],</span>
                                       <span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">,</span> <span class="n">python_multiprocessing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;seeds_idx&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;nid_feat&#39;</span><span class="p">,</span> <span class="s1">&#39;edges&#39;</span><span class="p">],</span>
                                      <span class="n">sampler</span><span class="o">=</span><span class="n">test_sampler</span><span class="p">,</span> <span class="n">python_multiprocessing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>mindspore_gl.sampling.sage_sampler_on_homo provides a k-hop sampling method. In the list of <code class="docutils literal notranslate"><span class="pre">self.neighbor_nums</span></code>, the number of sampling nodes from the central node to the outside when sampling.
Since the degree of each point is different, the size of the array after k-hop sampling is also different. Discretize the sampling results into 5 fixed values through the API of mindspore_gl.graph.PadArray2d.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_gl.dataloader.dataset</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">mindspore_gl.sampling.neighbor</span> <span class="kn">import</span> <span class="n">sage_sampler_on_homo</span>

<span class="k">class</span> <span class="nc">GraphSAGEDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Do sampling from neighbour nodes&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_dataset</span><span class="p">,</span> <span class="n">neighbor_nums</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">single_size</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">graph_dataset</span> <span class="o">=</span> <span class="n">graph_dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">graph_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_nums</span> <span class="o">=</span> <span class="n">neighbor_nums</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">graph_dataset</span><span class="o">.</span><span class="n">node_feat</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">graph_dataset</span><span class="o">.</span><span class="n">node_label</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_sampled_nodes_num</span> <span class="o">=</span> <span class="n">neighbor_nums</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">neighbor_nums</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">single_size</span> <span class="o">=</span> <span class="n">single_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length</span> <span class="o">=</span> <span class="n">length</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_nodes</span><span class="p">):</span>
        <span class="n">batch_nodes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">batch_nodes</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">sage_sampler_on_homo</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">batch_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_nums</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">array_kernel</span><span class="o">.</span><span class="n">int_1d_array_slicing</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">batch_nodes</span><span class="p">)</span>
        <span class="n">layered_edges_0</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;layered_edges_0&#39;</span><span class="p">]</span>
        <span class="n">layered_edges_1</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;layered_edges_1&#39;</span><span class="p">]</span>
        <span class="n">sample_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">layered_edges_0</span><span class="p">,</span> <span class="n">layered_edges_1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">sample_edges</span> <span class="o">=</span> <span class="n">sample_edges</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">:]</span>
        <span class="n">num_sample_edges</span> <span class="o">=</span> <span class="n">sample_edges</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">num_sample_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;all_nodes&#39;</span><span class="p">])</span>
        <span class="n">max_sampled_nodes_num</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_sampled_nodes_num</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">single_size</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">num_sample_nodes</span> <span class="o">&lt;</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.2</span><span class="o">*</span><span class="n">max_sampled_nodes_num</span><span class="p">):</span>
                <span class="n">pad_node_num</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.2</span><span class="o">*</span><span class="n">max_sampled_nodes_num</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">num_sample_nodes</span> <span class="o">&lt;</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.4</span><span class="o">*</span><span class="n">max_sampled_nodes_num</span><span class="p">):</span>
                <span class="n">pad_node_num</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.4</span> <span class="o">*</span> <span class="n">max_sampled_nodes_num</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">num_sample_nodes</span> <span class="o">&lt;</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.6</span><span class="o">*</span><span class="n">max_sampled_nodes_num</span><span class="p">):</span>
                <span class="n">pad_node_num</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.6</span> <span class="o">*</span> <span class="n">max_sampled_nodes_num</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">num_sample_nodes</span> <span class="o">&lt;</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.8</span><span class="o">*</span><span class="n">max_sampled_nodes_num</span><span class="p">):</span>
                <span class="n">pad_node_num</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="n">max_sampled_nodes_num</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pad_node_num</span> <span class="o">=</span> <span class="n">max_sampled_nodes_num</span>

            <span class="k">if</span> <span class="n">num_sample_edges</span> <span class="o">&lt;</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.2</span><span class="o">*</span><span class="n">max_sampled_nodes_num</span><span class="p">):</span>
                <span class="n">pad_edge_num</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.2</span><span class="o">*</span><span class="n">max_sampled_nodes_num</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">num_sample_edges</span> <span class="o">&lt;</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.4</span><span class="o">*</span><span class="n">max_sampled_nodes_num</span><span class="p">):</span>
                <span class="n">pad_edge_num</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.4</span> <span class="o">*</span> <span class="n">max_sampled_nodes_num</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">num_sample_edges</span> <span class="o">&lt;</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.6</span><span class="o">*</span><span class="n">max_sampled_nodes_num</span><span class="p">):</span>
                <span class="n">pad_edge_num</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.6</span> <span class="o">*</span> <span class="n">max_sampled_nodes_num</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">num_sample_edges</span> <span class="o">&lt;</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.8</span><span class="o">*</span><span class="n">max_sampled_nodes_num</span><span class="p">):</span>
                <span class="n">pad_edge_num</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="n">max_sampled_nodes_num</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pad_edge_num</span> <span class="o">=</span> <span class="n">max_sampled_nodes_num</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">pad_node_num</span> <span class="o">=</span> <span class="n">max_sampled_nodes_num</span>
            <span class="n">pad_edge_num</span> <span class="o">=</span> <span class="n">max_sampled_nodes_num</span>

        <span class="n">layered_edges_pad_op</span> <span class="o">=</span> <span class="n">PadArray2d</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">CONST</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">pad_edge_num</span><span class="p">],</span>
                                          <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="n">PadDirection</span><span class="o">.</span><span class="n">ROW</span><span class="p">,</span>
                                          <span class="n">fill_value</span><span class="o">=</span><span class="n">pad_node_num</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                                          <span class="p">)</span>
        <span class="n">nid_feat_pad_op</span> <span class="o">=</span> <span class="n">PadArray2d</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">CONST</span><span class="p">,</span>
                                     <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">pad_node_num</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_dataset</span><span class="o">.</span><span class="n">node_feat_size</span><span class="p">],</span>
                                     <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph_dataset</span><span class="o">.</span><span class="n">node_feat</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                                     <span class="n">direction</span><span class="o">=</span><span class="n">PadDirection</span><span class="o">.</span><span class="n">COL</span><span class="p">,</span>
                                     <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                     <span class="n">reset_with_fill_value</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                     <span class="n">use_shared_numpy</span><span class="o">=</span><span class="kc">True</span>
                                     <span class="p">)</span>
        <span class="n">sample_edges</span> <span class="o">=</span> <span class="n">sample_edges</span><span class="p">[:,</span> <span class="p">:</span><span class="n">pad_edge_num</span><span class="p">]</span>
        <span class="n">pad_sample_edges</span> <span class="o">=</span> <span class="n">layered_edges_pad_op</span><span class="p">(</span><span class="n">sample_edges</span><span class="p">)</span>
        <span class="n">feat</span> <span class="o">=</span> <span class="n">nid_feat_pad_op</span><span class="o">.</span><span class="n">lazy</span><span class="p">([</span><span class="n">num_sample_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_dataset</span><span class="o">.</span><span class="n">node_feat_size</span><span class="p">])</span>
        <span class="n">array_kernel</span><span class="o">.</span><span class="n">float_2d_gather_with_dst</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_dataset</span><span class="o">.</span><span class="n">node_feat</span><span class="p">,</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;all_nodes&#39;</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;seeds_idx&#39;</span><span class="p">],</span> <span class="n">label</span><span class="p">,</span> <span class="n">feat</span><span class="p">,</span> <span class="n">pad_sample_edges</span>
</pre></div>
</div>
</section>
<section id="network-training-and-validation">
<h2>Network Training and Validation<a class="headerlink" href="#network-training-and-validation" title="Permalink to this headline"></a></h2>
<section id="setting-environment-variables">
<h3>Setting Environment Variables<a class="headerlink" href="#setting-environment-variables" title="Permalink to this headline"></a></h3>
<p>During distributed training, data is imported in data parallel mode. At the end of each training step, each process unifies the model parameters. On Ascend it must be ensured that the data shape is the same in each process.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device_target</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;DEVICE_TARGET&#39;</span><span class="p">))</span>
<span class="k">if</span> <span class="n">device_target</span> <span class="o">==</span> <span class="s1">&#39;Ascend&#39;</span><span class="p">:</span>
    <span class="n">device_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;DEVICE_ID&#39;</span><span class="p">))</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_id</span><span class="o">=</span><span class="n">device_id</span><span class="p">)</span>
    <span class="n">single_size</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">init</span><span class="p">()</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">init</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>
    <span class="n">single_size</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>Graph Operator compilation optimization settings is similar to that of <a class="reference external" href="https://www.mindspore.cn/graphlearning/docs/en/master/full_training_of_GCN.html#setting-environment-variables">GCN</a>.</p>
</section>
<section id="defining-a-training-network">
<h3>Defining a Training Network<a class="headerlink" href="#defining-a-training-network" title="Permalink to this headline"></a></h3>
<p>Instantiation of the model body SAGENet and LossNet and optimizer.
The implementation method is similar to that of the <a class="reference external" href="https://www.mindspore.cn/graphlearning/docs/en/master/full_training_of_GCN.html#defining-a-training-network">GCN</a>.</p>
</section>
<section id="network-training-and-validation-1">
<h3>Network Training and Validation<a class="headerlink" href="#network-training-and-validation-1" title="Permalink to this headline"></a></h3>
<p>For the training and validation methods, refer to <a class="reference external" href="https://www.mindspore.cn/graphlearning/docs/en/master/full_training_of_GCN.html#network-training-and-validation-1">GCN</a>.</p>
</section>
</section>
<section id="executing-jobs-and-viewing-results">
<h2>Executing Jobs and Viewing Results<a class="headerlink" href="#executing-jobs-and-viewing-results" title="Permalink to this headline"></a></h2>
<section id="running-process">
<h3>Running Process<a class="headerlink" href="#running-process" title="Permalink to this headline"></a></h3>
<p>After running the program, translate the code and start training.</p>
</section>
<section id="execution-results">
<h3>Execution Results<a class="headerlink" href="#execution-results" title="Permalink to this headline"></a></h3>
<p>Run the <a class="reference external" href="https://gitee.com/mindspore/graphlearning/blob/master/model_zoo/graphsage/distributed_run.sh">distributed_run.sh</a> script to start training.</p>
<ul>
<li><p>GPU</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>model_zoo/graphsage
bash<span class="w"> </span>distributed_run.sh<span class="w"> </span>GPU<span class="w"> </span>DATA_PATH
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">{DATA_PATH}</span></code> indicates the dataset storage path.</p>
</li>
<li><p>Ascend</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>model_zoo/graphsage
bash<span class="w"> </span>bash<span class="w"> </span>distributed_run.sh<span class="w"> </span>Ascend<span class="w"> </span>DATA_PATH<span class="w"> </span>RANK_START<span class="w"> </span>RANK_SIZE<span class="w"> </span>RANK_TABLE_FILE
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">{DATA_PATH}</span></code> indicates the dataset storage path. {ANK_START} is the first Ascend device id be used. <code class="docutils literal notranslate"><span class="pre">{RANK_SIZE}</span></code> is numbers of Ascend device be used. <code class="docutils literal notranslate"><span class="pre">{RANK_TABLE_FILE}</span></code> is root path of ‘rank_table_*pcs.json’ file.</p>
</li>
</ul>
<p>The training result is as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>...
Iteration/Epoch:<span class="w"> </span><span class="m">30</span>:4<span class="w"> </span>train<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.41629112
Iteration/Epoch:<span class="w"> </span><span class="m">30</span>:4<span class="w"> </span>train<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.5337528
Iteration/Epoch:<span class="w"> </span><span class="m">30</span>:4<span class="w"> </span>train<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.42849028
Iteration/Epoch:<span class="w"> </span><span class="m">30</span>:4<span class="w"> </span>train<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.5358513
rank_id:3<span class="w"> </span>Epoch/Time:<span class="w"> </span><span class="m">4</span>:76.17579555511475
rank_id:1<span class="w"> </span>Epoch/Time:<span class="w"> </span><span class="m">4</span>:37.79207944869995
rank_id:2<span class="w"> </span>Epoch/Time:<span class="w"> </span><span class="m">4</span>:76.04292225837708
rank_id:0<span class="w"> </span>Epoch/Time:<span class="w"> </span><span class="m">4</span>:75.64319372177124
rank_id:2<span class="w"> </span><span class="nb">test</span><span class="w"> </span>accuracy<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.9276439525462963
rank_id:0<span class="w"> </span><span class="nb">test</span><span class="w"> </span>accuracy<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.9305013020833334
rank_id:3<span class="w"> </span><span class="nb">test</span><span class="w"> </span>accuracy<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.9290907118055556
rank_id:1<span class="w"> </span><span class="nb">test</span><span class="w"> </span>accuracy<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.9279513888888888
</pre></div>
</div>
<p>Accuracy verified on Reddit: 0.92.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="spatio_temporal_graph_training_STGCN.html" class="btn btn-neutral float-left" title="Spatio-Temporal Graph Training Network" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindspore_gl.html" class="btn btn-neutral float-right" title="mindspore_gl" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>