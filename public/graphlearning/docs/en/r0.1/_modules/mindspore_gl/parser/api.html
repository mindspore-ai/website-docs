<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore_gl.parser.api &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script><script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/js/theme.js"></script><script src="../../../_static/underscore.js"></script><script src="../../../_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore_graphlearning_install.html">Install Graph Learning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../full_training_of_gcn.html">Entire Graph Training Using Graph Convolutional Network (GCN)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore_gl.dataset.html">mindspore_gl.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore_gl.nn.html">mindspore_gl.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore_gl.parser.html">mindspore_gl.parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore_gl.sampling.html">mindspore_gl.sampling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../faq.html">FAQ</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>mindspore_gl.parser.api</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for mindspore_gl.parser.api</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2022 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ============================================================================</span>
<span class="sd">&quot;&quot;&quot;API&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>


<span class="k">class</span> <span class="nc">SrcVertex</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Source Vertex&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;SrcVertex Init: not implemented!&quot;</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">DstVertex</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Destination Vertex&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">innb</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_innbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">innb</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_edges</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">innbs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return a list of src_vertex of current vertex.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; for v in g.dst_vertex:</span>
<span class="sd">            ...     v.h = g.sum([u.h for u in v.innbs])</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_innbs</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">inedges</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return a list of (src, edge) tuples for current vertex.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; for v in g.dst_vertex:</span>
<span class="sd">            ...     [u.a + e.b for u,e in v.inedges]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_edges</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_edges</span>


<span class="k">class</span> <span class="nc">Edge</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Edge&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">):</span>
        <span class="n">dst</span><span class="o">.</span><span class="n">in_edges</span> <span class="o">=</span> <span class="p">[(</span><span class="n">src</span><span class="p">,</span> <span class="bp">self</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_src</span> <span class="o">=</span> <span class="n">src</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dst</span> <span class="o">=</span> <span class="n">dst</span>


<div class="viewcode-block" id="Graph"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.Graph">[docs]</a><span class="k">class</span> <span class="nc">Graph</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Graph class.</span>

<span class="sd">    This is the class which should be annotated in \</span>
<span class="sd">        construct function for GNNCell class.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_src_vertex</span> <span class="o">=</span> <span class="n">SrcVertex</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dst_vertex</span> <span class="o">=</span> <span class="p">[</span><span class="n">DstVertex</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_src_vertex</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_edge</span> <span class="o">=</span> <span class="p">[</span><span class="n">Edge</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_src_vertex</span><span class="p">,</span> <span class="n">dst_v</span><span class="p">)</span>
                      <span class="k">for</span> <span class="n">dst_v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dst_vertex</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dst_vertex</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return a list of destination vertex that only supports\</span>
<span class="sd">             iterate its innbs.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; for v in g.dst_vertex:</span>
<span class="sd">            ...     pass</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dst_vertex</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">src_vertex</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return a list of vertex that only supports iterate with its outnbs</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; for u in g.src_vertex:</span>
<span class="sd">            ...     pass</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_src_vertex</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">src_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A tensor with shape :math:`(N\_EDGES)`, represents the source node \</span>
<span class="sd">            index of COO edge matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dst_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A tensor with shape :math:`(N\_EDGES)`, represents the destination \</span>
<span class="sd">             node index of COO edge matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        An integer, represent the nodes count of the graph.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        An integer, represent the edges count of the graph.</span>
<span class="sd">        &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Graph.set_vertex_attr"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.Graph.set_vertex_attr">[docs]</a>    <span class="k">def</span> <span class="nf">set_vertex_attr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat_dict</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set attributes for vertices in vertex-centric environment.</span>
<span class="sd">        Keys will be attribute&#39;s name, values will be attributes&#39; data.</span>

<span class="sd">        Note:</span>
<span class="sd">            set_vertex_attr is equals to set_src_attr + set_dst_attr.</span>

<span class="sd">        Args:</span>
<span class="sd">            feat_dict (Dict): key type: str, value type: recommend tensor of \</span>
<span class="sd">                shape :math:`(N\_NODES, F)`, :math:`F` is the dimension of the node feature.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `feat_dict` is not a Dict.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import Graph, GraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_field = GraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([[1], [2], [1], [2], [0], [1], [2], [3], [1]], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestSetVertexAttr(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, g: Graph):</span>
<span class="sd">            ...         g.set_vertex_attr({&quot;h&quot;: x})</span>
<span class="sd">            ...         return [v.h for v in g.dst_vertex] * [u.h for u in g.src_vertex]</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestSetVertexAttr()(node_feat, *graph_field.get_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[1.0], [4.0], [1.0], [4.0], [0.0], [1.0], [4.0], [9.0], [1.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Graph.set_src_attr"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.Graph.set_src_attr">[docs]</a>    <span class="k">def</span> <span class="nf">set_src_attr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat_dict</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set attributes for source vertices in vertex-centric environment.</span>
<span class="sd">        Keys will be attribute&#39;s name, values will be attributes&#39; data.</span>

<span class="sd">        Args:</span>
<span class="sd">            feat_dict (Dict): key type: str, value type: recommend tensor of</span>
<span class="sd">                shape :math:`(N\_NODES, F)`, :math:`F` is the dimension of the node feature.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `feat_dict` is not a Dict.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import Graph, GraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_field = GraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([[1], [2], [1], [2], [0], [1], [2], [3], [1]], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestSetSrcAttr(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, g: Graph):</span>
<span class="sd">            ...         g.set_src_attr({&quot;h&quot;: x})</span>
<span class="sd">            ...         return [u.h for u in g.src_vertex]</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestSetSrcAttr()(node_feat, *graph_field.get_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[1.0], [2.0], [1.0], [2.0], [0.0], [1.0], [2.0], [3.0], [1.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Graph.set_dst_attr"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.Graph.set_dst_attr">[docs]</a>    <span class="k">def</span> <span class="nf">set_dst_attr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat_dict</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set attributes for destination vetices in vertex-centric environment</span>
<span class="sd">        Keys will be attribute&#39;s name, values will be attributes&#39; data.</span>

<span class="sd">        Args:</span>
<span class="sd">            feat_dict (Dict): key type: str, value type: recommend tensor of</span>
<span class="sd">                shape :math:`(N\_NODES, F)`, :math:`F` is the dimension of the node feature.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `feat_dict` is not a Dict.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import Graph, GraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_field = GraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([[1], [2], [1], [2], [0], [1], [2], [3], [1]], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestSetDstAttr(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, g: Graph):</span>
<span class="sd">            ...         g.set_dst_attr({&quot;h&quot;: x})</span>
<span class="sd">            ...         return [v.h for v in g.dst_vertex]</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestSetDstAttr()(node_feat, *graph_field.get_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[1.0], [2.0], [1.0], [2.0], [0.0], [1.0], [2.0], [3.0], [1.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Graph.set_edge_attr"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.Graph.set_edge_attr">[docs]</a>    <span class="k">def</span> <span class="nf">set_edge_attr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat_dict</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set attributes for edges in vertex-centric environment.</span>
<span class="sd">        Keys will be attribute&#39;s name, values will be attributes&#39; data.</span>

<span class="sd">        Args:</span>
<span class="sd">            feat_dict (Dict): key type: str, value type: recommend feature tensor</span>
<span class="sd">                of shape :math:`(N\_EDGES, F)`, :math:`F` is the dimension of the edge feature.</span>
<span class="sd">                Recommend the shape of value is :math:`(N\_EDGES, 1)` when the feature dimension is 1.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `feat_dict` is not a Dict.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import Graph, GraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_field = GraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([[1], [2], [1], [2], [0], [1], [2], [3], [1]], ms.float32)</span>
<span class="sd">            &gt;&gt;&gt; edge_feat = ms.Tensor([[1], [2], [1], [3], [1], [4], [1], [5], [1], [1], [1]], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestSetEdgeAttr(GNNCell):</span>
<span class="sd">            ...     def construct(self, nh, eh, g: Graph):</span>
<span class="sd">            ...         g.set_vertex_attr({&quot;nh&quot;: nh})</span>
<span class="sd">            ...         g.set_edge_attr({&quot;eh&quot;: eh})</span>
<span class="sd">            ...         for v in g.dst_vertex:</span>
<span class="sd">            ...             v.h = g.sum([u.nh * e.eh for u, e in v.inedges])</span>
<span class="sd">            ...         return [v.h for v in g.dst_vertex]</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestSetEdgeAttr()(node_feat, edge_feat, *graph_field.get_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[2.0], [2.0], [0.0], [0.0], [14.0], [6.0], [1.0], [0.0], [3.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Graph.set_graph_attr"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.Graph.set_graph_attr">[docs]</a>    <span class="k">def</span> <span class="nf">set_graph_attr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat_dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set attributes for the whole graph in vertex-centric environment.</span>
<span class="sd">        Keys will be attribute&#39;s name, values will be attributes&#39; data.</span>

<span class="sd">        Args:</span>
<span class="sd">            feat_dict (Dict): key type: str, value type: recommend feature tensor</span>
<span class="sd">                for the whole graph.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `feat_dict` is not a Dict.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import Graph, GraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_field = GraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">            &gt;&gt;&gt; g_attr = ms.Tensor([[0.0, 1.0], [0.0, 1.0], [0.0, 1.0]], ms.float32)</span>
<span class="sd">            &gt;&gt;&gt; v_attr = ms.Tensor([1.0, 1.0], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestSetGraphAttr(GNNCell):</span>
<span class="sd">            ...     def construct(self, vh, gh, g: Graph):</span>
<span class="sd">            ...         g.set_graph_attr({&quot;x&quot;: gh})</span>
<span class="sd">            ...         g.set_vertex_attr({&quot;h&quot;: vh})</span>
<span class="sd">            ...         for v in g.dst_vertex:</span>
<span class="sd">            ...             v.h = g.sum([u.h * g.x for u in v.innbs])</span>
<span class="sd">            ...         return [v.h for v in g.dst_vertex]</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestSetGraphAttr()(v_attr, g_attr, *graph_field.get_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[0.0, 1.0], [0.0, 2.0], [0.0, 0.0], [0.0, 0.0],</span>
<span class="sd">                 [0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Graph.sum"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.Graph.sum">[docs]</a>    <span class="k">def</span> <span class="nf">sum</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neigh_feat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Aggregating node features from their neighbour and generates a</span>
<span class="sd">        node-level representation by aggregate function &#39;sum&#39;.</span>

<span class="sd">        Args:</span>
<span class="sd">            neigh_feat (List[`SrcVertex` feature or `Edge` feature]): a list of `SrcVertex` or `Edge` attribute</span>
<span class="sd">                represents the neighbour nodes or edges feature, with shape :math:`(N, F)`,</span>
<span class="sd">                :math:`N` is the number of `SrcVertex` or `Edge`,</span>
<span class="sd">                :math:`F` is the feature dimension of the `SrcVertex` or `Edge` attribute.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N, F)`, :math:`N` is the number of nodes of the graph,</span>
<span class="sd">            :math:`F` is the feature dimension of the node.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `neigh_feat` is not a list of `Edge` or `SrcVertex`.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import Graph, GraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_field = GraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([[1], [2], [1], [2], [0], [1], [2], [3], [1]], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestSum(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, g: Graph):</span>
<span class="sd">            ...         g.set_vertex_attr({&quot;x&quot;: x})</span>
<span class="sd">            ...         for v in g.dst_vertex:</span>
<span class="sd">            ...             v.h = g.sum([u.x for u in v.innbs])</span>
<span class="sd">            ...         return [v.h for v in g.dst_vertex]</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestSum()(node_feat, *graph_field.get_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[1.0], [2.0], [0.0], [0.0], [3.0], [2.0], [1.0], [0.0], [3.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Graph.max"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.Graph.max">[docs]</a>    <span class="k">def</span> <span class="nf">max</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neigh_feat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Aggregating node features from their neighbour and generates</span>
<span class="sd">        a node-level representation by aggregate function &#39;max&#39;.</span>

<span class="sd">        Args:</span>
<span class="sd">            neigh_feat (List[`SrcVertex` feature or `Edge` feature]): a list of `SrcVertex` or `Edge` attributes</span>
<span class="sd">                represents the neighbour nodes or edges feature, with shape :math:`(N, F)`,</span>
<span class="sd">                :math:`N` is the number of `SrcVertex` or `Edge`,</span>
<span class="sd">                :math:`F` is the feature dimension of the `SrcVertex` or `Edge` attribute.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N, F)`, :math:`N` is the number of nodes of the graph,</span>
<span class="sd">            :math:`F` is the feature dimension of the node.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `neigh_feat` is not a list of `Edge` or `SrcVertex`.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import Graph, GraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_field = GraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([[1], [2], [1], [2], [0], [1], [2], [3], [1]], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestMax(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, g: Graph):</span>
<span class="sd">            ...         g.set_vertex_attr({&quot;x&quot;: x})</span>
<span class="sd">            ...         for v in g.dst_vertex:</span>
<span class="sd">            ...             v.h = g.max([u.x for u in v.innbs])</span>
<span class="sd">            ...         return [v.h for v in g.dst_vertex]</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestMax()(node_feat, *graph_field.get_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[1.0], [1.0], [0.0], [0.0], [2.0], [2.0], [1.0], [0.0], [1.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Graph.min"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.Graph.min">[docs]</a>    <span class="k">def</span> <span class="nf">min</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neigh_feat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Aggregating node features from their neighbour and generates</span>
<span class="sd">        a node-level representation by aggregate function &#39;min&#39;.</span>

<span class="sd">        Args:</span>
<span class="sd">            neigh_feat (List[`SrcVertex` feature or `Edge` feature]): a list of `SrcVertex` or `Edge` attributes</span>
<span class="sd">                represents the neighbour nodes or edges feature, with shape :math:`(N, F)`,</span>
<span class="sd">                :math:`N` is the number of `SrcVertex` or `Edge`,</span>
<span class="sd">                :math:`F` is the feature dimension of the `SrcVertex` or `Edge` attribute.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N, F)`, :math:`N` is the number of nodes of the graph,</span>
<span class="sd">            :math:`F` is the feature dimension of the node.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `neigh_feat` is not a list of `Edge` or `SrcVertex`.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import Graph, GraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_field = GraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([[1], [2], [1], [2], [0], [1], [2], [3], [1]], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestMin(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, g: Graph):</span>
<span class="sd">            ...         g.set_vertex_attr({&quot;x&quot;: x})</span>
<span class="sd">            ...         for v in g.dst_vertex:</span>
<span class="sd">            ...             v.h = g.min([u.x for u in v.innbs])</span>
<span class="sd">            ...         return [v.h for v in g.dst_vertex]</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestMin()(node_feat, *graph_field.get_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Graph.avg"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.Graph.avg">[docs]</a>    <span class="k">def</span> <span class="nf">avg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neigh_feat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Aggregating node features from their neighbour and generates a</span>
<span class="sd">        node-level representation by aggregate function &#39;avg&#39;.</span>

<span class="sd">        Args:</span>
<span class="sd">            neigh_feat (List[`SrcVertex` feature or `Edge` feature]): a list of `SrcVertex` or `Edge` attributes</span>
<span class="sd">                represents the neighbour nodes or edges feature, with shape :math:`(N, F)`,</span>
<span class="sd">                :math:`N` is the number of `SrcVertex` or `Edge`,</span>
<span class="sd">                :math:`F` is the feature dimension of the `SrcVertex` or `Edge` attribute.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N, F)`, :math:`N` is the number of nodes of the graph,</span>
<span class="sd">            :math:`F` is the feature dimension of the node.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `neigh_feat` is not a list of `Edge` or `SrcVertex`.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import math</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import Graph, GraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_field = GraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([[1], [2], [1], [2], [0], [1], [2], [3], [1]], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestAvg(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, g: Graph):</span>
<span class="sd">            ...         g.set_vertex_attr({&quot;x&quot;: x})</span>
<span class="sd">            ...         for v in g.dst_vertex:</span>
<span class="sd">            ...             v.h = g.avg([u.x for u in v.innbs])</span>
<span class="sd">            ...         return [v.h for v in g.dst_vertex]</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestAvg()(node_feat, *graph_field.get_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; NAN = 1e9</span>
<span class="sd">            &gt;&gt;&gt; for row in ret:</span>
<span class="sd">            ...     if math.isnan(row[0]):</span>
<span class="sd">            ...         row[0] = NAN</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[1.0], [1.0], [1000000000.0], [0.0], [1.5], [2.0], [1.0], [1000000000.0], [1.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Graph.dot"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.Graph.dot">[docs]</a>    <span class="k">def</span> <span class="nf">dot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat_x</span><span class="p">,</span> <span class="n">feat_y</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Dot mul operation for two node Tensors.</span>

<span class="sd">        Args:</span>
<span class="sd">            feat_x (`SrcVertex` feature or `DstVertex` feature): the arttribute of `SrcVertex` or `DstVertex`</span>
<span class="sd">                represent feature tensor of graph nodes with shape :math:`(N, F)`,</span>
<span class="sd">                :math:`N` is the number of nodes of the graph,</span>
<span class="sd">                :math:`F` is the feature dimension of the node.</span>
<span class="sd">            feat_y (`SrcVertex` feature or `DstVertex` feature): the arttribute of `SrcVertex` or `DstVertex`</span>
<span class="sd">                represent feature tensor of graph nodes with shape :math:`(N, F)`,</span>
<span class="sd">                :math:`N` is the number of nodes of the graph,</span>
<span class="sd">                :math:`F` is the feature dimension of the node.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N, 1)`, :math:`N` is the number of nodes of the graph.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `feat_x` is not in the &#39;mul&#39; operation support types [Tensor,Number,List,Tuple].</span>
<span class="sd">            TypeError: If `feat_y` is not in the &#39;mul&#39; operation support types [Tensor,Number,List,Tuple].</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import Graph, GraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_field = GraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([[1], [2], [1], [2], [0], [1], [2], [3], [1]], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestDot(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, g: Graph):</span>
<span class="sd">            ...         g.set_vertex_attr({&quot;src&quot;: x, &quot;dst&quot;: x})</span>
<span class="sd">            ...         for v in g.dst_vertex:</span>
<span class="sd">            ...             v.h = [g.dot(v.src, u.dst) for u in v.innbs]</span>
<span class="sd">            ...         return [v.h for v in g.dst_vertex]</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestDot()(node_feat, *graph_field.get_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[2.0], [1.0], [2.0], [2.0], [0.0], [0.0], [2.0], [0.0], [1.0], [1.0], [1.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Graph.in_degree"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.Graph.in_degree">[docs]</a>    <span class="k">def</span> <span class="nf">in_degree</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the in degree of each node in a graph.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N, 1)`,</span>
<span class="sd">            represent the in degree of each node, :math:`N` is the number of nodes of the graph.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import Graph, GraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_field = GraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestInDegree(GNNCell):</span>
<span class="sd">            ...     def construct(self, g: Graph):</span>
<span class="sd">            ...         return g.in_degree()</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestInDegree()(*graph_field.get_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[1], [2], [0], [1], [2], [1], [1], [0], [3]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Graph.out_degree"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.Graph.out_degree">[docs]</a>    <span class="k">def</span> <span class="nf">out_degree</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the out degree of each node in a graph.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N, 1)`,</span>
<span class="sd">            represent the out degree of each node, :math:`N` is the number of nodes of the graph.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import Graph, GraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_field = GraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestOutDegree(GNNCell):</span>
<span class="sd">            ...     def construct(self, g: Graph):</span>
<span class="sd">            ...         return g.out_degree()</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestOutDegree()(*graph_field.get_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[1], [0], [2], [1], [1], [2], [1], [0], [3]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Graph.adj_to_dense"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.Graph.adj_to_dense">[docs]</a>    <span class="k">def</span> <span class="nf">adj_to_dense</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the dense adjacent matrix of the graph.</span>

<span class="sd">        Note:</span>
<span class="sd">            You must set vertex attr first due to the current</span>
<span class="sd">            limits of our system.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N, N)`, :math:`N` is the number of nodes of the graph.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import Graph, GraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_field = GraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestAdjToDense(GNNCell):</span>
<span class="sd">            ...     def construct(self, g: Graph):</span>
<span class="sd">            ...         return g.adj_to_dense()</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestAdjToDense()(*graph_field.get_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[0, 1, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 1, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 1, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 1, 0, 1, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 1, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0, 0, 0, 3]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div></div>


<div class="viewcode-block" id="BatchedGraph"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph">[docs]</a><span class="k">class</span> <span class="nc">BatchedGraph</span><span class="p">(</span><span class="n">Graph</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Batched Graph class.</span>

<span class="sd">    This is the class which should be annotated in</span>
<span class="sd">    construct function for GNNCell class.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">ver_subgraph_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A tensor with shape :math:`(N)`, indicates each node belonging</span>
<span class="sd">        to which subgraph, :math:`N` is the number of the nodes of the graph.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">edge_subgraph_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A tensor with shape :math:`(N\_EDGES,)`, indicates each edge belonging to which subgraph.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">graph_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A tensor with shape :math:`(N\_GRAPHS,)`, indicates whether the subgraph is exist.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_graphs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        An integer, represent the graphs count of the batched graph.</span>
<span class="sd">        &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BatchedGraph.node_mask"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.node_mask">[docs]</a>    <span class="k">def</span> <span class="nf">node_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the node mask after padding.</span>

<span class="sd">        The node mask is calculated according to the graph_mask and</span>
<span class="sd">        ver_subgraph_idx.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N\_NODES, )`. Inside tensor, 1 represent the node exists and</span>
<span class="sd">            0 represent the node is generated by padding.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 2, 2], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1, 0], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestNodeMask(GNNCell):</span>
<span class="sd">            ...     def construct(self, bg: BatchedGraph):</span>
<span class="sd">            ...         return bg.node_mask()</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestNodeMask()(*batched_graph_field.get_batched_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [1, 1, 1, 1, 1, 1, 1, 0, 0]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BatchedGraph.edge_mask"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.edge_mask">[docs]</a>    <span class="k">def</span> <span class="nf">edge_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the edge mask after padding.</span>

<span class="sd">        The edge mask is calculated according to the graph_mask and</span>
<span class="sd">        ver_subgraph_idx.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N\_EDGES,)`.</span>
<span class="sd">            Inside tensor, 1 represent the edge exists and 0 represent the edge is generated by padding.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 2, 2], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1, 0], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestEdgeMask(GNNCell):</span>
<span class="sd">            ...     def construct(self, bg: BatchedGraph):</span>
<span class="sd">            ...         return bg.edge_mask()</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestEdgeMask()(*batched_graph_field.get_batched_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BatchedGraph.num_of_nodes"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.num_of_nodes">[docs]</a>    <span class="k">def</span> <span class="nf">num_of_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the number of nodes of each subgraph in a batched graph.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N\_GRAPHS, 1)` represent each subgraph contains how many nodes.</span>

<span class="sd">        Note:</span>
<span class="sd">            After padding operation, a not existing subgraph is created</span>
<span class="sd">            and all not existing nodes created belong to this subgraph.</span>
<span class="sd">            If you want to clear it, you need to multiply it</span>
<span class="sd">            with a graph mask manually.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 2, 2], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1, 0], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestNumOfNodes(GNNCell):</span>
<span class="sd">            ...     def construct(self, bg: BatchedGraph):</span>
<span class="sd">            ...         return bg.num_of_nodes()</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestNumOfNodes()(*batched_graph_field.get_batched_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[3], [4], [2]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BatchedGraph.num_of_edges"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.num_of_edges">[docs]</a>    <span class="k">def</span> <span class="nf">num_of_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the number of edges of each subgraph in a batched graph.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N\_GRAPHS, 1)`,</span>
<span class="sd">            represent each subgraph contains how many edges.</span>

<span class="sd">        Note:</span>
<span class="sd">            After padding operation, a not existing subgraph is created</span>
<span class="sd">            and all not existing edges created belong to this subgraph.</span>
<span class="sd">            If you want to clear it, you need to multiply it</span>
<span class="sd">            with a graph mask manually.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 2, 2], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1, 0], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestNumOfEdges(GNNCell):</span>
<span class="sd">            ...     def construct(self, bg: BatchedGraph):</span>
<span class="sd">            ...         return bg.num_of_edges()</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestNumOfEdges()(*batched_graph_field.get_batched_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[3], [5], [3]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BatchedGraph.sum_nodes"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.sum_nodes">[docs]</a>    <span class="k">def</span> <span class="nf">sum_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_feat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Aggregating node features and generates a graph-level representation</span>
<span class="sd">        by aggregation type &#39;sum&#39;.</span>

<span class="sd">        The node_feat should have shape :math:`(N\_NODES, F)`,</span>
<span class="sd">        Sum_nodes operation will aggregate the nodes</span>
<span class="sd">        feat according to ver_subgraph_idx.</span>
<span class="sd">        The output tensor will have a shape :math:`(N\_GRAPHS, F)`.</span>
<span class="sd">        :math:`F` is the dimension of the node feature.</span>

<span class="sd">        Args:</span>
<span class="sd">            node_feat (Tensor): a tensor represents the node feature,</span>
<span class="sd">                with shape :math:`(N\_NODES, F)`, :math:`F` is the dimension of the node node feature.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N\_GRAPHS, F)`, :math:`F` is the dimension of the node feature.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `node_feat` is not a Tensor which is the type of operation &#39;shape&#39;.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([</span>
<span class="sd">            ...     # graph 1:</span>
<span class="sd">            ...     [1, 2, 3, 4],</span>
<span class="sd">            ...     [2, 4, 1, 3],</span>
<span class="sd">            ...     [1, 3, 2, 4],</span>
<span class="sd">            ...     # graph 2:</span>
<span class="sd">            ...     [9, 7, 5, 8],</span>
<span class="sd">            ...     [8, 7, 6, 5],</span>
<span class="sd">            ...     [8, 6, 4, 6],</span>
<span class="sd">            ...     [1, 2, 1, 1],</span>
<span class="sd">            ... ], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 7</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 8</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestSumNodes(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, bg: BatchedGraph):</span>
<span class="sd">            ...         return bg.sum_nodes(x)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestSumNodes()(node_feat, *batched_graph_field.get_batched_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[4.0, 9.0, 6.0, 11.0], [26.0, 22.0, 16.0, 20.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BatchedGraph.sum_edges"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.sum_edges">[docs]</a>    <span class="k">def</span> <span class="nf">sum_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge_feat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Aggregating edge features and generates a graph-level representation</span>
<span class="sd">        by aggregation type &#39;sum&#39;.</span>

<span class="sd">        The edge_feat should have shape :math:`(N\_EDGES, F)`.</span>
<span class="sd">        Sum_edges operation will aggregate the edge_feat.</span>
<span class="sd">        according to edge_subgraph_idx.</span>
<span class="sd">        The output tensor will have a shape :math:`(N\_GRAPHS, F)`.</span>
<span class="sd">        :math:`F` is the dimension of the edge feature.</span>

<span class="sd">        Args:</span>
<span class="sd">            edge_feat (Tensor): a tensor represents the edge feature,</span>
<span class="sd">                with shape :math:`(N\_EDGES, F)`. :math:`F` is the dimension of the edge attribute.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N\_GRAPHS, F)`. :math:`F` is the dimension of the edge attribute.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `edge_feat` is not a Tensor which is the type of operation &#39;shape&#39;.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; edge_feat = ms.Tensor([</span>
<span class="sd">            ...     # graph 1:</span>
<span class="sd">            ...     [1, 2, 3, 4],</span>
<span class="sd">            ...     [2, 4, 1, 3],</span>
<span class="sd">            ...     [1, 3, 2, 4],</span>
<span class="sd">            ...     # graph 2:</span>
<span class="sd">            ...     [9, 7, 5, 8],</span>
<span class="sd">            ...     [8, 7, 6, 5],</span>
<span class="sd">            ...     [8, 6, 4, 6],</span>
<span class="sd">            ...     [1, 2, 1, 1],</span>
<span class="sd">            ...     [3, 2, 3, 3],</span>
<span class="sd">            ... ], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 7</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 8</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestSumEdges(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, bg: BatchedGraph):</span>
<span class="sd">            ...         return bg.sum_edges(x)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestSumEdges()(edge_feat, *batched_graph_field.get_batched_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[4.0, 9.0, 6.0, 11.0], [29.0, 24.0, 19.0, 23.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BatchedGraph.max_nodes"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.max_nodes">[docs]</a>    <span class="k">def</span> <span class="nf">max_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_feat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Aggregating node features and generates a graph-level</span>
<span class="sd">        representation by aggregation type &#39;max&#39;.</span>

<span class="sd">        The node_feat should have shape :math:`(N\_NODES, F)`.</span>
<span class="sd">        Max_nodes operation will aggregate the node_feat</span>
<span class="sd">        according to ver_subgraph_idx.</span>
<span class="sd">        The output tensor will have a shape :math:`(N\_GRAPHS, F)`.</span>
<span class="sd">        :math:`F` is the dimension of the node feature.</span>

<span class="sd">        Args:</span>
<span class="sd">            node_feat (Tensor): a tensor represents the node feature,</span>
<span class="sd">                with shape :math:`(N\_NODES, F)`. :math:`F` is the dimension of the node feature.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N\_GRAPHS, F)`, :math:`F` is the dimension of the node feature.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `node_feat` is not a Tensor which is the type of operation &#39;shape&#39;.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([</span>
<span class="sd">            ...     # graph 1:</span>
<span class="sd">            ...     [1, 2, 3, 4],</span>
<span class="sd">            ...     [2, 4, 1, 3],</span>
<span class="sd">            ...     [1, 3, 2, 4],</span>
<span class="sd">            ...     # graph 2:</span>
<span class="sd">            ...     [9, 7, 5, 8],</span>
<span class="sd">            ...     [8, 7, 6, 5],</span>
<span class="sd">            ...     [8, 6, 4, 6],</span>
<span class="sd">            ...     [1, 2, 1, 1],</span>
<span class="sd">            ... ], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 7</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 8</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestMaxNodes(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, bg: BatchedGraph):</span>
<span class="sd">            ...         return bg.max_nodes(x)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestMaxNodes()(node_feat, *batched_graph_field.get_batched_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[2.0, 4.0, 3.0, 4.0], [9.0, 7.0, 6.0, 8.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BatchedGraph.max_edges"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.max_edges">[docs]</a>    <span class="k">def</span> <span class="nf">max_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge_feat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Aggregating edge features and generates a graph-level</span>
<span class="sd">        representation by aggregation type &#39;max&#39;.</span>

<span class="sd">        The edge_feat should have shape :math:`(N\_EDGES, F)`.</span>
<span class="sd">        Max_edges operation will aggregate the edge_feat</span>
<span class="sd">        according to edge_subgraph_idx.</span>
<span class="sd">        The output tensor will have a shape :math:`(N\_GRAPHS, F)`.</span>
<span class="sd">        :math:`F` is the dimension of the edge feature.</span>

<span class="sd">        Args:</span>
<span class="sd">            edge_feat (Tensor): a tensor represents the edge feature,</span>
<span class="sd">                with shape :math:`(N\_EDGES, F)`. :math:`F` is the dimension of the edge feature.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N\_GRAPHS, F)`. :math:`F` is the dimension of the edge feature.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `edge_feat` is not a Tensor which is the type of operation &#39;shape&#39;.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; edge_feat = ms.Tensor([</span>
<span class="sd">            ...     # graph 1:</span>
<span class="sd">            ...     [1, 2, 3, 4],</span>
<span class="sd">            ...     [2, 4, 1, 3],</span>
<span class="sd">            ...     [1, 3, 2, 4],</span>
<span class="sd">            ...     # graph 2:</span>
<span class="sd">            ...     [9, 7, 5, 8],</span>
<span class="sd">            ...     [8, 7, 6, 5],</span>
<span class="sd">            ...     [8, 6, 4, 6],</span>
<span class="sd">            ...     [1, 2, 1, 1],</span>
<span class="sd">            ...     [3, 2, 3, 3],</span>
<span class="sd">            ... ], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 7</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 8</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestMaxEdges(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, bg: BatchedGraph):</span>
<span class="sd">            ...         return bg.max_edges(x)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestMaxEdges()(edge_feat, *batched_graph_field.get_batched_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[2.0, 4.0, 3.0, 4.0], [9.0, 7.0, 6.0, 8.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BatchedGraph.avg_nodes"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.avg_nodes">[docs]</a>    <span class="k">def</span> <span class="nf">avg_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_feat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Aggregating node features and generates a graph-level</span>
<span class="sd">        representation by aggregation type &#39;avg&#39;.</span>

<span class="sd">        The node_feat should have shape :math:`(N\_NODES, F)`.</span>
<span class="sd">        Avg_nodes operation will aggregate the node_feat</span>
<span class="sd">        according to ver_subgraph_idx.</span>
<span class="sd">        The output tensor will have a shape :math:`(N\_GRAPHS, F)`.</span>
<span class="sd">        :math:`F` is the dimension of the node feature.</span>

<span class="sd">        Args:</span>
<span class="sd">            node_feat (Tensor): a tensor represents the node feature,</span>
<span class="sd">                with shape :math:`(N\_NODES, F)`.</span>
<span class="sd">                :math:`F` is the dimension of the node feature.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N\_GRAPHS, F)`. :math:`F` is the dimension of the node feature.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `node_feat` is not a Tensor which is the type of operation.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([</span>
<span class="sd">            ...     # graph 1:</span>
<span class="sd">            ...     [1, 2, 3, 4],</span>
<span class="sd">            ...     [2, 4, 1, 3],</span>
<span class="sd">            ...     [1, 3, 2, 4],</span>
<span class="sd">            ...     # graph 2:</span>
<span class="sd">            ...     [9, 7, 5, 8],</span>
<span class="sd">            ...     [8, 7, 6, 5],</span>
<span class="sd">            ...     [8, 6, 4, 6],</span>
<span class="sd">            ...     [1, 2, 1, 1],</span>
<span class="sd">            ... ], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 7</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 8</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestAvgNodes(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, bg: BatchedGraph):</span>
<span class="sd">            ...         return bg.avg_nodes(x)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestAvgNodes()(node_feat, *batched_graph_field.get_batched_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[1.3333333730697632, 3.0, 2.0, 3.6666667461395264], [6.5, 5.5, 4.0, 5.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BatchedGraph.avg_edges"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.avg_edges">[docs]</a>    <span class="k">def</span> <span class="nf">avg_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge_feat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Aggregating edge features and generates a graph-level</span>
<span class="sd">        representation by aggregation type &#39;avg&#39;.</span>

<span class="sd">        The edge_feat should have shape :math:`(N\_EDGES, F)`.</span>
<span class="sd">        Avg_edges operation will aggregate the edge_feat</span>
<span class="sd">        according to edge_subgraph_idx.</span>
<span class="sd">        The output tensor will have a shape :math:`(N\_GRAPHS, F)`.</span>
<span class="sd">        :math:`F` is the dimension of the edge feature.</span>

<span class="sd">        Args:</span>
<span class="sd">            edge_feat (Tensor): a tensor represents the edge feature,</span>
<span class="sd">                with shape :math:`(N\_EDGES, F)`. :math:`F` is the dimension of the edge feature.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N\_GRAPHS, F)`,</span>
<span class="sd">            :math:`F` is the dimension of the edge feature.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `edge_feat` is not a Tensor which is the type of operation &#39;shape&#39;.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; edge_feat = ms.Tensor([</span>
<span class="sd">            ...     # graph 1:</span>
<span class="sd">            ...     [1, 2, 3, 4],</span>
<span class="sd">            ...     [2, 4, 1, 3],</span>
<span class="sd">            ...     [1, 3, 2, 4],</span>
<span class="sd">            ...     # graph 2:</span>
<span class="sd">            ...     [9, 7, 5, 8],</span>
<span class="sd">            ...     [8, 7, 6, 5],</span>
<span class="sd">            ...     [8, 6, 4, 6],</span>
<span class="sd">            ...     [1, 2, 1, 1],</span>
<span class="sd">            ...     [3, 2, 3, 3],</span>
<span class="sd">            ... ], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 7</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 8</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestAvgEdges(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, bg: BatchedGraph):</span>
<span class="sd">            ...         return bg.avg_edges(x)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestAvgEdges()(edge_feat, *batched_graph_field.get_batched_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[1.3333333730697632, 3.0, 2.0, 3.6666667461395264],</span>
<span class="sd">                 [5.800000190734863, 4.800000190734863, 3.799999952316284, 4.599999904632568]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BatchedGraph.topk_nodes"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.topk_nodes">[docs]</a>    <span class="k">def</span> <span class="nf">topk_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_feat</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">sortby</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return a graph-level representation by a graph-wise top-k</span>
<span class="sd">        on node features.</span>

<span class="sd">        If sortby is set to None, the function would perform top-k</span>
<span class="sd">        on all dimensions independently.</span>

<span class="sd">        Args:</span>
<span class="sd">            node_feat (Tensor): A tensor represent the node feature,</span>
<span class="sd">                with shape :math:`(N\_NODES, F)`. :math:`F` is the dimension of the node feature.</span>
<span class="sd">            k (int): Represent how many nodes for top-k.</span>
<span class="sd">            sortby (int): Sort according to which feature. If is None,</span>
<span class="sd">                all features are sorted independently.  Default is None.</span>

<span class="sd">        Note:</span>
<span class="sd">            The value participated in the sort by axis (all value if sortby is</span>
<span class="sd">            None) should be greater than zero.</span>
<span class="sd">            Due to the reason that we create zero value for padding</span>
<span class="sd">            and they may cover the features.</span>

<span class="sd">        Returns:</span>
<span class="sd">            - **topk_output** (Tensor) - a tensor with shape :math:`(B, K, F)`,</span>
<span class="sd">              where :math:`B` is the batch size of the input graph.</span>
<span class="sd">              :math:`K` is the input &#39;k&#39;, :math:`F` is the feature size.</span>
<span class="sd">            - **topk_indices** (Tensor), - a tensor with shape</span>
<span class="sd">              :math:`(B, K)`(:math:`(B, K, F)` if sortby is set to None),</span>
<span class="sd">              where :math:`B` is the batch size of the input graph,</span>
<span class="sd">              :math:`F` is the feature size.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `node_feat` is not a Tensor.</span>
<span class="sd">            TypeError: If `k` is not an int.</span>
<span class="sd">            ValueError: If `sortby` is not an int.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([</span>
<span class="sd">            ...     # graph 1:</span>
<span class="sd">            ...     [1, 2, 3, 4],</span>
<span class="sd">            ...     [2, 4, 1, 3],</span>
<span class="sd">            ...     [1, 3, 2, 4],</span>
<span class="sd">            ...     # graph 2:</span>
<span class="sd">            ...     [9, 7, 5, 8],</span>
<span class="sd">            ...     [8, 7, 6, 5],</span>
<span class="sd">            ...     [8, 6, 4, 6],</span>
<span class="sd">            ...     [1, 2, 1, 1],</span>
<span class="sd">            ... ], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 7</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 8</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestTopkNodes(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, bg: BatchedGraph):</span>
<span class="sd">            ...         return bg.topk_nodes(x, 2, 1)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; output, indices = TestTopkNodes()(node_feat, *batched_graph_field.get_batched_graph())</span>
<span class="sd">            &gt;&gt;&gt; output = output.asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; indices = indices.asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(output)</span>
<span class="sd">                [[2.0, 4.0, 1.0, 3.0], [1.0, 3.0, 2.0, 4.0]], [[9.0, 7.0, 5.0, 8.0], [8.0, 7.0, 6.0, 5.0]]</span>
<span class="sd">            &gt;&gt;&gt; print(indices)</span>
<span class="sd">                [[1, 2], [3, 4]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BatchedGraph.topk_edges"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.topk_edges">[docs]</a>    <span class="k">def</span> <span class="nf">topk_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge_feat</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">sortby</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return a graph-level representation by a graph-wise</span>
<span class="sd">        top-k on edge features.</span>

<span class="sd">        If sortby is set to None, the function would perform</span>
<span class="sd">        top-k on all dimensions independently.</span>

<span class="sd">        Args:</span>
<span class="sd">            edge_feat (Tensor): A tensor represent the edge feature,</span>
<span class="sd">                with shape :math:`(N\_EDGES, F)`, :math:`F` is the feature size.</span>
<span class="sd">            k (int): Represent how many edges for top-k.</span>
<span class="sd">            sortby (int): Sort according to which feature. If is None,</span>
<span class="sd">                all features are sorted independently. Default is None.</span>

<span class="sd">        Note:</span>
<span class="sd">            The value participated in the sort by axis</span>
<span class="sd">            (all value if sortby is None) should be greater than zero.</span>
<span class="sd">            Due to the reason that we create zero value for</span>
<span class="sd">            padding and they may cover the features.</span>

<span class="sd">        Returns:</span>
<span class="sd">            - **topk_output** (Tensor), - a tensor with shape :math:`(B, K, F)`,</span>
<span class="sd">              where :math:`B` is the batch size of the input graph,</span>
<span class="sd">              :math:`K` is input &#39;k&#39;, :math:`F` is the feature size.</span>
<span class="sd">            - **topk_indices** (Tensor), - a tensor with shape :math:`(B, K)`</span>
<span class="sd">              (:math:`(B, K, F)` if sortby is set to None)</span>
<span class="sd">              where :math:`B` is the batch size of the input graph, :math:`K` is input &#39;k&#39;,</span>
<span class="sd">              :math:`F` is the feature size.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `edge_feat` is not a Tensor.</span>
<span class="sd">            TypeError: If `k` is not an int.</span>
<span class="sd">            ValueError: If `sortby` is not an int.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; edge_feat = ms.Tensor([</span>
<span class="sd">            ...     # graph 1:</span>
<span class="sd">            ...     [1, 2, 3, 4],</span>
<span class="sd">            ...     [2, 4, 1, 3],</span>
<span class="sd">            ...     [1, 3, 2, 4],</span>
<span class="sd">            ...     # graph 2:</span>
<span class="sd">            ...     [9, 7, 5, 8],</span>
<span class="sd">            ...     [8, 7, 6, 5],</span>
<span class="sd">            ...     [8, 6, 4, 6],</span>
<span class="sd">            ...     [1, 2, 1, 1],</span>
<span class="sd">            ...     [3, 2, 3, 3],</span>
<span class="sd">            ... ], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 7</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 8</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestTopkEdges(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, bg: BatchedGraph):</span>
<span class="sd">            ...         return bg.topk_edges(x, 2, 1)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; output, indices = TestTopkEdges()(edge_feat, *batched_graph_field.get_batched_graph())</span>
<span class="sd">            &gt;&gt;&gt; output = output.asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; indices = indices.asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(output)</span>
<span class="sd">                [[[2.0, 4.0, 1.0, 3.0], [1.0, 3.0, 2.0, 4.0]], [[9.0, 7.0, 5.0, 8.0], [8.0, 7.0, 6.0, 5.0]]]</span>
<span class="sd">            &gt;&gt;&gt; print(indices)</span>
<span class="sd">                [[1, 2], [3, 4]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BatchedGraph.softmax_nodes"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.softmax_nodes">[docs]</a>    <span class="k">def</span> <span class="nf">softmax_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_feat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform graph-wise softmax on the node features.</span>

<span class="sd">        For each node :math:`v\in\mathcal{V}` and its feature :math:`x_v`,</span>
<span class="sd">        calculate its normalized feature as follows:</span>

<span class="sd">        .. math::</span>
<span class="sd">            z_v = \frac{\exp(x_v)}{\sum_{u\in\mathcal{V}}\exp(x_u)}</span>

<span class="sd">        Each subgraph computes softmax independently.</span>
<span class="sd">        The result tensor has the same shape as the original node feature.</span>

<span class="sd">        Args:</span>
<span class="sd">            node_feat (Tensor): a tensor represent the node feature,</span>
<span class="sd">                with shape :math:`(N\_NODES, F)`, :math:`F` is the feature size.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N\_NODES, F)`, :math:`F` is the feature size.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `node_feat` is not a Tensor.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([</span>
<span class="sd">            ...     # graph 1:</span>
<span class="sd">            ...     [1, 2, 3, 4],</span>
<span class="sd">            ...     [2, 4, 1, 3],</span>
<span class="sd">            ...     [1, 3, 2, 4],</span>
<span class="sd">            ...     # graph 2:</span>
<span class="sd">            ...     [9, 7, 5, 8],</span>
<span class="sd">            ...     [8, 7, 6, 5],</span>
<span class="sd">            ...     [8, 6, 4, 6],</span>
<span class="sd">            ...     [1, 2, 1, 1],</span>
<span class="sd">            ... ], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 7</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 8</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestSoftmaxNodes(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, bg: BatchedGraph):</span>
<span class="sd">            ...         return bg.softmax_nodes(x)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestSoftmaxNodes()(node_feat, *batched_graph_field.get_batched_graph()).asnumpy()</span>
<span class="sd">            &gt;&gt;&gt; print(np.array2string(ret, formatter={&#39;float_kind&#39;:&#39;{0:.5f}&#39;.format}))</span>
<span class="sd">                [[0.21194, 0.09003, 0.66524, 0.42232],</span>
<span class="sd">                 [0.57612, 0.66524, 0.09003, 0.15536],</span>
<span class="sd">                 [0.21194, 0.24473, 0.24473, 0.42232],</span>
<span class="sd">                 [0.57601, 0.42112, 0.24364, 0.84315],</span>
<span class="sd">                 [0.21190, 0.42112, 0.66227, 0.04198],</span>
<span class="sd">                 [0.21190, 0.15492, 0.08963, 0.11411],</span>
<span class="sd">                 [0.00019, 0.00284, 0.00446, 0.00077]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BatchedGraph.softmax_edges"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.softmax_edges">[docs]</a>    <span class="k">def</span> <span class="nf">softmax_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge_feat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform graph-wise softmax on the edge features.</span>

<span class="sd">        For each edge :math:`v\in\mathcal{V}` and its feature :math:`x_v`,</span>
<span class="sd">        calculate its normalized feature as follows:</span>

<span class="sd">        .. math::</span>
<span class="sd">            z_v = \frac{\exp(x_v)}{\sum_{u\in\mathcal{V}}\exp(x_u)}</span>

<span class="sd">        Each subgraph computes softmax independently.</span>
<span class="sd">        The result tensor has the same shape as the original edge feature.</span>

<span class="sd">        Args:</span>
<span class="sd">            edge_feat (Tensor): a tensor represent the edge feature,</span>
<span class="sd">                with shape :math:`(N\_EDGES, F)`, :math:`F` is the feature size.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N\_EDGES, F)`, :math:`F` is the feature size.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `edge_feat` is not a Tensor.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; edge_feat = ms.Tensor([</span>
<span class="sd">            ...     # graph 1:</span>
<span class="sd">            ...     [1, 2, 3, 4],</span>
<span class="sd">            ...     [2, 4, 1, 3],</span>
<span class="sd">            ...     [1, 3, 2, 4],</span>
<span class="sd">            ...     # graph 2:</span>
<span class="sd">            ...     [9, 7, 5, 8],</span>
<span class="sd">            ...     [8, 7, 6, 5],</span>
<span class="sd">            ...     [8, 6, 4, 6],</span>
<span class="sd">            ...     [1, 2, 1, 1],</span>
<span class="sd">            ...     [3, 2, 3, 3],</span>
<span class="sd">            ... ], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 7</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 8</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestSoftmaxEdges(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, bg: BatchedGraph):</span>
<span class="sd">            ...         return bg.softmax_edges(x)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestSoftmaxEdges()(edge_feat, *batched_graph_field.get_batched_graph()).asnumpy()</span>
<span class="sd">            &gt;&gt;&gt; print(np.array2string(ret, formatter={&#39;float_kind&#39;:&#39;{0:.5f}&#39;.format}))</span>
<span class="sd">                [[0.21194, 0.09003, 0.66524, 0.42232],</span>
<span class="sd">                 [0.57612, 0.66524, 0.09003, 0.15536],</span>
<span class="sd">                 [0.21194, 0.24473, 0.24473, 0.42232],</span>
<span class="sd">                 [0.57518, 0.41993, 0.23586, 0.83838],</span>
<span class="sd">                 [0.21160, 0.41993, 0.64113, 0.04174],</span>
<span class="sd">                 [0.21160, 0.15448, 0.08677, 0.11346],</span>
<span class="sd">                 [0.00019, 0.00283, 0.00432, 0.00076],</span>
<span class="sd">                 [0.00143, 0.00283, 0.03192, 0.00565]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BatchedGraph.broadcast_nodes"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.broadcast_nodes">[docs]</a>    <span class="k">def</span> <span class="nf">broadcast_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_feat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Broadcast graph-level features to node-level representation.</span>

<span class="sd">        Args:</span>
<span class="sd">            graph_feat (Tensor): a tensor represent the graph feature,</span>
<span class="sd">                with shape :math:`(N\_GRAPHS, F)`, :math:`F` is the feature size.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N\_NODES, F)`, :math:`F` is the feature size.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `graph_feat` is not a Tensor.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([</span>
<span class="sd">            ...     # graph 1:</span>
<span class="sd">            ...     [1, 2, 3, 4],</span>
<span class="sd">            ...     [2, 4, 1, 3],</span>
<span class="sd">            ...     [1, 3, 2, 4],</span>
<span class="sd">            ...     # graph 2:</span>
<span class="sd">            ...     [9, 7, 5, 8],</span>
<span class="sd">            ...     [8, 7, 6, 5],</span>
<span class="sd">            ...     [8, 6, 4, 6],</span>
<span class="sd">            ...     [1, 2, 1, 1],</span>
<span class="sd">            ... ], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 7</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 8</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestBroadCastNodes(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, bg: BatchedGraph):</span>
<span class="sd">            ...         ret = bg.max_nodes(x)</span>
<span class="sd">            ...         return bg.broadcast_nodes(ret)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestBroadCastNodes()(node_feat, *batched_graph_field.get_batched_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[2.0, 4.0, 3.0, 4.0], [2.0, 4.0, 3.0, 4.0], [2.0, 4.0, 3.0, 4.0],</span>
<span class="sd">                 [9.0, 7.0, 6.0, 8.0], [9.0, 7.0, 6.0, 8.0], [9.0, 7.0, 6.0, 8.0], [9.0, 7.0, 6.0, 8.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BatchedGraph.broadcast_edges"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraph.broadcast_edges">[docs]</a>    <span class="k">def</span> <span class="nf">broadcast_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_feat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Broadcast graph-level features to edge-level representation.</span>

<span class="sd">        Args:</span>
<span class="sd">            graph_feat (Tensor): a tensor represent the graph feature,</span>
<span class="sd">                with shape :math:`(N\_GRAPHS, F)`, :math:`F` is the feature size.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, a tensor with shape :math:`(N\_EDGES, F)`, :math:`F` is the feature size.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `graph_feat` is not a Tensor.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import BatchedGraph, BatchedGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; edge_feat = ms.Tensor([</span>
<span class="sd">            ...     # graph 1:</span>
<span class="sd">            ...     [1, 2, 3, 4],</span>
<span class="sd">            ...     [2, 4, 1, 3],</span>
<span class="sd">            ...     [1, 3, 2, 4],</span>
<span class="sd">            ...     # graph 2:</span>
<span class="sd">            ...     [9, 7, 5, 8],</span>
<span class="sd">            ...     [8, 7, 6, 5],</span>
<span class="sd">            ...     [8, 6, 4, 6],</span>
<span class="sd">            ...     [1, 2, 1, 1],</span>
<span class="sd">            ...     [3, 2, 3, 3],</span>
<span class="sd">            ... ], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = 7</span>
<span class="sd">            &gt;&gt;&gt; n_edges = 8</span>
<span class="sd">            &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1], ms.int32)</span>
<span class="sd">            &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">            ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestBroadCastEdges(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, bg: BatchedGraph):</span>
<span class="sd">            ...         ret = bg.max_edges(x)</span>
<span class="sd">            ...         return bg.broadcast_edges(ret)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestBroadCastEdges()(edge_feat, *batched_graph_field.get_batched_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[2.0, 4.0, 3.0, 4.0], [2.0, 4.0, 3.0, 4.0], [2.0, 4.0, 3.0, 4.0],</span>
<span class="sd">                 [9.0, 7.0, 6.0, 8.0], [9.0, 7.0, 6.0, 8.0], [9.0, 7.0, 6.0, 8.0],</span>
<span class="sd">                 [9.0, 7.0, 6.0, 8.0], [9.0, 7.0, 6.0, 8.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div></div>


<div class="viewcode-block" id="HeterGraph"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.HeterGraph">[docs]</a><span class="k">class</span> <span class="nc">HeterGraph</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The heterogeneous Graph.</span>

<span class="sd">    This is the class which should be annotated in construct function</span>
<span class="sd">    for GNNCell class.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">src_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A list of tensor with shape :math:`(N\_EDGES)`, represents the source</span>
<span class="sd">        node index of COO edge matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dst_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A list of tensor with shape :math:`(N\_EDGES)`, represents the</span>
<span class="sd">        destination node index of COO edge matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A list of integer, represent the nodes count of the graph.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A list of integer, represent the edges count of the graph.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

<div class="viewcode-block" id="HeterGraph.get_homo_graph"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.HeterGraph.get_homo_graph">[docs]</a>    <span class="k">def</span> <span class="nf">get_homo_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">etype</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the specific nodes, edges for etype.</span>

<span class="sd">        Args:</span>
<span class="sd">            etype (int): The edge type.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[Tensor], a homo graph.</span>

<span class="sd">        Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl import Graph, HeterGraph, HeterGraphField</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_gl.nn import GNNCell</span>
<span class="sd">            &gt;&gt;&gt; n_nodes = [9, 2]</span>
<span class="sd">            &gt;&gt;&gt; n_edges = [11, 1]</span>
<span class="sd">            &gt;&gt;&gt; src_idx = [ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32), ms.Tensor([0], ms.int32)]</span>
<span class="sd">            &gt;&gt;&gt; dst_idx = [ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32), ms.Tensor([1], ms.int32)]</span>
<span class="sd">            &gt;&gt;&gt; heter_graph_field = HeterGraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">            &gt;&gt;&gt; node_feat = ms.Tensor([[1], [2], [1], [2], [0], [1], [2], [3], [1]], ms.float32)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestSum(GNNCell):</span>
<span class="sd">            ...     def construct(self, x, g: Graph):</span>
<span class="sd">            ...         g.set_vertex_attr({&quot;x&quot;: x})</span>
<span class="sd">            ...         for v in g.dst_vertex:</span>
<span class="sd">            ...             v.h = g.sum([u.x for u in v.innbs])</span>
<span class="sd">            ...         return [v.h for v in g.dst_vertex]</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; class TestHeterGraph(GNNCell):</span>
<span class="sd">            ...     def __init__(self):</span>
<span class="sd">            ...         super().__init__()</span>
<span class="sd">            ...         self.sum = TestSum()</span>
<span class="sd">            ...</span>
<span class="sd">            ...     def construct(self, x, hg: HeterGraph):</span>
<span class="sd">            ...         return self.sum(x, *hg.get_homo_graph(0))</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; ret = TestHeterGraph()(node_feat, *heter_graph_field.get_heter_graph()).asnumpy().tolist()</span>
<span class="sd">            &gt;&gt;&gt; print(ret)</span>
<span class="sd">                [[1.0], [2.0], [0.0], [0.0], [3.0], [2.0], [1.0], [0.0], [3.0]]</span>
<span class="sd">        &quot;&quot;&quot;</span></div></div>


<div class="viewcode-block" id="GraphField"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.GraphField">[docs]</a><span class="k">class</span> <span class="nc">GraphField</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The data container for a graph.</span>

<span class="sd">    The edge information are stored in COO format.</span>

<span class="sd">    Args:</span>
<span class="sd">        src_idx (Tensor): A tensor with shape :math:`(N\_EDGES)`, with int dtype,</span>
<span class="sd">            represents the source node index of COO edge matrix.</span>
<span class="sd">        dst_idx (Tensor): A tensor with shape :math:`(N\_EDGES)`, with int dtype,</span>
<span class="sd">            represents the destination node index of COO edge matrix.</span>
<span class="sd">        n_nodes (int): An integer, represent the nodes count of the graph.</span>
<span class="sd">        n_edges (int): An integer, represent the edges count of the graph.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">        &gt;&gt;&gt; from mindspore_gl import GraphField</span>
<span class="sd">        &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">        &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">        &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">        &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">        &gt;&gt;&gt; graph_field = GraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src_idx</span><span class="p">,</span> <span class="n">dst_idx</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_edges</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">src_idx</span> <span class="o">=</span> <span class="n">src_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dst_idx</span> <span class="o">=</span> <span class="n">dst_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span> <span class="o">=</span> <span class="n">n_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_edges</span> <span class="o">=</span> <span class="n">n_edges</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">src_idx</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;src_idx should be a tensor, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">src_idx</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">src_idx</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;src_idx should be an int datatype, but got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">src_idx</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dst_idx</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;dst_idx should be a tensor, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dst_idx</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dst_idx</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;dst_idx should be an int datatype, but got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dst_idx</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">ms</span><span class="o">.</span><span class="n">bool_</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_nodes should be an integer, but got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_edges</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_edges</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">ms</span><span class="o">.</span><span class="n">bool_</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_edges should be an integer, but got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_edges</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_edges</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_edges</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_nodes should be an integer, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_edges</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_edges should be an integer, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_edges</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_nodes should be an integer, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_edges</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_edges should be an integer, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_edges</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="GraphField.get_graph"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.GraphField.get_graph">[docs]</a>    <span class="k">def</span> <span class="nf">get_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the Graph.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List, A list of tensor, which should be</span>
<span class="sd">            used for construct function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">src_idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dst_idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_edges</span><span class="p">]</span></div></div>


<div class="viewcode-block" id="BatchedGraphField"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraphField">[docs]</a><span class="k">class</span> <span class="nc">BatchedGraphField</span><span class="p">(</span><span class="n">GraphField</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The data container for a batched graph.</span>

<span class="sd">    The edge information are stored in COO format.</span>

<span class="sd">    Args:</span>
<span class="sd">        src_idx (Tensor): A tensor with shape :math:`(N\_EDGES)`, with int dtype,</span>
<span class="sd">            represents the source node index of COO edge matrix.</span>
<span class="sd">        dst_idx (Tensor): A tensor with shape :math:`(N\_EDGES)`, with int dtype,</span>
<span class="sd">            represents the destination node index of COO edge matrix.</span>
<span class="sd">        n_nodes (int): An integer, represent the nodes count of the graph.</span>
<span class="sd">        n_edges (int): An integer, represent the edges count of the graph.</span>
<span class="sd">        ver_subgraph_idx (Tensor): A tensor with shape :math:`(N\_NODES)`, with int dtype,</span>
<span class="sd">            indicates each node belonging to which subgraph.</span>
<span class="sd">        edge_subgraph_idx (Tensor): A tensor with shape :math:`(N\_EDGES,)`, with int dtype,</span>
<span class="sd">            indicates each edge belonging to which subgraph.</span>
<span class="sd">        graph_mask (Tensor): A tensor with shape :math:`(N\_GRAPHS,)`, with int dtype,</span>
<span class="sd">            indicates whether the subgraph is exist.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">        &gt;&gt;&gt; from mindspore_gl import BatchedGraphField</span>
<span class="sd">        &gt;&gt;&gt; n_nodes = 9</span>
<span class="sd">        &gt;&gt;&gt; n_edges = 11</span>
<span class="sd">        &gt;&gt;&gt; src_idx = ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32)</span>
<span class="sd">        &gt;&gt;&gt; dst_idx = ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32)</span>
<span class="sd">        &gt;&gt;&gt; ver_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 2, 2], ms.int32)</span>
<span class="sd">        &gt;&gt;&gt; edge_subgraph_idx = ms.Tensor([0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2], ms.int32)</span>
<span class="sd">        &gt;&gt;&gt; graph_mask = ms.Tensor([1, 1, 0], ms.int32)</span>
<span class="sd">        &gt;&gt;&gt; batched_graph_field = BatchedGraphField(src_idx, dst_idx, n_nodes, n_edges,</span>
<span class="sd">        ...                                         ver_subgraph_idx, edge_subgraph_idx, graph_mask)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src_idx</span><span class="p">,</span> <span class="n">dst_idx</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_edges</span><span class="p">,</span> <span class="n">ver_subgraph_idx</span><span class="p">,</span>
                 <span class="n">edge_subgraph_idx</span><span class="p">,</span> <span class="n">graph_mask</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">src_idx</span><span class="p">,</span> <span class="n">dst_idx</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_edges</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ver_subgraph_idx</span> <span class="o">=</span> <span class="n">ver_subgraph_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_subgraph_idx</span> <span class="o">=</span> <span class="n">edge_subgraph_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">graph_mask</span> <span class="o">=</span> <span class="n">graph_mask</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ver_subgraph_idx</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ver_subgraph_idx should be a tensor, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ver_subgraph_idx</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ver_subgraph_idx</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ver_subgraph_idx should be an int datatype, but got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ver_subgraph_idx</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_subgraph_idx</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;edge_subgraph_idx should be a tensor, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_subgraph_idx</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_subgraph_idx</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;edge_subgraph_idx should be an int datatype, but got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_subgraph_idx</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">graph_mask</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;graph_mask should be a tensor, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">graph_mask</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">graph_mask</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;graph_mask should be an int datatype, but got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">graph_mask</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="BatchedGraphField.get_batched_graph"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.BatchedGraphField.get_batched_graph">[docs]</a>    <span class="k">def</span> <span class="nf">get_batched_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the batched Graph.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List, A list of tensor, which should</span>
<span class="sd">            be used for construct function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batched_graph_field</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_graph</span><span class="p">()</span>
        <span class="n">batched_graph_field</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">ver_subgraph_idx</span><span class="p">,</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">edge_subgraph_idx</span><span class="p">,</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">graph_mask</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">batched_graph_field</span></div></div>


<div class="viewcode-block" id="HeterGraphField"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.HeterGraphField">[docs]</a><span class="k">class</span> <span class="nc">HeterGraphField</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The data container for a heterogeneous graph.</span>
<span class="sd">    The edge information are stored in COO format.</span>

<span class="sd">    Args:</span>
<span class="sd">        src_idx (List[Tensor]): A list of tensor with shape :math:`(N\_EDGES)`, with int dtype,</span>
<span class="sd">            represents the source node index of COO edge matrix.</span>
<span class="sd">        dst_idx (List[Tensor]): A list of tensor with shape :math:`(N\_EDGES)`, with int dtype,</span>
<span class="sd">            represents the destination node index of COO edge matrix.</span>
<span class="sd">        n_nodes (List[int]): A list of integer, represent the nodes count of the graph.</span>
<span class="sd">        n_edges (List[int]): A list of integer, represent the edges count of the graph.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">            ``GPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">        &gt;&gt;&gt; from mindspore_gl import HeterGraphField</span>
<span class="sd">        &gt;&gt;&gt; n_nodes = [9, 2]</span>
<span class="sd">        &gt;&gt;&gt; n_edges = [11, 1]</span>
<span class="sd">        &gt;&gt;&gt; src_idx = [ms.Tensor([0, 2, 2, 3, 4, 5, 5, 6, 8, 8, 8], ms.int32), ms.Tensor([0], ms.int32)]</span>
<span class="sd">        &gt;&gt;&gt; dst_idx = [ms.Tensor([1, 0, 1, 5, 3, 4, 6, 4, 8, 8, 8], ms.int32), ms.Tensor([1], ms.int32)]</span>
<span class="sd">        &gt;&gt;&gt; heter_graph_field = HeterGraphField(src_idx, dst_idx, n_nodes, n_edges)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src_idx</span><span class="p">,</span> <span class="n">dst_idx</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_edges</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">src_idx</span> <span class="o">=</span> <span class="n">src_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dst_idx</span> <span class="o">=</span> <span class="n">dst_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span> <span class="o">=</span> <span class="n">n_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_edges</span> <span class="o">=</span> <span class="n">n_edges</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">src_idx</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;src_idx should be a list, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">src_idx</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">per_src_idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">src_idx</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">per_src_idx</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;element of src_idx should be a tensor, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">per_src_idx</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">per_src_idx</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Int</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;element of src_idx should be an int datatype, but got </span><span class="si">{</span><span class="n">per_src_idx</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dst_idx</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;dst_idx should be a list, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dst_idx</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">per_dst_idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dst_idx</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">per_dst_idx</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;element of dst_idx should be a tensor, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">per_dst_idx</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">per_dst_idx</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Int</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;element of dst_idx should be an int datatype, but got </span><span class="si">{</span><span class="n">per_dst_idx</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_nodes should be a list, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_edges</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_edges should be a list, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_edges</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="HeterGraphField.get_heter_graph"><a class="viewcode-back" href="../../../mindspore_gl.parser.html#mindspore_gl.parser.HeterGraphField.get_heter_graph">[docs]</a>    <span class="k">def</span> <span class="nf">get_heter_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the hetergenous Graph.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List, A list of tensor list, which should be used for construct</span>
<span class="sd">            function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">src_idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dst_idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_edges</span><span class="p">]</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>