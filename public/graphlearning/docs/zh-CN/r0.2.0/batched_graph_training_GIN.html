

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>批次图训练网络 &mdash; MindSpore master 文档</title>
  

  
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script src="_static/translations.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="next" title="时空图训练网络" href="spatio_temporal_graph_training_STGCN.html" />
    <link rel="prev" title="整图训练网络" href="full_training_of_GCN.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindspore_graphlearning_install.html">安装 Graph Learning</a></li>
</ul>
<p class="caption"><span class="caption-text">使用指南</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="full_training_of_GCN.html">整图训练网络</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">批次图训练网络</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#概述">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gin原理">GIN原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="#定义网络结构">定义网络结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="#构造数据集">构造数据集</a></li>
<li class="toctree-l2"><a class="reference internal" href="#定义loss函数">定义loss函数</a></li>
<li class="toctree-l2"><a class="reference internal" href="#网络训练和验证">网络训练和验证</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#设置环境变量">设置环境变量</a></li>
<li class="toctree-l3"><a class="reference internal" href="#定义训练网络">定义训练网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="#网络训练及验证">网络训练及验证</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#执行并查看结果">执行并查看结果</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#运行过程">运行过程</a></li>
<li class="toctree-l3"><a class="reference internal" href="#执行结果">执行结果</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="spatio_temporal_graph_training_STGCN.html">时空图训练网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="single_host_distributed_Graphsage.html">单机多卡分布式训练</a></li>
</ul>
<p class="caption"><span class="caption-text">API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.html">mindspore_gl</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.dataloader.html">mindspore_gl.dataloader</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.dataset.html">mindspore_gl.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.graph.html">mindspore_gl.graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.nn.html">mindspore_gl.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.sampling.html">mindspore_gl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_gl.utils.html">mindspore_gl.utils</a></li>
</ul>
<p class="caption"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>批次图训练网络</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/batched_graph_training_GIN.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="批次图训练网络">
<h1>批次图训练网络<a class="headerlink" href="#批次图训练网络" title="永久链接至标题">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r2.0/docs/graphlearning/docs/source_zh_cn/batched_graph_training_GIN.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0/resource/_static/logo_source.png"></a>
  </p>
<div class="section" id="概述">
<h2>概述<a class="headerlink" href="#概述" title="永久链接至标题">¶</a></h2>
<p>在本例中将展示如何基于图同构网络的进行社会关系网络分类。</p>
<p>GIN的灵感来自GNN和Weisfeiler-Lehman (WL)图同构测试。WL测试是一个强大的测试，可以区分广泛的图类。如果GNN的聚合方案具有高度的表达能力，并且可以建模内射函数，GNN可以具有与WL测试一样大的鉴别力。</p>
<p>IMDB-BINARY是一个电影协作数据集，由1000名在IMDB中扮演电影角色的演员的角色网络组成。在每张图中，节点代表演员，如果他们出演过同一部电影，在节点直接建立一条边。这些图都来源于动作或浪漫电影。
分批次从IMDB-BINARY数据集中取出图数据，每张图都是由演员构成的电影，利用GIN对图进行分类，预测电影属于什么风格。</p>
<p>批次图模式中每次能够对多张图同时进行训练，并且每张图的节点数/边数都完全不同。mindspore_gl提供了构建虚拟图的方法将对批次内图整合成一张整图，并对整图数据进行统一，以降低内存消耗及加速计算。</p>
<blockquote>
<div><p>下载完整的样例<a class="reference external" href="https://gitee.com/mindspore/graphlearning/tree/r0.2.0/model_zoo/gin">GIN</a>代码。</p>
</div></blockquote>
</div>
<div class="section" id="gin原理">
<h2>GIN原理<a class="headerlink" href="#gin原理" title="永久链接至标题">¶</a></h2>
<p>论文链接：<a class="reference external" href="https://arxiv.org/pdf/1810.00826.pdf">How Powerful are Graph Neural Networks?</a></p>
</div>
<div class="section" id="定义网络结构">
<h2>定义网络结构<a class="headerlink" href="#定义网络结构" title="永久链接至标题">¶</a></h2>
<p>GINConv将图<code class="docutils literal notranslate"><span class="pre">g</span></code>解析为<code class="docutils literal notranslate"><span class="pre">BatchedGraph</span></code>，与<code class="docutils literal notranslate"><span class="pre">Graph</span></code>相比<code class="docutils literal notranslate"><span class="pre">BatchedGraph</span></code>能够支持更多图操作。输入的数据为整图，但是每张子图进行节点特征更新时，还是能根据自身的节点找到对应的邻居节点，而不会连接到其他子图的节点。</p>
<p>mindspore_gl.nn提供了GINConv的API可以直接调用。使用GINConv，再配合批次归一化、池化等操作实现一个多层的GinNet网络代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GinNet</span><span class="p">(</span><span class="n">GNNCell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;GIN net&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">num_layers</span><span class="p">,</span>
                 <span class="n">num_mlp_layers</span><span class="p">,</span>
                 <span class="n">input_dim</span><span class="p">,</span>
                 <span class="n">hidden_dim</span><span class="p">,</span>
                 <span class="n">output_dim</span><span class="p">,</span>
                 <span class="n">final_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">learn_eps</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">graph_pooling_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">,</span>
                 <span class="n">neighbor_pooling_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span>
                 <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_dropout</span> <span class="o">=</span> <span class="n">final_dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">graph_pooling_type</span> <span class="o">=</span> <span class="n">graph_pooling_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_pooling_type</span> <span class="o">=</span> <span class="n">neighbor_pooling_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learn_eps</span> <span class="o">=</span> <span class="n">learn_eps</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mlps</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CellList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CellList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_norms</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CellList</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_pooling_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="s1">&#39;avg&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">SyntaxError</span><span class="p">(</span><span class="s2">&quot;graph pooling type not supported.&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">mlps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MLP</span><span class="p">(</span><span class="n">num_mlp_layers</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">mlps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MLP</span><span class="p">(</span><span class="n">num_mlp_layers</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">GINConv</span><span class="p">(</span><span class="n">ApplyNodeFunc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlps</span><span class="p">[</span><span class="n">layer</span><span class="p">]),</span> <span class="n">learn_eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learn_eps</span><span class="p">,</span>
                                      <span class="n">aggregation_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">neighbor_pooling_type</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_norms</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">linears_prediction</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CellList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">linears_prediction</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">linears_prediction</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_weight</span><span class="p">,</span> <span class="n">g</span><span class="p">:</span> <span class="n">BatchedGraph</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;construct function&quot;&quot;&quot;</span>
        <span class="n">hidden_rep</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">[</span><span class="n">layer</span><span class="p">](</span><span class="n">h</span><span class="p">,</span> <span class="n">edge_weight</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span>
            <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_norms</span><span class="p">[</span><span class="n">layer</span><span class="p">](</span><span class="n">h</span><span class="p">)</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()(</span><span class="n">h</span><span class="p">)</span>
            <span class="n">hidden_rep</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

        <span class="n">score_over_layer</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">layer</span><span class="p">,</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hidden_rep</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_pooling_type</span> <span class="o">==</span> <span class="s1">&#39;sum&#39;</span><span class="p">:</span>
                <span class="n">pooled_h</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">sum_nodes</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pooled_h</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">avg_nodes</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
            <span class="n">score_over_layer</span> <span class="o">=</span> <span class="n">score_over_layer</span> <span class="o">+</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_dropout</span><span class="p">)(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">linears_prediction</span><span class="p">[</span><span class="n">layer</span><span class="p">](</span><span class="n">pooled_h</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">score_over_layer</span>
</pre></div>
</div>
<p>GINConv执行的更多细节可以看mindspore_gl.nn.GINConv的<a class="reference external" href="https://gitee.com/mindspore/graphlearning/blob/r0.2.0/mindspore_gl/nn/conv/ginconv.py">API</a>代码。</p>
</div>
<div class="section" id="构造数据集">
<h2>构造数据集<a class="headerlink" href="#构造数据集" title="永久链接至标题">¶</a></h2>
<p>从mindspore_gl.dataset调用了IMDB-BINARY的数据集，调用方法可以参考<a class="reference external" href="https://www.mindspore.cn/graphlearning/docs/zh-CN/r0.2/full_training_of_GCN.html#%E6%9E%84%E9%80%A0%E6%95%B0%E6%8D%AE%E9%9B%86">GCN</a>。然后利用mindspore_gl.dataloader.RandomBatchSampler定义了一个采样器，来生成采样索引。
MultiHomoGraphDataset根据采样索引从数据集里获取数据，将返回数据打包成batch，做出数据集的生成器。构建生成器后，调用mindspore.dataset.GeneratorDataset的API，完成数据加载器构建。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">IMDBBinary</span><span class="p">(</span><span class="n">arguments</span><span class="o">.</span><span class="n">data_path</span><span class="p">)</span>
<span class="n">train_batch_sampler</span> <span class="o">=</span> <span class="n">RandomBatchSampler</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">train_graphs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">arguments</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">train_multi_graph_dataset</span> <span class="o">=</span> <span class="n">MultiHomoGraphDataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">arguments</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">train_batch_sampler</span><span class="p">)))</span>
<span class="n">test_batch_sampler</span> <span class="o">=</span> <span class="n">RandomBatchSampler</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">val_graphs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">arguments</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">test_multi_graph_dataset</span> <span class="o">=</span> <span class="n">MultiHomoGraphDataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">arguments</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">test_batch_sampler</span><span class="p">)))</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">train_multi_graph_dataset</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;row&#39;</span><span class="p">,</span> <span class="s1">&#39;col&#39;</span><span class="p">,</span> <span class="s1">&#39;node_count&#39;</span><span class="p">,</span> <span class="s1">&#39;edge_count&#39;</span><span class="p">,</span>
                                                                   <span class="s1">&#39;node_map_idx&#39;</span><span class="p">,</span> <span class="s1">&#39;edge_map_idx&#39;</span><span class="p">,</span> <span class="s1">&#39;graph_mask&#39;</span><span class="p">,</span>
                                                                   <span class="s1">&#39;batched_label&#39;</span><span class="p">,</span> <span class="s1">&#39;batched_node_feat&#39;</span><span class="p">,</span>
                                                                   <span class="s1">&#39;batched_edge_feat&#39;</span><span class="p">],</span>
                                       <span class="n">sampler</span><span class="o">=</span><span class="n">train_batch_sampler</span><span class="p">)</span>

<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">test_multi_graph_dataset</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;row&#39;</span><span class="p">,</span> <span class="s1">&#39;col&#39;</span><span class="p">,</span> <span class="s1">&#39;node_count&#39;</span><span class="p">,</span> <span class="s1">&#39;edge_count&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;node_map_idx&#39;</span><span class="p">,</span> <span class="s1">&#39;edge_map_idx&#39;</span><span class="p">,</span> <span class="s1">&#39;graph_mask&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;batched_label&#39;</span><span class="p">,</span> <span class="s1">&#39;batched_node_feat&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;batched_edge_feat&#39;</span><span class="p">],</span>
                                      <span class="n">sampler</span><span class="o">=</span><span class="n">test_batch_sampler</span><span class="p">)</span>
</pre></div>
</div>
<p>利用mindspore_gl.graph.BatchHomoGraph将多张子图合并成一张整图。在模型训练时，batch内所有图将以一张整图的形式进行计算。</p>
<p>为了减少计算图的生成，加快计算速度，生成器在返回数据时，将每个batch中的数据统一到相同的尺寸。</p>
<p>假设节点数<code class="docutils literal notranslate"><span class="pre">node_size</span></code>与边数<code class="docutils literal notranslate"><span class="pre">edge_size</span></code>，并满足batch内所有图数据的节点数之和与边数之和都要都小于等于<code class="docutils literal notranslate"><span class="pre">node_size</span> <span class="pre">*</span> <span class="pre">batch</span></code>和<code class="docutils literal notranslate"><span class="pre">edge_size</span> <span class="pre">*</span> <span class="pre">batch</span></code>。
在batch内新建张虚拟图，使得batch内图节点数和、边数和等于<code class="docutils literal notranslate"><span class="pre">node_size</span> <span class="pre">*</span> <span class="pre">batch</span></code>和<code class="docutils literal notranslate"><span class="pre">edge_size</span> <span class="pre">*</span> <span class="pre">batch</span></code>。在计算loss时，这张图将不参与计算。</p>
<p>调用mindspore_gl.graph.PadArray2d定义节点和边特征填充的操作，将虚拟图上的节点特征和边特征都设置为0。
调用mindspore_gl.graph.PadHomoGraph定义对图结构上的节点和边进行填充的操作，使得batch内节点数等于<code class="docutils literal notranslate"><span class="pre">node_size</span> <span class="pre">*</span> <span class="pre">batch</span></code>，边数等于<code class="docutils literal notranslate"><span class="pre">edge_size</span> <span class="pre">*</span> <span class="pre">batch</span></code>。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MultiHomoGraphDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;MultiHomoGraph Dataset&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">CONST</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">edge_size</span><span class="o">=</span><span class="mi">350</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span> <span class="o">=</span> <span class="n">dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_length</span> <span class="o">=</span> <span class="n">length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_fn</span> <span class="o">=</span> <span class="n">BatchHomoGraph</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batched_edge_feat</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">node_size</span> <span class="o">*=</span> <span class="n">batch_size</span>
        <span class="n">edge_size</span> <span class="o">*=</span> <span class="n">batch_size</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">PadMode</span><span class="o">.</span><span class="n">CONST</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">node_feat_pad_op</span> <span class="o">=</span> <span class="n">PadArray2d</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">CONST</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="n">PadDirection</span><span class="o">.</span><span class="n">COL</span><span class="p">,</span>
                                               <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">node_size</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">node_feat_size</span><span class="p">),</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">edge_feat_pad_op</span> <span class="o">=</span> <span class="n">PadArray2d</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">CONST</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="n">PadDirection</span><span class="o">.</span><span class="n">COL</span><span class="p">,</span>
                                               <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">edge_size</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">edge_feat_size</span><span class="p">),</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_pad_op</span> <span class="o">=</span> <span class="n">PadHomoGraph</span><span class="p">(</span><span class="n">n_edge</span><span class="o">=</span><span class="n">edge_size</span><span class="p">,</span> <span class="n">n_node</span><span class="o">=</span><span class="n">node_size</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">CONST</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">node_feat_pad_op</span> <span class="o">=</span> <span class="n">PadArray2d</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="n">PadDirection</span><span class="o">.</span><span class="n">COL</span><span class="p">,</span>
                                               <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">edge_feat_pad_op</span> <span class="o">=</span> <span class="n">PadArray2d</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="n">PadDirection</span><span class="o">.</span><span class="n">COL</span><span class="p">,</span>
                                               <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_pad_op</span> <span class="o">=</span> <span class="n">PadHomoGraph</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">PadMode</span><span class="o">.</span><span class="n">AUTO</span><span class="p">)</span>

        <span class="c1"># For Padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="kc">True</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_mask</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_graph_idx</span><span class="p">):</span>
        <span class="n">graph_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">feature_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_graph_idx</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">graph_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="p">[</span><span class="n">batch_graph_idx</span><span class="p">[</span><span class="n">idx</span><span class="p">]])</span>
            <span class="n">feature_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="o">.</span><span class="n">graph_node_feat</span><span class="p">(</span><span class="n">batch_graph_idx</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>

        <span class="c1"># Batch Graph</span>
        <span class="n">batch_graph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_fn</span><span class="p">(</span><span class="n">graph_list</span><span class="p">)</span>

        <span class="c1"># Pad Graph</span>
        <span class="n">batch_graph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_pad_op</span><span class="p">(</span><span class="n">batch_graph</span><span class="p">)</span>

        <span class="c1"># Batch Node Feat</span>
        <span class="n">batched_node_feat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">feature_list</span><span class="p">)</span>

        <span class="c1"># Pad NodeFeat</span>
        <span class="n">batched_node_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_feat_pad_op</span><span class="p">(</span><span class="n">batched_node_feat</span><span class="p">)</span>
        <span class="n">batched_label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="o">.</span><span class="n">graph_label</span><span class="p">[</span><span class="n">batch_graph_idx</span><span class="p">]</span>

        <span class="c1"># Pad Label</span>
        <span class="n">batched_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batched_label</span><span class="p">,</span> <span class="n">batched_label</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Get Edge Feat</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batched_edge_feat</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">batched_edge_feat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">batch_graph</span><span class="o">.</span><span class="n">edge_count</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">batched_edge_feat</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batched_edge_feat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">batch_graph</span><span class="o">.</span><span class="n">edge_count</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># Trigger Node_Map_Idx/Edge_Map_Idx Computation, Because It Is Lazily Computed</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">batch_graph</span><span class="o">.</span><span class="n">batch_meta</span><span class="o">.</span><span class="n">node_map_idx</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">batch_graph</span><span class="o">.</span><span class="n">batch_meta</span><span class="o">.</span><span class="n">edge_map_idx</span>

        <span class="n">np_graph_mask</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">np_graph_mask</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">constant_graph_mask</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np_graph_mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="n">batchedgraphfiled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_batched_graph_field</span><span class="p">(</span><span class="n">batch_graph</span><span class="p">,</span> <span class="n">constant_graph_mask</span><span class="p">)</span>
        <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">node_count</span><span class="p">,</span> <span class="n">edge_count</span><span class="p">,</span> <span class="n">node_map_idx</span><span class="p">,</span> <span class="n">edge_map_idx</span><span class="p">,</span> <span class="n">graph_mask</span> <span class="o">=</span> <span class="n">batchedgraphfiled</span><span class="o">.</span><span class="n">get_batched_graph</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">node_count</span><span class="p">,</span> <span class="n">edge_count</span><span class="p">,</span> <span class="n">node_map_idx</span><span class="p">,</span> <span class="n">edge_map_idx</span><span class="p">,</span> <span class="n">graph_mask</span><span class="p">,</span> <span class="n">batched_label</span><span class="p">,</span>\
               <span class="n">batched_node_feat</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batched_edge_feat</span><span class="p">[:</span><span class="n">batch_graph</span><span class="o">.</span><span class="n">edge_count</span><span class="p">,</span> <span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="section" id="定义loss函数">
<h2>定义loss函数<a class="headerlink" href="#定义loss函数" title="永久链接至标题">¶</a></h2>
<p>由于本次任务为分类任务，可以采用交叉熵来作为损失函数，实现方法与<a class="reference external" href="https://www.mindspore.cn/graphlearning/docs/zh-CN/r0.2/full_training_of_GCN.html#%E5%AE%9A%E4%B9%89loss%E5%87%BD%E6%95%B0">GCN</a>类似。</p>
<p>与GCN不同的是，本次教程为图分类，因此在解析批次图时，调用的为mindspore_gl.BatchedGraph接口。</p>
<p>在<code class="docutils literal notranslate"><span class="pre">g.graph_mask</span></code>中最后一位为虚拟图的mask，等于0，因此在计算loss时，最后1个值也为0。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LossNet</span><span class="p">(</span><span class="n">GNNCell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; LossNet definition &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_feat</span><span class="p">,</span> <span class="n">edge_weight</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">g</span><span class="p">:</span> <span class="n">BatchedGraph</span><span class="p">):</span>
        <span class="n">predict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">node_feat</span><span class="p">,</span> <span class="n">edge_weight</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">()(</span><span class="n">target</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()(</span><span class="n">loss</span> <span class="o">*</span> <span class="n">g</span><span class="o">.</span><span class="n">graph_mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
</div>
<div class="section" id="网络训练和验证">
<h2>网络训练和验证<a class="headerlink" href="#网络训练和验证" title="永久链接至标题">¶</a></h2>
<div class="section" id="设置环境变量">
<h3>设置环境变量<a class="headerlink" href="#设置环境变量" title="永久链接至标题">¶</a></h3>
<p>环境变量设置方法可以<a class="reference external" href="https://www.mindspore.cn/graphlearning/docs/zh-CN/r0.2/full_training_of_GCN.html#%E8%AE%BE%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">GCN</a>。</p>
</div>
<div class="section" id="定义训练网络">
<h3>定义训练网络<a class="headerlink" href="#定义训练网络" title="永久链接至标题">¶</a></h3>
<p>实例化模型主体GinNet以及LossNet和优化器。
将LossNet实例和optimizer传入mindspore.nn.TrainOneStepCell构建一个单步训练网络train_net。
实现方法与GCN类似，可以参考<a class="reference external" href="https://www.mindspore.cn/graphlearning/docs/zh-CN/r0.2/full_training_of_GCN.html#%E5%AE%9A%E4%B9%89%E8%AE%AD%E7%BB%83%E7%BD%91%E7%BB%9C">GCN</a>。</p>
</div>
<div class="section" id="网络训练及验证">
<h3>网络训练及验证<a class="headerlink" href="#网络训练及验证" title="永久链接至标题">¶</a></h3>
<p>由于是批次图训练，构图时调用的API为mindspore_gl.BatchedGraphField，与mindspore_gl.GraphField不同的是，增加了<code class="docutils literal notranslate"><span class="pre">node_map_idx</span></code>、<code class="docutils literal notranslate"><span class="pre">edge_map_idx</span></code>、<code class="docutils literal notranslate"><span class="pre">graph_mask</span></code>三个参数。
其中在<code class="docutils literal notranslate"><span class="pre">graph_mask</span></code>为batch中每个图的掩码信息，由于最后1张图为虚构图，因此在<code class="docutils literal notranslate"><span class="pre">graph_mask</span></code>数组中，最后1位为0，其余为1。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_gl</span> <span class="kn">import</span> <span class="n">BatchedGraph</span><span class="p">,</span> <span class="n">BatchedGraphField</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
    <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">node_count</span><span class="p">,</span> <span class="n">edge_count</span><span class="p">,</span> <span class="n">node_map_idx</span><span class="p">,</span> <span class="n">edge_map_idx</span><span class="p">,</span> <span class="n">graph_mask</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">node_feat</span><span class="p">,</span> <span class="n">edge_feat</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">batch_homo</span> <span class="o">=</span> <span class="n">BatchedGraphField</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">node_count</span><span class="p">,</span> <span class="n">edge_count</span><span class="p">,</span> <span class="n">node_map_idx</span><span class="p">,</span> <span class="n">edge_map_idx</span><span class="p">,</span> <span class="n">graph_mask</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">node_feat</span><span class="p">,</span> <span class="n">edge_feat</span><span class="p">,</span> <span class="o">*</span><span class="n">batch_homo</span><span class="o">.</span><span class="n">get_batched_graph</span><span class="p">())</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="执行并查看结果">
<h2>执行并查看结果<a class="headerlink" href="#执行并查看结果" title="永久链接至标题">¶</a></h2>
<div class="section" id="运行过程">
<h3>运行过程<a class="headerlink" href="#运行过程" title="永久链接至标题">¶</a></h3>
<p>运行程序后，进行代码翻译并开始训练。</p>
</div>
<div class="section" id="执行结果">
<h3>执行结果<a class="headerlink" href="#执行结果" title="永久链接至标题">¶</a></h3>
<p>执行脚本<a class="reference external" href="https://gitee.com/mindspore/graphlearning/blob/r0.2.0/model_zoo/gin/trainval_imdb_binary.py">trainval_imdb_binary.py</a>启动训练。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>model_zoo/gin
python<span class="w"> </span>trainval_imdb_binary.py<span class="w"> </span>--data_path<span class="o">={</span>path<span class="o">}</span>
</pre></div>
</div>
<p>其中<code class="docutils literal notranslate"><span class="pre">{path}</span></code>为数据集存放路径。</p>
<p>可以看到训练的结果如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>...
Epoch<span class="w"> </span><span class="m">52</span>,<span class="w"> </span>Time<span class="w"> </span><span class="m">3</span>.547<span class="w"> </span>s,<span class="w"> </span>Train<span class="w"> </span>loss<span class="w"> </span><span class="m">0</span>.49981827,<span class="w"> </span>Train<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.74219,<span class="w"> </span>Test<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.594
Epoch<span class="w"> </span><span class="m">53</span>,<span class="w"> </span>Time<span class="w"> </span><span class="m">3</span>.599<span class="w"> </span>s,<span class="w"> </span>Train<span class="w"> </span>loss<span class="w"> </span><span class="m">0</span>.5046462,<span class="w"> </span>Train<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.74219,<span class="w"> </span>Test<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.656
Epoch<span class="w"> </span><span class="m">54</span>,<span class="w"> </span>Time<span class="w"> </span><span class="m">3</span>.505<span class="w"> </span>s,<span class="w"> </span>Train<span class="w"> </span>loss<span class="w"> </span><span class="m">0</span>.49653444,<span class="w"> </span>Train<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.74777,<span class="w"> </span>Test<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.766
Epoch<span class="w"> </span><span class="m">55</span>,<span class="w"> </span>Time<span class="w"> </span><span class="m">3</span>.468<span class="w"> </span>s,<span class="w"> </span>Train<span class="w"> </span>loss<span class="w"> </span><span class="m">0</span>.49411067,<span class="w"> </span>Train<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.74219,<span class="w"> </span>Test<span class="w"> </span>acc<span class="w"> </span><span class="m">0</span>.750
</pre></div>
</div>
<p>在IMDBBinary最好的验证精度为：0.766</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="spatio_temporal_graph_training_STGCN.html" class="btn btn-neutral float-right" title="时空图训练网络" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="full_training_of_GCN.html" class="btn btn-neutral float-left" title="整图训练网络" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>