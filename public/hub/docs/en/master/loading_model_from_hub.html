<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Loading the Model from Hub &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Publishing Models using MindSpore Hub" href="publish_model.html" />
    <link rel="prev" title="MindSpore Hub Installation" href="hub_installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="hub_installation.html">MindSpore Hub Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Loading the Model from Hub</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#for-inference-validation">For Inference Validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#for-transfer-training">For Transfer Training</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="publish_model.html">Publishing Models using MindSpore Hub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="hub.html">mindspore_hub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/resources/hub/">MindSpore Hub↗</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Loading the Model from Hub</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/loading_model_from_hub.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="loading-the-model-from-hub">
<h1>Loading the Model from Hub<a class="headerlink" href="#loading-the-model-from-hub" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/hub/docs/source_en/loading_model_from_hub.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>For individual developers, training a better model from scratch requires a lot of well-labeled data, sufficient computational resources, and a lot of training and debugging time. It makes model training very resource-consuming and raises the threshold of AI development. To solve the above problems, MindSpore Hub provides a lot of model weight files with completed training, which can enable developers to quickly train a better model with a small amount of data and only a small amount of training time.</p>
<p>This document demonstrates the use of the models provided by MindSpore Hub for both inference verification and migration learning, and shows how to quickly complete training with a small amount of data to get a better model.</p>
</section>
<section id="for-inference-validation">
<h2>For Inference Validation<a class="headerlink" href="#for-inference-validation" title="Permalink to this headline"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">mindspore_hub.load</span></code> API is used to load the pre-trained model in a single line of code. The main process of model loading is as follows:</p>
<ol class="arabic">
<li><p>Search the model of interest on <a class="reference external" href="https://www.mindspore.cn/resources/hub">MindSpore Hub Website</a>.</p>
<p>For example, if you aim to perform image classification on CIFAR-10 dataset using GoogleNet, please search on <a class="reference external" href="https://www.mindspore.cn/resources/hub">MindSpore Hub Website</a> with the keyword <code class="docutils literal notranslate"><span class="pre">GoogleNet</span></code>. Then all related models will be returned. Once you enter into the related model page, you can find the <code class="docutils literal notranslate"><span class="pre">Usage</span></code>. <strong>Notices</strong>: if the model page doesn’t have <code class="docutils literal notranslate"><span class="pre">Usage</span></code>, it means that the current model does not support loading with MindSpore Hub temporarily.</p>
</li>
<li><p>Complete the task of loading model according to the <code class="docutils literal notranslate"><span class="pre">Usage</span></code> , as shown in the example below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore_hub</span> <span class="k">as</span> <span class="nn">mshub</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">Model</span><span class="p">,</span> <span class="n">set_context</span><span class="p">,</span> <span class="n">GRAPH_MODE</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision</span> <span class="k">as</span> <span class="nn">vision</span>

<span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">GRAPH_MODE</span><span class="p">,</span>
            <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">,</span>
            <span class="n">device_id</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="s2">&quot;mindspore/1.6/googlenet_cifar10&quot;</span>

<span class="c1"># Initialize the number of classes based on the pre-trained model.</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">mshub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">network</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># ...</span>

</pre></div>
</div>
</li>
<li><p>After loading the model, you can use MindSpore to do inference. You can refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/infer/inference.html">Multi-Platform Inference Overview</a>.</p></li>
</ol>
</section>
<section id="for-transfer-training">
<h2>For Transfer Training<a class="headerlink" href="#for-transfer-training" title="Permalink to this headline"></a></h2>
<p>When loading a model with <code class="docutils literal notranslate"><span class="pre">mindspore_hub.load</span></code> API, we can add an extra argument to load the feature extraction part of the model only. So we can easily add new layers to perform transfer learning. This feature can be found in the related model page when an extra argument (e.g., include_top) has been integrated into the model construction by the model developer. The value of <code class="docutils literal notranslate"><span class="pre">include_top</span></code> is True or False, indicating whether to keep the top layer in the fully-connected network.</p>
<p>We use <a class="reference external" href="https://gitee.com/mindspore/models/tree/master/research/cv/centerface">MobileNetV2</a> as an example to illustrate how to load a model trained on the ImageNet dataset and then perform transfer learning (re-training) on a specific sub-task dataset. The main steps are listed below:</p>
<ol class="arabic">
<li><p>Search the model of interest on <a class="reference external" href="https://www.mindspore.cn/resources/hub/">MindSpore Hub Website</a> and find the corresponding <code class="docutils literal notranslate"><span class="pre">Usage</span></code>.</p></li>
<li><p>Load the model from MindSpore Hub using the <code class="docutils literal notranslate"><span class="pre">Usage</span></code>. Note that the parameter <code class="docutils literal notranslate"><span class="pre">include_top</span></code> is provided by the model developer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore_hub</span> <span class="k">as</span> <span class="nn">mshub</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">set_context</span><span class="p">,</span> <span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">train</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Momentum</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">save_checkpoint</span><span class="p">,</span> <span class="n">load_checkpoint</span><span class="p">,</span><span class="n">load_param_into_net</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision</span> <span class="k">as</span> <span class="nn">vision</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">,</span> <span class="n">device_id</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="s2">&quot;mindspore/1.6/mobilenetv2_imagenet2012&quot;</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">mshub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;Sigmoid&quot;</span><span class="p">)</span>
<span class="n">network</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Add a new classification layer into current model architecture.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ReduceMeanFlatten</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
      <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
         <span class="nb">super</span><span class="p">(</span><span class="n">ReduceMeanFlatten</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">(</span><span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>

      <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
         <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
         <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
         <span class="k">return</span> <span class="n">x</span>

<span class="c1"># Check MindSpore Hub website to conclude that the last output shape is 1280.</span>
<span class="n">last_channel</span> <span class="o">=</span> <span class="mi">1280</span>

<span class="c1"># The number of classes in target task is 10.</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">reducemean_flatten</span> <span class="o">=</span> <span class="n">ReduceMeanFlatten</span><span class="p">()</span>

<span class="n">classification_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">last_channel</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="n">classification_layer</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">train_network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span><span class="n">network</span><span class="p">,</span> <span class="n">reducemean_flatten</span><span class="p">,</span> <span class="n">classification_layer</span><span class="p">])</span>
</pre></div>
</div>
</li>
<li><p>Define <code class="docutils literal notranslate"><span class="pre">dataset_loader</span></code>.</p>
<p>As shown below， the new dataset used for fine-tuning is the <a class="reference external" href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a>. It is noted here we need to download the <code class="docutils literal notranslate"><span class="pre">binary</span> <span class="pre">version</span></code> dataset. After downloading and decompression, the following code can be used for data loading and processing. It is noted the <code class="docutils literal notranslate"><span class="pre">dataset_path</span></code> is the path to the dataset and should be given by the user.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_cifar10dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">usage</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">dataset_dir</span><span class="o">=</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">usage</span><span class="o">=</span><span class="n">usage</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span>

    <span class="c1"># define map operations</span>
    <span class="n">trans</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="p">]</span>

    <span class="n">type_cast_op</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">type_cast_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">trans</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="c1"># apply batch operations</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data_set</span>

<span class="c1"># Create Dataset</span>
<span class="n">dataset_path</span> <span class="o">=</span> <span class="s2">&quot;/path_to_dataset/cifar-10-batches-bin&quot;</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">create_cifar10dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">usage</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Define <code class="docutils literal notranslate"><span class="pre">loss</span></code>, <code class="docutils literal notranslate"><span class="pre">optimizer</span></code> and <code class="docutils literal notranslate"><span class="pre">learning</span> <span class="pre">rate</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_steps_lr</span><span class="p">(</span><span class="n">lr_init</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="p">,</span> <span class="n">total_epochs</span><span class="p">):</span>
    <span class="n">total_steps</span> <span class="o">=</span> <span class="n">total_epochs</span> <span class="o">*</span> <span class="n">steps_per_epoch</span>
    <span class="n">decay_epoch_index</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.3</span><span class="o">*</span><span class="n">total_steps</span><span class="p">,</span> <span class="mf">0.6</span><span class="o">*</span><span class="n">total_steps</span><span class="p">,</span> <span class="mf">0.8</span><span class="o">*</span><span class="n">total_steps</span><span class="p">]</span>
    <span class="n">lr_each_step</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_steps</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">decay_epoch_index</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">lr_init</span>
        <span class="k">elif</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">decay_epoch_index</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">lr_init</span> <span class="o">*</span> <span class="mf">0.1</span>
        <span class="k">elif</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">decay_epoch_index</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">lr_init</span> <span class="o">*</span> <span class="mf">0.01</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">lr_init</span> <span class="o">*</span> <span class="mf">0.001</span>
        <span class="n">lr_each_step</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lr_each_step</span>

<span class="c1"># Set epoch size</span>
<span class="n">epoch_size</span> <span class="o">=</span> <span class="mi">60</span>

<span class="c1"># Wrap the backbone network with loss.</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="n">loss_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">WithLossCell</span><span class="p">(</span><span class="n">train_network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>
<span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">generate_steps_lr</span><span class="p">(</span><span class="n">lr_init</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span> <span class="n">total_epochs</span><span class="o">=</span><span class="n">epoch_size</span><span class="p">)</span>

<span class="c1"># Create an optimizer.</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">classification_layer</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()),</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">4e-5</span><span class="p">)</span>
<span class="n">train_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">loss_net</span><span class="p">,</span> <span class="n">optim</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Start fine-tuning.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_size</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">items</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">items</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">train_net</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epoch_size</span><span class="si">}</span><span class="s2">, loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># Save the ckpt file for each epoch.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">&#39;ckpt&#39;</span><span class="p">):</span>
       <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s1">&#39;ckpt&#39;</span><span class="p">)</span>
    <span class="n">ckpt_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;./ckpt/cifar10_finetune_epoch</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">.ckpt&quot;</span>
    <span class="n">save_checkpoint</span><span class="p">(</span><span class="n">train_network</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Eval on test set.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="s2">&quot;mindspore/1.6/mobilenetv2_imagenet2012&quot;</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">mshub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;Sigmoid&quot;</span><span class="p">)</span>
<span class="n">network</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">reducemean_flatten</span> <span class="o">=</span> <span class="n">ReduceMeanFlatten</span><span class="p">()</span>
<span class="n">classification_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">last_channel</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="n">classification_layer</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span><span class="n">network</span><span class="p">,</span> <span class="n">reducemean_flatten</span><span class="p">,</span> <span class="n">classification_layer</span><span class="p">,</span> <span class="n">softmax</span><span class="p">])</span>

<span class="c1"># Load a pre-trained ckpt file.</span>
<span class="n">ckpt_path</span> <span class="o">=</span> <span class="s2">&quot;./ckpt/cifar10_finetune_epoch59.ckpt&quot;</span>
<span class="n">trained_ckpt</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">)</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">classification_layer</span><span class="p">,</span> <span class="n">trained_ckpt</span><span class="p">)</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>

<span class="c1"># Define loss and create model.</span>
<span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">create_cifar10dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">do_train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">eval_metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Loss&#39;</span><span class="p">:</span> <span class="n">train</span><span class="o">.</span><span class="n">Loss</span><span class="p">(),</span>
                 <span class="s1">&#39;Top1-Acc&#39;</span><span class="p">:</span> <span class="n">train</span><span class="o">.</span><span class="n">Top1CategoricalAccuracy</span><span class="p">(),</span>
                 <span class="s1">&#39;Top5-Acc&#39;</span><span class="p">:</span> <span class="n">train</span><span class="o">.</span><span class="n">Top5CategoricalAccuracy</span><span class="p">()}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">eval_metrics</span><span class="p">)</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;metric: &quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="hub_installation.html" class="btn btn-neutral float-left" title="MindSpore Hub Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="publish_model.html" class="btn btn-neutral float-right" title="Publishing Models using MindSpore Hub" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>