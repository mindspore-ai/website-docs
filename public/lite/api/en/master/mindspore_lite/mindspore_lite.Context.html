

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore_lite.Context &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/collapsible-lists/css/tree_view.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
        <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="mindspore_lite.FmkType" href="mindspore_lite.FmkType.html" />
    <link rel="prev" title="mindspore_lite" href="../mindspore_lite.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_NN.html">mindspore::NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_api.html">mindspore::api</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_api_utils.html">mindspore::api::utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_converter.html">mindspore::converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_dataset.html">mindspore::dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_dataset_config.html">mindspore::dataset::config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_dataset_text.html">mindspore::dataset::text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_dataset_transforms.html">mindspore::dataset::transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_dataset_vision.html">mindspore::dataset::vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_kernel.html">mindspore::kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_ops.html">mindspore::ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_registry.html">mindspore::registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_registry_opencl.html">mindspore::registry::opencl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/lite_cpp_example.html">Example</a></li>
</ul>
<p class="caption"><span class="caption-text">JAVA API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_java/class_list.html">Class List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/model_parallel_runner.html">ModelParallelRunner</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/mscontext.html">MSContext</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/mstensor.html">MSTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/runner_config.html">RunnerConfig</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/graph.html">Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/lite_java_example.html">Example</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore_lite.html">mindspore_lite</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore_lite.html#context">Context</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">mindspore_lite.Context</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore_lite.html#converter">Converter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore_lite.html#model">Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore_lite.html#tensor">Tensor</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">C API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_c/context_c.html">context_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/data_type_c.html">data_type_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/format_c.html">format_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/lite_c_example.html">Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/model_c.html">model_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/tensor_c.html">tensor_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/types_c.html">types_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/lite_c_example.html">Example</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../mindspore_lite.html">mindspore_lite</a> &raquo;</li>
        
      <li>mindspore_lite.Context</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/mindspore_lite/mindspore_lite.Context.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="mindspore-lite-context">
<h1>mindspore_lite.Context<a class="headerlink" href="#mindspore-lite-context" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="mindspore_lite.Context">
<em class="property">class </em><code class="sig-prename descclassname">mindspore_lite.</code><code class="sig-name descname">Context</code><a class="reference internal" href="../_modules/mindspore_lite/context.html#Context"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore_lite.Context" title="Permalink to this definition">¶</a></dt>
<dd><p>The <cite>Context</cite> class is used to transfer environment variables during execution.</p>
<p>The context should be configured before running the program.
If it is not configured, it will be set cpu target, and automatically set cpu attributes by default.</p>
<p>Context.parallel defines the context and configuration of <cite>ModelParallelRunner</cite> class.</p>
<dl>
<dt>Context.parallel properties:</dt><dd><ul>
<li><p><strong>workers_num</strong> (int) - the num of workers. A <cite>ModelParallelRunner</cite> contains multiple workers, which
are the units that actually perform parallel inferring. Setting <cite>workers_num</cite> to 0 represents
<cite>workers_num</cite> will be automatically adjusted based on computer performance and core numbers.</p></li>
<li><p><strong>config_info</strong> (dict{str, dict{str, str}}) - Nested map for passing model weight paths.
For example, {“weight”: {“weight_path”: “/home/user/weight.cfg”}}.
key currently supports [“weight”];
value is in dict format, key of it currently supports [“weight_path”],
value of it is the path of weight, For example, “/home/user/weight.cfg”.</p></li>
<li><p><strong>config_path</strong> (str) - Set the config file path. The config file is used to transfer user-defined
options during building <cite>ModelParallelRunner</cite> . In the following scenarios, users may need to set the
parameter. For example, “/home/user/config.txt”.</p>
<ul>
<li><p>Usage 1: Set mixed precision inference. The content and description of the configuration file are as
follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">execution_plan</span><span class="p">]</span>
<span class="p">[</span><span class="n">op_name1</span><span class="p">]</span><span class="o">=</span><span class="n">data_Type</span><span class="p">:</span> <span class="n">float16</span> <span class="p">(</span><span class="n">The</span> <span class="n">operator</span> <span class="n">named</span> <span class="n">op_name1</span> <span class="n">sets</span> <span class="n">the</span> <span class="n">data</span> <span class="nb">type</span> <span class="k">as</span> <span class="n">Float16</span><span class="p">)</span>
<span class="p">[</span><span class="n">op_name2</span><span class="p">]</span><span class="o">=</span><span class="n">data_Type</span><span class="p">:</span> <span class="n">float32</span> <span class="p">(</span><span class="n">The</span> <span class="n">operator</span> <span class="n">named</span> <span class="n">op_name2</span> <span class="n">sets</span> <span class="n">the</span> <span class="n">data</span> <span class="nb">type</span> <span class="k">as</span> <span class="n">Float32</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Usage 2: When GPU inference, set the configuration of TensorRT. The content and description of the
configuration file are as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">ms_cache</span><span class="p">]</span>
<span class="n">serialize_Path</span><span class="o">=</span><span class="p">[</span><span class="n">serialization</span> <span class="n">model</span> <span class="n">path</span><span class="p">](</span><span class="n">storage</span> <span class="n">path</span> <span class="n">of</span> <span class="n">serialization</span> <span class="n">model</span><span class="p">)</span>
<span class="p">[</span><span class="n">gpu_context</span><span class="p">]</span>
<span class="n">input_shape</span><span class="o">=</span><span class="n">input_Name</span><span class="p">:</span> <span class="p">[</span><span class="n">input_dim</span><span class="p">]</span> <span class="p">(</span><span class="n">Model</span> <span class="nb">input</span> <span class="n">dimension</span><span class="p">,</span> <span class="k">for</span> <span class="n">dynamic</span> <span class="n">shape</span><span class="p">)</span>
<span class="n">dynamic_Dims</span><span class="o">=</span><span class="p">[</span><span class="n">min_dim</span><span class="o">~</span><span class="n">max_dim</span><span class="p">]</span> <span class="p">(</span><span class="n">dynamic</span> <span class="n">dimension</span> <span class="nb">range</span> <span class="n">of</span> <span class="n">model</span> <span class="nb">input</span><span class="p">,</span> <span class="k">for</span> <span class="n">dynamic</span> <span class="n">shape</span><span class="p">)</span>
<span class="n">opt_Dims</span><span class="o">=</span><span class="p">[</span><span class="n">opt_dim</span><span class="p">]</span> <span class="p">(</span><span class="n">the</span> <span class="n">optimal</span> <span class="nb">input</span> <span class="n">dimension</span> <span class="n">of</span> <span class="n">the</span> <span class="n">model</span><span class="p">,</span> <span class="k">for</span> <span class="n">dynamic</span> <span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># create default context, which target is cpu by default.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore_lite</span> <span class="k">as</span> <span class="nn">mslite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Context</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
<span class="go">target: [&quot;cpu&quot;].</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># testcase 2 about context&#39;s attribute parallel based on server inference package</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># (export MSLITE_ENABLE_SERVER_INFERENCE=on before compile lite or use cloud inference package)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore_lite</span> <span class="k">as</span> <span class="nn">mslite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Context</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;cpu&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">workers_num</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">config_info</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;weight_path&quot;</span><span class="p">:</span> <span class="s2">&quot;/home/user/weight.cfg&quot;</span><span class="p">}}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">config_path</span> <span class="o">=</span> <span class="s2">&quot;/home/user/config.txt&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">parallel</span><span class="p">)</span>
<span class="go">workers num: 4,</span>
<span class="go">config info: weight: weight_path /home/user/weight.cfg,</span>
<span class="go">config path: /home/user/config.txt.</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore_lite.Context.target">
<em class="property">property </em><code class="sig-name descname">target</code><a class="headerlink" href="#mindspore_lite.Context.target" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the target device information of context.</p>
<p>Currently support target: [“cpu”] | [“gpu”] | [“ascend”].</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>After gpu is added to target, cpu will be added automatically as the backup target.
Because when ops are not supported on gpu, The system will try whether the cpu supports it.
At that time, need to switch to the context with cpu.</p>
<p>After Ascend is added, cpu will be added automatically as the backup target. when the inputs format of the
original model is inconsistent with that of the model generated by Converter, the model generated by
Converter on Ascend device will contain the ‘Transpose’ node, which needs to be executed on the cpu device
currently. So it needs to switch to the context with cpu target.</p>
</div>
<dl class="simple">
<dt>cpu properties:</dt><dd><ul class="simple">
<li><p><strong>inter_op_parallel_num</strong> (int) - Set the parallel number of operators at runtime.
<cite>inter_op_parallel_num</cite> cannot be greater than <cite>thread_num</cite> . Setting <cite>inter_op_parallel_num</cite>
to 0 represents <cite>inter_op_parallel_num</cite> will be automatically adjusted based on computer
performance and core num.</p></li>
<li><p><strong>precision_mode</strong> (str) - Set the mix precision mode. Options are “preferred_fp16” |
“enforce_fp32”.</p>
<ul>
<li><p>“preferred_fp16”: prefer to use fp16.</p></li>
<li><p>“enforce_fp32”: force to use fp32.</p></li>
</ul>
</li>
<li><p><strong>thread_num</strong> (int) - Set the number of threads at runtime. <cite>thread_num</cite> cannot be less than
<cite>inter_op_parallel_num</cite> . Setting <cite>thread_num</cite> to 0 represents <cite>thread_num</cite> will be automatically
adjusted based on computer performance and core numbers.</p></li>
<li><p><strong>thread_affinity_mode</strong> (int) - Set the mode of the CPU core binding policy at runtime. The
following <cite>thread_affinity_mode</cite> are supported.</p>
<ul>
<li><p>0: no binding core.</p></li>
<li><p>1: binding big cores first.</p></li>
<li><p>2: binding middle cores first.</p></li>
</ul>
</li>
<li><p><strong>thread_affinity_core_list</strong> (list[int]) - Set the list of CPU core binding policies at runtime.
For example, [0,1] represents the specified binding of CPU0 and CPU1.</p></li>
</ul>
</dd>
<dt>gpu properties:</dt><dd><ul class="simple">
<li><p><strong>device_id</strong> (int) - The device id.</p></li>
<li><p><strong>group_size</strong> (int) - the number of the clusters. Get only, not settable.</p></li>
<li><p><strong>precision_mode</strong> (str) - Set the mix precision mode. Options are “preferred_fp16” | “enforce_fp32”.</p>
<ul>
<li><p>“preferred_fp16”: prefer to use fp16.</p></li>
<li><p>“enforce_fp32”: force to use fp32.</p></li>
</ul>
</li>
<li><p><strong>rank_id</strong> (int) - the ID of the current device in the cluster, which starts from 0. Get only,
not settable.</p></li>
</ul>
</dd>
<dt>ascend properties:</dt><dd><ul class="simple">
<li><p><strong>device_id</strong> (int) - The device id.</p></li>
<li><p><strong>precision_mode</strong> (str) - Set the mix precision mode. Options are “enforce_fp32” | “preferred_fp32” |
“enforce_fp16” | “enforce_origin” | “preferred_optimal”.</p>
<ul>
<li><p>“enforce_fp32”: ACL option is force_fp32, force to use fp32.</p></li>
<li><p>“preferred_fp32”: ACL option is force_fp32, prefer to use fp32.</p></li>
<li><p>“enforce_fp16”: ACL option is force_fp16, force to use fp16.</p></li>
<li><p>“enforce_origin”: ACL option is must_keep_origin_dtype, force to use original type.</p></li>
<li><p>“preferred_optimal”: ACL option is allow_mix_precision, prefer to use fp16+ mix precision mode.</p></li>
</ul>
</li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list[str], the target device information of context.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># create default context, which target is cpu by default.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore_lite</span> <span class="k">as</span> <span class="nn">mslite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Context</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># set context with cpu target.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;cpu&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="go">[&quot;cpu&quot;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">cpu</span><span class="o">.</span><span class="n">precision_mode</span><span class="o">=</span><span class="s2">&quot;preferred_fp16&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">cpu</span><span class="o">.</span><span class="n">thread_num</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">cpu</span><span class="o">.</span><span class="n">inter_op_parallel_num</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">cpu</span><span class="o">.</span><span class="n">thread_affinity_mode</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">cpu</span><span class="o">.</span><span class="n">thread_affinity_core_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># set context with gpu target.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;gpu&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="go">[&quot;gpu&quot;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">gpu</span><span class="o">.</span><span class="n">precision_mode</span> <span class="o">=</span> <span class="s2">&quot;preferred_fp16&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">gpu</span><span class="o">.</span><span class="n">device_id</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">gpu</span><span class="o">.</span><span class="n">rank_id</span><span class="p">)</span>
<span class="go">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">gpu</span><span class="o">.</span><span class="n">group_size</span><span class="p">)</span>
<span class="go">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
<span class="go">device_type: DeviceType:kGPU,</span>
<span class="go">precision_mode: preferred_fp16,</span>
<span class="go">device_id: 2,</span>
<span class="go">rank_id: 0,</span>
<span class="go">group_size: 1.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># set context with ascend target.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ascend&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="go">[&quot;ascend&quot;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">ascend</span><span class="o">.</span><span class="n">precision_mode</span> <span class="o">=</span> <span class="s2">&quot;enforce_fp32&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">ascend</span><span class="o">.</span><span class="n">device_id</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">ascend</span><span class="p">)</span>
<span class="go">device_type: DeviceType:kAscend,</span>
<span class="go">precision_mode: enforce_fp32,</span>
<span class="go">device_id: 2.</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="mindspore_lite.FmkType.html" class="btn btn-neutral float-right" title="mindspore_lite.FmkType" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="../mindspore_lite.html" class="btn btn-neutral float-left" title="mindspore_lite" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>