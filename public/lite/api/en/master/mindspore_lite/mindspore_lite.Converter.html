

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore_lite.Converter &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/collapsible-lists/css/tree_view.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
        <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="mindspore_lite.ModelType" href="mindspore_lite.ModelType.html" />
    <link rel="prev" title="mindspore_lite.FmkType" href="mindspore_lite.FmkType.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_NN.html">mindspore::NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_api.html">mindspore::api</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_api_utils.html">mindspore::api::utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_converter.html">mindspore::converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_dataset.html">mindspore::dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_dataset_config.html">mindspore::dataset::config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_dataset_text.html">mindspore::dataset::text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_dataset_transforms.html">mindspore::dataset::transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_dataset_vision.html">mindspore::dataset::vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_kernel.html">mindspore::kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_ops.html">mindspore::ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_registry.html">mindspore::registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_registry_opencl.html">mindspore::registry::opencl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/lite_cpp_example.html">Example</a></li>
</ul>
<p class="caption"><span class="caption-text">JAVA API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_java/class_list.html">Class List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/model_parallel_runner.html">ModelParallelRunner</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/mscontext.html">MSContext</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/mstensor.html">MSTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/runner_config.html">RunnerConfig</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/graph.html">Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/lite_java_example.html">Example</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore_lite.html">mindspore_lite</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../mindspore_lite.html#context">Context</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore_lite.html#converter">Converter</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="mindspore_lite.FmkType.html">mindspore_lite.FmkType</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">mindspore_lite.Converter</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore_lite.html#model">Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore_lite.html#tensor">Tensor</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">C API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_c/context_c.html">context_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/data_type_c.html">data_type_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/format_c.html">format_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/lite_c_example.html">Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/model_c.html">model_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/tensor_c.html">tensor_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/types_c.html">types_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/lite_c_example.html">Example</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../mindspore_lite.html">mindspore_lite</a> &raquo;</li>
        
      <li>mindspore_lite.Converter</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/mindspore_lite/mindspore_lite.Converter.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="mindspore-lite-converter">
<h1>mindspore_lite.Converter<a class="headerlink" href="#mindspore-lite-converter" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="mindspore_lite.Converter">
<em class="property">class </em><code class="sig-prename descclassname">mindspore_lite.</code><code class="sig-name descname">Converter</code><a class="reference internal" href="../_modules/mindspore_lite/converter.html#Converter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore_lite.Converter" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs a <cite>Converter</cite> class.</p>
<p>Used in the following scenarios:</p>
<ol class="arabic simple">
<li><p>Convert the third-party model into MindSpore model or MindSpore Lite model.</p></li>
<li><p>Convert MindSpore model into MindSpore model or MindSpore Lite model.</p></li>
</ol>
<p>Convert to MindSpore model is recommended. Currently, Convert to MindSpore Lite model is supported,
but it will be deprecated in the future. If you want to convert to MindSpore Lite model, please use
<a class="reference external" href="https://www.mindspore.cn/lite/docs/en/master/use/cloud_infer/converter_tool.html">converter_tool</a>  instead of
The Python interface. The Model api and ModelParallelRunner api only support MindSpore model.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please construct the <cite>Converter</cite> class first, and then generate the model by executing the Converter.convert()
method.</p>
<p>The encryption and decryption function is only valid when it is set to <cite>MSLITE_ENABLE_MODEL_ENCRYPTION=on</cite> at
compile time, and only supports Linux x86 platforms. <cite>decrypt_key</cite> and <cite>encrypt_key</cite> are string expressed in
hexadecimal. For example, if encrypt_key is set as “30313233343637383939414243444546”, the corresponding
hexadecimal expression is ‘(b)0123456789ABCDEF’ . Linux platform users can use the’ xxd ‘tool to convert the
key expressed in bytes into hexadecimal expressions. It should be noted that the encryption and decryption
algorithm has been updated in version 1.7, resulting in the new Python interface does not support the conversion
of MindSpore Lite’s encryption exported models in version 1.6 and earlier.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># testcase 1 based on cloud inference package without train_model.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore_lite</span> <span class="k">as</span> <span class="nn">mslite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Converter</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The ms model may be generated only after converter.convert() is executed after the class is constructed.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">weight_fp16</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inTensor1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">input_format</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Format</span><span class="o">.</span><span class="n">NHWC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">input_data_type</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">DataType</span><span class="o">.</span><span class="n">FLOAT32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">output_data_type</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">DataType</span><span class="o">.</span><span class="n">FLOAT32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">save_type</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">ModelType</span><span class="o">.</span><span class="n">MINDIR</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">decrypt_key</span> <span class="o">=</span> <span class="s2">&quot;30313233343637383939414243444546&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">decrypt_mode</span> <span class="o">=</span> <span class="s2">&quot;AES-GCM&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">enable_encryption</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">encrypt_key</span> <span class="o">=</span> <span class="s2">&quot;30313233343637383939414243444546&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">infer</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">optimize</span> <span class="o">=</span> <span class="s2">&quot;general&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;Ascend&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">section</span> <span class="o">=</span> <span class="s2">&quot;common_quant_param&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config_info_in</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;quant_type&quot;</span><span class="p">:</span> <span class="s2">&quot;WEIGHT_QUANT&quot;</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">set_config_info</span><span class="p">(</span><span class="n">section</span><span class="p">,</span> <span class="n">config_info_in</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">converter</span><span class="o">.</span><span class="n">get_config_info</span><span class="p">())</span>
<span class="go">{&#39;common_quant_param&#39;: {&#39;quant_type&#39;: &#39;WEIGHT_QUANT&#39;}}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">converter</span><span class="p">)</span>
<span class="go">config_info: {&#39;common_quant_param&#39;: {&#39;quant_type&#39;: &#39;WEIGHT_QUANT&#39;}},</span>
<span class="go">weight_fp16: True,</span>
<span class="go">input_shape: {&#39;inTensor1&#39;: [1, 3, 32, 32]},</span>
<span class="go">input_format: Format.NHWC,</span>
<span class="go">input_data_type: DataType.FLOAT32,</span>
<span class="go">output_data_type: DataType.FLOAT32,</span>
<span class="go">save_type: ModelType.MINDIR,</span>
<span class="go">decrypt_key: 30313233343637383939414243444546,</span>
<span class="go">decrypt_mode: AES-GCM,</span>
<span class="go">enable_encryption: True,</span>
<span class="go">encrypt_key: 30313233343637383939414243444546,</span>
<span class="go">infer: True,</span>
<span class="go">optimize: general,</span>
<span class="go">device: Ascend.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># testcase 2 based on lite inference package with train_model.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore_lite</span> <span class="k">as</span> <span class="nn">mslite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Converter</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The ms model may be generated only after converter.convert() is executed after the class is constructed.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">train_model</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">converter</span><span class="o">.</span><span class="n">train_model</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore_lite.Converter.convert">
<code class="sig-name descname">convert</code><span class="sig-paren">(</span><em class="sig-param">fmk_type</em>, <em class="sig-param">model_file</em>, <em class="sig-param">output_file</em>, <em class="sig-param">weight_file=&quot;&quot;</em>, <em class="sig-param">config_file=&quot;&quot;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore_lite/converter.html#Converter.convert"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore_lite.Converter.convert" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform conversion, and convert the third-party model to the MindSpore model or MindSpore Lite model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fmk_type</strong> (<a class="reference internal" href="mindspore_lite.FmkType.html#mindspore_lite.FmkType" title="mindspore_lite.FmkType"><em>FmkType</em></a>) – Input model framework type. Options are FmkType.TF | FmkType.CAFFE |
FmkType.ONNX | FmkType.MINDIR | FmkType.TFLITE | FmkType.PYTORCH. For details, see
<a class="reference external" href="https://mindspore.cn/lite/api/en/master/mindspore_lite/mindspore_lite.FmkType.html">FmkType</a> .</p></li>
<li><p><strong>model_file</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Set the path of the input model when convert. For example, “/home/user/model.prototxt”.
Options are TF: “model.pb” | CAFFE: “model.prototxt” | ONNX: “model.onnx” | MINDIR: “model.mindir” |
TFLITE: “model.tflite” | PYTORCH: “model.pt or model.pth”.</p></li>
<li><p><strong>output_file</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Set the path of the output model. The suffix .ms or .mindir can be automatically
generated. If set <cite>save_type</cite> to ModelType.MINDIR, then MindSpore’s model will be generated, which uses
.mindir as suffix. If set <cite>save_type</cite> to ModelType.MINDIR_LITE, then MindSpore Lite’s model will be
generated, which uses .ms as suffix. For example, the input model is “/home/user/model.prototxt”, set
<cite>save_type</cite> to ModelType.MINDIR, it will generate the model named model.prototxt.mindir in /home/user/.</p></li>
<li><p><strong>weight_file</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – Set the path of input model weight file. Required only when fmk_type is
FmkType.CAFFE. The Caffe model is generally divided into two files: ‘model.prototxt’ is model structure,
corresponding to <cite>model_file</cite> parameter; ‘model.Caffemodel’ is model weight value file, corresponding to
<cite>weight_file</cite> parameter. For example, “/home/user/model.caffemodel”. Default: “”, indicating no weight
file.</p></li>
<li><p><strong>config_file</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – Set the path of the configuration file of Converter can be used to
post-training, offline split op to parallel, disable op fusion ability and set plugin so path.
<cite>config_file</cite> uses the <cite>key = value</cite> method to define the related parameters.
For the configuration parameters related to post training quantization, please refer to
<a class="reference external" href="https://www.mindspore.cn/lite/docs/en/master/use/post_training_quantization.html">quantization</a> .
For the configuration parameters related to extension, please refer to
<a class="reference external" href="https://www.mindspore.cn/lite/docs/en/master/use/nnie.html#extension-configuration">extension</a> .
For example, “/home/user/model.cfg”. Default: “”, indicating that no configuration file.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – <cite>fmk_type</cite> is not a FmkType.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – <cite>model_file</cite> is not a str.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – <cite>output_file</cite> is not a str.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – <cite>weight_file</cite> is not a str.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – <cite>config_file</cite> is not a str.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – <cite>model_file</cite> does not exist.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – <cite>weight_file</cite> is not “”, but <cite>weight_file</cite> does not exist.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – <cite>config_file</cite> is not “”, but <cite>config_file</cite> does not exist.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – convert model failed.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore_lite</span> <span class="k">as</span> <span class="nn">mslite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Converter</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">save_type</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">ModelType</span><span class="o">.</span><span class="n">MINDIR</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">mslite</span><span class="o">.</span><span class="n">FmkType</span><span class="o">.</span><span class="n">TFLITE</span><span class="p">,</span> <span class="s2">&quot;./mobilenetv2/mobilenet_v2_1.0_224.tflite&quot;</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="s2">&quot;mobilenet_v2_1.0_224.tflite&quot;</span><span class="p">)</span>
<span class="go">CONVERT RESULT SUCCESS:0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mobilenet_v2_1.0_224.tflite.mindir model will be generated.</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.decrypt_key">
<em class="property">property </em><code class="sig-name descname">decrypt_key</code><a class="headerlink" href="#mindspore_lite.Converter.decrypt_key" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the key used to decrypt the encrypted MindIR file.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>str, the key used to decrypt the encrypted MindIR file, expressed in hexadecimal characters. Only valid when
fmk_type is FmkType.MINDIR.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.decrypt_mode">
<em class="property">property </em><code class="sig-name descname">decrypt_mode</code><a class="headerlink" href="#mindspore_lite.Converter.decrypt_mode" title="Permalink to this definition">¶</a></dt>
<dd><p>Get decryption mode for the encrypted MindIR file.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>str, decryption mode for the encrypted MindIR file. Only valid when dec_key is set. Options are “AES-GCM” |
“AES-CBC”.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.device">
<em class="property">property </em><code class="sig-name descname">device</code><a class="headerlink" href="#mindspore_lite.Converter.device" title="Permalink to this definition">¶</a></dt>
<dd><p>Get target device when converter model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>str, target device when converter model. Only valid for Ascend. The use case is when on the Ascend device,
if you need to the converted model to have the ability to use Ascend backend to perform inference,
you can set the parameter. If it is not set, the converted model will use CPU backend to perform
inference by default. Option is “Ascend”.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.enable_encryption">
<em class="property">property </em><code class="sig-name descname">enable_encryption</code><a class="headerlink" href="#mindspore_lite.Converter.enable_encryption" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the status whether to encrypt the model when exporting.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>bool, whether to encrypt the model when exporting. Export encryption can protect the integrity of the model,
but it will increase the initialization time at runtime.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.encrypt_key">
<em class="property">property </em><code class="sig-name descname">encrypt_key</code><a class="headerlink" href="#mindspore_lite.Converter.encrypt_key" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the key used to encrypt the model when exporting.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>str, the key used to encrypt the model when exporting, expressed in hexadecimal characters. Only support to
use it when <cite>decrypt_mode</cite> is “AES-GCM”, the key length is 16.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.get_config_info">
<code class="sig-name descname">get_config_info</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore_lite/converter.html#Converter.get_config_info"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore_lite.Converter.get_config_info" title="Permalink to this definition">¶</a></dt>
<dd><p>Get config info of converter.It is used together with <cite>set_config_info</cite> method for online converter.
Please use <cite>set_config_info</cite> method before <cite>get_config_info</cite> .</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dict{str:</span> <span class="pre">dict{str:</span> <span class="pre">str}}</span></code>, the config info which has been set in converter.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore_lite</span> <span class="k">as</span> <span class="nn">mslite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Converter</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">section</span> <span class="o">=</span> <span class="s2">&quot;common_quant_param&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config_info_in</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;quant_type&quot;</span><span class="p">:</span> <span class="s2">&quot;WEIGHT_QUANT&quot;</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">set_config_info</span><span class="p">(</span><span class="n">section</span><span class="p">,</span> <span class="n">config_info_in</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config_info_out</span> <span class="o">=</span> <span class="n">converter</span><span class="o">.</span><span class="n">get_config_info</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">config_info_out</span><span class="p">)</span>
<span class="go">{&#39;common_quant_param&#39;: {&#39;quant_type&#39;: &#39;WEIGHT_QUANT&#39;}}</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.infer">
<em class="property">property </em><code class="sig-name descname">infer</code><a class="headerlink" href="#mindspore_lite.Converter.infer" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the status whether to perform pre-inference at the completion of the conversion.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>bool, whether to perform pre-inference at the completion of the conversion.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.input_data_type">
<em class="property">property </em><code class="sig-name descname">input_data_type</code><a class="headerlink" href="#mindspore_lite.Converter.input_data_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the data type of the quantization model input Tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>DataType, the data type of the quantization model input Tensor. It is only valid when the quantization
parameters ( <cite>scale</cite> and <cite>zero point</cite> ) of the model input Tensor are available. The following 4
DataTypes are supported: DataType.FLOAT32 | DataType.INT8 | DataType.UINT8 | DataType.UNKNOWN.
For details, see
<a class="reference external" href="https://mindspore.cn/lite/api/en/master/mindspore_lite/mindspore_lite.DataType.html">DataType</a> .</p>
<ul class="simple">
<li><p>DataType.FLOAT32: 32-bit floating-point number.</p></li>
<li><p>DataType.INT8:    8-bit integer.</p></li>
<li><p>DataType.UINT8:   unsigned 8-bit integer.</p></li>
<li><p>DataType.UNKNOWN: Set the Same DataType as the model input Tensor.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.input_format">
<em class="property">property </em><code class="sig-name descname">input_format</code><a class="headerlink" href="#mindspore_lite.Converter.input_format" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the input format of model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>Format, the input format of model. Only Valid for 4-dimensional input. The following 2 input formats are
supported: Format.NCHW | Format.NHWC. For details,
see <a class="reference external" href="https://mindspore.cn/lite/api/en/master/mindspore_lite/mindspore_lite.Format.html">Format</a> .</p>
<ul class="simple">
<li><p>Format.NCHW: Store Tensor data in the order of batch N, channel C, height H and width W.</p></li>
<li><p>Format.NHWC: Store Tensor data in the order of batch N, height H, width W and channel C.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.input_shape">
<em class="property">property </em><code class="sig-name descname">input_shape</code><a class="headerlink" href="#mindspore_lite.Converter.input_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the dimension of the model input.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>dict{str, list[int]}, the dimension of the model input. The order of input dimensions is consistent with the
original model. In the following scenarios, users may need to set the parameter.
For example, {“inTensor1”: [1, 32, 32, 32], “inTensor2”: [1, 1, 32, 32]}.</p>
<ul class="simple">
<li><p>Usage 1:The input of the model to be converted is dynamic shape, but prepare to use fixed shape for
inference, then set the parameter to fixed shape. After setting, when inferring on the converted
model, the default input shape is the same as the parameter setting, no need to resize.</p></li>
<li><p>Usage 2: No matter whether the original input of the model to be converted is dynamic shape or not,
but prepare to use fixed shape for inference, and the performance of the model is expected to be
optimized as much as possible, then set the parameter to fixed shape. After setting, the model
structure will be further optimized, but the converted model may lose the characteristics of dynamic
shape(some operators strongly related to shape will be merged).</p></li>
<li><p>Usage 3: When using the converter function to generate code for Micro inference execution, it is
recommended to set the parameter to reduce the probability of errors during deployment. When the model
contains a Shape ops or the input of the model to be converted is a dynamic shape, you must set the
parameter to fixed shape to support the relevant shape optimization and code generation.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.optimize">
<em class="property">property </em><code class="sig-name descname">optimize</code><a class="headerlink" href="#mindspore_lite.Converter.optimize" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the status whether avoid fusion optimization.</p>
<p>optimize is used to set the mode of optimization during the offline conversion. If this parameter is set to
“none”, no relevant graph optimization operations will be performed during the offline conversion phase of
the model, and the relevant graph optimization operations will be performed during the execution of the
inference phase. The advantage of this parameter is that the converted model can be deployed directly to any
CPU/GPU/Ascend hardware backend since it is not optimized in a specific way, while the disadvantage is that
the initialization time of the model increases during inference execution. If this parameter is set to
“general”, general optimization will be performed, such as constant folding and operator fusion (the
converted model only supports CPU/GPU hardware backend, not Ascend backend). If this parameter is set to
“ascend_oriented”, the optimization for Ascend hardware will be performed (the converted model only supports
Ascend hardware backend).</p>
<p>For the MindSpore model, since it is already a <cite>mindir</cite> model, two approaches are suggested:</p>
<ol class="arabic simple">
<li><p>Inference is performed directly without offline conversion.</p></li>
</ol>
<p>2. Setting <cite>optimize</cite> to “general” in CPU/GPU hardware backend and setting <cite>optimize</cite> to “ascend_oriented” in
Ascend hardware when using offline conversion. The relevant optimization is done in the offline phase to reduce
the initialization time of inference execution.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>str, whether avoid fusion optimization. Options are “none” | “general” | “ascend_oriented”. “none” means
fusion optimization is not allowed. “general” and “ascend_oriented” means fusion optimization is allowed.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.output_data_type">
<em class="property">property </em><code class="sig-name descname">output_data_type</code><a class="headerlink" href="#mindspore_lite.Converter.output_data_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the data type of the quantization model output Tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>DataType, the data type of the quantization model output Tensor. It is only valid when the quantization
parameters ( <cite>scale</cite> and <cite>zero point</cite> ) of the model output Tensor are available. The following 4
DataTypes are supported: DataType.FLOAT32 | DataType.INT8 | DataType.UINT8 | DataType.UNKNOWN.
For details, see
<a class="reference external" href="https://mindspore.cn/lite/api/en/master/mindspore_lite/mindspore_lite.DataType.html">DataType</a> .</p>
<ul class="simple">
<li><p>DataType.FLOAT32: 32-bit floating-point number.</p></li>
<li><p>DataType.INT8:    8-bit integer.</p></li>
<li><p>DataType.UINT8:   unsigned 8-bit integer.</p></li>
<li><p>DataType.UNKNOWN: Set the Same DataType as the model output Tensor.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.save_type">
<em class="property">property </em><code class="sig-name descname">save_type</code><a class="headerlink" href="#mindspore_lite.Converter.save_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the model type needs to be export.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>ModelType, the model type needs to be export. Options are ModelType.MINDIR |  ModelType.MINDIR_LITE.
Convert to MindSpore model is recommended. Currently, Convert to MindSpore Lite model is supported,
but it will be deprecated in the future. For details, see
<a class="reference external" href="https://mindspore.cn/lite/api/en/master/mindspore_lite/mindspore_lite.ModelType.html">ModelType</a> .</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.set_config_info">
<code class="sig-name descname">set_config_info</code><span class="sig-paren">(</span><em class="sig-param">section=&quot;&quot;</em>, <em class="sig-param">config_info=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore_lite/converter.html#Converter.set_config_info"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore_lite.Converter.set_config_info" title="Permalink to this definition">¶</a></dt>
<dd><p>Set config info for Converter.It is used together with <cite>get_config_info</cite> method for online converter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>section</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – <p>The category of the configuration parameter.
Set the individual parameters of the configfile together with <cite>config_info</cite> .
For example, for <cite>section</cite> = “common_quant_param”, <cite>config_info</cite> = {“quant_type”: “WEIGHT_QUANT”}.
Default: “”.</p>
<p>For the configuration parameters related to post training quantization, please refer to
<a class="reference external" href="https://www.mindspore.cn/lite/docs/en/master/use/post_training_quantization.html">quantization</a> .</p>
<p>For the configuration parameters related to extension, please refer to
<a class="reference external" href="https://www.mindspore.cn/lite/docs/en/master/use/nnie.html#extension-configuration">extension</a> .</p>
<ul>
<li><p>”common_quant_param”: Common quantization parameter.</p></li>
<li><p>”mixed_bit_weight_quant_param”: Mixed bit weight quantization parameter.</p></li>
<li><p>”full_quant_param”: Full quantization parameter.</p></li>
<li><p>”data_preprocess_param”: Data preprocess quantization parameter.</p></li>
<li><p>”registry”: Extension configuration parameter.</p></li>
</ul>
</p></li>
<li><p><strong>config_info</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict{str:</span> <span class="pre">str}</span></code>, optional) – <p>List of configuration parameters.
Set the individual parameters of the configfile together with <cite>section</cite> .
For example, for <cite>section</cite> = “common_quant_param”, <cite>config_info</cite> = {“quant_type”: “WEIGHT_QUANT”}.
Default: None, None is equivalent to {}.</p>
<p>For the configuration parameters related to post training quantization, please refer to
<a class="reference external" href="https://www.mindspore.cn/lite/docs/en/master/use/post_training_quantization.html">quantization</a> .</p>
<p>For the configuration parameters related to extension, please refer to
<a class="reference external" href="https://www.mindspore.cn/lite/docs/en/master/use/nnie.html#extension-configuration">extension</a> .</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – <cite>section</cite> is not a str.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – <cite>config_info</cite> is not a dict .</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – <cite>config_info</cite> is a dict, but the keys are not str.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – <cite>config_info</cite> is a dict, the keys are str, but the values are not str.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore_lite</span> <span class="k">as</span> <span class="nn">mslite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Converter</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">section</span> <span class="o">=</span> <span class="s2">&quot;common_quant_param&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config_info</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;quant_type&quot;</span><span class="p">:</span> <span class="s2">&quot;WEIGHT_QUANT&quot;</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">set_config_info</span><span class="p">(</span><span class="n">section</span><span class="p">,</span> <span class="n">config_info</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.train_model">
<em class="property">property </em><code class="sig-name descname">train_model</code><a class="headerlink" href="#mindspore_lite.Converter.train_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the status whether the model is going to be trained on device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><cite>train_model</cite> is not supported to use on MindSpore Lite cloud inference package.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>bool, whether the model is going to be trained on device.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.weight_fp16">
<em class="property">property </em><code class="sig-name descname">weight_fp16</code><a class="headerlink" href="#mindspore_lite.Converter.weight_fp16" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the status whether the model will be saved as the Float16 data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>bool, whether the model will be saved as the Float16 data type. If it is True, the const Tensor of the
Float32 in the model will be saved as the Float16 data type during Converter, and the generated model
size will be compressed. Then, according to <cite>Context.CPU</cite> ‘s <cite>precision_mode</cite> parameter determines the
inputs’ data type to perform inference. The priority of <cite>weight_fp16</cite> is very low. For example, if
quantization is enabled, for the weight of the quantized, <cite>weight_fp16</cite> will not take effect again.
<cite>weight_fp16</cite> only effective for the const Tensor in Float32 data type.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="mindspore_lite.ModelType.html" class="btn btn-neutral float-right" title="mindspore_lite.ModelType" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="mindspore_lite.FmkType.html" class="btn btn-neutral float-left" title="mindspore_lite.FmkType" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>