

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore_lite.converter &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/collapsible-lists/css/tree_view.css" type="text/css" />
   
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
        <script src="../../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
        
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_api.html">mindspore::api</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_api_utils.html">mindspore::api::utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_converter.html">mindspore::converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_dataset.html">mindspore::dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_dataset_config.html">mindspore::dataset::config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_dataset_text.html">mindspore::dataset::text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_dataset_transforms.html">mindspore::dataset::transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_dataset_vision.html">mindspore::dataset::vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_kernel.html">mindspore::kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_ops.html">mindspore::ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_registry.html">mindspore::registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_registry_opencl.html">mindspore::registry::opencl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/lite_cpp_example.html">Example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">JAVA API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/class_list.html">Class List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/model_parallel_runner.html">ModelParallelRunner</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/mscontext.html">MSContext</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/mstensor.html">MSTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/runner_config.html">RunnerConfig</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/graph.html">Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/lite_java_example.html">Example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore_lite.html">mindspore_lite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">C API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_c/context_c.html">context_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_c/data_type_c.html">data_type_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_c/format_c.html">format_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_c/lite_c_example.html">Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_c/model_c.html">model_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_c/tensor_c.html">tensor_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_c/types_c.html">types_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_c/lite_c_example.html">Example</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">Module code</a> &raquo;</li>
      <li>mindspore_lite.converter</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for mindspore_lite.converter</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2022 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ============================================================================</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Converter API.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Enum</span>

<span class="kn">from</span> <span class="nn">._checkparam</span> <span class="kn">import</span> <span class="n">check_isinstance</span><span class="p">,</span> <span class="n">check_input_shape</span><span class="p">,</span> <span class="n">check_config_info</span>
<span class="kn">from</span> <span class="nn">.lib</span> <span class="kn">import</span> <span class="n">_c_lite_wrapper</span>
<span class="kn">from</span> <span class="nn">.tensor</span> <span class="kn">import</span> <span class="n">DataType</span><span class="p">,</span> <span class="n">Format</span><span class="p">,</span> <span class="n">data_type_py_cxx_map</span><span class="p">,</span> <span class="n">data_type_cxx_py_map</span><span class="p">,</span> <span class="n">format_py_cxx_map</span><span class="p">,</span> <span class="n">format_cxx_py_map</span>
<span class="kn">from</span> <span class="nn">.model</span> <span class="kn">import</span> <span class="n">ModelType</span><span class="p">,</span> <span class="n">model_type_py_cxx_map</span><span class="p">,</span> <span class="n">model_type_cxx_py_map</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;FmkType&#39;</span><span class="p">,</span> <span class="s1">&#39;Converter&#39;</span><span class="p">]</span>


<div class="viewcode-block" id="FmkType"><a class="viewcode-back" href="../../mindspore_lite/mindspore_lite.FmkType.html#mindspore_lite.FmkType">[docs]</a><span class="k">class</span> <span class="nc">FmkType</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    When Converter, the `FmkType` is used to define Input model framework type.</span>

<span class="sd">    Currently, the following model framework types are supported:</span>

<span class="sd">    ===========================  ============================================================================</span>
<span class="sd">    Definition                    Description</span>
<span class="sd">    ===========================  ============================================================================</span>
<span class="sd">    `FmkType.TF`                 TensorFlow model&#39;s framework type, and the model uses .pb as suffix.</span>
<span class="sd">    `FmkType.CAFFE`              Caffe model&#39;s framework type, and the model uses .prototxt as suffix.</span>
<span class="sd">    `FmkType.ONNX`               ONNX model&#39;s framework type, and the model uses .onnx as suffix.</span>
<span class="sd">    `FmkType.MINDIR`             MindSpore model&#39;s framework type, and the model uses .mindir as suffix.</span>
<span class="sd">    `FmkType.TFLITE`             TensorFlow Lite model&#39;s framework type, and the model uses .tflite as suffix.</span>
<span class="sd">    `FmkType.PYTORCH`            PyTorch model&#39;s framework type, and the model uses .pt or .pth as suffix.</span>
<span class="sd">    ===========================  ============================================================================</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # Method 1: Import mindspore_lite package</span>
<span class="sd">        &gt;&gt;&gt; import mindspore_lite as mslite</span>
<span class="sd">        &gt;&gt;&gt; print(mslite.FmkType.TF)</span>
<span class="sd">        FmkType.TF</span>
<span class="sd">        &gt;&gt;&gt; # Method 2: from mindspore_lite package import FmkType</span>
<span class="sd">        &gt;&gt;&gt; from mindspore_lite import FmkType</span>
<span class="sd">        &gt;&gt;&gt; print(FmkType.TF)</span>
<span class="sd">        FmkType.TF</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">TF</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">CAFFE</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">ONNX</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">MINDIR</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">TFLITE</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">PYTORCH</span> <span class="o">=</span> <span class="mi">5</span></div>


<div class="viewcode-block" id="Converter"><a class="viewcode-back" href="../../mindspore_lite/mindspore_lite.Converter.html#mindspore_lite.Converter">[docs]</a><span class="k">class</span> <span class="nc">Converter</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs a `Converter` class. The usage scenarios are: 1. Convert the third-party model into MindSpore model or</span>
<span class="sd">    MindSpore Lite model; 2. Convert MindSpore model into MindSpore Lite model.</span>

<span class="sd">    Note:</span>
<span class="sd">        Please construct the `Converter` class first, and then generate the model by executing the Converter.converter()</span>
<span class="sd">        method.</span>

<span class="sd">        The encryption and decryption function is only valid when it is set to `MSLITE_ENABLE_MODEL_ENCRYPTION=on` at</span>
<span class="sd">        the compile time, and only supports Linux x86 platforms. `decrypt_key` and `encrypt_key` are string expressed in</span>
<span class="sd">        hexadecimal. For example, if the key is defined as &#39;(b)0123456789ABCDEF&#39; , the corresponding hexadecimal</span>
<span class="sd">        expression is &#39;30313233343637383939414243444546&#39; . Linux platform users can use the&#39; xxd &#39;tool to convert the</span>
<span class="sd">        key expressed in bytes into hexadecimal expressions. It should be noted that the encryption and decryption</span>
<span class="sd">        algorithm has been updated in version 1.7, resulting in the new python interface does not support the conversion</span>
<span class="sd">        of MindSpore Lite&#39;s encryption exported models in version 1.6 and earlier.</span>

<span class="sd">    Args:</span>
<span class="sd">        fmk_type (:class:`mindspore_lite.FmkType`): Input model framework type. Options: FmkType.TF | FmkType.CAFFE |</span>
<span class="sd">            FmkType.ONNX | FmkType.MINDIR | FmkType.TFLITE | FmkType.PYTORCH. For details, see</span>
<span class="sd">            `FmkType &lt;https://mindspore.cn/lite/api/en/r2.0.0-alpha/mindspore_lite/mindspore_lite.FmkType.html&gt;`_ .</span>
<span class="sd">        model_file (str): Set the path of the input model when converter. For example, &quot;/home/user/model.prototxt&quot;.</span>
<span class="sd">            Options:TF: &quot;model.pb&quot; | CAFFE: &quot;model.prototxt&quot; | ONNX: &quot;model.onnx&quot; | MINDIR: &quot;model.mindir&quot; |</span>
<span class="sd">            TFLITE: &quot;model.tflite&quot; | PYTORCH: &quot;model.pt or model.pth&quot;.</span>
<span class="sd">        output_file (str): Set the path of the output model. The suffix .ms or .mindir can be automatically generated.</span>
<span class="sd">            If set `export_mindir` to ModelType.MINDIR, then MindSpore&#39;s model will be generated, which uses .mindir as</span>
<span class="sd">            suffix. If set `export_mindir` to ModelType.MINDIR_LITE, then MindSpore Lite&#39;s model will be generated,</span>
<span class="sd">            which uses .ms as suffix. For example, the input model is &quot;/home/user/model.prototxt&quot;, it will generate the</span>
<span class="sd">            model named model.prototxt.ms in /home/user/.</span>
<span class="sd">        weight_file (str, optional): Set the path of input model weight file. Required only when fmk_type is</span>
<span class="sd">            FmkType.CAFFE. The Caffe model is generally divided into two files: &#39;model.prototxt&#39; is model structure,</span>
<span class="sd">            corresponding to `model_file` parameter; &#39;model.Caffemodel&#39; is model weight value file, corresponding to</span>
<span class="sd">            `weight_file` parameter. For example, &quot;/home/user/model.caffemodel&quot;. Default: &quot;&quot;.</span>
<span class="sd">        config_file (str, optional): Set the path of the configuration file of Converter can be used to post-training,</span>
<span class="sd">            offline split op to parallel, disable op fusion ability and set plugin so path. `config_file` uses the</span>
<span class="sd">            `key = value` method to define the related parameters.</span>
<span class="sd">            For the configuration parameters related to post training quantization, please refer to</span>
<span class="sd">            `quantization &lt;https://www.mindspore.cn/lite/docs/en/r2.0.0-alpha/use/post_training_quantization.html&gt;`_ .</span>
<span class="sd">            For the configuration parameters related to extension, please refer to</span>
<span class="sd">            `extension  &lt;https://www.mindspore.cn/lite/docs/en/r2.0.0-alpha/use/nnie.html#extension-configuration&gt;`_ .</span>
<span class="sd">            For example, &quot;/home/user/model.cfg&quot;. Default: &quot;&quot;.</span>
<span class="sd">        weight_fp16 (bool, optional): If it is True, the const Tensor of the Float32 in the model will be saved as the</span>
<span class="sd">            Float16 data type during Converter, and the generated model size will be compressed. Then, according to</span>
<span class="sd">            `DeviceInfo`&#39;s `enable_fp16` parameter determines the inputs&#39; data type to perform inference. The priority</span>
<span class="sd">            of `weight_fp16` is very low. For example, if quantization is enabled, for the weight of the quantized,</span>
<span class="sd">            `weight_fp16` will not take effect again. `weight_fp16` only effective for the const Tensor in Float32 data</span>
<span class="sd">            type. Default: False.</span>
<span class="sd">        input_shape (dict{str, list[int]}, optional): Set the dimension of the model input. The order of input</span>
<span class="sd">            dimensions is consistent with the original model. In the following scenarios, users may need to set the</span>
<span class="sd">            parameter. For example, {&quot;inTensor1&quot;: [1, 32, 32, 32], &quot;inTensor2&quot;: [1, 1, 32, 32]}. Default: None, None is</span>
<span class="sd">            equivalent to {}.</span>

<span class="sd">            - Usage 1:The input of the model to be converted is dynamic shape, but prepare to use fixed shape for</span>
<span class="sd">              inference, then set the parameter to fixed shape. After setting, when inferring on the converted</span>
<span class="sd">              model, the default input shape is the same as the parameter setting, no need to resize.</span>
<span class="sd">            - Usage 2: No matter whether the original input of the model to be converted is dynamic shape or not,</span>
<span class="sd">              but prepare to use fixed shape for inference, and the performance of the model is</span>
<span class="sd">              expected to be optimized as much as possible, then set the parameter to fixed shape. After</span>
<span class="sd">              setting, the model structure will be further optimized, but the converted model may lose the</span>
<span class="sd">              characteristics of dynamic shape(some operators strongly related to shape will be merged).</span>
<span class="sd">            - Usage 3: When using the converter function to generate code for Micro inference execution, it is</span>
<span class="sd">              recommended to set the parameter to reduce the probability of errors during deployment.</span>
<span class="sd">              When the model contains a Shape ops or the input of the model to be converted is a dynamic</span>
<span class="sd">              shape, you must set the parameter to fixed shape to support the relevant shape optimization and</span>
<span class="sd">              code generation.</span>

<span class="sd">        input_format (Format, optional): Set the input format of exported model. Only Valid for 4-dimensional input. The</span>
<span class="sd">            following 2 input formats are supported: Format.NCHW | Format.NHWC. Default: Format.NHWC.</span>

<span class="sd">            - Format.NCHW: Store tensor data in the order of batch N, channel C, height H and width W.</span>
<span class="sd">            - Format.NHWC: Store tensor data in the order of batch N, height H, width W and channel C.</span>

<span class="sd">        input_data_type (DataType, optional): Set the data type of the quantization model input Tensor. It is only valid</span>
<span class="sd">            when the quantization parameters ( `scale` and `zero point` ) of the model input tensor are available.</span>
<span class="sd">            The following 4 DataTypes are supported: DataType.FLOAT32 | DataType.INT8 | DataType.UINT8 |</span>
<span class="sd">            DataType.UNKNOWN. Default: DataType.FLOAT32.</span>

<span class="sd">            - DataType.FLOAT32: 32-bit floating-point number.</span>
<span class="sd">            - DataType.INT8:    8-bit integer.</span>
<span class="sd">            - DataType.UINT8:   unsigned 8-bit integer.</span>
<span class="sd">            - DataType.UNKNOWN: Set the Same DataType as the model input Tensor.</span>

<span class="sd">        output_data_type (DataType, optional): Set the data type of the quantization model output Tensor. It is only</span>
<span class="sd">            valid when the quantization parameters ( `scale` and `zero point` ) of the model output tensor are</span>
<span class="sd">            available. The following 4 DataTypes are supported: DataType.FLOAT32 | DataType.INT8 | DataType.UINT8 |</span>
<span class="sd">            DataType.UNKNOWN. Default: DataType.FLOAT32.</span>

<span class="sd">            - DataType.FLOAT32: 32-bit floating-point number.</span>
<span class="sd">            - DataType.INT8:    8-bit integer.</span>
<span class="sd">            - DataType.UINT8:   unsigned 8-bit integer.</span>
<span class="sd">            - DataType.UNKNOWN: Set the Same DataType as the model output Tensor.</span>

<span class="sd">        export_mindir (ModelType, optional): Set the model type needs to be export. Options: ModelType.MINDIR |</span>
<span class="sd">            ModelType.MINDIR_LITE. Default: ModelType.MINDIR_LITE. For details, see</span>
<span class="sd">            `ModelType &lt;https://mindspore.cn/lite/api/en/r2.0.0-alpha/mindspore_lite/mindspore_lite.ModelType.html&gt;`_ .</span>
<span class="sd">        decrypt_key (str, optional): Set the key used to decrypt the encrypted MindIR file, expressed in hexadecimal</span>
<span class="sd">            characters. Only valid when fmk_type is FmkType.MINDIR. Default: &quot;&quot;.</span>
<span class="sd">        decrypt_mode (str, optional): Set decryption mode for the encrypted MindIR file. Only valid when dec_key is</span>
<span class="sd">            set. Options: &quot;AES-GCM&quot; | &quot;AES-CBC&quot;. Default: &quot;AES-GCM&quot;.</span>
<span class="sd">        enable_encryption (bool, optional): Whether to encrypt the model when exporting. Export encryption can protect</span>
<span class="sd">            the integrity of the model, but it will increase the initialization time at runtime. Default: False.</span>
<span class="sd">        encrypt_key (str, optional): Set the key used to encrypt the model when exporting, expressed in hexadecimal</span>
<span class="sd">            characters. Only support when `decrypt_mode` is &quot;AES-GCM&quot;, the key length is 16. Default: &quot;&quot;.</span>
<span class="sd">        infer (bool, optional): Whether to do pre-inference after Converter. Default: False.</span>
<span class="sd">        train_model (bool, optional):   Whether the model is going to be trained on device. Default: False.</span>
<span class="sd">        no_fusion(bool, optional): Whether avoid fusion optimization, fusion optimization is allowed by default.</span>
<span class="sd">            Default: False.</span>
<span class="sd">        device (str, optional): Set target device when converter model. Only valid for ascend. The following device</span>
<span class="sd">            are supported: &quot;Ascend&quot;. Default: &quot;&quot;.</span>
<span class="sd">    Raises:</span>
<span class="sd">        TypeError: `fmk_type` is not a FmkType.</span>
<span class="sd">        TypeError: `model_file` is not a str.</span>
<span class="sd">        TypeError: `output_file` is not a str.</span>
<span class="sd">        TypeError: `weight_file` is not a str.</span>
<span class="sd">        TypeError: `config_file` is not a str.</span>
<span class="sd">        TypeError: `weight_fp16` is not a bool.</span>
<span class="sd">        TypeError: `input_shape` is neither a dict nor None.</span>
<span class="sd">        TypeError: `input_shape` is a dict, but the keys are not str.</span>
<span class="sd">        TypeError: `input_shape` is a dict, the keys are str, but the values are not list.</span>
<span class="sd">        TypeError: `input_shape` is a dict, the keys are str, the values are list, but the value&#39;s elements are not int.</span>
<span class="sd">        TypeError: `input_format` is not a Format.</span>
<span class="sd">        TypeError: `input_data_type` is not a DataType.</span>
<span class="sd">        TypeError: `output_data_type` is not a DataType.</span>
<span class="sd">        TypeError: `export_mindir` is not a ModelType.</span>
<span class="sd">        TypeError: `decrypt_key` is not a str.</span>
<span class="sd">        TypeError: `decrypt_mode` is not a str.</span>
<span class="sd">        TypeError: `enable_encryption` is not a bool.</span>
<span class="sd">        TypeError: `encrypt_key` is not a str.</span>
<span class="sd">        TypeError: `infer` is not a bool.</span>
<span class="sd">        TypeError: `train_model` is not a bool.</span>
<span class="sd">        TypeError: `no_fusion` is not a bool.</span>
<span class="sd">        TypeError: `device` is not a str.</span>
<span class="sd">        ValueError: `input_format` is neither Format.NCHW nor Format.NHWC when it is a Format.</span>
<span class="sd">        ValueError: `decrypt_mode` is neither &quot;AES-GCM&quot; nor &quot;AES-CBC&quot; when it is a str.</span>
<span class="sd">        ValueError: `device` is not &quot;Ascend&quot; when it is a str.</span>
<span class="sd">        RuntimeError: `model_file` does not exist.</span>
<span class="sd">        RuntimeError: `weight_file` is not &quot;&quot;, but `weight_file` does not exist.</span>
<span class="sd">        RuntimeError: `config_file` is not &quot;&quot;, but `config_file` does not exist.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore_lite as mslite</span>
<span class="sd">        &gt;&gt;&gt; converter = mslite.Converter(mslite.FmkType.TFLITE, &quot;./mobilenetv2/mobilenet_v2_1.0_224.tflite&quot;,</span>
<span class="sd">        ...                              &quot;mobilenet_v2_1.0_224.tflite&quot;)</span>
<span class="sd">        &gt;&gt;&gt; # The ms model may be generated only after converter.converter() is executed after the class is constructed.</span>
<span class="sd">        &gt;&gt;&gt; print(converter)</span>
<span class="sd">        config_file: ,</span>
<span class="sd">        config_info: {},</span>
<span class="sd">        weight_fp16: False,</span>
<span class="sd">        input_shape: {},</span>
<span class="sd">        input_format: Format.NHWC,</span>
<span class="sd">        input_data_type: DataType.FLOAT32,</span>
<span class="sd">        output_data_type: DataType.FLOAT32,</span>
<span class="sd">        export_mindir: ModelType.MINDIR_LITE,</span>
<span class="sd">        decrypt_key: ,</span>
<span class="sd">        decrypt_mode: AES-GCM,</span>
<span class="sd">        enable_encryption: False,</span>
<span class="sd">        encrypt_key: ,</span>
<span class="sd">        infer: False,</span>
<span class="sd">        train_model: False,</span>
<span class="sd">        no_fusion: False,</span>
<span class="sd">        device: .</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fmk_type</span><span class="p">,</span> <span class="n">model_file</span><span class="p">,</span> <span class="n">output_file</span><span class="p">,</span> <span class="n">weight_file</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">config_file</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">weight_fp16</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_format</span><span class="o">=</span><span class="n">Format</span><span class="o">.</span><span class="n">NHWC</span><span class="p">,</span> <span class="n">input_data_type</span><span class="o">=</span><span class="n">DataType</span><span class="o">.</span><span class="n">FLOAT32</span><span class="p">,</span>
                 <span class="n">output_data_type</span><span class="o">=</span><span class="n">DataType</span><span class="o">.</span><span class="n">FLOAT32</span><span class="p">,</span> <span class="n">export_mindir</span><span class="o">=</span><span class="n">ModelType</span><span class="o">.</span><span class="n">MINDIR_LITE</span><span class="p">,</span> <span class="n">decrypt_key</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
                 <span class="n">decrypt_mode</span><span class="o">=</span><span class="s2">&quot;AES-GCM&quot;</span><span class="p">,</span> <span class="n">enable_encryption</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encrypt_key</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">infer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">train_model</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">no_fusion</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;fmk_type&quot;</span><span class="p">,</span> <span class="n">fmk_type</span><span class="p">,</span> <span class="n">FmkType</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;model_file&quot;</span><span class="p">,</span> <span class="n">model_file</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;output_file&quot;</span><span class="p">,</span> <span class="n">output_file</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;weight_file&quot;</span><span class="p">,</span> <span class="n">weight_file</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;config_file&quot;</span><span class="p">,</span> <span class="n">config_file</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;weight_fp16&quot;</span><span class="p">,</span> <span class="n">weight_fp16</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span>
        <span class="n">check_input_shape</span><span class="p">(</span><span class="s2">&quot;input_shape&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">enable_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;input_format&quot;</span><span class="p">,</span> <span class="n">input_format</span><span class="p">,</span> <span class="n">Format</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;input_data_type&quot;</span><span class="p">,</span> <span class="n">input_data_type</span><span class="p">,</span> <span class="n">DataType</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;output_data_type&quot;</span><span class="p">,</span> <span class="n">output_data_type</span><span class="p">,</span> <span class="n">DataType</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;export_mindir&quot;</span><span class="p">,</span> <span class="n">export_mindir</span><span class="p">,</span> <span class="n">ModelType</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;decrypt_key&quot;</span><span class="p">,</span> <span class="n">decrypt_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;decrypt_mode&quot;</span><span class="p">,</span> <span class="n">decrypt_mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;enable_encryption&quot;</span><span class="p">,</span> <span class="n">enable_encryption</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;encrypt_key&quot;</span><span class="p">,</span> <span class="n">encrypt_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;infer&quot;</span><span class="p">,</span> <span class="n">infer</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;train_model&quot;</span><span class="p">,</span> <span class="n">train_model</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;no_fusion&quot;</span><span class="p">,</span> <span class="n">no_fusion</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;device&quot;</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">model_file</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Converter&#39;s init failed, model_file does not exist!&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">weight_file</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">weight_file</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Converter&#39;s init failed, weight_file does not exist!&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">config_file</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">config_file</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Converter&#39;s init failed, config_file does not exist!&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">input_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">Format</span><span class="o">.</span><span class="n">NCHW</span><span class="p">,</span> <span class="n">Format</span><span class="o">.</span><span class="n">NHWC</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Converter&#39;s init failed, input_format must be NCHW or NHWC.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">device</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;Ascend&quot;</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Converter&#39;s init failed, device must be Ascend&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">decrypt_mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;AES-GCM&quot;</span><span class="p">,</span> <span class="s2">&quot;AES-CBC&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Converter&#39;s init failed, decrypt_mode must be AES-GCM or AES-CBC.&quot;</span><span class="p">)</span>
        <span class="n">input_shape_</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">input_shape</span>

        <span class="n">fmk_type_py_cxx_map</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">FmkType</span><span class="o">.</span><span class="n">TF</span><span class="p">:</span> <span class="n">_c_lite_wrapper</span><span class="o">.</span><span class="n">FmkType</span><span class="o">.</span><span class="n">kFmkTypeTf</span><span class="p">,</span>
            <span class="n">FmkType</span><span class="o">.</span><span class="n">CAFFE</span><span class="p">:</span> <span class="n">_c_lite_wrapper</span><span class="o">.</span><span class="n">FmkType</span><span class="o">.</span><span class="n">kFmkTypeCaffe</span><span class="p">,</span>
            <span class="n">FmkType</span><span class="o">.</span><span class="n">ONNX</span><span class="p">:</span> <span class="n">_c_lite_wrapper</span><span class="o">.</span><span class="n">FmkType</span><span class="o">.</span><span class="n">kFmkTypeOnnx</span><span class="p">,</span>
            <span class="n">FmkType</span><span class="o">.</span><span class="n">MINDIR</span><span class="p">:</span> <span class="n">_c_lite_wrapper</span><span class="o">.</span><span class="n">FmkType</span><span class="o">.</span><span class="n">kFmkTypeMs</span><span class="p">,</span>
            <span class="n">FmkType</span><span class="o">.</span><span class="n">TFLITE</span><span class="p">:</span> <span class="n">_c_lite_wrapper</span><span class="o">.</span><span class="n">FmkType</span><span class="o">.</span><span class="n">kFmkTypeTflite</span><span class="p">,</span>
            <span class="n">FmkType</span><span class="o">.</span><span class="n">PYTORCH</span><span class="p">:</span> <span class="n">_c_lite_wrapper</span><span class="o">.</span><span class="n">FmkType</span><span class="o">.</span><span class="n">kFmkTypePytorch</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span> <span class="o">=</span> <span class="n">_c_lite_wrapper</span><span class="o">.</span><span class="n">ConverterBind</span><span class="p">(</span><span class="n">fmk_type_py_cxx_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">fmk_type</span><span class="p">),</span> <span class="n">model_file</span><span class="p">,</span> <span class="n">output_file</span><span class="p">,</span>
                                                        <span class="n">weight_file</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">config_file</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_config_file</span><span class="p">(</span><span class="n">config_file</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">weight_fp16</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_weight_fp16</span><span class="p">(</span><span class="n">weight_fp16</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">input_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_input_shape</span><span class="p">(</span><span class="n">input_shape_</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">input_format</span> <span class="o">!=</span> <span class="n">Format</span><span class="o">.</span><span class="n">NHWC</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_input_format</span><span class="p">(</span><span class="n">format_py_cxx_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">input_format</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">input_data_type</span> <span class="o">!=</span> <span class="n">DataType</span><span class="o">.</span><span class="n">FLOAT32</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_input_data_type</span><span class="p">(</span><span class="n">data_type_py_cxx_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">input_data_type</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">output_data_type</span> <span class="o">!=</span> <span class="n">DataType</span><span class="o">.</span><span class="n">FLOAT32</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_output_data_type</span><span class="p">(</span><span class="n">data_type_py_cxx_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">output_data_type</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">export_mindir</span> <span class="o">!=</span> <span class="n">ModelType</span><span class="o">.</span><span class="n">MINDIR_LITE</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_export_mindir</span><span class="p">(</span><span class="n">model_type_py_cxx_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">export_mindir</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">decrypt_key</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_decrypt_key</span><span class="p">(</span><span class="n">decrypt_key</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_decrypt_mode</span><span class="p">(</span><span class="n">decrypt_mode</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">enable_encryption</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_enable_encryption</span><span class="p">(</span><span class="n">enable_encryption</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">encrypt_key</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_encrypt_key</span><span class="p">(</span><span class="n">encrypt_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">infer</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_infer</span><span class="p">(</span><span class="n">infer</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">train_model</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_train_model</span><span class="p">(</span><span class="n">train_model</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">no_fusion</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_no_fusion</span><span class="p">(</span><span class="n">no_fusion</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;config_file: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_config_file</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;config_info: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_config_info</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;weight_fp16: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_weight_fp16</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;input_shape: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_input_shape</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;input_format: </span><span class="si">{</span><span class="n">format_cxx_py_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_input_format</span><span class="p">())</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;input_data_type: </span><span class="si">{</span><span class="n">data_type_cxx_py_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_input_data_type</span><span class="p">())</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;output_data_type: </span><span class="si">{</span><span class="n">data_type_cxx_py_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_output_data_type</span><span class="p">())</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;export_mindir: </span><span class="si">{</span><span class="n">model_type_cxx_py_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_export_mindir</span><span class="p">())</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;decrypt_key: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_decrypt_key</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;decrypt_mode: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_decrypt_mode</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;enable_encryption: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_enable_encryption</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;encrypt_key: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_encrypt_key</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;infer: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_infer</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;train_model: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_train_model</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;no_fusion: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_no_fusion</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;device: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_device</span><span class="p">()</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="k">return</span> <span class="n">res</span>

<div class="viewcode-block" id="Converter.set_config_info"><a class="viewcode-back" href="../../mindspore_lite/mindspore_lite.Converter.html#mindspore_lite.Converter.set_config_info">[docs]</a>    <span class="k">def</span> <span class="nf">set_config_info</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">section</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">config_info</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set config info for Converter.It is used together with `get_config_info` method for online converter.</span>

<span class="sd">        Args:</span>
<span class="sd">            section (str, optional): The category of the configuration parameter.</span>
<span class="sd">                Set the individual parameters of the configfile together with `config_info` .</span>
<span class="sd">                For example, for `section` = &quot;common_quant_param&quot;, `config_info` = {&quot;quant_type&quot;:&quot;WEIGHT_QUANT&quot;}.</span>
<span class="sd">                Default: &quot;&quot;.</span>

<span class="sd">                For the configuration parameters related to post training quantization, please refer to</span>
<span class="sd">                `quantization &lt;https://www.mindspore.cn/lite/docs/en/r2.0.0-alpha/use/</span>
<span class="sd">                post_training_quantization.html&gt;`_ .</span>

<span class="sd">                For the configuration parameters related to extension, please refer to</span>
<span class="sd">                `extension  &lt;https://www.mindspore.cn/lite/docs/en/r2.0.0-alpha/use/</span>
<span class="sd">                nnie.html#extension-configuration&gt;`_ .</span>

<span class="sd">                - &quot;common_quant_param&quot;: Common quantization parameter.</span>
<span class="sd">                - &quot;mixed_bit_weight_quant_param&quot;: Mixed bit weight quantization parameter.</span>
<span class="sd">                - &quot;full_quant_param&quot;: Full quantization parameter.</span>
<span class="sd">                - &quot;data_preprocess_param&quot;: Data preprocess quantization parameter.</span>
<span class="sd">                - &quot;registry&quot;: Extension configuration parameter.</span>

<span class="sd">            config_info (dict{str, str}, optional): List of configuration parameters.</span>
<span class="sd">                Set the individual parameters of the configfile together with `section` .</span>
<span class="sd">                For example, for `section` = &quot;common_quant_param&quot;, `config_info` = {&quot;quant_type&quot;:&quot;WEIGHT_QUANT&quot;}.</span>
<span class="sd">                Default: None, None is equivalent to {}.</span>

<span class="sd">                For the configuration parameters related to post training quantization, please refer to</span>
<span class="sd">                `quantization &lt;https://www.mindspore.cn/lite/docs/en/r2.0.0-alpha/use/</span>
<span class="sd">                post_training_quantization.html&gt;`_ .</span>

<span class="sd">                For the configuration parameters related to extension, please refer to</span>
<span class="sd">                `extension  &lt;https://www.mindspore.cn/lite/docs/en/r2.0.0-alpha/use/</span>
<span class="sd">                nnie.html#extension-configuration&gt;`_ .</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `section` is not a str.</span>
<span class="sd">            TypeError: `config_info` is not a dict .</span>
<span class="sd">            TypeError: `config_info` is a dict, but the keys are not str.</span>
<span class="sd">            TypeError: `config_info` is a dict, the keys are str, but the values are not str.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore_lite as mslite</span>
<span class="sd">            &gt;&gt;&gt; converter = mslite.Converter(mslite.FmkType.TFLITE, &quot;./mobilenetv2/mobilenet_v2_1.0_224.tflite&quot;,</span>
<span class="sd">            ...                              &quot;mobilenet_v2_1.0_224.tflite&quot;)</span>
<span class="sd">            &gt;&gt;&gt; section = &quot;common_quant_param&quot;</span>
<span class="sd">            &gt;&gt;&gt; config_info = {&quot;quant_type&quot;:&quot;WEIGHT_QUANT&quot;}</span>
<span class="sd">            &gt;&gt;&gt; converter.set_config_info(section, config_info)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;section&quot;</span><span class="p">,</span> <span class="n">section</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="n">check_config_info</span><span class="p">(</span><span class="s2">&quot;config_info&quot;</span><span class="p">,</span> <span class="n">config_info</span><span class="p">,</span> <span class="n">enable_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">section</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span> <span class="ow">and</span> <span class="n">config_info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">set_config_info</span><span class="p">(</span><span class="n">section</span><span class="p">,</span> <span class="n">config_info</span><span class="p">)</span></div>

<div class="viewcode-block" id="Converter.get_config_info"><a class="viewcode-back" href="../../mindspore_lite/mindspore_lite.Converter.html#mindspore_lite.Converter.get_config_info">[docs]</a>    <span class="k">def</span> <span class="nf">get_config_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get config info of converter.It is used together with `set_config_info` method for online converter.</span>
<span class="sd">        Please use `set_config_info` method before `get_config_info` .</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict{str, dict{str, str}}, the config info which has been set in converter.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore_lite as mslite</span>
<span class="sd">            &gt;&gt;&gt; converter = mslite.Converter(mslite.FmkType.TFLITE, &quot;./mobilenetv2/mobilenet_v2_1.0_224.tflite&quot;,</span>
<span class="sd">            ...                              &quot;mobilenet_v2_1.0_224.tflite&quot;)</span>
<span class="sd">            &gt;&gt;&gt; section = &quot;common_quant_param&quot;</span>
<span class="sd">            &gt;&gt;&gt; config_info_in = {&quot;quant_type&quot;:&quot;WEIGHT_QUANT&quot;}</span>
<span class="sd">            &gt;&gt;&gt; converter.set_config_info(section, config_info_in)</span>
<span class="sd">            &gt;&gt;&gt; config_info_out = converter.get_config_info()</span>
<span class="sd">            &gt;&gt;&gt; print(config_info_out)</span>
<span class="sd">            {&#39;common_quant_param&#39;: {&#39;quant_type&#39;: &#39;WEIGHT_QUANT&#39;}}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">get_config_info</span><span class="p">()</span></div>

<div class="viewcode-block" id="Converter.converter"><a class="viewcode-back" href="../../mindspore_lite/mindspore_lite.Converter.html#mindspore_lite.Converter.converter">[docs]</a>    <span class="k">def</span> <span class="nf">converter</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform conversion, and convert the third-party model to the mindspire model.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: converter model failed.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore_lite as mslite</span>
<span class="sd">            &gt;&gt;&gt; converter = mslite.Converter(mslite.FmkType.TFLITE, &quot;./mobilenetv2/mobilenet_v2_1.0_224.tflite&quot;,</span>
<span class="sd">            ...                              &quot;mobilenet_v2_1.0_224.tflite&quot;)</span>
<span class="sd">            &gt;&gt;&gt; converter.converter()</span>
<span class="sd">            CONVERT RESULT SUCCESS:0</span>
<span class="sd">            &gt;&gt;&gt; # mobilenet_v2_1.0_224.tflite.ms model will be generated.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_converter</span><span class="o">.</span><span class="n">converter</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">ret</span><span class="o">.</span><span class="n">IsOk</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Converter model failed! Error is </span><span class="si">{</span><span class="n">ret</span><span class="o">.</span><span class="n">ToString</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>