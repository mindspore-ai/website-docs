:gitee_url: https://gitee.com/mindspore/docs


.. _program_listing_file_include_converter_include_ops_attention.h:

Program Listing for File attention.h
====================================

|exhale_lsh| :ref:`Return to documentation for file <file_include_converter_include_ops_attention.h>` (``include/converter/include/ops/attention.h``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   
   #ifndef MINDSPORE_CORE_OPS_ATTENTION_H_
   #define MINDSPORE_CORE_OPS_ATTENTION_H_
   #include <map>
   #include <vector>
   #include <string>
   #include <memory>
   
   #include "ops/base_operator.h"
   #include "mindapi/base/types.h"
   
   namespace mindspore {
   namespace ops {
   constexpr auto kNameAttention = "Attention";
   class MIND_API Attention : public BaseOperator {
    public:
     MIND_API_BASE_MEMBER(Attention);
     Attention() : BaseOperator(kNameAttention) {
       InitIOName(
         {"q", "k", "v", "weight_q", "weight_k", "weight_v", "weight_o", "bias_q", "bias_k", "bias_v", "bias_o", "mask"},
         {"output"});
     }
     void Init(int64_t head_num, int64_t head_size, bool position_bias, bool cross = false);
     void set_head_num(int64_t head_num);
     void set_head_size(int64_t head_size);
     void set_cross(bool cross);
     void set_position_bias(bool position_bias);
     int64_t get_head_num() const;
     int64_t get_head_size() const;
     bool get_cross() const;
     bool get_position_bias() const;
   };
   }  // namespace ops
   }  // namespace mindspore
   #endif  // MINDSPORE_CORE_OPS_ATTENTION_H_
