:gitee_url: https://gitee.com/mindspore/docs


.. _program_listing_file_include_runtime_include_api_serialization.h:

Program Listing for File serialization.h
========================================

|exhale_lsh| :ref:`Return to documentation for file <file_include_runtime_include_api_serialization.h>` (``include/runtime/include/api/serialization.h``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   
   #ifndef MINDSPORE_INCLUDE_API_SERIALIZATION_H
   #define MINDSPORE_INCLUDE_API_SERIALIZATION_H
   
   #include <string>
   #include <vector>
   #include <map>
   #include <memory>
   #include "include/api/status.h"
   #include "include/api/types.h"
   #include "include/api/model.h"
   #include "include/api/graph.h"
   #include "include/api/dual_abi_helper.h"
   
   namespace mindspore {
   class MS_API Serialization {
    public:
     inline static Status Load(const void *model_data, size_t data_size, ModelType model_type, Graph *graph,
                               const Key &dec_key = {}, const std::string &dec_mode = kDecModeAesGcm);
   
     inline static Status Load(const std::string &file, ModelType model_type, Graph *graph, const Key &dec_key = {},
                               const std::string &dec_mode = kDecModeAesGcm);
   
     inline static Status Load(const std::vector<std::string> &files, ModelType model_type, std::vector<Graph> *graphs,
                               const Key &dec_key = {}, const std::string &dec_mode = kDecModeAesGcm);
   
     inline static Status SetParameters(const std::map<std::string, Buffer> &parameters, Model *model);
   
     static Status ExportModel(const Model &model, ModelType model_type, Buffer *model_data);
   
     inline static Status ExportModel(const Model &model, ModelType model_type, const std::string &model_file,
                                      QuantizationType quantization_type = kNoQuant, bool export_inference_only = true,
                                      std::vector<std::string> output_tensor_name = {});
   
    private:
     static Status Load(const void *model_data, size_t data_size, ModelType model_type, Graph *graph, const Key &dec_key,
                        const std::vector<char> &dec_mode);
     static Status Load(const std::vector<char> &file, ModelType model_type, Graph *graph);
     static Status Load(const std::vector<char> &file, ModelType model_type, Graph *graph, const Key &dec_key,
                        const std::vector<char> &dec_mode);
     static Status Load(const std::vector<std::vector<char>> &files, ModelType model_type, std::vector<Graph> *graphs,
                        const Key &dec_key, const std::vector<char> &dec_mode);
     static Status SetParameters(const std::map<std::vector<char>, Buffer> &parameters, Model *model);
     static Status ExportModel(const Model &model, ModelType model_type, const std::vector<char> &model_file,
                               QuantizationType quantization_type, bool export_inference_only,
                               const std::vector<std::vector<char>> &output_tensor_name);
   };
   
   Status Serialization::Load(const void *model_data, size_t data_size, ModelType model_type, Graph *graph,
                              const Key &dec_key, const std::string &dec_mode) {
     return Load(model_data, data_size, model_type, graph, dec_key, StringToChar(dec_mode));
   }
   
   Status Serialization::Load(const std::string &file, ModelType model_type, Graph *graph, const Key &dec_key,
                              const std::string &dec_mode) {
     return Load(StringToChar(file), model_type, graph, dec_key, StringToChar(dec_mode));
   }
   
   Status Serialization::Load(const std::vector<std::string> &files, ModelType model_type, std::vector<Graph> *graphs,
                              const Key &dec_key, const std::string &dec_mode) {
     return Load(VectorStringToChar(files), model_type, graphs, dec_key, StringToChar(dec_mode));
   }
   
   Status Serialization::SetParameters(const std::map<std::string, Buffer> &parameters, Model *model) {
     return SetParameters(MapStringToChar<Buffer>(parameters), model);
   }
   
   Status Serialization::ExportModel(const Model &model, ModelType model_type, const std::string &model_file,
                                     QuantizationType quantization_type, bool export_inference_only,
                                     std::vector<std::string> output_tensor_name) {
     return ExportModel(model, model_type, StringToChar(model_file), quantization_type, export_inference_only,
                        VectorStringToChar(output_tensor_name));
   }
   
   }  // namespace mindspore
   #endif  // MINDSPORE_INCLUDE_API_SERIALIZATION_H
