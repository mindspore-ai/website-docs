:gitee_url: https://gitee.com/mindspore/docs


.. _program_listing_file_include_runtime_include_dataset_execute.h:

Program Listing for File execute.h
==================================

|exhale_lsh| :ref:`Return to documentation for file <file_include_runtime_include_dataset_execute.h>` (``include/runtime/include/dataset/execute.h``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   
   
   #ifndef MINDSPORE_CCSRC_MINDDATA_DATASET_INCLUDE_DATASET_EXECUTE_H_
   #define MINDSPORE_CCSRC_MINDDATA_DATASET_INCLUDE_DATASET_EXECUTE_H_
   
   #include <string>
   #include <vector>
   #include <map>
   #include <memory>
   #include "include/api/context.h"
   #include "include/api/types.h"
   #include "include/dataset/constants.h"
   #include "include/dataset/transforms.h"
   
   namespace mindspore {
   namespace dataset {
   class DeviceResource;
   class TensorOp;
   class Tensor;
   
   // class to run tensor operations in eager mode
   class DATASET_API Execute {
    public:
     explicit Execute(const std::shared_ptr<TensorOperation> &op, MapTargetDevice device_type = MapTargetDevice::kCpu,
                      uint32_t device_id = 0);
   
     explicit Execute(const std::shared_ptr<TensorTransform> &op, MapTargetDevice device_type = MapTargetDevice::kCpu,
                      uint32_t device_id = 0);
   
     explicit Execute(const std::reference_wrapper<TensorTransform> &op,
                      MapTargetDevice device_type = MapTargetDevice::kCpu, uint32_t device_id = 0);
   
     explicit Execute(TensorTransform *op, MapTargetDevice device_type = MapTargetDevice::kCpu, uint32_t device_id = 0);
   
     explicit Execute(const std::vector<std::shared_ptr<TensorOperation>> &ops,
                      MapTargetDevice device_type = MapTargetDevice::kCpu, uint32_t device_id = 0);
   
     explicit Execute(const std::vector<std::shared_ptr<TensorTransform>> &ops,
                      MapTargetDevice device_type = MapTargetDevice::kCpu, uint32_t device_id = 0);
   
     explicit Execute(const std::vector<std::reference_wrapper<TensorTransform>> &ops,
                      MapTargetDevice device_type = MapTargetDevice::kCpu, uint32_t device_id = 0);
   
     explicit Execute(const std::vector<TensorTransform *> &ops, MapTargetDevice device_type = MapTargetDevice::kCpu,
                      uint32_t device_id = 0);
   
     ~Execute();
   
     Status operator()(const mindspore::MSTensor &input, mindspore::MSTensor *output);
   
     Status operator()(const std::vector<mindspore::MSTensor> &input_tensor_list, std::vector<mindspore::MSTensor> *out);
   
     static Status Run(const std::vector<std::shared_ptr<dataset::Execute>> &data_graph,
                       const std::vector<mindspore::MSTensor> &inputs, std::vector<mindspore::MSTensor> *outputs);
   
     Status DeviceMemoryRelease();
   
     std::string AippCfgGenerator();
   
    protected:
     Status BuildTransforms();
   
     Status ParseTransforms();
   
     Status ValidateDevice();
   
     Status InitResource(MapTargetDevice device_type, uint32_t device_id);
   
     std::vector<std::shared_ptr<TensorTransform>> transforms_;
     std::vector<std::shared_ptr<TensorOperation>> ops_;
     MapTargetDevice device_type_;
     std::shared_ptr<DeviceResource> device_resource_;
     struct ExtraInfo;
     std::shared_ptr<ExtraInfo> info_;
     std::vector<std::shared_ptr<TensorOp>> transforms_rt_;
     bool ops_created{false};
   };
   
   class PyExecute : public Execute {
    public:
     // inherit base class constructors
     using Execute::Execute;
   
     Status operator()(const std::shared_ptr<Tensor> &input_tensor, std::shared_ptr<Tensor> *out);
   
     Status operator()(const std::vector<std::shared_ptr<Tensor>> &input_tensor_list,
                       std::vector<std::shared_ptr<Tensor>> *out);
   };
   }  // namespace dataset
   }  // namespace mindspore
   #endif  // MINDSPORE_CCSRC_MINDDATA_DATASET_INCLUDE_DATASET_EXECUTE_H_
