<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore_lite.Context &mdash; MindSpore Lite master 文档</title>
      <link rel="stylesheet" href="../_static/collapsible-lists/css/tree_view.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/translations.js"></script>
        <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
        <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="mindspore_lite.FmkType" href="mindspore_lite.FmkType.html" />
    <link rel="prev" title="mindspore_lite" href="../mindspore_lite.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_NN.html">mindspore::NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_api.html">mindspore::api</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_api_utils.html">mindspore::api::utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_converter.html">mindspore::converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_dataset.html">mindspore::dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_dataset_transforms.html">mindspore::dataset::transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_kernel.html">mindspore::kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_ops.html">mindspore::ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_registry.html">mindspore::registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_registry_opencl.html">mindspore::registry::opencl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/lite_cpp_example.html">样例</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">JAVA API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_java/class_list.html">类列表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/model_parallel_runner.html">ModelParallelRunner</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/mscontext.html">MSContext</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/mstensor.html">MSTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/runner_config.html">RunnerConfig</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/graph.html">Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/lite_java_example.html">样例</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore_lite.html">mindspore_lite</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore_lite.html#运行环境">运行环境</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">mindspore_lite.Context</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore_lite.html#转换">转换</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore_lite.html#模型">模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore_lite.html#张量">张量</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">C API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_c/context_c.html">context_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/data_type_c.html">data_type_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/format_c.html">format_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/model_c.html">model_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/tensor_c.html">tensor_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/types_c.html">types_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/lite_c_example.html">样例</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../mindspore_lite.html">mindspore_lite</a> &raquo;</li>
      <li>mindspore_lite.Context</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/mindspore_lite/mindspore_lite.Context.rst.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mindspore-lite-context">
<h1>mindspore_lite.Context<a class="headerlink" href="#mindspore-lite-context" title="永久链接至标题"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore_lite.Context">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_lite.</span></span><span class="sig-name descname"><span class="pre">Context</span></span><a class="reference internal" href="../_modules/mindspore_lite/context.html#Context"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_lite.Context" title="打开链接"></a></dt>
<dd><p>The <cite>Context</cite> class is used to transfer environment variables during execution.</p>
<p>The context should be configured before running the program.
If it is not configured, it will be set cpu target, and automatically set cpu attributes by default.</p>
<p>Context.parallel defines the context and configuration of <cite>ModelParallelRunner</cite> class.</p>
<dl>
<dt>Context.parallel properties:</dt><dd><ul>
<li><p><strong>workers_num</strong> (int) - the num of workers. A <cite>ModelParallelRunner</cite> contains multiple workers, which
are the units that actually perform parallel inferring. Setting <cite>workers_num</cite> to 0 represents
<cite>workers_num</cite> will be automatically adjusted based on computer performance and core numbers.</p></li>
<li><p><strong>config_info</strong> (dict{str, dict{str, str}}) - Nested map for transferring user defined options during building
<cite>ModelParallelRunner</cite> online. More configurable options refer to <cite>config_path</cite> .
For example, {“model_file”: {“mindir_path”: “/home/user/model_graph.mindir”}}.
section is “model_file”, one of the keys is “mindir_path”,
the corresponding value in the map is “/home/user/model_graph.mindir”.</p></li>
<li><p><strong>config_path</strong> (str) - Set the config file path. The config file is used to transfer user-defined
options during building <cite>ModelParallelRunner</cite> . In the following scenarios, users may need to set the
parameter. For example, “/home/user/config.txt”.</p>
<ul>
<li><p>Usage 1: Set mixed precision inference. The content and description of the configuration file are as
follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">execution_plan</span><span class="p">]</span>
<span class="p">[</span><span class="n">op_name1</span><span class="p">]</span><span class="o">=</span><span class="n">data_Type</span><span class="p">:</span> <span class="n">float16</span> <span class="p">(</span><span class="n">The</span> <span class="n">operator</span> <span class="n">named</span> <span class="n">op_name1</span> <span class="n">sets</span> <span class="n">the</span> <span class="n">data</span> <span class="nb">type</span> <span class="k">as</span> <span class="n">Float16</span><span class="p">)</span>
<span class="p">[</span><span class="n">op_name2</span><span class="p">]</span><span class="o">=</span><span class="n">data_Type</span><span class="p">:</span> <span class="n">float32</span> <span class="p">(</span><span class="n">The</span> <span class="n">operator</span> <span class="n">named</span> <span class="n">op_name2</span> <span class="n">sets</span> <span class="n">the</span> <span class="n">data</span> <span class="nb">type</span> <span class="k">as</span> <span class="n">Float32</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Usage 2: When GPU inference, set the configuration of TensorRT. The content and description of the
configuration file are as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">ms_cache</span><span class="p">]</span>
<span class="n">serialize_Path</span><span class="o">=</span><span class="p">[</span><span class="n">serialization</span> <span class="n">model</span> <span class="n">path</span><span class="p">](</span><span class="n">storage</span> <span class="n">path</span> <span class="n">of</span> <span class="n">serialization</span> <span class="n">model</span><span class="p">)</span>
<span class="p">[</span><span class="n">gpu_context</span><span class="p">]</span>
<span class="n">input_shape</span><span class="o">=</span><span class="n">input_Name</span><span class="p">:</span> <span class="p">[</span><span class="n">input_dim</span><span class="p">]</span> <span class="p">(</span><span class="n">Model</span> <span class="nb">input</span> <span class="n">dimension</span><span class="p">,</span> <span class="k">for</span> <span class="n">dynamic</span> <span class="n">shape</span><span class="p">)</span>
<span class="n">dynamic_Dims</span><span class="o">=</span><span class="p">[</span><span class="n">min_dim</span><span class="o">~</span><span class="n">max_dim</span><span class="p">]</span> <span class="p">(</span><span class="n">dynamic</span> <span class="n">dimension</span> <span class="nb">range</span> <span class="n">of</span> <span class="n">model</span> <span class="nb">input</span><span class="p">,</span> <span class="k">for</span> <span class="n">dynamic</span> <span class="n">shape</span><span class="p">)</span>
<span class="n">opt_Dims</span><span class="o">=</span><span class="p">[</span><span class="n">opt_dim</span><span class="p">]</span> <span class="p">(</span><span class="n">the</span> <span class="n">optimal</span> <span class="nb">input</span> <span class="n">dimension</span> <span class="n">of</span> <span class="n">the</span> <span class="n">model</span><span class="p">,</span> <span class="k">for</span> <span class="n">dynamic</span> <span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Usage 3: For the large model, when using the model buffer to load and compile, you need to set the path
of the weight file separately through passing the path of the large model. And it is necessary to ensure
that the large model file and the folder where the weight file is located are in the same folder.
For example, when the directory is as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>.
└── /home/user/
     ├── model_graph.mindir
     └── model_variables
          └── data_0
</pre></div>
</div>
<p>The content and description of the configuration file are as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">model_file</span><span class="p">]</span>
<span class="n">mindir_path</span><span class="o">=</span><span class="p">[</span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">model_graph</span><span class="o">.</span><span class="n">mindir</span><span class="p">](</span><span class="n">storage</span> <span class="n">path</span> <span class="n">of</span> <span class="n">the</span> <span class="n">large</span> <span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</dd>
</dl>
<p class="rubric">样例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># create default context, which target is cpu by default.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore_lite</span> <span class="k">as</span> <span class="nn">mslite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Context</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
<span class="go">target: [&#39;cpu&#39;].</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># testcase 2 about context&#39;s attribute parallel based on server inference package</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># (export MSLITE_ENABLE_SERVER_INFERENCE=on before compile lite or use cloud inference package)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore_lite</span> <span class="k">as</span> <span class="nn">mslite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Context</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;cpu&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">workers_num</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">config_info</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model_file&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;mindir_path&quot;</span><span class="p">:</span> <span class="s2">&quot;/home/user/model_graph.mindir&quot;</span><span class="p">}}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">config_path</span> <span class="o">=</span> <span class="s2">&quot;/home/user/config.txt&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">parallel</span><span class="p">)</span>
<span class="go">workers num: 4,</span>
<span class="go">config info: model_file: mindir_path /home/user/model_graph.mindir,</span>
<span class="go">config path: /home/user/config.txt.</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore_lite.Context.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore_lite/context.html#Context.__init__"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_lite.Context.__init__" title="打开链接"></a></dt>
<dd></dd></dl>

<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mindspore_lite.Context.__init__" title="mindspore_lite.Context.__init__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__init__</span></code></a>()</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p class="rubric">Attributes</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">target</span></code></p></td>
<td><p>Get the target device information of context.</p></td>
</tr>
</tbody>
</table>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../mindspore_lite.html" class="btn btn-neutral float-left" title="mindspore_lite" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="mindspore_lite.FmkType.html" class="btn btn-neutral float-right" title="mindspore_lite.FmkType" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2021, MindSpore Lite.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>