

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore_lite.Converter &mdash; MindSpore Lite master 文档</title>
  

  
  <link rel="stylesheet" href="../_static/collapsible-lists/css/tree_view.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/translations.js"></script>
        <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
        <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="mindspore_lite.ModelType" href="mindspore_lite.ModelType.html" />
    <link rel="prev" title="mindspore_lite.FmkType" href="mindspore_lite.FmkType.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore Lite
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_NN.html">mindspore::NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_api.html">mindspore::api</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_api_utils.html">mindspore::api::utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_converter.html">mindspore::converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_dataset.html">mindspore::dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_dataset_transforms.html">mindspore::dataset::transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_kernel.html">mindspore::kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_ops.html">mindspore::ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_registry.html">mindspore::registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/mindspore_registry_opencl.html">mindspore::registry::opencl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_cpp/lite_cpp_example.html">样例</a></li>
</ul>
<p class="caption"><span class="caption-text">JAVA API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_java/class_list.html">类列表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/model_parallel_runner.html">ModelParallelRunner</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/mscontext.html">MSContext</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/mstensor.html">MSTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/runner_config.html">RunnerConfig</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/graph.html">Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_java/lite_java_example.html">样例</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore_lite.html">mindspore_lite</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../mindspore_lite.html#运行环境">运行环境</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore_lite.html#转换">转换</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="mindspore_lite.FmkType.html">mindspore_lite.FmkType</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">mindspore_lite.Converter</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore_lite.html#模型">模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore_lite.html#张量">张量</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">C API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_c/context_c.html">context_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/data_type_c.html">data_type_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/format_c.html">format_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/model_c.html">model_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/tensor_c.html">tensor_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/types_c.html">types_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_c/lite_c_example.html">样例</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../mindspore_lite.html">mindspore_lite</a> &raquo;</li>
        
      <li>mindspore_lite.Converter</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/mindspore_lite/mindspore_lite.Converter.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="mindspore-lite-converter">
<h1>mindspore_lite.Converter<a class="headerlink" href="#mindspore-lite-converter" title="永久链接至标题">¶</a></h1>
<dl class="class">
<dt id="mindspore_lite.Converter">
<em class="property">class </em><code class="sig-prename descclassname">mindspore_lite.</code><code class="sig-name descname">Converter</code><a class="reference internal" href="../_modules/mindspore_lite/converter.html#Converter"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore_lite.Converter" title="打开链接">¶</a></dt>
<dd><p>构造 <cite>Converter</cite> 的类。</p>
<p>适用于以下场景：</p>
<ol class="arabic simple">
<li><p>将第三方模型转换生成MindSpore模型或MindSpore Lite模型。</p></li>
<li><p>将MindSpore模型转换生成MindSpore模型或MindSpore Lite模型。</p></li>
</ol>
<p>推荐转换为MindSpore模型。目前，支持转换为MindSpore Lite模型，但是该选项将会被废弃。如有需要，请使用 <a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/r2.0/use/cloud_infer/converter_tool.html">推理模型离线转换</a> 来替换Python接口。Model接口和ModelParallelRunner接口只支持MindSpore模型。</p>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>请先构造Converter类，再通过执行Converter.convert()方法生成模型。</p>
<p>加解密功能仅在编译时设置为 <cite>MSLITE_ENABLE_MODEL_ENCRYPTION=on</cite> 时生效，并且仅支持Linux x86平台。其中密钥为十六进制表示的字符串，如encrypt_key设置为”30313233343536373839414243444546”，对应的十六进制表示为 <cite>(b)0123456789ABCDEF</cite> ，Linux平台用户可以使用 <cite>xxd</cite> 工具对字节表示的密钥进行十六进制表达转换。需要注意的是，加解密算法在1.7版本进行了更新，导致新版的Python接口不支持对1.6及其之前版本的MindSpore Lite加密导出的模型进行转换。</p>
</div>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># testcase 1 based on cloud inference package without train_model.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore_lite</span> <span class="k">as</span> <span class="nn">mslite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Converter</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The ms model may be generated only after converter.convert() is executed after the class is constructed.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">weight_fp16</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inTensor1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">input_format</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Format</span><span class="o">.</span><span class="n">NHWC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">input_data_type</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">DataType</span><span class="o">.</span><span class="n">FLOAT32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">output_data_type</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">DataType</span><span class="o">.</span><span class="n">FLOAT32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">save_type</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">ModelType</span><span class="o">.</span><span class="n">MINDIR_LITE</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">decrypt_key</span> <span class="o">=</span> <span class="s2">&quot;30313233343637383939414243444546&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">decrypt_mode</span> <span class="o">=</span> <span class="s2">&quot;AES-GCM&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">enable_encryption</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">encrypt_key</span> <span class="o">=</span> <span class="s2">&quot;30313233343637383939414243444546&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">infer</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">optimize</span> <span class="o">=</span> <span class="s2">&quot;general&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;Ascend&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">section</span> <span class="o">=</span> <span class="s2">&quot;common_quant_param&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config_info_in</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;quant_type&quot;</span><span class="p">:</span> <span class="s2">&quot;WEIGHT_QUANT&quot;</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">set_config_info</span><span class="p">(</span><span class="n">section</span><span class="p">,</span> <span class="n">config_info_in</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">converter</span><span class="o">.</span><span class="n">get_config_info</span><span class="p">())</span>
<span class="go">{&#39;common_quant_param&#39;: {&#39;quant_type&#39;: &#39;WEIGHT_QUANT&#39;}}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">converter</span><span class="p">)</span>
<span class="go">config_info: {&#39;common_quant_param&#39;: {&#39;quant_type&#39;: &#39;WEIGHT_QUANT&#39;}},</span>
<span class="go">weight_fp16: True,</span>
<span class="go">input_shape: {&#39;inTensor1&#39;: [1, 3, 32, 32]},</span>
<span class="go">input_format: Format.NHWC,</span>
<span class="go">input_data_type: DataType.FLOAT32,</span>
<span class="go">output_data_type: DataType.FLOAT32,</span>
<span class="go">save_type: ModelType.MINDIR_LITE,</span>
<span class="go">decrypt_key: 30313233343637383939414243444546,</span>
<span class="go">decrypt_mode: AES-GCM,</span>
<span class="go">enable_encryption: True,</span>
<span class="go">encrypt_key: 30313233343637383939414243444546,</span>
<span class="go">infer: True,</span>
<span class="go">optimize: general,</span>
<span class="go">device: Ascend.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># testcase 2 based on lite inference package with train_model.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore_lite</span> <span class="k">as</span> <span class="nn">mslite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Converter</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The ms model may be generated only after converter.convert() is executed after the class is constructed.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">train_model</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">converter</span><span class="o">.</span><span class="n">train_model</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore_lite.Converter.convert">
<code class="sig-name descname">convert</code><span class="sig-paren">(</span><em class="sig-param">fmk_type</em>, <em class="sig-param">model_file</em>, <em class="sig-param">output_file</em>, <em class="sig-param">weight_file=&quot;&quot;</em>, <em class="sig-param">config_file=&quot;&quot;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore_lite/converter.html#Converter.convert"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore_lite.Converter.convert" title="打开链接">¶</a></dt>
<dd><p>执行转换，将第三方模型转换为MindSpore模型或MindSpore Lite模型。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>fmk_type</strong> (FmkType) - 输入模型框架类型。选项有FmkType.TF | FmkType.CAFFE | FmkType.ONNX | FmkType.MINDIR | FmkType.TFLITE | FmkType.PYTORCH。有关详细信息，请参见 <a class="reference external" href="https://mindspore.cn/lite/api/zh-CN/r2.0/mindspore_lite/mindspore_lite.FmkType.html">框架类型</a> 。</p></li>
<li><p><strong>model_file</strong> (str) - 转换时的输入模型文件路径。例如：”/home/user/model.prototxt”。选项有TF: “model.pb” | CAFFE: “model.prototxt” | ONNX: “model.onnx” | MINDIR: “model.mindir” | TFLITE: “model.tflite” | PYTORCH: “model.pt or model.pth”。</p></li>
<li><p><strong>output_file</strong> (str) - 转换时的输出模型文件路径。可自动生成.ms或.mindir后缀。如果将 <cite>save_type</cite> 设置为ModelType.MINDIR，那么将生成MindSpore模型，该模型使用.mindir作为后缀。如果将 <cite>save_type</cite> 设置为ModelType.MINDIR_LITE，那么将生成MindSpore Lite模型，该模型使用.ms作为后缀。例如：输入模型为”/home/user/model.prototxt”，将 <cite>save_type</cite> 设置为ModelType.MINDIR，它将生成名为model.prototxt.mindir的模型在/home/user/路径下。</p></li>
<li><p><strong>weight_file</strong> (str，可选) - 输入模型权重文件。仅当输入模型框架类型为FmkType.CAFFE时必选，Caffe模型一般分为两个文件： <cite>model.prototxt</cite> 是模型结构，对应 <cite>model_file</cite> 参数； <cite>model.caffemodel</cite> 是模型权值文件，对应 <cite>weight_file</cite> 参数。例如：”/home/user/model.caffemodel”。默认值：””，表示无模型权重文件。</p></li>
<li><p><strong>config_file</strong> (str，可选) - Converter的配置文件，可配置训练后量化或离线拆分算子并行或禁用算子融合功能并将插件设置为so路径等功能。 <cite>config_file</cite> 配置文件采用 <cite>key = value</cite> 的方式定义相关参数，有关训练后量化的配置参数，请参见 <a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/r2.0/use/post_training_quantization.html">训练后量化</a> 。有关扩展的配置参数，请参见 <a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/r2.0/use/nnie.html#扩展配置">扩展配置</a> 。例如：”/home/user/model.cfg”。默认值：””，表示不设置Converter的配置文件。</p></li>
</ul>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>TypeError</strong> - <cite>fmk_type</cite> 不是FmkType类型。</p></li>
<li><p><strong>TypeError</strong> - <cite>model_file</cite> 不是str类型。</p></li>
<li><p><strong>TypeError</strong> - <cite>output_file</cite> 不是str类型。</p></li>
<li><p><strong>TypeError</strong> - <cite>weight_file</cite> 不是str类型。</p></li>
<li><p><strong>TypeError</strong> - <cite>config_file</cite> 不是str类型。</p></li>
<li><p><strong>RuntimeError</strong> - <cite>model_file</cite> 文件路径不存在。</p></li>
<li><p><strong>RuntimeError</strong> - 当 <cite>model_file</cite> 不是””时， <cite>model_file</cite> 文件路径不存在。</p></li>
<li><p><strong>RuntimeError</strong> - 当 <cite>config_file</cite> 不是””时， <cite>config_file</cite> 文件路径不存在。</p></li>
<li><p><strong>RuntimeError</strong> - 转换模型失败。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore_lite</span> <span class="k">as</span> <span class="nn">mslite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Converter</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">mslite</span><span class="o">.</span><span class="n">FmkType</span><span class="o">.</span><span class="n">TFLITE</span><span class="p">,</span> <span class="s2">&quot;./mobilenetv2/mobilenet_v2_1.0_224.tflite&quot;</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="s2">&quot;mobilenet_v2_1.0_224.tflite&quot;</span><span class="p">)</span>
<span class="go">CONVERT RESULT SUCCESS:0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mobilenet_v2_1.0_224.tflite.ms model will be generated.</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.decrypt_key">
<em class="property">property </em><code class="sig-name descname">decrypt_key</code><a class="headerlink" href="#mindspore_lite.Converter.decrypt_key" title="打开链接">¶</a></dt>
<dd><p>获取用于加载密文MindIR时的密钥。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>str，用于加载密文MindIR时的密钥，以十六进制字符表示。仅当fmk_type为FmkType.MINDIR时有效。</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.decrypt_mode">
<em class="property">property </em><code class="sig-name descname">decrypt_mode</code><a class="headerlink" href="#mindspore_lite.Converter.decrypt_mode" title="打开链接">¶</a></dt>
<dd><p>获取加载密文MindIR的模式。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>str，加载密文MindIR的模式。只在设置了 <cite>decryptKey</cite> 时有效。选项有”AES-GCM” | “AES-CBC”。</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.device">
<em class="property">property </em><code class="sig-name descname">device</code><a class="headerlink" href="#mindspore_lite.Converter.device" title="打开链接">¶</a></dt>
<dd><p>获取转换模型时的目标设备。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>str，转换模型时的目标设备。仅对Ascend设备有效。使用场景是在Ascend设备上，如果你需要转换生成的模型调用Ascend后端执行推理，则设置该参数，若未设置，默认模型调用CPU后端推理。支持以下目标设备：”Ascend”。</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.enable_encryption">
<em class="property">property </em><code class="sig-name descname">enable_encryption</code><a class="headerlink" href="#mindspore_lite.Converter.enable_encryption" title="打开链接">¶</a></dt>
<dd><p>获取导出模型时是否加密的状态。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>bool，导出模型时是否加密。导出加密可保护模型完整性，但会增加运行时初始化时间。</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.encrypt_key">
<em class="property">property </em><code class="sig-name descname">encrypt_key</code><a class="headerlink" href="#mindspore_lite.Converter.encrypt_key" title="打开链接">¶</a></dt>
<dd><p>获取用于加密文件的密钥。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>str，用于加密文件的密钥，以十六进制字符表示。仅在当 <cite>decrypt_mode</cite> 是”AES-GCM”时支持使用该属性，密钥长度为16。</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.get_config_info">
<code class="sig-name descname">get_config_info</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore_lite/converter.html#Converter.get_config_info"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore_lite.Converter.get_config_info" title="打开链接">¶</a></dt>
<dd><p>获取Converter的配置信息。配套 <cite>set_config_info</cite> 方法使用，用于在线推理场景。在 <cite>get_config_info</cite> 前，请先用 <cite>set_config_info</cite> 方法赋值。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>dict{str: dict{str: str}}，在Converter中设置的配置信息。</p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore_lite</span> <span class="k">as</span> <span class="nn">mslite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Converter</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">section</span> <span class="o">=</span> <span class="s2">&quot;common_quant_param&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config_info_in</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;quant_type&quot;</span><span class="p">:</span> <span class="s2">&quot;WEIGHT_QUANT&quot;</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">set_config_info</span><span class="p">(</span><span class="n">section</span><span class="p">,</span> <span class="n">config_info_in</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config_info_out</span> <span class="o">=</span> <span class="n">converter</span><span class="o">.</span><span class="n">get_config_info</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">config_info_out</span><span class="p">)</span>
<span class="go">{&#39;common_quant_param&#39;: {&#39;quant_type&#39;: &#39;WEIGHT_QUANT&#39;}}</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.infer">
<em class="property">property </em><code class="sig-name descname">infer</code><a class="headerlink" href="#mindspore_lite.Converter.infer" title="打开链接">¶</a></dt>
<dd><p>获取是否转换完成时进行预推理的状态。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>bool， 是否在转换完成时进行预推理。</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.input_data_type">
<em class="property">property </em><code class="sig-name descname">input_data_type</code><a class="headerlink" href="#mindspore_lite.Converter.input_data_type" title="打开链接">¶</a></dt>
<dd><p>获取量化模型输入Tensor的数据类型。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>DataType，量化模型输入Tensor的数据类型。仅当模型输入Tensor的量化参数（ <cite>scale</cite> 和 <cite>zero point</cite> ）都具备时有效。默认与原始模型输入Tensor的data type保持一致。支持以下4种数据类型：DataType.FLOAT32 | DataType.INT8 | DataType.UINT8 | DataType.UNKNOWN。默认值：DataType.FLOAT32。有关详细信息，请参见 <a class="reference external" href="https://mindspore.cn/lite/api/zh-CN/r2.0/mindspore_lite/mindspore_lite.DataType.html">数据类型</a> 。</p>
<ul class="simple">
<li><p><strong>DataType.FLOAT32</strong> - 32位浮点数。</p></li>
<li><p><strong>DataType.INT8</strong>    - 8位整型数。</p></li>
<li><p><strong>DataType.UINT8</strong>   - 无符号8位整型数。</p></li>
<li><p><strong>DataType.UNKNOWN</strong> - 设置与模型输入Tensor相同的DataType。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.input_format">
<em class="property">property </em><code class="sig-name descname">input_format</code><a class="headerlink" href="#mindspore_lite.Converter.input_format" title="打开链接">¶</a></dt>
<dd><p>获取模型的输入format。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>Format，模型的输入format。仅对四维输入有效。支持以下2种输入格式：Format.NCHW | Format.NHWC。默认值：Format.NHWC。有关详细信息，请参见 <a class="reference external" href="https://mindspore.cn/lite/api/zh-CN/r2.0/mindspore_lite/mindspore_lite.Format.html">数据格式</a> 。</p>
<ul class="simple">
<li><p><strong>Format.NCHW</strong> - 按批次N、通道C、高度H和宽度W的顺序存储Tensor数据。</p></li>
<li><p><strong>Format.NHWC</strong> - 按批次N、高度H、宽度W和通道C的顺序存储Tensor数据。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.input_shape">
<em class="property">property </em><code class="sig-name descname">input_shape</code><a class="headerlink" href="#mindspore_lite.Converter.input_shape" title="打开链接">¶</a></dt>
<dd><p>获取模型输入的维度。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>dict{str, list[int]}，模型输入的维度。输入维度的顺序与原始模型一致。在以下场景下，用户可能需要设置该参数。例如：{“inTensor1”: [1, 32, 32, 32], “inTensor2”: [1, 1, 32, 32]}。默认值：None，等同于设置为{}。</p>
<ul class="simple">
<li><p><strong>用法1</strong> - 待转换模型的输入是动态shape，准备采用固定shape推理，则设置该参数为固定shape。设置之后，在对Converter后的模型进行推理时，默认输入的shape与该参数设置一样，无需再进行resize操作。</p></li>
<li><p><strong>用法2</strong> - 无论待转换模型的原始输入是否为动态shape，准备采用固定shape推理，并希望模型的性能尽可能优化，则设置该参数为固定shape。设置之后，将对模型结构进一步优化，但转换后的模型可能会失去动态shape的特征（部分跟shape强相关的算子会被融合）。</p></li>
<li><p><strong>用法3</strong> - 使用Converter功能来生成用于Micro推理执行代码时，推荐配置该参数，以减少部署过程中出错的概率。当模型含有Shape算子或者待转换模型输入为动态shape时，则必须配置该参数，设置固定shape，以支持相关shape优化和代码生成。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.optimize">
<em class="property">property </em><code class="sig-name descname">optimize</code><a class="headerlink" href="#mindspore_lite.Converter.optimize" title="打开链接">¶</a></dt>
<dd><p>获取是否融合优化的状态。</p>
<p>optimize是用来设定在离线转换的过程中需要完成哪些特定的优化。如果该参数设置为”none”，那么在模型的离线转换阶段将不进行相关的图优化操作，相关的图优化操作将会在执行推理阶段完成。该参数的优点在于转换出来的模型由于没有经过特定的优化，可以直接部署到CPU/GPU/Ascend任意硬件后端；而带来的缺点是推理执行时模型的初始化时间增长。如果设置成”general”，表示离线转换过程会完成通用优化，包括常量折叠，算子融合等（转换出的模型只支持CPU/GPU后端，不支持Ascend后端）。如果设置成”ascend_oriented”，表示转换过程中只完成针对Ascend后端的优化（转换出来的模型只支持Ascend后端）。</p>
<p>针对MindSpore模型，由于已经是mindir模型，建议两种做法：</p>
<ol class="arabic simple">
<li><p>不需要经过离线转换，直接进行推理执行。</p></li>
<li><p>使用离线转换，CPU/GPU后端设置optimize为”general”，NPU后端设置optimize为”ascend_oriented”，在离线阶段完成相关优化，减少推理执行的初始化时间。</p></li>
</ol>
<dl class="simple">
<dt>返回：</dt><dd><p>str，是否融合优化。选项有”none” | “general” | “ascend_oriented”。”none” 表示不允许融合优化。 “general” 和 “ascend_oriented” 表示允许融合优化。</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.output_data_type">
<em class="property">property </em><code class="sig-name descname">output_data_type</code><a class="headerlink" href="#mindspore_lite.Converter.output_data_type" title="打开链接">¶</a></dt>
<dd><p>获取量化模型输出Tensor的data type。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>DataType，量化模型输出Tensor的data type。仅当模型输出Tensor的量化参数（scale和zero point）都具备时有效。默认与原始模型输出Tensor的data type保持一致。支持以下4种数据类型：DataType.FLOAT32 | DataType.INT8 | DataType.UINT8 | DataType.UNKNOWN。有关详细信息，请参见 <a class="reference external" href="https://mindspore.cn/lite/api/zh-CN/r2.0/mindspore_lite/mindspore_lite.DataType.html">数据类型</a> 。</p>
<ul class="simple">
<li><p><strong>DataType.FLOAT32</strong> - 32位浮点数。</p></li>
<li><p><strong>DataType.INT8</strong>    - 8位整型数。</p></li>
<li><p><strong>DataType.UINT8</strong>   - 无符号8位整型数。</p></li>
<li><p><strong>DataType.UNKNOWN</strong> - 设置与模型输出Tensor相同的DataType。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.save_type">
<em class="property">property </em><code class="sig-name descname">save_type</code><a class="headerlink" href="#mindspore_lite.Converter.save_type" title="打开链接">¶</a></dt>
<dd><p>获取导出模型文件的类型。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>ModelType，导出模型文件的类型。选项有ModelType.MINDIR | ModelType.MINDIR_LITE。推荐转换为MindSpore模型。目前，支持转换为MindSpore Lite模型，但是该选项将会被废弃。有关详细信息，请参见 <a class="reference external" href="https://mindspore.cn/lite/api/zh-CN/r2.0/mindspore_lite/mindspore_lite.ModelType.html">模型类型</a> 。</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.set_config_info">
<code class="sig-name descname">set_config_info</code><span class="sig-paren">(</span><em class="sig-param">section=&quot;&quot;</em>, <em class="sig-param">config_info=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore_lite/converter.html#Converter.set_config_info"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore_lite.Converter.set_config_info" title="打开链接">¶</a></dt>
<dd><p>设置Converter时的配置信息。配套 <cite>get_config_info</cite> 方法使用，用于在线推理场景。</p>
<dl>
<dt>参数：</dt><dd><ul>
<li><p><strong>section</strong> (str，可选) - 配置参数的类别。配合 <cite>config_info</cite> 一起，设置confile的个别参数。例如：对于 <cite>section</cite> 是”common_quant_param”， <cite>config_info</cite> 是{“quant_type”:”WEIGHT_QUANT”}。默认值：””。</p>
<p>有关训练后量化的配置参数，请参见 <a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/r2.0/use/post_training_quantization.html">训练后量化</a> 。</p>
<p>有关扩展的配置参数，请参见 <a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/r2.0/use/nnie.html#扩展配置">扩展配置</a> 。</p>
<ul class="simple">
<li><p>“common_quant_param”：公共量化参数部分。</p></li>
<li><p>“mixed_bit_weight_quant_param”：混合位权重量化参数部分。</p></li>
<li><p>“full_quant_param”：全量化参数部分。</p></li>
<li><p>“data_preprocess_param”：数据预处理量化参数部分。</p></li>
<li><p>“registry”：扩展配置参数部分。</p></li>
</ul>
</li>
<li><p><strong>config_info</strong> (dict{str: str}，可选) - 配置参数列表。配合 <cite>section</cite> 一起，设置confile的个别参数。例如：对于 <cite>section</cite> 是”common_quant_param”， <cite>config_info</cite> 是{“quant_type”:”WEIGHT_QUANT”}。默认值：None。</p>
<p>有关训练后量化的配置参数，请参见 <a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/r2.0/use/post_training_quantization.html">训练后量化</a> 。</p>
<p>有关扩展的配置参数，请参见 <a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/r2.0/use/nnie.html#扩展配置">扩展配置</a> 。</p>
</li>
</ul>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>TypeError</strong> - <cite>section</cite> 不是str类型。</p></li>
<li><p><strong>TypeError</strong> - <cite>config_info</cite> 不是dict类型。</p></li>
<li><p><strong>TypeError</strong> - <cite>config_info</cite> 是dict类型，但key不是str类型。</p></li>
<li><p><strong>TypeError</strong> - <cite>config_info</cite> 是dict类型，key是str类型，但value不是str类型。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore_lite</span> <span class="k">as</span> <span class="nn">mslite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span> <span class="o">=</span> <span class="n">mslite</span><span class="o">.</span><span class="n">Converter</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">section</span> <span class="o">=</span> <span class="s2">&quot;common_quant_param&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config_info</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;quant_type&quot;</span><span class="p">:</span> <span class="s2">&quot;WEIGHT_QUANT&quot;</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">converter</span><span class="o">.</span><span class="n">set_config_info</span><span class="p">(</span><span class="n">section</span><span class="p">,</span> <span class="n">config_info</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore_lite.Converter.weight_fp16">
<em class="property">property </em><code class="sig-name descname">weight_fp16</code><a class="headerlink" href="#mindspore_lite.Converter.weight_fp16" title="打开链接">¶</a></dt>
<dd><p>获取模型是否保存为Float16数据类型的状态。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>bool，模型是否保存为Float16数据类型。若True，则在转换时，会将模型中Float32的常量Tensor保存成Float16数据类型，压缩生成的模型尺寸。之后根据 <cite>Context.CPU</cite> 的 <cite>precision_mode</cite> 参数决定输入的数据类型执行推理。 <cite>weight_fp16</cite> 的优先级很低，如果开启了量化，那么对于已经量化的权重， <cite>weight_fp16</cite> 不会再次生效。 <cite>weight_fp16</cite> 仅对Float32数据类型中的常量Tensor有效。</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="mindspore_lite.ModelType.html" class="btn btn-neutral float-right" title="mindspore_lite.ModelType" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="mindspore_lite.FmkType.html" class="btn btn-neutral float-left" title="mindspore_lite.FmkType" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2021, MindSpore Lite.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>