<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore_lite.context &mdash; MindSpore Lite master 文档</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../../_static/collapsible-lists/css/tree_view.css" type="text/css" /><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script><script src="../../_static/jquery.js"></script>
        <script src="../../_static/js/theme.js"></script><script src="../../_static/underscore.js"></script><script src="../../_static/doctools.js"></script><script src="../../_static/translations.js"></script><script src="../../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script><script src="../../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_api.html">mindspore::api</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_api_utils.html">mindspore::api::utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_converter.html">mindspore::converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_dataset.html">mindspore::dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_dataset_config.html">mindspore::dataset::config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_dataset_text.html">mindspore::dataset::text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_dataset_transforms.html">mindspore::dataset::transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_dataset_vision.html">mindspore::dataset::vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_kernel.html">mindspore::kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_ops.html">mindspore::ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_registry.html">mindspore::registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/mindspore_registry_opencl.html">mindspore::registry::opencl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_cpp/lite_cpp_example.html">样例</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">JAVA API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/class_list.html">类列表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/model_parallel_runner.html">ModelParallelRunner</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/mscontext.html">MSContext</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/mstensor.html">MSTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/runner_config.html">RunnerConfig</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/graph.html">Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_java/lite_java_example.html">样例</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore_lite.html">mindspore_lite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">C API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_c/context_c.html">context_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_c/data_type_c.html">data_type_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_c/format_c.html">format_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_c/model_c.html">model_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_c/tensor_c.html">tensor_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_c/types_c.html">types_c</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_c/lite_c_example.html">样例</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">模块代码</a> &raquo;</li>
      <li>mindspore_lite.context</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>mindspore_lite.context 源代码</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2022-2023 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ============================================================================</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Context API.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">from</span> <span class="nn">mindspore_lite._checkparam</span> <span class="kn">import</span> <span class="n">check_isinstance</span><span class="p">,</span> <span class="n">check_list_of_element</span>
<span class="kn">from</span> <span class="nn">mindspore_lite.lib</span> <span class="kn">import</span> <span class="n">_c_lite_wrapper</span>
<span class="kn">from</span> <span class="nn">mindspore_lite._check_ascend</span> <span class="kn">import</span> <span class="n">AscendEnvChecker</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Context&#39;</span><span class="p">]</span>


<div class="viewcode-block" id="Context"><a class="viewcode-back" href="../../mindspore_lite/mindspore_lite.Context.html#mindspore_lite.Context">[文档]</a><span class="k">class</span> <span class="nc">Context</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The `Context` class is used to transfer environment variables during execution.</span>

<span class="sd">    The context should be configured before running the program.</span>
<span class="sd">    If it is not configured, the `target` will be set to ``cpu``, and automatically set ``cpu`` attributes by default.</span>

<span class="sd">    Context.parallel defines the context and configuration of `ModelParallelRunner` class.</span>

<span class="sd">    Context.parallel properties:</span>
<span class="sd">        - **workers_num** (int) - the num of workers. A `ModelParallelRunner` contains multiple workers, which</span>
<span class="sd">          are the units that actually perform parallel inferring. Setting `workers_num` to 0 represents</span>
<span class="sd">          `workers_num` will be automatically adjusted based on computer performance and core numbers.</span>
<span class="sd">        - **config_info** (dict{str, dict{str, str}}) - Nested map for transferring user defined options during building</span>
<span class="sd">          `ModelParallelRunner` online. More configurable options refer to `config_path` .</span>
<span class="sd">          For example, ``{&quot;model_file&quot;: {&quot;mindir_path&quot;: &quot;/home/user/model_graph.mindir&quot;}}``.</span>
<span class="sd">          `section` is ``&quot;model_file&quot;``, one of the keys is ``&quot;mindir_path&quot;``,</span>
<span class="sd">          the corresponding value in the map is ``&quot;/home/user/model_graph.mindir&quot;``.</span>
<span class="sd">        - **config_path** (str) - Set the config file path. The config file is used to transfer user-defined</span>
<span class="sd">          options during building `ModelParallelRunner` . In the following scenarios, users may need to set the</span>
<span class="sd">          parameter. For example, ``&quot;/home/user/config.txt&quot;``.</span>

<span class="sd">          - Usage 1: Set mixed precision inference. The content and description of the configuration file are as</span>
<span class="sd">            follows:</span>

<span class="sd">            .. code-block::</span>

<span class="sd">                [execution_plan]</span>
<span class="sd">                [op_name1]=data_Type: float16 (The operator named op_name1 sets the data type as float16)</span>
<span class="sd">                [op_name2]=data_Type: float32 (The operator named op_name2 sets the data type as float32)</span>

<span class="sd">          - Usage 2: When GPU inference, set the configuration of TensorRT. The content and description of the</span>
<span class="sd">            configuration file are as follows:</span>

<span class="sd">            .. code-block::</span>

<span class="sd">                [ms_cache]</span>
<span class="sd">                serialize_Path=[serialization model path](storage path of serialization model)</span>
<span class="sd">                [gpu_context]</span>
<span class="sd">                input_shape=input_Name: [input_dim] (Model input dimension, for dynamic shape)</span>
<span class="sd">                dynamic_Dims=[min_dim~max_dim] (dynamic dimension range of model input, for dynamic shape)</span>
<span class="sd">                opt_Dims=[opt_dim] (the optimal input dimension of the model, for dynamic shape)</span>

<span class="sd">          - Usage 3: For the large model, when using the model buffer to load and compile, you need to set the path</span>
<span class="sd">            of the weight file separately through passing the path of the large model. And it is necessary to ensure</span>
<span class="sd">            that the large model file and the folder where the weight file is located are in the same folder.</span>
<span class="sd">            For example, when the directory is as follows:</span>

<span class="sd">            .. code-block::</span>

<span class="sd">                .</span>
<span class="sd">                └── /home/user/</span>
<span class="sd">                     ├── model_graph.mindir</span>
<span class="sd">                     └── model_variables</span>
<span class="sd">                          └── data_0</span>

<span class="sd">            The content and description of the configuration file are as follows:</span>

<span class="sd">            .. code-block::</span>

<span class="sd">                [model_file]</span>
<span class="sd">                mindir_path=[/home/user/model_graph.mindir](storage path of the large model)</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # create default context, which target is cpu by default.</span>
<span class="sd">        &gt;&gt;&gt; import mindspore_lite as mslite</span>
<span class="sd">        &gt;&gt;&gt; context = mslite.Context()</span>
<span class="sd">        &gt;&gt;&gt; print(context)</span>
<span class="sd">        target: [&#39;cpu&#39;].</span>
<span class="sd">        &gt;&gt;&gt; # testcase 2 about context&#39;s attribute parallel based on server inference package</span>
<span class="sd">        &gt;&gt;&gt; # (export MSLITE_ENABLE_SERVER_INFERENCE=on before compile lite or use cloud inference package)</span>
<span class="sd">        &gt;&gt;&gt; import mindspore_lite as mslite</span>
<span class="sd">        &gt;&gt;&gt; context = mslite.Context()</span>
<span class="sd">        &gt;&gt;&gt; context.target = [&quot;cpu&quot;]</span>
<span class="sd">        &gt;&gt;&gt; context.parallel.workers_num = 4</span>
<span class="sd">        &gt;&gt;&gt; context.parallel.config_info = {&quot;model_file&quot;: {&quot;mindir_path&quot;: &quot;/home/user/model_graph.mindir&quot;}}</span>
<span class="sd">        &gt;&gt;&gt; context.parallel.config_path = &quot;/home/user/config.txt&quot;</span>
<span class="sd">        &gt;&gt;&gt; print(context.parallel)</span>
<span class="sd">        workers num: 4,</span>
<span class="sd">        config info: model_file: mindir_path /home/user/model_graph.mindir,</span>
<span class="sd">        config path: /home/user/config.txt.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_context</span> <span class="o">=</span> <span class="n">_InnerContext</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cpu</span> <span class="o">=</span> <span class="n">_CPU</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gpu</span> <span class="o">=</span> <span class="n">_GPU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ascend</span> <span class="o">=</span> <span class="n">_Ascend</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;cpu&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">_c_lite_wrapper</span><span class="p">,</span> <span class="s2">&quot;RunnerConfigBind&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parallel</span> <span class="o">=</span> <span class="n">_Parallel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;target: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">target</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the target device information of context.</span>

<span class="sd">        Currently support target: ``&quot;cpu&quot;`` , ``&quot;gpu&quot;`` , ``&quot;ascend&quot;``.</span>

<span class="sd">        Note:</span>
<span class="sd">            After gpu is added to target, cpu will be added automatically as the backup target.</span>
<span class="sd">            Because when ops are not supported on gpu, The system will try whether the cpu supports it.</span>
<span class="sd">            At that time, need to switch to the context with cpu.</span>

<span class="sd">            After Ascend is added, cpu will be added automatically as the backup target. when the inputs format of the</span>
<span class="sd">            original model is inconsistent with that of the model generated by Converter, the model generated by</span>
<span class="sd">            Converter on Ascend device will contain the &#39;Transpose&#39; node, which needs to be executed on the cpu device</span>
<span class="sd">            currently. So it needs to switch to the context with cpu target.</span>

<span class="sd">        cpu properties:</span>
<span class="sd">            - **inter_op_parallel_num** (int) - Set the parallel number of operators at runtime.</span>
<span class="sd">              `inter_op_parallel_num` cannot be greater than `thread_num` . Setting `inter_op_parallel_num`</span>
<span class="sd">              to ``0`` represents `inter_op_parallel_num` will be automatically adjusted based on computer</span>
<span class="sd">              performance and core num.</span>
<span class="sd">            - **precision_mode** (str) - Set the mix precision mode. Options are ``&quot;preferred_fp16&quot;`` ,</span>
<span class="sd">              ``&quot;enforce_fp32&quot;``.</span>

<span class="sd">              - ``&quot;preferred_fp16&quot;`` : prefer to use fp16.</span>
<span class="sd">              - ``&quot;enforce_fp32&quot;`` : force use fp32.</span>

<span class="sd">            - **thread_num** (int) - Set the number of threads at runtime. `thread_num` cannot be less than</span>
<span class="sd">              `inter_op_parallel_num` . Setting `thread_num` to 0 represents `thread_num` will be automatically</span>
<span class="sd">              adjusted based on computer performance and core numbers.</span>
<span class="sd">            - **thread_affinity_mode** (int) - Set the mode of the CPU core binding policy at runtime. The</span>
<span class="sd">              following `thread_affinity_mode` are supported.</span>

<span class="sd">              - ``0`` : no binding core.</span>
<span class="sd">              - ``1`` : binding big cores first.</span>
<span class="sd">              - ``2`` : binding middle cores first.</span>

<span class="sd">            - **thread_affinity_core_list** (list[int]) - Set the list of CPU core binding policies at runtime.</span>
<span class="sd">              For example, [0,1] represents the specified binding of CPU0 and CPU1.</span>

<span class="sd">        gpu properties:</span>
<span class="sd">            - **device_id** (int) - The device id.</span>
<span class="sd">            - **group_size** (int) - the number of the clusters. Get only, not settable.</span>
<span class="sd">            - **precision_mode** (str) - Set the mix precision mode. Options are ``&quot;preferred_fp16&quot;`` ,</span>
<span class="sd">              ``&quot;enforce_fp32&quot;``.</span>

<span class="sd">              - ``&quot;preferred_fp16&quot;``: prefer to use fp16.</span>
<span class="sd">              - ``&quot;enforce_fp32&quot;``: force use fp32.</span>

<span class="sd">            - **rank_id** (int) - the ID of the current device in the cluster, which starts from 0. Get only,</span>
<span class="sd">              not settable.</span>

<span class="sd">        ascend properties:</span>
<span class="sd">            - **device_id** (int) - The device id.</span>
<span class="sd">            - **precision_mode** (str) - Set the mix precision mode. Options are ``&quot;enforce_fp32&quot;`` ,</span>
<span class="sd">              ``&quot;preferred_fp32&quot;`` , ``&quot;enforce_fp16&quot;`` , ``&quot;enforce_origin&quot;`` , ``&quot;preferred_optimal&quot;``.</span>

<span class="sd">              - ``&quot;enforce_fp32&quot;``: ACL option is force_fp32, force use fp32.</span>
<span class="sd">              - ``&quot;preferred_fp32&quot;``: ACL option is allow_fp32_to_fp16, prefer to use fp32.</span>
<span class="sd">              - ``&quot;enforce_fp16&quot;``: ACL option is force_fp16, force use fp16.</span>
<span class="sd">              - ``&quot;enforce_origin&quot;``: ACL option is must_keep_origin_dtype, force use original type.</span>
<span class="sd">              - ``&quot;preferred_optimal&quot;``: ACL option is allow_mix_precision, prefer to use fp16+ mix precision mode.</span>

<span class="sd">            - **provider** (str) - The provider that supports the inference capability of the target device,</span>
<span class="sd">              can be ``&quot;&quot;`` or ``&quot;ge&quot;``. The default is ``&quot;&quot;``.</span>
<span class="sd">            - **rank_id** (int) - The ID of the current device in the cluster, which starts from ``0``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list[str], the target device information of context.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # create default context, which target is cpu by default.</span>
<span class="sd">            &gt;&gt;&gt; import mindspore_lite as mslite</span>
<span class="sd">            &gt;&gt;&gt; context = mslite.Context()</span>
<span class="sd">            &gt;&gt;&gt; # set context with cpu target.</span>
<span class="sd">            &gt;&gt;&gt; context.target = [&quot;cpu&quot;]</span>
<span class="sd">            &gt;&gt;&gt; print(context.target)</span>
<span class="sd">            [&#39;cpu&#39;]</span>
<span class="sd">            &gt;&gt;&gt; context.cpu.precision_mode = &quot;preferred_fp16&quot;</span>
<span class="sd">            &gt;&gt;&gt; context.cpu.thread_num = 2</span>
<span class="sd">            &gt;&gt;&gt; context.cpu.inter_op_parallel_num = 2</span>
<span class="sd">            &gt;&gt;&gt; context.cpu.thread_affinity_mode = 1</span>
<span class="sd">            &gt;&gt;&gt; context.cpu.thread_affinity_core_list = [0,1]</span>
<span class="sd">            &gt;&gt;&gt; print(context.cpu)</span>
<span class="sd">            device_type: DeviceType.kCPU,</span>
<span class="sd">            precision_mode: preferred_fp16,</span>
<span class="sd">            thread_num: 2,</span>
<span class="sd">            inter_op_parallel_num: 2,</span>
<span class="sd">            thread_affinity_mode: 1,</span>
<span class="sd">            thread_affinity_core_list: [0, 1].</span>
<span class="sd">            &gt;&gt;&gt; # set context with gpu target.</span>
<span class="sd">            &gt;&gt;&gt; context.target = [&quot;gpu&quot;]</span>
<span class="sd">            &gt;&gt;&gt; print(context.target)</span>
<span class="sd">            [&#39;gpu&#39;]</span>
<span class="sd">            &gt;&gt;&gt; context.gpu.precision_mode = &quot;preferred_fp16&quot;</span>
<span class="sd">            &gt;&gt;&gt; context.gpu.device_id = 2</span>
<span class="sd">            &gt;&gt;&gt; print(context.gpu.rank_id)</span>
<span class="sd">            0</span>
<span class="sd">            &gt;&gt;&gt; print(context.gpu.group_size)</span>
<span class="sd">            1</span>
<span class="sd">            &gt;&gt;&gt; print(context.gpu)</span>
<span class="sd">            device_type: DeviceType.kGPU,</span>
<span class="sd">            precision_mode: preferred_fp16,</span>
<span class="sd">            device_id: 2,</span>
<span class="sd">            rank_id: 0,</span>
<span class="sd">            group_size: 1.</span>
<span class="sd">            &gt;&gt;&gt; # set context with ascend target.</span>
<span class="sd">            &gt;&gt;&gt; context.target = [&quot;ascend&quot;]</span>
<span class="sd">            &gt;&gt;&gt; print(context.target)</span>
<span class="sd">            [&#39;ascend&#39;]</span>
<span class="sd">            &gt;&gt;&gt; context.ascend.precision_mode = &quot;enforce_fp32&quot;</span>
<span class="sd">            &gt;&gt;&gt; context.ascend.device_id = 2</span>
<span class="sd">            &gt;&gt;&gt; context.ascend.provider = &quot;ge&quot;</span>
<span class="sd">            &gt;&gt;&gt; context.ascend.rank_id = 0</span>
<span class="sd">            &gt;&gt;&gt; print(context.ascend)</span>
<span class="sd">            device_type: DeviceType.kAscend,</span>
<span class="sd">            precision_mode: enforce_fp32,</span>
<span class="sd">            device_id: 2,</span>
<span class="sd">            provider: ge,</span>
<span class="sd">            rank_id: 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_target</span>

    <span class="nd">@target</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">target</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the target device information of context.</span>

<span class="sd">        Args:</span>
<span class="sd">            target (list[str]): the target device information of context.</span>
<span class="sd">            Currently support target: [&quot;cpu&quot;] | [&quot;gpu&quot;] | [&quot;ascend&quot;].</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `target` is not a list.</span>
<span class="sd">            TypeError: `target` is a list, but the elements are not str.</span>
<span class="sd">            ValueError: `target` is a list, but the elements are not in [&#39;cpu&#39;, &#39;gpu&#39;, &#39;ascend&#39;].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;cpu&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">target</span> <span class="k">else</span> <span class="n">target</span>
        <span class="n">check_list_of_element</span><span class="p">(</span><span class="s2">&quot;target&quot;</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">ele</span> <span class="ow">in</span> <span class="n">target</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ele</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="s2">&quot;ascend&quot;</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;target elements must be in [&#39;cpu&#39;, &#39;gpu&#39;, &#39;ascend&#39;], but got </span><span class="si">{</span><span class="n">ele</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="o">.</span><span class="n">clear_target</span><span class="p">()</span>
        <span class="n">need_cpu_backup</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">ele</span> <span class="ow">in</span> <span class="n">target</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ele</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;ascend&quot;</span><span class="p">:</span>
                <span class="n">ascend_checker</span> <span class="o">=</span> <span class="n">AscendEnvChecker</span><span class="p">()</span>
                <span class="n">ascend_checker</span><span class="o">.</span><span class="n">check_env</span><span class="p">()</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="o">.</span><span class="n">append_device_info</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ascend</span><span class="p">)</span>
                <span class="n">need_cpu_backup</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="n">ele</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;gpu&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="o">.</span><span class="n">append_device_info</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
                <span class="n">need_cpu_backup</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="o">.</span><span class="n">append_device_info</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">need_cpu_backup</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="o">.</span><span class="n">append_device_info</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_target</span> <span class="o">=</span> <span class="n">target</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">group_info_file</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get or set communication group info file for distributed inference.</span>

<span class="sd">        In the pipeline parallel scenario, different stage device nodes are in different communication groups. When</span>
<span class="sd">        exporting the model, set the `group_ckpt_save_file` parameter in interface</span>
<span class="sd">        [mindspore.set_auto_parallel_context](https://www.mindspore.cn/docs/zh-CN/r2.3/api_python/mindspore/mindspore.set_auto_parallel_context.html)</span>
<span class="sd">        to export the group file information. In addition, in non pipeline parallel scenarios, if there</span>
<span class="sd">        are communication operators involving local communication groups, the group file information also needs to be</span>
<span class="sd">        exported through the &#39;group_ckpt_save_file&#39; parameter.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # export communication group information file when export mindir</span>
<span class="sd">            &gt;&gt;&gt; import mindspore</span>
<span class="sd">            &gt;&gt;&gt; mindspore.set_auto_parallel_context(group_ckpt_save_file=f&quot;{export_dir}/group_config_{rank_id}.pb&quot;)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # use communication group information file when load mindir</span>
<span class="sd">            &gt;&gt;&gt; import mindspore_lite as mslite</span>
<span class="sd">            &gt;&gt;&gt; context = mslite.Context()</span>
<span class="sd">            &gt;&gt;&gt; context.group_info_file = f&quot;{export_dir}/group_config_{rank_id}.pb&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="o">.</span><span class="n">group_info_file</span>

    <span class="nd">@group_info_file</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">group_info_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">group_info_file</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set communication group information for distributed inference.&quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;group_info_file&quot;</span><span class="p">,</span> <span class="n">group_info_file</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="o">.</span><span class="n">group_info_file</span> <span class="o">=</span> <span class="n">group_info_file</span></div>


<span class="k">class</span> <span class="nc">_InnerContext</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;_InnerContext is used to bind Python API(Context) to C++ API(Context).&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span> <span class="o">=</span> <span class="n">_c_lite_wrapper</span><span class="o">.</span><span class="n">ContextBind</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">cpu_thread_num</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the number of threads at runtime.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">get_thread_num</span><span class="p">()</span>

    <span class="nd">@cpu_thread_num</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">cpu_thread_num</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cpu_thread_num</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the number of threads at runtime.&quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;cpu_thread_num&quot;</span><span class="p">,</span> <span class="n">cpu_thread_num</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cpu_thread_num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cpu_thread_num must be a non-negative int.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">set_thread_num</span><span class="p">(</span><span class="n">cpu_thread_num</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">cpu_inter_op_parallel_num</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the parallel number of operators at runtime.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">get_inter_op_parallel_num</span><span class="p">()</span>

    <span class="nd">@cpu_inter_op_parallel_num</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">cpu_inter_op_parallel_num</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cpu_inter_op_parallel_num</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the parallel number of operators at runtime.&quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;cpu_inter_op_parallel_num&quot;</span><span class="p">,</span> <span class="n">cpu_inter_op_parallel_num</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cpu_inter_op_parallel_num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Context&#39;s init failed, cpu_inter_op_parallel_num must be a non-negative int.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">set_inter_op_parallel_num</span><span class="p">(</span><span class="n">cpu_inter_op_parallel_num</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">cpu_thread_affinity_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the mode of the CPU core binding policy at runtime.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">get_thread_affinity_mode</span><span class="p">()</span>

    <span class="nd">@cpu_thread_affinity_mode</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">cpu_thread_affinity_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cpu_thread_affinity_mode</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the mode of the CPU core binding policy at runtime.&quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;cpu_thread_affinity_mode&quot;</span><span class="p">,</span> <span class="n">cpu_thread_affinity_mode</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">set_thread_affinity_mode</span><span class="p">(</span><span class="n">cpu_thread_affinity_mode</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">cpu_thread_affinity_core_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the list of CPU core binding policies at runtime.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">get_thread_affinity_core_list</span><span class="p">()</span>

    <span class="nd">@cpu_thread_affinity_core_list</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">cpu_thread_affinity_core_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cpu_thread_affinity_core_list</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the list of CPU core binding policies at runtime.&quot;&quot;&quot;</span>
        <span class="n">check_list_of_element</span><span class="p">(</span><span class="s2">&quot;cpu_thread_affinity_core_list&quot;</span><span class="p">,</span> <span class="n">cpu_thread_affinity_core_list</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">enable_none</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">set_thread_affinity_core_list</span><span class="p">(</span><span class="n">cpu_thread_affinity_core_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_target</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the target device information of context.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">get_device_list</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">clear_target</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clear the target device information of context.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">clear_device_info</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">append_device_info</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Append one user-defined target device info to the context.&quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;target&quot;</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">_Target</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">append_device_info</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">_device_info</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">group_info_file</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get communication group info file for distributed inference.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">get_group_info_file</span><span class="p">()</span>

    <span class="nd">@group_info_file</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">group_info_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">group_info_file</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set communication group info file for distributed inference.&quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;group_info_file&quot;</span><span class="p">,</span> <span class="n">group_info_file</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">set_group_info_file</span><span class="p">(</span><span class="n">group_info_file</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_Target</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper class used to describe device hardware information.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Initialize _Target&quot;&quot;&quot;</span>


<span class="k">class</span> <span class="nc">_CPU</span><span class="p">(</span><span class="n">_Target</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper class used to describe CPU device hardware information, and it inherits :class:`mindspore_lite._Target`</span>
<span class="sd">    base class.</span>

<span class="sd">    Args:</span>
<span class="sd">        inner_context(_InnerContext): Use to set inner context&#39;s cpu parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inner_context</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_CPU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;inner_context&quot;</span><span class="p">,</span> <span class="n">inner_context</span><span class="p">,</span> <span class="n">_InnerContext</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span> <span class="o">=</span> <span class="n">inner_context</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span> <span class="o">=</span> <span class="n">_c_lite_wrapper</span><span class="o">.</span><span class="n">CPUDeviceInfoBind</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;device_type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">get_device_type</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;precision_mode: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">precision_mode</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;thread_num: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">thread_num</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;inter_op_parallel_num: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">inter_op_parallel_num</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;thread_affinity_mode: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">thread_affinity_mode</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;thread_affinity_core_list: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">thread_affinity_core_list</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">precision_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get mixed precision mode.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">get_enable_fp16</span><span class="p">():</span>
            <span class="k">return</span> <span class="s2">&quot;preferred_fp16&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;enforce_fp32&quot;</span>

    <span class="nd">@precision_mode</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">precision_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cpu_precision_mode</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set mixed precision mode.</span>

<span class="sd">        Args:</span>
<span class="sd">            cpu_precision_mode (str): Set mixed precision mode. CPU options are &quot;preferred_fp16&quot; | &quot;enforce_fp32&quot;.</span>

<span class="sd">                - &quot;preferred_fp16&quot;: prefer to use fp16.</span>
<span class="sd">                - &quot;enforce_fp32&quot;: force use fp32.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `cpu_precision_mode` is not a str.</span>
<span class="sd">            ValueError: `cpu_precision_mode` is neither &quot;enforce_fp32&quot; nor &quot;preferred_fp16&quot; when it is a str.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;cpu_precision_mode&quot;</span><span class="p">,</span> <span class="n">cpu_precision_mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cpu_precision_mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;enforce_fp32&quot;</span><span class="p">,</span> <span class="s2">&quot;preferred_fp16&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cpu_precision_mode must be in [enforce_fp32, preferred_fp16],&quot;</span>
                             <span class="sa">f</span><span class="s2">&quot; but got </span><span class="si">{</span><span class="n">cpu_precision_mode</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cpu_precision_mode</span> <span class="o">==</span> <span class="s2">&quot;preferred_fp16&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">set_enable_fp16</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">set_enable_fp16</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">thread_num</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the number of threads at runtime.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">cpu_thread_num</span>

    <span class="nd">@thread_num</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">thread_num</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cpu_thread_num</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the number of threads at runtime.</span>

<span class="sd">        Args:</span>
<span class="sd">            cpu_thread_num (int): Set the number of threads at runtime. `cpu_thread_num` cannot be less than</span>
<span class="sd">                `cpu_inter_op_parallel_num` . Setting `cpu_thread_num` to 0 represents `cpu_thread_num` will be</span>
<span class="sd">                automatically adjusted based on computer performance and core numbers.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `cpu_thread_num` is not an int.</span>
<span class="sd">            ValueError: `cpu_thread_num` is less than 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;cpu_thread_num&quot;</span><span class="p">,</span> <span class="n">cpu_thread_num</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cpu_thread_num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cpu_thread_num must be a non-negative int.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">cpu_thread_num</span> <span class="o">=</span> <span class="n">cpu_thread_num</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">inter_op_parallel_num</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the parallel number of operators at runtime.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">cpu_inter_op_parallel_num</span>

    <span class="nd">@inter_op_parallel_num</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">inter_op_parallel_num</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cpu_inter_op_parallel_num</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the parallel number of operators at runtime.</span>

<span class="sd">        Args:</span>
<span class="sd">            cpu_inter_op_parallel_num (int): Set the parallel number of operators at runtime.</span>
<span class="sd">                `cpu_inter_op_parallel_num` cannot be greater than `cpu_thread_num` . Setting</span>
<span class="sd">                `cpu_inter_op_parallel_num` to 0 represents `cpu_inter_op_parallel_num` will be automatically adjusted</span>
<span class="sd">                based on computer performance and core num.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `cpu_inter_op_parallel_num` is not an int.</span>
<span class="sd">            ValueError: `cpu_inter_op_parallel_num` is less than 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;cpu_inter_op_parallel_num&quot;</span><span class="p">,</span> <span class="n">cpu_inter_op_parallel_num</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cpu_inter_op_parallel_num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cpu_inter_op_parallel_num must be a non-negative int.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">cpu_inter_op_parallel_num</span> <span class="o">=</span> <span class="n">cpu_inter_op_parallel_num</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">thread_affinity_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the mode of the CPU core binding policy at runtime.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">cpu_thread_affinity_mode</span>

    <span class="nd">@thread_affinity_mode</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">thread_affinity_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cpu_thread_affinity_mode</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the mode of the CPU core binding policy at runtime.</span>

<span class="sd">        Args:</span>
<span class="sd">            cpu_thread_affinity_mode (int): Set the mode of the CPU core binding policy at runtime. The</span>
<span class="sd">                following `cpu_thread_affinity_mode` are supported.</span>

<span class="sd">                - 0: no binding core.</span>
<span class="sd">                - 1: binding big cores first.</span>
<span class="sd">                - 2: binding middle cores first.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `cpu_thread_affinity_mode` is not an int.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;cpu_thread_affinity_mode&quot;</span><span class="p">,</span> <span class="n">cpu_thread_affinity_mode</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">cpu_thread_affinity_mode</span> <span class="o">=</span> <span class="n">cpu_thread_affinity_mode</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">thread_affinity_core_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the list of CPU core binding policies at runtime.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">cpu_thread_affinity_core_list</span>

    <span class="nd">@thread_affinity_core_list</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">thread_affinity_core_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cpu_thread_affinity_core_list</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the list of CPU core binding policies at runtime.</span>

<span class="sd">        Args:</span>
<span class="sd">            cpu_thread_affinity_core_list (list[int]): Set the list of CPU core binding policies at runtime.</span>
<span class="sd">                For example, [0,1] represents the specified binding of CPU0 and CPU1.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `cpu_thread_affinity_core_list` is not a list.</span>
<span class="sd">            TypeError: `cpu_thread_affinity_core_list` is a list, but the elements are not int.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_list_of_element</span><span class="p">(</span><span class="s2">&quot;cpu_thread_affinity_core_list&quot;</span><span class="p">,</span> <span class="n">cpu_thread_affinity_core_list</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">enable_none</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inner_context</span><span class="o">.</span><span class="n">cpu_thread_affinity_core_list</span> <span class="o">=</span> <span class="n">cpu_thread_affinity_core_list</span>


<span class="k">class</span> <span class="nc">_GPU</span><span class="p">(</span><span class="n">_Target</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper class used to describe GPU device hardware information, and it inherits :class:`mindspore_lite._Target`</span>
<span class="sd">    base class.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_GPU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span> <span class="o">=</span> <span class="n">_c_lite_wrapper</span><span class="o">.</span><span class="n">GPUDeviceInfoBind</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;device_type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">get_device_type</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;precision_mode: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">precision_mode</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;device_id: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device_id</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;rank_id: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_id</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;group_size: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">group_size</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">precision_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get mixed precision mode.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">get_enable_fp16</span><span class="p">():</span>
            <span class="k">return</span> <span class="s2">&quot;preferred_fp16&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;enforce_fp32&quot;</span>

    <span class="nd">@precision_mode</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">precision_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gpu_precision_mode</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set mixed precision mode.</span>

<span class="sd">        Args:</span>
<span class="sd">            gpu_precision_mode (str): Set mixed precision mode. GPU options are &quot;preferred_fp16&quot; | &quot;enforce_fp32&quot;.</span>

<span class="sd">                - &quot;preferred_fp16&quot;: prefer to use fp16.</span>
<span class="sd">                - &quot;enforce_fp32&quot;: force use fp32.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `gpu_precision_mode` is not a str.</span>
<span class="sd">            ValueError: `gpu_precision_mode` is neither &quot;enforce_fp32&quot; nor &quot;preferred_fp16&quot; when it is a str.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;gpu_precision_mode&quot;</span><span class="p">,</span> <span class="n">gpu_precision_mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">gpu_precision_mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;enforce_fp32&quot;</span><span class="p">,</span> <span class="s2">&quot;preferred_fp16&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;gpu_precision_mode must be in [enforce_fp32, preferred_fp16],&quot;</span>
                             <span class="sa">f</span><span class="s2">&quot; but got </span><span class="si">{</span><span class="n">gpu_precision_mode</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">gpu_precision_mode</span> <span class="o">==</span> <span class="s2">&quot;preferred_fp16&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">set_enable_fp16</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">set_enable_fp16</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device_id</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the device id.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">get_device_id</span><span class="p">()</span>

    <span class="nd">@device_id</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">device_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gpu_device_id</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the device id.</span>

<span class="sd">        Args:</span>
<span class="sd">            gpu_device_id(int): The device id.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `gpu_device_id` is not an int.</span>
<span class="sd">            ValueError: `gpu_device_id` is less than 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;gpu_device_id&quot;</span><span class="p">,</span> <span class="n">gpu_device_id</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">gpu_device_id</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;gpu_device_id must be a non-negative int.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">set_device_id</span><span class="p">(</span><span class="n">gpu_device_id</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">rank_id</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the ID of the current device in the cluster from context.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int, the ID of the current device in the cluster, which starts from 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">get_rank_id</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">group_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the number of the clusters from context.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int, the number of the clusters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">get_group_size</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">_Ascend</span><span class="p">(</span><span class="n">_Target</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper class used to describe Ascend device hardware information, and it inherits :class:`mindspore_lite._Target`</span>
<span class="sd">    base class.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_Ascend</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span> <span class="o">=</span> <span class="n">_c_lite_wrapper</span><span class="o">.</span><span class="n">AscendDeviceInfoBind</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;device_type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">get_device_type</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;precision_mode: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">precision_mode</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;device_id: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device_id</span><span class="si">}</span><span class="s2">.&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;provider: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">provider</span><span class="si">}</span><span class="s2">.&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;rank_id: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_id</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">precision_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get mixed precision mode.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">get_precision_mode</span><span class="p">()</span>

    <span class="nd">@precision_mode</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">precision_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ascend_precision_mode</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set mixed precision mode.</span>

<span class="sd">        Args:</span>
<span class="sd">            ascend_precision_mode (str): Set mixed precision mode. Ascend options are &quot;enforce_fp32&quot; |</span>
<span class="sd">                &quot;preferred_fp32&quot; | &quot;enforce_fp16&quot; | &quot;enforce_origin&quot; | &quot;preferred_optimal&quot;.</span>

<span class="sd">              - &quot;enforce_fp32&quot;: ACL option is force_fp32, force use fp32.</span>
<span class="sd">              - &quot;preferred_fp32&quot;: ACL option is allow_fp32_to_fp16, prefer to use fp32.</span>
<span class="sd">              - &quot;enforce_fp16&quot;: ACL option is force_fp16, force use fp16.</span>
<span class="sd">              - &quot;enforce_origin&quot;: ACL option is must_keep_origin_dtype, force use original type.</span>
<span class="sd">              - &quot;preferred_optimal&quot;: ACL option is allow_mix_precision, prefer to use fp16+ mix precision mode.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `ascend_precision_mode` is not a str.</span>
<span class="sd">            ValueError: `ascend_precision_mode` is not in [&quot;enforce_fp32&quot;, &quot;preferred_fp32&quot;, &quot;enforce_fp16&quot;,</span>
<span class="sd">            &quot;enforce_origin&quot;, &quot;preferred_optimal&quot;] when it is a str.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;ascend_precision_mode&quot;</span><span class="p">,</span> <span class="n">ascend_precision_mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ascend_precision_mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;enforce_fp32&quot;</span><span class="p">,</span> <span class="s2">&quot;preferred_fp32&quot;</span><span class="p">,</span> <span class="s2">&quot;enforce_fp16&quot;</span><span class="p">,</span> <span class="s2">&quot;enforce_origin&quot;</span><span class="p">,</span>
                                         <span class="s2">&quot;preferred_optimal&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ascend_precision_mode must be in [enforce_fp32, preferred_fp32, enforce_fp16, &quot;</span>
                             <span class="sa">f</span><span class="s2">&quot;enforce_origin, preferred_optimal], but got </span><span class="si">{</span><span class="n">ascend_precision_mode</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">set_precision_mode</span><span class="p">(</span><span class="n">ascend_precision_mode</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device_id</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the device id.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">get_device_id</span><span class="p">()</span>

    <span class="nd">@device_id</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">device_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ascend_device_id</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the device id.</span>

<span class="sd">        Args:</span>
<span class="sd">            ascend_device_id(int): The device id.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `ascend_device_id` is not an int.</span>
<span class="sd">            ValueError: `ascend_device_id` is less than 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;ascend_device_id&quot;</span><span class="p">,</span> <span class="n">ascend_device_id</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ascend_device_id</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ascend_device_id must be a non-negative int.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">set_device_id</span><span class="p">(</span><span class="n">ascend_device_id</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">rank_id</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the ID of the current device in the cluster from context.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int, the ID of the current device in the cluster, which starts from 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">get_rank_id</span><span class="p">()</span>

    <span class="nd">@rank_id</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">rank_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ascend_rank_id</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the ID of the current device in the cluster from context.</span>

<span class="sd">        Args:</span>
<span class="sd">            ascend_rank_id(int): The rank id.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `ascend_rank_id` is not an int.</span>
<span class="sd">            ValueError: `ascend_rank_id` is less than 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;ascend_rank_id&quot;</span><span class="p">,</span> <span class="n">ascend_rank_id</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ascend_rank_id</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ascend_rank_id must be a non-negative int.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">set_rank_id</span><span class="p">(</span><span class="n">ascend_rank_id</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">provider</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the provider that supports the inference capability of target device.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">get_provider</span><span class="p">()</span>

    <span class="nd">@provider</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">provider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ascend_provider</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the provider that supports the inference capability of target device.</span>

<span class="sd">        Args:</span>
<span class="sd">            ascend_provider(str): The ascend provider, which can be &quot;&quot; or &quot;ge&quot;, default &quot;&quot;.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `ascend_provider` is not a str.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;ascend_provider&quot;</span><span class="p">,</span> <span class="n">ascend_provider</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device_info</span><span class="o">.</span><span class="n">set_provider</span><span class="p">(</span><span class="n">ascend_provider</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_Parallel</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    _Parallel Class defines the context and configuration of `ModelParallelRunner` class.</span>

<span class="sd">    Args:</span>
<span class="sd">        context (Context, optional): Define the context used to store options during execution. Default: ``None``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: `context` is neither a Context nor None.</span>
<span class="sd">        RuntimeError: Not MindSpore Lite serving package, can&#39;t set parallel.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">_c_lite_wrapper</span><span class="p">,</span> <span class="s2">&quot;RunnerConfigBind&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_runner_config</span> <span class="o">=</span> <span class="n">_c_lite_wrapper</span><span class="o">.</span><span class="n">RunnerConfigBind</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;parallel init failed, If you want to set parallel, you need to build&quot;</span>
                               <span class="sa">f</span><span class="s2">&quot;MindSpore Lite serving package by export MSLITE_ENABLE_SERVER_INFERENCE=on.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">context</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_runner_config</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">_inner_context</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;workers num: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">workers_num</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;config info: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config_info</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;config file: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config_path</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">workers_num</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the num of workers.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_runner_config</span><span class="o">.</span><span class="n">get_workers_num</span><span class="p">()</span>

    <span class="nd">@workers_num</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">workers_num</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">workers_num</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the num of workers.</span>

<span class="sd">        Args:</span>
<span class="sd">            workers_num (int): the num of workers. A `ModelParallelRunner` contains multiple workers, which</span>
<span class="sd">                are the units that actually perform parallel inferring. Setting `workers_num` to 0 represents</span>
<span class="sd">                `workers_num` will be automatically adjusted based on computer performance and core numbers.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `workers_num` is not an int.</span>
<span class="sd">            ValueError: `workers_num` is an int, but it is less than 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;workers_num&quot;</span><span class="p">,</span> <span class="n">workers_num</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">workers_num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Set parallel failed, workers_num must be a non-negative int.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_runner_config</span><span class="o">.</span><span class="n">set_workers_num</span><span class="p">(</span><span class="n">workers_num</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">config_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get Nested map for transferring user defined options during building `ModelParallelRunner` online.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_runner_config</span><span class="o">.</span><span class="n">get_config_info_string</span><span class="p">()</span><span class="o">.</span><span class="n">rstrip</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nd">@config_info</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">config_info</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config_info</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        set Nested map for transferring user defined options during building `ModelParallelRunner` online.</span>

<span class="sd">        Args:</span>
<span class="sd">            config_info (dict{str, dict{str, str}}): Nested map for transferring user defined options during building</span>
<span class="sd">                `ModelParallelRunner` online. More configurable options refer to `config_path` .</span>
<span class="sd">                For example, {&quot;model_file&quot;: {&quot;mindir_path&quot;: &quot;/home/user/model_graph.mindir&quot;}}.</span>
<span class="sd">                `section` is &quot;model_file&quot;, value is in dict format, one of the keys is &quot;mindir_path&quot;,</span>
<span class="sd">                the corresponding value is &quot;/home/user/model_graph.mindir&quot;.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `config_info` is not a dict.</span>
<span class="sd">            TypeError: `config_info` is a dict, but the key is not str.</span>
<span class="sd">            TypeError: `config_info` is a dict, the key is str, but the value is not dict.</span>
<span class="sd">            TypeError: `config_info` is a dict, the key is str, the value is dict, but the key of value is not str.</span>
<span class="sd">            TypeError: `config_info` is a dict, the key is str, the value is dict, the key of the value is str, but</span>
<span class="sd">                the value of the value is not str.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;config_info&quot;</span><span class="p">,</span> <span class="n">config_info</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">config_info</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;config_info_key&quot;</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;config_info_value&quot;</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">v_k</span><span class="p">,</span> <span class="n">v_v</span> <span class="ow">in</span> <span class="n">v</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;config_info_value_key&quot;</span><span class="p">,</span> <span class="n">v_k</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
                <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;config_info_value_value&quot;</span><span class="p">,</span> <span class="n">v_v</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">config_info</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_runner_config</span><span class="o">.</span><span class="n">set_config_info</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">config_path</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the config file path.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_runner_config</span><span class="o">.</span><span class="n">get_config_path</span><span class="p">()</span>

    <span class="nd">@config_path</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">config_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config_path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the config file path.</span>

<span class="sd">        Args:</span>
<span class="sd">            config_path (str): Set the config file path. the config file is used to transfer user defined</span>
<span class="sd">                options during building `ModelParallelRunner` . In the following scenarios, users may need to set the</span>
<span class="sd">                parameter. For example, &quot;/home/user/config.txt&quot;.</span>

<span class="sd">                - Usage 1: Set mixed precision inference. The content and description of the configuration file are as</span>
<span class="sd">                  follows:</span>

<span class="sd">                  .. code-block::</span>

<span class="sd">                      [execution_plan]</span>
<span class="sd">                      [op_name1]=data_Type: float16 (The operator named op_name1 sets the data type as float16)</span>
<span class="sd">                      [op_name2]=data_Type: float32 (The operator named op_name2 sets the data type as float32)</span>

<span class="sd">                - Usage 2: When GPU inference, set the configuration of TensorRT. The content and description of the</span>
<span class="sd">                  configuration file are as follows:</span>

<span class="sd">                  .. code-block::</span>

<span class="sd">                      [ms_cache]</span>
<span class="sd">                      serialize_Path=[serialization model path](storage path of serialization model)</span>
<span class="sd">                      [gpu_context]</span>
<span class="sd">                      input_shape=input_Name: [input_dim] (Model input dimension, for dynamic shape)</span>
<span class="sd">                      dynamic_Dims=[min_dim~max_dim] (dynamic dimension range of model input, for dynamic shape)</span>
<span class="sd">                      opt_Dims=[opt_dim] (the optimal input dimension of the model, for dynamic shape)</span>

<span class="sd">                - Usage 3: For the large model, when using the model buffer to load and compile, you need to set the</span>
<span class="sd">                  path of the weight file separately through passing the path of the large model. And it is necessary to</span>
<span class="sd">                  ensure that the large model file and the folder where the weight file is located are in the same</span>
<span class="sd">                  folder. For example, when the directory is as follows:</span>

<span class="sd">                  .. code-block::</span>

<span class="sd">                      .</span>
<span class="sd">                      └── /home/user/</span>
<span class="sd">                           ├── model_graph.mindir</span>
<span class="sd">                           └── model_variables</span>
<span class="sd">                                └── data_0</span>

<span class="sd">                  The content and description of the configuration file are as follows:</span>

<span class="sd">                  .. code-block::</span>

<span class="sd">                      [model_file]</span>
<span class="sd">                      mindir_path=[/home/user/model_graph.mindir](storage path of the large model)</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `config_path` is not a str.</span>
<span class="sd">            ValueError: `config_path` does not exist.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_isinstance</span><span class="p">(</span><span class="s2">&quot;config_path&quot;</span><span class="p">,</span> <span class="n">config_path</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">config_path</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">config_path</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Set parallel failed, config_path does not exist!&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_runner_config</span><span class="o">.</span><span class="n">set_config_path</span><span class="p">(</span><span class="n">config_path</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the device id list.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_runner_config</span><span class="o">.</span><span class="n">get_device_ids</span><span class="p">()</span>

    <span class="nd">@device_ids</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">device_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device_ids</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the device id list.</span>

<span class="sd">        Args:</span>
<span class="sd">            device_ids(list): A `ModelParallelRunner` contains multiple workers, set the device id of each</span>
<span class="sd">                worker based on the device_ids sequence. If the device_ids length is less than workers_num,</span>
<span class="sd">                the worker will distribute evenly to each device.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: `device_ids` is not a list.</span>
<span class="sd">            TypeError: `device_ids` is a list, but the elements are not int.</span>
<span class="sd">            ValueError: element of `device_ids` is less than 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_list_of_element</span><span class="p">(</span><span class="s2">&quot;device_ids&quot;</span><span class="p">,</span> <span class="n">device_ids</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">enable_none</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">element</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">device_ids</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">element</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Set parallel failed, device_ids contain a negative number.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_runner_config</span><span class="o">.</span><span class="n">set_device_ids</span><span class="p">(</span><span class="n">device_ids</span><span class="p">)</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 MindSpore.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>