<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Building Cloud-side MindSpore Lite &mdash; MindSpore Lite master documentation</title>
      <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/lite.css" type="text/css" /><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/js/lite.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Quick Start to Device-side Inference" href="../../quick_start/one_hour_introduction.html" />
    <link rel="prev" title="Building Device-side MindSpore Lite" href="../build.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Obtain MindSpore Lite</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../downloads.html">Downloading MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../build.html">Building Device-side MindSpore Lite</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Building Cloud-side MindSpore Lite</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#environment-requirements">Environment Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="#compilation-options">Compilation Options</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#instructions-for-using-the-parameters-of-build-sh">Instructions for Using the Parameters of <code class="docutils literal notranslate"><span class="pre">build.sh</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-build-compilation-options">Module Build Compilation Options</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#compilation-examples">Compilation Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#environment-preparation">Environment Preparation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#ascend">Ascend</a></li>
<li class="toctree-l4"><a class="reference internal" href="#gpu">GPU</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cpu">CPU</a></li>
<li class="toctree-l4"><a class="reference internal" href="#installing-llvm-optional">Installing LLVM-optional</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#executing-compilation">Executing Compilation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#directory-structure">Directory Structure</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../quick_start/one_hour_introduction.html">Quick Start to Device-side Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quick_start/one_hour_introduction_cloud.html">Quick Start to Cloud-side Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Device-side Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../device_infer_example.html">Device-side Inference Sample</a></li>
<li class="toctree-l1"><a class="reference internal" href="../post_training_quantization.html">Post Training Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data_preprocessing.html">Data Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../runtime.html">Executing Model Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../micro.html">Performing Inference or Training on MCU or Small Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asic.html">Application Specific Integrated Circuit Integration Instructions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Device-side Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../device_train_example.html">Device-side Training Sample</a></li>
<li class="toctree-l1"><a class="reference internal" href="../runtime_train.html">Executing Model Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Third-party hardware docking</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../register.html">Custom Kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../delegate.html">Using Delegate to Support Third-party AI Framework</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Device-side Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../converter.html">Converting Models for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark.html">Benchmark Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cropper_tool.html">Static Library Cropper Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../visual_tool.html">Visualization Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../obfuscator_tool.html">Model Obfuscation Tool</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Cloud-side Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">Performing Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime_parallel.html">Performing Concurrent Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime_distributed.html">Distributed Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Cloud-side Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="converter.html">Model Converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">Benchmark Tool</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../architecture_lite.html">Overall Architecture (Lite)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../operator_list_lite.html">Lite Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../operator_list_codegen.html">Codegen Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_lite.html">Model List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../troubleshooting_guide.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../log.html">Log</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Building Cloud-side MindSpore Lite</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/use/cloud_infer/build.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="building-cloud-side-mindspore-lite">
<h1>Building Cloud-side MindSpore Lite<a class="headerlink" href="#building-cloud-side-mindspore-lite" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/lite/docs/source_en/use/cloud_infer/build.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png" /></a></p>
<p>This section describes how to quickly compile MindSpore Lite.</p>
<p>Cloud-side MindSpore Lite contains modules:</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Modules</p></th>
<th class="head"><p>Supported Platforms</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>converter</p></td>
<td><p>Linux</p></td>
<td><p>Model Converter</p></td>
</tr>
<tr class="row-odd"><td><p>runtime(cpp, java)</p></td>
<td><p>Linux</p></td>
<td><p>Model Inference Framework</p></td>
</tr>
<tr class="row-even"><td><p>benchmark</p></td>
<td><p>Linux</p></td>
<td><p>Benchmarking Tool</p></td>
</tr>
<tr class="row-odd"><td><p>minddata</p></td>
<td><p>Linux</p></td>
<td><p>Image Processing Library</p></td>
</tr>
<tr class="row-even"><td><p>akg</p></td>
<td><p>Linux</p></td>
<td><p>Polyhedral-based deep learning operator compiler（<a class="reference external" href="https://gitee.com/mindspore/akg">Auto Kernel Generator</a>）</p></td>
</tr>
</tbody>
</table>
<section id="environment-requirements">
<h2>Environment Requirements<a class="headerlink" href="#environment-requirements" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>System Environment: Linux x86_64 or arm64, Ubuntu 18.04.02LTS recommended</p></li>
<li><p>C++ compilation dependencies</p>
<ul>
<li><p><a class="reference external" href="https://gcc.gnu.org/releases.html">GCC</a> &gt;= 7.3.0</p></li>
<li><p><a class="reference external" href="https://cmake.org/download/">CMake</a> &gt;= 3.18.3</p></li>
<li><p><a class="reference external" href="https://git-scm.com/downloads">Git</a> &gt;= 2.28.0</p></li>
</ul>
</li>
<li><p>Compilation dependency of the Java API module (optional), which is not compiled if the JAVA_HOME environment variable is not set.</p>
<ul>
<li><p><a class="reference external" href="https://gradle.org/releases/">Gradle</a> &gt;= 6.6.1</p>
<ul>
<li><p>Configure environment variables: <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">GRADLE_HOME=GRADLE</span> <span class="pre">path</span></code>, and <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">GRADLE_USER_HOME=GRADLE</span> <span class="pre">path</span></code></p></li>
<li><p>Add the bin directory to the PATH: <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">PATH=${GRADLE_HOME}/bin:$PATH</span></code></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://archive.apache.org/dist/maven/maven-3/">Maven</a> &gt;= 3.3.1</p>
<ul>
<li><p>Configure environment variables: <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">MAVEN_HOME=MAVEN</span> <span class="pre">path</span></code></p></li>
<li><p>Add the bin directory to the PATH: <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">PATH=${MAVEN_HOME}/bin:$PATH</span></code></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://openjdk.java.net/install/">OpenJDK</a> between 1.8 and 1.15</p>
<ul>
<li><p>Configure environment variables: <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">JAVA_HOME=JDK</span> <span class="pre">path</span></code></p></li>
<li><p>Add the bin directory to the PATH: <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">PATH=${JAVA_HOME}/bin:$PATH</span></code></p></li>
</ul>
</li>
</ul>
</li>
<li><p>Compilation dependency for the Python API module (optional), which is not compiled if Python3 or NumPy is not installed.</p>
<ul>
<li><p><a class="reference external" href="https://www.python.org/">Python</a> &gt;= 3.7.0</p></li>
<li><p><a class="reference external" href="https://numpy.org/">NumPy</a> &gt;= 1.17.0 (If installation with pip fails, please upgrade the pip version first: <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">pip</span> <span class="pre">install</span> <span class="pre">-U</span> <span class="pre">pip</span></code>)</p></li>
<li><p><a class="reference external" href="https://pypi.org/project/wheel/">wheel</a> &gt;= 0.32.0 (If installation with pip fails, please upgrade the pip version first: <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">pip</span> <span class="pre">install</span> <span class="pre">-U</span> <span class="pre">pip</span></code>)</p></li>
</ul>
</li>
<li><p>Compilation dependency for AKG (optional, compiled by default), which is not compiled if LLVM-12 or Python3 is not installed. To compile the AKG for the Ascend backend, git-lfs must be installed.</p>
<ul>
<li><p><span class="xref myst">llvm</span> == 12.0.1</p></li>
<li><p><a class="reference external" href="https://git-lfs.com/">git-lfs</a></p></li>
</ul>
</li>
</ul>
<blockquote>
<div><p>Gradle recommends using <a class="reference external" href="https://gradle.org/next-steps/?version=6.6.1&amp;format=all">gradle-6.6.1-complete</a>, and configuring other versions of gradle will use the gradle wrapper mechanism to automatically download <code class="docutils literal notranslate"> <span class="pre">gradle-6.6.1-complete</span></code>.</p>
<p>You can also directly use Docker compiling images that have been configured with the above dependencies.</p>
<ul class="simple">
<li><p>Download images: <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">pull</span> <span class="pre">swr.cn-south-1.myhuaweicloud.com/mindspore-build/mindspore-lite:ubuntu18.04.2-20210530</span></code></p></li>
<li><p>Create a container: <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">-tid</span> <span class="pre">--net=host</span> <span class="pre">--name=docker01</span> <span class="pre">swr.cn-south-1.myhuaweicloud.com/mindspore-build/mindspore-lite:ubuntu18.04.2-20210530</span></code></p></li>
<li><p>Enter the container: <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">exec</span> <span class="pre">-ti</span> <span class="pre">-u</span> <span class="pre">0</span> <span class="pre">docker01</span> <span class="pre">bash</span></code></p></li>
</ul>
</div></blockquote>
</section>
<section id="compilation-options">
<h2>Compilation Options<a class="headerlink" href="#compilation-options" title="Permalink to this headline"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">build.sh</span></code> script in the MindSpore root directory can be used to compile cloud-side MindSpore Lite.</p>
<section id="instructions-for-using-the-parameters-of-build-sh">
<h3>Instructions for Using the Parameters of <code class="docutils literal notranslate"><span class="pre">build.sh</span></code><a class="headerlink" href="#instructions-for-using-the-parameters-of-build-sh" title="Permalink to this headline"></a></h3>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Parameters</p></th>
<th class="head"><p>Description of the parameters</p></th>
<th class="head"><p>Range of values</p></th>
<th class="head"><p>Default values</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>-I</p></td>
<td><p>Select target architecture</p></td>
<td><p>arm64, x86_64</p></td>
<td><p>None</p></td>
</tr>
<tr class="row-odd"><td><p>-d</p></td>
<td><p>Set this parameter to compile the Debug version, otherwise compile the Release version</p></td>
<td><p>None</p></td>
<td><p>None</p></td>
</tr>
<tr class="row-even"><td><p>-i</p></td>
<td><p>Set this parameter for incremental compilation, otherwise for full compilation</p></td>
<td><p>None</p></td>
<td><p>None</p></td>
</tr>
<tr class="row-odd"><td><p>-j[n]</p></td>
<td><p>Set the number of threads used at compile time, otherwise the default setting is 8 threads</p></td>
<td><p>Integer</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-even"><td><p>-K</p></td>
<td><p>Set whether to compile AKG during compilation, otherwise the default setting is on</p></td>
<td><p>on, off</p></td>
<td><p>on</p></td>
</tr>
</tbody>
</table>
<blockquote>
<div><ul class="simple">
<li><p>If the JAVA_HOME environment variable is configured and Gradle is installed, the JAR package is compiled at the same time.</p></li>
<li><p>Add the <code class="docutils literal notranslate"><span class="pre">-i</span></code> parameter for incremental compilation does not take effect when the <code class="docutils literal notranslate"><span class="pre">-I</span></code> parameter changes, e.g. <code class="docutils literal notranslate"><span class="pre">-I</span> <span class="pre">x86_64</span></code> becomes <code class="docutils literal notranslate"><span class="pre">-I</span> <span class="pre">arm64</span></code>.</p></li>
<li><p>Cross-compilation is not supported, i.e. the arm64 version needs to be compiled in the arm environment.</p></li>
</ul>
</div></blockquote>
</section>
<section id="module-build-compilation-options">
<h3>Module Build Compilation Options<a class="headerlink" href="#module-build-compilation-options" title="Permalink to this headline"></a></h3>
<p>The building of modules is controlled through environment variables, and the users can control the build compilation modules by declaring the relevant environment variables. After modifying the compilation options, the <code class="docutils literal notranslate"><span class="pre">-i</span></code> parameter can not be added for incremental compilation when compiling with the <code class="docutils literal notranslate"><span class="pre">build.sh</span></code> script in order for the options to take effect.</p>
<p>General module compilation options:</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Options</p></th>
<th class="head"><p>Description of the parameters</p></th>
<th class="head"><p>Range of values</p></th>
<th class="head"><p>Default values</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MSLITE_GPU_BACKEND</p></td>
<td><p>Set GPU backend, only tensorrt is valid at <code class="docutils literal notranslate"><span class="pre">-I</span> <span class="pre">x86_64</span></code>.</p></td>
<td><p>tensorrt, off</p></td>
<td><p>off in <code class="docutils literal notranslate"><span class="pre">-I</span> <span class="pre">x86_64</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>MSLITE_ENABLE_TOOLS</p></td>
<td><p>Whether to compile the accompanying benchmarking tool</p></td>
<td><p>on, off</p></td>
<td><p>on</p></td>
</tr>
<tr class="row-even"><td><p>MSLITE_ENABLE_TESTCASES</p></td>
<td><p>Whether to compile test cases</p></td>
<td><p>on, off</p></td>
<td><p>off</p></td>
</tr>
<tr class="row-odd"><td><p>MSLITE_ENABLE_ACL</p></td>
<td><p>Whether to enable Ascend ACL</p></td>
<td><p>on, off</p></td>
<td><p>off</p></td>
</tr>
<tr class="row-even"><td><p>MSLITE_ENABLE_CLOUD_INFERENCE</p></td>
<td><p>Whether to enable cloud-side inference</p></td>
<td><p>on, off</p></td>
<td><p>off</p></td>
</tr>
<tr class="row-odd"><td><p>MSLITE_ENABLE_SSE</p></td>
<td><p>Whether to enable SSE instruction set, only valid for <code class="docutils literal notranslate"><span class="pre">-I</span> <span class="pre">x86_64</span></code></p></td>
<td><p>on, off</p></td>
<td><p>off</p></td>
</tr>
<tr class="row-even"><td><p>MSLITE_ENABLE_AVX512</p></td>
<td><p>Whether to enable AVX512 instruction set, only valid for <code class="docutils literal notranslate"><span class="pre">-I</span> <span class="pre">x86_64</span></code></p></td>
<td><p>on, off</p></td>
<td><p>off</p></td>
</tr>
</tbody>
</table>
<blockquote>
<div><ul class="simple">
<li><p>The cloud-side inference version relies on the model converter, so when <code class="docutils literal notranslate"><span class="pre">MSLITE_ENABLE_CLOUD_INFERENCE</span></code> is configured to <code class="docutils literal notranslate"><span class="pre">on</span></code>, it will compile <code class="docutils literal notranslate"><span class="pre">converter</span></code> at the same time.</p></li>
<li><p>If the environment only supports the SSE instruction set, the AVX512 instruction set needs to be configured as <code class="docutils literal notranslate"><span class="pre">off</span></code>.</p></li>
</ul>
</div></blockquote>
</section>
</section>
<section id="compilation-examples">
<h2>Compilation Examples<a class="headerlink" href="#compilation-examples" title="Permalink to this headline"></a></h2>
<p>First, you need to download the source code from the MindSpore code repository before compiling.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://gitee.com/mindspore/mindspore.git
</pre></div>
</div>
<section id="environment-preparation">
<h3>Environment Preparation<a class="headerlink" href="#environment-preparation" title="Permalink to this headline"></a></h3>
<section id="ascend">
<h4>Ascend<a class="headerlink" href="#ascend" title="Permalink to this headline"></a></h4>
<ul>
<li><p>Verify the installation of the Ascend AI processor package.</p>
<ul class="simple">
<li><p>The Ascend package is available in both commercial and community versions.</p>
<ol class="arabic simple">
<li><p>Please refer to the <a class="reference external" href="https://support.huawei.com/enterprise/en/doc/EDOC1100280094">Ascend Data Center Solution 22.0.RC3 Installation Guide document</a> for the download link and installation method of the commercial version.</p></li>
<li><p>There is no restriction on downloading the Community Edition. Please go to <a class="reference external" href="https://www.hiascend.com/software/cann/community-history">CANN Community Edition</a>, select <code class="docutils literal notranslate"><span class="pre">5.1.RC2.alpha007</span></code> version, and get the corresponding firmware and driver installation packages from the <a class="reference external" href="https://www.hiascend.com/hardware/firmware-drivers?tag=community">Firmware and Driver</a>. For package selection and installation, please refer to the commercial version installation guide document above.</p></li>
</ol>
</li>
<li><p>The default installation path for the installation package is <code class="docutils literal notranslate"><span class="pre">/usr/local/Ascend</span></code>. After installation, make sure the current user has permission to access the installation path of the Ascend AI processor companion package. If you don’t have permission, the root user needs to add the current user to the user group where <code class="docutils literal notranslate"><span class="pre">/usr/local/Ascend</span></code> is located.</p></li>
<li><p>Install the whl package included with the Ascend AI processor companion software. If you have previously installed the package included with the Ascend AI processor, you need to uninstall the corresponding whl package first by using the following command.</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>uninstall<span class="w"> </span>te<span class="w"> </span>topi<span class="w"> </span>-y
</pre></div>
</div>
<p>The default installation path is installed via the following command. If the installation path is not the default path, you need to replace the path in the command with the installation path.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>/usr/local/Ascend/ascend-toolkit/latest/lib64/topi-<span class="o">{</span>version<span class="o">}</span>-py3-none-any.whl
pip<span class="w"> </span>install<span class="w"> </span>/usr/local/Ascend/ascend-toolkit/latest/lib64/te-<span class="o">{</span>version<span class="o">}</span>-py3-none-any.whl
</pre></div>
</div>
</li>
<li><p>Configure environment variables</p>
<ul>
<li><p>After installing Ascend package, you need to export Runtime-related environment variables. The <code class="docutils literal notranslate"><span class="pre">/LOCAL_ASCEND=/usr/local/Ascend</span></code> in the following command indicates the installation path of the package, so you need to change it to the actual installation path of the package.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># control log level. 0-EBUG, 1-INFO, 2-WARNING, 3-ERROR, 4-CRITICAL, default level is WARNING.</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">GLOG_v</span><span class="o">=</span><span class="m">2</span>

<span class="c1"># Conda environmental options</span>
<span class="nv">LOCAL_ASCEND</span><span class="o">=</span>/usr/local/Ascend<span class="w"> </span><span class="c1"># the root directory of run package</span>

<span class="c1"># lib libraries that the run package depends on</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">LOCAL_ASCEND</span><span class="si">}</span>/ascend-toolkit/latest/lib64:<span class="si">${</span><span class="nv">LOCAL_ASCEND</span><span class="si">}</span>/driver/lib64:<span class="si">${</span><span class="nv">LOCAL_ASCEND</span><span class="si">}</span>/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/op_tiling:<span class="si">${</span><span class="nv">LD_LIBRARY_PATH</span><span class="si">}</span>

<span class="c1"># Environment variables that must be configured</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">TBE_IMPL_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">LOCAL_ASCEND</span><span class="si">}</span>/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe<span class="w">            </span><span class="c1"># TBE operator implementation tool path</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">ASCEND_OPP_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">LOCAL_ASCEND</span><span class="si">}</span>/ascend-toolkit/latest/opp<span class="w">                                       </span><span class="c1"># OPP path</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">LOCAL_ASCEND</span><span class="si">}</span>/ascend-toolkit/latest/compiler/ccec_compiler/bin/:<span class="si">${</span><span class="nv">PATH</span><span class="si">}</span><span class="w">                  </span><span class="c1"># TBE operator compilation tool path</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">PYTHONPATH</span><span class="o">=</span><span class="si">${</span><span class="nv">TBE_IMPL_PATH</span><span class="si">}</span>:<span class="si">${</span><span class="nv">PYTHONPATH</span><span class="si">}</span><span class="w">                                                       </span><span class="c1"># Python library that TBE implementation depends on</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</section>
<section id="gpu">
<h4>GPU<a class="headerlink" href="#gpu" title="Permalink to this headline"></a></h4>
<p>GPU environment compilation. Using TensorRT requires integration with CUDA, TensorRT. The current version is adapted to <a class="reference external" href="https://developer.nvidia.com/cuda-11.1.1-download-archive">CUDA 11.1</a> and <a class="reference external" href="https://developer.nvidia.com/nvidia-tensorrt-8x-download">TensorRT 8.5.1</a>.</p>
<p>Install the appropriate version of CUDA and set the installed directory to the environment variable <code class="docutils literal notranslate"><span class="pre">${CUDA_HOME}</span></code>. The build script will use this environment variable to find CUDA.</p>
<p>Download the corresponding version of the TensorRT archive and set the directory where the archive was unzipped to the environment variable <code class="docutils literal notranslate"><span class="pre">${TENSORRT_PATH}</span></code>. The build script will use this environment variable to find TensorRT.</p>
</section>
<section id="cpu">
<h4>CPU<a class="headerlink" href="#cpu" title="Permalink to this headline"></a></h4>
<p>Use x86_64 or ARM64 environment.</p>
</section>
<section id="installing-llvm-optional">
<h4>Installing LLVM-optional<a class="headerlink" href="#installing-llvm-optional" title="Permalink to this headline"></a></h4>
<p>The CPU backend of the graph kernel fusion in the converter needs to rely on LLVM-12. Run the following commands to install <a class="reference external" href="https://llvm.org/">LLVM</a> to enable CPU backend. If LLVM-12 is not installed, the graph kernel fusion can only support GPU and Ascend backend.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>-O<span class="w"> </span>-<span class="w"> </span>https://apt.llvm.org/llvm-snapshot.gpg.key<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>apt-key<span class="w"> </span>add<span class="w"> </span>-
sudo<span class="w"> </span>add-apt-repository<span class="w"> </span><span class="s2">&quot;deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-12 main&quot;</span>
sudo<span class="w"> </span>apt-get<span class="w"> </span>update
sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>llvm-12-dev<span class="w"> </span>-y
</pre></div>
</div>
</section>
</section>
<section id="executing-compilation">
<h3>Executing Compilation<a class="headerlink" href="#executing-compilation" title="Permalink to this headline"></a></h3>
<p>Three-backend-unification packages need to configure the following environment variables:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MSLITE_ENABLE_CLOUD_INFERENCE</span><span class="o">=</span>on
<span class="nb">export</span><span class="w"> </span><span class="nv">MSLITE_GPU_BACKEND</span><span class="o">=</span>tensorrt
<span class="nb">export</span><span class="w"> </span><span class="nv">MSLITE_ENABLE_ACL</span><span class="o">=</span>on
</pre></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p>If you don’t need Ascend backend, you can configure <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">MSLITE_ENABLE_ACL=off</span></code>.</p></li>
<li><p>If you don’t need GPU backend, you can configure <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">MSLITE_GPU_BACKEND=off</span></code>.</p></li>
</ul>
</div></blockquote>
<p>Execute the following command in the source root directory to compile different versions of MindSpore Lite.</p>
<ul>
<li><p>Compile the x86_64 architecture version while set the number of threads.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>build.sh<span class="w"> </span>-I<span class="w"> </span>x86_64<span class="w"> </span>-j32
</pre></div>
</div>
</li>
<li><p>Compile the arm64 architecture version while set the number of threads.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>build.sh<span class="w"> </span>-I<span class="w"> </span>arm64<span class="w"> </span>-j32
</pre></div>
</div>
</li>
<li><p>Compile the x86_64 architecture version while setting the number of threads, but do not compile AKG.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>build.sh<span class="w"> </span>-I<span class="w"> </span>x86_64<span class="w"> </span>-j32<span class="w"> </span>-K<span class="w"> </span>off
</pre></div>
</div>
</li>
</ul>
<p>Finally, the following file will be generated in the <code class="docutils literal notranslate"><span class="pre">output/</span></code> directory:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mindspore-lite-{version}-{os}-{arch}.tar.gz</span></code>: contains runtime and companion tools.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mindspore-lite-{version}-{python}-{os}-{arch}.whl</span></code>: contains the Whl package for runtime (Python).</p></li>
</ul>
<blockquote>
<div><ul class="simple">
<li><p>version: The version number of the output, which corresponds to the version of the branch code compiled.</p></li>
<li><p>python: The output Python version, e.g. Python 3.7 for <code class="docutils literal notranslate"><span class="pre">cp37-cp37m</span></code>.</p></li>
<li><p>os: The operating system to which the output piece should be deployed</p></li>
<li><p>arch: The system architecture in which the output pieces should be deployed.</p></li>
</ul>
</div></blockquote>
<p>To experience the Python interface, you need to move to the <code class="docutils literal notranslate"><span class="pre">output/</span></code> directory and use the following command to install the Whl installer.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>mindspore-lite-<span class="o">{</span>version<span class="o">}</span>-<span class="o">{</span>python<span class="o">}</span>-<span class="o">{</span>os<span class="o">}</span>-<span class="o">{</span>arch<span class="o">}</span>.whl
</pre></div>
</div>
<p>After installation, you can use the following command to check whether the installation is successful: if no error is reported, the installation is successful.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import mindspore_lite&quot;</span>
</pre></div>
</div>
<p>After installation, you can use the following command to check if the built-in AKG in MindSpore Lite is installed successfully: if no error is reported, the installation is successful.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import mindspore_lite.akg&quot;</span>
</pre></div>
</div>
<p>After successful installation, you can use the <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">show</span> <span class="pre">mindspore_lite</span></code> command to see where the Python modules for MindSpore Lite are installed.</p>
</section>
</section>
<section id="directory-structure">
<h2>Directory Structure<a class="headerlink" href="#directory-structure" title="Permalink to this headline"></a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>mindspore-lite-{version}-linux-{arch}
├── runtime
│   ├── include
│   ├── lib
│   │   ├── libascend_kernel_plugin.so # Ascend Kernel Plugin Dynamic Library
│   │   ├── libdvpp_utils.so           # DVPP Image Preprocessing Tools Dynamic Library
│   │   ├── libminddata-lite.a         # Image Processing Static Library
│   │   ├── libminddata-lite.so        # Image Processing Dynamic Library
│   │   ├── libmindspore-core.so       # MindSpore Core Dynamic Library
│   │   ├── libmindspore-glog.so.0     # glog Dynamic Library
│   │   ├── libmindspore-lite-jni.so   # jni dynamic library of MindSpore Lite inference framework
│   │   ├── libmindspore-lite.so       # MindSpore Lite Inference Framework Dynamic Library
│   │   ├── libmsplugin-ge-litert.so   # GE LiteRT Plugin Dynamic Library
│   │   └── mindspore-lite-java.jar    # MindSpore Lite Inference framework jar package
│   └── third_party
│       ├── glog
│       ├── libjpeg-turbo
│       └── securec
└── tools
    ├── akg
    |    └── akg-{version}-{python}-{os}-{arch}.whl # AKG Python whl package
    ├── benchmark              # Benchmarking Tools
    │   └── benchmark          # Benchmarking tool executable file
    └── converter              # Model converter
        ├── converter
        │   └── converter_lite # Converter executable file
        ├── include
        └── lib
            ├── libascend_pass_plugin.so
            ├── libmindspore_converter.so
            ├── libmindspore_core.so
            ├── libmindspore_glog.so.0
            ├── libmslite_shared_lib.so
            ├── libmslite_converter_plugin.so
            ├── libopencv_core.so.4.5
            ├── libopencv_imgcodecs.so.4.5
            └── libopencv_imgproc.so.4.5
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../build.html" class="btn btn-neutral float-left" title="Building Device-side MindSpore Lite" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../quick_start/one_hour_introduction.html" class="btn btn-neutral float-right" title="Quick Start to Device-side Inference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore Lite.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>