<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Implement Device Training Based On C++ Interface &mdash; MindSpore Lite master documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/lite.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/lite.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Implement Device Training Based On Java Interface" href="train_lenet_java.html" />
    <link rel="prev" title="Android Application Development Based on Java Interface" href="image_segmentation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Obtain MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/downloads.html">Downloading MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/build.html">Building MindSpore Lite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="quick_start_cpp.html">Experience C++ Simple Inference Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_java.html">Experience Java Simple Inference Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">Android Application Development Based on JNI Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_segmentation.html">Android Application Development Based on Java Interface</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Implement Device Training Based On C++ Interface</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#environment-preparing">Environment Preparing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#environment-requirements">Environment Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dataset">DataSet</a></li>
<li class="toctree-l3"><a class="reference internal" href="#install-mindspore">Install MindSpore</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-and-install-mindspore-lite">Download and Install MindSpore Lite</a></li>
<li class="toctree-l3"><a class="reference internal" href="#connect-android-device">Connect Android Device</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#train-and-eval">Train and Eval</a></li>
<li class="toctree-l2"><a class="reference internal" href="#details">Details</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#folder-structure">Folder Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-exporting">Model Exporting</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-transferring">Model Transferring</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-training">Model Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#loading-model">Loading Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dataset-processing">Dataset Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="#execute-training">Execute Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#execute-evaluating">Execute Evaluating</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="train_lenet_java.html">Implement Device Training Based On Java Interface</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference on Devices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/converter_tool.html">Converting Models for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/post_training_quantization.html">Optimizing the Model (Quantization After Training)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preprocessing.html">Data Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/runtime.html">Executing Model Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/micro.html">Perform Inference on Mini and Small Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/asic.html">Application Specific Integrated Circuit Integration Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/register_kernel.html">Register Kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/delegate.html">Using Delegate to Support Third-party AI Framework</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training on Devices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/converter_train.html">Creating MindSpore Lite Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/runtime_train.html">Executing Model Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/benchmark.html">Benchmark Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/cropper_tool.html">Static Library Cropper Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/visual_tool.html">Visualization Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/obfuscator_tool.html">Model Obfuscation Tool</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../architecture_lite.html">Overall Architecture (Lite)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_lite.html">Lite Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_codegen.html">Codegen Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_lite.html">Model List</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Implement Device Training Based On C++ Interface</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/quick_start/train_lenet.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="implement-device-training-based-on-c-interface">
<h1>Implement Device Training Based On C++ Interface<a class="headerlink" href="#implement-device-training-based-on-c-interface" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">C++</span></code> <code class="docutils literal notranslate"><span class="pre">Android</span></code> <code class="docutils literal notranslate"><span class="pre">Whole</span> <span class="pre">Process</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Export</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Converting</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Training</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.5/docs/lite/docs/source_en/quick_start/train_lenet.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source_en.png"></a></p>
<blockquote>
<div><p>MindSpore has unified the end-to-side cloud inference API. If you want to continue to use the MindSpore Lite independent API for training, you can refer to <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r1.3/quick_start/train_lenet.html">here</a>.</p>
</div></blockquote>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>Here we will demonstrate the code that trains a LeNet model using MindSpore Training-on-Device infrastructure. The code segments that are given below are provided fully in <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.5/mindspore/lite/examples/unified_api/">unified_api</a>.</p>
<p>The completed training procedure is as follows:</p>
<ol class="arabic simple">
<li><p>Constructing your training model based on MindSpore Lite Architecture and Export it into <code class="docutils literal notranslate"><span class="pre">MindIR</span></code> model file.</p></li>
<li><p>Converting <code class="docutils literal notranslate"><span class="pre">MindIR</span></code> model file to the <code class="docutils literal notranslate"><span class="pre">MS</span></code> ToD model file by using MindSpore Lite <code class="docutils literal notranslate"><span class="pre">Converter</span></code> tool.</p></li>
<li><p>Loading <code class="docutils literal notranslate"><span class="pre">MS</span></code> model file and executing model training by calling MindSpore Lite training API.</p></li>
</ol>
<p>Details will be told after environment deployed and model training by running prepared shell scripts.</p>
</section>
<section id="environment-preparing">
<h2>Environment Preparing<a class="headerlink" href="#environment-preparing" title="Permalink to this headline"></a></h2>
<p>Ubuntu 18.04 64-bit operating system on x86 platform is recommended.</p>
<section id="environment-requirements">
<h3>Environment Requirements<a class="headerlink" href="#environment-requirements" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>The compilation environment supports Linux x86_64 only. Ubuntu 18.04.02 LTS is recommended.</p></li>
<li><p>Software dependency</p>
<ul>
<li><p><a class="reference external" href="https://gcc.gnu.org/releases.html">GCC</a> &gt;= 7.3.0</p></li>
<li><p><a class="reference external" href="https://cmake.org/download/">CMake</a> &gt;= 3.18.3</p></li>
<li><p><a class="reference external" href="https://git-scm.com/downloads">Git</a> &gt;= 2.28.0</p></li>
<li><p><a class="reference external" href="https://dl.google.com/android/repository/android-ndk-r20b-linux-x86_64.zip">Android_NDK</a> &gt;= r20</p>
<ul>
<li><p>Configure environment variables: <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">ANDROID_NDK=NDK</span> <span class="pre">path</span></code>.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="dataset">
<h3>DataSet<a class="headerlink" href="#dataset" title="Permalink to this headline"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">MNIST</span></code> dataset used in this example consists of 10 classes of 28 x 28 pixels grayscale images. It has a training set of 60,000 examples, and a test set of 10,000 examples.</p>
<blockquote>
<div><p>Download the MNIST dataset at <a class="reference external" href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>. This page provides four download links of dataset files. The first two links are training dataset and training label, while the last two links are test dataset and test label.</p>
</div></blockquote>
<p>Download and decompress the files to <code class="docutils literal notranslate"><span class="pre">/PATH/MNIST_Data/train</span></code> and <code class="docutils literal notranslate"><span class="pre">/PATH/MNIST_Data/test</span></code> separately.</p>
<p>The directory structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─MNIST_Data
    ├─test
    │      t10k-images.idx3-ubyte
    │      t10k-labels.idx1-ubyte
    │
    └─train
            train-images.idx3-ubyte
            train-labels.idx1-ubyte
</pre></div>
</div>
</section>
<section id="install-mindspore">
<h3>Install MindSpore<a class="headerlink" href="#install-mindspore" title="Permalink to this headline"></a></h3>
<p>MindSpore can be installed by source code or using <code class="docutils literal notranslate"><span class="pre">pip</span></code>. Refer <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.5/install/mindspore_cpu_install_pip_en.md#">MindSpore installation guide</a> for more details.</p>
</section>
<section id="download-and-install-mindspore-lite">
<h3>Download and Install MindSpore Lite<a class="headerlink" href="#download-and-install-mindspore-lite" title="Permalink to this headline"></a></h3>
<p>Use <code class="docutils literal notranslate"><span class="pre">git</span></code> to clone the source code, the command in <code class="docutils literal notranslate"><span class="pre">Linux</span></code> is as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://gitee.com/mindspore/mindspore.git<span class="w"> </span>-b<span class="w"> </span>r1.5
<span class="nb">cd</span><span class="w"> </span>./mindspore
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/unified_api</span></code> directory relative to the MindSpore Lite source code contains this demo’s source code.</p>
<p>Go to the <a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/r1.5/use/downloads.html">MindSpore Lite Download Page</a> to download the mindspore-lite-{version}-linux-x64.tar.gz and mindspore-lite-{version}-android-aarch64.tar.gz. The mindspore-lite-{version}-linux-x64.tar.gz is the MindSpore Lite install package for x86 platform, it contains the converter tool <code class="docutils literal notranslate"><span class="pre">converter_lite</span></code>, this demo uses it to converte <code class="docutils literal notranslate"><span class="pre">MIDIR</span></code> model to <code class="docutils literal notranslate"><span class="pre">.ms</span></code> which is supported by MindSpore Lite; The mindspore-lite-{version}-android-aarch64.tar.gz is the MindSpore Lite install package for Android, it contains training runtime library <code class="docutils literal notranslate"><span class="pre">libmindspore-lite.so</span></code>, this demo uses it to train model. Then put the files to the <code class="docutils literal notranslate"><span class="pre">output</span></code> directory relative to MindSpore Lite source code（if there is no <code class="docutils literal notranslate"><span class="pre">output</span></code> directory，you should create it).</p>
<p>Suppose these packags are downloaded in <code class="docutils literal notranslate"><span class="pre">/Downloads</span></code> directory, <code class="docutils literal notranslate"><span class="pre">Linux</span></code> commands for operations above is as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>output
cp<span class="w"> </span>/Downloads/mindspore-lite-<span class="o">{</span>version<span class="o">}</span>-linux-x64.tar.gz<span class="w"> </span>output/mindspore-lite-<span class="o">{</span>version<span class="o">}</span>-linux-x64.tar.gz
cp<span class="w"> </span>/Downloads/mindspore-lite-<span class="o">{</span>version<span class="o">}</span><span class="m">0</span>-android-aarch64.tar.gz<span class="w"> </span>output/mindspore-lite-<span class="o">{</span>version<span class="o">}</span>-android-aarch64.tar.gz
</pre></div>
</div>
<p>You can also <a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/r1.5/use/build.html">compile from source</a> to generate the training package for x86 platform mindspore-lite-{version}-linux-x64.tar.gz and for Andorid platform mindspore-lite-{version}-android-aarch64.tar.gz. These packages will directly generated in <code class="docutils literal notranslate"><span class="pre">output</span></code> directory and you should make sure that in the <code class="docutils literal notranslate"><span class="pre">output</span></code> directory both the two packages exist.</p>
</section>
<section id="connect-android-device">
<h3>Connect Android Device<a class="headerlink" href="#connect-android-device" title="Permalink to this headline"></a></h3>
<p>Turning on the ‘USB debugging’ mode of your Android device and connect it with your PC by using <code class="docutils literal notranslate"><span class="pre">adb</span></code> debugging tool (run<code class="docutils literal notranslate"><span class="pre">sudo</span> <span class="pre">apt</span> <span class="pre">install</span> <span class="pre">adb</span></code> in Ubuntu OS command line).</p>
</section>
</section>
<section id="train-and-eval">
<h2>Train and Eval<a class="headerlink" href="#train-and-eval" title="Permalink to this headline"></a></h2>
<p>Enter the target directory and run the training bash script. The <code class="docutils literal notranslate"><span class="pre">Linux</span></code> command is as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/mindspore/lite/examples/unified_api
bash<span class="w"> </span>prepare_and_run.sh<span class="w"> </span>-D<span class="w"> </span>/PATH/MNIST_Data<span class="w"> </span>-t<span class="w"> </span>arm64
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">/PATH/MNIST_Data</span></code> is the absolute mnist dataset path in your machine, <code class="docutils literal notranslate"><span class="pre">-t</span> <span class="pre">arm64</span></code> represents that we will train and run the model on an Android device, if the work computer is connected to multiple mobile devices, you can use <code class="docutils literal notranslate"><span class="pre">-i</span> <span class="pre">devices_id</span></code> to specify the running device.</p>
<p>The script <code class="docutils literal notranslate"><span class="pre">prepare_and_run.sh</span></code> has done the following works:</p>
<ol class="arabic simple">
<li><p>Export the <code class="docutils literal notranslate"><span class="pre">lenet_tod.mindir</span></code> model file.</p></li>
<li><p>Calling the converter tool in the last section and convert the <code class="docutils literal notranslate"><span class="pre">MINDIR</span></code> file to the <code class="docutils literal notranslate"><span class="pre">ms</span></code> file.</p></li>
<li><p>Push the <code class="docutils literal notranslate"><span class="pre">lenet.ms</span></code> model file, MNIST dataset and the related library files to your <code class="docutils literal notranslate"><span class="pre">Android</span></code> device.</p></li>
<li><p>Train, save and infer the model.</p></li>
</ol>
<p>The model will be trained on your device and print training loss and accuracy value every epoch. The trained model will be saved as ‘lenet_tod.ms’ file. The 10 epochs training result of lenet is shown below (the classification accuracy varies in devices):</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>======Training Locally=========
1.100:  Loss is 1.19449
1.200:  Loss is 0.477986
1.300:  Loss is 0.440362
1.400:  Loss is 0.165605
1.500:  Loss is 0.368853
1.600:  Loss is 0.179764
1.700:  Loss is 0.173386
1.800:  Loss is 0.0767713
1.900:  Loss is 0.493
1.1000: Loss is 0.460352
1.1100: Loss is 0.262044
1.1200: Loss is 0.222022
1.1300: Loss is 0.058006
1.1400: Loss is 0.0794117
1.1500: Loss is 0.0241433
1.1600: Loss is 0.127109
1.1700: Loss is 0.0557566
1.1800: Loss is 0.0698758
Epoch (1):      Loss is 0.384778
Epoch (1):      Training Accuracy is 0.8702
2.100:  Loss is 0.0538642
2.200:  Loss is 0.444504
2.300:  Loss is 0.0806976
2.400:  Loss is 0.0495807
2.500:  Loss is 0.178903
2.600:  Loss is 0.265705
2.700:  Loss is 0.0933796
2.800:  Loss is 0.0880472
2.900:  Loss is 0.0480734
2.1000: Loss is 0.241272
2.1100: Loss is 0.0920451
2.1200: Loss is 0.371406
2.1300: Loss is 0.0365746
2.1400: Loss is 0.0784372
2.1500: Loss is 0.207537
2.1600: Loss is 0.442626
2.1700: Loss is 0.0814725
2.1800: Loss is 0.12081
Epoch (2):      Loss is 0.176118
Epoch (2):      Training Accuracy is 0.94415
......
10.1000:        Loss is 0.0984653
10.1100:        Loss is 0.189702
10.1200:        Loss is 0.0896037
10.1300:        Loss is 0.0138191
10.1400:        Loss is 0.0152357
10.1500:        Loss is 0.12785
10.1600:        Loss is 0.026495
10.1700:        Loss is 0.436495
10.1800:        Loss is 0.157564
Epoch (5):     Loss is 0.102652
Epoch (5):     Training Accuracy is 0.96805
AvgRunTime: 18980.5 ms
Total allocation: 125829120
Accuracy is 0.965244

===Evaluating trained Model=====
Total allocation: 20971520
Accuracy is 0.965244

===Running Inference Model=====
There are 1 input tensors with sizes:
tensor 0: shape is [32 32 32 1]
There are 1 output tensor with sizes:
tensor 0: shape is [32 10]
The predicted classes are:
4, 0, 2, 8, 9, 4, 5, 6, 3, 5, 2, 1, 4, 6, 8, 0, 5, 7, 3, 5, 8, 3, 4, 1, 9, 8, 7, 3, 0, 2, 3, 6,
</pre></div>
</div>
<blockquote>
<div><p>If the Android device is not available on your hand, you could also exectute <code class="docutils literal notranslate"><span class="pre">bash</span> <span class="pre">prepare_and_run.sh</span> <span class="pre">-D</span> <span class="pre">/PATH/MNIST_Data</span> <span class="pre">-t</span> <span class="pre">x86</span></code> and run it on the x86 platform.</p>
</div></blockquote>
</section>
<section id="details">
<h2>Details<a class="headerlink" href="#details" title="Permalink to this headline"></a></h2>
<section id="folder-structure">
<h3>Folder Structure<a class="headerlink" href="#folder-structure" title="Permalink to this headline"></a></h3>
<p>The demo project folder structure:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>unified_api/
  ├── model
  │   ├── lenet_export.py
  │   ├── prepare_model.sh
  │   └── train_utils.py
  │
  ├── scripts
  │   ├── batch_of32.dat
  │   ├── eval.sh
  │   ├── infer.sh
  │   └── train.sh
  │
  ├── src
  │   ├── inference.cc
  │   ├── net_runner.cc
  │   ├── net_runner.h
  │   └── utils.h
  │
  ├── Makefile
  ├── README.md
  ├── README_CN.md
  └── prepare_and_run.sh
</pre></div>
</div>
</section>
<section id="model-exporting">
<h3>Model Exporting<a class="headerlink" href="#model-exporting" title="Permalink to this headline"></a></h3>
<p>Whether it is an off-the-shelf prepared model, or a custom written model, the model needs to be exported to a <code class="docutils literal notranslate"><span class="pre">.mindir</span></code> file. Here we use the already-implemented <a class="reference external" href="https://gitee.com/mindspore/models/tree/r1.5/official/cv/lenet">LeNet model</a>.</p>
<p>Import and instantiate a LeNet5 model and set the model to train mode:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.dtype</span> <span class="k">as</span> <span class="nn">mstype</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">export</span>
<span class="kn">from</span> <span class="nn">lenet</span> <span class="kn">import</span> <span class="n">LeNet5</span>
<span class="kn">from</span> <span class="nn">train_utils</span> <span class="kn">import</span> <span class="n">TrainWrap</span>

<span class="n">n</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="n">n</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">,</span> <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Set MindSpore context and initialize the data and label tensors. In this case we use a MindSpore that was compiled for CPU. We define a batch size of 32 and initialize the tensors according to MNIST data – single channel 32x32 images.</p>
<p>The tensors does not need to be loaded with relevant data, but the shape and type must be correct. Note also, that this export code runs on the server, and in this case uses the CPU device. However, the Training on Device will run according to the <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r1.5/use/runtime_train_cpp.html#creating-contexts">context</a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">BATCH_SIZE</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">TrainWrap</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
<p>Wrapping the network with a loss layer and an optimizer and <code class="docutils literal notranslate"><span class="pre">export</span></code> it to a <code class="docutils literal notranslate"><span class="pre">MindIR</span></code> file. <code class="docutils literal notranslate"><span class="pre">TrainWrap</span></code> is provided in the example as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ParameterTuple</span>

<span class="k">def</span> <span class="nf">train_wrap</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    train_wrap</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">loss_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">loss_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">WithLossCell</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>
    <span class="n">loss_net</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">ParameterTuple</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
    <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.003</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">use_locking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">use_nesterov</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">4e-5</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">train_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">loss_net</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_net</span>
</pre></div>
</div>
<p>Finally, exporting the defined model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">export</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">&quot;lenet_tod&quot;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;MINDIR&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;finished exporting&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="model-transferring">
<h3>Model Transferring<a class="headerlink" href="#model-transferring" title="Permalink to this headline"></a></h3>
<p>To convert the model simply use the converter as explained in the <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r1.5/use/converter_train.html#creating-mindspore-tod-models">Convert Section</a>, the command is:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite<span class="w"> </span>--fmk<span class="o">=</span>MINDIR<span class="w"> </span>--trainModel<span class="o">=</span><span class="nb">true</span><span class="w"> </span>--modelFile<span class="o">=</span>lenet_tod.mindir<span class="w"> </span>--outputFile<span class="o">=</span>lenet_tod
</pre></div>
</div>
<p>The exported file <code class="docutils literal notranslate"><span class="pre">lenet_tod.ms</span></code> is under the folder <code class="docutils literal notranslate"><span class="pre">./unified_api/model</span></code>.</p>
</section>
<section id="model-training">
<h3>Model Training<a class="headerlink" href="#model-training" title="Permalink to this headline"></a></h3>
<p>The model training progress is in <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.5/mindspore/lite/examples/unified_api/src/net_runner.cc">net_runner.cc</a>.</p>
<p>The main code continues as follows:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">NetRunner::Main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Load model and create session</span>
<span class="w">  </span><span class="n">InitAndFigureInputs</span><span class="p">();</span>
<span class="w">  </span><span class="c1">// initialize the dataset</span>
<span class="w">  </span><span class="n">InitDB</span><span class="p">();</span>
<span class="w">  </span><span class="c1">// Execute the training</span>
<span class="w">  </span><span class="n">TrainLoop</span><span class="p">();</span>
<span class="w">  </span><span class="c1">// Evaluate the trained model</span>
<span class="w">  </span><span class="n">CalculateAccuracy</span><span class="p">();</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">epochs_</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">trained_fn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ms_file_</span><span class="p">.</span><span class="n">substr</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">ms_file_</span><span class="p">.</span><span class="n">find_last_of</span><span class="p">(</span><span class="sc">&#39;.&#39;</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s">&quot;_trained.ms&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Serialization</span><span class="o">::</span><span class="n">ExportModel</span><span class="p">(</span><span class="o">*</span><span class="n">model_</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kFlatBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">trained_fn</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kNoQuant</span><span class="p">,</span><span class="w"> </span><span class="nb">false</span><span class="p">);</span>
<span class="w">    </span><span class="n">trained_fn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ms_file_</span><span class="p">.</span><span class="n">substr</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">ms_file_</span><span class="p">.</span><span class="n">find_last_of</span><span class="p">(</span><span class="sc">&#39;.&#39;</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s">&quot;_infer.ms&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Serialization</span><span class="o">::</span><span class="n">ExportModel</span><span class="p">(</span><span class="o">*</span><span class="n">model_</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kFlatBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">trained_fn</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kNoQuant</span><span class="p">,</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<section id="loading-model">
<h4>Loading Model<a class="headerlink" href="#loading-model" title="Permalink to this headline"></a></h4>
<p><code class="docutils literal notranslate"><span class="pre">InitAndFigureInputs</span></code> creates the TrainSession instance from the <code class="docutils literal notranslate"><span class="pre">.ms</span></code> file, then sets the input tensors indices for the <code class="docutils literal notranslate"><span class="pre">.ms</span></code> model.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">NetRunner::InitAndFigureInputs</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">Context</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">cpu_context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">CPUDeviceInfo</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">  </span><span class="n">cpu_context</span><span class="o">-&gt;</span><span class="n">SetEnableFP16</span><span class="p">(</span><span class="n">enable_fp16_</span><span class="p">);</span>
<span class="w">  </span><span class="n">context</span><span class="o">-&gt;</span><span class="n">MutableDeviceInfo</span><span class="p">().</span><span class="n">push_back</span><span class="p">(</span><span class="n">cpu_context</span><span class="p">);</span>

<span class="w">  </span><span class="n">graph_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Graph</span><span class="p">();</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Serialization</span><span class="o">::</span><span class="n">Load</span><span class="p">(</span><span class="n">ms_file_</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kFlatBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">graph_</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">status</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Error &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">status</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; during serialization of graph &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">ms_file_</span><span class="p">;</span>
<span class="w">    </span><span class="n">MS_ASSERT</span><span class="p">(</span><span class="n">status</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kSuccess</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">cfg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">TrainCfg</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">enable_fp16_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cfg</span><span class="p">.</span><span class="n">get</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">optimization_level_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kO2</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">model_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Model</span><span class="p">();</span>
<span class="w">  </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_</span><span class="o">-&gt;</span><span class="n">Build</span><span class="p">(</span><span class="n">mindspore</span><span class="o">::</span><span class="n">GraphCell</span><span class="p">(</span><span class="o">*</span><span class="n">graph_</span><span class="p">),</span><span class="w"> </span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">cfg</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">status</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Error &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">status</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; during build of model &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">ms_file_</span><span class="p">;</span>
<span class="w">    </span><span class="n">MS_ASSERT</span><span class="p">(</span><span class="n">status</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kSuccess</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">acc_metrics_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">AccuracyMetrics</span><span class="o">&gt;</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">AccuracyMetrics</span><span class="p">);</span>
<span class="w">  </span><span class="n">model_</span><span class="o">-&gt;</span><span class="n">InitMetrics</span><span class="p">({</span><span class="n">acc_metrics_</span><span class="p">.</span><span class="n">get</span><span class="p">()});</span>

<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_</span><span class="o">-&gt;</span><span class="n">GetInputs</span><span class="p">();</span>
<span class="w">  </span><span class="n">MS_ASSERT</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">nhwc_input_dims</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputs</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">Shape</span><span class="p">();</span>

<span class="w">  </span><span class="n">batch_size_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nhwc_input_dims</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">h_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nhwc_input_dims</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="w">  </span><span class="n">w_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nhwc_input_dims</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="dataset-processing">
<h4>Dataset Processing<a class="headerlink" href="#dataset-processing" title="Permalink to this headline"></a></h4>
<p><code class="docutils literal notranslate"><span class="pre">InitDB</span></code> initializes the MNIST dataset and loads it into the memory. MindData has provided the data preprocessing API, the user could refer to the <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.5/api_cpp/mindspore_dataset.html">C++ API Docs</a> for more details.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">NetRunner::InitDB</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">train_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Mnist</span><span class="p">(</span><span class="n">data_dir_</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s">&quot;/train&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;all&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">SequentialSampler</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">));</span>

<span class="w">  </span><span class="n">TypeCast</span><span class="w"> </span><span class="n">typecast_f</span><span class="p">(</span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat32</span><span class="p">);</span>
<span class="w">  </span><span class="n">Resize</span><span class="w"> </span><span class="n">resize</span><span class="p">({</span><span class="n">h_</span><span class="p">,</span><span class="w"> </span><span class="n">w_</span><span class="p">});</span>
<span class="w">  </span><span class="n">train_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_ds_</span><span class="o">-&gt;</span><span class="n">Map</span><span class="p">({</span><span class="o">&amp;</span><span class="n">resize</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">typecast_f</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="s">&quot;image&quot;</span><span class="p">});</span>

<span class="w">  </span><span class="n">TypeCast</span><span class="w"> </span><span class="n">typecast</span><span class="p">(</span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeInt32</span><span class="p">);</span>
<span class="w">  </span><span class="n">train_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_ds_</span><span class="o">-&gt;</span><span class="n">Map</span><span class="p">({</span><span class="o">&amp;</span><span class="n">typecast</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="s">&quot;label&quot;</span><span class="p">});</span>

<span class="w">  </span><span class="n">train_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_ds_</span><span class="o">-&gt;</span><span class="n">Batch</span><span class="p">(</span><span class="n">batch_size_</span><span class="p">,</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">verbose_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;DatasetSize is &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">train_ds_</span><span class="o">-&gt;</span><span class="n">GetDatasetSize</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">train_ds_</span><span class="o">-&gt;</span><span class="n">GetDatasetSize</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;No relevant data was found in &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">data_dir_</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="n">MS_ASSERT</span><span class="p">(</span><span class="n">train_ds_</span><span class="o">-&gt;</span><span class="n">GetDatasetSize</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="execute-training">
<h4>Execute Training<a class="headerlink" href="#execute-training" title="Permalink to this headline"></a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">TrainLoop</span></code> method is the core of the training procedure. We first display its code then review it.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">NetRunner::TrainLoop</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">mindspore</span><span class="o">::</span><span class="n">LossMonitor</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="mi">100</span><span class="p">);</span>
<span class="w">  </span><span class="n">mindspore</span><span class="o">::</span><span class="n">TrainAccuracy</span><span class="w"> </span><span class="n">am</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>

<span class="w">  </span><span class="n">mindspore</span><span class="o">::</span><span class="n">CkptSaver</span><span class="w"> </span><span class="n">cs</span><span class="p">(</span><span class="n">kSaveEpochs</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="s">&quot;lenet&quot;</span><span class="p">));</span>
<span class="w">  </span><span class="n">Rescaler</span><span class="w"> </span><span class="n">rescale</span><span class="p">(</span><span class="n">kScalePoint</span><span class="p">);</span>
<span class="w">  </span><span class="n">Measurement</span><span class="w"> </span><span class="n">measure</span><span class="p">(</span><span class="n">epochs_</span><span class="p">);</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">virtual_batch_</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">model_</span><span class="o">-&gt;</span><span class="n">Train</span><span class="p">(</span><span class="n">epochs_</span><span class="p">,</span><span class="w"> </span><span class="n">train_ds_</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="o">&amp;</span><span class="n">rescale</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lm</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cs</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">measure</span><span class="p">});</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">mindspore</span><span class="o">::</span><span class="n">StepLRLambda</span><span class="w"> </span><span class="n">step_lr_lambda</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">kGammaFactor</span><span class="p">);</span>
<span class="w">    </span><span class="n">mindspore</span><span class="o">::</span><span class="n">LRScheduler</span><span class="w"> </span><span class="n">step_lr_sched</span><span class="p">(</span><span class="n">mindspore</span><span class="o">::</span><span class="n">StepLRLambda</span><span class="p">,</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">void</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">step_lr_lambda</span><span class="p">),</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">    </span><span class="n">model_</span><span class="o">-&gt;</span><span class="n">Train</span><span class="p">(</span><span class="n">epochs_</span><span class="p">,</span><span class="w"> </span><span class="n">train_ds_</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="o">&amp;</span><span class="n">rescale</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lm</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cs</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">am</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">step_lr_sched</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">measure</span><span class="p">});</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="execute-evaluating">
<h4>Execute Evaluating<a class="headerlink" href="#execute-evaluating" title="Permalink to this headline"></a></h4>
<p>To eval the model accuracy, the <code class="docutils literal notranslate"><span class="pre">CalculateAccuracy</span></code> method is being called. Within which, the model is switched to <code class="docutils literal notranslate"><span class="pre">Eval</span></code> mode, and the method runs a cycle of test tensors through the trained network to measure the current accuracy rate.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">float</span><span class="w"> </span><span class="nf">NetRunner::CalculateAccuracy</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">max_tests</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">test_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Mnist</span><span class="p">(</span><span class="n">data_dir_</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s">&quot;/test&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;all&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="n">TypeCast</span><span class="w"> </span><span class="n">typecast_f</span><span class="p">(</span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat32</span><span class="p">);</span>
<span class="w">  </span><span class="n">Resize</span><span class="w"> </span><span class="n">resize</span><span class="p">({</span><span class="n">h_</span><span class="p">,</span><span class="w"> </span><span class="n">w_</span><span class="p">});</span>
<span class="w">  </span><span class="n">test_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_ds_</span><span class="o">-&gt;</span><span class="n">Map</span><span class="p">({</span><span class="o">&amp;</span><span class="n">resize</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">typecast_f</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="s">&quot;image&quot;</span><span class="p">});</span>

<span class="w">  </span><span class="n">TypeCast</span><span class="w"> </span><span class="n">typecast</span><span class="p">(</span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeInt32</span><span class="p">);</span>
<span class="w">  </span><span class="n">test_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_ds_</span><span class="o">-&gt;</span><span class="n">Map</span><span class="p">({</span><span class="o">&amp;</span><span class="n">typecast</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="s">&quot;label&quot;</span><span class="p">});</span>
<span class="w">  </span><span class="n">test_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_ds_</span><span class="o">-&gt;</span><span class="n">Batch</span><span class="p">(</span><span class="n">batch_size_</span><span class="p">,</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span>

<span class="w">  </span><span class="n">model_</span><span class="o">-&gt;</span><span class="n">Evaluate</span><span class="p">(</span><span class="n">test_ds_</span><span class="p">,</span><span class="w"> </span><span class="p">{});</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Accuracy is &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">acc_metrics_</span><span class="o">-&gt;</span><span class="n">Eval</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>In the given example, the program runs a fixed number of train cycles. The user may easily change the termination condition, e.g., run until a certain accuracy is reached, or run only at night time when device is connected to a power source.</p>
<p>Finally, when trainining is completed, the fully trained model needs to be saved. The <code class="docutils literal notranslate"><span class="pre">SaveToFile</span></code> method is used for this purpose.</p>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="image_segmentation.html" class="btn btn-neutral float-left" title="Android Application Development Based on Java Interface" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="train_lenet_java.html" class="btn btn-neutral float-right" title="Implement Device Training Based On Java Interface" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore Lite.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>