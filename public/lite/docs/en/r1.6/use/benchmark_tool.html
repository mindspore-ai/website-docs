<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>benchmark &mdash; MindSpore Lite master documentation</title>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/lite.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/lite.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="benchmark_train" href="benchmark_train_tool.html" />
    <link rel="prev" title="Benchmark Tool" href="benchmark.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Obtain MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="downloads.html">Downloading MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="build.html">Building MindSpore Lite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/one_hour_introduction.html">Getting Started in One Hour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_cpp.html">Experience C++ Simple Inference Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_java.html">Experience Java Simple Inference Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Android Application Development Based on JNI Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/image_segmentation.html">Android Application Development Based on Java Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/train_lenet.html">Implement Device Training Based On C++ Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/train_lenet_java.html">Implement Device Training Based On Java Interface</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference on Devices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="converter_tool.html">Converting Models for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="post_training_quantization.html">Post Training Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_preprocessing.html">Data Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">Executing Model Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="micro.html">Perform Inference on Mini and Small Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="asic.html">Application Specific Integrated Circuit Integration Instructions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training on Devices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="converter_train.html">Creating MindSpore Lite Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime_train.html">Executing Model Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Third-party hardware docking</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="register.html">Custom Kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="delegate.html">Using Delegate to Support Third-party AI Framework</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Tools</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="benchmark.html">Benchmark Tool</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">benchmark</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#linux-environment-usage">Linux Environment Usage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#environment-preparation">Environment Preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#parameter-description">Parameter Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example">Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dump">Dump</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#windows-environment-usage">Windows Environment Usage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">Environment Preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id2">Parameter Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id3">Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id6">Dump</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="benchmark_train_tool.html">benchmark_train</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cropper_tool.html">Static Library Cropper Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="visual_tool.html">Visualization Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="obfuscator_tool.html">Model Obfuscation Tool</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../architecture_lite.html">Overall Architecture (Lite)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_lite.html">Lite Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_codegen.html">Codegen Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_lite.html">Model List</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="benchmark.html">Benchmark Tool</a> &raquo;</li>
      <li>benchmark</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/use/benchmark_tool.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="benchmark">
<h1>benchmark<a class="headerlink" href="#benchmark" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Windows</span></code> <code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Environment</span> <span class="pre">Preparation</span></code> <code class="docutils literal notranslate"><span class="pre">Benchmark</span> <span class="pre">Testing</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.6/docs/lite/docs/source_en/use/benchmark_tool.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.6/resource/_static/logo_source_en.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>After model conversion and before inference, you can use the Benchmark tool to perform benchmark testing on a MindSpore Lite model. It can not only perform quantitative analysis (performance) on the forward inference execution duration of a MindSpore Lite model, but also perform comparative error analysis (accuracy) based on the output of the specified model.</p>
</section>
<section id="linux-environment-usage">
<h2>Linux Environment Usage<a class="headerlink" href="#linux-environment-usage" title="Permalink to this headline"></a></h2>
<section id="environment-preparation">
<h3>Environment Preparation<a class="headerlink" href="#environment-preparation" title="Permalink to this headline"></a></h3>
<p>To use the Benchmark tool, you need to prepare the environment as follows:</p>
<ul>
<li><p>Compilation: Install build dependencies and perform build. The code of the Benchmark tool is stored in the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/tools/benchmark</span></code> directory of the MindSpore source code. For details about the build operations, see the <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r1.6/use/build.html#environment-requirements">Environment Requirements</a> and <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r1.6/use/build.html#compilation-example">Compilation Example</a> in the build document.</p></li>
<li><p>Run: Obtain the <code class="docutils literal notranslate"><span class="pre">Benchmark</span></code> tool and configure environment variables. For details, see <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r1.6/use/build.html#output-description">Output Description</a> in the build document.</p></li>
<li><p>Add the path of dynamic library required by the inference code to the environment variables LD_LIBRARY_PATH.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">PACKAGE_ROOT_PATH</span><span class="si">}</span>/runtime/lib:<span class="si">${</span><span class="nv">LD_LIBRARY_PATH</span><span class="si">}</span>
</pre></div>
</div>
<p>${PACKAGE_ROOT_PATH} is the compiled inference package path after decompressing.</p>
</li>
</ul>
</section>
<section id="parameter-description">
<h3>Parameter Description<a class="headerlink" href="#parameter-description" title="Permalink to this headline"></a></h3>
<p>The command used for benchmark testing based on the compiled Benchmark tool is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./benchmark [--modelFile=&lt;MODELFILE&gt;] [--accuracyThreshold=&lt;ACCURACYTHRESHOLD&gt;]
   [--benchmarkDataFile=&lt;BENCHMARKDATAFILE&gt;] [--benchmarkDataType=&lt;BENCHMARKDATATYPE&gt;]
   [--cpuBindMode=&lt;CPUBINDMODE&gt;] [--device=&lt;DEVICE&gt;] [--help]
   [--inDataFile=&lt;INDATAFILE&gt;] [--loopCount=&lt;LOOPCOUNT&gt;]
   [--numThreads=&lt;NUMTHREADS&gt;] [--warmUpLoopCount=&lt;WARMUPLOOPCOUNT&gt;]
   [--enableFp16=&lt;ENABLEFP16&gt;] [--timeProfiling=&lt;TIMEPROFILING&gt;]
   [--inputShapes=&lt;INPUTSHAPES&gt;] [--perfProfiling=&lt;PERFPROFILING&gt;]
            [--perfEvent=&lt;PERFEVENT&gt;]
</pre></div>
</div>
<p>The following describes the parameters in detail.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Attribute</p></th>
<th class="head"><p>Function</p></th>
<th class="head"><p>Parameter Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Value Range</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--modelFile=&lt;MODELFILE&gt;</span></code></p></td>
<td><p>Mandatory</p></td>
<td><p>Specifies the file path of the MindSpore Lite model for benchmark testing.</p></td>
<td><p>String</p></td>
<td><p>Null</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--accuracyThreshold=&lt;ACCURACYTHRESHOLD&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specifies the accuracy threshold.</p></td>
<td><p>Float</p></td>
<td><p>0.5</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--benchmarkDataFile=&lt;BENCHMARKDATAFILE&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specifies the file path of the benchmark data. The benchmark data, as the comparison output of the tested model, is output from the forward inference of the tested model under other deep learning frameworks using the same input.</p></td>
<td><p>String</p></td>
<td><p>Null</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--benchmarkDataType=&lt;BENCHMARKDATATYPE&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specifies the calibration data type.</p></td>
<td><p>String</p></td>
<td><p>FLOAT</p></td>
<td><p>FLOAT, INT32, INT8 or UINT8</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--cpuBindMode=&lt;CPUBINDMODE&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specifies the type of the CPU core bound to the model inference program.</p></td>
<td><p>Integer</p></td>
<td><p>1</p></td>
<td><p>2: medium core<br/>1: large core<br/>0: not bound</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--device=&lt;DEVICE&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specifies the type of the device on which the model inference program runs.</p></td>
<td><p>String</p></td>
<td><p>CPU</p></td>
<td><p>CPU or GPU or NPU or Ascend310</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--help</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Displays the help information about the <code class="docutils literal notranslate"><span class="pre">benchmark</span></code> command.</p></td>
<td><p>-</p></td>
<td><p>-</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--inDataFile=&lt;INDATAFILE&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specifies the file path of the input data of the tested model. If this parameter is not set, a random value will be used.</p></td>
<td><p>String</p></td>
<td><p>Null</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--loopCount=&lt;LOOPCOUNT&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specifies the number of forward inference times of the tested model when the Benchmark tool is used for the benchmark testing. The value should be a positive integer.</p></td>
<td><p>Integer</p></td>
<td><p>10</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--numThreads=&lt;NUMTHREADS&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specifies the number of threads for running the model inference program.</p></td>
<td><p>Integer</p></td>
<td><p>2</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--warmUpLoopCount=&lt;WARMUPLOOPCOUNT&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specifies the number of preheating inference times of the tested model before multiple rounds of the benchmark test are executed.</p></td>
<td><p>Integer</p></td>
<td><p>3</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--enableFp16=&lt;ENABLEFP16&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specifies whether the float16 operator is preferred.</p></td>
<td><p>Boolean</p></td>
<td><p>false</p></td>
<td><p>true, false</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--timeProfiling=&lt;TIMEPROFILING&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specifies whether to use TimeProfiler to print every kernel’s cost time.</p></td>
<td><p>Boolean</p></td>
<td><p>false</p></td>
<td><p>true, false</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--inputShapes=&lt;INPUTSHAPES&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specifies the shape of input data, the format should be NHWC. Use “,” to segregate each dimension of input shape, and for several input shapes, use “:” to segregate.</p></td>
<td><p>String</p></td>
<td><p>Null</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--perfProfiling=&lt;PERFPROFILING&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specifies whether to use PerfProfiler to print every kernel’s CPU performance data (PMU readings), it is disabled when timeProfiling is true. Only aarch64 CPU is supported.</p></td>
<td><p>Boolean</p></td>
<td><p>false</p></td>
<td><p>true, false</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--perfEvent=&lt;PERFEVENT&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specifies what CPU performance data to measure when PerfProfiling is true. When set as CYCLE, the number of CPU cycles and instructions will be printed; when set as CACHE, cache reference times and cache miss times will be printed; when set as STALL, CPU front-end stall cycles and back-end stall cycles will be printed.</p></td>
<td><p>String</p></td>
<td><p>CYCLE</p></td>
<td><p>CYCLE/CACHE/STALL</p></td>
</tr>
</tbody>
</table>
</section>
<section id="example">
<h3>Example<a class="headerlink" href="#example" title="Permalink to this headline"></a></h3>
<p>When using the Benchmark tool to perform benchmark testing on different MindSpore Lite models, you can set different parameters to implement different test functions. The testing is classified into performance test and accuracy test.</p>
<section id="performance-test">
<h4>Performance Test<a class="headerlink" href="#performance-test" title="Permalink to this headline"></a></h4>
<p>The main test indicator of the performance test performed by the Benchmark tool is the duration of a single forward inference. In a performance test, you do not need to set benchmark data parameters such as <code class="docutils literal notranslate"><span class="pre">benchmarkDataFile</span></code>. But you can set the parameter <code class="docutils literal notranslate"><span class="pre">timeProfiling</span></code> as True or False to decide whether to print the running time of the model at the network layer on a certain device. The default value of <code class="docutils literal notranslate"><span class="pre">timeProfiling</span></code> is False. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./benchmark<span class="w"> </span>--modelFile<span class="o">=</span>/path/to/model.ms
</pre></div>
</div>
<p>This command uses a random input, and other parameters use default values. After this command is executed, the following statistics are displayed. The statistics include the minimum duration, maximum duration, and average duration of a single inference after the tested model runs for the specified number of inference rounds.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Model = model.ms, numThreads = 2, MinRunTime = 72.228996 ms, MaxRuntime = 73.094002 ms, AvgRunTime = 72.556000 ms
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./benchmark<span class="w"> </span>--modelFile<span class="o">=</span>/path/to/model.ms<span class="w"> </span>--timeProfiling<span class="o">=</span><span class="nb">true</span>
</pre></div>
</div>
<p>This command uses a random input, sets the parameter <code class="docutils literal notranslate"><span class="pre">timeProfiling</span></code> as true, and other parameters use default values. After this command is executed, the statistics on the running time of the model at the network layer will be displayed as follows. In this case, the statistics are displayed by<code class="docutils literal notranslate"><span class="pre">opName</span></code> and <code class="docutils literal notranslate"><span class="pre">optype</span></code>. <code class="docutils literal notranslate"><span class="pre">opName</span></code> indicates the operator name, <code class="docutils literal notranslate"><span class="pre">optype</span></code> indicates the operator type, and <code class="docutils literal notranslate"><span class="pre">avg</span></code> indicates the average running time of the operator per single run, <code class="docutils literal notranslate"><span class="pre">percent</span></code> indicates the ratio of the operator running time to the total operator running time, <code class="docutils literal notranslate"><span class="pre">calledTimess</span></code> indicates the number of times that the operator is run, and <code class="docutils literal notranslate"><span class="pre">opTotalTime</span></code> indicates the total time that the operator is run for a specified number of times. Finally, <code class="docutils literal notranslate"><span class="pre">total</span> <span class="pre">time</span></code> and <code class="docutils literal notranslate"><span class="pre">kernel</span> <span class="pre">cost</span></code> show the average time consumed by a single inference operation of the model and the sum of the average time consumed by all operators in the model inference, respectively.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>-----------------------------------------------------------------------------------------
opName                                                          avg(ms)         percent         calledTimess    opTotalTime
conv2d_1/convolution                                            2.264800        0.824012        10              22.648003
conv2d_2/convolution                                            0.223700        0.081390        10              2.237000
dense_1/BiasAdd                                                 0.007500        0.002729        10              0.075000
dense_1/MatMul                                                  0.126000        0.045843        10              1.260000
dense_1/Relu                                                    0.006900        0.002510        10              0.069000
max_pooling2d_1/MaxPool                                         0.035100        0.012771        10              0.351000
max_pooling2d_2/MaxPool                                         0.014300        0.005203        10              0.143000
max_pooling2d_2/MaxPool_nchw2nhwc_reshape_1/Reshape_0           0.006500        0.002365        10              0.065000
max_pooling2d_2/MaxPool_nchw2nhwc_reshape_1/Shape_0             0.010900        0.003966        10              0.109000
output/BiasAdd                                                  0.005300        0.001928        10              0.053000
output/MatMul                                                   0.011400        0.004148        10              0.114000
output/Softmax                                                  0.013300        0.004839        10              0.133000
reshape_1/Reshape                                               0.000900        0.000327        10              0.009000
reshape_1/Reshape/shape                                         0.009900        0.003602        10              0.099000
reshape_1/Shape                                                 0.002300        0.000837        10              0.023000
reshape_1/strided_slice                                         0.009700        0.003529        10              0.097000
-----------------------------------------------------------------------------------------
opType          avg(ms)         percent         calledTimess    opTotalTime
Activation      0.006900        0.002510        10              0.069000
BiasAdd         0.012800        0.004657        20              0.128000
Conv2D          2.488500        0.905401        20              24.885004
MatMul          0.137400        0.049991        20              1.374000
Nchw2Nhwc       0.017400        0.006331        20              0.174000
Pooling         0.049400        0.017973        20              0.494000
Reshape         0.000900        0.000327        10              0.009000
Shape           0.002300        0.000837        10              0.023000
SoftMax         0.013300        0.004839        10              0.133000
Stack           0.009900        0.003602        10              0.099000
StridedSlice    0.009700        0.003529        10              0.097000

total time :     2.90800 ms,    kernel cost : 2.74851 ms

-----------------------------------------------------------------------------------------
</pre></div>
</div>
</section>
<section id="accuracy-test">
<h4>Accuracy Test<a class="headerlink" href="#accuracy-test" title="Permalink to this headline"></a></h4>
<p>The accuracy test performed by the Benchmark tool aims to verify the accuracy of the MinSpore model output by setting benchmark data (the default input and benchmark data type are float32). In an accuracy test, in addition to the <code class="docutils literal notranslate"><span class="pre">modelFile</span></code> parameter, the <code class="docutils literal notranslate"><span class="pre">benchmarkDataFile</span></code> parameter must be set. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./benchmark<span class="w"> </span>--modelFile<span class="o">=</span>/path/to/model.ms<span class="w"> </span>--inDataFile<span class="o">=</span>/path/to/input.bin<span class="w"> </span>--device<span class="o">=</span>CPU<span class="w"> </span>--accuracyThreshold<span class="o">=</span><span class="m">3</span><span class="w"> </span>--benchmarkDataFile<span class="o">=</span>/path/to/output.out
</pre></div>
</div>
<p>This command specifies the input data and benchmark data of the tested model, specifies that the model inference program runs on the CPU, and sets the accuracy threshold to 3%. After this command is executed, the following statistics are displayed, including the single input data of the tested model, output result and average deviation rate of the output node, and average deviation rate of all nodes.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>InData0: 139.947 182.373 153.705 138.945 108.032 164.703 111.585 227.402 245.734 97.7776 201.89 134.868 144.851 236.027 18.1142 22.218 5.15569 212.318 198.43 221.853
================ Comparing Output data ================
Data of node age_out : 5.94584e-08 6.3317e-08 1.94726e-07 1.91809e-07 8.39805e-08 7.66035e-08 1.69285e-07 1.46246e-07 6.03796e-07 1.77631e-07 1.54343e-07 2.04623e-07 8.89609e-07 3.63487e-06 4.86876e-06 1.23939e-05 3.09981e-05 3.37098e-05 0.000107102 0.000213932 0.000533579 0.00062465 0.00296401 0.00993984 0.038227 0.0695085 0.162854 0.123199 0.24272 0.135048 0.169159 0.0221256 0.013892 0.00502971 0.00134921 0.00135701 0.000383242 0.000163475 0.000136294 9.77864e-05 8.00793e-05 5.73874e-05 3.53858e-05 2.18535e-05 2.04467e-05 1.85286e-05 1.05075e-05 9.34751e-06 6.12732e-06 4.55476e-06
Mean bias of node age_out : 0%
Mean bias of all nodes: 0%
=======================================================
</pre></div>
</div>
<p>To set specified input shapes (such as 1,32,32,1), use the command as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./benchmark<span class="w"> </span>--modelFile<span class="o">=</span>/path/to/model.ms<span class="w"> </span>--inDataFile<span class="o">=</span>/path/to/input.bin<span class="w"> </span>--inputShapes<span class="o">=</span><span class="m">1</span>,32,32,1<span class="w"> </span>--device<span class="o">=</span>CPU<span class="w"> </span>--accuracyThreshold<span class="o">=</span><span class="m">3</span><span class="w"> </span>--benchmarkDataFile<span class="o">=</span>/path/to/output.out
</pre></div>
</div>
</section>
<section id="cpu-performance-test">
<h4>CPU Performance Test<a class="headerlink" href="#cpu-performance-test" title="Permalink to this headline"></a></h4>
<p>The main test indicator of the CPU performance test performed by the Benchmark tool is the readings of CPU Performance Monitor Unit(PMU) of a single forward inference, including the number of CPU cycles and instructions, cache reference times and cache miss times, front-end stall cycles and back-end stall cycles. In a performance test, you do not need to set benchmark data parameters such as <code class="docutils literal notranslate"><span class="pre">benchmarkDataFile</span></code>. But you can set the parameter <code class="docutils literal notranslate"><span class="pre">perfProfiling</span></code> as True or False to decide whether to print the CPU performance data of the model at the network layer on a certain device, and set <code class="docutils literal notranslate"><span class="pre">perfEvent</span></code> as <code class="docutils literal notranslate"><span class="pre">CYCLE</span></code>/<code class="docutils literal notranslate"><span class="pre">CACHE</span></code>/<code class="docutils literal notranslate"><span class="pre">STALL</span></code> to decide what CPU performance data to measure. The default value of <code class="docutils literal notranslate"><span class="pre">perfProfiling</span></code> is False, the default value of <code class="docutils literal notranslate"><span class="pre">perfEvent</span></code> is <code class="docutils literal notranslate"><span class="pre">CYCLE</span></code>. Due to the fluctuation of PMU readings in multi-thread tests, <code class="docutils literal notranslate"><span class="pre">numThreads</span></code> is suggested to be set as <code class="docutils literal notranslate"><span class="pre">1</span></code>. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./benchmark<span class="w"> </span>--modelFile<span class="o">=</span>/path/to/model.ms<span class="w"> </span>--perfProfiling<span class="o">=</span><span class="nb">true</span><span class="w"> </span>--numThreads<span class="o">=</span><span class="m">1</span>
</pre></div>
</div>
<p>This command uses a random input, sets the parameter <code class="docutils literal notranslate"><span class="pre">perfProfiling</span></code> as true, and other parameters use default values. After this command is executed, the statistics on the running time of the model at the network layer will be displayed as follows. In this case, the statistics are displayed by<code class="docutils literal notranslate"><span class="pre">opName</span></code> and <code class="docutils literal notranslate"><span class="pre">optype</span></code>. <code class="docutils literal notranslate"><span class="pre">opName</span></code> indicates the operator name, <code class="docutils literal notranslate"><span class="pre">optype</span></code> indicates the operator type, and <code class="docutils literal notranslate"><span class="pre">cycles(k)</span></code> indicates the average CPU cycles of the operator per single run (in thousand, affected by CPU frequency), <code class="docutils literal notranslate"><span class="pre">cycles(%)</span></code> indicates the ratio of the operator CPU cycles to the total operator CPU cycles, <code class="docutils literal notranslate"><span class="pre">ins(k)</span></code> indicates the average CPU instructions of the operator per single run (in thousand), and <code class="docutils literal notranslate"><span class="pre">ins(%)</span></code> indicates the ratio of the operator CPU instructions to the total operator CPU instructions. Finally, <code class="docutils literal notranslate"><span class="pre">Model</span></code>/<code class="docutils literal notranslate"><span class="pre">NumThreads</span></code>/<code class="docutils literal notranslate"><span class="pre">MinRuntime</span></code>/<code class="docutils literal notranslate"><span class="pre">MaxRunTime</span></code>/<code class="docutils literal notranslate"><span class="pre">AvgRunTime</span></code> is presented for reference.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>-----------------------------------------------------------------------------------------
opName                                                   cycles(k)       cycles(%)       ins(k)          ins(%)
Add_Plus214_Output_0                                     1.53            0.006572        1.27            0.002148
Conv_Convolution110_Output_0                             91.12           0.390141        217.58          0.369177
Conv_COnvolution28_Output_0                              114.61          0.490704        306.28          0.519680
Matmul_Times212_Output_0                                 8.75            0.037460        15.55           0.026385
MaxPool_Pooling160_Output_0                              3.24            0.013873        8.70            0.014767
MaxPool_Pooling66_Output_0                               11.63           0.049780        35.17           0.059671
Reshape_Pooling160_Output_0_reshape0                     0.91            0.003899        1.58            0.002677
nhwc2nchw_MaxPool_Pooling160_Output_0_post8_0            1.77            0.007571        3.25            0.005508
-----------------------------------------------------------------------------------------
opType          cycles(k)       cycles(%)       ins(k)          ins(%)
Add             1.53            0.006572        1.27            0.002148
Conv2D          205.73          0.880845        523.85          0.888856
MatMul          8.75            0.037460        15.55           0.026385
Nhwc2nchw       1.77            0.007571        3.25            0.005508
Pooling         14.87           0.063654        43.87           0.074437
Reshape         0.91            0.003839        1.58            0.002677

Model = model.ms, NumThreads = 1, MinRunTime = 0.104000 ms, MaxRunTime = 0.179000 ms, AvgRunTime = 0.116000 ms

-----------------------------------------------------------------------------------------
</pre></div>
</div>
<p>When <code class="docutils literal notranslate"><span class="pre">perfEvent</span></code> is set as <code class="docutils literal notranslate"><span class="pre">CACHE</span></code>, the columns will be <code class="docutils literal notranslate"><span class="pre">cache</span> <span class="pre">ref(k)</span></code>/<code class="docutils literal notranslate"><span class="pre">cache</span> <span class="pre">ref(%)</span></code>/<code class="docutils literal notranslate"><span class="pre">miss(k)</span></code>/<code class="docutils literal notranslate"><span class="pre">miss(%)</span></code>, which indicate cache reference times / cache reference ratio / cache miss times / cache miss ratio(to all cache misses, not to cache references); when <code class="docutils literal notranslate"><span class="pre">perfEvent</span></code> is set as <code class="docutils literal notranslate"><span class="pre">STALL</span></code>, the columns will be<code class="docutils literal notranslate"><span class="pre">frontend(k)</span></code>/<code class="docutils literal notranslate"><span class="pre">frontend(%)</span></code>/<code class="docutils literal notranslate"><span class="pre">backend(k)</span></code>/<code class="docutils literal notranslate"><span class="pre">backend(%)</span></code>, which indicate CPU front-end stall cycles / front-end stall cycles ratio / back-end stall cycles / back-end stall cycles ratio. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./benchmark<span class="w"> </span>--modelFile<span class="o">=</span>/path/to/model.ms<span class="w"> </span>--perfProfiling<span class="o">=</span><span class="nb">true</span><span class="w"> </span>--numThreads<span class="o">=</span><span class="m">1</span><span class="w"> </span>--perfEvent<span class="o">=</span><span class="s2">&quot;CACHE&quot;</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./benchmark<span class="w"> </span>--modelFile<span class="o">=</span>/path/to/model.ms<span class="w"> </span>--perfProfiling<span class="o">=</span><span class="nb">true</span><span class="w"> </span>--numThreads<span class="o">=</span><span class="m">1</span><span class="w"> </span>--perfEvent<span class="o">=</span><span class="s2">&quot;STALL&quot;</span>
</pre></div>
</div>
</section>
</section>
<section id="dump">
<h3>Dump<a class="headerlink" href="#dump" title="Permalink to this headline"></a></h3>
<p>Benchmark tool provides Dump function (currently only supports <code class="docutils literal notranslate"><span class="pre">CPU</span></code> operator), which saves the input and output data of the operator in the model to a disk file. These files can be used to locate the problem of abnormal accuracy during the model inference process.</p>
<section id="dump-step">
<h4>Dump Step<a class="headerlink" href="#dump-step" title="Permalink to this headline"></a></h4>
<ol class="arabic">
<li><p>Create dump json file:<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>, the name and location of the JSON file can be customized.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;common_dump_settings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;dump_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;/absolute_path&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;net_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ResNet50&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;input_output&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;kernels&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;Default/Conv-op12&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;Default/Conv-op13&quot;</span><span class="p">]</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dump_mode</span></code>: 0: dump all kernels in graph, 1: dump kernels in kernels list.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>: The absolute path to save dump data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>: The net name, e.g.: ResNet50. If this field is not specified, the default value is “default”.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output</span></code>: 0: dump input and output of kernel, 1: dump input of kernel, 2: dump output of kernel.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernels</span></code>: List of operator names. If this field is not specified or the value is set to [], <code class="docutils literal notranslate"><span class="pre">&quot;dump_mode&quot;</span></code> must be set to 0; otherwise, the value of <code class="docutils literal notranslate"><span class="pre">&quot;dump_mode&quot;</span></code> must be set to 1.</p></li>
</ul>
</li>
<li><p>Specify the json configuration file of Dump.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_DUMP_CONFIG</span><span class="o">=</span><span class="si">${</span><span class="nv">xxx</span><span class="si">}</span>
</pre></div>
</div>
<p>“xxx” represents the absolute path of data_dump.json, such as:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_DUMP_CONFIG</span><span class="o">=</span>/path/to/data_dump.json
</pre></div>
</div>
<p>Note：</p>
<ul class="simple">
<li><p>The environment variables need to be set before the benchmark is executed. The settings will not take effect during the execution of the benchmark.</p></li>
</ul>
</li>
</ol>
</section>
<section id="dump-data-directory-dtructure">
<h4>Dump Data Directory Dtructure<a class="headerlink" href="#dump-data-directory-dtructure" title="Permalink to this headline"></a></h4>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{path}/
    - {net_name}/
        - {folder_id}/
            {op_name}_{input_output_index}_{shape}_{data_type}_{format}.bin
        ...
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>: the absolute path set in the <code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code> configuration file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>: the network name set in the <code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code> configuration file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">folder_id</span></code>: The folder number created by default is 0. Each time the benchmark program is executed, the folder number is increased by 1, the maximum number of folders supported is 1000.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_name</span></code>: the name of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output_index</span></code>: the index of input or output. For example, <code class="docutils literal notranslate"><span class="pre">output_0</span></code> means that the file is the data of the first output Tensor of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data_type</span></code>: the data type of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shape</span></code>: the shape of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">format</span></code>: the format of the operator.</p></li>
</ul>
<p>The data file generated by Dump is a binary file with the suffix <code class="docutils literal notranslate"><span class="pre">.bin</span></code>. You can use the <code class="docutils literal notranslate"><span class="pre">np.fromfile()</span></code> interface in Numpy to read the data. Take the bin file with the data type of float32 as an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">fromfile</span><span class="p">(</span><span class="s2">&quot;/path/to/dump.bin&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="windows-environment-usage">
<h2>Windows Environment Usage<a class="headerlink" href="#windows-environment-usage" title="Permalink to this headline"></a></h2>
<section id="id1">
<h3>Environment Preparation<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<p>To use the Benchmark tool, you need to prepare the environment as follows:</p>
<ul>
<li><p>Compilation: Install build dependencies and perform build. The code of the Benchmark tool is stored in the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/tools/benchmark</span></code> directory of the MindSpore source code. For details about the build operations, see the <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r1.6/use/build.html#id1">Environment Requirements</a> and <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r1.6/use/build.html#id3">Compilation Example</a> in the build document.</p></li>
<li><p>Add the path of dynamic library required by the benchmark to the environment variables PATH.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">set</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span>%PACKAGE_ROOT_PATH%<span class="se">\i</span>nference<span class="se">\l</span>ib<span class="p">;</span>%PATH%
</pre></div>
</div>
</li>
</ul>
</section>
<section id="id2">
<h3>Parameter Description<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<p>The command used for benchmark testing based on the compiled Benchmark tool is as follows. The parameters are the same as those used in the Linux environment, and will not be repeated here.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>call benchmark.exe [--modelFile=&lt;MODELFILE&gt;] [--accuracyThreshold=&lt;ACCURACYTHRESHOLD&gt;]
   [--benchmarkDataFile=&lt;BENCHMARKDATAFILE&gt;] [--benchmarkDataType=&lt;BENCHMARKDATATYPE&gt;]
   [--cpuBindMode=&lt;CPUBINDMODE&gt;] [--device=&lt;DEVICE&gt;] [--help]
   [--inDataFile=&lt;INDATAFILE&gt;] [--loopCount=&lt;LOOPCOUNT&gt;]
   [--numThreads=&lt;NUMTHREADS&gt;] [--warmUpLoopCount=&lt;WARMUPLOOPCOUNT&gt;]
   [--enableFp16=&lt;ENABLEFP16&gt;] [--timeProfiling=&lt;TIMEPROFILING&gt;]
            [--inputShapes=&lt;INPUTSHAPES&gt;]
</pre></div>
</div>
</section>
<section id="id3">
<h3>Example<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h3>
<p>When using the Benchmark tool to perform benchmark testing on different MindSpore Lite models, you can set different parameters to implement different test functions. The testing is classified into performance test and accuracy test. The output statistics are the same as those in the Linux environment, and will not be repeated here.</p>
<section id="id4">
<h4>Performance Test<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h4>
<ul class="simple">
<li><p>Use a random input and default values for other parameters.</p></li>
</ul>
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span><span class="k">call</span> benchmark.exe --modelFile=/path/to/model.ms
</pre></div>
</div>
<ul class="simple">
<li><p>set <code class="docutils literal notranslate"><span class="pre">timeProfiling=true</span></code>, use a random input and default values for other parameters.</p></li>
</ul>
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span><span class="k">call</span> benchmark.exe --modelFile=/path/to/model.ms --timeProfiling=true
</pre></div>
</div>
</section>
<section id="id5">
<h4>Accuracy Test<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h4>
<p>The input data is set by the <code class="docutils literal notranslate"><span class="pre">inDataFile</span></code> parameter, and the calibration data is set by the <code class="docutils literal notranslate"><span class="pre">benchmarkDataFile</span></code> parameter.</p>
<ul class="simple">
<li><p>Set the accuracy threshold to 3%.</p></li>
</ul>
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span><span class="k">call</span> benchmark.exe --modelFile=/path/to/model.ms --inDataFile=/path/to/input.bin --benchmarkDataFile=/path/to/output.out --accuracyThreshold=3
</pre></div>
</div>
<ul class="simple">
<li><p>Run on the CPU.</p></li>
</ul>
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span><span class="k">call</span> benchmark.exe --modelFile=/path/to/model.ms --inDataFile=/path/to/input.bin --benchmarkDataFile=/path/to/output.out --device=CPU
</pre></div>
</div>
<ul class="simple">
<li><p>Set specified input shapes.</p></li>
</ul>
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span><span class="k">call</span> benchmark.exe --modelFile=/path/to/model.ms --inDataFile=/path/to/input.bin --benchmarkDataFile=/path/to/output.out --inputShapes=1,32,32,1
</pre></div>
</div>
</section>
</section>
<section id="id6">
<h3>Dump<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<p>The usage of Dump function in the Windows environment is basically the same as that of in the <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r1.6/use/benchmark_tool.html#dump">Linux environment</a>, and will not be repeated here.</p>
<p>Note that in the Windows environment, when setting the absolute path <code class="docutils literal notranslate"><span class="pre">Path</span></code> in the <code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code> configuration file, it must be specified in the form of <code class="docutils literal notranslate"><span class="pre">\\</span></code>.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="benchmark.html" class="btn btn-neutral float-left" title="Benchmark Tool" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="benchmark_train_tool.html" class="btn btn-neutral float-right" title="benchmark_train" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore Lite.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>