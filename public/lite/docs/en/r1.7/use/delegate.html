

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Using Delegate to Support Third-party AI Framework &mdash; MindSpore Lite master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/lite.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/lite.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Benchmark Tool" href="benchmark.html" />
    <link rel="prev" title="Building Custom Operators Online" href="register_kernel.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore Lite
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Obtain MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="downloads.html">Downloading MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="build.html">Building MindSpore Lite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/one_hour_introduction.html">Getting Started in One Hour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_cpp.html">Experience C++ Simple Inference Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_server_inference_cpp.html">Experience C++ Minimalist Concurrent Reasoning Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_java.html">Experience Java Simple Inference Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_server_inference_java.html">Experience Java Minimalist Concurrent Reasoning Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Android Application Development Based on JNI Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/image_segmentation.html">Android Application Development Based on Java Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/train_lenet.html">Implement Device Training Based On C++ Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/train_lenet_java.html">Implement Device Training Based On Java Interface</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference on Devices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="converter_tool.html">Converting Models for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="post_training_quantization.html">Post Training Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_preprocessing.html">Data Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">Executing Model Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="micro.html">Perform Inference on Mini and Small Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="asic.html">Application Specific Integrated Circuit Integration Instructions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training on Devices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="converter_train.html">Creating MindSpore Lite Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime_train.html">Executing Model Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Third-party hardware docking</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="register.html">Custom Kernel</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Using Delegate to Support Third-party AI Framework</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#usage-of-delegate">Usage of Delegate</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#adding-a-custom-delegate-class">Adding a Custom Delegate Class</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implementing-the-init">Implementing the Init</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implementing-the-build">Implementing the Build</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implementing-the-sub-graph-kernel">Implementing the Sub-graph Kernel</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#calling-delegate-by-lite-framework">Calling Delegate by Lite Framework</a></li>
<li class="toctree-l2"><a class="reference internal" href="#example-of-npudelegate">Example of NPUDelegate</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#adding-the-npudelegate-class">Adding the NPUDelegate Class</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implementing-the-init-of-npudelegate">Implementing the Init of NPUDelegate</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implementing-the-build-of-npudelegate">Implementing the Build of NPUDelegate</a></li>
<li class="toctree-l3"><a class="reference internal" href="#creating-npugraph">Creating NPUGraph</a></li>
<li class="toctree-l3"><a class="reference internal" href="#adding-the-npugraph-class">Adding the NPUGraph Class</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">Benchmark Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="cropper_tool.html">Static Library Cropper Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="visual_tool.html">Visualization Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="obfuscator_tool.html">Model Obfuscation Tool</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../architecture_lite.html">Overall Architecture (Lite)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_lite.html">Lite Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_codegen.html">Codegen Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_lite.html">Model List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting_guide.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../log.html">Log</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Using Delegate to Support Third-party AI Framework</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/use/delegate.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="using-delegate-to-support-third-party-ai-framework">
<h1>Using Delegate to Support Third-party AI Framework<a class="headerlink" href="#using-delegate-to-support-third-party-ai-framework" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.7/docs/lite/docs/source_en/use/delegate.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.7/resource/_static/logo_source_en.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>Delegate of MindSpore Lite is used to support third-party AI frameworks (such as NPU, TensorRT) to quickly access to the inference process in MindSpore Lite. Third-party frameworks can be implemented by users themselves, or other open source frameworks. Generally, the framework has the ability to build model online, that is, multiple operators can be built into a sub-graph and distributed to the device for inference. If the user wants to schedule other inference frameworks through MindSpore Lite, please refer to this article.</p>
</section>
<section id="usage-of-delegate">
<h2>Usage of Delegate<a class="headerlink" href="#usage-of-delegate" title="Permalink to this headline"></a></h2>
<p>Using Delegate to support a third-party AI framework mainly includes the following steps:</p>
<ol class="arabic simple">
<li><p>Add a custom delegate class: Inherit the <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Delegate.html">Delegate</a> class to implement XXXDelegate.</p></li>
<li><p>Implementing the Init Function: The <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Delegate.html">Init</a> function needs to check whether the device supports the delegate framework and to apply for resources related to delegate.</p></li>
<li><p>Implementing the Build Function: The <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Delegate.html">Build</a> function will implement the kernel support judgment, the sub-graph construction, and the online graph building.</p></li>
<li><p>Implementing the sub-graph Kernel: Inherit the <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_kernel_Kernel.html#class-kernel">Kernel</a> to implement delegate sub-graph Kernel.</p></li>
</ol>
<section id="adding-a-custom-delegate-class">
<h3>Adding a Custom Delegate Class<a class="headerlink" href="#adding-a-custom-delegate-class" title="Permalink to this headline"></a></h3>
<p>XXXDelegate should inherit from <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Delegate.html">Delegate</a>. In the constructor of XXXDelegate, configure settings for third-party AI framework to build and execute the model, such as NPU frequency, CPU thread number, etc.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">XXXDelegate</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">Delegate</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="n">XXXDelegate</span><span class="p">()</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span>

<span class="w">  </span><span class="o">~</span><span class="n">XXXDelegate</span><span class="p">()</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span>

<span class="w">  </span><span class="n">Status</span><span class="w"> </span><span class="nf">Init</span><span class="p">()</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">  </span><span class="n">Status</span><span class="w"> </span><span class="nf">Build</span><span class="p">(</span><span class="n">DelegateModel</span><span class="w"> </span><span class="o">*</span><span class="n">model</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">};</span>
</pre></div>
</div>
</section>
<section id="implementing-the-init">
<h3>Implementing the Init<a class="headerlink" href="#implementing-the-init" title="Permalink to this headline"></a></h3>
<p><a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Delegate.html">Init</a> will be called during the <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Model.html">Build</a> process of <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Model.html#class-model">Model</a>. The specific location is in the <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.7/mindspore/lite/src/lite_session.cc#L696">LiteSession::Init</a> function of MindSpore Lite internal process.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Status</span><span class="w"> </span><span class="nf">XXXDelegate::Init</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// 1. Check whether the inference device matches the delegate framework.</span>
<span class="w">  </span><span class="c1">// 2. Initialize delegate related resources.</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="implementing-the-build">
<h3>Implementing the Build<a class="headerlink" href="#implementing-the-build" title="Permalink to this headline"></a></h3>
<p>The input parameter of the <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Delegate.html">Build(DelegateModel *model)</a> interface is <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_DelegateModel.html">DelegateModel</a>。</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">std::vector&lt;kernel::Kernel</span> <span class="pre">*&gt;</span> <span class="pre">*kernels_</span></code>: A list of kernels that have been selected by MindSpore Lite and topologically sorted.</p>
<p><code class="docutils literal notranslate"><span class="pre">const</span> <span class="pre">std::map&lt;kernel::Kernel</span> <span class="pre">*,</span> <span class="pre">const</span> <span class="pre">schema::Primitive</span> <span class="pre">*&gt;</span> <span class="pre">primitives_</span></code>: A map of kernel and its attribute <code class="docutils literal notranslate"><span class="pre">schema::Primitive</span></code>, which is used to analyze the original attribute information.</p>
</div></blockquote>
<p><a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Delegate.html">Build</a> will be called during the <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Model.html">Build</a> process of <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Model.html#class-model">Model</a>. The specific location is in the <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.7/mindspore/lite/src/scheduler.cc#L132">Schedule::Schedule</a> function of MindSpore Lite internal process. At this time, the inner kernels have been selected by MindSpore Lite. The following steps should be implemented in Build function:</p>
<ol class="arabic simple">
<li><p>Traverse the kernel list, use <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_DelegateModel.html">GetPrimitive</a> to get the attribute of kernel. Analyze the attribute to judge whether the delegate framework supports it.</p></li>
<li><p>For a continuous supported kernel list, construct a delegate sub-graph kernel and <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_DelegateModel.html">Replace</a> the continuous supported kernels with it.</p></li>
</ol>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Status</span><span class="w"> </span><span class="nf">XXXDelegate::Build</span><span class="p">(</span><span class="n">DelegateModel</span><span class="w"> </span><span class="o">*</span><span class="n">model</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">KernelIter</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">BeginKernelIterator</span><span class="p">();</span><span class="w">                   </span><span class="c1">// Record the start operator position supported by the Delegate</span>
<span class="w">  </span><span class="n">KernelIter</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">BeginKernelIterator</span><span class="p">();</span><span class="w">                    </span><span class="c1">// Record the end operator position supported by the Delegate</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">KernelIter</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">BeginKernelIterator</span><span class="p">();</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">EndKernelIterator</span><span class="p">();</span><span class="w"> </span><span class="n">iter</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="o">*</span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">iter</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">IsSupport</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">GetPrimitive</span><span class="p">(</span><span class="n">kernel</span><span class="p">)))</span><span class="w"> </span><span class="p">{</span><span class="w">           </span><span class="c1">// Check whether the Delegate framework supports the kernel according to the primitive</span>
<span class="w">      </span><span class="n">end</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iter</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w">                                                        </span><span class="c1">// The current kernel is not supported, and the sub-graph is truncated</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">from</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">end</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">xxx_graph_kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CreateXXXGraph</span><span class="p">(</span><span class="n">from</span><span class="p">,</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="p">);</span><span class="w">   </span><span class="c1">// Create a Delegate sub-graph Kernel</span>
<span class="w">        </span><span class="n">iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">Replace</span><span class="p">(</span><span class="n">from</span><span class="p">,</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">xxx_graph_kernel</span><span class="p">);</span><span class="w">     </span><span class="c1">// Replace the supported kernels list with a Delegate sub-graph Kernel</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">      </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">      </span><span class="n">end</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">RET_OK</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="implementing-the-sub-graph-kernel">
<h3>Implementing the Sub-graph Kernel<a class="headerlink" href="#implementing-the-sub-graph-kernel" title="Permalink to this headline"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">CreateXXXGraph</span></code> interface above will return a sub-graph kernel of XXXDelegate. The code is as follows:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="o">*</span><span class="nf">XXXDelegate::CreateXXXGraph</span><span class="p">(</span><span class="n">KernelIter</span><span class="w"> </span><span class="n">from</span><span class="p">,</span><span class="w"> </span><span class="n">KernelIter</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">DelegateModel</span><span class="w"> </span><span class="o">*</span><span class="n">model</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">in_tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GraphInTensors</span><span class="p">(...);</span><span class="w">    </span><span class="c1">// Find the input tensors of the Delegate sub-graph</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">out_tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GraphOutTensors</span><span class="p">(...);</span><span class="w">  </span><span class="c1">// Find the output tensors of the Delegate sub-graph</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">graph_kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">nothrow</span><span class="p">)</span><span class="w"> </span><span class="n">XXXGraph</span><span class="p">(</span><span class="n">in_tensors</span><span class="p">,</span><span class="w"> </span><span class="n">out_tensors</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">graph_kernel</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New XXX Graph failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="c1">// Build graph online, load model, etc.</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">graph_kernel</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The delegate sub-graph kernel <code class="docutils literal notranslate"><span class="pre">XXXGraph</span></code> should inherit from <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_kernel_Kernel.html#class-kernel">Kernel</a>. The realization of <code class="docutils literal notranslate"><span class="pre">XXXGraph</span></code> should focus on:</p>
<ol class="arabic simple">
<li><p>Find the correct in_tensors and out_tensors for <code class="docutils literal notranslate"><span class="pre">XXXGraph</span></code> according to the original kernels list.</p></li>
<li><p>Rewrite the Prepare, Resize, and Execute interfaces. <a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.7/api_cpp/mindspore_kernel.html#prepare">Prepare</a> will be called in <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Model.html">Build</a> of <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Model.html#class-model">Model</a>. <a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.7/api_cpp/mindspore_kernel.html#execute">Execute</a> will be called in <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Model.html">Predict</a> of Model. <a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.7/api_cpp/mindspore_kernel.html#resize">ReSize</a> will be called in <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Model.html">Resize</a> of Model.</p></li>
</ol>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">XXXGraph</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="n">XXXGraph</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs</span><span class="p">)</span>
<span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="k">nullptr</span><span class="p">,</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{}</span>

<span class="w">  </span><span class="o">~</span><span class="n">XXXGraph</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="nf">Prepare</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Generally, the model will be built only once, so Prepare is also called once.</span>
<span class="w">    </span><span class="c1">// Do something without input data, such as pack the constant weight tensor, etc.</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="nf">Execute</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Obtain input data from in_tensors.</span>
<span class="w">    </span><span class="c1">// Execute the inference process.</span>
<span class="w">    </span><span class="c1">// Write the result back to out_tensors.</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="nf">ReSize</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Support dynamic shape, and input shape will changed.</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
</section>
</section>
<section id="calling-delegate-by-lite-framework">
<h2>Calling Delegate by Lite Framework<a class="headerlink" href="#calling-delegate-by-lite-framework" title="Permalink to this headline"></a></h2>
<p>MindSpore Lite schedules user-defined delegate by <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Context.html#class-context">Context</a>. Use <a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.7/api_cpp/mindspore.html#setdelegate">SetDelegate</a> to set a custom delegate for Context.  Delegate will be passed by <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Model.html">Build</a> to MindSpore Lite. If the Delegate in the Context is a null pointer, the process will call the inner inference of MindSpore Lite.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">Context</span><span class="o">&gt;</span><span class="p">();</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">context</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New context failed&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">auto</span><span class="w"> </span><span class="n">delegate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">XXXDelegate</span><span class="o">&gt;</span><span class="p">();</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">delegate</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New XXX delegate failed&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">context</span><span class="o">-&gt;</span><span class="n">SetDelegate</span><span class="p">(</span><span class="n">delegate</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">nothrow</span><span class="p">)</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Model</span><span class="p">();</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">model</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New Model failed.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>
<span class="c1">// Assuming that we have read a ms file and stored in the address pointed by model_buf</span>
<span class="k">auto</span><span class="w"> </span><span class="n">build_ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">Build</span><span class="p">(</span><span class="n">model_buf</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kMindIR</span><span class="p">,</span><span class="w"> </span><span class="n">context</span><span class="p">);</span>
<span class="k">delete</span><span class="p">[](</span><span class="n">model_buf</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">build_ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Build model failed.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="example-of-npudelegate">
<h2>Example of NPUDelegate<a class="headerlink" href="#example-of-npudelegate" title="Permalink to this headline"></a></h2>
<p>Currently, MindSpore Lite uses the <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.7/mindspore/lite/src/delegate/npu/npu_delegate.h#L29">NPUDelegate</a> for the NPU backend. This tutorial gives a brief description of NPUDelegate, so that users can quickly understand the usage of Delegate APIs.</p>
<section id="adding-the-npudelegate-class">
<h3>Adding the NPUDelegate Class<a class="headerlink" href="#adding-the-npudelegate-class" title="Permalink to this headline"></a></h3>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">NPUDelegate</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">Delegate</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="k">explicit</span><span class="w"> </span><span class="n">NPUDelegate</span><span class="p">(</span><span class="n">lite</span><span class="o">::</span><span class="n">NpuDeviceInfo</span><span class="w"> </span><span class="n">device_info</span><span class="p">)</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">Delegate</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">frequency_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">device_info</span><span class="p">.</span><span class="n">frequency_</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>

<span class="w">  </span><span class="o">~</span><span class="n">NPUDelegate</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w">  </span><span class="n">Status</span><span class="w"> </span><span class="nf">Init</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w">  </span><span class="n">Status</span><span class="w"> </span><span class="nf">Build</span><span class="p">(</span><span class="n">DelegateModel</span><span class="w"> </span><span class="o">*</span><span class="n">model</span><span class="p">)</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w"> </span><span class="k">protected</span><span class="o">:</span>
<span class="w">  </span><span class="c1">// Analyze a kernel and its attribute.</span>
<span class="w">  </span><span class="c1">// If NPU supports it, return an NPUOp, which has the information of connection relationship with other kernels and the attributes.</span>
<span class="w">  </span><span class="c1">// If not support, return null pointer.</span>
<span class="w">  </span><span class="n">NPUOp</span><span class="w"> </span><span class="o">*</span><span class="n">GetOP</span><span class="p">(</span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="o">*</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">schema</span><span class="o">::</span><span class="n">Primitive</span><span class="w"> </span><span class="o">*</span><span class="n">primitive</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Construct a NPU sub-graph with a continuous NPUOps</span>
<span class="w">  </span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="o">*</span><span class="nf">CreateNPUGraph</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">NPUOp</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">ops</span><span class="p">,</span><span class="w"> </span><span class="n">DelegateModel</span><span class="w"> </span><span class="o">*</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">KernelIter</span><span class="w"> </span><span class="n">from</span><span class="p">,</span>
<span class="w">                                 </span><span class="n">KernelIter</span><span class="w"> </span><span class="n">end</span><span class="p">);</span>

<span class="w">  </span><span class="n">NPUManager</span><span class="w"> </span><span class="o">*</span><span class="n">npu_manager_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="n">NPUPassManager</span><span class="w"> </span><span class="o">*</span><span class="n">pass_manager_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">schema</span><span class="o">::</span><span class="n">PrimitiveType</span><span class="p">,</span><span class="w"> </span><span class="n">NPUGetOp</span><span class="o">&gt;</span><span class="w"> </span><span class="n">op_func_lists_</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">frequency_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w">  </span><span class="c1">// NPU frequency</span>
<span class="p">};</span>
</pre></div>
</div>
</section>
<section id="implementing-the-init-of-npudelegate">
<h3>Implementing the Init of NPUDelegate<a class="headerlink" href="#implementing-the-init-of-npudelegate" title="Permalink to this headline"></a></h3>
<p><a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.7/mindspore/lite/src/delegate/npu/npu_delegate.cc#L75">Init</a> function is used to apply resource for NPU and determine whether the hardware supports NPU.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Status</span><span class="w"> </span><span class="nf">NPUDelegate::Init</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">npu_manager_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">nothrow</span><span class="p">)</span><span class="w"> </span><span class="n">NPUManager</span><span class="p">();</span><span class="w">       </span><span class="c1">// NPU manager of model buffer and client.</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">npu_manager_</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New npu manager failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">npu_manager_</span><span class="o">-&gt;</span><span class="n">IsSupportNPU</span><span class="p">())</span><span class="w"> </span><span class="p">{</span><span class="w">                  </span><span class="c1">// Check whether the current device supports NPU.</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">DEBUG</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Checking npu is unsupported.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">RET_NOT_SUPPORT</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">pass_manager_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">nothrow</span><span class="p">)</span><span class="w"> </span><span class="n">NPUPassManager</span><span class="p">();</span><span class="w">  </span><span class="c1">// The default format of MindSpore Lite is NHWC, and the default format of NPU is NCHW. The NPUPassManager is used to pack data between the sub-graphs.</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">pass_manager_</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New npu pass manager failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Initialize op_func lists. Get the correspondence between kernel type and GetOP function.</span>
<span class="w">  </span><span class="n">op_func_lists_</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">RET_OK</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="implementing-the-build-of-npudelegate">
<h3>Implementing the Build of NPUDelegate<a class="headerlink" href="#implementing-the-build-of-npudelegate" title="Permalink to this headline"></a></h3>
<p>The <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.7/mindspore/lite/src/delegate/npu/npu_delegate.cc#L163">Build</a> interface parses the DelegateModel and mainly implements the kernel support judgment, the sub-graph construction, and the online graph building.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Status</span><span class="w"> </span><span class="nf">NPUDelegate::Build</span><span class="p">(</span><span class="n">DelegateModel</span><span class="w"> </span><span class="o">*</span><span class="n">model</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">KernelIter</span><span class="w"> </span><span class="n">from</span><span class="p">,</span><span class="w"> </span><span class="n">end</span><span class="p">;</span><span class="w">                     </span><span class="c1">// Record the start and end positions of kernel supported by the NPU sub-graph.</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">NPUOp</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">npu_ops</span><span class="p">;</span><span class="w">             </span><span class="c1">// Save all NPUOp used to construct an NPU sub-graph.</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">graph_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">KernelIter</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">BeginKernelIterator</span><span class="p">();</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">EndKernelIterator</span><span class="p">();</span><span class="w"> </span><span class="n">iter</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="o">*</span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">iter</span><span class="p">;</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">npu_op</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetOP</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">GetPrimitive</span><span class="p">(</span><span class="n">kernel</span><span class="p">));</span><span class="w">  </span><span class="c1">// Obtain an NPUOp according to the kernel and the primitive. Each NPUOp contains information such as input tensors, output tensors and operator attribute.</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">npu_op</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">                </span><span class="c1">// NPU supports the current kernel.</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">npu_ops</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iter</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">      </span><span class="n">npu_ops</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">npu_op</span><span class="p">);</span>
<span class="w">      </span><span class="n">end</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iter</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w">                                 </span><span class="c1">// NPU does not support the current kernel.</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">npu_ops</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">npu_graph_kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CreateNPUGraph</span><span class="p">(</span><span class="n">npu_ops</span><span class="p">);</span><span class="w">  </span><span class="c1">// Create a NPU sub-graph kernel.</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">npu_graph_kernel</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">          </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Create NPU Graph failed.&quot;</span><span class="p">;</span>
<span class="w">          </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="n">npu_graph_kernel</span><span class="o">-&gt;</span><span class="n">set_name</span><span class="p">(</span><span class="s">&quot;NpuGraph&quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">to_string</span><span class="p">(</span><span class="n">graph_index</span><span class="o">++</span><span class="p">));</span>
<span class="w">        </span><span class="n">iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">Replace</span><span class="p">(</span><span class="n">from</span><span class="p">,</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">npu_graph_kernel</span><span class="p">);</span><span class="w">  </span><span class="c1">// Replace the supported kernel list with a NPU sub-graph kernel.</span>
<span class="w">        </span><span class="n">npu_ops</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">npu_manager_</span><span class="o">-&gt;</span><span class="n">LoadOMModel</span><span class="p">();</span><span class="w">    </span><span class="c1">// Build model online. Load NPU model.</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">RET_OK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;NPU client load model failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">RET_OK</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="creating-npugraph">
<h3>Creating NPUGraph<a class="headerlink" href="#creating-npugraph" title="Permalink to this headline"></a></h3>
<p>The following <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.7/mindspore/lite/src/delegate/npu/npu_delegate.cc#L273">Sample Code</a> is the CreateNPUGraph interface of NPUDelegate, used to generate an NPU sub-graph kernel.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="o">*</span><span class="nf">NPUDelegate::CreateNPUGraph</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">NPUOp</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">ops</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">in_tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GraphInTensors</span><span class="p">(</span><span class="n">ops</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">out_tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GraphOutTensors</span><span class="p">(</span><span class="n">ops</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">graph_kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">nothrow</span><span class="p">)</span><span class="w"> </span><span class="n">NPUGraph</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span><span class="w"> </span><span class="n">npu_manager_</span><span class="p">,</span><span class="w"> </span><span class="n">in_tensors</span><span class="p">,</span><span class="w"> </span><span class="n">out_tensors</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">graph_kernel</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">DEBUG</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New NPU Graph failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">graph_kernel</span><span class="o">-&gt;</span><span class="n">Init</span><span class="p">();</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">RET_OK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">DEBUG</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;NPU Graph Init failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">graph_kernel</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="adding-the-npugraph-class">
<h3>Adding the NPUGraph Class<a class="headerlink" href="#adding-the-npugraph-class" title="Permalink to this headline"></a></h3>
<p><a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.7/mindspore/lite/src/delegate/npu/npu_graph.h#L29">NPUGraph</a> inherits from <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_kernel_Kernel.html#class-kernel">Kernel</a>. And we need to rewrite the Prepare, Execute, and ReSize interfaces.</p>
<p><a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.7/mindspore/lite/src/delegate/npu/npu_graph.cc#L306">NPUGraph::Prepare</a> mainly implements:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">NPUGraph::Prepare</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Find the mapping relationship between hiai::AiTensor defined by NPU and MSTensor defined by MindSpore Lite</span>
<span class="p">}</span>
</pre></div>
</div>
<p><a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.7/mindspore/lite/src/delegate/npu/npu_graph.cc#L322">NPUGraph::Execute</a> mainly implements:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">NPUGraph::Execute</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// 1. Processing input: copy input data from MSTensor to hiai::AiTensor</span>
<span class="w">  </span><span class="c1">// 2. Perform inference</span>
<span class="w">  </span><span class="n">executor_</span><span class="o">-&gt;</span><span class="n">Execute</span><span class="p">();</span>
<span class="w">  </span><span class="c1">// 3. Processing output: copy output data from hiai::AiTensor to MSTensor</span>
<span class="p">}</span>
</pre></div>
</div>
<blockquote>
<div><p><a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r1.7/use/npu_info.html">NPU</a> is a third-party AI framework that added by MindSpore Lite internal developers. The usage of NPU is slightly different. You can set the <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Context.html#class-context">Context</a> through <a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.7/api_cpp/mindspore.html#setdelegate">SetDelegate</a>, or you can add the description of the NPU device <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_KirinNPUDeviceInfo.html#class-kirinnpudeviceinfo">KirinNPUDeviceInfo</a> to <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/generate/classmindspore_Context.html">MutableDeviceInfo</a> of the Context.</p>
</div></blockquote>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="register_kernel.html" class="btn btn-neutral float-left" title="Building Custom Operators Online" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="benchmark.html" class="btn btn-neutral float-right" title="Benchmark Tool" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore Lite.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>