<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Experience Java Simple Inference Demo &mdash; MindSpore Lite master documentation</title>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/lite.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/lite.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Experience Java Minimalist Concurrent Reasoning Demo" href="quick_start_server_inference_java.html" />
    <link rel="prev" title="Experience C++ Minimalist Concurrent Reasoning Demo" href="quick_start_server_inference_cpp.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Obtain MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/downloads.html">Downloading MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/build.html">Building MindSpore Lite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="one_hour_introduction.html">Getting Started in One Hour</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_cpp.html">Experience C++ Simple Inference Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_server_inference_cpp.html">Experience C++ Minimalist Concurrent Reasoning Demo</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Experience Java Simple Inference Demo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#building-and-running">Building and Running</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-loadingoptional">Model Loading(optional)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-build">Model Build</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-inference">Model Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="#memory-release">Memory Release</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_server_inference_java.html">Experience Java Minimalist Concurrent Reasoning Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_c.html">Expriencing Simpcified Inference Demo with C-language</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_segmentation.html">Android Application Development Based on Java Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="train_lenet.html">Implement Device Training Based On C++ Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="train_lenet_java.html">Implement Device Training Based On Java Interface</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference on Devices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/converter_tool.html">Converting Models for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/post_training_quantization.html">Post Training Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preprocessing.html">Data Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/runtime.html">Executing Model Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/micro.html">Performing Inference on MCU or Small Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/asic.html">Application Specific Integrated Circuit Integration Instructions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training on Devices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/converter_train.html">Creating MindSpore Lite Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/runtime_train.html">Executing Model Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Server Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/runtime_server_inference.html">Executing Server Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Third-party hardware docking</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/register.html">Custom Kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/delegate.html">Using Delegate to Support Third-party AI Framework</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/benchmark.html">Benchmark Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/cropper_tool.html">Static Library Cropper Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/visual_tool.html">Visualization Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/obfuscator_tool.html">Model Obfuscation Tool</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../architecture_lite.html">Overall Architecture (Lite)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_lite.html">Lite Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_codegen.html">Codegen Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_lite.html">Model List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting_guide.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../log.html">Log</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Experience Java Simple Inference Demo</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/quick_start/quick_start_java.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="experience-java-simple-inference-demo">
<h1>Experience Java Simple Inference Demo<a class="headerlink" href="#experience-java-simple-inference-demo" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.9/docs/lite/docs/source_en/quick_start/quick_start_java.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.9/resource/_static/logo_source_en.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>This tutorial provides an example program for MindSpore Lite to perform inference. It demonstrates the basic process of performing inference on the device side using <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.9/index.html">MindSpore Lite Java API</a> by random inputting data, executing inference, and printing the inference result. You can quickly understand how to use the Java APIs related to inference on MindSpore Lite. In this tutorial, the randomly generated data is used as the input data to perform the inference on the MobileNetV2 model and print the output data. The code is stored in the <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.9/mindspore/lite/examples/quick_start_java">mindspore/lite/examples/quick_start_java</a> directory.</p>
<p>The MindSpore Lite inference steps are as follows:</p>
<ol class="arabic simple">
<li><p>Load the model(optional): Read the <code class="docutils literal notranslate"><span class="pre">.ms</span></code> model converted by the <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r1.9/use/converter_tool.html">model conversion tool</a> from the file system.</p></li>
<li><p>Create and configure context: Create a configuration context <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.9/api_java/mscontext.html#mscontext">MSContext</a> to save some basic configuration parameters required by a session to guide graph build and execution. including <code class="docutils literal notranslate"><span class="pre">deviceType</span></code> (device type), <code class="docutils literal notranslate"><span class="pre">threadNum</span></code> (number of threads), <code class="docutils literal notranslate"><span class="pre">cpuBindMode</span></code> (CPU binding mode), and <code class="docutils literal notranslate"><span class="pre">enable_float16</span></code> (whether to preferentially use the float16 operator).</p></li>
<li><p>Build a graph: Before building a graph, the <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.9/api_java/model.html#build">build</a> interface of <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.9/api_java/model.html#model">model</a> needs to be called to build the graph, including subgraph partition and operator selection and scheduling. This takes a long time. Therefore, it is recommended that with one <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.9/api_java/model.html#model">model</a> created, one graph be built. In this case, the inference will be performed for multiple times.</p></li>
<li><p>Input data: Before the graph is executed, data needs to be filled in the <code class="docutils literal notranslate"><span class="pre">Input</span> <span class="pre">Tensor</span></code>.</p></li>
<li><p>Perform inference: Use the <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.9/api_java/model.html#predict">predict</a> of the <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.9/api_java/model.html#model">model</a> to perform model inference.</p></li>
<li><p>Obtain the output: After the graph execution is complete, you can obtain the inference result by <code class="docutils literal notranslate"><span class="pre">outputting</span> <span class="pre">the</span> <span class="pre">tensor</span></code>.</p></li>
<li><p>Release the memory: If the MindSpore Lite inference framework is not required, release the created <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.9/api_java/model.html#model">model</a>.</p></li>
</ol>
<p><img alt="img" src="../_images/lite_runtime.png" /></p>
<blockquote>
<div><p>To view the advanced usage of MindSpore Lite, see <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r1.9/use/runtime_java.html">Using Runtime to Perform Inference (Java)</a>.</p>
</div></blockquote>
</section>
<section id="building-and-running">
<h2>Building and Running<a class="headerlink" href="#building-and-running" title="Permalink to this headline"></a></h2>
<ul>
<li><p>Environment requirements</p>
<ul class="simple">
<li><p>System environment: Linux x86_64 (Ubuntu 18.04.02LTS is recommended.)</p></li>
<li><p>Build dependency:</p>
<ul>
<li><p><a class="reference external" href="https://git-scm.com/downloads">Git</a> &gt;= 2.28.0</p></li>
<li><p><a class="reference external" href="https://maven.apache.org/download.cgi">Maven</a> &gt;= 3.3</p></li>
<li><p><a class="reference external" href="https://openjdk.java.net/install/">OpenJDK</a> 1.8 to 1.15</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Build</p>
<p>Run the <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.9/mindspore/lite/examples/quick_start_java/build.sh">build script</a> in the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_java</span></code> directory to automatically download the MindSpore Lite inference framework library and model files and build the Demo.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>build.sh
</pre></div>
</div>
<blockquote>
<div><p>If the MindSpore Lite inference framework fails to be downloaded, manually download the MindSpore Lite model inference framework <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r1.9/use/downloads.html">mindspore-lite-{version}-linux-x64.tar.gz</a> whose hardware platform is CPU and operating system is Ubuntu-x64. Decompress the package and copy <code class="docutils literal notranslate"><span class="pre">runtime/lib/mindspore-lite-java.jar</span></code> file to the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_java/lib</span></code> directory.</p>
<p>If the MobileNetV2 model fails to be downloaded, manually download the model file <a class="reference external" href="https://download.mindspore.cn/model_zoo/official/lite/quick_start/mobilenetv2.ms">mobilenetv2.ms</a> and copy it to the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_java/model/</span></code> directory.</p>
<p>After manually downloading and placing the file in the specified location, you need to execute the build.sh script again to complete the compilation.</p>
</div></blockquote>
</li>
<li><p>Inference</p>
<p>After the build, go to the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_java/target</span></code> directory and run the following command to experience MindSpore Lite inference on the MobileNetV2 model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>java<span class="w"> </span>-classpath<span class="w"> </span>.:./quick_start_java.jar:../lib/mindspore-lite-java.jar<span class="w">  </span>com.mindspore.lite.demo.Main<span class="w"> </span>../model/mobilenetv2.ms
</pre></div>
</div>
<p>After the execution, the following information is displayed, including the tensor name, tensor size, number of output tensors, and the first 50 pieces of data.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>out tensor shape: [1,1000,] and out data: 5.4091015E-5 4.030303E-4 3.032344E-4 4.0029243E-4 2.2730739E-4 8.366581E-5 2.629827E-4 3.512394E-4 2.879536E-4 1.9557697E-4xxxxxxxxxx MindSpore Lite 1.1.0out tensor shape: [1,1000,] and out data: 5.4091015E-5 4.030303E-4 3.032344E-4 4.0029243E-4 2.2730739E-4 8.366581E-5 2.629827E-4 3.512394E-4 2.879536E-4 1.9557697E-4tensor name is:Default/Sigmoid-op204 tensor size is:2000 tensor elements num is:500output data is:3.31223e-05 1.99382e-05 3.01624e-05 0.000108345 1.19685e-05 4.25282e-06 0.00049955 0.000340809 0.00199094 0.000997094 0.00013585 1.57605e-05 4.34131e-05 1.56114e-05 0.000550819 2.9839e-05 4.70447e-06 6.91601e-06 0.000134483 2.06795e-06 4.11612e-05 2.4667e-05 7.26248e-06 2.37974e-05 0.000134513 0.00142482 0.00011707 0.000161848 0.000395011 3.01961e-05 3.95325e-05 3.12398e-06 3.57709e-05 1.36277e-06 1.01068e-05 0.000350805 5.09019e-05 0.000805241 6.60321e-05 2.13734e-05 9.88654e-05 2.1991e-06 3.24065e-05 3.9479e-05 4.45178e-05 0.00205024 0.000780899 2.0633e-05 1.89997e-05 0.00197261 0.000259391
</pre></div>
</div>
</li>
</ul>
</section>
<section id="model-loadingoptional">
<h2>Model Loading(optional)<a class="headerlink" href="#model-loadingoptional" title="Permalink to this headline"></a></h2>
<p>Read the MindSpore Lite model from the file system.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="c1">// Load the .ms model.</span>
<span class="n">MappedByteBuffer</span><span class="w"> </span><span class="n">byteBuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">null</span><span class="p">;</span>
<span class="k">try</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">fc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">RandomAccessFile</span><span class="p">(</span><span class="n">fileName</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;r&quot;</span><span class="p">).</span><span class="na">getChannel</span><span class="p">();</span>
<span class="w">    </span><span class="n">byteBuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fc</span><span class="p">.</span><span class="na">map</span><span class="p">(</span><span class="n">FileChannel</span><span class="p">.</span><span class="na">MapMode</span><span class="p">.</span><span class="na">READ_ONLY</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">fc</span><span class="p">.</span><span class="na">size</span><span class="p">()).</span><span class="na">load</span><span class="p">();</span>
<span class="p">}</span><span class="w"> </span><span class="k">catch</span><span class="w"> </span><span class="p">(</span><span class="n">IOException</span><span class="w"> </span><span class="n">e</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">e</span><span class="p">.</span><span class="na">printStackTrace</span><span class="p">();</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="model-build">
<h2>Model Build<a class="headerlink" href="#model-build" title="Permalink to this headline"></a></h2>
<p>Model build includes context configuration creation and model compilation. current graph build support file and mappedbytebuffer format. The following [sample code] describes model compilation by reading from a file.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="kd">private</span><span class="w"> </span><span class="kd">static</span><span class="w"> </span><span class="kt">boolean</span><span class="w"> </span><span class="nf">compile</span><span class="p">(</span><span class="n">String</span><span class="w"> </span><span class="n">modelPath</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MSContext</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">MSContext</span><span class="p">();</span>
<span class="w">    </span><span class="c1">// use default param init context</span>
<span class="w">    </span><span class="n">context</span><span class="p">.</span><span class="na">init</span><span class="p">();</span>
<span class="w">    </span><span class="kt">boolean</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">context</span><span class="p">.</span><span class="na">addDeviceInfo</span><span class="p">(</span><span class="n">DeviceType</span><span class="p">.</span><span class="na">DT_CPU</span><span class="p">,</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">ret</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">System</span><span class="p">.</span><span class="na">err</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Compile graph failed&quot;</span><span class="p">);</span>
<span class="w">        </span><span class="n">context</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="kc">false</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="c1">// Create the MindSpore lite session.</span>
<span class="w">    </span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">Model</span><span class="p">();</span>
<span class="w">    </span><span class="c1">// Compile graph.</span>
<span class="w">    </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="na">build</span><span class="p">(</span><span class="n">modelPath</span><span class="p">,</span><span class="w"> </span><span class="n">ModelType</span><span class="p">.</span><span class="na">MT_MINDIR</span><span class="p">,</span><span class="w"> </span><span class="n">context</span><span class="p">);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">ret</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">System</span><span class="p">.</span><span class="na">err</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Compile graph failed&quot;</span><span class="p">);</span>
<span class="w">        </span><span class="n">model</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="kc">false</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="kc">true</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="model-inference">
<h2>Model Inference<a class="headerlink" href="#model-inference" title="Permalink to this headline"></a></h2>
<p>Model inference includes data input, inference execution, and output obtaining. In this example, the input data is randomly generated, and the output result is printed after inference.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="kd">private</span><span class="w"> </span><span class="kd">static</span><span class="w"> </span><span class="kt">boolean</span><span class="w"> </span><span class="nf">run</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MSTensor</span><span class="w"> </span><span class="n">inputTensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="na">getInputByTensorName</span><span class="p">(</span><span class="s">&quot;graph_input-173&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">inputTensor</span><span class="p">.</span><span class="na">getDataType</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">DataType</span><span class="p">.</span><span class="na">kNumberTypeFloat32</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">System</span><span class="p">.</span><span class="na">err</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Input tensor data type is not float, the data type is &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="na">getDataType</span><span class="p">());</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="kc">false</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="c1">// Generator Random Data.</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">elementNums</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="na">elementsNum</span><span class="p">();</span>
<span class="w">    </span><span class="kt">float</span><span class="o">[]</span><span class="w"> </span><span class="n">randomData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">generateArray</span><span class="p">(</span><span class="n">elementNums</span><span class="p">);</span>
<span class="w">    </span><span class="n">ByteBuffer</span><span class="w"> </span><span class="n">inputData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floatArrayToByteBuffer</span><span class="p">(</span><span class="n">randomData</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Set Input Data.</span>
<span class="w">    </span><span class="n">inputTensor</span><span class="p">.</span><span class="na">setData</span><span class="p">(</span><span class="n">inputData</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Run Inference.</span>
<span class="w">    </span><span class="kt">boolean</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="na">predict</span><span class="p">();</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">ret</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">inputTensor</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
<span class="w">        </span><span class="n">System</span><span class="p">.</span><span class="na">err</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;MindSpore Lite run failed.&quot;</span><span class="p">);</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="kc">false</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Get Output Tensor Data.</span>
<span class="w">    </span><span class="n">MSTensor</span><span class="w"> </span><span class="n">outTensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="na">getOutputByTensorName</span><span class="p">(</span><span class="s">&quot;Softmax-65&quot;</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Print out Tensor Data.</span>
<span class="w">    </span><span class="n">StringBuilder</span><span class="w"> </span><span class="n">msgSb</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">StringBuilder</span><span class="p">();</span>
<span class="w">    </span><span class="n">msgSb</span><span class="p">.</span><span class="na">append</span><span class="p">(</span><span class="s">&quot;out tensor shape: [&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="o">[]</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outTensor</span><span class="p">.</span><span class="na">getShape</span><span class="p">();</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">dim</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">shape</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">msgSb</span><span class="p">.</span><span class="na">append</span><span class="p">(</span><span class="n">dim</span><span class="p">).</span><span class="na">append</span><span class="p">(</span><span class="s">&quot;,&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">msgSb</span><span class="p">.</span><span class="na">append</span><span class="p">(</span><span class="s">&quot;]&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">outTensor</span><span class="p">.</span><span class="na">getDataType</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">DataType</span><span class="p">.</span><span class="na">kNumberTypeFloat32</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">inputTensor</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
<span class="w">        </span><span class="n">outTensor</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
<span class="w">        </span><span class="n">System</span><span class="p">.</span><span class="na">err</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;output tensor data type is not float, the data type is &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">outTensor</span><span class="p">.</span><span class="na">getDataType</span><span class="p">());</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="kc">false</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="kt">float</span><span class="o">[]</span><span class="w"> </span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outTensor</span><span class="p">.</span><span class="na">getFloatData</span><span class="p">();</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">result</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="kc">null</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">inputTensor</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
<span class="w">        </span><span class="n">outTensor</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
<span class="w">        </span><span class="n">System</span><span class="p">.</span><span class="na">err</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;decodeBytes return null&quot;</span><span class="p">);</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="kc">false</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">msgSb</span><span class="p">.</span><span class="na">append</span><span class="p">(</span><span class="s">&quot; and out data:&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">50</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">outTensor</span><span class="p">.</span><span class="na">elementsNum</span><span class="p">();</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">msgSb</span><span class="p">.</span><span class="na">append</span><span class="p">(</span><span class="s">&quot; &quot;</span><span class="p">).</span><span class="na">append</span><span class="p">(</span><span class="n">result</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">msgSb</span><span class="p">.</span><span class="na">toString</span><span class="p">());</span>
<span class="w">    </span><span class="c1">// In/Out Tensor must be free</span>
<span class="w">    </span><span class="n">inputTensor</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
<span class="w">    </span><span class="n">outTensor</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="kc">true</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="memory-release">
<h2>Memory Release<a class="headerlink" href="#memory-release" title="Permalink to this headline"></a></h2>
<p>If the MindSpore Lite inference framework is not required, release the created <code class="docutils literal notranslate"><span class="pre">model</span></code>.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="c1">// Delete model buffer.</span>
<span class="n">model</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="quick_start_server_inference_cpp.html" class="btn btn-neutral float-left" title="Experience C++ Minimalist Concurrent Reasoning Demo" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="quick_start_server_inference_java.html" class="btn btn-neutral float-right" title="Experience Java Minimalist Concurrent Reasoning Demo" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore Lite.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>