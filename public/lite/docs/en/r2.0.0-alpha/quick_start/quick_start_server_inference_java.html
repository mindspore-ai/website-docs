

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Experience Java Minimalist Concurrent Reasoning Demo &mdash; MindSpore Lite master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/lite.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/js/lite.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Experiencing the Python Simplified Inference Demo" href="quick_start_python.html" />
    <link rel="prev" title="Experience Java Simple Inference Demo" href="quick_start_java.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore Lite
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Obtain MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/downloads.html">Downloading MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/build.html">Building MindSpore Lite</a></li>
</ul>
<p class="caption"><span class="caption-text">Quick Start</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="one_hour_introduction.html">Getting Started in One Hour</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_cpp.html">Experience C++ Simple Inference Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_server_inference_cpp.html">Experience C++ Minimalist Concurrent Reasoning Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_java.html">Experience Java Simple Inference Demo</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Experience Java Minimalist Concurrent Reasoning Demo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#building-and-running">Building and Running</a></li>
<li class="toctree-l2"><a class="reference internal" href="#init">Init</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parallel-predict">Parallel predict</a></li>
<li class="toctree-l2"><a class="reference internal" href="#memory-release">Memory Release</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_python.html">Experiencing the Python Simplified Inference Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_server_inference_python.html">Experiencing the Python Simplified Concurrent Inference Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_c.html">Expriencing Simpcified Inference Demo with C-language</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_segmentation.html">Android Application Development Based on Java Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="train_lenet.html">Implement Device Training Based On C++ Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="train_lenet_java.html">Implement Device Training Based On Java Interface</a></li>
</ul>
<p class="caption"><span class="caption-text">Inference on Devices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/post_training_quantization.html">Post Training Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preprocessing.html">Data Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/runtime.html">Executing Model Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/micro.html">Performing Inference or Training on MCU or Small Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/asic.html">Application Specific Integrated Circuit Integration Instructions</a></li>
</ul>
<p class="caption"><span class="caption-text">Training on Devices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/runtime_train.html">Executing Model Training</a></li>
</ul>
<p class="caption"><span class="caption-text">Server Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/runtime_server_inference.html">Executing Server Inference</a></li>
</ul>
<p class="caption"><span class="caption-text">Third-party hardware docking</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/register.html">Custom Kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/delegate.html">Using Delegate to Support Third-party AI Framework</a></li>
</ul>
<p class="caption"><span class="caption-text">Other Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/converter.html">Converting Models for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/benchmark.html">Benchmark Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/cropper_tool.html">Static Library Cropper Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/visual_tool.html">Visualization Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/obfuscator_tool.html">Model Obfuscation Tool</a></li>
</ul>
<p class="caption"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../architecture_lite.html">Overall Architecture (Lite)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_lite.html">Lite Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_codegen.html">Codegen Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_lite.html">Model List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting_guide.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../log.html">Log</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Experience Java Minimalist Concurrent Reasoning Demo</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/quick_start/quick_start_server_inference_java.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="experience-java-minimalist-concurrent-reasoning-demo">
<h1>Experience Java Minimalist Concurrent Reasoning Demo<a class="headerlink" href="#experience-java-minimalist-concurrent-reasoning-demo" title="Permalink to this headline">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r2.0.0-alpha/docs/lite/docs/source_en/quick_start/quick_start_server_inference_java.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0.0-alpha/resource/_static/logo_source_en.png"></a></p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>This tutorial provides an example program for MindSpore Lite to parallel inference. It demonstrates the basic process of performing inference on the device side using <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r2.0.0-alpha/index.html">MindSpore Lite Java API</a> by random inputting data, executing inference, and printing the inference result. You can quickly understand how to use the Java APIs related to inference on MindSpore Lite. In this tutorial, the randomly generated data is used as the input data to perform the inference on the MobileNetV2 model and print the output data. The code is stored in the <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r2.0.0-alpha/mindspore/lite/examples/quick_start_server_inference_java">mindspore/lite/examples/quick_start_server_inference_java</a> directory.</p>
<p>The MindSpore Lite inference steps are as follows:</p>
<ol class="simple">
<li><p>Load the model: Read the <code class="docutils literal notranslate"><span class="pre">.ms</span></code> model converted by the <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r2.0.0-alpha/use/converter_tool.html">model conversion tool</a> from the file system.</p></li>
<li><p>Create and configure context: Create a configuration <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r2.0.0-alpha/api_java/runner_config.html#runnerconfig">RunnerConfig</a> to save some basic configuration parameters required by a ModelParallelRunner to guide model pool init. including <code class="docutils literal notranslate"><span class="pre">MSContext</span></code>, <code class="docutils literal notranslate"><span class="pre">threadNum</span></code> (number of threads), <code class="docutils literal notranslate"><span class="pre">WorkersNum</span></code>.</p></li>
<li><p>Init: Before building a graph, the <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r2.0.0-alpha/api_java/model_parallel_runner.html#modelparallelrunner">ModelParallelRunner</a> interface of <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r2.0.0-alpha/api_java/model_parallel_runner.html#init">init</a> needs to be called to init the model parallel runner, including init model pool and subgraph partition and operator selection and scheduling. This takes a long time. Therefore, it is recommended that with one <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r2.0.0-alpha/api_java/model_parallel_runner.html#init">Init</a> created, one graph be built. In this case, the inference will be performed for multiple times.</p></li>
<li><p>Input data: Before the graph is executed, data needs to be filled in the <code class="docutils literal notranslate"><span class="pre">Input</span> <span class="pre">Tensor</span></code>.</p></li>
<li><p>Perform inference: Use the <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r2.0.0-alpha/api_java/model_parallel_runner.html#predict">predict</a> of the <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r2.0.0-alpha/api_java/model_parallel_runner.html#modelparallelrunner">ModelParallelRunner</a> to perform model inference.</p></li>
<li><p>Obtain the output: After the graph execution is complete, you can obtain the inference result by <code class="docutils literal notranslate"><span class="pre">outputting</span> <span class="pre">the</span> <span class="pre">tensor</span></code>.</p></li>
<li><p>Release the memory: If the MindSpore Lite inference framework is not required, release the created <a class="reference external" href="https://www.mindspore.cn/lite/api/en/r2.0.0-alpha/api_java/model_parallel_runner.html#modelparallelrunner">ModelParallelRunner</a>.</p></li>
</ol>
<p><img alt="img" src="../_images/server_inference.png" /></p>
</div>
<div class="section" id="building-and-running">
<h2>Building and Running<a class="headerlink" href="#building-and-running" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p>Environment requirements</p>
<ul class="simple">
<li><p>System environment: Linux x86_64 (Ubuntu 18.04.02LTS is recommended.)</p></li>
<li><p>Build dependency:</p>
<ul>
<li><p><a class="reference external" href="https://git-scm.com/downloads">Git</a> &gt;= 2.28.0</p></li>
<li><p><a class="reference external" href="https://maven.apache.org/download.cgi">Maven</a> &gt;= 3.3</p></li>
<li><p><a class="reference external" href="https://openjdk.java.net/install/">OpenJDK</a> 1.8 to 1.15</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Build</p>
<p>Run the <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r2.0.0-alpha/mindspore/lite/examples/quick_start_server_inference_java/build.sh">build script</a> in the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_server_inference_java</span></code> directory to automatically download the MindSpore Lite inference framework library and model files and build the Demo.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>build.sh
</pre></div>
</div>
<blockquote>
<div><p>If the MindSpore Lite inference framework fails to be downloaded, manually download the MindSpore Lite model inference framework <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r2.0.0-alpha/use/downloads.html">mindspore-lite-{version}-linux-x64.tar.gz</a> whose hardware platform is CPU and operating system is Ubuntu-x64. Decompress the package and copy <code class="docutils literal notranslate"><span class="pre">runtime/lib/mindspore-lite-java.jar</span></code> file to the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_server_inference_java/lib</span></code> directory.</p>
<p>If the MobileNetV2 model fails to be downloaded, manually download the model file <a class="reference external" href="https://download.mindspore.cn/model_zoo/official/lite/quick_start/mobilenetv2.ms">mobilenetv2.ms</a> and copy it to the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_server_inference_java/model/</span></code> directory.</p>
<p>After manually downloading and placing the file in the specified location, you need to execute the build.sh script again to complete the compilation.</p>
</div></blockquote>
</li>
<li><p>Inference</p>
<p>After the build, go to the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_server_inference_java/target</span></code> directory and run the following command to experience MindSpore Lite inference on the MobileNetV2 model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>java<span class="w"> </span>-classpath<span class="w"> </span>.:./quick_start_server_inference_java.jar:../lib/mindspore-lite-java.jar<span class="w">  </span>com.mindspore.lite.demo.Main<span class="w"> </span>../model/mobilenetv2.ms
</pre></div>
</div>
<p>After the execution, the following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>========== model parallel runner predict success ==========
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="init">
<h2>Init<a class="headerlink" href="#init" title="Permalink to this headline">¶</a></h2>
<p>ModelParallelRunner Init includes context configuration creation and model compilation.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="kd">private</span><span class="w"> </span><span class="kd">static</span><span class="w"> </span><span class="n">ModelParallelRunner</span><span class="w"> </span><span class="n">runner</span><span class="p">;</span>
<span class="kd">private</span><span class="w"> </span><span class="kd">static</span><span class="w"> </span><span class="n">List</span><span class="o">&lt;</span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">inputs</span><span class="p">;</span>
<span class="kd">private</span><span class="w"> </span><span class="kd">static</span><span class="w"> </span><span class="n">List</span><span class="o">&lt;</span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">outputs</span><span class="p">;</span>

<span class="c1">// use default param init context</span>
<span class="n">MSContext</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">MSContext</span><span class="p">();</span>
<span class="n">context</span><span class="p">.</span><span class="na">init</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">);</span>
<span class="kt">boolean</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">context</span><span class="p">.</span><span class="na">addDeviceInfo</span><span class="p">(</span><span class="n">DeviceType</span><span class="p">.</span><span class="na">DT_CPU</span><span class="p">,</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">ret</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">System</span><span class="p">.</span><span class="na">err</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;init context failed&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="n">context</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="p">;</span>
<span class="p">}</span>

<span class="c1">// init runner config</span>
<span class="n">RunnerConfig</span><span class="w"> </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">RunnerConfig</span><span class="p">();</span>
<span class="n">config</span><span class="p">.</span><span class="na">init</span><span class="p">(</span><span class="n">context</span><span class="p">);</span>
<span class="n">config</span><span class="p">.</span><span class="na">setWorkersNum</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span>

<span class="c1">// init ModelParallelRunner</span>
<span class="n">ModelParallelRunner</span><span class="w"> </span><span class="n">runner</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">ModelParallelRunner</span><span class="p">();</span>
<span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">runner</span><span class="p">.</span><span class="na">init</span><span class="p">(</span><span class="n">modelPath</span><span class="p">,</span><span class="w"> </span><span class="n">config</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">ret</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">System</span><span class="p">.</span><span class="na">err</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;ModelParallelRunner init failed.&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="n">runner</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
<span class="w">    </span><span class="k">return</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="parallel-predict">
<h2>Parallel predict<a class="headerlink" href="#parallel-predict" title="Permalink to this headline">¶</a></h2>
<p>Model inference includes data input, inference execution, and output obtaining. In this example, the input data is randomly generated, and the output result is printed after inference.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="c1">// init input tensor</span>
<span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">ArrayList</span><span class="o">&lt;&gt;</span><span class="p">();</span>
<span class="n">MSTensor</span><span class="w"> </span><span class="n">input</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">runner</span><span class="p">.</span><span class="na">getInputs</span><span class="p">().</span><span class="na">get</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">input</span><span class="p">.</span><span class="na">getDataType</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">DataType</span><span class="p">.</span><span class="na">kNumberTypeFloat32</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">System</span><span class="p">.</span><span class="na">err</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Input tensor data type is not float, the data type is &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">input</span><span class="p">.</span><span class="na">getDataType</span><span class="p">());</span>
<span class="w">    </span><span class="k">return</span><span class="p">;</span>
<span class="p">}</span>
<span class="c1">// Generator Random Data.</span>
<span class="kt">int</span><span class="w"> </span><span class="n">elementNums</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">.</span><span class="na">elementsNum</span><span class="p">();</span>
<span class="kt">float</span><span class="o">[]</span><span class="w"> </span><span class="n">randomData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">generateArray</span><span class="p">(</span><span class="n">elementNums</span><span class="p">);</span>
<span class="n">ByteBuffer</span><span class="w"> </span><span class="n">inputData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floatArrayToByteBuffer</span><span class="p">(</span><span class="n">randomData</span><span class="p">);</span>
<span class="c1">// create input MSTensor</span>
<span class="n">MSTensor</span><span class="w"> </span><span class="n">inputTensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MSTensor</span><span class="p">.</span><span class="na">createTensor</span><span class="p">(</span><span class="n">input</span><span class="p">.</span><span class="na">tensorName</span><span class="p">(),</span><span class="w"> </span><span class="n">DataType</span><span class="p">.</span><span class="na">kNumberTypeFloat32</span><span class="p">,</span><span class="n">input</span><span class="p">.</span><span class="na">getShape</span><span class="p">(),</span><span class="w"> </span><span class="n">inputData</span><span class="p">);</span>
<span class="n">inputs</span><span class="p">.</span><span class="na">add</span><span class="p">(</span><span class="n">inputTensor</span><span class="p">);</span>

<span class="c1">// init output</span>
<span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">ArrayList</span><span class="o">&lt;&gt;</span><span class="p">();</span>

<span class="c1">// runner do predict</span>
<span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">runner</span><span class="p">.</span><span class="na">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="n">outputs</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">ret</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">System</span><span class="p">.</span><span class="na">err</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;MindSpore Lite predict failed.&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="n">freeTensor</span><span class="p">();</span>
<span class="w">    </span><span class="n">runner</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
<span class="w">    </span><span class="k">return</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;========== model parallel runner predict success ==========&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="section" id="memory-release">
<h2>Memory Release<a class="headerlink" href="#memory-release" title="Permalink to this headline">¶</a></h2>
<p>If the MindSpore Lite inference framework is not required, release the created <code class="docutils literal notranslate"><span class="pre">ModelParallelRunner</span></code>.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="kd">private</span><span class="w"> </span><span class="kd">static</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">freeTensor</span><span class="p">(){</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">inputs</span><span class="p">.</span><span class="na">size</span><span class="p">();</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">inputs</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="n">i</span><span class="p">).</span><span class="na">free</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">outputs</span><span class="p">.</span><span class="na">size</span><span class="p">();</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">outputs</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="n">i</span><span class="p">).</span><span class="na">free</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
<span class="n">freeTensor</span><span class="p">();</span>
<span class="n">runner</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="quick_start_python.html" class="btn btn-neutral float-right" title="Experiencing the Python Simplified Inference Demo" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="quick_start_java.html" class="btn btn-neutral float-left" title="Experience Java Simple Inference Demo" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, MindSpore Lite.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>