<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>benchmark &mdash; MindSpore Lite master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script><script src="../../_static/jquery.js"></script>
        <script src="../../_static/js/theme.js"></script><script src="../../_static/underscore.js"></script><script src="../../_static/doctools.js"></script><script src="../../_static/js/lite.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Overall Architecture (Lite)" href="../../architecture_lite.html" />
    <link rel="prev" title="Benchmark Tool" href="benchmark.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Obtain MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../downloads.html">Downloading MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../build.html">Building Device-side MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="build.html">Building Cloud-side MindSpore Lite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../quick_start/one_hour_introduction.html">Quick Start to Device-side Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quick_start/one_hour_introduction_cloud.html">Quick Start to Cloud-side Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Device-side Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../device_infer_example.html">Device-side Inference Sample</a></li>
<li class="toctree-l1"><a class="reference internal" href="../post_training_quantization.html">Post Training Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data_preprocessing.html">Data Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../runtime.html">Executing Model Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../micro.html">Performing Inference or Training on MCU or Small Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asic.html">Application Specific Integrated Circuit Integration Instructions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Device-side Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../device_train_example.html">Device-side Training Sample</a></li>
<li class="toctree-l1"><a class="reference internal" href="../runtime_train.html">Executing Model Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Third-party hardware docking</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../register.html">Custom Kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../delegate.html">Using Delegate to Support Third-party AI Framework</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Device-side Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../converter.html">Converting Models for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark.html">Benchmark Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cropper_tool.html">Static Library Cropper Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../visual_tool.html">Visualization Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../obfuscator_tool.html">Model Obfuscation Tool</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Cloud-side Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">Performing Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime_parallel.html">Performing Concurrent Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime_distributed.html">Distributed Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Cloud-side Tools</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="converter.html">Model Converter</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="benchmark.html">Benchmark Tool</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">benchmark</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#linux-environment-usage-instructions">Linux Environment Usage Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#environment-preparation">Environment Preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#description-of-parameters">Description of Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#usage-examples">Usage Examples</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../architecture_lite.html">Overall Architecture (Lite)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../operator_list_lite.html">Lite Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../operator_list_codegen.html">Codegen Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_lite.html">Model List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../troubleshooting_guide.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../log.html">Log</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="benchmark.html">Benchmark Tool</a> &raquo;</li>
      <li>benchmark</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/use/cloud_infer/benchmark_tool.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="benchmark">
<h1>benchmark<a class="headerlink" href="#benchmark" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.3/docs/lite/docs/source_en/use/cloud_infer/benchmark_tool.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3/resource/_static/logo_source_en.svg" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>Before performing inference after converting the model, you can use the Benchmark tool to benchmark the MindSpore Lite cloud-side inference model. It allows not only quantitative analysis of the forward inference execution time of MindSpore Lite cloud-side inference models (performance), but also comparable error analysis (accuracy) by specifying the model output.</p>
</section>
<section id="linux-environment-usage-instructions">
<h2>Linux Environment Usage Instructions<a class="headerlink" href="#linux-environment-usage-instructions" title="Permalink to this headline"></a></h2>
<section id="environment-preparation">
<h3>Environment Preparation<a class="headerlink" href="#environment-preparation" title="Permalink to this headline"></a></h3>
<p>To use the Benchmark tool, you need to do the following environment preparation work.</p>
<ul>
<li><p>Compile: The Benchmark tool code is in the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/tools/benchmark</span></code> directory of the MindSpore source code. Refer to the build documentation for <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r2.3/use/cloud_infer/build.html#environment-requirements">Environment requirements</a> and <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r2.3/use/cloud_infer/build.html#compilation-examples">Compilation Examples</a> in the build documentation to perform the compilation.</p></li>
<li><p>Run: Refer to <a class="reference external" href="https://www.mindspore.cn/lite/docs/en/r2.3/use/cloud_infer/build.html#directory-structure">compilation output</a> in the build documentation to get the <code class="docutils literal notranslate"><span class="pre">benchmark</span></code> tool from the compiled package.</p></li>
<li><p>Add the dynamic link libraries needed for inference to the environment variable LD_LIBRARY_PATH.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">PACKAGE_ROOT_PATH</span><span class="si">}</span>/runtime/lib:<span class="si">${</span><span class="nv">PACKAGE_ROOT_PATH</span><span class="si">}</span>/tools/converter/lib:<span class="si">${</span><span class="nv">LD_LIBRARY_PATH</span><span class="si">}</span>
</pre></div>
</div>
<p>${PACKAGE_ROOT_PATH} is the root directory of the compiled package after unpacking.</p>
</li>
</ul>
</section>
<section id="description-of-parameters">
<h3>Description of Parameters<a class="headerlink" href="#description-of-parameters" title="Permalink to this headline"></a></h3>
<p>When using the compiled Benchmark tool to benchmark the model, the command format is shown below.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./benchmark [--modelFile=&lt;MODELFILE&gt;] [--accuracyThreshold=&lt;ACCURACYTHRESHOLD&gt;]
   [--cosineDistanceThreshold=&lt;COSINEDISTANCETHRESHOLD&gt;]
   [--benchmarkDataFile=&lt;BENCHMARKDATAFILE&gt;] [--benchmarkDataType=&lt;BENCHMARKDATATYPE&gt;]
   [--cpuBindMode=&lt;CPUBINDMODE&gt;] [--device=&lt;DEVICE&gt;] [--help]
   [--inDataFile=&lt;INDATAFILE&gt;] [--loopCount=&lt;LOOPCOUNT&gt;]
   [--numThreads=&lt;NUMTHREADS&gt;] [--warmUpLoopCount=&lt;WARMUPLOOPCOUNT&gt;]
   [--enableFp16=&lt;ENABLEFP16&gt;] [--timeProfiling=&lt;TIMEPROFILING&gt;]
   [--inputShapes=&lt;INPUTSHAPES&gt;] [--perfProfiling=&lt;PERFPROFILING&gt;]
   [--perfEvent=&lt;PERFEVENT&gt;]
</pre></div>
</div>
<p>Detailed parameter descriptions are provided below.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter names</p></th>
<th class="head"><p>Properties</p></th>
<th class="head"><p>Function Descriptions</p></th>
<th class="head"><p>Tpyes of parameters</p></th>
<th class="head"><p>Default values</p></th>
<th class="head"><p>Value range</p></th>
<th class="head"><p>Remarks</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--modelFile=&lt;MODELPATH&gt;</span></code></p></td>
<td><p>Required</p></td>
<td><p>Specify the path to the MindSpore Lite model file that needs to be benchmarked.</p></td>
<td><p>String</p></td>
<td><p>null</p></td>
<td><p>-</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--accuracyThreshold=&lt;ACCURACYTHRESHOLD&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specify the accuracy threshold.</p></td>
<td><p>Float</p></td>
<td><p>0.5</p></td>
<td><p>-</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--benchmarkDataFile=&lt;CALIBDATAPATH&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specify the file path to the benchmark data. The benchmark data is used as the comparison output for this test model, which is derived from the same input and forward inference from other deep learning frameworks.</p></td>
<td><p>String</p></td>
<td><p>null</p></td>
<td><p>-</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--benchmarkDataType=&lt;CALIBDATATYPE&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specify the benchmark data type.</p></td>
<td><p>String</p></td>
<td><p>FLOAT</p></td>
<td><p>FLOAT, INT32, INT8, UINT8</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--device=&lt;DEVICE&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specify the type of device on which the model inference program runs.</p></td>
<td><p>String</p></td>
<td><p>CPU</p></td>
<td><p>CPU, GPU, NPU, Ascend</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--help</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Display help information for the <code class="docutils literal notranslate"><span class="pre">benchmark</span></code> command.</p></td>
<td><p>-</p></td>
<td><p>-</p></td>
<td><p>-</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--inDataFile=&lt;INDATAPATH&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specify the file path to the test model input data. If not set, random input is used.</p></td>
<td><p>String</p></td>
<td><p>null</p></td>
<td><p>-</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--loopCount=&lt;LOOPCOUNT&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specify the number of forward inference runs for the test model when Benchmark tool performs benchmarking, with a positive integer value.</p></td>
<td><p>Integer</p></td>
<td><p>10</p></td>
<td><p>-</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--numThreads=&lt;NUMTHREADS&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specify the number of threads on which the model inference program will run.</p></td>
<td><p>Integer</p></td>
<td><p>2</p></td>
<td><p>-</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--warmUpLoopCount=&lt;WARMUPLOOPCOUNT&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specify the number of model warm-up inferences performed by the test model before executing the number of rounds of the benchmark test run.</p></td>
<td><p>Integer</p></td>
<td><p>3</p></td>
<td><p>-</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--inputShapes=&lt;INPUTSHAPES&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specify the input dimensions, which should follow the original model format. The dimension values are separated by ‘,’ and multiple input dimensions are separated by ‘:’</p></td>
<td><p>String</p></td>
<td><p>Null</p></td>
<td><p>-</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--cosineDistanceThreshold=&lt;COSINEDISTANCETHRESHOLD&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specify the cosine distance threshold. The cosine distance will be calculated only if this parameter is specified and its value is greater than -1.</p></td>
<td><p>Float</p></td>
<td><p>-1.1</p></td>
<td><p>-</p></td>
<td><p>Not supported at the moment</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--cpuBindMode=&lt;CPUBINDMODE&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specify the type of CPU core to which the model inference program is bound when it runs.</p></td>
<td><p>Integer</p></td>
<td><p>1</p></td>
<td><p>2: means medium core<br/>1: means large core<br/>0: means no binding</p></td>
<td><p>Not supported at the moment</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--enableFp16=&lt;FP16PIORITY&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Specify whether to give preference to float16 operator.</p></td>
<td><p>Boolean</p></td>
<td><p>false</p></td>
<td><p>true, false</p></td>
<td><p>Not supported at the moment</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--timeProfiling=&lt;TIMEPROFILING&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Take effect at performance verification, specifying whether to use TimeProfiler to print the time of each operator.</p></td>
<td><p>Boolean</p></td>
<td><p>false</p></td>
<td><p>true, false</p></td>
<td><p>Not supported at the moment</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--perfEvent=&lt;PERFEVENT&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Take effect during CPU performance verification. Specify the specific content of the CPU performance parameters printed by PerfProfiler. When specified as CYCLE, the number of CPU cycles and the number of instructions of the operator will be printed. When specified as CACHE, the number of cache reads and the number of cache misses of the operator will be printed. When specified as STALL, the number of CPU front-end waiting cycles and the number of back-end waiting cycles will be printed.</p></td>
<td><p>String</p></td>
<td><p>CYCLE</p></td>
<td><p>CYCLE/CACHE/STALL</p></td>
<td><p>Not supported at the moment</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--decryptKey=&lt;DECRYPTKEY&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>The key used to decrypt the file, expressed in hexadecimal characters. Only AES-GCM is supported, and the key length is only 16Byte.</p></td>
<td><p>String</p></td>
<td><p>null</p></td>
<td><p>Note that the key is a hexadecimal representation of the string, such as the key is defined as <code class="docutils literal notranslate"><span class="pre">b'0123456789ABCDEF'</span></code> corresponding to the hexadecimal representation of <code class="docutils literal notranslate"><span class="pre">30313233343536373839414243444546</span></code>. Linux platform users can use the <code class="docutils literal notranslate"><span class="pre">xxd</span></code> tool to convert the byte representation of the key to hexadecimal expression.</p></td>
<td><p>Not supported at the moment</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--cryptoLibPath=&lt;CRYPTOLIBPATH&gt;</span></code></p></td>
<td><p>Optional</p></td>
<td><p>Path to the OpenSSL crypto library crypto</p></td>
<td><p>String</p></td>
<td><p>null</p></td>
<td><p>-</p></td>
<td><p>Not supported at the moment</p></td>
</tr>
</tbody>
</table>
</section>
<section id="usage-examples">
<h3>Usage Examples<a class="headerlink" href="#usage-examples" title="Permalink to this headline"></a></h3>
<p>For different MindSpore Lite cloud-side inference models, when benchmarking them with Benchmark tool, different parameters can be set to achieve different testing functions for them, mainly divided into performance test and accuracy test.</p>
<section id="performance-test">
<h4>Performance Test<a class="headerlink" href="#performance-test" title="Permalink to this headline"></a></h4>
<p>The main test metric of the performance test performed by the Benchmark tool is the time taken by the model for a single forward inference. In the performance test task, there is no need to set benchmark data parameters such as <code class="docutils literal notranslate"><span class="pre">benchmarkDataFile</span></code>. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./benchmark<span class="w"> </span>--modelFile<span class="o">=</span>/path/to/model.mindir
</pre></div>
</div>
<p>This command uses random input and uses default values for other parameters. This command outputs the following statistics after execution, which shows the shortest single inference time, the longest single inference time and the average inference time of the test model after running the specified number of inference rounds.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Model = model.mindir, numThreads = 2, MinRunTime = 72.228996 ms, MaxRuntime = 73.094002 ms, AvgRunTime = 72.556000 ms
</pre></div>
</div>
</section>
<section id="accuracy-test">
<h4>Accuracy Test<a class="headerlink" href="#accuracy-test" title="Permalink to this headline"></a></h4>
<p>The accuracy test performed by the Benchmark tool is mainly to compare and verify the accuracy of MindSpore Lite cloud-side inference model output by setting benchmark data. In the accuracy test task, in addition to the <code class="docutils literal notranslate"><span class="pre">modelFile</span></code> parameter, the <code class="docutils literal notranslate"><span class="pre">benchmarkDataFile</span></code> parameter must also be set. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./benchmark<span class="w"> </span>--modelFile<span class="o">=</span>/path/to/model.mindir<span class="w"> </span>--inDataFile<span class="o">=</span>/path/to/input.bin<span class="w"> </span>--device<span class="o">=</span>CPU<span class="w"> </span>--accuracyThreshold<span class="o">=</span><span class="m">3</span><span class="w"> </span>--benchmarkDataFile<span class="o">=</span>/path/to/output.out
</pre></div>
</div>
<p>This command specifies the input data and benchmark data of the test model, (the default input and benchmark data types are float32), and also specifies the model inference program to run on the CPU with an accuracy threshold of 3%. The command outputs the following statistics after execution, which shows the single input data of the test model, the output results and average deviation rate of the output nodes, and the average deviation rate of all nodes.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>InData0: 139.947 182.373 153.705 138.945 108.032 164.703 111.585 227.402 245.734 97.7776 201.89 134.868 144.851 236.027 18.1142 22.218 5.15569 212.318 198.43 221.853
================ Comparing Output data ================
Data of node age_out : 5.94584e-08 6.3317e-08 1.94726e-07 1.91809e-07 8.39805e-08 7.66035e-08 1.69285e-07 1.46246e-07 6.03796e-07 1.77631e-07 1.54343e-07 2.04623e-07 8.89609e-07 3.63487e-06 4.86876e-06 1.23939e-05 3.09981e-05 3.37098e-05 0.000107102 0.000213932 0.000533579 0.00062465 0.00296401 0.00993984 0.038227 0.0695085 0.162854 0.123199 0.24272 0.135048 0.169159 0.0221256 0.013892 0.00502971 0.00134921 0.00135701 0.000383242 0.000163475 0.000136294 9.77864e-05 8.00793e-05 5.73874e-05 3.53858e-05 2.18535e-05 2.04467e-05 1.85286e-05 1.05075e-05 9.34751e-06 6.12732e-06 4.55476e-06
Mean bias of node age_out : 0%
Mean bias of all nodes: 0%
=======================================================
</pre></div>
</div>
<p>If you need to specify the dimension of the input data (e.g. input dimension is 1, 32, 32, 1), use the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./benchmark<span class="w"> </span>--modelFile<span class="o">=</span>/path/to/model.mindir<span class="w"> </span>--inDataFile<span class="o">=</span>/path/to/input.bin<span class="w"> </span>--inputShapes<span class="o">=</span><span class="m">1</span>,32,32,1<span class="w"> </span>--device<span class="o">=</span>CPU<span class="w"> </span>--accuracyThreshold<span class="o">=</span><span class="m">3</span><span class="w"> </span>--benchmarkDataFile<span class="o">=</span>/path/to/output.out
</pre></div>
</div>
<p>If the model is encryption model, inference is performed after both <code class="docutils literal notranslate"><span class="pre">decryptKey</span></code> and <code class="docutils literal notranslate"><span class="pre">cryptoLibPath</span></code> are configured to decrypt the model. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./benchmark<span class="w"> </span>--modelFile<span class="o">=</span>/path/to/encry_model.mindir<span class="w"> </span>--decryptKey<span class="o">=</span><span class="m">30313233343536373839414243444546</span><span class="w"> </span>--cryptoLibPath<span class="o">=</span>/root/anaconda3/bin/openssl
</pre></div>
</div>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="benchmark.html" class="btn btn-neutral float-left" title="Benchmark Tool" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../architecture_lite.html" class="btn btn-neutral float-right" title="Overall Architecture (Lite)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>