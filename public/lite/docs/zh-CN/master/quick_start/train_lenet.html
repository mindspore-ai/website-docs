<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>基于C++接口实现端侧训练 &mdash; MindSpore Lite master 文档</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script src="../_static/js/lite.js"></script><script src="../_static/translations.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="基于Java接口实现端侧训练" href="train_lenet_java.html" />
    <link rel="prev" title="端侧训练样例" href="../device_train_example.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">获取MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/downloads.html">下载MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/build.html">编译端侧MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/cloud_infer/build.html">编译云侧MindSpore Lite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="one_hour_introduction.html">端侧推理快速入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="one_hour_introduction_cloud.html">云侧推理快速入门</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">端侧推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../device_infer_example.html">端侧推理样例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/post_training_quantization.html">训练后量化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preprocessing.html">预处理数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/runtime.html">执行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/micro.html">在MCU或小型系统上执行推理或训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/asic.html">专用芯片集成说明</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">端侧训练</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../device_train_example.html">端侧训练样例</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">基于C++接口实现端侧训练</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#概述">概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#准备">准备</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#环境要求">环境要求</a></li>
<li class="toctree-l4"><a class="reference internal" href="#下载数据集">下载数据集</a></li>
<li class="toctree-l4"><a class="reference internal" href="#安装mindspore">安装MindSpore</a></li>
<li class="toctree-l4"><a class="reference internal" href="#下载并安装mindspore-lite">下载并安装MindSpore Lite</a></li>
<li class="toctree-l4"><a class="reference internal" href="#连接安卓设备">连接安卓设备</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#模型训练和验证">模型训练和验证</a></li>
<li class="toctree-l3"><a class="reference internal" href="#示例程序详解">示例程序详解</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#示例程序结构">示例程序结构</a></li>
<li class="toctree-l4"><a class="reference internal" href="#定义并导出模型">定义并导出模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="#转换模型">转换模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="#训练模型">训练模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="train_lenet_java.html">基于Java接口实现端侧训练</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../use/runtime_train.html">执行训练</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">端侧第三方接入</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/register.html">自定义算子</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/delegate.html">使用Delegate支持第三方AI框架接入</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">端侧工具</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/converter.html">模型转换工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/benchmark.html">基准测试工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/cropper_tool.html">静态库裁剪工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/visual_tool.html">可视化工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/obfuscator_tool.html">模型混淆工具</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">云侧推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/cloud_infer/runtime.html">基础推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/cloud_infer/runtime_parallel.html">并发推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/cloud_infer/runtime_distributed.html">分布式推理</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">云侧工具</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/cloud_infer/converter.html">模型转换工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/cloud_infer/benchmark.html">基准测试工具</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../architecture_lite.html">总体架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_lite.html">Lite算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_codegen.html">Codegen算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_lite.html">模型支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting_guide.html">问题定位指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../log.html">日志</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../device_train_example.html">端侧训练样例</a> &raquo;</li>
      <li>基于C++接口实现端侧训练</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/quick_start/train_lenet.md.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="基于c接口实现端侧训练">
<h1>基于C++接口实现端侧训练<a class="headerlink" href="#基于c接口实现端侧训练" title="永久链接至标题"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/lite/docs/source_zh_cn/quick_start/train_lenet.md"><img alt="查看源文件" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.svg" /></a></p>
<blockquote>
<div><p>注意：MindSpore已经统一端边云推理API，如您想继续使用MindSpore Lite独立API进行端侧训练，可以参考<a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/r1.3/quick_start/train_lenet.html">此文档</a>。</p>
</div></blockquote>
<section id="概述">
<h2>概述<a class="headerlink" href="#概述" title="永久链接至标题"></a></h2>
<p>本教程基于<a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/master/mindspore/lite/examples/train_lenet_cpp">LeNet训练示例代码</a>，演示在Android设备上训练一个LeNet。</p>
<p>端侧训练流程如下：</p>
<ol class="arabic simple">
<li><p>基于MindSpore构建训练模型，并导出<code class="docutils literal notranslate"><span class="pre">MindIR</span></code>模型文件。</p></li>
<li><p>使用MindSpore Lite <code class="docutils literal notranslate"><span class="pre">Converter</span></code>工具，将<code class="docutils literal notranslate"><span class="pre">MindIR</span></code>模型转为端侧<code class="docutils literal notranslate"><span class="pre">MS</span></code>模型。</p></li>
<li><p>调用MindSpore Lite训练API，加载端侧<code class="docutils literal notranslate"><span class="pre">MS</span></code>模型，执行训练。</p></li>
</ol>
<p>下面章节首先通过示例代码中集成好的脚本，帮你快速部署并执行示例，再详细讲解实现细节。</p>
</section>
<section id="准备">
<h2>准备<a class="headerlink" href="#准备" title="永久链接至标题"></a></h2>
<p>推荐使用Ubuntu 18.04 64位操作系统。</p>
<section id="环境要求">
<h3>环境要求<a class="headerlink" href="#环境要求" title="永久链接至标题"></a></h3>
<ul class="simple">
<li><p>系统环境：Linux x86_64，推荐使用Ubuntu 18.04.02LTS</p></li>
<li><p>软件依赖</p>
<ul>
<li><p><a class="reference external" href="https://gcc.gnu.org/releases.html">GCC</a> &gt;= 7.3.0</p></li>
<li><p><a class="reference external" href="https://cmake.org/download/">CMake</a> &gt;= 3.18.3</p></li>
<li><p><a class="reference external" href="https://git-scm.com/downloads">Git</a> &gt;= 2.28.0</p></li>
<li><p><a class="reference external" href="https://dl.google.com/android/repository/android-ndk-r20b-linux-x86_64.zip">Android_NDK</a> &gt;= r20</p>
<ul>
<li><p>配置环境变量：<code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">ANDROID_NDK=NDK路径</span></code></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="下载数据集">
<h3>下载数据集<a class="headerlink" href="#下载数据集" title="永久链接至标题"></a></h3>
<p>示例中的<code class="docutils literal notranslate"><span class="pre">MNIST</span></code>数据集由10类28*28的灰度图片组成，训练数据集包含60000张图片，测试数据集包含10000张图片。</p>
<blockquote>
<div><p>MNIST数据集官网下载地址：<a class="reference external" href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>，共4个下载链接，分别是训练数据、训练标签、测试数据和测试标签。</p>
</div></blockquote>
<p>下载并解压到本地，解压后的训练和测试集分别存放于<code class="docutils literal notranslate"><span class="pre">/PATH/MNIST_Data/train</span></code>和<code class="docutils literal notranslate"><span class="pre">/PATH/MNIST_Data/test</span></code>路径下。</p>
<p>目录结构如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./MNIST_Data/
├── test
│   ├── t10k-images-idx3-ubyte
│   └── t10k-labels-idx1-ubyte
└── train
    ├── train-images-idx3-ubyte
    └── train-labels-idx1-ubyte
</pre></div>
</div>
</section>
<section id="安装mindspore">
<h3>安装MindSpore<a class="headerlink" href="#安装mindspore" title="永久链接至标题"></a></h3>
<p>你可以通过<code class="docutils literal notranslate"><span class="pre">pip</span></code>或是源码的方式安装MindSpore，详见<a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_pip.md#">MindSpore官网安装教程</a>。</p>
</section>
<section id="下载并安装mindspore-lite">
<h3>下载并安装MindSpore Lite<a class="headerlink" href="#下载并安装mindspore-lite" title="永久链接至标题"></a></h3>
<p>通过<code class="docutils literal notranslate"><span class="pre">git</span></code>克隆源码，进入源码目录，<code class="docutils literal notranslate"><span class="pre">Linux</span></code>指令如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://gitee.com/mindspore/mindspore.git<span class="w"> </span>-b<span class="w"> </span><span class="o">{</span>version<span class="o">}</span>
<span class="nb">cd</span><span class="w"> </span>./mindspore
</pre></div>
</div>
<p>源码路径下的<code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/train_lenet_cpp</span></code>目录包含了本示例程序的源码。其中version和下文中<a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/master/use/downloads.html">MindSpore Lite下载页面</a>的version保持一致。如果-b 指定master，需要通过<a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/master/use/build.html">源码编译</a>的方式获取对应的安装包。</p>
<p>请到<a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/master/use/downloads.html">MindSpore Lite下载页面</a>下载mindspore-lite-{version}-linux-x64.tar.gz以及mindspore-lite-{version}-android-aarch64.tar.gz。其中，mindspore-lite-{version}-linux-x64.tar.gz是MindSpore Lite在x86平台的安装包，里面包含模型转换工具converter_lite，本示例用它来将MINDIR模型转换成MindSpore Lite支持的<code class="docutils literal notranslate"><span class="pre">.ms</span></code>格式；mindspore-lite-{version}-android-aarch64.tar.gz是MindSpore Lite在Android平台的安装包，里面包含训练运行时库libmindspore-lite.so，本示例用它所提供的接口在Android上训练模型。最后将文件放到MindSpore源码下的<code class="docutils literal notranslate"><span class="pre">output</span></code>目录（如果没有<code class="docutils literal notranslate"><span class="pre">output</span></code>目录，请创建它）。</p>
<p>假设下载的安装包存放在<code class="docutils literal notranslate"><span class="pre">/Downloads</span></code>目录，上述操作对应的<code class="docutils literal notranslate"><span class="pre">Linux</span></code>指令如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>output
cp<span class="w"> </span>/Downloads/mindspore-lite-<span class="o">{</span>version<span class="o">}</span>-linux-x64.tar.gz<span class="w"> </span>output/mindspore-lite-<span class="o">{</span>version<span class="o">}</span>-linux-x64.tar.gz
cp<span class="w"> </span>/Downloads/mindspore-lite-<span class="o">{</span>version<span class="o">}</span>-android-aarch64.tar.gz<span class="w"> </span>output/mindspore-lite-<span class="o">{</span>version<span class="o">}</span>-android-aarch64.tar.gz
</pre></div>
</div>
<p>您也可以通过<a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/master/use/build.html">源码编译</a>直接生成端侧训练框架对应的x86平台安装包mindspore-lite-{version}-linux-x64.tar.gz以及Android平台安装包mindspore-lite-{version}-android-aarch64.tar.gz，源码编译的安装包会自动生成在<code class="docutils literal notranslate"><span class="pre">output</span></code>目录下，请确保<code class="docutils literal notranslate"><span class="pre">output</span></code>目录下同时存在这两个安装包。</p>
</section>
<section id="连接安卓设备">
<h3>连接安卓设备<a class="headerlink" href="#连接安卓设备" title="永久链接至标题"></a></h3>
<p>准备好一台Android设备，并通过USB与工作电脑正确连接。手机需开启“USB调试模式”，华为手机一般在<code class="docutils literal notranslate"><span class="pre">设置-&gt;系统和更新-&gt;开发人员选项-&gt;USB调试</span></code>中打开“USB调试模式”。</p>
<p>本示例使用<a class="reference external" href="https://developer.android.google.cn/studio/command-line/adb">adb</a>工具与Android设备进行通信，在工作电脑上远程操控移动设备；如果没有安装<code class="docutils literal notranslate"><span class="pre">adb</span></code>工具，可以执行<code class="docutils literal notranslate"><span class="pre">apt</span> <span class="pre">install</span> <span class="pre">adb</span></code>安装。</p>
</section>
</section>
<section id="模型训练和验证">
<h2>模型训练和验证<a class="headerlink" href="#模型训练和验证" title="永久链接至标题"></a></h2>
<p>进入示例代码目录并执行训练脚本，<code class="docutils literal notranslate"><span class="pre">Linux</span></code>指令如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>mindspore/lite/examples/train_lenet_cpp
bash<span class="w"> </span>prepare_and_run.sh<span class="w"> </span>-D<span class="w"> </span>/PATH/MNIST_Data<span class="w"> </span>-t<span class="w"> </span>arm64
</pre></div>
</div>
<p>其中<code class="docutils literal notranslate"><span class="pre">/PATH/MNIST_Data</span></code>是你工作电脑上存放MNIST数据集的绝对路径，<code class="docutils literal notranslate"><span class="pre">-t</span> <span class="pre">arm64</span></code>为执行训练和推理的设备类型，如果工作电脑连接多台手机设备，可使用<code class="docutils literal notranslate"><span class="pre">-i</span> <span class="pre">devices_id</span></code>指定运行设备。</p>
<p><code class="docutils literal notranslate"><span class="pre">prepare_and_run.sh</span></code>脚本做了以下工作：</p>
<ol class="arabic simple">
<li><p>导出<code class="docutils literal notranslate"><span class="pre">lenet_tod.mindir</span></code>模型文件；</p></li>
<li><p>调用上节的模型转换工具将<code class="docutils literal notranslate"><span class="pre">lenet_tod.mindir</span></code>转换为<code class="docutils literal notranslate"><span class="pre">lenet_tod.ms</span></code>文件；</p></li>
<li><p>将<code class="docutils literal notranslate"><span class="pre">lenet_tod.ms</span></code>、MNIST数据集和相关依赖库文件推送至你的<code class="docutils literal notranslate"><span class="pre">Android</span></code>设备；</p></li>
<li><p>执行训练、保存并推理模型。</p></li>
</ol>
<p>Android设备上训练LeNet模型每轮会输出损失值和准确率；最后选择训练完成的模型执行推理，验证<code class="docutils literal notranslate"><span class="pre">MNIST</span></code>手写字识别精度。端侧训练LeNet模型10个epoch的结果如下所示（测试准确率会受设备差异的影响）：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>======Training Locally=========
1.100:  Loss is 1.19449
1.200:  Loss is 0.477986
1.300:  Loss is 0.440362
1.400:  Loss is 0.165605
1.500:  Loss is 0.368853
1.600:  Loss is 0.179764
1.700:  Loss is 0.173386
1.800:  Loss is 0.0767713
1.900:  Loss is 0.493
1.1000: Loss is 0.460352
1.1100: Loss is 0.262044
1.1200: Loss is 0.222022
1.1300: Loss is 0.058006
1.1400: Loss is 0.0794117
1.1500: Loss is 0.0241433
1.1600: Loss is 0.127109
1.1700: Loss is 0.0557566
1.1800: Loss is 0.0698758
Epoch (1):      Loss is 0.384778
Epoch (1):      Training Accuracy is 0.8702
2.100:  Loss is 0.0538642
2.200:  Loss is 0.444504
2.300:  Loss is 0.0806976
2.400:  Loss is 0.0495807
2.500:  Loss is 0.178903
2.600:  Loss is 0.265705
2.700:  Loss is 0.0933796
2.800:  Loss is 0.0880472
2.900:  Loss is 0.0480734
2.1000: Loss is 0.241272
2.1100: Loss is 0.0920451
2.1200: Loss is 0.371406
2.1300: Loss is 0.0365746
2.1400: Loss is 0.0784372
2.1500: Loss is 0.207537
2.1600: Loss is 0.442626
2.1700: Loss is 0.0814725
2.1800: Loss is 0.12081
Epoch (2):      Loss is 0.176118
Epoch (2):      Training Accuracy is 0.94415
......
10.1000:        Loss is 0.0984653
10.1100:        Loss is 0.189702
10.1200:        Loss is 0.0896037
10.1300:        Loss is 0.0138191
10.1400:        Loss is 0.0152357
10.1500:        Loss is 0.12785
10.1600:        Loss is 0.026495
10.1700:        Loss is 0.436495
10.1800:        Loss is 0.157564
Epoch (5):     Loss is 0.102652
Epoch (5):     Training Accuracy is 0.96805
AvgRunTime: 18980.5 ms
Total allocation: 125829120
Accuracy is 0.965244

===Evaluating trained Model=====
Total allocation: 20971520
Accuracy is 0.965244

===Running Inference Model=====
There are 1 input tensors with sizes:
tensor 0: shape is [32 32 32 1]
There are 1 output tensors with sizes:
tensor 0: shape is [32 10]
The predicted classes are:
4, 0, 2, 8, 9, 4, 5, 6, 3, 5, 2, 1, 4, 6, 8, 0, 5, 7, 3, 5, 8, 3, 4, 1, 9, 8, 7, 3, 0, 2, 3, 6,
</pre></div>
</div>
<blockquote>
<div><p>如果你没有Android设备，也可以执行<code class="docutils literal notranslate"><span class="pre">bash</span> <span class="pre">prepare_and_run.sh</span> <span class="pre">-D</span> <span class="pre">/PATH/MNIST_Data</span> <span class="pre">-t</span> <span class="pre">x86</span></code>直接在PC上运行本示例。</p>
</div></blockquote>
</section>
<section id="示例程序详解">
<h2>示例程序详解<a class="headerlink" href="#示例程序详解" title="永久链接至标题"></a></h2>
<section id="示例程序结构">
<h3>示例程序结构<a class="headerlink" href="#示例程序结构" title="永久链接至标题"></a></h3>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>train_lenet_cpp/
  ├── model
  │   ├── lenet_export.py
  │   ├── prepare_model.sh
  │   └── train_utils.py
  │
  ├── scripts
  │   ├── batch_of32.dat
  │   ├── eval.sh
  │   ├── infer.sh
  │   └── train.sh
  │
  ├── src
  │   ├── inference.cc
  │   ├── net_runner.cc
  │   ├── net_runner.h
  │   └── utils.h
  │
  ├── Makefile
  ├── README.md
  ├── README_CN.md
  └── prepare_and_run.sh
</pre></div>
</div>
</section>
<section id="定义并导出模型">
<h3>定义并导出模型<a class="headerlink" href="#定义并导出模型" title="永久链接至标题"></a></h3>
<p>首先我们需要基于MindSpore框架创建一个LeNet模型，本例中直接用MindSpore ModelZoo的现有<a class="reference external" href="https://gitee.com/mindspore/models/tree/master/research/cv/lenet">LeNet模型</a>。</p>
<blockquote>
<div><p>本小结使用MindSpore云侧功能导出，更多信息请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/index.html">MindSpore教程</a>。</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">lenet</span> <span class="kn">import</span> <span class="n">LeNet5</span>
<span class="kn">from</span> <span class="nn">train_utils</span> <span class="kn">import</span> <span class="n">TrainWrap</span>

<span class="n">n</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="n">n</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">,</span> <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>然后定义输入和标签张量大小：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">BATCH_SIZE</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">TrainWrap</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
<p>定义损失函数、网络可训练参数、优化器，并启用单步训练，由<code class="docutils literal notranslate"><span class="pre">TrainWrap</span></code>函数实现。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="k">def</span> <span class="nf">train_wrap</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    train_wrap</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">loss_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">loss_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">WithLossCell</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>
    <span class="n">loss_net</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">ParameterTuple</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
    <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.003</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">use_locking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">use_nesterov</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">4e-5</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">train_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">loss_net</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_net</span>
</pre></div>
</div>
<p>最后调用<code class="docutils literal notranslate"><span class="pre">export</span></code>接口将模型导出为<code class="docutils literal notranslate"><span class="pre">MindIR</span></code>文件保存（目前端侧训练仅支持<code class="docutils literal notranslate"><span class="pre">MindIR</span></code>格式）。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ms</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">&quot;lenet_tod&quot;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;MINDIR&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;finished exporting&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>如果输出<code class="docutils literal notranslate"><span class="pre">finished</span> <span class="pre">exporting</span></code>表示导出成功，生成的<code class="docutils literal notranslate"><span class="pre">lenet_tod.mindir</span></code>文件在<code class="docutils literal notranslate"><span class="pre">../train_lenet_cpp/model</span></code>目录下。完整代码参见<code class="docutils literal notranslate"><span class="pre">lenet_export.py</span></code>和<code class="docutils literal notranslate"><span class="pre">train_utils.py</span></code>。</p>
</section>
<section id="转换模型">
<h3>转换模型<a class="headerlink" href="#转换模型" title="永久链接至标题"></a></h3>
<p>在<code class="docutils literal notranslate"><span class="pre">prepare_model.sh</span></code>中使用MindSpore Lite <code class="docutils literal notranslate"><span class="pre">converter_lite</span></code>工具将<code class="docutils literal notranslate"><span class="pre">lenet_tod.mindir</span></code>转换为<code class="docutils literal notranslate"><span class="pre">ms</span></code>模型文件，执行指令如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite<span class="w"> </span>--fmk<span class="o">=</span>MINDIR<span class="w"> </span>--trainModel<span class="o">=</span><span class="nb">true</span><span class="w"> </span>--modelFile<span class="o">=</span>lenet_tod.mindir<span class="w"> </span>--outputFile<span class="o">=</span>lenet_tod
</pre></div>
</div>
<p>转换成功后，当前目录下会生成<code class="docutils literal notranslate"><span class="pre">lenet_tod.ms</span></code>模型文件。</p>
<blockquote>
<div><p>更多用法参见<a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/master/use/converter_train.html">训练模型转换</a>。</p>
</div></blockquote>
</section>
<section id="训练模型">
<h3>训练模型<a class="headerlink" href="#训练模型" title="永久链接至标题"></a></h3>
<p>模型训练的处理详细流程请参考<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/master/mindspore/lite/examples/train_lenet_cpp/src/net_runner.cc">net_runner.cc源码</a>。</p>
<p>模型训练的主函数为：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">NetRunner::Main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Load model and create session</span>
<span class="w">  </span><span class="n">InitAndFigureInputs</span><span class="p">();</span>
<span class="w">  </span><span class="c1">// initialize the dataset</span>
<span class="w">  </span><span class="n">InitDB</span><span class="p">();</span>
<span class="w">  </span><span class="c1">// Execute the training</span>
<span class="w">  </span><span class="n">TrainLoop</span><span class="p">();</span>
<span class="w">  </span><span class="c1">// Evaluate the trained model</span>
<span class="w">  </span><span class="n">CalculateAccuracy</span><span class="p">();</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">epochs_</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">trained_fn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ms_file_</span><span class="p">.</span><span class="n">substr</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">ms_file_</span><span class="p">.</span><span class="n">find_last_of</span><span class="p">(</span><span class="sc">&#39;.&#39;</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s">&quot;_trained.ms&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Serialization</span><span class="o">::</span><span class="n">ExportModel</span><span class="p">(</span><span class="o">*</span><span class="n">model_</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kMindIR</span><span class="p">,</span><span class="w"> </span><span class="n">trained_fn</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kNoQuant</span><span class="p">,</span><span class="w"> </span><span class="nb">false</span><span class="p">);</span>
<span class="w">    </span><span class="n">trained_fn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ms_file_</span><span class="p">.</span><span class="n">substr</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">ms_file_</span><span class="p">.</span><span class="n">find_last_of</span><span class="p">(</span><span class="sc">&#39;.&#39;</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s">&quot;_infer.ms&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Serialization</span><span class="o">::</span><span class="n">ExportModel</span><span class="p">(</span><span class="o">*</span><span class="n">model_</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kMindIR</span><span class="p">,</span><span class="w"> </span><span class="n">trained_fn</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kNoQuant</span><span class="p">,</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<ol class="arabic">
<li><p>加载模型</p>
<p><code class="docutils literal notranslate"><span class="pre">InitAndFigureInputs</span></code>函数加载转换后的<code class="docutils literal notranslate"><span class="pre">MS</span></code>模型文件，调用<code class="docutils literal notranslate"><span class="pre">Graph</span></code>接口创建<code class="docutils literal notranslate"><span class="pre">graph_</span></code>实例(下述代码中的<code class="docutils literal notranslate"><span class="pre">ms_file_</span></code>就是转换模型阶段生成的<code class="docutils literal notranslate"><span class="pre">lenet_tod.ms</span></code>模型)。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">NetRunner::InitAndFigureInputs</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">Context</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">cpu_context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">CPUDeviceInfo</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">  </span><span class="n">cpu_context</span><span class="o">-&gt;</span><span class="n">SetEnableFP16</span><span class="p">(</span><span class="n">enable_fp16_</span><span class="p">);</span>
<span class="w">  </span><span class="n">context</span><span class="o">-&gt;</span><span class="n">MutableDeviceInfo</span><span class="p">().</span><span class="n">push_back</span><span class="p">(</span><span class="n">cpu_context</span><span class="p">);</span>

<span class="w">  </span><span class="n">graph_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Graph</span><span class="p">();</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Serialization</span><span class="o">::</span><span class="n">Load</span><span class="p">(</span><span class="n">ms_file_</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kMindIR</span><span class="p">,</span><span class="w"> </span><span class="n">graph_</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">status</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Error &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">status</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; during serialization of graph &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">ms_file_</span><span class="p">;</span>
<span class="w">    </span><span class="n">MS_ASSERT</span><span class="p">(</span><span class="n">status</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kSuccess</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">cfg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">TrainCfg</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">enable_fp16_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cfg</span><span class="p">.</span><span class="n">get</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">optimization_level_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kO2</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">model_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Model</span><span class="p">();</span>
<span class="w">  </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_</span><span class="o">-&gt;</span><span class="n">Build</span><span class="p">(</span><span class="n">mindspore</span><span class="o">::</span><span class="n">GraphCell</span><span class="p">(</span><span class="o">*</span><span class="n">graph_</span><span class="p">),</span><span class="w"> </span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">cfg</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">status</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Error &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">status</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; during build of model &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">ms_file_</span><span class="p">;</span>
<span class="w">    </span><span class="n">MS_ASSERT</span><span class="p">(</span><span class="n">status</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kSuccess</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">acc_metrics_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">AccuracyMetrics</span><span class="o">&gt;</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">AccuracyMetrics</span><span class="p">);</span>
<span class="w">  </span><span class="n">model_</span><span class="o">-&gt;</span><span class="n">InitMetrics</span><span class="p">({</span><span class="n">acc_metrics_</span><span class="p">.</span><span class="n">get</span><span class="p">()});</span>

<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_</span><span class="o">-&gt;</span><span class="n">GetInputs</span><span class="p">();</span>
<span class="w">  </span><span class="n">MS_ASSERT</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">nhwc_input_dims</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputs</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">Shape</span><span class="p">();</span>

<span class="w">  </span><span class="n">batch_size_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nhwc_input_dims</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">h_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nhwc_input_dims</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="w">  </span><span class="n">w_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nhwc_input_dims</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>数据集处理</p>
<p><code class="docutils literal notranslate"><span class="pre">InitDB</span></code>函数预处理<code class="docutils literal notranslate"><span class="pre">MNIST</span></code>数据集并加载至内存。MindData提供了数据预处理API，用户可参见<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/master/api_cpp/mindspore_dataset.html">C++ API 说明文档</a> 获取更多详细信息。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">NetRunner::InitDB</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">train_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Mnist</span><span class="p">(</span><span class="n">data_dir_</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s">&quot;/train&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;all&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">SequentialSampler</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">));</span>

<span class="w">  </span><span class="n">TypeCast</span><span class="w"> </span><span class="n">typecast_f</span><span class="p">(</span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat32</span><span class="p">);</span>
<span class="w">  </span><span class="n">Resize</span><span class="w"> </span><span class="n">resize</span><span class="p">({</span><span class="n">h_</span><span class="p">,</span><span class="w"> </span><span class="n">w_</span><span class="p">});</span>
<span class="w">  </span><span class="n">train_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_ds_</span><span class="o">-&gt;</span><span class="n">Map</span><span class="p">({</span><span class="o">&amp;</span><span class="n">resize</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">typecast_f</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="s">&quot;image&quot;</span><span class="p">});</span>

<span class="w">  </span><span class="n">TypeCast</span><span class="w"> </span><span class="n">typecast</span><span class="p">(</span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeInt32</span><span class="p">);</span>
<span class="w">  </span><span class="n">train_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_ds_</span><span class="o">-&gt;</span><span class="n">Map</span><span class="p">({</span><span class="o">&amp;</span><span class="n">typecast</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="s">&quot;label&quot;</span><span class="p">});</span>

<span class="w">  </span><span class="n">train_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_ds_</span><span class="o">-&gt;</span><span class="n">Batch</span><span class="p">(</span><span class="n">batch_size_</span><span class="p">,</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">verbose_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;DatasetSize is &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">train_ds_</span><span class="o">-&gt;</span><span class="n">GetDatasetSize</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">train_ds_</span><span class="o">-&gt;</span><span class="n">GetDatasetSize</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;No relevant data was found in &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">data_dir_</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="n">MS_ASSERT</span><span class="p">(</span><span class="n">train_ds_</span><span class="o">-&gt;</span><span class="n">GetDatasetSize</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>执行训练</p>
<p>首先创建训练回调类对象（例如<code class="docutils literal notranslate"><span class="pre">LRScheduler</span></code>、<code class="docutils literal notranslate"><span class="pre">LossMonitor</span></code>、<code class="docutils literal notranslate"><span class="pre">TrainAccuracy</span></code>和<code class="docutils literal notranslate"><span class="pre">CkptSaver</span></code>）数组指针；然后调用<code class="docutils literal notranslate"><span class="pre">TrainLoop</span></code>类的<code class="docutils literal notranslate"><span class="pre">Train</span></code>函数，将模型设置为训练模式；最后在训练过程中遍历执行回调类对象对应的函数并输出训练日志。<code class="docutils literal notranslate"><span class="pre">CkptSaver</span></code>会根据设定训练步长数值为当前会话保存<code class="docutils literal notranslate"><span class="pre">CheckPoint</span></code>模型，<code class="docutils literal notranslate"><span class="pre">CheckPoint</span></code>模型包含已更新的权重，在应用崩溃或设备出现故障时可以直接加载<code class="docutils literal notranslate"><span class="pre">CheckPoint</span></code>模型，继续开始训练。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">NetRunner::TrainLoop</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">mindspore</span><span class="o">::</span><span class="n">LossMonitor</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="mi">100</span><span class="p">);</span>
<span class="w">  </span><span class="n">mindspore</span><span class="o">::</span><span class="n">TrainAccuracy</span><span class="w"> </span><span class="n">am</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>

<span class="w">  </span><span class="n">mindspore</span><span class="o">::</span><span class="n">CkptSaver</span><span class="w"> </span><span class="n">cs</span><span class="p">(</span><span class="n">kSaveEpochs</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="s">&quot;lenet&quot;</span><span class="p">));</span>
<span class="w">  </span><span class="n">Rescaler</span><span class="w"> </span><span class="n">rescale</span><span class="p">(</span><span class="n">kScalePoint</span><span class="p">);</span>
<span class="w">  </span><span class="n">Measurement</span><span class="w"> </span><span class="n">measure</span><span class="p">(</span><span class="n">epochs_</span><span class="p">);</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">virtual_batch_</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">model_</span><span class="o">-&gt;</span><span class="n">Train</span><span class="p">(</span><span class="n">epochs_</span><span class="p">,</span><span class="w"> </span><span class="n">train_ds_</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="o">&amp;</span><span class="n">rescale</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lm</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cs</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">measure</span><span class="p">});</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">mindspore</span><span class="o">::</span><span class="n">StepLRLambda</span><span class="w"> </span><span class="n">step_lr_lambda</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">kGammaFactor</span><span class="p">);</span>
<span class="w">    </span><span class="n">mindspore</span><span class="o">::</span><span class="n">LRScheduler</span><span class="w"> </span><span class="n">step_lr_sched</span><span class="p">(</span><span class="n">mindspore</span><span class="o">::</span><span class="n">StepLRLambda</span><span class="p">,</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">void</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">step_lr_lambda</span><span class="p">),</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">    </span><span class="n">model_</span><span class="o">-&gt;</span><span class="n">Train</span><span class="p">(</span><span class="n">epochs_</span><span class="p">,</span><span class="w"> </span><span class="n">train_ds_</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="o">&amp;</span><span class="n">rescale</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lm</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cs</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">am</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">step_lr_sched</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">measure</span><span class="p">});</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>验证精度</p>
<p>训练结束后调用<code class="docutils literal notranslate"><span class="pre">CalculateAccuracy</span></code>评估模型精度。该函数调用<code class="docutils literal notranslate"><span class="pre">AccuracyMetrics</span></code>的<code class="docutils literal notranslate"><span class="pre">Eval</span></code>方法，将模型设置为推理模式。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">float</span><span class="w"> </span><span class="nf">NetRunner::CalculateAccuracy</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">max_tests</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">test_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Mnist</span><span class="p">(</span><span class="n">data_dir_</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s">&quot;/test&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;all&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="n">TypeCast</span><span class="w"> </span><span class="n">typecast_f</span><span class="p">(</span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat32</span><span class="p">);</span>
<span class="w">  </span><span class="n">Resize</span><span class="w"> </span><span class="n">resize</span><span class="p">({</span><span class="n">h_</span><span class="p">,</span><span class="w"> </span><span class="n">w_</span><span class="p">});</span>
<span class="w">  </span><span class="n">test_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_ds_</span><span class="o">-&gt;</span><span class="n">Map</span><span class="p">({</span><span class="o">&amp;</span><span class="n">resize</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">typecast_f</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="s">&quot;image&quot;</span><span class="p">});</span>

<span class="w">  </span><span class="n">TypeCast</span><span class="w"> </span><span class="n">typecast</span><span class="p">(</span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeInt32</span><span class="p">);</span>
<span class="w">  </span><span class="n">test_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_ds_</span><span class="o">-&gt;</span><span class="n">Map</span><span class="p">({</span><span class="o">&amp;</span><span class="n">typecast</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="s">&quot;label&quot;</span><span class="p">});</span>
<span class="w">  </span><span class="n">test_ds_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_ds_</span><span class="o">-&gt;</span><span class="n">Batch</span><span class="p">(</span><span class="n">batch_size_</span><span class="p">,</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span>

<span class="w">  </span><span class="n">model_</span><span class="o">-&gt;</span><span class="n">Evaluate</span><span class="p">(</span><span class="n">test_ds_</span><span class="p">,</span><span class="w"> </span><span class="p">{});</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Accuracy is &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">acc_metrics_</span><span class="o">-&gt;</span><span class="n">Eval</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../device_train_example.html" class="btn btn-neutral float-left" title="端侧训练样例" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="train_lenet_java.html" class="btn btn-neutral float-right" title="基于Java接口实现端侧训练" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 MindSpore.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>