

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Ascend转换工具功能说明 &mdash; MindSpore Lite master 文档</title>
  

  
  <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/lite.css" type="text/css" />
   
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script src="../../_static/js/lite.js"></script>
        <script src="../../_static/translations.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="基准测试工具" href="benchmark.html" />
    <link rel="prev" title="使用Python接口模型转换" href="converter_python.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore Lite
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">获取MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../downloads.html">下载MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../build.html">编译端侧MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="build.html">编译云侧MindSpore Lite</a></li>
</ul>
<p class="caption"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../quick_start/one_hour_introduction.html">端侧推理快速入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quick_start/one_hour_introduction_cloud.html">云侧推理快速入门</a></li>
</ul>
<p class="caption"><span class="caption-text">端侧推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../device_infer_example.html">端侧推理样例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../post_training_quantization.html">训练后量化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data_preprocessing.html">预处理数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="../runtime.html">执行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../micro.html">在MCU或小型系统上执行推理或训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asic.html">专用芯片集成说明</a></li>
</ul>
<p class="caption"><span class="caption-text">端侧训练</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../device_train_example.html">端侧训练样例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../runtime_train.html">执行训练</a></li>
</ul>
<p class="caption"><span class="caption-text">端侧第三方接入</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../register.html">自定义算子</a></li>
<li class="toctree-l1"><a class="reference internal" href="../delegate.html">使用Delegate支持第三方AI框架接入</a></li>
</ul>
<p class="caption"><span class="caption-text">端侧工具</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../converter.html">模型转换工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark.html">基准测试工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cropper_tool.html">静态库裁剪工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../visual_tool.html">可视化工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../obfuscator_tool.html">模型混淆工具</a></li>
</ul>
<p class="caption"><span class="caption-text">云侧推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">执行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime_parallel.html">执行并发推理</a></li>
</ul>
<p class="caption"><span class="caption-text">云侧工具</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="converter.html">模型转换工具</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="converter_tool.html">推理模型离线转换</a></li>
<li class="toctree-l2"><a class="reference internal" href="converter_python.html">使用Python接口模型转换</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Ascend转换工具功能说明</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#概述">概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#配置文件">配置文件</a></li>
<li class="toctree-l3"><a class="reference internal" href="#动态shape配置">动态shape配置</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#动态batch-size">动态Batch size</a></li>
<li class="toctree-l4"><a class="reference internal" href="#动态分辨率">动态分辨率</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#aoe自动调优">AOE自动调优</a></li>
<li class="toctree-l3"><a class="reference internal" href="#部署ascend自定义算子">部署Ascend自定义算子</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">基准测试工具</a></li>
</ul>
<p class="caption"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../architecture_lite.html">总体架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../operator_list_lite.html">Lite算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../operator_list_codegen.html">Codegen算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_lite.html">模型支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../troubleshooting_guide.html">问题定位指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../log.html">日志</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore Lite</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="converter.html">模型转换工具</a> &raquo;</li>
        
      <li>Ascend转换工具功能说明</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/use/cloud_infer/converter_tool_ascend.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="ascend转换工具功能说明">
<h1>Ascend转换工具功能说明<a class="headerlink" href="#ascend转换工具功能说明" title="永久链接至标题">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/master/docs/lite/docs/source_zh_cn/use/cloud_infer/converter_tool_ascend.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.png"></a></p>
<div class="section" id="概述">
<h2>概述<a class="headerlink" href="#概述" title="永久链接至标题">¶</a></h2>
<p>本文档介绍云侧推理模型转换工具在Ascend后端的相关功能，如配置文件的选项、动态shape、AOE、自定义算子等。</p>
</div>
<div class="section" id="配置文件">
<h2>配置文件<a class="headerlink" href="#配置文件" title="永久链接至标题">¶</a></h2>
<p>表1：配置[ascend_context]参数</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>参数</th>
<th>属性</th>
<th>功能描述</th>
<th>参数类型</th>
<th>取值说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>input_format</code></td>
<td>可选</td>
<td>指定模型输入format。</td>
<td>String</td>
<td>可选有<code>"NCHW"</code>、<code>"NHWC"</code>、<code>"ND"</code></td>
</tr>
<tr>
<td><code>input_shape</code></td>
<td>可选</td>
<td>指定模型输入Shape，input_name必须是转换前的网络模型中的输入名称，按输入次序排列，用<code>；</code>隔开。</td>
<td>String</td>
<td>例如：<code>"input1:[1,64,64,3];input2:[1,256,256,3]"</code></td>
</tr>
<tr>
<td><code>dynamic_dims</code></td>
<td>可选</td>
<td>指定动态BatchSize和动态分辨率参数。</td>
<td>String</td>
<td>见<a href="#动态shape配置">动态shape配置</a></td>
</tr>
<tr>
<td><code>precision_mode</code></td>
<td>可选</td>
<td>配置模型精度模式。</td>
<td>String</td>
<td>可选有<code>"enforce_fp32"</code>，<code>"preferred_fp32"</code>，<code>"enforce_fp16"</code>，<code>"enforce_origin"</code>或者<code>"preferred_optimal"</code>，默认为<code>"enforce_fp16"</code></td>
</tr>
<tr>
<td><code>op_select_impl_mode</code></td>
<td>可选</td>
<td>配置算子选择模式。</td>
<td>String</td>
<td>可选有<code>"high_performance"</code>和<code>"high_precision"</code>，默认为<code>"high_performance"</code></td>
</tr>
<tr>
<td><code>output_type</code></td>
<td>可选</td>
<td>指定网络输出数据类型。</td>
<td>String</td>
<td>可选有<code>"FP16"</code>、<code>"FP32"</code>、<code>"UINT8"</code></td>
</tr>
<tr>
<td><code>fusion_switch_config_file_path</code></td>
<td>可选</td>
<td>配置<a href="https://www.hiascend.com/document/detail/zh/canncommercial/601/inferapplicationdev/atctool/atctool_0078.html">融合规则开关配置</a>文件路径及文件名。</td>
<td>String</td>
<td>指定融合规则开关的配置文件</td>
</tr>
<tr>
<td><code>insert_op_config_file_path</code></td>
<td>可选</td>
<td>模型插入<a href="https://www.hiascend.com/document/detail/zh/canncommercial/601/inferapplicationdev/atctool/atctool_0018.html">AIPP</a>算子</td>
<td>String</td>
<td><a href="https://www.hiascend.com/document/detail/zh/canncommercial/601/inferapplicationdev/atctool/atctool_0021.html">AIPP</a>配置文件路径</td>
</tr>
<tr>
<td><code>aoe_mode</code></td>
<td>可选</td>
<td><a href="https://www.hiascend.com/document/detail/zh/canncommercial/601/devtools/auxiliarydevtool/aoe_16_001.html">AOE</a>自动调优模式</td>
<td>String</td>
<td>可选有"subgraph turing"、"operator turing"或者"subgraph turing、operator turing"，默认不使能</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="动态shape配置">
<h2>动态shape配置<a class="headerlink" href="#动态shape配置" title="永久链接至标题">¶</a></h2>
<p>在某些推理场景，如检测出目标后再执行目标识别网络，由于目标个数不固定导致目标识别网络输入BatchSize不固定。如果每次推理都按照最大的BatchSize或最大分辨率进行计算，会造成计算资源浪费。因此，推理需要支持动态BatchSize和动态分辨率的场景，Lite在Ascend上推理支持动态BatchSize和动态分辨率场景，在convert阶段通过congFile配置[ascend_context]中dynamic_dims动态参数，推理时使用model的<a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/master/use/cloud_infer/runtime_cpp.html#%E5%8A%A8%E6%80%81shape%E8%BE%93%E5%85%A5">Resize</a>功能，改变输入shape。</p>
<div class="section" id="动态batch-size">
<h3>动态Batch size<a class="headerlink" href="#动态batch-size" title="永久链接至标题">¶</a></h3>
<ul>
<li><p>参数名</p>
<p>dynamic_dims</p>
</li>
<li><p>功能</p>
<p>设置动态batch档位参数，适用于执行推理时，每次处理图片数量不固定的场景，该参数需要与input_shape配合使用，input_shape中-1的位置为动态batch所在的维度。</p>
</li>
<li><p>取值</p>
<p>最多支持100档配置，每一档通过英文逗号分隔，每个档位数值限制为：[1~2048]。例如配置文件中参数配置如下：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">ascend_context</span><span class="p">]</span>
<span class="n">input_shape</span><span class="o">=</span><span class="nb">input</span><span class="p">:[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>
<span class="n">dynamic_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
<p>其中，input_shape中的”-1”表示设置动态batch，档位可取值为”1,2”，即支持档位0：[1,64,64,3]，档位1：[2,64,64,3]。</p>
<p>若存在多个输入，不同输入对应的挡位需要一致，并用<code class="docutils literal notranslate"><span class="pre">;</span></code>隔开。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">ascend_context</span><span class="p">]</span>
<span class="n">input_shape</span><span class="o">=</span><span class="n">input1</span><span class="p">:[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">3</span><span class="p">];</span><span class="n">input2</span><span class="p">:[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>
<span class="n">dynamic_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">2</span><span class="p">];[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</li>
<li><p>converter</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite<span class="w"> </span>--fmk<span class="o">=</span>ONNX<span class="w"> </span>--modelFile<span class="o">=</span><span class="si">${</span><span class="nv">model_name</span><span class="si">}</span>.onnx<span class="w"> </span>--configFile<span class="o">=</span>./config.txt<span class="w"> </span>--optimize<span class="o">=</span>ascend_oriented<span class="w"> </span>--outputFile<span class="o">=</span><span class="si">${</span><span class="nv">model_name</span><span class="si">}</span>
</pre></div>
</div>
<p>说明：使能动态BatchSize时，不需要指定inputShape参数，仅需要通过configFile配置[ascend_context]动态batch size，即上节示例中配置内容。</p>
</li>
<li><p>推理</p>
<p>使能动态BatchSize，进行模型推理时，输入shape只能选择converter时设置的档位值，想切换到其他档位对应的输入shape，使用model <a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/master/use/cloud_infer/runtime_cpp.html#%E5%8A%A8%E6%80%81shape%E8%BE%93%E5%85%A5">Resize</a>功能。</p>
</li>
<li><p>注意事项</p>
<p>1）若用户执行推理业务时，每次处理的图片数量不固定，则可以通过配置该参数来动态分配每次处理的图片数量。例如用户执行推理业务时需要每次处理2张，4张，8张图片，则可以配置为2,4,8，申请了档位后，模型推理时会根据实际档位申请内存。<br/>
2）如果用户设置的档位数值过大或档位过多，可能会导致模型编译失败，此时建议用户减少档位或调低档位数值。<br/>
3）如果用户设置的档位数值过大或档位过多，在运行环境执行推理时，建议执行swapoff -a命令关闭swap交换区间作为内存的功能，防止出现由于内存不足，将swap交换空间作为内存继续调用，导致运行环境异常缓慢的情况。<br/></p>
</li>
</ul>
</div>
<div class="section" id="动态分辨率">
<h3>动态分辨率<a class="headerlink" href="#动态分辨率" title="永久链接至标题">¶</a></h3>
<ul>
<li><p>参数名</p>
<p>dynamic_dims</p>
</li>
<li><p>功能</p>
<p>设置输入图片的动态分辨率参数。适用于执行推理时，每次处理图片宽和高不固定的场景，该参数需要与input_shape配合使用，input_shape中-1的位置为动态分辨率所在的维度。</p>
</li>
<li><p>取值</p>
<p>最多支持100档配置，每一档通过英文逗号分隔。例如： “[imagesize1_height,imagesize1_width],[imagesize2_height,imagesize2_width]”。例如配置文件中参数配置如下：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">ascend_context</span><span class="p">]</span>
<span class="n">input_format</span><span class="o">=</span><span class="n">NHWC</span>
<span class="n">input_shape</span><span class="o">=</span><span class="nb">input</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>
<span class="n">dynamic_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">],[</span><span class="mi">19200</span><span class="p">,</span><span class="mi">960</span><span class="p">]</span>
</pre></div>
</div>
<p>其中，input_shape中的”-1”表示设置动态分辨率，即支持档位0：[1,64,64,3]，档位1：[1,19200,960,3]。</p>
</li>
<li><p>converter</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite<span class="w"> </span>--fmk<span class="o">=</span>ONNX<span class="w"> </span>--modelFile<span class="o">=</span><span class="si">${</span><span class="nv">model_name</span><span class="si">}</span>.onnx<span class="w"> </span>--configFile<span class="o">=</span>./config.txt<span class="w"> </span>--optimize<span class="o">=</span>ascend_oriented<span class="w"> </span>--outputFile<span class="o">=</span><span class="si">${</span><span class="nv">model_name</span><span class="si">}</span>
</pre></div>
</div>
<p>说明：使能动态BatchSize时，不需要指定inputShape参数，仅需要通过configFile配置[ascend_context]动态分辨率，即上节示例中配置内容。</p>
</li>
<li><p>推理</p>
<p>使能动态分辨率，进行模型推理时，输入shape只能选择converter时设置的档位值，想切换到其他档位对应的输入shape，使用model的<a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/master/use/cloud_infer/runtime_cpp.html#%E5%8A%A8%E6%80%81shape%E8%BE%93%E5%85%A5">Resize</a>功能。</p>
</li>
<li><p>注意事项</p>
<p>1）如果用户设置的分辨率数值过大或档位过多，可能会导致模型编译失败，此时建议用户减少档位或调低档位数值。<br/>
2）如果用户设置了动态分辨率，实际推理时，使用的数据集图片大小需要与具体使用的分辨率相匹配。<br/>
3）如果用户设置的分辨率数值过大或档位过多，在运行环境执行推理时，建议执行swapoff -a命令关闭swap交换区间作为内存的功能，防止出现由于内存不足，将swap交换空间作为内存继续调用，导致运行环境异常缓慢的情况。<br/></p>
</li>
</ul>
</div>
</div>
<div class="section" id="aoe自动调优">
<h2>AOE自动调优<a class="headerlink" href="#aoe自动调优" title="永久链接至标题">¶</a></h2>
<p>AOE是一款专门为Davinci平台打造的计算图形性能自动调优工具。Lite使能AOE的能力，是在converter阶段集成AOE离线可执行程序，对图进行性能调优，生成知识库，并保存离线模型。该功能支持子图调优和算子调优。具体使用流程如下：</p>
<ol>
<li><p>配置环境变量</p>
<p><code class="docutils literal notranslate"><span class="pre">${LOCAL_ASCEND}</span></code>为昇腾软件包安装所在路径</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">LOCAL_ASCEND</span><span class="o">=</span>/usr/local/Ascend
<span class="nb">source</span><span class="w"> </span><span class="si">${</span><span class="nv">LOCAL_ASCEND</span><span class="si">}</span>/latest/bin/setenv.bash
</pre></div>
</div>
<p>确认环境中AOE可执行程序可被找到并运行：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>aoe<span class="w"> </span>-h
</pre></div>
</div>
</li>
<li><p>指定知识库路径</p>
<p>AOE调优会生成算子知识库，默认的路径为</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="si">${</span><span class="nv">HOME</span><span class="si">}</span>/Ascend/latest/data/aoe/custom/graph<span class="o">(</span>op<span class="o">)</span>/<span class="si">${</span><span class="nv">soc_version</span><span class="si">}</span>
</pre></div>
</div>
<p>（可选）也可通过<code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">TUNE_BANK_PATH</span></code>环境变量来自定义知识库路径。</p>
</li>
<li><p>清除缓存</p>
<p>为了模型编译能命中AOE生成的知识库，在使能AOE之前，最好先删除编译缓存，以免缓存复用，以昇腾310P环境，用户为root为例，删除<code class="docutils literal notranslate"><span class="pre">/root/atc_data/kernel_cache/Ascend310P3</span></code>和<code class="docutils literal notranslate"><span class="pre">/root/atc_data/fuzzy_kernel_cache/Ascend310P3</span></code>目录。</p>
</li>
<li><p>配置文件指定选项</p>
<p>在转换工具config配置文件中<code class="docutils literal notranslate"><span class="pre">[ascend_context]</span></code>指定AOE调优模式，如下举例中，会先执行子图调优，再执行算子调优。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>ascend_context<span class="o">]</span>
<span class="nv">aoe_mode</span><span class="o">=</span><span class="s2">&quot;subgraph tuning, operator tuning&quot;</span>
</pre></div>
</div>
</li>
</ol>
<blockquote>
<div><ul class="simple">
<li><p>性能提升结果会因不同环境存在差异，实际时延减少百分比不完全等同于调优日志中所展示的结果。</p></li>
<li><p>AOE调优会在执行任务的当前目录下产生<code class="docutils literal notranslate"><span class="pre">aoe_workspace</span></code>目录，用于保存调优前后的模型，用于性能提升对比，以及调优所必须的过程数据和结果文件。该目录会占用额外磁盘空间，如500MB左右的原始模型会占用2~10GB的磁盘空间，视模型大小，算子种类结构，输入shape的大小等因素浮动。因此建议预留足够的磁盘空间，否则可能导致调优失败。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">aoe_workspace</span></code>目录需要手动删除来释放磁盘空间。</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="部署ascend自定义算子">
<h2>部署Ascend自定义算子<a class="headerlink" href="#部署ascend自定义算子" title="永久链接至标题">¶</a></h2>
<p>MindSpore Lite converter支持将带有MindSpore Lite自定义Ascend算子的模型转换为MindSpore Lite的模型，通过自定义算子，可以在特殊场景下使用自定义算子对模型推理性能进行优化，如使用自定义的MatMul实现更高的矩阵乘法计算，使用MindSpore Lite提供的transformer融合算子提升transformer模型性能（待上线）以及使用AKG图算融合算子对模型进行自动融合优化提升推理性能等。</p>
<p>如果MindSpore Lite转换Ascend模型时有自定义算子，用户需要在调用converter之前部署自定义算子到ACL的算子库中才能正常完成转换，以下描述了部署Ascend自定义算子的关键步骤：</p>
<ol>
<li><p>配置环境变量</p>
<p><code class="docutils literal notranslate"><span class="pre">${ASCEND_OPP_PATH}</span></code>为昇腾软件CANN包的算子库路径，通常是在昇腾软件安装路径下，默认一般是<code class="docutils literal notranslate"><span class="pre">/usr/local/Ascend/latest/opp</span></code>。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">ASCEND_OPP_PATH</span><span class="o">=</span>/usr/local/Ascend/latest/opp
</pre></div>
</div>
</li>
<li><p>获取Ascend自定义算子包</p>
<p>Mindspore Lite云侧推理包中会包含Ascend自定义算子包目录，其相对目录为<code class="docutils literal notranslate"><span class="pre">${LITE_PACKAGE_PATH}/tools/custom_kernels/ascend</span></code>，解压MindSpore Lite云侧推理包后，进入对应目录。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tar<span class="w"> </span>zxf<span class="w"> </span>mindspore-lite-<span class="o">{</span>version<span class="o">}</span>-linux-<span class="o">{</span>arch<span class="o">}</span>.tar.gz
<span class="nb">cd</span><span class="w"> </span>tools/custom_kernels/ascend
</pre></div>
</div>
</li>
<li><p>运行install.sh脚本部署自定义算子</p>
<p>在算子包目录下运行安装脚本部署自定义算子。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>install.sh
</pre></div>
</div>
</li>
<li><p>查看昇腾算子库目录检查是否安装成功</p>
<p>完成部署自定义算子之后，进入昇腾算子库目录<code class="docutils literal notranslate"><span class="pre">/usr/local/Ascend/latest/opp/vendors/</span></code>，查看其下目录是否有对应的自定义算子文件，当前主要提供了基本算子样例和AKG图算融合算子实现，具体文件结构如下。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>/usr/local/Ascend/latest/opp/vendors/
├── config.ini                                                     # 自定义算子vendor配置文件，定义不同vendor间优先级，需要有mslite的vendor配置
└── mslite                                                         # mslite提供的自定义算子目录
    ├── framework                                                  # 第三方框架适配配置
    │    └── tensorflow                                            # tensorflow适配配置，非必需
    │       └── npu_supported_ops.json
    ├── op_impl                                                    # 自定义算子实现目录
    │   ├── ai_core                                                # 运行在ai_core的算子实现目录
    │   │   └── tbe                                                # tbe算子实现目录
    │   │       ├── config                                         # 不同芯片的算子配置
    │   │       │   ├── ascend310                                  # 310芯片的算子配置
    │   │       │       └── aic_ascend310-ops-info.json
    │   │       │   ├── ascend310p                                 # 310p芯片的算子配置
    │   │       │       └── aic_ascend310p-ops-info.json
    │   │       │   ├── ascend910                                  # 910芯片的算子配置
    │   │       │       └── aic_ascend910-ops-info.json
    │   │       └── mslite_impl                                    # 算子的实现逻辑目录
    │   │           ├── add_dsl.py                                 # 基于dsl开发的add样例逻辑实现文件
    │   │           ├── add_tik.py                                 # 基于tik开发的add样例逻辑实现文件
    │   │           ├── compiler.py                                # akg图算需要的算子编译逻辑文件
    │   │           ├── custom.py                                  # akg自定义算子实现文件
    │   │           ├── matmul_tik.py                              # 基于tik开发的matmul样例逻辑实现文件
    │   ├── cpu                                                    # aicpu自定义算子目录，非必需
    │   │   └── aicpu_kernel
    │   │       └── impl
    │   └── vector_core                                            # 运行在vector_core的算子实现目录
    │       └── tbe                                                # tbe算子实现目录
    │           └── mslite_impl                                    # 算子的实现逻辑目录
    │               ├── add_dsl.py                                 # 基于dsl开发的add样例逻辑实现文件
    │               ├── add_tik.py                                 # 基于tik开发的add样例逻辑实现文件
    │               └── matmul_tik.py                              # 基于tik开发的matmul样例逻辑实现文件
    └── op_proto                                                   # 算子原型定义包目录
        └── libcust_op_proto.so                                    # 算子原型定义so文件，akg自定义算子默认注册，不需要此文件
</pre></div>
</div>
</li>
</ol>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="benchmark.html" class="btn btn-neutral float-right" title="基准测试工具" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="converter_python.html" class="btn btn-neutral float-left" title="使用Python接口模型转换" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2021, MindSpore Lite.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>