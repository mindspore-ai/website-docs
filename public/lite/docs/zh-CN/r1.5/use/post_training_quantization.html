

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>优化模型(训练后量化) &mdash; MindSpore Lite master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/lite.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/js/lite.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="预处理数据" href="data_preprocessing.html" />
    <link rel="prev" title="推理模型转换" href="converter_tool.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore Lite
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">获取MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="downloads.html">下载MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="build.html">编译MindSpore Lite</a></li>
</ul>
<p class="caption"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_cpp.html">体验C++极简推理Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_java.html">体验Java极简推理Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">基于JNI接口的Android应用开发</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/image_segmentation.html">基于Java接口的Android应用开发</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/train_lenet.html">基于C++接口实现端侧训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/train_lenet_java.html">基于Java接口实现端侧训练</a></li>
</ul>
<p class="caption"><span class="caption-text">端侧推理</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="converter_tool.html">推理模型转换</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">优化模型(训练后量化)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id2">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">配置参数</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id4">通用量化参数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">混合比特权重量化参数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">全量化参数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">数据预处理</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id8">权重量化</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id9">混合比特量化</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">固定比特量化</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id11">部分模型精度结果</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id12">全量化</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id13">部分模型精度结果</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="data_preprocessing.html">预处理数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">执行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="micro.html">在轻量和小型系统上执行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="asic.html">专用芯片集成说明</a></li>
<li class="toctree-l1"><a class="reference internal" href="register_kernel.html">自定义南向算子</a></li>
<li class="toctree-l1"><a class="reference internal" href="delegate.html">使用Delegate支持第三方AI框架接入</a></li>
</ul>
<p class="caption"><span class="caption-text">端侧训练</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="converter_train.html">训练模型转换</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime_train.html">执行训练</a></li>
</ul>
<p class="caption"><span class="caption-text">其他工具</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">基准测试工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="cropper_tool.html">静态库剪裁工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="visual_tool.html">可视化工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="obfuscator_tool.html">模型混淆工具</a></li>
</ul>
<p class="caption"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../architecture_lite.html">总体架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_lite.html">Lite算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_codegen.html">Codegen算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_lite.html">模型支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting_guide.html">问题定位指南</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>优化模型(训练后量化)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/use/post_training_quantization.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1>优化模型(训练后量化)<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Windows</span></code> <code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">模型转换</span></code> <code class="docutils literal notranslate"><span class="pre">模型调优</span></code> <code class="docutils literal notranslate"><span class="pre">中级</span></code> <code class="docutils literal notranslate"><span class="pre">高级</span></code></p>
<!-- TOC -->
<ul class="simple">
<li><p><a class="reference external" href="#%E4%BC%98%E5%8C%96%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%90%8E%E9%87%8F%E5%8C%96">优化模型(训练后量化)</a></p>
<ul>
<li><p><a class="reference external" href="#%E6%A6%82%E8%BF%B0">概述</a></p></li>
<li><p><a class="reference external" href="#%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0">配置参数</a></p>
<ul>
<li><p><a class="reference external" href="#%E9%80%9A%E7%94%A8%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0">通用量化参数</a></p></li>
<li><p><a class="reference external" href="#%E6%B7%B7%E5%90%88%E6%AF%94%E7%89%B9%E6%9D%83%E9%87%8D%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0">混合比特权重量化参数</a></p></li>
<li><p><a class="reference external" href="#%E5%85%A8%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0">全量化参数</a></p></li>
<li><p><a class="reference external" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86">数据预处理</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#%E6%9D%83%E9%87%8D%E9%87%8F%E5%8C%96">权重量化</a></p>
<ul>
<li><p><a class="reference external" href="#%E6%B7%B7%E5%90%88%E6%AF%94%E7%89%B9%E9%87%8F%E5%8C%96">混合比特量化</a></p></li>
<li><p><a class="reference external" href="#%E5%9B%BA%E5%AE%9A%E6%AF%94%E7%89%B9%E9%87%8F%E5%8C%96">固定比特量化</a></p></li>
<li><p><a class="reference external" href="#%E9%83%A8%E5%88%86%E6%A8%A1%E5%9E%8B%E7%B2%BE%E5%BA%A6%E7%BB%93%E6%9E%9C">部分模型精度结果</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#%E5%85%A8%E9%87%8F%E5%8C%96">全量化</a></p>
<ul>
<li><p><a class="reference external" href="#%E9%83%A8%E5%88%86%E6%A8%A1%E5%9E%8B%E7%B2%BE%E5%BA%A6%E7%BB%93%E6%9E%9C-1">部分模型精度结果</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- /TOC -->
<p><a href="https://gitee.com/mindspore/docs/blob/r1.5/docs/lite/docs/source_zh_cn/use/post_training_quantization.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source.png"></a></p>
<div class="section" id="id2">
<h2>概述<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>对于已经训练好的<code class="docutils literal notranslate"><span class="pre">float32</span></code>模型，通过训练后量化将其转为<code class="docutils literal notranslate"><span class="pre">int8</span></code>，不仅能减小模型大小，而且能显著提高推理性能。在MindSpore Lite中，这部分功能集成在模型转换工具<code class="docutils literal notranslate"><span class="pre">conveter_lite</span></code>内，通过配置<code class="docutils literal notranslate"><span class="pre">量化配置文件</span></code>的方式，便能够转换得到量化后模型。</p>
<p>MindSpore Lite训练后量化分为两类：</p>
<ol class="simple">
<li><p>权重量化：对模型的权值进行量化，仅压缩模型大小，推理时仍然执行<code class="docutils literal notranslate"><span class="pre">float32</span></code>推理；</p></li>
<li><p>全量化：对模型的权值、激活值等统一进行量化，推理时执行<code class="docutils literal notranslate"><span class="pre">int</span></code>运算，能提升模型推理速度、降低功耗。</p></li>
</ol>
</div>
<div class="section" id="id3">
<h2>配置参数<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>训练后量化可通过<a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/r1.5/use/converter_tool.html">转换工具</a>配置<code class="docutils literal notranslate"><span class="pre">configFile</span></code>的方式启用训练后量化。配置文件采用<code class="docutils literal notranslate"><span class="pre">INI</span></code>的风格，针对量化场景，目前可配置的参数包括<code class="docutils literal notranslate"><span class="pre">通用量化参数[common_quant_param]</span></code>、<code class="docutils literal notranslate"><span class="pre">混合比特权重量化参数[mixed_bit_weight_quant_param]</span></code>、<code class="docutils literal notranslate"><span class="pre">全量化参数[full_quant_param]</span></code>和<code class="docutils literal notranslate"><span class="pre">数据预处理参数[data_preprocess_param]</span></code>。</p>
<div class="section" id="id4">
<h3>通用量化参数<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>通用量化参数是训练后量化的基本设置，主要包括<code class="docutils literal notranslate"><span class="pre">quant_type</span></code>、<code class="docutils literal notranslate"><span class="pre">bit_num</span></code>、<code class="docutils literal notranslate"><span class="pre">min_quant_weight_size</span></code>和<code class="docutils literal notranslate"><span class="pre">min_quant_weight_channel</span></code>。参数的详细介绍如下所示：</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>参数</th>
<th>属性</th>
<th>功能描述</th>
<th>参数类型</th>
<th>默认值</th>
<th>取值范围</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>quant_type</code></td>
<td>必选</td>
<td>设置量化类型，设置为WEIGHT_QUANT时，启用权重量化；设置为FULL_QUANT时，启用全量化。</td>
<td>String</td>
<td>-</td>
<td>WEIGHT_QUANT、FULL_QUANT</td>
</tr>
<tr>
<td><code>bit_num</code></td>
<td>可选</td>
<td>设置量化的比特数，目前权重量化支持0-16bit量化，设置为1-16bit时为固定比特量化，设置为0bit时，启用混合比特量化。全量化支持1-8bit量化。</td>
<td>Integer</td>
<td>8</td>
<td>权重量化：[0，16]<br/>全量化：[1，8]</td>
</tr>
<tr>
<td><code>min_quant_weight_size</code></td>
<td>可选</td>
<td>设置参与量化的权重尺寸阈值，若权重数大于该值，则对此权重进行量化。</td>
<td>Integer</td>
<td>0</td>
<td>[0, 65535]</td>
</tr>
<tr>
<td><code>min_quant_weight_channel</code></td>
<td>可选</td>
<td>设置参与量化的权重通道数阈值，若权重通道数大于该值，则对此权重进行量化。</td>
<td>Integer</td>
<td>16</td>
<td>[0, 65535]</td>
</tr>
</tbody>
</table>
<p>通用量化参数配置如下所示：</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[common_quant_param]</span>
<span class="c1"># Supports WEIGHT_QUANT or FULL_QUANT</span>
<span class="na">quant_type</span><span class="o">=</span><span class="s">WEIGHT_QUANT</span>
<span class="c1"># Weight quantization support the number of bits [0,16], Set to 0 is mixed bit quantization, otherwise it is fixed bit quantization</span>
<span class="c1"># Full quantization support the number of bits [1,8]</span>
<span class="na">bit_num</span><span class="o">=</span><span class="s">8</span>
<span class="c1"># Layers with size of weights exceeds threshold `min_quant_weight_size` will be quantized.</span>
<span class="na">min_quant_weight_size</span><span class="o">=</span><span class="s">0</span>
<span class="c1"># Layers with channel size of weights exceeds threshold `min_quant_weight_channel` will be quantized.</span>
<span class="na">min_quant_weight_channel</span><span class="o">=</span><span class="s">16</span>
</pre></div>
</div>
</div>
<div class="section" id="id5">
<h3>混合比特权重量化参数<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>混合比特权重量化参数包括<code class="docutils literal notranslate"><span class="pre">init_scale</span></code>，启用混合比特权重量化后，将会针对不同层自动搜索最优的比特数。参数的详细介绍如下所示：</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>参数</th>
<th>属性</th>
<th>功能描述</th>
<th>参数类型</th>
<th>默认值</th>
<th>取值范围</th>
</tr>
</thead>
<tbody>
<tr>
<td>init_scale</td>
<td>可选</td>
<td>初始化scale，数值越大可以带来更大的压缩率，但是也会造成不同程度的精度损失</td>
<td>float</td>
<td>0.02</td>
<td>(0 , 1)</td>
</tr>
</tbody>
</table>
<p>混合比特量化参数配置如下所示：</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[mixed_bit_weight_quant_param]</span>
<span class="na">init_scale</span><span class="o">=</span><span class="s">0.02</span>
</pre></div>
</div>
</div>
<div class="section" id="id6">
<h3>全量化参数<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>全量化参数主要包括<code class="docutils literal notranslate"><span class="pre">activation_quant_method</span></code>及<code class="docutils literal notranslate"><span class="pre">bias_correction</span></code>。参数的详细介绍如下所示：</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>参数</th>
<th>属性</th>
<th>功能描述</th>
<th>参数类型</th>
<th>默认值</th>
<th>取值范围</th>
</tr>
</thead>
<tbody>
<tr>
<td>activation_quant_method</td>
<td>可选</td>
<td>激活值量化算法</td>
<td>String</td>
<td>MAX_MIN</td>
<td>KL，MAX_MIN，RemovalOutlier。 <br>KL：基于<a href="http://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf">KL散度</a>对数据范围作量化校准。 <br>MAX_MIN：基于最大值、最小值计算数据的量化参数。 <br>RemovalOutlier：按照一定比例剔除数据的极大极小值，再计算量化参数。 <br>在校准数据集与实际推理时的输入数据相吻合的情况下，推荐使用MAX_MIN；而在校准数据集噪声比较大的情况下，推荐使用KL或者REMOVAL_OUTLIER</td>
</tr>
<tr>
<td>bias_correction</td>
<td>可选</td>
<td>是否对量化误差进行校正</td>
<td>Boolean</td>
<td>True</td>
<td>True，False。使能后，将能提升量化模型的精度。</td>
</tr>
</tbody>
</table>
<p>全量化参数配置如下所示：</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[full_quant_param]</span>
<span class="c1"># Activation quantized method supports MAX_MIN or KL or REMOVAL_OUTLIER</span>
<span class="na">activation_quant_method</span><span class="o">=</span><span class="s">MAX_MIN</span>
<span class="c1"># Whether to correct the quantization error. Recommended to set to true.</span>
<span class="na">bias_correction</span><span class="o">=</span><span class="s">true</span>
</pre></div>
</div>
</div>
<div class="section" id="id7">
<h3>数据预处理<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>计算全量化的激活值量化参数，用户需要提供校准数据集，针对图片校准数据集，将提供通道转换、归一化、缩放和裁剪等数据预处理功能。</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>参数</th>
<th>属性</th>
<th>功能描述</th>
<th>参数类型</th>
<th>默认值</th>
<th>取值范围</th>
</tr>
</thead>
<tbody>
<tr>
<td>calibrate_path</td>
<td>必选</td>
<td>存放校准数据集的目录；如果模型有多个输入，请依次填写对应的数据所在目录，目录路径间请用<code>,</code>隔开</td>
<td>String</td>
<td>-</td>
<td>input_name_1:/mnt/image/input_1_dir,input_name_2:input_2_dir</td>
</tr>
<tr>
<td>calibrate_size</td>
<td>必选</td>
<td>矫正集数量</td>
<td>Integer</td>
<td>-</td>
<td>[1, 65535]</td>
</tr>
<tr>
<td>input_type</td>
<td>必选</td>
<td>矫正数据文件格式类型</td>
<td>String</td>
<td>-</td>
<td>IMAGE、BIN <br>IMAGE：图片文件数据 <br>BIN：满足推理的输入要求二进制<code>.bin</code>文件数据</td>
</tr>
<tr>
<td>image_to_format</td>
<td>可选</td>
<td>图像格式转换</td>
<td>String</td>
<td>-</td>
<td>RGB、GRAY、BGR</td>
</tr>
<tr>
<td>normalize_mean</td>
<td>可选</td>
<td>图像归一化的均值<br/>dst = (src - mean) / std</td>
<td>Vector</td>
<td>-</td>
<td>3通道：[mean_1, mean_2, mean_3] <br/>1通道：[mean_1]</td>
</tr>
<tr>
<td>normalize_std</td>
<td>可选</td>
<td>图像归一化的标准差<br/>dst = (src - mean) / std</td>
<td>Vector</td>
<td>-</td>
<td>3通道：[std_1, std_2, std_3] <br/>1通道：[std_1]</td>
</tr>
<tr>
<td>resize_width</td>
<td>可选</td>
<td>图像缩放宽度</td>
<td>Integer</td>
<td>-</td>
<td>[1, 65535]</td>
</tr>
<tr>
<td>resize_height</td>
<td>可选</td>
<td>图像缩放高度</td>
<td>Integer</td>
<td>-</td>
<td>[1, 65535]</td>
</tr>
<tr>
<td>resize_method</td>
<td>可选</td>
<td>图像缩放算法</td>
<td>String</td>
<td>-</td>
<td>LINEAR、NEAREST、CUBIC<br/>LINEAR：线性插值<br/>NEARST：最邻近插值<br/>CUBIC：三次样条插值</td>
</tr>
<tr>
<td>center_crop_width</td>
<td>可选</td>
<td>中心裁剪宽度</td>
<td>Integer</td>
<td>-</td>
<td>[1, 65535]</td>
</tr>
<tr>
<td>center_crop_height</td>
<td>可选</td>
<td>中心裁剪高度</td>
<td>Integer</td>
<td>-</td>
<td>[1, 65535]</td>
</tr>
</tbody>
</table>
<p>数据预处理参数配置如下所示：</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[data_preprocess_param]</span>
<span class="c1"># Calibration dataset path, the format is input_name_1:input_1_dir,input_name_2:input_2_dir</span>
<span class="c1"># Full quantification must provide correction dataset</span>
<span class="na">calibrate_path</span><span class="o">=</span><span class="s">input_name_1:/mnt/image/input_1_dir,input_name_2:input_2_dir</span>
<span class="c1"># Calibration data size</span>
<span class="na">calibrate_size</span><span class="o">=</span><span class="s">100</span>
<span class="c1"># Input type supports IMAGE or BIN</span>
<span class="c1"># When set to IMAGE, the image data will be read</span>
<span class="c1"># When set to BIN, the `.bin` binary file will be read</span>
<span class="na">input_type</span><span class="o">=</span><span class="s">IMAGE</span>
<span class="c1"># The output format of the preprocessed image</span>
<span class="c1"># Supports RGB or GRAY or BGR</span>
<span class="na">image_to_format</span><span class="o">=</span><span class="s">RGB</span>
<span class="c1"># Image normalization</span>
<span class="c1"># dst = (src - mean) / std</span>
<span class="na">normalize_mean</span><span class="o">=</span><span class="s">[127.5, 127.5, 127.5]</span>
<span class="na">normalize_std</span><span class="o">=</span><span class="s">[127.5, 127.5, 127.5]</span>
<span class="c1"># Image resize</span>
<span class="na">resize_width</span><span class="o">=</span><span class="s">224</span>
<span class="na">resize_height</span><span class="o">=</span><span class="s">224</span>
<span class="c1"># Resize method supports LINEAR or NEAREST or CUBIC</span>
<span class="na">resize_method</span><span class="o">=</span><span class="s">LINEAR</span>
<span class="c1"># Image center crop</span>
<span class="na">center_crop_width</span><span class="o">=</span><span class="s">224</span>
<span class="na">center_crop_height</span><span class="o">=</span><span class="s">224</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id8">
<h2>权重量化<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p>权重量化支持混合比特量化，同时也支持1~16之间的固定比特量化，比特数越低，模型压缩率越大，但是精度损失通常也比较大。下面对权重量化的使用方式和效果进行阐述。</p>
<div class="section" id="id9">
<h3>混合比特量化<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>目前权重量化支持混合比特量化，会根据模型参数的分布情况，根据用户设置的<code class="docutils literal notranslate"><span class="pre">init_scale</span></code>作为初始值，自动搜索出最适合当前层的比特数。配置参数的<code class="docutils literal notranslate"><span class="pre">bit_num</span></code>设置为0时，将启用混合比特量化。</p>
<p>混合比特权重量化转换命令的一般形式为：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite --fmk<span class="o">=</span>ModelType --modelFile<span class="o">=</span>ModelFilePath --outputFile<span class="o">=</span>ConvertedModelPath --configFile<span class="o">=</span>/mindspore/lite/tools/converter/quantizer/config/mixed_bit_weight_quant.cfg
</pre></div>
</div>
<p>混合比特权重量化配置文件如下所示：</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[common_quant_param]</span>
<span class="c1"># Supports WEIGHT_QUANT or FULL_QUANT</span>
<span class="na">quant_type</span><span class="o">=</span><span class="s">WEIGHT_QUANT</span>
<span class="c1"># Weight quantization support the number of bits [0,16], Set to 0 is mixed bit quantization, otherwise it is fixed bit quantization</span>
<span class="c1"># Full quantization support the number of bits [1,8]</span>
<span class="na">bit_num</span><span class="o">=</span><span class="s">0</span>
<span class="c1"># Layers with size of weights exceeds threshold `min_quant_weight_size` will be quantized.</span>
<span class="na">min_quant_weight_size</span><span class="o">=</span><span class="s">5000</span>
<span class="c1"># Layers with channel size of weights exceeds threshold `min_quant_weight_channel` will be quantized.</span>
<span class="na">min_quant_weight_channel</span><span class="o">=</span><span class="s">5</span>

<span class="k">[mixed_bit_weight_quant_param]</span>
<span class="c1"># Initialization scale in (0,1).</span>
<span class="c1"># A larger value can get a larger compression ratio, but it may also cause a larger error.</span>
<span class="na">init_scale</span><span class="o">=</span><span class="s">0.02</span>
</pre></div>
</div>
<p>用户可根据模型及自身需要对权重量化的参数作出调整。</p>
<blockquote>
<div><p>init_scale默认的初始值为0.02，搜索的压缩率相当与6-7固定比特的压缩效果。</p>
<p>针对稀疏结构模型，建议将init_scale设置为0.00003。</p>
</div></blockquote>
</div>
<div class="section" id="id10">
<h3>固定比特量化<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>固定比特的权重量化支持1~16之间的固定比特量化，用户可根据模型及自身需要对权重量化的参数作出调整。</p>
<p>固定比特权重量化转换命令的一般形式为：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite --fmk<span class="o">=</span>ModelType --modelFile<span class="o">=</span>ModelFilePath --outputFile<span class="o">=</span>ConvertedModelPath --configFile<span class="o">=</span>/mindspore/lite/tools/converter/quantizer/config/fixed_bit_weight_quant.cfg
</pre></div>
</div>
<p>固定比特权重量化配置文件如下所示：</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[common_quant_param]</span>
<span class="c1"># Supports WEIGHT_QUANT or FULL_QUANT</span>
<span class="na">quant_type</span><span class="o">=</span><span class="s">WEIGHT_QUANT</span>
<span class="c1"># Weight quantization support the number of bits [0,16], Set to 0 is mixed bit quantization, otherwise it is fixed bit quantization</span>
<span class="c1"># Full quantization support the number of bits [1,8]</span>
<span class="na">bit_num</span><span class="o">=</span><span class="s">8</span>
<span class="c1"># Layers with size of weights exceeds threshold `min_quant_weight_size` will be quantized.</span>
<span class="na">min_quant_weight_size</span><span class="o">=</span><span class="s">0</span>
<span class="c1"># Layers with channel size of weights exceeds threshold `min_quant_weight_channel` will be quantized.</span>
<span class="na">min_quant_weight_channel</span><span class="o">=</span><span class="s">16</span>
</pre></div>
</div>
</div>
<div class="section" id="id11">
<h3>部分模型精度结果<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th>模型</th>
<th>测试数据集</th>
<th>FP32模型精度</th>
<th>权重量化精度（8bit）</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/model_zoo/upload_20180427/inception_v3_2018_04_27.tgz">Inception_V3</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>77.60%</td>
<td>77.53%</td>
</tr>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz">Mobilenet_V1_1.0_224</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>70.96%</td>
<td>70.56%</td>
</tr>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224.tgz">Mobilenet_V2_1.0_224</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>71.56%</td>
<td>71.53%</td>
</tr>
</tbody>
</table>
<blockquote>
<div><p>以上所有结果均在x86环境上测得。</p>
</div></blockquote>
</div>
</div>
<div class="section" id="id12">
<h2>全量化<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h2>
<p>针对需要提升模型运行速度、降低模型运行功耗的场景，可以使用训练后全量化功能。下面对全量化的使用方式和效果进行阐述。</p>
<p>全量化计算激活值的量化参数，用户需要提供校准数据集。校准数据集最好来自真实推理场景，能表征模型的实际输入情况，数量在100个左右。</p>
<p>针对图片数据，目前支持通道调整、归一化、缩放、裁剪等预处理的功能。用户可以根据推理时所需的预处理操作，设置相应的<a class="reference external" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86">参数</a>。</p>
<p>全量化转换命令的一般形式为：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite --fmk<span class="o">=</span>ModelType --modelFile<span class="o">=</span>ModelFilePath --outputFile<span class="o">=</span>ConvertedModelPath --configFile<span class="o">=</span>/mindspore/lite/tools/converter/quantizer/config/full_quant.cfg
</pre></div>
</div>
<p>全量化配置文件如下所示：</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[common_quant_param]</span>
<span class="c1"># Supports WEIGHT_QUANT or FULL_QUANT</span>
<span class="na">quant_type</span><span class="o">=</span><span class="s">FULL_QUANT</span>
<span class="c1"># Weight quantization support the number of bits [0,16], Set to 0 is mixed bit quantization, otherwise it is fixed bit quantization</span>
<span class="c1"># Full quantization support the number of bits [1,8]</span>
<span class="na">bit_num</span><span class="o">=</span><span class="s">8</span>
<span class="c1"># Layers with size of weights exceeds threshold `min_quant_weight_size` will be quantized.</span>
<span class="na">min_quant_weight_size</span><span class="o">=</span><span class="s">0</span>
<span class="c1"># Layers with channel size of weights exceeds threshold `min_quant_weight_channel` will be quantized.</span>
<span class="na">min_quant_weight_channel</span><span class="o">=</span><span class="s">16</span>

<span class="k">[data_preprocess_param]</span>
<span class="c1"># Calibration dataset path, the format is input_name_1:input_1_dir,input_name_2:input_2_dir</span>
<span class="c1"># Full quantification must provide correction dataset</span>
<span class="na">calibrate_path</span><span class="o">=</span><span class="s">input_name_1:/mnt/image/input_1_dir,input_name_2:input_2_dir</span>
<span class="c1"># Calibration data size</span>
<span class="na">calibrate_size</span><span class="o">=</span><span class="s">100</span>
<span class="c1"># Input type supports IMAGE or BIN</span>
<span class="c1"># When set to IMAGE, the image data will be read</span>
<span class="c1"># When set to BIN, the `.bin` binary file will be read</span>
<span class="na">input_type</span><span class="o">=</span><span class="s">IMAGE</span>
<span class="c1"># The output format of the preprocessed image</span>
<span class="c1"># Supports RGB or GRAY or BGR</span>
<span class="na">image_to_format</span><span class="o">=</span><span class="s">RGB</span>
<span class="c1"># Image normalization</span>
<span class="c1"># dst = (src - mean) / std</span>
<span class="na">normalize_mean</span><span class="o">=</span><span class="s">[127.5, 127.5, 127.5]</span>
<span class="na">normalize_std</span><span class="o">=</span><span class="s">[127.5, 127.5, 127.5]</span>
<span class="c1"># Image resize</span>
<span class="na">resize_width</span><span class="o">=</span><span class="s">224</span>
<span class="na">resize_height</span><span class="o">=</span><span class="s">224</span>
<span class="c1"># Resize method supports LINEAR or NEAREST or CUBIC</span>
<span class="na">resize_method</span><span class="o">=</span><span class="s">LINEAR</span>
<span class="c1"># Image center crop</span>
<span class="na">center_crop_width</span><span class="o">=</span><span class="s">224</span>
<span class="na">center_crop_height</span><span class="o">=</span><span class="s">224</span>

<span class="k">[full_quant_param]</span>
<span class="c1"># Activation quantized method supports MAX_MIN or KL or REMOVAL_OUTLIER</span>
<span class="na">activation_quant_method</span><span class="o">=</span><span class="s">MAX_MIN</span>
<span class="c1"># Whether to correct the quantization error. Recommended to set to true.</span>
<span class="na">bias_correction</span><span class="o">=</span><span class="s">true</span>
</pre></div>
</div>
<div class="section" id="id13">
<h3>部分模型精度结果<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th>模型</th>
<th>测试数据集</th>
<th>method_x</th>
<th>FP32模型精度</th>
<th>全量化精度（8bit）</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/model_zoo/upload_20180427/inception_v3_2018_04_27.tgz">Inception_V3</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>KL</td>
<td>77.60%</td>
<td>77.40%</td>
<td>校准数据集随机选择ImageNet Validation数据集中的100张</td>
</tr>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz">Mobilenet_V1_1.0_224</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>KL</td>
<td>70.96%</td>
<td>70.31%</td>
<td>校准数据集随机选择ImageNet Validation数据集中的100张</td>
</tr>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224.tgz">Mobilenet_V2_1.0_224</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>MAX_MIN</td>
<td>71.56%</td>
<td>71.16%</td>
<td>校准数据集随机选择ImageNet Validation数据集中的100张</td>
</tr>
</tbody>
</table>
<blockquote>
<div><p>以上所有结果均在x86环境上测得。</p>
</div></blockquote>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="data_preprocessing.html" class="btn btn-neutral float-right" title="预处理数据" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="converter_tool.html" class="btn btn-neutral float-left" title="推理模型转换" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, MindSpore Lite.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>