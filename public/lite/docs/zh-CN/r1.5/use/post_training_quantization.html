<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>优化模型(训练后量化) &mdash; MindSpore Lite master documentation</title>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/lite.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/lite.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="预处理数据" href="data_preprocessing.html" />
    <link rel="prev" title="推理模型转换" href="converter_tool.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">获取MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="downloads.html">下载MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="build.html">编译MindSpore Lite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_cpp.html">体验C++极简推理Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_java.html">体验Java极简推理Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">基于JNI接口的Android应用开发</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/image_segmentation.html">基于Java接口的Android应用开发</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/train_lenet.html">基于C++接口实现端侧训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/train_lenet_java.html">基于Java接口实现端侧训练</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">端侧推理</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="converter_tool.html">推理模型转换</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">优化模型(训练后量化)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id2">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">配置参数</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id4">通用量化参数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">混合比特权重量化参数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">全量化参数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">数据预处理</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id8">权重量化</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id9">混合比特量化</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">固定比特量化</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id11">部分模型精度结果</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id12">全量化</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id13">部分模型精度结果</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="data_preprocessing.html">预处理数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">执行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="micro.html">在轻量和小型系统上执行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="asic.html">专用芯片集成说明</a></li>
<li class="toctree-l1"><a class="reference internal" href="register_kernel.html">自定义南向算子</a></li>
<li class="toctree-l1"><a class="reference internal" href="delegate.html">使用Delegate支持第三方AI框架接入</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">端侧训练</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="converter_train.html">训练模型转换</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime_train.html">执行训练</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">其他工具</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">基准测试工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="cropper_tool.html">静态库剪裁工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="visual_tool.html">可视化工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="obfuscator_tool.html">模型混淆工具</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../architecture_lite.html">总体架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_lite.html">Lite算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_codegen.html">Codegen算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_lite.html">模型支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting_guide.html">问题定位指南</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>优化模型(训练后量化)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/use/post_training_quantization.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1>优化模型(训练后量化)<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Windows</span></code> <code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">模型转换</span></code> <code class="docutils literal notranslate"><span class="pre">模型调优</span></code> <code class="docutils literal notranslate"><span class="pre">中级</span></code> <code class="docutils literal notranslate"><span class="pre">高级</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.5/docs/lite/docs/source_zh_cn/use/post_training_quantization.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source.png"></a></p>
<section id="id2">
<h2>概述<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<p>对于已经训练好的<code class="docutils literal notranslate"><span class="pre">float32</span></code>模型，通过训练后量化将其转为<code class="docutils literal notranslate"><span class="pre">int8</span></code>，不仅能减小模型大小，而且能显著提高推理性能。在MindSpore Lite中，这部分功能集成在模型转换工具<code class="docutils literal notranslate"><span class="pre">conveter_lite</span></code>内，通过配置<code class="docutils literal notranslate"><span class="pre">量化配置文件</span></code>的方式，便能够转换得到量化后模型。</p>
<p>MindSpore Lite训练后量化分为两类：</p>
<ol class="arabic simple">
<li><p>权重量化：对模型的权值进行量化，仅压缩模型大小，推理时仍然执行<code class="docutils literal notranslate"><span class="pre">float32</span></code>推理；</p></li>
<li><p>全量化：对模型的权值、激活值等统一进行量化，推理时执行<code class="docutils literal notranslate"><span class="pre">int</span></code>运算，能提升模型推理速度、降低功耗。</p></li>
</ol>
</section>
<section id="id3">
<h2>配置参数<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h2>
<p>训练后量化可通过<a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/r1.5/use/converter_tool.html">转换工具</a>配置<code class="docutils literal notranslate"><span class="pre">configFile</span></code>的方式启用训练后量化。配置文件采用<code class="docutils literal notranslate"><span class="pre">INI</span></code>的风格，针对量化场景，目前可配置的参数包括<code class="docutils literal notranslate"><span class="pre">通用量化参数[common_quant_param]</span></code>、<code class="docutils literal notranslate"><span class="pre">混合比特权重量化参数[mixed_bit_weight_quant_param]</span></code>、<code class="docutils literal notranslate"><span class="pre">全量化参数[full_quant_param]</span></code>和<code class="docutils literal notranslate"><span class="pre">数据预处理参数[data_preprocess_param]</span></code>。</p>
<section id="id4">
<h3>通用量化参数<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<p>通用量化参数是训练后量化的基本设置，主要包括<code class="docutils literal notranslate"><span class="pre">quant_type</span></code>、<code class="docutils literal notranslate"><span class="pre">bit_num</span></code>、<code class="docutils literal notranslate"><span class="pre">min_quant_weight_size</span></code>和<code class="docutils literal notranslate"><span class="pre">min_quant_weight_channel</span></code>。参数的详细介绍如下所示：</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>参数</p></th>
<th class="head"><p>属性</p></th>
<th class="head"><p>功能描述</p></th>
<th class="head"><p>参数类型</p></th>
<th class="head"><p>默认值</p></th>
<th class="head"><p>取值范围</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">quant_type</span></code></p></td>
<td><p>必选</p></td>
<td><p>设置量化类型，设置为WEIGHT_QUANT时，启用权重量化；设置为FULL_QUANT时，启用全量化。</p></td>
<td><p>String</p></td>
<td><p>-</p></td>
<td><p>WEIGHT_QUANT、FULL_QUANT</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">bit_num</span></code></p></td>
<td><p>可选</p></td>
<td><p>设置量化的比特数，目前权重量化支持0-16bit量化，设置为1-16bit时为固定比特量化，设置为0bit时，启用混合比特量化。全量化支持1-8bit量化。</p></td>
<td><p>Integer</p></td>
<td><p>8</p></td>
<td><p>权重量化：[0，16]<br/>全量化：[1，8]</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">min_quant_weight_size</span></code></p></td>
<td><p>可选</p></td>
<td><p>设置参与量化的权重尺寸阈值，若权重数大于该值，则对此权重进行量化。</p></td>
<td><p>Integer</p></td>
<td><p>0</p></td>
<td><p>[0, 65535]</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">min_quant_weight_channel</span></code></p></td>
<td><p>可选</p></td>
<td><p>设置参与量化的权重通道数阈值，若权重通道数大于该值，则对此权重进行量化。</p></td>
<td><p>Integer</p></td>
<td><p>16</p></td>
<td><p>[0, 65535]</p></td>
</tr>
</tbody>
</table>
<p>通用量化参数配置如下所示：</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[common_quant_param]</span>
<span class="c1"># Supports WEIGHT_QUANT or FULL_QUANT</span>
<span class="na">quant_type</span><span class="o">=</span><span class="s">WEIGHT_QUANT</span>
<span class="c1"># Weight quantization support the number of bits [0,16], Set to 0 is mixed bit quantization, otherwise it is fixed bit quantization</span>
<span class="c1"># Full quantization support the number of bits [1,8]</span>
<span class="na">bit_num</span><span class="o">=</span><span class="s">8</span>
<span class="c1"># Layers with size of weights exceeds threshold `min_quant_weight_size` will be quantized.</span>
<span class="na">min_quant_weight_size</span><span class="o">=</span><span class="s">0</span>
<span class="c1"># Layers with channel size of weights exceeds threshold `min_quant_weight_channel` will be quantized.</span>
<span class="na">min_quant_weight_channel</span><span class="o">=</span><span class="s">16</span>
</pre></div>
</div>
</section>
<section id="id5">
<h3>混合比特权重量化参数<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h3>
<p>混合比特权重量化参数包括<code class="docutils literal notranslate"><span class="pre">init_scale</span></code>，启用混合比特权重量化后，将会针对不同层自动搜索最优的比特数。参数的详细介绍如下所示：</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>参数</p></th>
<th class="head"><p>属性</p></th>
<th class="head"><p>功能描述</p></th>
<th class="head"><p>参数类型</p></th>
<th class="head"><p>默认值</p></th>
<th class="head"><p>取值范围</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>init_scale</p></td>
<td><p>可选</p></td>
<td><p>初始化scale，数值越大可以带来更大的压缩率，但是也会造成不同程度的精度损失</p></td>
<td><p>float</p></td>
<td><p>0.02</p></td>
<td><p>(0 , 1)</p></td>
</tr>
</tbody>
</table>
<p>混合比特量化参数配置如下所示：</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[mixed_bit_weight_quant_param]</span>
<span class="na">init_scale</span><span class="o">=</span><span class="s">0.02</span>
</pre></div>
</div>
</section>
<section id="id6">
<h3>全量化参数<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<p>全量化参数主要包括<code class="docutils literal notranslate"><span class="pre">activation_quant_method</span></code>及<code class="docutils literal notranslate"><span class="pre">bias_correction</span></code>。参数的详细介绍如下所示：</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>参数</p></th>
<th class="head"><p>属性</p></th>
<th class="head"><p>功能描述</p></th>
<th class="head"><p>参数类型</p></th>
<th class="head"><p>默认值</p></th>
<th class="head"><p>取值范围</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>activation_quant_method</p></td>
<td><p>可选</p></td>
<td><p>激活值量化算法</p></td>
<td><p>String</p></td>
<td><p>MAX_MIN</p></td>
<td><p>KL，MAX_MIN，RemovalOutlier。 <br>KL：基于<a class="reference external" href="http://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf">KL散度</a>对数据范围作量化校准。 <br>MAX_MIN：基于最大值、最小值计算数据的量化参数。 <br>RemovalOutlier：按照一定比例剔除数据的极大极小值，再计算量化参数。 <br>在校准数据集与实际推理时的输入数据相吻合的情况下，推荐使用MAX_MIN；而在校准数据集噪声比较大的情况下，推荐使用KL或者REMOVAL_OUTLIER</p></td>
</tr>
<tr class="row-odd"><td><p>bias_correction</p></td>
<td><p>可选</p></td>
<td><p>是否对量化误差进行校正</p></td>
<td><p>Boolean</p></td>
<td><p>True</p></td>
<td><p>True，False。使能后，将能提升量化模型的精度。</p></td>
</tr>
</tbody>
</table>
<p>全量化参数配置如下所示：</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[full_quant_param]</span>
<span class="c1"># Activation quantized method supports MAX_MIN or KL or REMOVAL_OUTLIER</span>
<span class="na">activation_quant_method</span><span class="o">=</span><span class="s">MAX_MIN</span>
<span class="c1"># Whether to correct the quantization error. Recommended to set to true.</span>
<span class="na">bias_correction</span><span class="o">=</span><span class="s">true</span>
</pre></div>
</div>
</section>
<section id="id7">
<h3>数据预处理<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h3>
<p>计算全量化的激活值量化参数，用户需要提供校准数据集，针对图片校准数据集，将提供通道转换、归一化、缩放和裁剪等数据预处理功能。</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>参数</p></th>
<th class="head"><p>属性</p></th>
<th class="head"><p>功能描述</p></th>
<th class="head"><p>参数类型</p></th>
<th class="head"><p>默认值</p></th>
<th class="head"><p>取值范围</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>calibrate_path</p></td>
<td><p>必选</p></td>
<td><p>存放校准数据集的目录；如果模型有多个输入，请依次填写对应的数据所在目录，目录路径间请用<code class="docutils literal notranslate"><span class="pre">,</span></code>隔开</p></td>
<td><p>String</p></td>
<td><p>-</p></td>
<td><p>input_name_1:/mnt/image/input_1_dir,input_name_2:input_2_dir</p></td>
</tr>
<tr class="row-odd"><td><p>calibrate_size</p></td>
<td><p>必选</p></td>
<td><p>矫正集数量</p></td>
<td><p>Integer</p></td>
<td><p>-</p></td>
<td><p>[1, 65535]</p></td>
</tr>
<tr class="row-even"><td><p>input_type</p></td>
<td><p>必选</p></td>
<td><p>矫正数据文件格式类型</p></td>
<td><p>String</p></td>
<td><p>-</p></td>
<td><p>IMAGE、BIN <br>IMAGE：图片文件数据 <br>BIN：满足推理的输入要求二进制<code class="docutils literal notranslate"><span class="pre">.bin</span></code>文件数据</p></td>
</tr>
<tr class="row-odd"><td><p>image_to_format</p></td>
<td><p>可选</p></td>
<td><p>图像格式转换</p></td>
<td><p>String</p></td>
<td><p>-</p></td>
<td><p>RGB、GRAY、BGR</p></td>
</tr>
<tr class="row-even"><td><p>normalize_mean</p></td>
<td><p>可选</p></td>
<td><p>图像归一化的均值<br/>dst = (src - mean) / std</p></td>
<td><p>Vector</p></td>
<td><p>-</p></td>
<td><p>3通道：[mean_1, mean_2, mean_3] <br/>1通道：[mean_1]</p></td>
</tr>
<tr class="row-odd"><td><p>normalize_std</p></td>
<td><p>可选</p></td>
<td><p>图像归一化的标准差<br/>dst = (src - mean) / std</p></td>
<td><p>Vector</p></td>
<td><p>-</p></td>
<td><p>3通道：[std_1, std_2, std_3] <br/>1通道：[std_1]</p></td>
</tr>
<tr class="row-even"><td><p>resize_width</p></td>
<td><p>可选</p></td>
<td><p>图像缩放宽度</p></td>
<td><p>Integer</p></td>
<td><p>-</p></td>
<td><p>[1, 65535]</p></td>
</tr>
<tr class="row-odd"><td><p>resize_height</p></td>
<td><p>可选</p></td>
<td><p>图像缩放高度</p></td>
<td><p>Integer</p></td>
<td><p>-</p></td>
<td><p>[1, 65535]</p></td>
</tr>
<tr class="row-even"><td><p>resize_method</p></td>
<td><p>可选</p></td>
<td><p>图像缩放算法</p></td>
<td><p>String</p></td>
<td><p>-</p></td>
<td><p>LINEAR、NEAREST、CUBIC<br/>LINEAR：线性插值<br/>NEARST：最邻近插值<br/>CUBIC：三次样条插值</p></td>
</tr>
<tr class="row-odd"><td><p>center_crop_width</p></td>
<td><p>可选</p></td>
<td><p>中心裁剪宽度</p></td>
<td><p>Integer</p></td>
<td><p>-</p></td>
<td><p>[1, 65535]</p></td>
</tr>
<tr class="row-even"><td><p>center_crop_height</p></td>
<td><p>可选</p></td>
<td><p>中心裁剪高度</p></td>
<td><p>Integer</p></td>
<td><p>-</p></td>
<td><p>[1, 65535]</p></td>
</tr>
</tbody>
</table>
<p>数据预处理参数配置如下所示：</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[data_preprocess_param]</span>
<span class="c1"># Calibration dataset path, the format is input_name_1:input_1_dir,input_name_2:input_2_dir</span>
<span class="c1"># Full quantification must provide correction dataset</span>
<span class="na">calibrate_path</span><span class="o">=</span><span class="s">input_name_1:/mnt/image/input_1_dir,input_name_2:input_2_dir</span>
<span class="c1"># Calibration data size</span>
<span class="na">calibrate_size</span><span class="o">=</span><span class="s">100</span>
<span class="c1"># Input type supports IMAGE or BIN</span>
<span class="c1"># When set to IMAGE, the image data will be read</span>
<span class="c1"># When set to BIN, the `.bin` binary file will be read</span>
<span class="na">input_type</span><span class="o">=</span><span class="s">IMAGE</span>
<span class="c1"># The output format of the preprocessed image</span>
<span class="c1"># Supports RGB or GRAY or BGR</span>
<span class="na">image_to_format</span><span class="o">=</span><span class="s">RGB</span>
<span class="c1"># Image normalization</span>
<span class="c1"># dst = (src - mean) / std</span>
<span class="na">normalize_mean</span><span class="o">=</span><span class="s">[127.5, 127.5, 127.5]</span>
<span class="na">normalize_std</span><span class="o">=</span><span class="s">[127.5, 127.5, 127.5]</span>
<span class="c1"># Image resize</span>
<span class="na">resize_width</span><span class="o">=</span><span class="s">224</span>
<span class="na">resize_height</span><span class="o">=</span><span class="s">224</span>
<span class="c1"># Resize method supports LINEAR or NEAREST or CUBIC</span>
<span class="na">resize_method</span><span class="o">=</span><span class="s">LINEAR</span>
<span class="c1"># Image center crop</span>
<span class="na">center_crop_width</span><span class="o">=</span><span class="s">224</span>
<span class="na">center_crop_height</span><span class="o">=</span><span class="s">224</span>
</pre></div>
</div>
</section>
</section>
<section id="id8">
<h2>权重量化<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h2>
<p>权重量化支持混合比特量化，同时也支持1~16之间的固定比特量化，比特数越低，模型压缩率越大，但是精度损失通常也比较大。下面对权重量化的使用方式和效果进行阐述。</p>
<section id="id9">
<h3>混合比特量化<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h3>
<p>目前权重量化支持混合比特量化，会根据模型参数的分布情况，根据用户设置的<code class="docutils literal notranslate"><span class="pre">init_scale</span></code>作为初始值，自动搜索出最适合当前层的比特数。配置参数的<code class="docutils literal notranslate"><span class="pre">bit_num</span></code>设置为0时，将启用混合比特量化。</p>
<p>混合比特权重量化转换命令的一般形式为：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite<span class="w"> </span>--fmk<span class="o">=</span>ModelType<span class="w"> </span>--modelFile<span class="o">=</span>ModelFilePath<span class="w"> </span>--outputFile<span class="o">=</span>ConvertedModelPath<span class="w"> </span>--configFile<span class="o">=</span>/mindspore/lite/tools/converter/quantizer/config/mixed_bit_weight_quant.cfg
</pre></div>
</div>
<p>混合比特权重量化配置文件如下所示：</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[common_quant_param]</span>
<span class="c1"># Supports WEIGHT_QUANT or FULL_QUANT</span>
<span class="na">quant_type</span><span class="o">=</span><span class="s">WEIGHT_QUANT</span>
<span class="c1"># Weight quantization support the number of bits [0,16], Set to 0 is mixed bit quantization, otherwise it is fixed bit quantization</span>
<span class="c1"># Full quantization support the number of bits [1,8]</span>
<span class="na">bit_num</span><span class="o">=</span><span class="s">0</span>
<span class="c1"># Layers with size of weights exceeds threshold `min_quant_weight_size` will be quantized.</span>
<span class="na">min_quant_weight_size</span><span class="o">=</span><span class="s">5000</span>
<span class="c1"># Layers with channel size of weights exceeds threshold `min_quant_weight_channel` will be quantized.</span>
<span class="na">min_quant_weight_channel</span><span class="o">=</span><span class="s">5</span>

<span class="k">[mixed_bit_weight_quant_param]</span>
<span class="c1"># Initialization scale in (0,1).</span>
<span class="c1"># A larger value can get a larger compression ratio, but it may also cause a larger error.</span>
<span class="na">init_scale</span><span class="o">=</span><span class="s">0.02</span>
</pre></div>
</div>
<p>用户可根据模型及自身需要对权重量化的参数作出调整。</p>
<blockquote>
<div><p>init_scale默认的初始值为0.02，搜索的压缩率相当与6-7固定比特的压缩效果。</p>
<p>针对稀疏结构模型，建议将init_scale设置为0.00003。</p>
</div></blockquote>
</section>
<section id="id10">
<h3>固定比特量化<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h3>
<p>固定比特的权重量化支持1~16之间的固定比特量化，用户可根据模型及自身需要对权重量化的参数作出调整。</p>
<p>固定比特权重量化转换命令的一般形式为：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite<span class="w"> </span>--fmk<span class="o">=</span>ModelType<span class="w"> </span>--modelFile<span class="o">=</span>ModelFilePath<span class="w"> </span>--outputFile<span class="o">=</span>ConvertedModelPath<span class="w"> </span>--configFile<span class="o">=</span>/mindspore/lite/tools/converter/quantizer/config/fixed_bit_weight_quant.cfg
</pre></div>
</div>
<p>固定比特权重量化配置文件如下所示：</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[common_quant_param]</span>
<span class="c1"># Supports WEIGHT_QUANT or FULL_QUANT</span>
<span class="na">quant_type</span><span class="o">=</span><span class="s">WEIGHT_QUANT</span>
<span class="c1"># Weight quantization support the number of bits [0,16], Set to 0 is mixed bit quantization, otherwise it is fixed bit quantization</span>
<span class="c1"># Full quantization support the number of bits [1,8]</span>
<span class="na">bit_num</span><span class="o">=</span><span class="s">8</span>
<span class="c1"># Layers with size of weights exceeds threshold `min_quant_weight_size` will be quantized.</span>
<span class="na">min_quant_weight_size</span><span class="o">=</span><span class="s">0</span>
<span class="c1"># Layers with channel size of weights exceeds threshold `min_quant_weight_channel` will be quantized.</span>
<span class="na">min_quant_weight_channel</span><span class="o">=</span><span class="s">16</span>
</pre></div>
</div>
</section>
<section id="id11">
<h3>部分模型精度结果<a class="headerlink" href="#id11" title="Permalink to this headline"></a></h3>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>模型</p></th>
<th class="head"><p>测试数据集</p></th>
<th class="head"><p>FP32模型精度</p></th>
<th class="head"><p>权重量化精度（8bit）</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/model_zoo/upload_20180427/inception_v3_2018_04_27.tgz">Inception_V3</a></p></td>
<td><p><a class="reference external" href="http://image-net.org/">ImageNet</a></p></td>
<td><p>77.60%</p></td>
<td><p>77.53%</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz">Mobilenet_V1_1.0_224</a></p></td>
<td><p><a class="reference external" href="http://image-net.org/">ImageNet</a></p></td>
<td><p>70.96%</p></td>
<td><p>70.56%</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224.tgz">Mobilenet_V2_1.0_224</a></p></td>
<td><p><a class="reference external" href="http://image-net.org/">ImageNet</a></p></td>
<td><p>71.56%</p></td>
<td><p>71.53%</p></td>
</tr>
</tbody>
</table>
<blockquote>
<div><p>以上所有结果均在x86环境上测得。</p>
</div></blockquote>
</section>
</section>
<section id="id12">
<h2>全量化<a class="headerlink" href="#id12" title="Permalink to this headline"></a></h2>
<p>针对需要提升模型运行速度、降低模型运行功耗的场景，可以使用训练后全量化功能。下面对全量化的使用方式和效果进行阐述。</p>
<p>全量化计算激活值的量化参数，用户需要提供校准数据集。校准数据集最好来自真实推理场景，能表征模型的实际输入情况，数量在100个左右。</p>
<p>针对图片数据，目前支持通道调整、归一化、缩放、裁剪等预处理的功能。用户可以根据推理时所需的预处理操作，设置相应的<span class="xref myst">参数</span>。</p>
<p>全量化转换命令的一般形式为：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite<span class="w"> </span>--fmk<span class="o">=</span>ModelType<span class="w"> </span>--modelFile<span class="o">=</span>ModelFilePath<span class="w"> </span>--outputFile<span class="o">=</span>ConvertedModelPath<span class="w"> </span>--configFile<span class="o">=</span>/mindspore/lite/tools/converter/quantizer/config/full_quant.cfg
</pre></div>
</div>
<p>全量化配置文件如下所示：</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[common_quant_param]</span>
<span class="c1"># Supports WEIGHT_QUANT or FULL_QUANT</span>
<span class="na">quant_type</span><span class="o">=</span><span class="s">FULL_QUANT</span>
<span class="c1"># Weight quantization support the number of bits [0,16], Set to 0 is mixed bit quantization, otherwise it is fixed bit quantization</span>
<span class="c1"># Full quantization support the number of bits [1,8]</span>
<span class="na">bit_num</span><span class="o">=</span><span class="s">8</span>
<span class="c1"># Layers with size of weights exceeds threshold `min_quant_weight_size` will be quantized.</span>
<span class="na">min_quant_weight_size</span><span class="o">=</span><span class="s">0</span>
<span class="c1"># Layers with channel size of weights exceeds threshold `min_quant_weight_channel` will be quantized.</span>
<span class="na">min_quant_weight_channel</span><span class="o">=</span><span class="s">16</span>

<span class="k">[data_preprocess_param]</span>
<span class="c1"># Calibration dataset path, the format is input_name_1:input_1_dir,input_name_2:input_2_dir</span>
<span class="c1"># Full quantification must provide correction dataset</span>
<span class="na">calibrate_path</span><span class="o">=</span><span class="s">input_name_1:/mnt/image/input_1_dir,input_name_2:input_2_dir</span>
<span class="c1"># Calibration data size</span>
<span class="na">calibrate_size</span><span class="o">=</span><span class="s">100</span>
<span class="c1"># Input type supports IMAGE or BIN</span>
<span class="c1"># When set to IMAGE, the image data will be read</span>
<span class="c1"># When set to BIN, the `.bin` binary file will be read</span>
<span class="na">input_type</span><span class="o">=</span><span class="s">IMAGE</span>
<span class="c1"># The output format of the preprocessed image</span>
<span class="c1"># Supports RGB or GRAY or BGR</span>
<span class="na">image_to_format</span><span class="o">=</span><span class="s">RGB</span>
<span class="c1"># Image normalization</span>
<span class="c1"># dst = (src - mean) / std</span>
<span class="na">normalize_mean</span><span class="o">=</span><span class="s">[127.5, 127.5, 127.5]</span>
<span class="na">normalize_std</span><span class="o">=</span><span class="s">[127.5, 127.5, 127.5]</span>
<span class="c1"># Image resize</span>
<span class="na">resize_width</span><span class="o">=</span><span class="s">224</span>
<span class="na">resize_height</span><span class="o">=</span><span class="s">224</span>
<span class="c1"># Resize method supports LINEAR or NEAREST or CUBIC</span>
<span class="na">resize_method</span><span class="o">=</span><span class="s">LINEAR</span>
<span class="c1"># Image center crop</span>
<span class="na">center_crop_width</span><span class="o">=</span><span class="s">224</span>
<span class="na">center_crop_height</span><span class="o">=</span><span class="s">224</span>

<span class="k">[full_quant_param]</span>
<span class="c1"># Activation quantized method supports MAX_MIN or KL or REMOVAL_OUTLIER</span>
<span class="na">activation_quant_method</span><span class="o">=</span><span class="s">MAX_MIN</span>
<span class="c1"># Whether to correct the quantization error. Recommended to set to true.</span>
<span class="na">bias_correction</span><span class="o">=</span><span class="s">true</span>
</pre></div>
</div>
<section id="id13">
<h3>部分模型精度结果<a class="headerlink" href="#id13" title="Permalink to this headline"></a></h3>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>模型</p></th>
<th class="head"><p>测试数据集</p></th>
<th class="head"><p>method_x</p></th>
<th class="head"><p>FP32模型精度</p></th>
<th class="head"><p>全量化精度（8bit）</p></th>
<th class="head"><p>说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/model_zoo/upload_20180427/inception_v3_2018_04_27.tgz">Inception_V3</a></p></td>
<td><p><a class="reference external" href="http://image-net.org/">ImageNet</a></p></td>
<td><p>KL</p></td>
<td><p>77.60%</p></td>
<td><p>77.40%</p></td>
<td><p>校准数据集随机选择ImageNet Validation数据集中的100张</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz">Mobilenet_V1_1.0_224</a></p></td>
<td><p><a class="reference external" href="http://image-net.org/">ImageNet</a></p></td>
<td><p>KL</p></td>
<td><p>70.96%</p></td>
<td><p>70.31%</p></td>
<td><p>校准数据集随机选择ImageNet Validation数据集中的100张</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224.tgz">Mobilenet_V2_1.0_224</a></p></td>
<td><p><a class="reference external" href="http://image-net.org/">ImageNet</a></p></td>
<td><p>MAX_MIN</p></td>
<td><p>71.56%</p></td>
<td><p>71.16%</p></td>
<td><p>校准数据集随机选择ImageNet Validation数据集中的100张</p></td>
</tr>
</tbody>
</table>
<blockquote>
<div><p>以上所有结果均在x86环境上测得。</p>
</div></blockquote>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="converter_tool.html" class="btn btn-neutral float-left" title="推理模型转换" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="data_preprocessing.html" class="btn btn-neutral float-right" title="预处理数据" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore Lite.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>