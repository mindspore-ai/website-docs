<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>使用Delegate支持第三方AI框架接入 &mdash; MindSpore Lite master documentation</title>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/lite.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/lite.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="基准测试工具" href="benchmark.html" />
    <link rel="prev" title="在线构建自定义算子" href="register_kernel.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">获取MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="downloads.html">下载MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="build.html">编译MindSpore Lite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/one_hour_introduction.html">一小时入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_cpp.html">体验C++极简推理Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_java.html">体验Java极简推理Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">基于JNI接口的Android应用开发</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/image_segmentation.html">基于Java接口的Android应用开发</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/train_lenet.html">基于C++接口实现端侧训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/train_lenet_java.html">基于Java接口实现端侧训练</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">端侧推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="converter_tool.html">推理模型转换</a></li>
<li class="toctree-l1"><a class="reference internal" href="post_training_quantization.html">训练后量化</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_preprocessing.html">预处理数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">执行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="micro.html">在轻量和小型系统上执行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="asic.html">专用芯片集成说明</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">端侧训练</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="converter_train.html">训练模型转换</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime_train.html">执行训练</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">第三方接入</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="register.html">自定义算子</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">使用Delegate支持第三方AI框架接入</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#delegate">Delegate使用</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">新增自定义Delegate类</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">实现初始化接口</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">实现构图接口</a></li>
<li class="toctree-l3"><a class="reference internal" href="#kernel">实现子图Kernel</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#lite">Lite框架调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="#npudelegate">NPUDelegate示例</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id5">新增NPUDelegate类</a></li>
<li class="toctree-l3"><a class="reference internal" href="#init">实现Init接口</a></li>
<li class="toctree-l3"><a class="reference internal" href="#build">实现Build接口</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">实现构图代码</a></li>
<li class="toctree-l3"><a class="reference internal" href="#npugraph">实现NPUGraph</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">其他工具</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">基准测试工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="cropper_tool.html">静态库剪裁工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="visual_tool.html">可视化工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="obfuscator_tool.html">模型混淆工具</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../architecture_lite.html">总体架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_lite.html">Lite算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_codegen.html">Codegen算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_lite.html">模型支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting_guide.html">问题定位指南</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>使用Delegate支持第三方AI框架接入</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/use/delegate.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="delegateai">
<h1>使用Delegate支持第三方AI框架接入<a class="headerlink" href="#delegateai" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">代理</span></code> <code class="docutils literal notranslate"><span class="pre">第三方接入</span></code> <code class="docutils literal notranslate"><span class="pre">自定义框架</span></code> <code class="docutils literal notranslate"><span class="pre">高级</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.6/docs/lite/docs/source_zh_cn/use/delegate.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.6/resource/_static/logo_source.png"></a></p>
<section id="id1">
<h2>概述<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<p>MindSpore Lite的Delegate接口用于支持第三方AI框架（例如：NPU、TensorRT）能快速接入Lite的推理流程。第三方框架可以是用户自己实现，也可以是业内其他开源的框架，一般都具备在线构图的能力，即可以将多个算子构建成一张子图发放给设备执行。如果用户想通过MindSpore Lite框架调度到其他框架的推理流程，可参考本文。</p>
</section>
<section id="delegate">
<h2>Delegate使用<a class="headerlink" href="#delegate" title="Permalink to this headline"></a></h2>
<p>使用Delegate接入第三方AI框架执行推理主要包含以下步骤：</p>
<ol class="arabic simple">
<li><p>新增自定义Delegate类：继承<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#delegate">Delegate</a>类实现自定义的Delegate。</p></li>
<li><p>实现初始化接口：<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#init">Init</a>接口实现判断运行设备是否支持Delegate框架，初始化Delegate资源等功能。</p></li>
<li><p>实现构图接口：<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#id24">Build</a>接口要实现算子支持判断、子图构建、在线构图功能。</p></li>
<li><p>实现子图Kernel：继承<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore_kernel.html#kernel">Kernel</a>实现Delegate的子图Kernel。</p></li>
</ol>
<section id="id2">
<h3>新增自定义Delegate类<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<p>自定义Delegate要继承自<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#delegate">Delegate</a>类。可以在构造函数中完成对第三方框架调度硬件设备有关config的初始化，如NPU指定频率、CPU指定线程数等。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">XXXDelegate</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">Delegate</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="n">XXXDelegate</span><span class="p">()</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span>

<span class="w">  </span><span class="o">~</span><span class="n">XXXDelegate</span><span class="p">()</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span>

<span class="w">  </span><span class="n">Status</span><span class="w"> </span><span class="nf">Init</span><span class="p">()</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">  </span><span class="n">Status</span><span class="w"> </span><span class="nf">Build</span><span class="p">(</span><span class="n">DelegateModel</span><span class="w"> </span><span class="o">*</span><span class="n">model</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="id3">
<h3>实现初始化接口<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h3>
<p><a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#init">Init</a>接口会在<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#model">Model</a>的<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#build">Build</a>流程中被调用。具体的调用位置在MindSpore Lite内部代码<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.6/mindspore/lite/src/lite_session.cc#L696">LiteSession::Init</a>函数中。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Status</span><span class="w"> </span><span class="nf">XXXDelegate::Init</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// 1. Check whether the inference device matches the delegate framework.</span>
<span class="w">  </span><span class="c1">// 2. Initialize delegate related resources.</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="id4">
<h3>实现构图接口<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<p>构图接口<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#id24">Build(DelegateModel *model)</a>接口的入参是<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#delegatemodel">DelegateModel</a>的实例。</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">DelegateModel</span></code>中，<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#kernel">std::vector&lt;kernel::Kernel *&gt; *kernels_</a>是已经完成MindSpore Lite内置算子注册、经过拓扑排序的算子列表。</p>
<p><a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#primitives">const std::map&lt;kernel::Kernel *, const schema::Primitive *&gt; primitives_</a>保存了每个算子对应的属性值<code class="docutils literal notranslate"><span class="pre">schema::Primitive</span></code>，用于解析每个算子的原始属性信息。</p>
</div></blockquote>
<p>Build会在<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#model">Model</a>的<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#build">Build</a>接口被调用。具体的位置在MindSpore Lite内部代码<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.6/mindspore/lite/src/scheduler.cc#L132">Schedule::Schedule</a>函数中，此时已完成内置算子选择，算子存放在DelegateModel的<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#kernel">Kernel列表</a>中。Build需要实现以下功能：</p>
<ol class="arabic simple">
<li><p>遍历Kernel列表，调用<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#getprimitive">GetPrimitive</a>获取每个算子对应的属性值，解析该算子的属性值，判断Delegate框架是否支持。</p></li>
<li><p>对连续可支持的一段算子列表，构建一张Delegate子图，调用<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#replace">Replace</a>用子图Kernel去替换这段连续的算子。</p></li>
</ol>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Status</span><span class="w"> </span><span class="nf">XXXDelegate::Build</span><span class="p">(</span><span class="n">DelegateModel</span><span class="w"> </span><span class="o">*</span><span class="n">model</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">KernelIter</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">BeginKernelIterator</span><span class="p">();</span><span class="w">                   </span><span class="c1">// Record the start operator position supported by the Delegate</span>
<span class="w">  </span><span class="n">KernelIter</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">BeginKernelIterator</span><span class="p">();</span><span class="w">                    </span><span class="c1">// Record the end operator position supported by the Delegate</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">KernelIter</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">BeginKernelIterator</span><span class="p">();</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">EndKernelIterator</span><span class="p">();</span><span class="w"> </span><span class="n">iter</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="o">*</span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">iter</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">IsSupport</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">GetPrimitive</span><span class="p">(</span><span class="n">kernel</span><span class="p">)))</span><span class="w"> </span><span class="p">{</span><span class="w">           </span><span class="c1">// Check whether the Delegate framework supports the kernel according to the primitive</span>
<span class="w">      </span><span class="n">end</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iter</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w">                                                        </span><span class="c1">// The current kernel is not supported, and the sub-graph is truncated</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">from</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">end</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">xxx_graph_kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CreateXXXGraph</span><span class="p">(</span><span class="n">from</span><span class="p">,</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="p">);</span><span class="w">   </span><span class="c1">// Create a Delegate sub-graph Kernel</span>
<span class="w">        </span><span class="n">iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">Replace</span><span class="p">(</span><span class="n">from</span><span class="p">,</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">xxx_graph_kernel</span><span class="p">);</span><span class="w">     </span><span class="c1">// Replace the supported kernels list with a Delegate sub-graph Kernel</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">      </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">      </span><span class="n">end</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">RET_OK</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="kernel">
<h3>实现子图Kernel<a class="headerlink" href="#kernel" title="Permalink to this headline"></a></h3>
<p>上述<code class="docutils literal notranslate"><span class="pre">CreateXXXGraph</span></code>接口要返回一张Delegate的子图，示例代码如下所示:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="o">*</span><span class="nf">XXXDelegate::CreateXXXGraph</span><span class="p">(</span><span class="n">KernelIter</span><span class="w"> </span><span class="n">from</span><span class="p">,</span><span class="w"> </span><span class="n">KernelIter</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">DelegateModel</span><span class="w"> </span><span class="o">*</span><span class="n">model</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">in_tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GraphInTensors</span><span class="p">(...);</span><span class="w">    </span><span class="c1">// Find the input tensors of the Delegate sub-graph</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">out_tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GraphOutTensors</span><span class="p">(...);</span><span class="w">  </span><span class="c1">// Find the output tensors of the Delegate sub-graph</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">graph_kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">nothrow</span><span class="p">)</span><span class="w"> </span><span class="n">XXXGraph</span><span class="p">(</span><span class="n">in_tensors</span><span class="p">,</span><span class="w"> </span><span class="n">out_tensors</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">graph_kernel</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New XXX Graph failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="c1">// Build graph online, load model, etc.</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">graph_kernel</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Delegate子图<code class="docutils literal notranslate"><span class="pre">XXXGraph</span></code>的定义要继承自<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore_kernel.html#kernel">Kernel</a>，如下代码所示。对这张子图，要注意：</p>
<ol class="arabic simple">
<li><p>要根据原始的Kernel列表找到正确的in_tensors和out_tensors，以便Execute时，能找到正确的输入tensor和输入数据，并将输出数据写回到正确的地址中。</p></li>
<li><p>重写对应的Prepare、Resize、Execute接口。其中，<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore_kernel.html#prepare">Prepare</a>会在Model的<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#build">Build</a>阶段调用。<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore_kernel.html#execute">Execute</a>会在Model的<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#predict">Predict</a>阶段被调用。<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore_kernel.html#resize">ReSize</a>会在Model的<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore_kernel.html#resize">Resize</a>阶段被调用。</p></li>
</ol>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">XXXGraph</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="n">XXXGraph</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs</span><span class="p">)</span>
<span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="k">nullptr</span><span class="p">,</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{}</span>

<span class="w">  </span><span class="o">~</span><span class="n">XXXGraph</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="nf">Prepare</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Generally, the model will be built only once, so Prepare is also called once.</span>
<span class="w">    </span><span class="c1">// Do something without input data, such as pack the constant weight tensor, etc.</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="nf">Execute</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Obtain input data from in_tensors.</span>
<span class="w">    </span><span class="c1">// Execute the inference process.</span>
<span class="w">    </span><span class="c1">// Write the result back to out_tensors.</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="nf">ReSize</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Support dynamic shape, and input shape will changed.</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
</section>
</section>
<section id="lite">
<h2>Lite框架调度<a class="headerlink" href="#lite" title="Permalink to this headline"></a></h2>
<p>Lite框架要调度用户自定义的Delegate，在创建<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#context">Context</a>时，需要通过<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#setdelegate">SetDelegate</a>设置自定义Delegate指针，见以下示例代码。再通过<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#build">Build</a>传递给Lite框架。如果Context中的Delegate为空指针，推理流程会调用到Lite框架内置的推理。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">Context</span><span class="o">&gt;</span><span class="p">();</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">context</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New context failed&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">auto</span><span class="w"> </span><span class="n">delegate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">XXXDelegate</span><span class="o">&gt;</span><span class="p">();</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">delegate</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New XXX delegate failed&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">context</span><span class="o">-&gt;</span><span class="n">SetDelegate</span><span class="p">(</span><span class="n">delegate</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">nothrow</span><span class="p">)</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Model</span><span class="p">();</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">model</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New Model failed.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>
<span class="c1">// Assuming that we have read a ms file and stored in the address pointed by model_buf</span>
<span class="k">auto</span><span class="w"> </span><span class="n">build_ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">Build</span><span class="p">(</span><span class="n">model_buf</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kMindIR</span><span class="p">,</span><span class="w"> </span><span class="n">context</span><span class="p">);</span>
<span class="k">delete</span><span class="p">[](</span><span class="n">model_buf</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">build_ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Build model failed.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="npudelegate">
<h2>NPUDelegate示例<a class="headerlink" href="#npudelegate" title="Permalink to this headline"></a></h2>
<p>目前，MindSpore Lite对于NPU后端的集成采用了<a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.6/mindspore/lite/src/delegate/npu/npu_delegate.h#L29">NPUDelegate</a>接口。本教程对NPUDelegate做简单说明，使用户能快速了解Delegate相关API的使用。</p>
<section id="id5">
<h3>新增NPUDelegate类<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h3>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">NPUDelegate</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">Delegate</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="k">explicit</span><span class="w"> </span><span class="n">NPUDelegate</span><span class="p">(</span><span class="n">lite</span><span class="o">::</span><span class="n">NpuDeviceInfo</span><span class="w"> </span><span class="n">device_info</span><span class="p">)</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">Delegate</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">frequency_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">device_info</span><span class="p">.</span><span class="n">frequency_</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>

<span class="w">  </span><span class="o">~</span><span class="n">NPUDelegate</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w">  </span><span class="n">Status</span><span class="w"> </span><span class="nf">Init</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w">  </span><span class="n">Status</span><span class="w"> </span><span class="nf">Build</span><span class="p">(</span><span class="n">DelegateModel</span><span class="w"> </span><span class="o">*</span><span class="n">model</span><span class="p">)</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w"> </span><span class="k">protected</span><span class="o">:</span>
<span class="w">  </span><span class="c1">// Analyze a kernel and its attribute.</span>
<span class="w">  </span><span class="c1">// If NPU supports it, return an NPUOp, which has the information of connection relationship with other kernels and the attributes.</span>
<span class="w">  </span><span class="c1">// If not support, return null pointer.</span>
<span class="w">  </span><span class="n">NPUOp</span><span class="w"> </span><span class="o">*</span><span class="n">GetOP</span><span class="p">(</span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="o">*</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">schema</span><span class="o">::</span><span class="n">Primitive</span><span class="w"> </span><span class="o">*</span><span class="n">primitive</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Construct a NPU sub-graph with a continuous NPUOps</span>
<span class="w">  </span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="o">*</span><span class="nf">CreateNPUGraph</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">NPUOp</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">ops</span><span class="p">,</span><span class="w"> </span><span class="n">DelegateModel</span><span class="w"> </span><span class="o">*</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">KernelIter</span><span class="w"> </span><span class="n">from</span><span class="p">,</span>
<span class="w">                                 </span><span class="n">KernelIter</span><span class="w"> </span><span class="n">end</span><span class="p">);</span>

<span class="w">  </span><span class="n">NPUManager</span><span class="w"> </span><span class="o">*</span><span class="n">npu_manager_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="n">NPUPassManager</span><span class="w"> </span><span class="o">*</span><span class="n">pass_manager_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">schema</span><span class="o">::</span><span class="n">PrimitiveType</span><span class="p">,</span><span class="w"> </span><span class="n">NPUGetOp</span><span class="o">&gt;</span><span class="w"> </span><span class="n">op_func_lists_</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">frequency_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w">  </span><span class="c1">// NPU frequency</span>
<span class="p">};</span>
</pre></div>
</div>
</section>
<section id="init">
<h3>实现Init接口<a class="headerlink" href="#init" title="Permalink to this headline"></a></h3>
<p><a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.6/mindspore/lite/src/delegate/npu/npu_delegate.cc#L75">Init</a>接口实现和NPU有关的资源申请。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Status</span><span class="w"> </span><span class="nf">NPUDelegate::Init</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">npu_manager_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">nothrow</span><span class="p">)</span><span class="w"> </span><span class="n">NPUManager</span><span class="p">();</span><span class="w">       </span><span class="c1">// NPU manager of model buffer and client.</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">npu_manager_</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New npu manager failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">npu_manager_</span><span class="o">-&gt;</span><span class="n">IsSupportNPU</span><span class="p">())</span><span class="w"> </span><span class="p">{</span><span class="w">                  </span><span class="c1">// Check whether the current device supports NPU.</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">DEBUG</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Checking npu is unsupported.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">RET_NOT_SUPPORT</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">pass_manager_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">nothrow</span><span class="p">)</span><span class="w"> </span><span class="n">NPUPassManager</span><span class="p">();</span><span class="w">  </span><span class="c1">// The default format of MindSpore Lite is NHWC, and the default format of NPU is NCHW. The NPUPassManager is used to pack data between the sub-graphs.</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">pass_manager_</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New npu pass manager failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Initialize op_func lists. Get the correspondence between kernel type and GetOP function.</span>
<span class="w">  </span><span class="n">op_func_lists_</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">RET_OK</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="build">
<h3>实现Build接口<a class="headerlink" href="#build" title="Permalink to this headline"></a></h3>
<p>Build接口解析DelegateModel实例，主要实现算子支持判断、子图构建、在线构图等功能。下面<a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.6/mindspore/lite/src/delegate/npu/npu_delegate.cc#L163">示例代码</a>是NPUDelegate Build接口的实现。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Status</span><span class="w"> </span><span class="nf">NPUDelegate::Build</span><span class="p">(</span><span class="n">DelegateModel</span><span class="w"> </span><span class="o">*</span><span class="n">model</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">KernelIter</span><span class="w"> </span><span class="n">from</span><span class="p">,</span><span class="w"> </span><span class="n">end</span><span class="p">;</span><span class="w">                     </span><span class="c1">// Record the start and end positions of kernel supported by the NPU sub-graph.</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">NPUOp</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">npu_ops</span><span class="p">;</span><span class="w">             </span><span class="c1">// Save all NPUOp used to construct an NPU sub-graph.</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">graph_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">KernelIter</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">BeginKernelIterator</span><span class="p">();</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">EndKernelIterator</span><span class="p">();</span><span class="w"> </span><span class="n">iter</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="o">*</span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">iter</span><span class="p">;</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">npu_op</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetOP</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">GetPrimitive</span><span class="p">(</span><span class="n">kernel</span><span class="p">));</span><span class="w">  </span><span class="c1">// Obtain an NPUOp according to the kernel and the primitive. Each NPUOp contains information such as input tensors, output tensors and operator attribute.</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">npu_op</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">                </span><span class="c1">// NPU supports the current kernel.</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">npu_ops</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iter</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">      </span><span class="n">npu_ops</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">npu_op</span><span class="p">);</span>
<span class="w">      </span><span class="n">end</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iter</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w">                                 </span><span class="c1">// NPU does not support the current kernel.</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">npu_ops</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">npu_graph_kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CreateNPUGraph</span><span class="p">(</span><span class="n">npu_ops</span><span class="p">);</span><span class="w">  </span><span class="c1">// Create a NPU sub-graph kernel.</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">npu_graph_kernel</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">          </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Create NPU Graph failed.&quot;</span><span class="p">;</span>
<span class="w">          </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="n">npu_graph_kernel</span><span class="o">-&gt;</span><span class="n">set_name</span><span class="p">(</span><span class="s">&quot;NpuGraph&quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">to_string</span><span class="p">(</span><span class="n">graph_index</span><span class="o">++</span><span class="p">));</span>
<span class="w">        </span><span class="n">iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">Replace</span><span class="p">(</span><span class="n">from</span><span class="p">,</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">npu_graph_kernel</span><span class="p">);</span><span class="w">  </span><span class="c1">// Replace the supported kernel list with a NPU sub-graph kernel.</span>
<span class="w">        </span><span class="n">npu_ops</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">npu_manager_</span><span class="o">-&gt;</span><span class="n">LoadOMModel</span><span class="p">();</span><span class="w">    </span><span class="c1">// Build model online. Load NPU model.</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">RET_OK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;NPU client load model failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">RET_OK</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="id6">
<h3>实现构图代码<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<p>以下<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.6/mindspore/lite/src/delegate/npu/npu_delegate.cc#L273">示例代码</a>是NPUDelegate的CreateNPUGraph接口，用于生成一张NPU子图。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="o">*</span><span class="nf">NPUDelegate::CreateNPUGraph</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">NPUOp</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">ops</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">in_tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GraphInTensors</span><span class="p">(</span><span class="n">ops</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">out_tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GraphOutTensors</span><span class="p">(</span><span class="n">ops</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">graph_kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">nothrow</span><span class="p">)</span><span class="w"> </span><span class="n">NPUGraph</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span><span class="w"> </span><span class="n">npu_manager_</span><span class="p">,</span><span class="w"> </span><span class="n">in_tensors</span><span class="p">,</span><span class="w"> </span><span class="n">out_tensors</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">graph_kernel</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">DEBUG</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New NPU Graph failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">graph_kernel</span><span class="o">-&gt;</span><span class="n">Init</span><span class="p">();</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">RET_OK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">DEBUG</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;NPU Graph Init failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">graph_kernel</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="npugraph">
<h3>实现NPUGraph<a class="headerlink" href="#npugraph" title="Permalink to this headline"></a></h3>
<p><a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.6/mindspore/lite/src/delegate/npu/npu_graph.h#L29">NPUGraph</a>继承自<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore_kernel.html#kernel">Kernel</a>，需要重写Prepare、Execute、ReSize接口。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">NPUGraph</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="n">NPUGraph</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">NPUOp</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">npu_ops</span><span class="p">,</span><span class="w"> </span><span class="n">NPUManager</span><span class="w"> </span><span class="o">*</span><span class="n">npu_manager</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">inputs</span><span class="p">,</span>
<span class="w">           </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs</span><span class="p">)</span>
<span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="k">nullptr</span><span class="p">,</span><span class="w"> </span><span class="k">nullptr</span><span class="p">),</span><span class="w"> </span><span class="n">npu_ops_</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">npu_ops</span><span class="p">)),</span><span class="w"> </span><span class="n">npu_manager_</span><span class="p">(</span><span class="n">npu_manager</span><span class="p">)</span><span class="w"> </span><span class="p">{}</span>

<span class="w">  </span><span class="o">~</span><span class="n">NPUGraph</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="nf">Prepare</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="nf">Execute</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="nf">ReSize</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span><span class="w">               </span><span class="c1">// NPU does not support dynamic shapes.</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;NPU does not support the resize function temporarily.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">lite</span><span class="o">::</span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w"> </span><span class="k">protected</span><span class="o">:</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">NPUOp</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">npu_ops_</span><span class="p">{};</span>
<span class="w">  </span><span class="n">NPUManager</span><span class="w"> </span><span class="o">*</span><span class="n">npu_manager_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span><span class="w">  </span>
<span class="w">  </span><span class="n">NPUExecutor</span><span class="w"> </span><span class="o">*</span><span class="n">executor_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span><span class="w">     </span><span class="c1">// NPU inference executor.</span>
<span class="p">};</span>
</pre></div>
</div>
<p><a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.6/mindspore/lite/src/delegate/npu/npu_graph.cc#L306">NPUGraph::Prepare</a>接口主要实现:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">NPUGraph::Prepare</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Find the mapping relationship between hiai::AiTensor defined by NPU and MSTensor defined by MindSpore Lite</span>
<span class="p">}</span>
</pre></div>
</div>
<p><a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.6/mindspore/lite/src/delegate/npu/npu_graph.cc#L322">NPUGraph::Execute</a>接口主要实现:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">NPUGraph::Execute</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// 1. Processing input: copy input data from MSTensor to hiai::AiTensor</span>
<span class="w">  </span><span class="c1">// 2. Perform inference</span>
<span class="w">  </span><span class="n">executor_</span><span class="o">-&gt;</span><span class="n">Execute</span><span class="p">();</span>
<span class="w">  </span><span class="c1">// 3. Processing output: copy output data from hiai::AiTensor to MSTensor</span>
<span class="p">}</span>
</pre></div>
</div>
<blockquote>
<div><p><a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/r1.6/use/npu_info.html">NPU</a>是MindSpore Lite开发人员对接的第三方AI框架，使用方法和用户自定义的Delegate略有不同，既可以通过<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#setdelegate">SetDelegate</a>设置<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#context">Context</a>，也可以设置Context的<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#mutabledeviceinfo">MutableDeviceInfo</a>，增加NPU设备的描述<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.6/api_cpp/mindspore.html#kirinnpudeviceinfo">KirinNPUDeviceInfo</a>。</p>
</div></blockquote>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="register_kernel.html" class="btn btn-neutral float-left" title="在线构建自定义算子" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="benchmark.html" class="btn btn-neutral float-right" title="基准测试工具" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore Lite.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>