<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>在线构建自定义算子 &mdash; MindSpore Lite master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script src="../_static/js/lite.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="使用Delegate支持第三方AI框架接入" href="delegate.html" />
    <link rel="prev" title="离线构建自定义算子" href="converter_register.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">获取MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="downloads.html">下载MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="build.html">编译MindSpore Lite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/one_hour_introduction.html">一小时入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_cpp.html">体验C++极简推理Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_server_inference_cpp.html">体验C++极简并发推理Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_java.html">体验Java极简推理Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_server_inference_java.html">体验Java极简并发推理Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">基于JNI接口的Android应用开发</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/image_segmentation.html">基于Java接口的Android应用开发</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/train_lenet.html">基于C++接口实现端侧训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/train_lenet_java.html">基于Java接口实现端侧训练</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">端侧推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="converter_tool.html">推理模型转换</a></li>
<li class="toctree-l1"><a class="reference internal" href="post_training_quantization.html">训练后量化</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_preprocessing.html">预处理数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">执行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="micro.html">在MCU或小型系统上执行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="asic.html">专用芯片集成说明</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">端侧训练</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="converter_train.html">训练模型转换</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime_train.html">执行训练</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">服务端推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="runtime_server_inference.html">执行并发推理</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">第三方接入</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="register.html">自定义算子</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="converter_register.html">离线构建自定义算子</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">在线构建自定义算子</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#如何实现自定义算子">如何实现自定义算子</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#确定算子类型">确定算子类型</a></li>
<li class="toctree-l4"><a class="reference internal" href="#通用算子">通用算子</a></li>
<li class="toctree-l4"><a class="reference internal" href="#custom算子">Custom算子</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#自定义gpu算子">自定义GPU算子</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#算子注册">算子注册</a></li>
<li class="toctree-l4"><a class="reference internal" href="#算子实现">算子实现</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="delegate.html">使用Delegate支持第三方AI框架接入</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">其他工具</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">基准测试工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="cropper_tool.html">静态库裁剪工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="visual_tool.html">可视化工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="obfuscator_tool.html">模型混淆工具</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../architecture_lite.html">总体架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_lite.html">Lite算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_codegen.html">Codegen算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_lite.html">模型支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting_guide.html">问题定位指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../log.html">日志</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="register.html">自定义算子</a> &raquo;</li>
      <li>在线构建自定义算子</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/use/register_kernel.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="在线构建自定义算子">
<h1>在线构建自定义算子<a class="headerlink" href="#在线构建自定义算子" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.8/docs/lite/docs/source_zh_cn/use/register_kernel.md"><img alt="查看源文件" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_source.png" /></a></p>
<section id="如何实现自定义算子">
<h2>如何实现自定义算子<a class="headerlink" href="#如何实现自定义算子" title="Permalink to this headline"></a></h2>
<p>MindSpore Lite当前提供了一套南向的算子注册机制，如果用户想通过MindSpore Lite框架调度到自己的算子实现上，可参考本文。</p>
<p>实现自定义算子大概有以下几个步骤：</p>
<ol class="arabic simple">
<li><p>确定算子类型 ：分为通用算子与Custom算子。</p></li>
<li><p>算子实现：继承Kernel类实现自定义算子，并注册进MindSpore Lite。</p></li>
<li><p>算子InferShape：继承mindspore::kernel::KernelInteface实现自定义算子的InferShape能力，并注册进MindSpore Lite。</p></li>
</ol>
<section id="确定算子类型">
<h3>确定算子类型<a class="headerlink" href="#确定算子类型" title="Permalink to this headline"></a></h3>
<p>查看mindspore/lite/schema/ops.fbs中的算子原型定义，确认要注册实现的算子原型是否在PrimitiveType中有定义，有定义的话则要注册的算子为通用算子，可以按照已有的IR直接实现算子与注册，否则即为Custom算子。</p>
</section>
<section id="通用算子">
<h3>通用算子<a class="headerlink" href="#通用算子" title="Permalink to this headline"></a></h3>
<p>整个算子的实现、注册、infershape等相关的代码可以参看代码仓里的<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.8/mindspore/lite/test/ut/src/registry/registry_test.cc">样例</a>。</p>
<section id="通用算子实现">
<h4>通用算子实现<a class="headerlink" href="#通用算子实现" title="Permalink to this headline"></a></h4>
<p>继承<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.8/api_cpp/mindspore_kernel.html">mindspore::kernel::Kernel</a>，重载实现必要的接口。以自定义一个Add算子为例：</p>
<ol class="arabic simple">
<li><p>算子继承Kernel。</p></li>
<li><p>PreProcess()对内存进行了预分配。</p></li>
<li><p>Execute()对input进行了相加。</p></li>
</ol>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="p">;</span>

<span class="k">class</span><span class="w"> </span><span class="nc">TestCustomAdd</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">Kernel</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="n">TestCustomAdd</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs</span><span class="p">,</span>
<span class="w">                </span><span class="k">const</span><span class="w"> </span><span class="n">schema</span><span class="o">::</span><span class="n">Primitive</span><span class="w"> </span><span class="o">*</span><span class="n">primitive</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">lite</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="o">*</span><span class="n">ctx</span><span class="p">)</span>
<span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">Kernel</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">primitive</span><span class="p">,</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span><span class="w"> </span><span class="p">{}</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">Prepare</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">Execute</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="nf">ReSize</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>

<span class="w"> </span><span class="k">private</span><span class="o">:</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">PreProcess</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">*</span><span class="n">output</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">outputs_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="c1">// malloc data for output tensor</span>
<span class="w">      </span><span class="k">auto</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">output</span><span class="o">-&gt;</span><span class="n">MutableData</span><span class="p">();</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Get data failed&quot;</span><span class="p">;</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">TestCustomAdd::Execute</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">inputs_</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteParamInvalid</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">PreProcess</span><span class="p">();</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="o">*</span><span class="n">in0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">inputs_</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">Data</span><span class="p">().</span><span class="n">get</span><span class="p">());</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="o">*</span><span class="n">in1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">inputs_</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">Data</span><span class="p">().</span><span class="n">get</span><span class="p">());</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">outputs_</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">MutableData</span><span class="p">());</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">num</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outputs_</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">ElementNum</span><span class="p">();</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">in1</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="通用算子注册">
<h4>通用算子注册<a class="headerlink" href="#通用算子注册" title="Permalink to this headline"></a></h4>
<p>当前有提供现成的宏<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.8/api_cpp/mindspore_registry.html#register-kernel">REGISTER_KERNEL</a>可以进行算子注册，实现步骤如下：</p>
<ol class="arabic simple">
<li><p>函数TestCustomAddCreator用来创建Kernel。</p></li>
<li><p>通过宏REGISTER_KERNEL进行Kernel注册，这里生产商假定为BuiltInTest。</p></li>
</ol>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">schema</span><span class="o">::</span><span class="n">PrimitiveType_AddFusion</span><span class="p">;</span>

<span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">Kernel</span><span class="o">&gt;</span><span class="w"> </span><span class="n">TestCustomAddCreator</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">inputs</span><span class="p">,</span>
<span class="w">                                             </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs</span><span class="p">,</span>
<span class="w">                                             </span><span class="k">const</span><span class="w"> </span><span class="n">schema</span><span class="o">::</span><span class="n">Primitive</span><span class="w"> </span><span class="o">*</span><span class="n">primitive</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">lite</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="o">*</span><span class="n">ctx</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">TestCustomAdd</span><span class="o">&gt;</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">primitive</span><span class="p">,</span><span class="w"> </span><span class="n">ctx</span><span class="p">);</span>
<span class="p">}</span>
<span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">kFloat32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat32</span><span class="p">;</span>

<span class="n">REGISTER_KERNEL</span><span class="p">(</span><span class="n">CPU</span><span class="p">,</span><span class="w"> </span><span class="n">BuiltInTest</span><span class="p">,</span><span class="w"> </span><span class="n">kFloat32</span><span class="p">,</span><span class="w"> </span><span class="n">PrimitiveType_AddFusion</span><span class="p">,</span><span class="w"> </span><span class="n">TestCustomAddCreator</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="通用算子infershape">
<h4>通用算子InferShape<a class="headerlink" href="#通用算子infershape" title="Permalink to this headline"></a></h4>
<p>继承KernelInterface后重载Infer函数，实现InferShape能力。实现步骤如下：</p>
<ol class="arabic simple">
<li><p>继承<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.8/api_cpp/mindspore_kernel.html#kernelinterface">KernelInterface</a>。</p></li>
<li><p>重载实现Infer函数，推导出output tensor的shape，format，data_type。</p></li>
</ol>
<p>这里以自定义Add算子为例：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kernel</span><span class="o">::</span><span class="n">KernelInterface</span><span class="p">;</span>

<span class="k">class</span><span class="w"> </span><span class="nc">TestCustomAddInfer</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">KernelInterface</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="n">TestCustomAddInfer</span><span class="p">()</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span>
<span class="w">  </span><span class="o">~</span><span class="n">TestCustomAddInfer</span><span class="p">()</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span>
<span class="w">  </span><span class="n">Status</span><span class="w"> </span><span class="nf">Infer</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">*</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">*</span><span class="n">outputs</span><span class="p">,</span>
<span class="w">               </span><span class="k">const</span><span class="w"> </span><span class="n">schema</span><span class="o">::</span><span class="n">Primitive</span><span class="w"> </span><span class="o">*</span><span class="n">primitive</span><span class="p">)</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="p">(</span><span class="o">*</span><span class="n">outputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">SetFormat</span><span class="p">((</span><span class="o">*</span><span class="n">inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">format</span><span class="p">());</span>
<span class="w">    </span><span class="p">(</span><span class="o">*</span><span class="n">outputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">SetDataType</span><span class="p">((</span><span class="o">*</span><span class="n">inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">DataType</span><span class="p">());</span>
<span class="w">    </span><span class="p">(</span><span class="o">*</span><span class="n">outputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">SetShape</span><span class="p">((</span><span class="o">*</span><span class="n">inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">Shape</span><span class="p">());</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
</section>
<section id="通用算子infershape注册">
<h4>通用算子InferShape注册<a class="headerlink" href="#通用算子infershape注册" title="Permalink to this headline"></a></h4>
<p>当前有提供现成的宏<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.8/api_cpp/mindspore_registry.html#register-kernel-interface">REGISTER_KERNEL_INTERFACE</a>可以进行算子InferShape注册，步骤如下：</p>
<ol class="arabic simple">
<li><p>函数CustomAddInferCreator用来创建KernelInterface实例。</p></li>
<li><p>调用REGISTER_KERNEL_INTERFACE宏对通用算子InferShape进行注册，这里生产商假定为BuiltInTest。</p></li>
</ol>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">KernelInterface</span><span class="o">&gt;</span><span class="w"> </span><span class="n">CustomAddInferCreator</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">TestCustomAddInfer</span><span class="o">&gt;</span><span class="p">();</span><span class="w"> </span><span class="p">}</span>

<span class="n">REGISTER_KERNEL_INTERFACE</span><span class="p">(</span><span class="n">BuiltInTest</span><span class="p">,</span><span class="w"> </span><span class="n">PrimitiveType_AddFusion</span><span class="p">,</span><span class="w"> </span><span class="n">CustomAddInferCreator</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="custom算子">
<h3>Custom算子<a class="headerlink" href="#custom算子" title="Permalink to this headline"></a></h3>
<p>Custom算子的解析、创建、操作等相关的代码可以参看代码仓里的<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.8/mindspore/lite/test/ut/tools/converter/registry/pass_registry_test.cc">样例</a>。</p>
<section id="custom算子定义">
<h4>Custom算子定义<a class="headerlink" href="#custom算子定义" title="Permalink to this headline"></a></h4>
<div class="highlight-css notranslate"><div class="highlight"><pre><span></span><span class="nt">table</span><span class="w"> </span><span class="nt">Attribute</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="n">string</span><span class="p">;</span>
<span class="w">    </span><span class="n">data</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="n">ubyte</span><span class="p">];</span>
<span class="p">}</span>

<span class="nt">table</span><span class="w"> </span><span class="nt">Custom</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">type</span><span class="p">:</span><span class="w"> </span><span class="n">string</span><span class="p">;</span>
<span class="w">    </span><span class="n">attr</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="n">Attribute</span><span class="p">];</span>
<span class="p">}</span>
</pre></div>
</div>
<p>属性是以字典的形式进行存储：name解释了属性名，data里存储了属性内容的字节流。
type：Custom算子的类型。</p>
</section>
<section id="custom算子创建">
<h4>Custom算子创建<a class="headerlink" href="#custom算子创建" title="Permalink to this headline"></a></h4>
<p>通过转换工具<code class="docutils literal notranslate"><span class="pre">Converter</span></code>的Pass注册接口，可以注册用户自己的Pass，用以导出想要的算子结构。这里以AddN算子转为一个Custom算子为例：</p>
<ol class="arabic simple">
<li><p>设Custom算子存在”input_num”、”op_kind”属性。</p></li>
<li><p>通过自定义Pass子类，实现Custom算子的转换与创建。</p></li>
<li><p>注册自定义Pass类。</p></li>
</ol>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">namespace</span><span class="w"> </span><span class="nn">mindspore</span><span class="o">::</span><span class="nn">opt</span><span class="w"> </span><span class="p">{</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Test2Fusion</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">Pass</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="n">AnfNodePtr</span><span class="w"> </span><span class="n">CreateCustomOp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">FuncGraphPtr</span><span class="w"> </span><span class="n">func_graph</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">CNodePtr</span><span class="w"> </span><span class="n">cnode</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">func_graph</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="n">cnode</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">primc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">ops</span><span class="o">::</span><span class="n">Custom</span><span class="o">&gt;</span><span class="p">();</span><span class="w">      </span><span class="c1">// 创建Primitive，存储算子属性</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">primc</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">primc</span><span class="o">-&gt;</span><span class="n">set_type</span><span class="p">(</span><span class="s">&quot;Custom_AddN&quot;</span><span class="p">);</span><span class="w">        </span><span class="c1">// 设置Custom算子类型</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">custom_attrs</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">input_num</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">to_string</span><span class="p">(</span><span class="n">cnode</span><span class="o">-&gt;</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">input_num_attr</span><span class="p">(</span><span class="n">input_num</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">input_num</span><span class="p">.</span><span class="n">end</span><span class="p">());</span>
<span class="w">    </span><span class="n">custom_attrs</span><span class="p">[</span><span class="s">&quot;input_num&quot;</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input_num_attr</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">op_kind</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;custom op&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">op_kind_attr</span><span class="p">(</span><span class="n">op_kind</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">op_kind</span><span class="p">.</span><span class="n">end</span><span class="p">());</span>
<span class="w">    </span><span class="n">custom_attrs</span><span class="p">[</span><span class="s">&quot;op_kind&quot;</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">op_kind_attr</span><span class="p">;</span>
<span class="w">    </span><span class="n">primc</span><span class="o">-&gt;</span><span class="n">set_attr</span><span class="p">(</span><span class="n">custom_attrs</span><span class="p">);</span><span class="w">         </span><span class="c1">// 设置Custom算子属性</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cnode</span><span class="o">-&gt;</span><span class="n">inputs</span><span class="p">();</span>
<span class="w">    </span><span class="n">inputs</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">begin</span><span class="p">());</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">custom_cnode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">func_graph</span><span class="o">-&gt;</span><span class="n">NewCNode</span><span class="p">(</span><span class="n">primc</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">);</span><span class="w">         </span><span class="c1">// 创建CNode节点</span>
<span class="w">    </span><span class="n">custom_cnode</span><span class="o">-&gt;</span><span class="n">set_fullname_with_scope</span><span class="p">(</span><span class="n">cnode</span><span class="o">-&gt;</span><span class="n">fullname_with_scope</span><span class="p">());</span><span class="w">     </span><span class="c1">// 设置节点名</span>
<span class="w">    </span><span class="n">custom_cnode</span><span class="o">-&gt;</span><span class="n">set_abstract</span><span class="p">(</span><span class="n">cnode</span><span class="o">-&gt;</span><span class="n">abstract</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">Clone</span><span class="p">());</span><span class="w">          </span><span class="c1">// 设置算子输出的基本属性，存储于abstract中</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">custom_cnode</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">Run</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">FuncGraphPtr</span><span class="w"> </span><span class="o">&amp;</span><span class="n">func_graph</span><span class="p">)</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">manager</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Manage</span><span class="p">(</span><span class="n">func_graph</span><span class="p">,</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span><span class="w">       </span><span class="c1">// 创建FuncGrap管理器</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">manager</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">node_list</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">TopoSort</span><span class="p">(</span><span class="n">func_graph</span><span class="o">-&gt;</span><span class="n">get_return</span><span class="p">());</span><span class="w">      </span><span class="c1">// 获取所有节点</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">node</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">node_list</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">utils</span><span class="o">::</span><span class="n">isa</span><span class="o">&lt;</span><span class="n">CNode</span><span class="o">&gt;</span><span class="p">(</span><span class="n">node</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">continue</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">opt</span><span class="o">::</span><span class="n">CheckPrimitiveType</span><span class="p">(</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">prim</span><span class="o">::</span><span class="n">kPrimAddN</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">     </span><span class="c1">// 判断当前节点是否为AddN算子</span>
<span class="w">        </span><span class="k">continue</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">      </span><span class="k">auto</span><span class="w"> </span><span class="n">cnode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">node</span><span class="o">-&gt;</span><span class="n">cast</span><span class="o">&lt;</span><span class="n">CNodePtr</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">      </span><span class="k">auto</span><span class="w"> </span><span class="n">custom_cnode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CreateCustomOp</span><span class="p">(</span><span class="n">func_graph</span><span class="p">,</span><span class="w"> </span><span class="n">cnode</span><span class="p">);</span><span class="w">    </span><span class="c1">// 创建Custom算子</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">custom_cnode</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">      </span><span class="n">manager</span><span class="o">-&gt;</span><span class="n">Replace</span><span class="p">(</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">custom_cnode</span><span class="p">)</span><span class="w">        </span><span class="c1">// 通过管理器用新节点替换旧节点</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>

<span class="n">REG_PASS</span><span class="p">(</span><span class="n">Test1Fusion</span><span class="p">,</span><span class="w"> </span><span class="n">Test1Fusion</span><span class="p">)</span><span class="w">    </span><span class="c1">// 注册Test1Fusion</span>
<span class="n">REG_PASS</span><span class="p">(</span><span class="n">Test2Fusion</span><span class="p">,</span><span class="w"> </span><span class="n">Test2Fusion</span><span class="p">)</span><span class="w">    </span><span class="c1">// 注册Test2Fusion</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;</span><span class="w"> </span><span class="n">schedule</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="s">&quot;Test1Fusion&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Test2Fusion&quot;</span><span class="p">};</span>
<span class="n">REG_SCHEDULED_PASS</span><span class="p">(</span><span class="n">POSITION_BEGIN</span><span class="p">,</span><span class="w"> </span><span class="n">schedule</span><span class="p">)</span><span class="w">       </span><span class="c1">// 设置外部Pass调度逻辑，在内置融合前运行外部Pass</span>
<span class="p">}</span><span class="w">  </span><span class="c1">// namespace mindspore::opt</span>
</pre></div>
</div>
<p>整个Custom算子的实现、注册、infershape等相关的代码可以参看代码仓里的<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.8/mindspore/lite/test/ut/src/registry/registry_custom_op_test.cc">样例</a>。</p>
</section>
<section id="custom算子实现">
<h4>Custom算子实现<a class="headerlink" href="#custom算子实现" title="Permalink to this headline"></a></h4>
<p>Custom算子的实现整体流程与通用算子的实现是一致的，因为都是<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.8/api_cpp/mindspore_kernel.html">Kernel</a>的具体子类。
如果自定义算子不是运行在CPU平台上，需要在运行结束时把结果重新拷回output tensor。这里以创建一个Add能力的Custom算子为例：</p>
<ol class="arabic simple">
<li><p>算子继承Kernel。</p></li>
<li><p>PreProcess()对内存进行了预分配。</p></li>
<li><p>Execute()对input进行了相加。</p></li>
</ol>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="p">;</span>

<span class="k">class</span><span class="w"> </span><span class="nc">TestCustomOp</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">Kernel</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="n">TestCustomOp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs</span><span class="p">,</span>
<span class="w">               </span><span class="k">const</span><span class="w"> </span><span class="n">schema</span><span class="o">::</span><span class="n">Primitive</span><span class="w"> </span><span class="o">*</span><span class="n">primitive</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">lite</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="o">*</span><span class="n">ctx</span><span class="p">)</span>
<span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">Kernel</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">primitive</span><span class="p">,</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span><span class="w"> </span><span class="p">{}</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">Prepare</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">Execute</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="nf">ReSize</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>

<span class="w"> </span><span class="k">private</span><span class="o">:</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">PreProcess</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">*</span><span class="n">output</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">outputs_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="c1">// malloc data for output tensor</span>
<span class="w">      </span><span class="k">auto</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">output</span><span class="o">-&gt;</span><span class="n">MutableData</span><span class="p">();</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Get data failed&quot;</span><span class="p">;</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">TestCustomOp</span><span class="o">::</span><span class="n">Execute</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">inputs_</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteParamInvalid</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">PreProcess</span><span class="p">();</span>
<span class="w">  </span><span class="n">GetAttrData</span><span class="p">();</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">in0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">inputs_</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">Data</span><span class="p">().</span><span class="n">get</span><span class="p">());</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">in1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">inputs_</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">Data</span><span class="p">().</span><span class="n">get</span><span class="p">());</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">outputs_</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">MutableData</span><span class="p">());</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">num</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outputs_</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">ElementNum</span><span class="p">();</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">in1</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="custom算子属性解码样例">
<h4>Custom算子属性解码样例<a class="headerlink" href="#custom算子属性解码样例" title="Permalink to this headline"></a></h4>
<p>样例中是把属性里的字节流复制到了buf内。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">prim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">primitive_</span><span class="o">-&gt;</span><span class="n">value_as_Custom</span><span class="p">();</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">prim</span><span class="o">-&gt;</span><span class="n">attr</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">return</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">data_bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prim</span><span class="o">-&gt;</span><span class="n">attr</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">Get</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">();</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">data_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_bytes</span><span class="o">-&gt;</span><span class="n">size</span><span class="p">();</span>
<span class="w">    </span><span class="kt">char</span><span class="w"> </span><span class="n">buf</span><span class="p">[</span><span class="mi">100</span><span class="p">];</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">data_size</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">buf</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">&gt;</span><span class="p">(</span><span class="n">data_bytes</span><span class="o">-&gt;</span><span class="n">Get</span><span class="p">(</span><span class="n">i</span><span class="p">));</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">buf</span><span class="p">[</span><span class="n">data_size</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</pre></div>
</div>
</section>
<section id="custom算子注册">
<h4>Custom算子注册<a class="headerlink" href="#custom算子注册" title="Permalink to this headline"></a></h4>
<p>当前有提供的现成的宏<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.8/api_cpp/mindspore_registry.html#register-custom-kernel">REGISTER_CUSTOM_KERNEL</a>可以进行算子注册，步骤如下：</p>
<ol class="arabic simple">
<li><p>TestCustomAddCreator函数用来创建Kernel。</p></li>
<li><p>通过宏REGISTER_CUSTOM_KERNEL进行算子注册，这里假定生产商为BuiltInTest，算子类型为Add。</p></li>
</ol>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">schema</span><span class="o">::</span><span class="n">PrimitiveType_AddFusion</span><span class="p">;</span>

<span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">Kernel</span><span class="o">&gt;</span><span class="w"> </span><span class="n">TestCustomAddCreator</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">inputs</span><span class="p">,</span>
<span class="w">                                             </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs</span><span class="p">,</span>
<span class="w">                                             </span><span class="k">const</span><span class="w"> </span><span class="n">schema</span><span class="o">::</span><span class="n">Primitive</span><span class="w"> </span><span class="o">*</span><span class="n">primitive</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">lite</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="o">*</span><span class="n">ctx</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">TestCustomOp</span><span class="o">&gt;</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">primitive</span><span class="p">,</span><span class="w"> </span><span class="n">ctx</span><span class="p">);</span>
<span class="p">}</span>
<span class="k">constexpr</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">kFloat32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat32</span><span class="p">;</span>
<span class="n">REGISTER_CUSTOM_KERNEL</span><span class="p">(</span><span class="n">CPU</span><span class="p">,</span><span class="w"> </span><span class="n">BuiltInTest</span><span class="p">,</span><span class="w"> </span><span class="n">kFloat32</span><span class="p">,</span><span class="w"> </span><span class="n">Add</span><span class="p">,</span><span class="w"> </span><span class="n">TestCustomAddCreator</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="custom算子infershape">
<h4>Custom算子InferShape<a class="headerlink" href="#custom算子infershape" title="Permalink to this headline"></a></h4>
<p>整体实现与通用算子InferShape是一样的。步骤如下：</p>
<ol class="arabic simple">
<li><p>继承<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.8/api_cpp/mindspore_kernel.html#kernelinterface">KernelInterface</a>。</p></li>
<li><p>重载实现Infer函数，推导出output tensor的shape、format、data_type。</p></li>
</ol>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">TestCustomOpInfer</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">KernelInterface</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="n">TestCustomOpInfer</span><span class="p">()</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span>
<span class="w">  </span><span class="o">~</span><span class="n">TestCustomOpInfer</span><span class="p">()</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span>
<span class="w">  </span><span class="n">Status</span><span class="w"> </span><span class="nf">Infer</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">*</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">*</span><span class="n">outputs</span><span class="p">,</span>
<span class="w">             </span><span class="k">const</span><span class="w"> </span><span class="n">schema</span><span class="o">::</span><span class="n">Primitive</span><span class="w"> </span><span class="o">*</span><span class="n">primitive</span><span class="p">)</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="p">(</span><span class="o">*</span><span class="n">outputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">SetFormat</span><span class="p">((</span><span class="o">*</span><span class="n">inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">format</span><span class="p">());</span>
<span class="w">    </span><span class="p">(</span><span class="o">*</span><span class="n">outputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">SetDataType</span><span class="p">((</span><span class="o">*</span><span class="n">inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">DataType</span><span class="p">());</span>
<span class="w">    </span><span class="p">(</span><span class="o">*</span><span class="n">outputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">SetShape</span><span class="p">((</span><span class="o">*</span><span class="n">inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">Shape</span><span class="p">());</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
</section>
<section id="custom算子infershape注册">
<h4>Custom算子InferShape注册<a class="headerlink" href="#custom算子infershape注册" title="Permalink to this headline"></a></h4>
<p>当前有提供的现成的宏<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.8/api_cpp/mindspore_registry.html#register-custom-kernel-interface">REGISTER_CUSTOM_KERNEL_INTERFACE</a>可以进行Custom算子InferShape的注册，步骤如下：</p>
<ol class="arabic simple">
<li><p>CustomAddInferCreator函数用于创建自定义的KernelInterface。</p></li>
<li><p>通过宏<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.8/api_cpp/mindspore_registry.html#register-custom-kernel-interface">REGISTER_CUSTOM_KERNEL_INTERFACE</a>注册InferShape能力，这里的算子类型Add必须与REGISTER_CUSTOM_KERNEL时的算子类型一致。</p></li>
</ol>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">KernelInterface</span><span class="o">&gt;</span><span class="w"> </span><span class="n">CustomAddInferCreator</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">TestCustomOpInfer</span><span class="o">&gt;</span><span class="p">();</span><span class="w"> </span><span class="p">}</span>

<span class="n">REGISTER_CUSTOM_KERNEL_INTERFACE</span><span class="p">(</span><span class="n">BuiltInTest</span><span class="p">,</span><span class="w"> </span><span class="n">Add</span><span class="p">,</span><span class="w"> </span><span class="n">CustomAddInferCreator</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="自定义gpu算子">
<h2>自定义GPU算子<a class="headerlink" href="#自定义gpu算子" title="Permalink to this headline"></a></h2>
<p>为支持GPU自定义算子的便捷开发，并使GPU自定义算子与内部的GPU算子共享一套资源，以加快调度效率，我们还提供了一套GPU相关的功能接口，相关API说明请参考<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.8/api_cpp/mindspore_registry_opencl.html">mindspore::registry::opencl</a>。
本文以样例代码解析的方式，向用户阐明自定义GPU算子开发的相关实现。用户需对<a class="reference internal" href="#如何实现自定义算子"><span class="std std-doc">如何实现自定义算子</span></a>有所了解的情况下，再来阅读此文。
在代码仓<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.8/mindspore/lite/test/ut/src/registry/registry_gpu_custom_op_test.cc">样例代码</a>中包含了对自定义GPU算子的实现、注册。</p>
<section id="算子注册">
<h3>算子注册<a class="headerlink" href="#算子注册" title="Permalink to this headline"></a></h3>
<p>本样例中注册的是<code class="docutils literal notranslate"><span class="pre">Custom_Add</span></code>自定义算子，关于该算子的创建与实现，请参考<a class="reference internal" href="#custom算子定义"><span class="std std-doc">Custom算子定义</span></a>和<a class="reference internal" href="#custom算子实现"><span class="std std-doc">Custom算子实现</span></a>。</p>
<section id="实现创建算子实例的函数">
<h4>实现创建算子实例的函数<a class="headerlink" href="#实现创建算子实例的函数" title="Permalink to this headline"></a></h4>
<p>实现自定义算子注册的第一步，需实现一个创建算子实例的函数。函数类型声明在<code class="docutils literal notranslate"><span class="pre">include/registry/register_kernel.h</span></code>，如下所示：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">/// \brief CreateKernel Defined a functor to create a kernel.</span>
<span class="c1">///</span>
<span class="c1">/// \param[in] inputs Define input tensors of kernel.</span>
<span class="c1">/// \param[in] outputs Define output tensors of kernel.</span>
<span class="c1">/// \param[in] primitive Define attributes of op.</span>
<span class="c1">/// \param[in] ctx Define for holding environment variables during runtime.</span>
<span class="c1">///</span>
<span class="c1">/// \return Smart Pointer of kernel.</span>
<span class="k">using</span><span class="w"> </span><span class="n">CreateKernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">function</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="o">&gt;</span><span class="p">(</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">schema</span><span class="o">::</span><span class="n">Primitive</span><span class="w"> </span><span class="o">*</span><span class="n">primitive</span><span class="p">,</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="o">*</span><span class="n">ctx</span><span class="p">)</span><span class="o">&gt;</span><span class="p">;</span>
</pre></div>
</div>
<p>本例中实现的创建算子实例函数如下，函数返回一个<code class="docutils literal notranslate"><span class="pre">CustomAddKernel</span></code>类实例，该类为继承<code class="docutils literal notranslate"><span class="pre">kernel::Kernel</span></code>类的用户自定义算子类，关于该类的实现参考<a class="reference internal" href="#算子实现"><span class="std std-doc">算子实现</span></a>。
在函数内，除了将函数参数传递给<code class="docutils literal notranslate"><span class="pre">CustomAddKernel</span></code>类的构造函数外，还传递了一个布尔型的变量，该变量用于控制创建的<code class="docutils literal notranslate"><span class="pre">CustomAddKernel</span></code>实例处理的数据类型是FLOAT32还是FLOAT16。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">namespace</span><span class="w"> </span><span class="nn">custom_gpu_demo</span><span class="w"> </span><span class="p">{</span>
<span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="o">&gt;</span><span class="w"> </span><span class="n">CustomAddCreator</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">inputs</span><span class="p">,</span>
<span class="w">                                                 </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs</span><span class="p">,</span>
<span class="w">                                                 </span><span class="k">const</span><span class="w"> </span><span class="n">schema</span><span class="o">::</span><span class="n">Primitive</span><span class="w"> </span><span class="o">*</span><span class="n">primitive</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="o">*</span><span class="n">ctx</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">fp16_enable</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;using fp32 add.</span><span class="se">\n</span><span class="s">&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">CustomAddKernel</span><span class="o">&gt;</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">primitive</span><span class="p">,</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">fp16_enable</span><span class="p">);</span>
<span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="注册算子">
<h4>注册算子<a class="headerlink" href="#注册算子" title="Permalink to this headline"></a></h4>
<p>在注册GPU算子时，必须将设备类型声明为GPU，并将上一步实现的创建算子实例函数<code class="docutils literal notranslate"><span class="pre">CustomAddCreator</span></code>传入。
本样例注册了<code class="docutils literal notranslate"><span class="pre">Custom_Add</span></code>算子GPU内的Float32实现，注册代码如下所示，注册宏中的其他参数参考<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.8/api_cpp/mindspore_registry.html">API说明</a>。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">kFloat32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat32</span><span class="p">;</span>
<span class="c1">// Register custom &quot;Custom_Add&quot; operator</span>
<span class="n">REGISTER_CUSTOM_KERNEL</span><span class="p">(</span><span class="n">GPU</span><span class="p">,</span><span class="w"> </span><span class="n">BuiltInTest</span><span class="p">,</span><span class="w"> </span><span class="n">kFloat32</span><span class="p">,</span><span class="w"> </span><span class="n">Custom_Add</span><span class="p">,</span><span class="w"> </span><span class="n">CustomAddCreator</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="算子实现">
<h3>算子实现<a class="headerlink" href="#算子实现" title="Permalink to this headline"></a></h3>
<p>在本样例中算子实现为<code class="docutils literal notranslate"><span class="pre">CustomAddKernel</span></code>类，该类继承<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.8/api_cpp/mindspore_kernel.html">mindspore::kernel::Kernel</a>，重载实现必要的接口，从而实现自定义算子的运算。</p>
<section id="构造及析构函数说明">
<h4>构造及析构函数说明<a class="headerlink" href="#构造及析构函数说明" title="Permalink to this headline"></a></h4>
<p>在<code class="docutils literal notranslate"><span class="pre">CustomAddKernel</span></code>类构造函数中，保存了传递进来的布尔变量<code class="docutils literal notranslate"><span class="pre">fp16_enable</span></code>，并将其他参数传递给基类的构造函数。
在<code class="docutils literal notranslate"><span class="pre">CustomAddKernel</span></code>类析构函数中，调用<code class="docutils literal notranslate"><span class="pre">FreeWeight()</span></code>对因运算需要而临时申请的内存进行释放。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">CustomAddKernel</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="n">CustomAddKernel</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs</span><span class="p">,</span>
<span class="w">                  </span><span class="k">const</span><span class="w"> </span><span class="n">schema</span><span class="o">::</span><span class="n">Primitive</span><span class="w"> </span><span class="o">*</span><span class="n">primitive</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="o">*</span><span class="n">ctx</span><span class="p">,</span>
<span class="w">                  </span><span class="kt">bool</span><span class="w"> </span><span class="n">fp16_enable</span><span class="p">)</span>
<span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">Kernel</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">primitive</span><span class="p">,</span><span class="w"> </span><span class="n">ctx</span><span class="p">),</span><span class="w"> </span><span class="n">fp16_enable_</span><span class="p">(</span><span class="n">fp16_enable</span><span class="p">)</span><span class="w"> </span><span class="p">{}</span>
<span class="w">  </span><span class="o">~</span><span class="n">CustomAddKernel</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">FreeWeight</span><span class="p">();</span><span class="w"> </span><span class="p">}</span>

<span class="w">  </span><span class="p">...</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="类成员变量说明">
<h4>类成员变量说明<a class="headerlink" href="#类成员变量说明" title="Permalink to this headline"></a></h4>
<ul>
<li><p>opencl_runtime_</p>
<p>为OpenCLRuntimeWrapper类的实例，在算子内部可通过该对象调取MindSpore Lite提供的OpenCL操作相关接口<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.8/api_cpp/mindspore_registry_opencl.html">mindspore::registry::opencl</a>。</p>
</li>
<li><p>fp16_enable_</p>
<p>为算子是否使用FP16进行运算的标志。若要使用FP16进行运算，需将算子注册为FP16算子。本例中注册的是FP32算子。</p>
</li>
<li><p>weight_ptrs_</p>
<p>保存算子运算所需的临时内存的指针。</p>
</li>
<li><p>其他变量</p>
<p>其他变量为进行OpenCL操作时所需的变量，详细意义可查看OpenCL操作时对应的接口说明<a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.8/api_cpp/mindspore_registry_opencl.html">mindspore::registry::opencl</a>。</p>
</li>
</ul>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">CustomAddKernel</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">kernel</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="p">...</span>
<span class="w"> </span><span class="k">private</span><span class="o">:</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">fp16_enable_</span><span class="p">;</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="n">kernel_</span><span class="p">;</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Event</span><span class="w"> </span><span class="n">event_</span><span class="p">;</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">NDRange</span><span class="w"> </span><span class="n">global_range_</span><span class="p">{</span><span class="n">cl</span><span class="o">::</span><span class="n">NullRange</span><span class="p">};</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">NDRange</span><span class="w"> </span><span class="n">local_range_</span><span class="p">{</span><span class="n">cl</span><span class="o">::</span><span class="n">NullRange</span><span class="p">};</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">void</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">weight_ptrs_</span><span class="p">;</span>
<span class="w">  </span><span class="n">registry</span><span class="o">::</span><span class="n">opencl</span><span class="o">::</span><span class="n">OpenCLRuntimeWrapper</span><span class="w"> </span><span class="n">opencl_runtime_</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="prepare实现代码与说明">
<h4>Prepare实现代码与说明<a class="headerlink" href="#prepare实现代码与说明" title="Permalink to this headline"></a></h4>
<p>在图编译阶段<code class="docutils literal notranslate"><span class="pre">mindspore::Model::Build</span></code>，将调用算子的Prepare实现。用户可以在这里进行一些较为耗时，一次性的操作，以节约<code class="docutils literal notranslate"><span class="pre">mindspore::Model::Predict</span></code>时算子计算的时间。
在该样例中，通过重载Prepare接口，实现对自定义的OpenCL代码进行加载并编译。</p>
<ol class="arabic simple">
<li><p>检验环境</p></li>
</ol>
<p>样例中，首先通过调用<code class="docutils literal notranslate"><span class="pre">CheckSpecs</span></code>，对算子的运行环境进行检查。
此处，在<code class="docutils literal notranslate"><span class="pre">CheckSpecs</span></code>中，检查了输入和输出的数据类型，及输入和输出的tensor数量。
通过<code class="docutils literal notranslate"><span class="pre">MSTensor::IsConst()</span></code>接口可以判断一个tensor的数据是否为常量，此处对非常量输入的数据类型，和算子注册时所声明处理的数据类型也进行了对比校验。对于常量数据的处理，参考本章后续的教程。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">Prepare</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CheckSpecs</span><span class="p">();</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Prepare failed for check kernel specs!&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">ret</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="p">...</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">CheckSpecs</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">tensor</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">inputs_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="n">DataType</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat32</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">DataType</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat16</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;ArithmeticOpenCLKernel only support fp32/fp16 input&quot;</span><span class="p">;</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">tensor</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">outputs_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="n">DataType</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat32</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">DataType</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat16</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;ArithmeticOpenCLKernel only support fp32/fp16 output&quot;</span><span class="p">;</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">inputs_</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="n">outputs_</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;in size: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">inputs_</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;, out size: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">outputs_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">inputs_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">in_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputs_</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">in_tensor</span><span class="p">.</span><span class="n">IsConst</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">fp16_enable_</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">in_tensor</span><span class="p">.</span><span class="n">DataType</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat32</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Inputs data type error, expectation kNumberTypeFloat16 but kNumberTypeFloat32.&quot;</span><span class="p">;</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">fp16_enable_</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">in_tensor</span><span class="p">.</span><span class="n">DataType</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat16</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Inputs data type error, expectation kNumberTypeFloat32 but kNumberTypeFloat16.&quot;</span><span class="p">;</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>加载自定义的OpenCL代码</p></li>
</ol>
<p>通过<code class="docutils literal notranslate"><span class="pre">opencl_runtime_</span></code>调用<code class="docutils literal notranslate"><span class="pre">OpenCLRuntimeWrapper::LoadSource</span></code>接口加载自定义的OpenCL代码。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">Prepare</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="p">...</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">kernel_name_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;ElementAdd&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">program_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Arithmetic&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">arithmetic_source</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">opencl_runtime_</span><span class="p">.</span><span class="n">LoadSource</span><span class="p">(</span><span class="n">program_name</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Load source failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="p">...</span>
<span class="p">}</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">arithmetic_source</span></code>的为用户自定义的OpenCL代码，如下所示：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">arithmetic_source</span><span class="w"> </span><span class="o">=</span>
<span class="w">  </span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;#pragma OPENCL EXTENSION cl_khr_fp16 : enable</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;__constant sampler_t smp_none = CLK_NORMALIZED_COORDS_FALSE | CLK_ADDRESS_NONE | CLK_FILTER_NEAREST;</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;__kernel void ElementAdd(__read_only image2d_t input_a, __read_only image2d_t input_b, __write_only image2d_t &quot;</span>
<span class="w">  </span><span class="s">&quot;output,</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;                         const int2 output_shape) {</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;  int X = get_global_id(0);</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;  int Y = get_global_id(1);</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;  if (X &gt;= output_shape.x || Y &gt;= output_shape.y) {</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;    return;</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;  }</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;  FLT4 a = READ_IMAGE(input_a, smp_none, (int2)(X, Y));</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;  FLT4 b = READ_IMAGE(input_b, smp_none, (int2)(X, Y));</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;  FLT4 result = a + b;</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;  WRITE_IMAGE(output, (int2)(X, Y), result);</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">  </span><span class="s">&quot;}</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>编译OpenCL代码</p></li>
</ol>
<p>通过<code class="docutils literal notranslate"><span class="pre">fp16_enable_</span></code>指定不同的编译选项，以生成处理FLOAT16或FPLOAT32数据的代码。
通过<code class="docutils literal notranslate"><span class="pre">opencl_runtime_</span></code>调用<code class="docutils literal notranslate"><span class="pre">OpenCLRuntimeWrapper::BuildKernel</span></code>接口，得到编译后的<code class="docutils literal notranslate"><span class="pre">cl::Kernel</span></code>变量，保存在<code class="docutils literal notranslate"><span class="pre">kernel_</span></code>。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">Prepare</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="p">...</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;</span><span class="w"> </span><span class="n">build_options_ext</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="s">&quot;-cl-mad-enable -cl-fast-relaxed-math -Werror&quot;</span><span class="p">};</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">fp16_enable_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">build_options_ext</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="s">&quot; -DFLT4=half4 -DWRITE_IMAGE=write_imageh -DREAD_IMAGE=read_imageh&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">build_options_ext</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="s">&quot; -DFLT4=float4 -DWRITE_IMAGE=write_imagef -DREAD_IMAGE=read_imagef&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">opencl_runtime_</span><span class="p">.</span><span class="n">BuildKernel</span><span class="p">(</span><span class="o">&amp;</span><span class="n">kernel_</span><span class="p">,</span><span class="w"> </span><span class="n">program_name</span><span class="p">,</span><span class="w"> </span><span class="n">kernel_name_</span><span class="p">,</span><span class="w"> </span><span class="n">build_options_ext</span><span class="p">)</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Build kernel failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="p">...</span>
<span class="p">}</span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>设置OpenCL工作组和工作项</p></li>
</ol>
<p>对注册为GPU的算子来说，除输入为常量的情况，所接收到的是Image格式的输入数据，Format为NHWC4（指C轴4字节对齐的NHWC格式数据）。
本例中也将所有数据转为这种格式进行计算和输出。
例程中实现的是一个简单的加法自定义算子，所以这里直接通过<code class="docutils literal notranslate"><span class="pre">GpuTensorInfo</span></code>函数计算输出数据<code class="docutils literal notranslate"><span class="pre">Image</span></code>内存所用宽度和高度来设置工作项。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">Prepare</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="p">...</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">out_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GpuTensorInfo</span><span class="p">(</span><span class="o">&amp;</span><span class="n">outputs_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="o">&amp;</span><span class="n">opencl_runtime_</span><span class="p">);</span>
<span class="w">  </span><span class="n">local_range_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">NullRange</span><span class="p">;</span>
<span class="w">  </span><span class="n">global_range_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">NDRange</span><span class="p">(</span><span class="n">out_shape</span><span class="p">.</span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="n">out_shape</span><span class="p">.</span><span class="n">height</span><span class="p">);</span>
<span class="w">  </span><span class="p">...</span>
<span class="p">}</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">GpuTensorInfo</span></code>的实现如下，首先通过<code class="docutils literal notranslate"><span class="pre">Broadcast2GpuShape</span></code>函数将tensor的shape转为四维，然后计算Format为NHWC4时的shape值。
再接着通过<code class="docutils literal notranslate"><span class="pre">OpenCLRuntimeWrapper::GetMaxImage2DWidth</span></code>及<code class="docutils literal notranslate"><span class="pre">OpenCLRuntimeWrapper::GetMaxImage2DHeight</span></code>接口得到Image内存所支持的最大宽度和高度，以此确定算子实际使用的Image内存宽度和高度。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="nc">GpuTensorInfo</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">GpuTensorInfo</span><span class="p">()</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span>
<span class="w">  </span><span class="k">explicit</span><span class="w"> </span><span class="n">GpuTensorInfo</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*</span><span class="n">tensor</span><span class="p">,</span><span class="w"> </span><span class="n">registry</span><span class="o">::</span><span class="n">opencl</span><span class="o">::</span><span class="n">OpenCLRuntimeWrapper</span><span class="w"> </span><span class="o">*</span><span class="n">opencl_run</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tensor</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">return</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">shape_ori</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tensor</span><span class="o">-&gt;</span><span class="n">Shape</span><span class="p">();</span>
<span class="w">    </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">shape</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>
<span class="w">    </span><span class="n">Broadcast2GpuShape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span><span class="w"> </span><span class="n">shape_ori</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">shape_ori</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span><span class="w"> </span><span class="mf">1l</span><span class="p">);</span>
<span class="w">    </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">    </span><span class="n">H</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
<span class="w">    </span><span class="n">W</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="w">    </span><span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
<span class="w">    </span><span class="n">Slice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">UP_DIV</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">C4NUM</span><span class="p">);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tensor</span><span class="o">-&gt;</span><span class="n">DataType</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat16</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">FLT_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">cl_half</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">FLT_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">cl_float</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">FLT4_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">FLT_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">W</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Slice</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">opencl_run</span><span class="o">-&gt;</span><span class="n">GetMaxImage2DWidth</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">H</span><span class="p">;</span>
<span class="w">      </span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">W</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Slice</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">H</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">W</span><span class="p">;</span>
<span class="w">      </span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Slice</span><span class="p">;</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">height</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">opencl_run</span><span class="o">-&gt;</span><span class="n">GetMaxImage2DHeight</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="w">        </span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="n">ElementsNum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">H</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">W</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">C</span><span class="p">;</span>
<span class="w">    </span><span class="n">Image2DSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">FLT4_size</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">N</span><span class="p">{</span><span class="mi">1</span><span class="p">};</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">H</span><span class="p">{</span><span class="mi">1</span><span class="p">};</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">W</span><span class="p">{</span><span class="mi">1</span><span class="p">};</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">C</span><span class="p">{</span><span class="mi">1</span><span class="p">};</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">Slice</span><span class="p">{};</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">width</span><span class="p">{};</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">height</span><span class="p">{};</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">FLT_size</span><span class="p">{</span><span class="mi">4</span><span class="p">};</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">FLT4_size</span><span class="p">{</span><span class="mi">16</span><span class="p">};</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">ElementsNum</span><span class="p">{};</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">Image2DSize</span><span class="p">{};</span>
<span class="p">};</span>
<span class="p">}</span><span class="w">  </span><span class="c1">// namespace</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Broadcast2GpuShape</span></code>的实现如下所示。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">SrcT</span><span class="p">,</span><span class="w"> </span><span class="k">typename</span><span class="w"> </span><span class="nc">DstT</span><span class="o">&gt;</span>
<span class="kt">void</span><span class="w"> </span><span class="n">Broadcast2GpuShape</span><span class="p">(</span><span class="n">DstT</span><span class="w"> </span><span class="o">*</span><span class="n">dst</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">SrcT</span><span class="w"> </span><span class="o">*</span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">src_num</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">src</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="n">src_num</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dst</span><span class="p">;</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="o">*</span><span class="n">H</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dst</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="o">*</span><span class="n">W</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dst</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dst</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">3</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">src_num</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">  </span><span class="c1">// 1 1 1 C</span>
<span class="w">    </span><span class="o">*</span><span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">src_num</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">  </span><span class="c1">// N 1 1 C</span>
<span class="w">    </span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">    </span><span class="o">*</span><span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">src_num</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">  </span><span class="c1">// N 1 W C</span>
<span class="w">    </span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">    </span><span class="o">*</span><span class="n">W</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
<span class="w">    </span><span class="o">*</span><span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">src_num</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">  </span><span class="c1">// N H W C</span>
<span class="w">    </span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">    </span><span class="o">*</span><span class="n">H</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
<span class="w">    </span><span class="o">*</span><span class="n">W</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="w">    </span><span class="o">*</span><span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">src_num</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;GPU doesn&#39;t support ndim&gt;=&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">src_num</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>

<span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">SrcT</span><span class="p">,</span><span class="w"> </span><span class="k">typename</span><span class="w"> </span><span class="nc">DstT</span><span class="o">&gt;</span>
<span class="kt">void</span><span class="w"> </span><span class="n">Broadcast2GpuShape</span><span class="p">(</span><span class="n">DstT</span><span class="w"> </span><span class="o">*</span><span class="n">dst</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">SrcT</span><span class="w"> </span><span class="o">*</span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">src_num</span><span class="p">,</span><span class="w"> </span><span class="n">DstT</span><span class="w"> </span><span class="n">default_value</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">dst</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">default_value</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">src</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="n">src_num</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Broadcast2GpuShape</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">src_num</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p>将常量输入转为合适格式的数据，并分配GPU内存</p></li>
</ol>
<p>对注册为GPU的算子来说，除输入为常量的情况，其它情况下，输入数据已经为Image格式的GPU内存数据。
为满足算子运算所需，用户需为常量输入设置合适的格式，必要时为其分配GPU内存。在此例，针对常量tensor的操作如下所示。</p>
<p>首先通过<code class="docutils literal notranslate"><span class="pre">MSTensor::IsConst()</span></code>接口判断输入是否为常量，并通过<code class="docutils literal notranslate"><span class="pre">GpuTensorInfo</span></code>计算转为Image格式时所需的内存大小。
然后分配该大小的局部内存<code class="docutils literal notranslate"><span class="pre">weight</span></code>，并通过<code class="docutils literal notranslate"><span class="pre">PackNHWCToNHWC4</span></code>函数将tensor内存转到<code class="docutils literal notranslate"><span class="pre">weight</span></code>中存储。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">inputs_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">in_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputs_</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">in_tensor</span><span class="p">.</span><span class="n">IsConst</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">GpuTensorInfo</span><span class="w"> </span><span class="n">in_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GpuTensorInfo</span><span class="p">(</span><span class="o">&amp;</span><span class="n">in_tensor</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">opencl_runtime_</span><span class="p">);</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">&gt;</span><span class="w"> </span><span class="n">weight</span><span class="p">(</span><span class="n">in_shape</span><span class="p">.</span><span class="n">Image2DSize</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="kt">bool</span><span class="w"> </span><span class="n">src_is_fp16</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in_tensor</span><span class="p">.</span><span class="n">DataType</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat16</span><span class="p">;</span>
<span class="w">    </span><span class="n">PackNHWCToNHWC4</span><span class="p">(</span><span class="n">in_tensor</span><span class="p">.</span><span class="n">MutableData</span><span class="p">(),</span><span class="w"> </span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">src_is_fp16</span><span class="p">,</span><span class="w"> </span><span class="n">fp16_enable_</span><span class="p">,</span><span class="w"> </span><span class="n">in_shape</span><span class="p">,</span>
<span class="w">                    </span><span class="n">in_tensor</span><span class="p">.</span><span class="n">DataType</span><span class="p">());</span>
<span class="w">    </span><span class="p">...</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">PackNHWCToNHWC4</span></code>函数实现如下，其中包含了对FLOAT16和FLOAT32类型的转换。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">PackNHWCToNHWC4</span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">dst</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">src_is_fp16</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">dst_is_fp16</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">GpuTensorInfo</span><span class="w"> </span><span class="o">&amp;</span><span class="n">tensor</span><span class="p">,</span>
<span class="w">                     </span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="w"> </span><span class="n">data_type</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">src_fp16</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="n">float16_t</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">src</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">src_fp32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="n">float32_t</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">src</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">src_int32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">int32_t</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">src</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">dst_fp16</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="n">float16_t</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">dst</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">dst_fp32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="n">float32_t</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">dst</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">dst_int32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">int32_t</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">dst</span><span class="p">);</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">src_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">n</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">h</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">h</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">H</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">h</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">W</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">w</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">C</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="o">++</span><span class="n">src_idx</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">          </span><span class="kt">int</span><span class="w"> </span><span class="n">dst_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">((</span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">H</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">h</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">W</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">w</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">Slice</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">C4NUM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">c</span><span class="p">;</span>
<span class="w">          </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">data_type</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeInt32</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">dst_int32</span><span class="p">[</span><span class="n">dst_idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src_int32</span><span class="p">[</span><span class="n">src_idx</span><span class="p">];</span>
<span class="w">          </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">dst_is_fp16</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">dst_fp16</span><span class="p">[</span><span class="n">dst_idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src_is_fp16</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">src_fp16</span><span class="p">[</span><span class="n">src_idx</span><span class="p">]</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="n">float16_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">src_fp32</span><span class="p">[</span><span class="n">src_idx</span><span class="p">]);</span>
<span class="w">          </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">dst_fp32</span><span class="p">[</span><span class="n">dst_idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src_is_fp16</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="n">float32_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">src_fp16</span><span class="p">[</span><span class="n">src_idx</span><span class="p">])</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">src_fp32</span><span class="p">[</span><span class="n">src_idx</span><span class="p">];</span>
<span class="w">          </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="n">ElementsNum</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">dst_is_fp16</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">dst_fp16</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dst_fp16</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dst_fp16</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dst_fp16</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">dst_fp32</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dst_fp32</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dst_fp32</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dst_fp32</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>通过<code class="docutils literal notranslate"><span class="pre">OpenCLRuntimeWrapper::GetAllocator</span></code>得到分配GPU内存的内存分配器。
然后通过分配器的<code class="docutils literal notranslate"><span class="pre">mindspore::Allocator::Malloc</span></code>接口，可以申请到Image格式的GPU内存。
接着通过<code class="docutils literal notranslate"><span class="pre">OpenCLRuntimeWrapper::WriteImage(void</span> <span class="pre">*buffer,</span> <span class="pre">void</span> <span class="pre">*src_data)</span></code>接口，将已经转为NHWC4格式的<code class="docutils literal notranslate"><span class="pre">weight</span></code>数据写入到GPU内存中。
申请的GPU内存指针保存到weight_ptrs_中，以便在析构时释放。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">DataType</span><span class="w"> </span><span class="n">dtype</span><span class="w"> </span><span class="o">=</span>
<span class="w">  </span><span class="n">fp16_enable_</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat16</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kNumberTypeFloat32</span><span class="p">;</span>
<span class="k">auto</span><span class="w"> </span><span class="n">allocator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">opencl_runtime_</span><span class="p">.</span><span class="n">GetAllocator</span><span class="p">();</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">allocator</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;GetAllocator fail.&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="n">FreeWeight</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">auto</span><span class="w"> </span><span class="n">weight_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">allocator</span><span class="o">-&gt;</span><span class="n">Malloc</span><span class="p">(</span><span class="n">in_shape</span><span class="p">.</span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="n">in_shape</span><span class="p">.</span><span class="n">height</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">weight_ptr</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Malloc fail.&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="n">FreeWeight</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">weight_ptrs_</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">weight_ptr</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">opencl_runtime_</span><span class="p">.</span><span class="n">WriteImage</span><span class="p">(</span><span class="n">weight_ptr</span><span class="p">,</span><span class="w"> </span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">())</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;WriteImage fail.&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="n">FreeWeight</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>析构时调用的释放GPU内存函数如下，通过<code class="docutils literal notranslate"><span class="pre">OpenCLRuntimeWrapper::GetAllocator</span></code>得到分配GPU内存的内存分配器。
然后通过分配器的<code class="docutils literal notranslate"><span class="pre">mindspore::Allocator::Free</span></code>接口，可以释放申请到的GPU内存。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">FreeWeight</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">allocator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">opencl_runtime_</span><span class="p">.</span><span class="n">GetAllocator</span><span class="p">();</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">allocator</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;GetAllocator fail.&quot;</span><span class="p">;</span>
<span class="w">      </span><span class="k">return</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">weight_ptr</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">weight_ptrs_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">weight_ptr</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">allocator</span><span class="o">-&gt;</span><span class="n">Free</span><span class="p">(</span><span class="n">weight_ptr</span><span class="p">);</span>
<span class="w">        </span><span class="n">weight_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
</pre></div>
</div>
<ol class="arabic simple" start="6">
<li><p>设置OpenCL内核运行时参数的值</p></li>
</ol>
<p>某些OpenCL内核运行时不会改变的参数，可以在<code class="docutils literal notranslate"><span class="pre">Prepare</span></code>阶段进行设置。
在此例中，通过<code class="docutils literal notranslate"><span class="pre">OpenCLRuntimeWrapper::SetKernelArg</span></code>，设置<code class="docutils literal notranslate"><span class="pre">ElementAdd</span></code>运行时的第三个参数（计算的范围）。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="n">arg_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">3</span><span class="p">;</span>
<span class="n">cl_int2</span><span class="w"> </span><span class="n">output_shape</span><span class="p">{</span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">global_range_</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">global_range_</span><span class="p">[</span><span class="mi">1</span><span class="p">])};</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">opencl_runtime_</span><span class="p">.</span><span class="n">SetKernelArg</span><span class="p">(</span><span class="n">kernel_</span><span class="p">,</span><span class="w"> </span><span class="n">arg_idx</span><span class="p">,</span><span class="w"> </span><span class="n">output_shape</span><span class="p">)</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Set kernel arg&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">arg_idx</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;failed.&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="n">FreeWeight</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="resize及execute实现代码与说明">
<h4>ReSize及Execute实现代码与说明<a class="headerlink" href="#resize及execute实现代码与说明" title="Permalink to this headline"></a></h4>
<p>通过重载实现<code class="docutils literal notranslate"><span class="pre">Execute</span></code>可以实现推理时算子的自定义运算操作。</p>
<ol class="arabic simple">
<li><p>调用<code class="docutils literal notranslate"><span class="pre">ReSize</span></code>函数，以支持运行时shape变更</p></li>
</ol>
<p>在本例中，首先调用<code class="docutils literal notranslate"><span class="pre">PreProcess</span></code>来处理运算前的一些准备工作。
在<code class="docutils literal notranslate"><span class="pre">PreProcess()</span></code>中，首先调用<code class="docutils literal notranslate"><span class="pre">ReSize</span></code>函数，该函数为需要用户重载实现的运行时shape变更适配接口。
在<code class="docutils literal notranslate"><span class="pre">ReSize</span></code>函数中，通过调用<code class="docutils literal notranslate"><span class="pre">CheckOutputs</span></code>判断算子的输出tensor的shape是否存在非法值，以判断是否需要重新进行shape推理。若不需要，直接返回。
在需要进行shape推理时，通过<code class="docutils literal notranslate"><span class="pre">registry::RegisterKernelInterface::GetKernelInterface</span></code>获得该算子所注册的shape推理函数，此处得到的其实就是本例程中用户实现并注册的<code class="docutils literal notranslate"><span class="pre">InferShape</span></code>函数。
在重新推理之后，通过调用之前实现的<code class="docutils literal notranslate"><span class="pre">Prepare</span></code>接口，重新申请和分配算子运算时需要的内存及相关变量。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">ReSize</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">CheckOutputs</span><span class="p">(</span><span class="n">outputs_</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">status</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="n">registry</span><span class="o">::</span><span class="n">RegisterKernelInterface</span><span class="o">::</span><span class="n">GetKernelInterface</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">primitive_</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">Infer</span><span class="p">(</span><span class="o">&amp;</span><span class="n">inputs_</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs_</span><span class="p">,</span><span class="w"> </span><span class="n">primitive_</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">status</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;infer failed.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Prepare</span><span class="p">();</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;ReSize failed for kernel prepare!&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">ret</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">PreProcess</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">   </span><span class="kt">int</span><span class="w"> </span><span class="n">ret</span><span class="p">;</span>
<span class="w">   </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ReSize</span><span class="p">();</span>
<span class="w">   </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="k">return</span><span class="w"> </span><span class="n">ret</span><span class="p">;</span>
<span class="w">   </span><span class="p">}</span>
<span class="w">   </span><span class="p">...</span>
<span class="w"> </span><span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">Execute</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">inputs_</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteParamInvalid</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">PreProcess</span><span class="p">();</span>
<span class="w">  </span><span class="p">...</span>
<span class="p">}</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>为输出tensor申请内存分配</p></li>
</ol>
<p>在算子运行前，需要为输出tensor申请分配GPU内存，由于框架的限制，该GPU内存需要托管给框架管理，用户不可人为释放。具体操作流程如下：</p>
<ol class="arabic simple">
<li><p>通过调用输出tensor的<code class="docutils literal notranslate"><span class="pre">allocator()</span></code>接口，可以得到框架中管理这个tensor的内存分配器，在GPU注册算子中，则为负责分配GPU内存的内存分配器。</p></li>
<li><p>计算需要分配的内存大小，此例中通过<code class="docutils literal notranslate"><span class="pre">GpuTensorInfo</span></code>函数来计算。</p></li>
<li><p>通过内存分配器的<code class="docutils literal notranslate"><span class="pre">Malloc</span></code>接口申请内存，用户可分别通过<code class="docutils literal notranslate"><span class="pre">void</span> <span class="pre">*Malloc(size_t</span> <span class="pre">weight,</span> <span class="pre">size_t</span> <span class="pre">height,</span> <span class="pre">DataType</span> <span class="pre">type)</span></code>和<code class="docutils literal notranslate"><span class="pre">void</span> <span class="pre">*Malloc(size_t</span> <span class="pre">size)</span></code>接口得到Image或Buffer格式的内存。</p></li>
<li><p>通过<code class="docutils literal notranslate"><span class="pre">SetData</span></code>接口，将申请的内存赋值给tensor，此后，此内存将由框架统一管理，用户不可手动释放。</p></li>
</ol>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">PreProcess</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="p">...</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">outputs_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="o">*</span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs_</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">img_info</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GpuTensorInfo</span><span class="p">(</span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">opencl_runtime_</span><span class="p">);</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">allocator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">output</span><span class="o">-&gt;</span><span class="n">allocator</span><span class="p">();</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">allocator</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;The output tensor of OpenCL kernel must have an allocator.&quot;</span><span class="p">;</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">data_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">allocator</span><span class="o">-&gt;</span><span class="n">Malloc</span><span class="p">(</span><span class="n">img_info</span><span class="p">.</span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="n">img_info</span><span class="p">.</span><span class="n">height</span><span class="p">,</span><span class="w"> </span><span class="n">output</span><span class="o">-&gt;</span><span class="n">DataType</span><span class="p">());</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">data_ptr</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Malloc data failed&quot;</span><span class="p">;</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">output</span><span class="o">-&gt;</span><span class="n">SetData</span><span class="p">(</span><span class="n">data_ptr</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>运行OpenCL内核</p></li>
</ol>
<p>通过<code class="docutils literal notranslate"><span class="pre">SetKernelArg</span></code>接口设置OpenCL的Kernel运行时的参数，通过<code class="docutils literal notranslate"><span class="pre">RunKernel</span></code>运行OpenCL的Kernel。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">Execute</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="p">...</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="k">this</span><span class="o">-&gt;</span><span class="n">name</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; Running!&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">input_0_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">weight_ptrs_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">inputs_</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">MutableData</span><span class="p">()</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">weight_ptrs_</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">input_1_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">weight_ptrs_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">inputs_</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">MutableData</span><span class="p">()</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">weight_ptrs_</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">arg_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">opencl_runtime_</span><span class="o">-&gt;</span><span class="n">SetKernelArg</span><span class="p">(</span><span class="n">kernel_</span><span class="p">,</span><span class="w"> </span><span class="n">arg_idx</span><span class="o">++</span><span class="p">,</span><span class="w"> </span><span class="n">input_0_ptr</span><span class="p">)</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Set kernel arg&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">arg_idx</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">opencl_runtime_</span><span class="o">-&gt;</span><span class="n">SetKernelArg</span><span class="p">(</span><span class="n">kernel_</span><span class="p">,</span><span class="w"> </span><span class="n">arg_idx</span><span class="o">++</span><span class="p">,</span><span class="w"> </span><span class="n">input_1_ptr</span><span class="p">)</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Set kernel arg&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">arg_idx</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">opencl_runtime_</span><span class="o">-&gt;</span><span class="n">SetKernelArg</span><span class="p">(</span><span class="n">kernel_</span><span class="p">,</span><span class="w"> </span><span class="n">arg_idx</span><span class="o">++</span><span class="p">,</span><span class="w"> </span><span class="n">outputs_</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">MutableData</span><span class="p">())</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Set kernel arg&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">arg_idx</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">opencl_runtime_</span><span class="o">-&gt;</span><span class="n">RunKernel</span><span class="p">(</span><span class="n">kernel_</span><span class="p">,</span><span class="w"> </span><span class="n">global_range_</span><span class="p">,</span><span class="w"> </span><span class="n">local_range_</span><span class="p">,</span><span class="w"> </span><span class="k">nullptr</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">event_</span><span class="p">)</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Run kernel failed.&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">kLiteError</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">kSuccess</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="converter_register.html" class="btn btn-neutral float-left" title="离线构建自定义算子" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="delegate.html" class="btn btn-neutral float-right" title="使用Delegate支持第三方AI框架接入" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>