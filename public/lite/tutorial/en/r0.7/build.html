<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Build &mdash; MindSpore Lite master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Implementing an Image Classification Application" href="quick_start/quick_start.html" />
    <link rel="prev" title="MindSpore Lite Tutorials" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Build</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#linux-environment-compilation">Linux Environment Compilation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#environment-requirements">Environment Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compilation-options">Compilation Options</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compilation-example">Compilation Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="#output-description">Output Description</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#description-of-converter-s-directory-structure">Description of Converter’s Directory Structure</a></li>
<li class="toctree-l4"><a class="reference internal" href="#description-of-runtime-and-other-tools-directory-structure">Description of Runtime and Other tools’ Directory Structure</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="use/converter_tool.html">Converter Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="use/runtime.html">Runtime User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="use/benchmark_tool.html">Benchmark Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="use/timeprofiler_tool.html">TimeProfiler Tool</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Build</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/build.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="build">
<h1>Build<a class="headerlink" href="#build" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r0.7/lite/tutorials/source_en/build.md"><img alt="View Source On Gitee" src="_images/logo_source.png" /></a></p>
<p>This chapter introduces how to quickly compile MindSpore Lite, which includes the following modules:</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Module</p></th>
<th class="head"><p>Support Platform</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>converter</p></td>
<td><p>Linux</p></td>
<td><p>Model Conversion Tool</p></td>
</tr>
<tr class="row-odd"><td><p>runtime</p></td>
<td><p>Linux、Android</p></td>
<td><p>Model Inference Framework</p></td>
</tr>
<tr class="row-even"><td><p>benchmark</p></td>
<td><p>Linux、Android</p></td>
<td><p>Benchmarking Tool</p></td>
</tr>
<tr class="row-odd"><td><p>time_profiler</p></td>
<td><p>Linux、Android</p></td>
<td><p>Performance Analysis Tool</p></td>
</tr>
</tbody>
</table>
<section id="linux-environment-compilation">
<h2>Linux Environment Compilation<a class="headerlink" href="#linux-environment-compilation" title="Permalink to this headline"></a></h2>
<section id="environment-requirements">
<h3>Environment Requirements<a class="headerlink" href="#environment-requirements" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>The compilation environment supports Linux x86_64 only. Ubuntu 18.04.02 LTS is recommended.</p></li>
<li><p>Compilation dependencies of runtime、benchmark and time_profiler:</p>
<ul>
<li><p><a class="reference external" href="https://cmake.org/download/">CMake</a> &gt;= 3.14.1</p></li>
<li><p><a class="reference external" href="https://gcc.gnu.org/releases.html">GCC</a> &gt;= 7.3.0</p></li>
<li><p><a class="reference external" href="https://dl.google.com/android/repository/android-ndk-r20b-linux-x86_64.zip">Android_NDK r20b</a></p></li>
<li><p><a class="reference external" href="https://git-scm.com/downloads">Git</a> &gt;= 2.28.0</p></li>
</ul>
</li>
<li><p>Compilation dependencies of converter:</p>
<ul>
<li><p><a class="reference external" href="https://cmake.org/download/">CMake</a> &gt;= 3.14.1</p></li>
<li><p><a class="reference external" href="https://gcc.gnu.org/releases.html">GCC</a> &gt;= 7.3.0</p></li>
<li><p><a class="reference external" href="https://dl.google.com/android/repository/android-ndk-r20b-linux-x86_64.zip">Android_NDK r20b</a></p></li>
<li><p><a class="reference external" href="https://git-scm.com/downloads">Git</a> &gt;= 2.28.0</p></li>
<li><p><a class="reference external" href="http://ftp.gnu.org/gnu/autoconf/">Autoconf</a> &gt;= 2.69</p></li>
<li><p><a class="reference external" href="https://www.gnu.org/software/libtool/">Libtool</a> &gt;= 2.4.6</p></li>
<li><p><a class="reference external" href="http://www.libressl.org/">LibreSSL</a> &gt;= 3.1.3</p></li>
<li><p><a class="reference external" href="https://www.gnu.org/software/automake/">Automake</a> &gt;= 1.11.6</p></li>
<li><p><a class="reference external" href="https://libevent.org">Libevent</a> &gt;= 2.0</p></li>
<li><p><a class="reference external" href="https://www.gnu.org/software/m4/m4.html">M4</a> &gt;= 1.4.18</p></li>
<li><p><a class="reference external" href="https://www.openssl.org/">OpenSSL</a> &gt;= 1.1.1</p></li>
</ul>
</li>
</ul>
<blockquote>
<div><ul class="simple">
<li><p>To install and use <code class="docutils literal notranslate"><span class="pre">Android_NDK</span></code>, you need to configure environment variables. The command example is <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">ANDROID_NDK={$NDK_PATH}/android-ndk-r20b</span></code>.</p></li>
<li><p>In the <code class="docutils literal notranslate"><span class="pre">build.sh</span></code> script, run the <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">clone</span></code> command to obtain the code in the third-party dependency library. Ensure that the network settings of Git are correct.</p></li>
</ul>
</div></blockquote>
</section>
<section id="compilation-options">
<h3>Compilation Options<a class="headerlink" href="#compilation-options" title="Permalink to this headline"></a></h3>
<p>MindSpore Lite provides a compilation script <code class="docutils literal notranslate"><span class="pre">build.sh</span></code> for one-click compilation, located in the root directory of MindSpore. This script can be used to compile the code of training and inference. The following describes the compilation options of MindSpore Lite.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Parameter Description</p></th>
<th class="head"><p>Value Range</p></th>
<th class="head"><p>Mandatory or Not</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>-I</strong></p></td>
<td><p><strong>Selects an applicable architecture. This option is required when compile MindSpore Lite.</strong></p></td>
<td><p><strong>arm64, arm32, or x86_64</strong></p></td>
<td><p><strong>Yes</strong></p></td>
</tr>
<tr class="row-odd"><td><p>-d</p></td>
<td><p>If this parameter is set, the debug version is compiled. Otherwise, the release version is compiled.</p></td>
<td><p>None</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p>-i</p></td>
<td><p>If this parameter is set, incremental compilation is performed. Otherwise, full compilation is performed.</p></td>
<td><p>None</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p>-j[n]</p></td>
<td><p>Sets the number of threads used during compilation. Otherwise, the number of threads is set to 8 by default.</p></td>
<td><p>Integer</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p>-e</p></td>
<td><p>In the Arm architecture, select the backend operator and set the <code class="docutils literal notranslate"><span class="pre">gpu</span></code> parameter. The built-in GPU operator of the framework is compiled at the same time.</p></td>
<td><p>GPU</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p>-h</p></td>
<td><p>Displays the compilation help information.</p></td>
<td><p>None</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
<blockquote>
<div><p>When the <code class="docutils literal notranslate"><span class="pre">-I</span></code> parameter changes, such as <code class="docutils literal notranslate"><span class="pre">-I</span> <span class="pre">x86_64</span></code> is converted to <code class="docutils literal notranslate"><span class="pre">-I</span> <span class="pre">arm64</span></code>, adding <code class="docutils literal notranslate"><span class="pre">-i</span></code> for parameter compilation does not take effect.</p>
</div></blockquote>
</section>
<section id="compilation-example">
<h3>Compilation Example<a class="headerlink" href="#compilation-example" title="Permalink to this headline"></a></h3>
<p>First, download source code from the MindSpore code repository.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://gitee.com/mindspore/mindspore.git
</pre></div>
</div>
<p>Then, run the following commands in the root directory of the source code to compile MindSpore Lite of different versions:</p>
<ul>
<li><p>Debug version of the x86_64 architecture:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>build.sh<span class="w"> </span>-I<span class="w"> </span>x86_64<span class="w"> </span>-d
</pre></div>
</div>
</li>
<li><p>Release version of the x86_64 architecture, with the number of threads set:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>build.sh<span class="w"> </span>-I<span class="w"> </span>x86_64<span class="w"> </span>-j32
</pre></div>
</div>
</li>
<li><p>Release version of the Arm 64-bit architecture in incremental compilation mode, with the number of threads set:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>build.sh<span class="w"> </span>-I<span class="w"> </span>arm64<span class="w"> </span>-i<span class="w"> </span>-j32
</pre></div>
</div>
</li>
<li><p>Release version of the Arm 64-bit architecture in incremental compilation mode, with the built-in GPU operator compiled:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>build.sh<span class="w"> </span>-I<span class="w"> </span>arm64<span class="w"> </span>-e<span class="w"> </span>gpu
</pre></div>
</div>
</li>
</ul>
</section>
<section id="output-description">
<h3>Output Description<a class="headerlink" href="#output-description" title="Permalink to this headline"></a></h3>
<p>After the compilation is complete, go to the <code class="docutils literal notranslate"><span class="pre">mindspore/output</span></code> directory of the source code to view the file generated after compilation. The file is divided into two parts.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mindspore-lite-{version}-converter-{os}.tar.gz</span></code>：Contains model conversion tool.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mindspore-lite-{version}-runtime-{os}-{device}.tar.gz</span></code>：Contains model inference framework、benchmarking tool and performance analysis tool.</p></li>
</ul>
<blockquote>
<div><p>version: version of the output, consistent with that of the MindSpore.</p>
<p>device: Currently divided into cpu (built-in CPU operator) and gpu (built-in CPU and GPU operator).</p>
<p>os: Operating system on which the output will be deployed.</p>
</div></blockquote>
<p>Execute the decompression command to obtain the compiled output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tar<span class="w"> </span>-xvf<span class="w"> </span>mindspore-lite-<span class="o">{</span>version<span class="o">}</span>-converter-<span class="o">{</span>os<span class="o">}</span>.tar.gz
tar<span class="w"> </span>-xvf<span class="w"> </span>mindspore-lite-<span class="o">{</span>version<span class="o">}</span>-runtime-<span class="o">{</span>os<span class="o">}</span>-<span class="o">{</span>device<span class="o">}</span>.tar.gz
</pre></div>
</div>
<section id="description-of-converter-s-directory-structure">
<h4>Description of Converter’s Directory Structure<a class="headerlink" href="#description-of-converter-s-directory-structure" title="Permalink to this headline"></a></h4>
<p>The conversion tool is only available under the <code class="docutils literal notranslate"><span class="pre">-I</span> <span class="pre">x86_64</span></code> compilation option, and the content includes the following parts:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>|
├── mindspore-lite-{version}-converter-{os} 
│   └── converter # Model conversion Ttool
│   └── third_party # Header files and libraries of third party libraries
│       ├── protobuf # Dynamic library of Protobuf

</pre></div>
</div>
</section>
<section id="description-of-runtime-and-other-tools-directory-structure">
<h4>Description of Runtime and Other tools’ Directory Structure<a class="headerlink" href="#description-of-runtime-and-other-tools-directory-structure" title="Permalink to this headline"></a></h4>
<p>The inference framework can be obtained under <code class="docutils literal notranslate"><span class="pre">-I</span> <span class="pre">x86_64</span></code>, <code class="docutils literal notranslate"><span class="pre">-I</span> <span class="pre">arm64</span></code> and <code class="docutils literal notranslate"><span class="pre">-I</span> <span class="pre">arm32</span></code> compilation options, and the content includes the following parts:</p>
<ul>
<li><p>When the compilation option is <code class="docutils literal notranslate"><span class="pre">-I</span> <span class="pre">x86_64</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>|
├── mindspore-lite-{version}-runtime-x86-cpu 
│   └── benchmark # Benchmarking Tool
│   └── lib # Inference framework dynamic library
│       ├── libmindspore-lite.so # Dynamic library of infernece framework in MindSpore Lite
│   └── third_party # Header files and libraries of third party libraries
│       ├── flatbuffers # Header files of FlatBuffers
│   └── include # Header files of inference framework
│   └── time_profile # Model network layer time-consuming analysis tool

</pre></div>
</div>
</li>
<li><p>When the compilation option is <code class="docutils literal notranslate"><span class="pre">-I</span> <span class="pre">arm64</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>|
├── mindspore-lite-{version}-runtime-arm64-cpu
│   └── benchmark # Benchmarking Tool
│   └── lib # Inference framework dynamic library
│       ├── libmindspore-lite.so # Dynamic library of infernece framework in MindSpore Lite
│       ├── liboptimize.so # Operator performance optimization library in MindSpore Lite  
│   └── third_party # Header files and libraries of third party libraries
│       ├── flatbuffers # Header files of FlatBuffers
│   └── include # Header files of inference framework
│   └── time_profile # Model network layer time-consuming analysis tool
  
</pre></div>
</div>
</li>
<li><p>When the compilation option is <code class="docutils literal notranslate"><span class="pre">-I</span> <span class="pre">arm32</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>|
├── mindspore-lite-{version}-runtime-arm64-cpu
│   └── benchmark # Benchmarking Tool
│   └── lib # Inference framework dynamic library
│       ├── libmindspore-lite.so # Dynamic library of infernece framework in MindSpore Lite
│   └── third_party # Header files and libraries of third party libraries
│       ├── flatbuffers # Header files of FlatBuffers
│   └── include # Header files of inference framework
│   └── time_profile # Model network layer time-consuming analysis tool
  
</pre></div>
</div>
</li>
</ul>
<blockquote>
<div><ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">liboptimize.so</span></code> only exists in the output package of runtime-arm64 and is only used on ARMv8.2 and CPUs that support fp16.</p></li>
<li><p>Compile ARM64 to get the inference framework output of arm64-cpu by default, if you add <code class="docutils literal notranslate"><span class="pre">-e</span> <span class="pre">gpu</span></code>, you will get the inference framework output of arm64-gpu, and the package name is <code class="docutils literal notranslate"><span class="pre">mindspore-lite-{version}-runtime-arm64-gpu.tar.gz</span></code>, compiling ARM32 is in the same way.</p></li>
<li><p>Before running the tools in the converter, benchmark or time_profile directory, you need to configure environment variables, and configure the path where the dynamic libraries of MindSpore Lite and Protobuf are located to the path where the system searches for dynamic libraries. Take the compiled under version 0.7.0-beta as an example: configure converter: <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">LD_LIBRARY_PATH=./output/mindspore-lite-0.7.0-converter-ubuntu/third_party/protobuf/lib:${LD_LIBRARY_PATH}</span></code>; configure benchmark and timeprofiler: <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">LD_LIBRARY_PATH=</span> <span class="pre">./output/mindspore-lite-0.7.0-runtime-x86-cpu/lib:${LD_LIBRARY_PATH}</span></code>.</p></li>
</ol>
</div></blockquote>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="MindSpore Lite Tutorials" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="quick_start/quick_start.html" class="btn btn-neutral float-right" title="Implementing an Image Classification Application" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore Lite.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>