

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>AI Model Security Testing Design &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="MindSpore Armour Module Introduction" href="security_and_privacy.html" />
    <link rel="prev" title="Differential Privacy Design" href="differential_privacy_design.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindarmour_install.html">MindSpore Armour Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI Security</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluation_of_CNNCTC.html">Evaluating the Robustness of the OCR Model CNN-CTC</a></li>
<li class="toctree-l1"><a class="reference internal" href="dynamic_obfuscation_protection.html">Dynamic Model Obfuscation</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_encrypt_protection.html">Model Encryption Protection</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_suppress_privacy.html">Protecting User Privacy with Suppress Privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">Using Membership Inference to Test Model Security</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI Reliability</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="concept_drift_time_series.html">Implementing the Concept Drift Detection Application of Time Series Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="concept_drift_images.html">Implementing the Concept Drift Detection Application of Image Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="fault_injection.html">Implementing the Model Fault Injection and Evaluation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.html">mindarmour</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.attacks.html">mindarmour.adv_robustness.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.defenses.html">mindarmour.adv_robustness.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.detectors.html">mindarmour.adv_robustness.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.evaluations.html">mindarmour.adv_robustness.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.fuzz_testing.html">mindarmour.fuzz_testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.natural_robustness.transform.image.html">mindarmour.natural_robustness.transform.image</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.diff_privacy.html">mindarmour.privacy.diff_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.evaluation.html">mindarmour.privacy.evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.sup_privacy.html">mindarmour.privacy.sup_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.reliability.html">mindarmour.reliability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.utils.html">mindarmour.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="design.html">Overall Security and Trustworthiness Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="differential_privacy_design.html">Differential Privacy Design</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">AI Model Security Testing Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#background">Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fuzz-testing-design">Fuzz Testing Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fuzz-testing-process">Fuzz Testing Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="#code-implementation">Code Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="security_and_privacy.html">MindSpore Armour Module Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>AI Model Security Testing Design</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/fuzzer_design.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section class="tex2jax_ignore mathjax_ignore" id="ai-model-security-testing-design">
<h1>AI Model Security Testing Design<a class="headerlink" href="#ai-model-security-testing-design" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/master/docs/mindarmour/docs/source_en/fuzzer_design.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png"></a></p>
<section id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this headline"></a></h2>
<p>Different from <a class="reference external" href="https://zhuanlan.zhihu.com/p/43432370">fuzzing security test for traditional programs</a>, MindSpore Armour provides the AI model security test module fuzz_testing for deep neural network. Based on the neural network features, the concept of neuron coverage rate [1] is introduced to guide the fuzz testing. Fuzz testing is guided to generate samples in the direction of increasing neuron coverage rate so that more neurons can be activated by inputs. The distribution range of neuron values is wider to fully test DNN and explore the output results of different types of models and model error behavior.</p>
</section>
<section id="fuzz-testing-design">
<h2>Fuzz Testing Design<a class="headerlink" href="#fuzz-testing-design" title="Permalink to this headline"></a></h2>
<p>The following figure shows the security test design of the AI model.</p>
<p><img alt="fuzz_architecture" src="_images/fuzz_architecture.png" /></p>
<p>At the user interface layer, users need to provide the original dataset <code class="docutils literal notranslate"><span class="pre">DataSet</span></code>, tested model <code class="docutils literal notranslate"><span class="pre">Model</span></code>, and Fuzzer parameter <code class="docutils literal notranslate"><span class="pre">Fuzzer</span> <span class="pre">configuration</span></code>. After fuzzing the model and data, Fuzzer module returns the security report <code class="docutils literal notranslate"><span class="pre">Security</span> <span class="pre">Report</span></code>.</p>
<p>Fuzz testting architecture consists of three modules:</p>
<ol class="arabic">
<li><p>Natural Threat/Adversarial Example Generator:</p>
<p>Randomly select a mutation method to mutate seed data and generate multiple variants. Mutation policies supporting multiple samples include:</p>
<ul class="simple">
<li><p>Natural Robustness Methods</p>
<ul>
<li><p>Image affine transformation methods: Translate, Scale, Shear, Rotate, Perspective, Curve;</p></li>
<li><p>Image blur methods: GaussianBlur, MotionBlur, GradientBlur;</p></li>
<li><p>Luminance adjustment methods: Contrast, GradientLuminance;</p></li>
<li><p>Add noise methods: UniformNoise, GaussianNoise, SaltAndPepperNoise, NaturalNoise.</p></li>
</ul>
</li>
<li><p>Methods for generating adversarial examples based on white-box and black-box attacks: FGSM(FastGradientSignMethod), PGD(ProjectedGradientDescent), and MDIIM(MomentumDiverseInputIterativeMethod).</p></li>
</ul>
</li>
<li><p>Fuzzer Moduler:</p>
<p>Perform fuzz testing on the mutated data to observe the change of the neuron coverage rate. If the generated data increases the neuron coverage rate, add the data to the mutated seed queue for the next round of data mutation. Currently, the following neuron coverage metrics are supported: KMNC, NBC, SNAC, NC and TKNC.[2].</p>
</li>
<li><p>Evaluation:</p>
<p>Evaluate the fuzz testing effect, quality of generated data, and strength of mutation methods. Five metrics of three types are supported, including the general evaluation metric (accuracy), neuron coverage rate metrics (kmnc, nbc, snac, nc and tknc), and adversarial attack evaluation metric (attack_success_rate).</p>
</li>
</ol>
</section>
<section id="fuzz-testing-process">
<h2>Fuzz Testing Process<a class="headerlink" href="#fuzz-testing-process" title="Permalink to this headline"></a></h2>
<p><img alt="fuzz_process" src="_images/fuzz_process.png" /></p>
<p>The fuzz testing process is as follows:</p>
<ol class="arabic simple">
<li><p>Select seed A from the seed queue according to the policy.</p></li>
<li><p>Randomly select a mutation policy to mutate seed A and generate multiple variants A1, A2, …</p></li>
<li><p>Use the target model to predict the variants. If the semantics of variant is consistent with the seed, the variant enters the Fuzzed Tests.</p></li>
<li><p>If the prediction is correct, use the neuron coverage metric for analysis.</p></li>
<li><p>If a variant increases the coverage rate, place the variant in the seed queue for the next round of mutation.</p></li>
</ol>
<p>Through multiple rounds of mutations, you can obtain a series of variant data in the Fuzzed Tests, perform further analysis, and provide security reports from multiple perspectives. You can use them to deeply analyze defects of the neural network model and enhance the model to improve its universality and robustness.</p>
</section>
<section id="code-implementation">
<h2>Code Implementation<a class="headerlink" href="#code-implementation" title="Permalink to this headline"></a></h2>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://gitee.com/mindspore/mindarmour/blob/master/mindarmour/fuzz_testing/fuzzing.py">fuzzing.py</a>: overall fuzz testing process.</p></li>
<li><p><a class="reference external" href="https://gitee.com/mindspore/mindarmour/blob/master/mindarmour/fuzz_testing/model_coverage_metrics.py">model_coverage_metrics.py</a>: neuron coverage rate metrics, including KMNC, NBC, and SNAC.</p></li>
<li><p><a class="reference external" href="https://gitee.com/mindspore/mindarmour/tree/master/mindarmour/natural_robustness/transform/image">image transform methods</a>: image mutation methods, including a plurality of noise addition, blurring, brightness adjustment and affine transformation methods.</p></li>
<li><p><a class="reference external" href="https://gitee.com/mindspore/mindarmour/tree/master/mindarmour/adv_robustness/attacks">adversarial attacks</a>: methods for generating adversarial examples based on white-box and black-box attacks.</p></li>
</ol>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline"></a></h2>
<p>[1] Pei K, Cao Y, Yang J, et al. Deepxplore: Automated whitebox testing of deep learning systems[C]//Proceedings of the 26th Symposium on Operating Systems Principles. ACM, 2017: 1-18.</p>
<p>[2] Ma L, Juefei-Xu F, Zhang F, et al. Deepgauge: Multi-granularity testing criteria for deep learning systems[C]//Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. ACM, 2018: 120-131.</p>
</section>
</section>


           </div>
           
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="differential_privacy_design.html" class="btn btn-neutral float-left" title="Differential Privacy Design" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="security_and_privacy.html" class="btn btn-neutral float-right" title="MindSpore Armour Module Introduction" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>