<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindarmour.adv_robustness.attacks &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/mathjax/MathJax-3.2.2/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="mindarmour.adv_robustness.defenses" href="mindarmour.adv_robustness.defenses.html" />
    <link rel="prev" title="mindarmour" href="mindarmour.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindarmour_install.html">MindSpore Armour Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI Security</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluation_of_CNNCTC.html">Evaluating the Robustness of the OCR Model CNN-CTC</a></li>
<li class="toctree-l1"><a class="reference internal" href="dynamic_obfuscation_protection.html">Dynamic Model Obfuscation</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_encrypt_protection.html">Model Encryption Protection</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_suppress_privacy.html">Protecting User Privacy with Suppress Privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">Using Membership Inference to Test Model Security</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI Reliability</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="concept_drift_time_series.html">Implementing the Concept Drift Detection Application of Time Series Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="concept_drift_images.html">Implementing the Concept Drift Detection Application of Image Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="fault_injection.html">Implementing the Model Fault Injection and Evaluation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mindarmour.html">mindarmour</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindarmour.adv_robustness.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.defenses.html">mindarmour.adv_robustness.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.detectors.html">mindarmour.adv_robustness.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.evaluations.html">mindarmour.adv_robustness.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.fuzz_testing.html">mindarmour.fuzz_testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.natural_robustness.transform.image.html">mindarmour.natural_robustness.transform.image</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.diff_privacy.html">mindarmour.privacy.diff_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.evaluation.html">mindarmour.privacy.evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.sup_privacy.html">mindarmour.privacy.sup_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.reliability.html">mindarmour.reliability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.utils.html">mindarmour.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design.html">Overall Security and Trustworthiness Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="differential_privacy_design.html">Differential Privacy Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="fuzzer_design.html">AI Model Security Testing Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="security_and_privacy.html">MindSpore Armour Module Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>mindarmour.adv_robustness.attacks</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/mindarmour.adv_robustness.attacks.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-mindarmour.adv_robustness.attacks">
<span id="mindarmour-adv-robustness-attacks"></span><h1>mindarmour.adv_robustness.attacks<a class="headerlink" href="#module-mindarmour.adv_robustness.attacks" title="Permalink to this headline"></a></h1>
<p>This module includes classical black-box and white-box attack algorithms
in making adversarial examples.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.AutoProjectedGradientDescent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">AutoProjectedGradientDescent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span> <span class="pre">/</span> <span class="pre">255</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'inf'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eot_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thr_decr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.75</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#AutoProjectedGradientDescent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.AutoProjectedGradientDescent" title="Permalink to this definition"></a></dt>
<dd><p>APGD (Auto Projected Gradient Descent) is an iterative method and an upgraded
version of the PGD method. In this approach, perturbations are projected onto
the Lp-ball after each iteration (in addition to clipping the values of the
adversarial samples so that they lie within the allowed data range) and adaptive
steps and momentum are introduced to accelerate convergence and improve attack
performance. This is the attack proposed for adversarial training by Croce et al.</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/abs/2003.01690">Croce and Hein, “Reliable evaluation of adversarial robustness with an ensemble of     diverse parameter-free attacks” in ICML, 2020</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of adversarial perturbation generated by the
attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">8</span> <span class="pre">/</span> <span class="pre">255</span></code>.</p></li>
<li><p><strong>eps_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation
generated by the attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.1</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, untargeted
attack. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>nb_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration. Default: <code class="docutils literal notranslate"><span class="pre">10</span></code>.</p></li>
<li><p><strong>norm_level</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>numpy.inf</em><em>]</em>) – Order of the norm. Possible values:
<code class="docutils literal notranslate"><span class="pre">inf</span></code>, <code class="docutils literal notranslate"><span class="pre">1</span></code> or <code class="docutils literal notranslate"><span class="pre">2</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">inf</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><em>None</em><em>]</em>) – Loss function for optimization. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input network             is already equipped with loss function. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>eot_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration for EOT. Default: <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
<li><p><strong>thr_decr</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Parameter for step-size update. Default: <code class="docutils literal notranslate"><span class="pre">0.75</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">AutoProjectedGradientDescent</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">AutoProjectedGradientDescent</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.AutoProjectedGradientDescent.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#AutoProjectedGradientDescent.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.AutoProjectedGradientDescent.generate" title="Permalink to this definition"></a></dt>
<dd><p>Iteratively generate adversarial examples. The perturbation
is normalized by projected method with parameter <cite>norm_level</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Benign input samples used as references to
create adversarial examples.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Original/target labels.                 For each input if it has more than one label, it is wrapped in a tuple.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, generated adversarial examples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.BasicIterativeMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">BasicIterativeMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#BasicIterativeMethod"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.BasicIterativeMethod" title="Permalink to this definition"></a></dt>
<dd><p>The Basic Iterative Method attack, an iterative FGSM method to generate
adversarial examples.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1607.02533">A. Kurakin, I. Goodfellow, and S. Bengio, “Adversarial examples
in the physical world,” in ICLR, 2017</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of adversarial perturbation generated by the
attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.3</span></code>.</p></li>
<li><p><strong>eps_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation
generated by the attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.1</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, untargeted
attack. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>nb_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration. Default: <code class="docutils literal notranslate"><span class="pre">5</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><em>None</em><em>]</em>) – Loss function for optimization. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input network             is already equipped with loss function. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">BasicIterativeMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">BasicIterativeMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.BasicIterativeMethod.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#BasicIterativeMethod.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.BasicIterativeMethod.generate" title="Permalink to this definition"></a></dt>
<dd><p>Simple iterative FGSM method to generate adversarial examples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Benign input samples used as references to
create adversarial examples.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Original/target labels.                 For each input if it has more than one label, it is wrapped in a tuple.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, generated adversarial examples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.CarliniWagnerL2Attack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">CarliniWagnerL2Attack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">box_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">box_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bin_search_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confidence</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.005</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_const</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abort_early_check_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fast</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abort_early</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/carlini_wagner.html#CarliniWagnerL2Attack"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.CarliniWagnerL2Attack" title="Permalink to this definition"></a></dt>
<dd><p>The Carlini &amp; Wagner attack using L2 norm generates the adversarial examples
by utilizing two separate losses: an adversarial loss to make the generated example
actually adversarial, and a distance loss to control the quality of the adversarial example.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1608.04644">Nicholas Carlini, David Wagner: “Towards Evaluating
the Robustness of Neural Networks”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of labels of model output, which should be
greater than zero.</p></li>
<li><p><strong>box_min</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Lower bound of input of the target model. Default: <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
<li><p><strong>box_max</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Upper bound of input of the target model. Default: <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p></li>
<li><p><strong>bin_search_steps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of steps for the binary search
used to find the optimal trade-off constant between distance
and confidence. Default: <code class="docutils literal notranslate"><span class="pre">5</span></code>.</p></li>
<li><p><strong>max_iterations</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The maximum number of iterations, which should be
greater than zero. Default: <code class="docutils literal notranslate"><span class="pre">1000</span></code>.</p></li>
<li><p><strong>confidence</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Confidence of the output of adversarial examples.
Default: <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
<li><p><strong>learning_rate</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The learning rate for the attack algorithm.
Default: <code class="docutils literal notranslate"><span class="pre">5e-3</span></code>.</p></li>
<li><p><strong>initial_const</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The initial trade-off constant to use to balance
the relative importance of perturbation norm and confidence
difference. Default: <code class="docutils literal notranslate"><span class="pre">1e-2</span></code>.</p></li>
<li><p><strong>abort_early_check_ratio</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Check loss progress every ratio of
all iteration. Default: <code class="docutils literal notranslate"><span class="pre">5e-2</span></code>.</p></li>
<li><p><strong>targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, untargeted attack.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>fast</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, return the first found adversarial example.
If <code class="docutils literal notranslate"><span class="pre">False</span></code>, return the adversarial samples with smaller
perturbations. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>abort_early</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, Adam will be aborted if the loss hasn’t
decreased for some time. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, Adam will continue work until the
max iterations is arrived. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, input labels are sparse-coded. If <code class="docutils literal notranslate"><span class="pre">False</span></code>,
input labels are onehot-coded. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">CarliniWagnerL2Attack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">input_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">CarliniWagnerL2Attack</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">targeted</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_data</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_np</span><span class="p">,</span> <span class="n">label_np</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.CarliniWagnerL2Attack.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/carlini_wagner.html#CarliniWagnerL2Attack.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.CarliniWagnerL2Attack.generate" title="Permalink to this definition"></a></dt>
<dd><p>Generate adversarial examples based on input data and targeted labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Input samples.</p></li>
<li><p><strong>labels</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – The ground truth label of input samples
or target labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, generated adversarial examples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.DeepFool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">DeepFool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'classification'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reserve_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overshoot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/deep_fool.html#DeepFool"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.DeepFool" title="Permalink to this definition"></a></dt>
<dd><p>DeepFool is an untargeted &amp; iterative attack achieved by moving the benign
sample to the nearest classification boundary and crossing the boundary.</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/abs/1511.04599">DeepFool: a simple and accurate method to fool deep neural
networks</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of labels of model output, which should be
greater than zero.</p></li>
<li><p><strong>model_type</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Tye type of targeted model. <code class="docutils literal notranslate"><span class="pre">'classification'</span></code> and <code class="docutils literal notranslate"><span class="pre">'detection'</span></code> are supported now.
Default: <code class="docutils literal notranslate"><span class="pre">'classification'</span></code>.</p></li>
<li><p><strong>reserve_ratio</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – The percentage of objects that can be detected after attaks,
specifically for <cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'detection'</span></code>. Reserve_ratio should be in the range of (0, 1).
Default: <code class="docutils literal notranslate"><span class="pre">0.3</span></code>.</p></li>
<li><p><strong>max_iters</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Max iterations, which should be
greater than zero. Default: <code class="docutils literal notranslate"><span class="pre">50</span></code>.</p></li>
<li><p><strong>overshoot</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Overshoot parameter. Default: <code class="docutils literal notranslate"><span class="pre">0.02</span></code>.</p></li>
<li><p><strong>norm_level</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>numpy.inf</em><em>]</em>) – Order of the vector norm. Possible values: np.inf
or 2. Default: <code class="docutils literal notranslate"><span class="pre">2</span></code>.</p></li>
<li><p><strong>bounds</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>]</em>) – Upper and lower bounds of data range. In form of (clip_min,
clip_max). Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, input labels are sparse-coded. If <code class="docutils literal notranslate"><span class="pre">False</span></code>,
input labels are onehot-coded. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">DeepFool</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="n">input_shape</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">DeepFool</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">max_iters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">norm_level</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>                  <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_me</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">input_np</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">true_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">input_me</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">advs</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_np</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.DeepFool.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/deep_fool.html#DeepFool.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.DeepFool.generate" title="Permalink to this definition"></a></dt>
<dd><p>Generate adversarial examples based on input samples and original labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Input samples. The format of inputs should be numpy.ndarray if
<cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'classification'</span></code>. The format of inputs can be (input1, input2, …) or only
one array if <cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'detection'</span></code>.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Targeted labels or ground-truth labels. The format of labels should
be numpy.ndarray if <cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'classification'</span></code>. The format of labels should be
(gt_boxes, gt_labels) if <cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'detection'</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, adversarial examples.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#NotImplementedError" title="(in Python v3.8)"><strong>NotImplementedError</strong></a> – If <cite>norm_level</cite> is not <code class="docutils literal notranslate"><span class="pre">2</span></code>, <code class="docutils literal notranslate"><span class="pre">np.inf</span></code>, <code class="docutils literal notranslate"><span class="pre">'2'</span></code> or <code class="docutils literal notranslate"><span class="pre">'inf'</span></code>.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.DiverseInputIterativeMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">DiverseInputIterativeMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#DiverseInputIterativeMethod"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.DiverseInputIterativeMethod" title="Permalink to this definition"></a></dt>
<dd><p>The Diverse Input Iterative Method attack follows the basic iterative method,
and applies random transformation to the input data at each iteration. Such transformation
on the input data could improve the transferability of the adversarial examples.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1803.06978">Xie, Cihang and Zhang, et al., “Improving Transferability of
Adversarial Examples With Input Diversity,” in CVPR, 2019</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of adversarial perturbation generated by the
attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.3</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, untargeted
attack. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>prob</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Transformation probability. Default: <code class="docutils literal notranslate"><span class="pre">0.5</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><em>None</em><em>]</em>) – Loss function for optimization. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input network             is already equipped with loss function. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">DiverseInputIterativeMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">DiverseInputIterativeMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.FastGradientMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">FastGradientMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#FastGradientMethod"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.FastGradientMethod" title="Permalink to this definition"></a></dt>
<dd><p>This attack is a one-step attack based on gradients calculation, and
the norm of perturbations includes L1, L2 and Linf.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1412.6572">I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining
and harnessing adversarial examples,” in ICLR, 2015.</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation generated
by the attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.07</span></code>.</p></li>
<li><p><strong>alpha</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>None</em><em>]</em>) – Proportion of single-step random perturbation to data range.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>norm_level</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>numpy.inf</em><em>]</em>) – Order of the norm.
Possible values: <code class="docutils literal notranslate"><span class="pre">np.inf</span></code>, <code class="docutils literal notranslate"><span class="pre">1</span></code> or <code class="docutils literal notranslate"><span class="pre">2</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">2</span></code>.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, targeted attack. If False, untargeted
attack. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>loss</em><em>, </em><em>None</em><em>]</em>) – Loss function for optimization. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input network             is already equipped with loss function. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">FastGradientMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">FastGradientMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.FastGradientSignMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">FastGradientSignMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#FastGradientSignMethod"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.FastGradientSignMethod" title="Permalink to this definition"></a></dt>
<dd><p>The Fast Gradient Sign Method attack calculates the gradient of the input
data, and then uses the sign of the gradient to create adversarial noises.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1412.6572">Ian J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining
and harnessing adversarial examples,” in ICLR, 2015</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation generated
by the attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.07</span></code>.</p></li>
<li><p><strong>alpha</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>None</em><em>]</em>) – Proportion of single-step random perturbation to data range.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, untargeted
attack. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><em>None</em><em>]</em>) – Loss function for optimization. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input network             is already equipped with loss function. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">FastGradientSignMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">FastGradientSignMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.GeneticAttack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">GeneticAttack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'classification'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reserve_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pop_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mutation_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.005</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.15</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adaptive</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/genetic_attack.html#GeneticAttack"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.GeneticAttack" title="Permalink to this definition"></a></dt>
<dd><p>The Genetic Attack represents the black-box attack based on the genetic algorithm,
which belongs to differential evolution algorithms.</p>
<p>This attack was proposed by Moustafa Alzantot et al. (2018).</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1805.11090">Moustafa Alzantot, Yash Sharma, Supriyo Chakraborty,
“GeneticAttack: Practical Black-box Attacks with
Gradient-FreeOptimization”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="mindarmour.html#mindarmour.BlackModel" title="mindarmour.BlackModel"><em>BlackModel</em></a>) – Target model.</p></li>
<li><p><strong>model_type</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The type of targeted model. <code class="docutils literal notranslate"><span class="pre">'classification'</span></code> and <code class="docutils literal notranslate"><span class="pre">'detection'</span></code> are supported now.
Default: <code class="docutils literal notranslate"><span class="pre">'classification'</span></code>.</p></li>
<li><p><strong>targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, turns on the targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>,
turns on untargeted attack. It should be noted that only untargeted attack
is supported for <cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'detection'</span></code>, Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>reserve_ratio</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – The percentage of objects that can be detected after attacks,
specifically for <cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'detection'</span></code>. Reserve_ratio should be in the range of (0, 1).
Default: <code class="docutils literal notranslate"><span class="pre">0.3</span></code>.</p></li>
<li><p><strong>pop_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of particles, which should be greater than
zero. Default: <code class="docutils literal notranslate"><span class="pre">6</span></code>.</p></li>
<li><p><strong>mutation_rate</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – The probability of mutations, which should be in the range of (0, 1).
Default: <code class="docutils literal notranslate"><span class="pre">0.005</span></code>.</p></li>
<li><p><strong>per_bounds</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Maximum L_inf distance.</p></li>
<li><p><strong>max_steps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The maximum round of iteration for each adversarial
example. Default: <code class="docutils literal notranslate"><span class="pre">1000</span></code>.</p></li>
<li><p><strong>step_size</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Attack step size. Default: <code class="docutils literal notranslate"><span class="pre">0.2</span></code>.</p></li>
<li><p><strong>temp</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Sampling temperature for selection. Default: <code class="docutils literal notranslate"><span class="pre">0.3</span></code>.
The greater the temp, the greater the differences between individuals’
selecting probabilities.</p></li>
<li><p><strong>bounds</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><em>None</em><em>]</em>) – Upper and lower bounds of data. In form
of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>adaptive</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, turns on dynamic scaling of mutation
parameters. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, turns on static mutation parameters.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, input labels are sparse-encoded. If <code class="docutils literal notranslate"><span class="pre">False</span></code>,
input labels are one-hot-encoded. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>c</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Weight of perturbation loss. Default: <code class="docutils literal notranslate"><span class="pre">0.1</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">M</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Cell</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">GeneticAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">GeneticAttack</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)[</span><span class="n">y_test</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">adv_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.GeneticAttack.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/genetic_attack.html#GeneticAttack.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.GeneticAttack.generate" title="Permalink to this definition"></a></dt>
<dd><p>Generate adversarial examples based on input data and targeted labels (or ground_truth labels).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Input samples. The format of inputs should be numpy.ndarray if
<cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'classification'</span></code>. The format of inputs can be (input1, input2, …) or only
one array if <cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'detection'</span></code>.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Targeted labels or ground-truth labels. The format of labels should
be numpy.ndarray if <cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'classification'</span></code>. The format of labels should be
(gt_boxes, gt_labels) if <cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'detection'</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>numpy.ndarray, bool values for each attack result.</p></li>
<li><p>numpy.ndarray, generated adversarial examples.</p></li>
<li><p>numpy.ndarray, query times for each sample.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.HopSkipJumpAttack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">HopSkipJumpAttack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_num_evals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_evals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stepsize_search</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'geometric_progression'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'l2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/hop_skip_jump_attack.html#HopSkipJumpAttack"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.HopSkipJumpAttack" title="Permalink to this definition"></a></dt>
<dd><p>HopSkipJumpAttack proposed by Chen, Jordan and Wainwright is a
decision-based attack. The attack requires access to output labels of
target model.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1904.02144">Chen J, Michael I. Jordan, Martin J. Wainwright.
HopSkipJumpAttack: A Query-Efficient Decision-Based Attack. 2019.
arXiv:1904.02144</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="mindarmour.html#mindarmour.BlackModel" title="mindarmour.BlackModel"><em>BlackModel</em></a>) – Target model.</p></li>
<li><p><strong>init_num_evals</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The initial number of evaluations for gradient
estimation. Default: <code class="docutils literal notranslate"><span class="pre">100</span></code>.</p></li>
<li><p><strong>max_num_evals</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The maximum number of evaluations for gradient
estimation. Default: <code class="docutils literal notranslate"><span class="pre">1000</span></code>.</p></li>
<li><p><strong>stepsize_search</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Indicating how to search for stepsize; Possible
values are <code class="docutils literal notranslate"><span class="pre">'geometric_progression'</span></code>, <code class="docutils literal notranslate"><span class="pre">'grid_search'</span></code>.
Default: <code class="docutils literal notranslate"><span class="pre">'geometric_progression'</span></code>.</p></li>
<li><p><strong>num_iterations</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of iterations. Default: <code class="docutils literal notranslate"><span class="pre">20</span></code>.</p></li>
<li><p><strong>gamma</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Used to set binary search threshold theta. Default: <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.
For l2 attack the binary search threshold <cite>theta</cite> is
<span class="math notranslate nohighlight">\(gamma / d^{3/2}\)</span>. For linf attack is <span class="math notranslate nohighlight">\(gamma / d^2\)</span>.
Default: <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p></li>
<li><p><strong>constraint</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The norm distance to optimize. Possible values are <code class="docutils literal notranslate"><span class="pre">'l2'</span></code>,
<code class="docutils literal notranslate"><span class="pre">'linf'</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'l2'</span></code>.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Batch size. Default: <code class="docutils literal notranslate"><span class="pre">32</span></code>.</p></li>
<li><p><strong>clip_min</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – The minimum image component value.
Default: <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
<li><p><strong>clip_max</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – The maximum image component value.
Default: <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, input labels are sparse-encoded. If <code class="docutils literal notranslate"><span class="pre">False</span></code>,
input labels are one-hot-encoded. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>stepsize_search</cite> is not <code class="docutils literal notranslate"><span class="pre">'geometric_progression'</span></code> or
    <code class="docutils literal notranslate"><span class="pre">'grid_search'</span></code>.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>constraint</cite> is not <code class="docutils literal notranslate"><span class="pre">'l2'</span></code> or <code class="docutils literal notranslate"><span class="pre">'linf'</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">HopSkipJumpAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">HopSkipJumpAttack</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">class_num</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">n</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">class_num</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">adv_x</span><span class="p">,</span> <span class="n">_</span><span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.HopSkipJumpAttack.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/hop_skip_jump_attack.html#HopSkipJumpAttack.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.HopSkipJumpAttack.generate" title="Permalink to this definition"></a></dt>
<dd><p>Generate adversarial images in a for loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Origin images.</p></li>
<li><p><strong>labels</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Target labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>numpy.ndarray, bool values for each attack result.</p></li>
<li><p>numpy.ndarray, generated adversarial examples.</p></li>
<li><p>numpy.ndarray, query times for each sample.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.HopSkipJumpAttack.set_target_images">
<span class="sig-name descname"><span class="pre">set_target_images</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_images</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/hop_skip_jump_attack.html#HopSkipJumpAttack.set_target_images"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.HopSkipJumpAttack.set_target_images" title="Permalink to this definition"></a></dt>
<dd><p>Setting target images for target attack.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target_images</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Target images.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.IterativeGradientMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">IterativeGradientMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#IterativeGradientMethod"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.IterativeGradientMethod" title="Permalink to this definition"></a></dt>
<dd><p>Abstract base class for all iterative gradient based attacks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of adversarial perturbation generated by the
attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.3</span></code>.</p></li>
<li><p><strong>eps_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation
generated by the attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.1</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>nb_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration. Default: <code class="docutils literal notranslate"><span class="pre">5</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><em>None</em><em>]</em>) – Loss function for optimization. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input network             is already equipped with loss function. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.IterativeGradientMethod.generate">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#IterativeGradientMethod.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.IterativeGradientMethod.generate" title="Permalink to this definition"></a></dt>
<dd><p>Generate adversarial examples based on input samples and original/target labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Benign input samples used as references to create
adversarial examples.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Original/target labels.                 For each input if it has more than one label, it is wrapped in a tuple.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#NotImplementedError" title="(in Python v3.8)"><strong>NotImplementedError</strong></a> – This function is not available in
    IterativeGradientMethod.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.JSMAAttack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">JSMAAttack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">box_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">box_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">theta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_count</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">increase</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/jsma.html#JSMAAttack"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.JSMAAttack" title="Permalink to this definition"></a></dt>
<dd><p>Jacobian-based Saliency Map Attack is a targeted and iterative attack based on saliency
map of the input features. It uses the gradient of loss with each class labels with respect
to every component of the input. Then a saliency map is used to select the dimension which
produces the maximum error.</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/abs/1511.07528">The limitations of deep learning in adversarial settings</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of labels of model output, which should be
greater than zero.</p></li>
<li><p><strong>box_min</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Lower bound of input of the target model. Default: <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
<li><p><strong>box_max</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Upper bound of input of the target model. Default: <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p></li>
<li><p><strong>theta</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Change ratio of one pixel (relative to
input data range). Default: <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p></li>
<li><p><strong>max_iteration</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Maximum round of iteration. Default: <code class="docutils literal notranslate"><span class="pre">1000</span></code>.</p></li>
<li><p><strong>max_count</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Maximum times to change each pixel. Default: <code class="docutils literal notranslate"><span class="pre">3</span></code>.</p></li>
<li><p><strong>increase</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, increase perturbation. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, decrease
perturbation. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, input labels are sparse-coded. If <code class="docutils literal notranslate"><span class="pre">False</span></code>,
input labels are onehot-coded. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">JSMAAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="n">input_shape</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">JSMAAttack</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">max_iteration</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">advs</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_np</span><span class="p">,</span> <span class="n">label_np</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.JSMAAttack.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/jsma.html#JSMAAttack.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.JSMAAttack.generate" title="Permalink to this definition"></a></dt>
<dd><p>Generate adversarial examples in batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Input samples.</p></li>
<li><p><strong>labels</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Target labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, adversarial samples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.LBFGS">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">LBFGS</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">150</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_iters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/lbfgs.html#LBFGS"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.LBFGS" title="Permalink to this definition"></a></dt>
<dd><p>In L-BFGS-B attack, the Limited-Memory BFGS optimizaiton algorithm is used
to minimize the distance between the inputs and the adversarial examples.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1510.05328">Pedro Tabacof, Eduardo Valle. “Exploring the Space of
Adversarial Images”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – The network of attacked model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Attack step size. Default: <code class="docutils literal notranslate"><span class="pre">1e-5</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data. Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, untargeted
attack. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>nb_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration of lbfgs-optimizer, which should be
greater than zero. Default: <code class="docutils literal notranslate"><span class="pre">150</span></code>.</p></li>
<li><p><strong>search_iters</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of changes in step size, which should be
greater than zero. Default: <code class="docutils literal notranslate"><span class="pre">30</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Functions</em>) – Loss function of substitute model. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, input labels are sparse-coded. If <code class="docutils literal notranslate"><span class="pre">False</span></code>,
input labels are onehot-coded. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">LBFGS</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">LBFGS</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">is_targeted</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">7</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)[</span><span class="n">target_np</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_np</span><span class="p">,</span> <span class="n">target_np</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.LBFGS.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/lbfgs.html#LBFGS.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.LBFGS.generate" title="Permalink to this definition"></a></dt>
<dd><p>Generate adversarial examples based on input data and target labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Benign input samples used as references to create
adversarial examples.</p></li>
<li><p><strong>labels</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Original/target labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, generated adversarial examples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.LeastLikelyClassMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">LeastLikelyClassMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#LeastLikelyClassMethod"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.LeastLikelyClassMethod" title="Permalink to this definition"></a></dt>
<dd><p>The Single Step Least-Likely Class Method, a variant of FGSM, targets the
least-likely class to generate the adversarial examples.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1705.07204">F. Tramer, et al., “Ensemble adversarial training: Attacks
and defenses,” in ICLR, 2018</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation generated
by the attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.07</span></code>.</p></li>
<li><p><strong>alpha</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>None</em><em>]</em>) – Proportion of single-step random perturbation to data range.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><em>None</em><em>]</em>) – Loss function for optimization. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input network             is already equipped with loss function. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">LeastLikelyClassMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">LeastLikelyClassMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.MomentumDiverseInputIterativeMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">MomentumDiverseInputIterativeMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'l1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#MomentumDiverseInputIterativeMethod"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.MomentumDiverseInputIterativeMethod" title="Permalink to this definition"></a></dt>
<dd><p>The Momentum Diverse Input Iterative Method attack is a momentum iterative method,
and applies random transformation to the input data at each iteration. Such transformation
on the input data could improve the transferability of the adversarial examples.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1803.06978">Xie, Cihang and Zhang, et al., “Improving Transferability of
Adversarial Examples With Input Diversity,” in CVPR, 2019</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of adversarial perturbation generated by the
attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.3</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, untargeted
attack. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>norm_level</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>numpy.inf</em><em>]</em>) – Order of the norm. Possible values:
np.inf, 1 or 2. Default: <code class="docutils literal notranslate"><span class="pre">'l1'</span></code>.</p></li>
<li><p><strong>prob</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Transformation probability. Default: <code class="docutils literal notranslate"><span class="pre">0.5</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><em>None</em><em>]</em>) – Loss function for optimization. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input network             is already equipped with loss function. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">MomentumDiverseInputIterativeMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">MomentumDiverseInputIterativeMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.MomentumIterativeMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">MomentumIterativeMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decay_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'inf'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#MomentumIterativeMethod"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.MomentumIterativeMethod" title="Permalink to this definition"></a></dt>
<dd><p>The Momentum Iterative Method attack accelerates the gradient descent algorithm,
such as FGSM, FGM, and LLCM, by accumulating a velocity vector in the gradient
direction of the loss function across iterations, and thus generates the adversarial examples.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1710.06081">Y. Dong, et al., “Boosting adversarial attacks with
momentum,” arXiv:1710.06081, 2017</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of adversarial perturbation generated by the
attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.3</span></code>.</p></li>
<li><p><strong>eps_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation
generated by the attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.1</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, untargeted
attack. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>nb_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration. Default: <code class="docutils literal notranslate"><span class="pre">5</span></code>.</p></li>
<li><p><strong>decay_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Decay factor in iterations. Default: <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p></li>
<li><p><strong>norm_level</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>numpy.inf</em><em>]</em>) – Order of the norm. Possible values:
<code class="docutils literal notranslate"><span class="pre">np.inf</span></code>, <code class="docutils literal notranslate"><span class="pre">1</span></code> or <code class="docutils literal notranslate"><span class="pre">2</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'inf'</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><em>None</em><em>]</em>) – Loss function for optimization. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input network             is already equipped with loss function. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">MomentumIterativeMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">MomentumIterativeMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.MomentumIterativeMethod.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#MomentumIterativeMethod.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.MomentumIterativeMethod.generate" title="Permalink to this definition"></a></dt>
<dd><p>Generate adversarial examples based on input data and origin/target labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Benign input samples used as references to
create adversarial examples.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Original/target labels.                 For each input if it has more than one label, it is wrapped in a tuple.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, generated adversarial examples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.NES">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">NES</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scene</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_queries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples_per_draw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0005</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plateau_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plateau_drop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adv_thresh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zero_iters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">starting_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">starting_delta_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_only_sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conservative</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/natural_evolutionary_strategy.html#NES"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.NES" title="Permalink to this definition"></a></dt>
<dd><p>The class is an implementation of the Natural Evolutionary Strategies Attack
Method. NES uses natural evolutionary strategies to estimate gradients to
improve query efficiency. NES covers three settings: Query-Limited setting,
Partial-Information setting and Label-Only setting. In the query-limit
setting, the attack has a limited number of queries to the target model but
access to the probabilities of all classes. In the partial-info setting,
the attack only has access to the probabilities for top-k classes.
In the label-only setting, the attack only has access to a list of k inferred
labels ordered by their predicted probabilities. In the Partial-Information
setting and Label-Only setting, NES do target attack so user need to use
set_target_images method to set target images of target classes.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1804.08598">Andrew Ilyas, Logan Engstrom, Anish Athalye, and Jessy Lin.
Black-box adversarial attacks with limited queries and information. In
ICML, July 2018</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="mindarmour.html#mindarmour.BlackModel" title="mindarmour.BlackModel"><em>BlackModel</em></a>) – Target model to be attacked.</p></li>
<li><p><strong>scene</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Scene in <code class="docutils literal notranslate"><span class="pre">'Label_Only'</span></code>, <code class="docutils literal notranslate"><span class="pre">'Partial_Info'</span></code> or <code class="docutils literal notranslate"><span class="pre">'Query_Limit'</span></code>.</p></li>
<li><p><strong>max_queries</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Maximum query numbers to generate an adversarial example. Default: <code class="docutils literal notranslate"><span class="pre">10000</span></code>.</p></li>
<li><p><strong>top_k</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – For Partial-Info or Label-Only setting, indicating how much (Top-k) information is
available for the attacker. For Query-Limited setting, this input should be set as <code class="docutils literal notranslate"><span class="pre">-1</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">-1</span></code>.</p></li>
<li><p><strong>num_class</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of classes in dataset. Default: <code class="docutils literal notranslate"><span class="pre">10</span></code>.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Batch size. Default: <code class="docutils literal notranslate"><span class="pre">128</span></code>.</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Maximum perturbation allowed in attack. Default: <code class="docutils literal notranslate"><span class="pre">0.3</span></code>.</p></li>
<li><p><strong>samples_per_draw</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of samples draw in antithetic sampling. Default: <code class="docutils literal notranslate"><span class="pre">128</span></code>.</p></li>
<li><p><strong>momentum</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Momentum. Default: <code class="docutils literal notranslate"><span class="pre">0.9</span></code>.</p></li>
<li><p><strong>learning_rate</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Learning rate. Default: <code class="docutils literal notranslate"><span class="pre">1e-3</span></code>.</p></li>
<li><p><strong>max_lr</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Max Learning rate. Default: <code class="docutils literal notranslate"><span class="pre">5e-2</span></code>.</p></li>
<li><p><strong>min_lr</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Min Learning rate. Default: <code class="docutils literal notranslate"><span class="pre">5e-4</span></code>.</p></li>
<li><p><strong>sigma</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Step size of random noise. Default: <code class="docutils literal notranslate"><span class="pre">1e-3</span></code>.</p></li>
<li><p><strong>plateau_length</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Length of plateau used in Annealing algorithm. Default: <code class="docutils literal notranslate"><span class="pre">20</span></code>.</p></li>
<li><p><strong>plateau_drop</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Drop of plateau used in Annealing algorithm. Default: <code class="docutils literal notranslate"><span class="pre">2.0</span></code>.</p></li>
<li><p><strong>adv_thresh</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Threshold of adversarial. Default: <code class="docutils literal notranslate"><span class="pre">0.25</span></code>.</p></li>
<li><p><strong>zero_iters</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of points to use for the proxy score. Default: <code class="docutils literal notranslate"><span class="pre">10</span></code>.</p></li>
<li><p><strong>starting_eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Starting epsilon used in Label-Only setting. Default: <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p></li>
<li><p><strong>starting_delta_eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Delta epsilon used in Label-Only setting. Default: <code class="docutils literal notranslate"><span class="pre">0.5</span></code>.</p></li>
<li><p><strong>label_only_sigma</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Sigma used in Label-Only setting. Default: <code class="docutils literal notranslate"><span class="pre">1e-3</span></code>.</p></li>
<li><p><strong>conservative</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Conservation used in epsilon decay, it will increase if no convergence. Default: <code class="docutils literal notranslate"><span class="pre">2</span></code>.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, input labels are sparse-encoded. If <code class="docutils literal notranslate"><span class="pre">False</span></code>,
input labels are one-hot-encoded. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">NES</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">SCENE</span> <span class="o">=</span> <span class="s1">&#39;Query_Limit&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TOP_K</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span><span class="o">=</span> <span class="n">NES</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">SCENE</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">TOP_K</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_class</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_image</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">orig_class</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_class</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span><span class="o">.</span><span class="n">set_target_images</span><span class="p">(</span><span class="n">target_image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tag</span><span class="p">,</span> <span class="n">adv</span><span class="p">,</span> <span class="n">queries</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">target_class</span><span class="p">]))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.NES.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/natural_evolutionary_strategy.html#NES.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.NES.generate" title="Permalink to this definition"></a></dt>
<dd><p>Generate adversarial examples based on input data and target labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Benign input samples.</p></li>
<li><p><strong>labels</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Target labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>numpy.ndarray, bool values for each attack result.</p></li>
<li><p>numpy.ndarray, generated adversarial examples.</p></li>
<li><p>numpy.ndarray, query times for each sample.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the <cite>top_k</cite> less than 0 in Label-Only or Partial-Info setting.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the <cite>target_imgs</cite> is <code class="docutils literal notranslate"><span class="pre">None</span></code> in Label-Only or Partial-Info setting.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>scene</cite> is not <code class="docutils literal notranslate"><span class="pre">'Label_Only'</span></code>, <code class="docutils literal notranslate"><span class="pre">'Partial_Info'</span></code> or <code class="docutils literal notranslate"><span class="pre">'Query_Limit'</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.NES.set_target_images">
<span class="sig-name descname"><span class="pre">set_target_images</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_images</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/natural_evolutionary_strategy.html#NES.set_target_images"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.NES.set_target_images" title="Permalink to this definition"></a></dt>
<dd><p>Set target samples for target attack in the Partial-Info setting or Label-Only setting.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target_images</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Target samples for target attack.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.PSOAttack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">PSOAttack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'classification'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reserve_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pop_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/pso_attack.html#PSOAttack"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.PSOAttack" title="Permalink to this definition"></a></dt>
<dd><p>The PSO Attack represents the black-box attack based on Particle Swarm
Optimization algorithm, which belongs to differential evolution algorithms.
This attack was proposed by Rayan Mosli et al. (2019).</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1909.07490">Rayan Mosli, Matthew Wright, Bo Yuan, Yin Pan, “They Might NOT
Be Giants: Crafting Black-Box Adversarial Examples with Fewer Queries
Using Particle Swarm Optimization”, arxiv: 1909.07490, 2019.</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="mindarmour.html#mindarmour.BlackModel" title="mindarmour.BlackModel"><em>BlackModel</em></a>) – Target model.</p></li>
<li><p><strong>step_size</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Attack step size. Default: <code class="docutils literal notranslate"><span class="pre">0.5</span></code>.</p></li>
<li><p><strong>per_bounds</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Relative variation range of perturbations. Default: <code class="docutils literal notranslate"><span class="pre">0.6</span></code>.</p></li>
<li><p><strong>c1</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Weight coefficient. Default: <code class="docutils literal notranslate"><span class="pre">2</span></code>.</p></li>
<li><p><strong>c2</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Weight coefficient. Default: <code class="docutils literal notranslate"><span class="pre">2</span></code>.</p></li>
<li><p><strong>c</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Weight of perturbation loss. Default: <code class="docutils literal notranslate"><span class="pre">2</span></code>.</p></li>
<li><p><strong>pop_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of particles, which should be greater
than zero. Default: <code class="docutils literal notranslate"><span class="pre">6</span></code>.</p></li>
<li><p><strong>t_max</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The maximum round of iteration for each adversarial example,
which should be greater than zero. Default: <code class="docutils literal notranslate"><span class="pre">1000</span></code>.</p></li>
<li><p><strong>pm</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – The probability of mutations, which should be in the range of (0, 1).
Default: <code class="docutils literal notranslate"><span class="pre">0.5</span></code>.</p></li>
<li><p><strong>bounds</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><em>None</em><em>]</em>) – Upper and lower bounds of data. In form of (clip_min,
clip_max). Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, turns on the targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>,
turns on untargeted attack. It should be noted that only untargeted attack
is supported for <cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'detection'</span></code>, Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, input labels are sparse-encoded. If <code class="docutils literal notranslate"><span class="pre">False</span></code>,
input labels are one-hot-encoded. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>model_type</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The type of targeted model. <code class="docutils literal notranslate"><span class="pre">'classification'</span></code> and <code class="docutils literal notranslate"><span class="pre">'detection'</span></code> are supported now.
default: <code class="docutils literal notranslate"><span class="pre">'classification'</span></code>.</p></li>
<li><p><strong>reserve_ratio</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – The percentage of objects that can be detected after attacks,
specifically for <cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'detection'</span></code>. Reserve_ratio should be in the range of (0, 1).
Default: <code class="docutils literal notranslate"><span class="pre">0.3</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Cell</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">PSOAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">PSOAttack</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">pm</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)[</span><span class="n">y_test</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">adv_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.PSOAttack.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/pso_attack.html#PSOAttack.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.PSOAttack.generate" title="Permalink to this definition"></a></dt>
<dd><p>Generate adversarial examples based on input data and
targeted labels (or ground_truth labels).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Input samples. The format of inputs should be numpy.ndarray if
<cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'classification'</span></code>. The format of inputs can be (input1, input2, …) or only
one array if <cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'detection'</span></code>.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Targeted labels or ground-truth labels. The format of labels should
be numpy.ndarray if <cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'classification'</span></code>. The format of labels should be
(gt_boxes, gt_labels) if <cite>model_type</cite> is <code class="docutils literal notranslate"><span class="pre">'detection'</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>numpy.ndarray, bool values for each attack result.</p></li>
<li><p>numpy.ndarray, generated adversarial examples.</p></li>
<li><p>numpy.ndarray, query times for each sample.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.PointWiseAttack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">PointWiseAttack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_attack</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/pointwise_attack.html#PointWiseAttack"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.PointWiseAttack" title="Permalink to this definition"></a></dt>
<dd><p>The Pointwise Attack make sure use the minimum number of changed pixels to generate adversarial sample for each
original sample.Those changed pixels will use binary search to make sure the distance between adversarial sample
and original sample is as close as possible.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1805.09190">L. Schott, J. Rauber, M. Bethge, W. Brendel: “Towards the
first adversarially robust neural network model on MNIST”, ICLR (2019)</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="mindarmour.html#mindarmour.BlackModel" title="mindarmour.BlackModel"><em>BlackModel</em></a>) – Target model.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Max rounds of iteration to generate adversarial image. Default: <code class="docutils literal notranslate"><span class="pre">1000</span></code>.</p></li>
<li><p><strong>search_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Max rounds of binary search. Default: <code class="docutils literal notranslate"><span class="pre">10</span></code>.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, untargeted attack. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>init_attack</strong> (<em>Union</em><em>[</em><a class="reference internal" href="mindarmour.html#mindarmour.Attack" title="mindarmour.Attack"><em>Attack</em></a><em>, </em><em>None</em><em>]</em>) – Attack used to find a starting point. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, input labels are sparse-encoded. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, input labels are one-hot-encoded.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">PointWiseAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">PointWiseAttack</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">is_adv_list</span><span class="p">,</span> <span class="n">adv_list</span><span class="p">,</span> <span class="n">query_times_each_adv</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.PointWiseAttack.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/pointwise_attack.html#PointWiseAttack.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.PointWiseAttack.generate" title="Permalink to this definition"></a></dt>
<dd><p>Generate adversarial examples based on input samples and targeted labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Benign input samples used as references to create adversarial examples.</p></li>
<li><p><strong>labels</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – For targeted attack, labels are adversarial target labels.
For untargeted attack, labels are ground-truth labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>numpy.ndarray, bool values for each attack result.</p></li>
<li><p>numpy.ndarray, generated adversarial examples.</p></li>
<li><p>numpy.ndarray, query times for each sample.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.ProjectedGradientDescent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">ProjectedGradientDescent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'inf'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#ProjectedGradientDescent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.ProjectedGradientDescent" title="Permalink to this definition"></a></dt>
<dd><p>The Projected Gradient Descent attack is a variant of the Basic Iterative
Method in which, after each iteration, the perturbation is projected on an
lp-ball of specified radius (in addition to clipping the values of the
adversarial sample so that it lies in the permitted data range). This is
the attack proposed by Madry et al. for adversarial training.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1706.06083">A. Madry, et al., “Towards deep learning models resistant to
adversarial attacks,” in ICLR, 2018</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of adversarial perturbation generated by the
attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.3</span></code>.</p></li>
<li><p><strong>eps_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation
generated by the attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.1</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, untargeted
attack. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>nb_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration. Default: <code class="docutils literal notranslate"><span class="pre">5</span></code>.</p></li>
<li><p><strong>norm_level</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>numpy.inf</em><em>]</em>) – Order of the norm. Possible values:
np.inf, 1 or 2. Default: <code class="docutils literal notranslate"><span class="pre">'inf'</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><em>None</em><em>]</em>) – Loss function for optimization. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input network             is already equipped with loss function. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">ProjectedGradientDescent</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">ProjectedGradientDescent</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.ProjectedGradientDescent.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#ProjectedGradientDescent.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.ProjectedGradientDescent.generate" title="Permalink to this definition"></a></dt>
<dd><p>Iteratively generate adversarial examples. The
perturbation is normalized by projected method with parameter norm_level .</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Benign input samples used as references to
create adversarial examples.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Original/target labels.                 For each input if it has more than one label, it is wrapped in a tuple.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, generated adversarial examples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.RandomFastGradientMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">RandomFastGradientMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.035</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#RandomFastGradientMethod"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.RandomFastGradientMethod" title="Permalink to this definition"></a></dt>
<dd><p>Fast Gradient Method use Random perturbation.
An one-step attack based on gradients calculation. The adversarial noises
are generated based on the gradients of inputs, and then randomly perturbed.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1705.07204">Florian Tramer, Alexey Kurakin, Nicolas Papernot, “Ensemble
adversarial training: Attacks and defenses” in ICLR, 2018</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation generated
by the attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.07</span></code>.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step random perturbation to data range.
Default: <code class="docutils literal notranslate"><span class="pre">0.035</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>norm_level</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>numpy.inf</em><em>]</em>) – Order of the norm.
Possible values: <code class="docutils literal notranslate"><span class="pre">np.inf</span></code>, <code class="docutils literal notranslate"><span class="pre">1</span></code> or <code class="docutils literal notranslate"><span class="pre">2</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">2</span></code>.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, untargeted
attack. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>loss</em><em>, </em><em>None</em><em>]</em>) – Loss function for optimization. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input network             is already equipped with loss function. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – <cite>eps</cite> is smaller than <cite>alpha</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">RandomFastGradientMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">RandomFastGradientMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.RandomFastGradientSignMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">RandomFastGradientSignMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.035</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#RandomFastGradientSignMethod"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.RandomFastGradientSignMethod" title="Permalink to this definition"></a></dt>
<dd><p>Fast Gradient Sign Method using random perturbation.
The Random Fast Gradient Sign Method attack calculates the gradient of the input
data, and then uses the sign of the gradient with random perturbation
to create adversarial noises.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1705.07204">F. Tramer, et al., “Ensemble adversarial training: Attacks
and defenses,” in ICLR, 2018</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation generated
by the attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.07</span></code>.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step random perturbation to data range.
Default: <code class="docutils literal notranslate"><span class="pre">0.035</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – <code class="docutils literal notranslate"><span class="pre">True</span></code>: targeted attack. <code class="docutils literal notranslate"><span class="pre">False</span></code>: untargeted attack.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><em>None</em><em>]</em>) – Loss function for optimization. If None, the input network             is already equipped with loss function. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – eps is smaller than alpha!</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">RandomFastGradientSignMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">RandomFastGradientSignMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.RandomLeastLikelyClassMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">RandomLeastLikelyClassMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.035</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#RandomLeastLikelyClassMethod"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.RandomLeastLikelyClassMethod" title="Permalink to this definition"></a></dt>
<dd><p>Least-Likely Class Method use Random perturbation.</p>
<p>The Single Step Least-Likely Class Method with Random Perturbation, a variant of Random FGSM,
targets the least-likely class to generate the adversarial examples.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1705.07204">F. Tramer, et al., “Ensemble adversarial training: Attacks
and defenses,” in ICLR, 2018</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation generated
by the attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.07</span></code>.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step random perturbation to data range.
Default: <code class="docutils literal notranslate"><span class="pre">0.035</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><em>None</em><em>]</em>) – Loss function for optimization. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input network             is already equipped with loss function. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – eps is smaller than alpha!</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">RandomLeastLikelyClassMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">RandomLeastLikelyClassMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.SaltAndPepperNoiseAttack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">SaltAndPepperNoiseAttack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/salt_and_pepper_attack.html#SaltAndPepperNoiseAttack"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.SaltAndPepperNoiseAttack" title="Permalink to this definition"></a></dt>
<dd><p>Increases the amount of salt and pepper noise  to generate adversarial samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="mindarmour.html#mindarmour.BlackModel" title="mindarmour.BlackModel"><em>BlackModel</em></a>) – Target model.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data. In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Max iteration to generate an adversarial example. Default: <code class="docutils literal notranslate"><span class="pre">100</span></code>.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, untargeted attack. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, input labels are sparse-encoded. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, input labels are one-hot-encoded.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">SaltAndPepperNoiseAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">SaltAndPepperNoiseAttack</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">adv_list</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.SaltAndPepperNoiseAttack.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/salt_and_pepper_attack.html#SaltAndPepperNoiseAttack.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.SaltAndPepperNoiseAttack.generate" title="Permalink to this definition"></a></dt>
<dd><p>Generate adversarial examples based on input data and target labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – The original, unperturbed inputs.</p></li>
<li><p><strong>labels</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – The target labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>numpy.ndarray, bool values for each attack result.</p></li>
<li><p>numpy.ndarray, generated adversarial examples.</p></li>
<li><p>numpy.ndarray, query times for each sample.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.VarianceTuningMomentumIterativeMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">VarianceTuningMomentumIterativeMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decay_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_neighbor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neighbor_beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span> <span class="pre">/</span> <span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'inf'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#VarianceTuningMomentumIterativeMethod"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.VarianceTuningMomentumIterativeMethod" title="Permalink to this definition"></a></dt>
<dd><p>VMI-FGSM is a momentum iterative method, it aggregate the gradient with variance on the input data
in each iteration, and could improve the transferability of the adversarial examples.</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/abs/2103.15571">X Wang, H Kun, “Enhancing the Transferability of Adversarial Attacks through Variance Tuning”
in CVPR, 2021</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of adversarial perturbation generated by the
attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">0.3</span></code>.</p></li>
<li><p><strong>eps_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The proportion of perturbation in each step. Default: <code class="docutils literal notranslate"><span class="pre">0.1</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, untargeted
attack. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>nb_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration. Default: <code class="docutils literal notranslate"><span class="pre">5</span></code>.</p></li>
<li><p><strong>decay_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The momentum factor. Default: <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p></li>
<li><p><strong>nb_neighbor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of sampled examples in the neighborhood.</p></li>
<li><p><strong>neighbor_beta</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The upper bound of neighborhood. Default: <code class="docutils literal notranslate"><span class="pre">3/2</span></code>.</p></li>
<li><p><strong>norm_level</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>numpy.inf</em><em>]</em>) – Order of the norm. Possible values:
np.inf, 1 or 2. Default: <code class="docutils literal notranslate"><span class="pre">inf</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><em>None</em><em>]</em>) – Loss function for optimization. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input network             is already equipped with loss function. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">VarianceTuningMomentumIterativeMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">VarianceTuningMomentumIterativeMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">nb_neighbor</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">neighbor_beta</span><span class="o">=</span><span class="mi">3</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.VarianceTuningMomentumIterativeMethod.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#VarianceTuningMomentumIterativeMethod.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.VarianceTuningMomentumIterativeMethod.generate" title="Permalink to this definition"></a></dt>
<dd><p>Generate adversarial examples based on input data and origin/target labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Benign input samples used as references to
create adversarial examples.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Original/target labels.                 For each input if it has more than one label, it is wrapped in a tuple.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, generated adversarial examples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.VarianceTuningNesterovIterativeMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">VarianceTuningNesterovIterativeMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span> <span class="pre">/</span> <span class="pre">255</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span> <span class="pre">/</span> <span class="pre">255</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decay_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_neighbor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neighbor_beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span> <span class="pre">/</span> <span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'inf'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#VarianceTuningNesterovIterativeMethod"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.VarianceTuningNesterovIterativeMethod" title="Permalink to this definition"></a></dt>
<dd><p>VNI-FGSM algorithm is an iterative gradient-based adversarial attack method.
Compared with VMI-FGSM,VNI-FGSM uses not only the current gradient but also the average gradient of
all previous iterations in each iteration, thus increasing the stability and robustness of the attack.
Experimental results show that the attack mobility can be improved by more than 30%, and VNI-FGSM
has a higher attack success rate against the training model compared to the VMI-FGSM algorithm.</p>
<p>References: VNI-FGSM in the paper Enhancing the Transferability of Adversarial
Attacks through Variance Tuning [<a class="reference external" href="https://arxiv.org/abs/2103.15571">https://arxiv.org/abs/2103.15571</a>], published as
a conference paper at CVPR 2021 Modified from “<a class="reference external" href="https://github.com/JHL-HUST/VT">https://github.com/JHL-HUST/VT</a>”</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of adversarial perturbation generated by the
attack to data range. Default: <code class="docutils literal notranslate"><span class="pre">8/255</span></code>.</p></li>
<li><p><strong>eps_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The proportion of perturbation in each step. Default: <code class="docutils literal notranslate"><span class="pre">2/255</span></code>.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, targeted attack. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, untargeted
attack. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>nb_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration. Default: <code class="docutils literal notranslate"><span class="pre">10</span></code>.</p></li>
<li><p><strong>decay_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The momentum factor. Default: <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p></li>
<li><p><strong>nb_neighbor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of sampled examples in the neighborhood.</p></li>
<li><p><strong>neighbor_beta</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The upper bound of neighborhood. Default: <code class="docutils literal notranslate"><span class="pre">3/2</span></code>.</p></li>
<li><p><strong>norm_level</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>numpy.inf</em><em>]</em>) – Order of the norm. Possible values:
<code class="docutils literal notranslate"><span class="pre">numpy.inf</span></code> , <code class="docutils literal notranslate"><span class="pre">1</span></code>, <code class="docutils literal notranslate"><span class="pre">2</span></code>, <code class="docutils literal notranslate"><span class="pre">'1'</span></code>, <code class="docutils literal notranslate"><span class="pre">'2'</span></code>, <code class="docutils literal notranslate"><span class="pre">'l1'</span></code>, <code class="docutils literal notranslate"><span class="pre">'l2'</span></code>, <code class="docutils literal notranslate"><span class="pre">'np.inf'</span></code>,
<code class="docutils literal notranslate"><span class="pre">'inf'</span></code> or <code class="docutils literal notranslate"><span class="pre">'linf'</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'inf'</span></code>.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><em>None</em><em>]</em>) – Loss function for optimization. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input network
is already equipped with loss function. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">VarianceTuningNesterovIterativeMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">VarianceTuningNesterovIterativeMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">nb_neighbor</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">neighbor_beta</span><span class="o">=</span><span class="mi">3</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>            <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.VarianceTuningNesterovIterativeMethod.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#VarianceTuningNesterovIterativeMethod.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.VarianceTuningNesterovIterativeMethod.generate" title="Permalink to this definition"></a></dt>
<dd><p>Generate adversarial examples based on input data and origin/target labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Benign input samples used as references to
create adversarial examples.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Original/target labels.
For each input if it has more than one label, it is wrapped in a tuple.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, generated adversarial examples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindarmour.html" class="btn btn-neutral float-left" title="mindarmour" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindarmour.adv_robustness.defenses.html" class="btn btn-neutral float-right" title="mindarmour.adv_robustness.defenses" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>