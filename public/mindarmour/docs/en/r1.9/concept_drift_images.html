<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Implementing the Concept Drift Detection Application of Image Data &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Implementing the Model Fault Injection and Evaluation" href="fault_injection.html" />
    <link rel="prev" title="Implementing the Concept Drift Detection Application of Time Series Data" href="concept_drift_time_series.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindarmour_install.html">MindArmour Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI Security</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">Using Membership Inference to Test Model Security</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_suppress_privacy.html">Protecting User Privacy with Suppress Privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_encrypt_protection.html">Model Encryption Protection</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI Reliability</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="concept_drift_time_series.html">Implementing the Concept Drift Detection Application of Time Series Data</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Implementing the Concept Drift Detection Application of Image Data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#preparations">Preparations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#preparing-a-dataset">Preparing a Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#importing-the-python-library-and-modules">Importing the Python Library and Modules</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#loading-data">Loading Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#loading-a-neural-network-model">Loading a Neural Network Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#initializing-the-image-concept-drift-detection-module">Initializing the Image Concept Drift Detection Module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#obtaining-an-optimal-concept-drift-detection-threshold">Obtaining an Optimal Concept Drift Detection Threshold</a></li>
<li class="toctree-l2"><a class="reference internal" href="#executing-the-concept-drift-detection">Executing the Concept Drift Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="#viewing-the-result">Viewing the Result</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="fault_injection.html">Implementing the Model Fault Injection and Evaluation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.html">mindarmour</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.attacks.html">mindarmour.adv_robustness.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.defenses.html">mindarmour.adv_robustness.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.detectors.html">mindarmour.adv_robustness.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.evaluations.html">mindarmour.adv_robustness.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.fuzz_testing.html">mindarmour.fuzz_testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.natural_robustness.transform.image.html">mindarmour.natural_robustness.transform.image</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.diff_privacy.html">mindarmour.privacy.diff_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.evaluation.html">mindarmour.privacy.evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.sup_privacy.html">mindarmour.privacy.sup_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.reliability.html">mindarmour.reliability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.utils.html">mindarmour.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design.html">Overall Security and Trustworthiness Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="differential_privacy_design.html">Differential Privacy Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="fuzzer_design.html">AI Model Security Testing Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="security_and_privacy.html">MindArmour Module Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Implementing the Concept Drift Detection Application of Image Data</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/concept_drift_images.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="implementing-the-concept-drift-detection-application-of-image-data">
<h1>Implementing the Concept Drift Detection Application of Image Data<a class="headerlink" href="#implementing-the-concept-drift-detection-application-of-image-data" title="Permalink to this headline">ÔÉÅ</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.9/docs/mindarmour/docs/source_en/concept_drift_images.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.9/resource/_static/logo_source_en.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>Concept drift of image data is an important data phenomenon in the AI learning field. It is also called out-of-distribution (OOD), which indicates that the image data (real-time distribution) in online inference is inconsistent with the training data (historical distribution).
For example, if the neural network model is obtained through training based on the MNIST dataset, but the actual test data is in the CIFAR-10 data environment, the CIFAR-10 dataset is an OOD sample.</p>
<p>This example provides a method for detecting a distribution change of image data. An overall process is as follows:</p>
<ol class="arabic simple">
<li><p>Load public datasets or use user-defined data.</p></li>
<li><p>Load a neural network model.</p></li>
<li><p>Initialize the image concept drift parameters.</p></li>
<li><p>Obtain an optimal concept drift detection threshold.</p></li>
<li><p>Execute the concept drift detection function.</p></li>
<li><p>View the execution result.</p></li>
</ol>
<blockquote>
<div><p>You can obtain the complete executable sample code at <a class="reference external" href="https://gitee.com/mindspore/mindarmour/blob/r1.9/examples/reliability/concept_drift_check_images_lenet.py">https://gitee.com/mindspore/mindarmour/blob/r1.9/examples/reliability/concept_drift_check_images_lenet.py</a>.</p>
</div></blockquote>
</section>
<section id="preparations">
<h2>Preparations<a class="headerlink" href="#preparations" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>Ensure that the MindSpore is correctly installed. If not, install MindSpore by following the <a class="reference external" href="https://www.mindspore.cn/install/en">Installation Guide</a>.</p>
<section id="preparing-a-dataset">
<h3>Preparing a Dataset<a class="headerlink" href="#preparing-a-dataset" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>The public image datasets MNIST and CIFAR-10 are used in the example.</p>
<blockquote>
<div><p>Dataset download pages: <a class="reference external" href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a> and <a class="reference external" href="http://www.cs.toronto.edu/~kriz/cifar.html">http://www.cs.toronto.edu/~kriz/cifar.html</a>.</p>
</div></blockquote>
</section>
<section id="importing-the-python-library-and-modules">
<h3>Importing the Python Library and Modules<a class="headerlink" href="#importing-the-python-library-and-modules" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>Before start, you need to import the Python library.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindarmour.utils</span> <span class="kn">import</span> <span class="n">LogUtil</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">examples.common.networks.lenet5.lenet5_net_for_fuzzing</span> <span class="kn">import</span> <span class="n">LeNet5</span>
<span class="kn">from</span> <span class="nn">mindarmour.reliability</span> <span class="kn">import</span> <span class="n">OodDetectorFeatureCluster</span>
</pre></div>
</div>
</section>
</section>
<section id="loading-data">
<h2>Loading Data<a class="headerlink" href="#loading-data" title="Permalink to this headline">ÔÉÅ</a></h2>
<ol class="arabic simple">
<li><p>Use the MNIST dataset as the training set <code class="docutils literal notranslate"><span class="pre">ds_train</span></code>. The <code class="docutils literal notranslate"><span class="pre">ds_train</span></code> contains only image data and does not contain labels.</p></li>
<li><p>Mix MNIST and CIFAR-10 into a dataset as test set <code class="docutils literal notranslate"><span class="pre">ds_test</span></code>, which contains only image data and does not contain labels.</p></li>
<li><p>Use another mixed dataset of MNIST and CIFAR-10 as a validation sample and record it as <code class="docutils literal notranslate"><span class="pre">ds_eval</span></code>. <code class="docutils literal notranslate"><span class="pre">ds_eval</span></code> contains only image data and does not contain labels. <code class="docutils literal notranslate"><span class="pre">ds_eval</span></code> is marked separately. Non-OOD samples are marked as 0, OOD samples are marked as 1, and <code class="docutils literal notranslate"><span class="pre">ds_eval</span></code> is marked as <code class="docutils literal notranslate"><span class="pre">ood_label</span></code>.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ds_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/dataset/concept_train_lenet.npy&#39;</span><span class="p">)</span>
<span class="n">ds_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/dataset/concept_test_lenet2.npy&#39;</span><span class="p">)</span>
<span class="n">ds_eval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/dataset/concept_test_lenet1.npy&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">ds_train(numpy.ndarray)</span></code>: training set, which contains only image data.</p>
<p><code class="docutils literal notranslate"><span class="pre">ds_test(numpy.ndarray)</span></code>: test set, which contains only image data.</p>
<p><code class="docutils literal notranslate"><span class="pre">ds_eval(numpy.ndarray)</span></code>: validation set, which contains only image data.</p>
</section>
<section id="loading-a-neural-network-model">
<h2>Loading a Neural Network Model<a class="headerlink" href="#loading-a-neural-network-model" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>Use the training set <code class="docutils literal notranslate"><span class="pre">ds_train</span></code> and its classification <code class="docutils literal notranslate"><span class="pre">label</span></code> to train the neural network LeNet and load the model. Here, we directly import the trained model file.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">label</span></code> here is different from the <code class="docutils literal notranslate"><span class="pre">ood_label</span></code> mentioned above. The <code class="docutils literal notranslate"><span class="pre">label</span></code> indicates the classification label of the sample, and <code class="docutils literal notranslate"><span class="pre">ood_label</span></code> indicates whether the sample belongs to the OOD label.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ckpt_path</span> <span class="o">=</span> <span class="s1">&#39;../../dataset/trained_ckpt_file/checkpoint_lenet-10_1875.ckpt&#39;</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="n">load_dict</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">load_dict</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">ckpt_path(str)</span></code>: model file path.</p>
<p>It should be noted that, to extract feature output of a specific layer by using a neural network, functions of the feature extraction and the naming neural layer need to be added to a neural network construction process.
The <code class="docutils literal notranslate"><span class="pre">layer</span></code> is used to name the neural network layer. You can use the following method to reconstruct the neural network model, name the neural network at each layer, and obtain the feature output value.</p>
<ol class="arabic simple">
<li><p>Import the <code class="docutils literal notranslate"><span class="pre">TensorSummary</span></code> module.</p></li>
<li><p>Add <code class="docutils literal notranslate"><span class="pre">self.summary</span> <span class="pre">=</span> <span class="pre">TensorSummary()</span></code> to the initialization function <code class="docutils literal notranslate"><span class="pre">__init__</span></code>.</p></li>
<li><p>Add <code class="docutils literal notranslate"><span class="pre">self.summary(</span></code>name<code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">x)</span></code> after the constructor function of each layer of the neural network.</p></li>
</ol>
<p>In this test case, the KMeans function in sklearn is used for feature clustering analysis. Therefore, the input data dimension of KMeans must be two-dimensional. LeNet is used as an example. The features of the fully-connected layer and ReLU layer from the bottom five layers are extracted. The data dimensions meet the KMeans requirements.</p>
<p>The LeNet neural network construction process is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">TruncatedNormal</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">TensorSummary</span>

<span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrap conv.&quot;&quot;&quot;</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                     <span class="n">weight_init</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fc_with_initialize</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrap initialize method of full connection layer.&quot;&quot;&quot;</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">weight_variable</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrap initialize variable.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">TruncatedNormal</span><span class="p">(</span><span class="mf">0.05</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">LeNet5</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Lenet network</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet5</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">16</span><span class="o">*</span><span class="mi">5</span><span class="o">*</span><span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary</span> <span class="o">=</span> <span class="n">TensorSummary</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        construct the network architecture</span>
<span class="sd">        Returns:</span>
<span class="sd">            x (tensor): network output</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="s1">&#39;8&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="s1">&#39;9&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="s1">&#39;10&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="s1">&#39;11&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="s1">&#39;output&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

</pre></div>
</div>
</section>
<section id="initializing-the-image-concept-drift-detection-module">
<h2>Initializing the Image Concept Drift Detection Module<a class="headerlink" href="#initializing-the-image-concept-drift-detection-module" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>Import the concept drift detection module and initialize it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">detector</span> <span class="o">=</span> <span class="n">OodDetectorFeatureCluster</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">n_cluster</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="s1">&#39;output[:Tensor]&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">model(Model)</span></code>: neural network model, which is obtained by training the training set <code class="docutils literal notranslate"><span class="pre">ds_train</span></code> and its classification labels.</p>
<p><code class="docutils literal notranslate"><span class="pre">ds_train(numpy.ndarray)</span></code>: training set, which contains only image data.</p>
<p><code class="docutils literal notranslate"><span class="pre">n_cluster(int)</span></code>: number of feature clusters.</p>
<p><code class="docutils literal notranslate"><span class="pre">layer(str)</span></code>: name of the layer used by the neural network to extract features.</p>
<p>Note that during <code class="docutils literal notranslate"><span class="pre">OodDetectorFeatureCluster</span></code> initialization, the <code class="docutils literal notranslate"><span class="pre">[:Tensor]</span></code> suffix needs to be added after the <code class="docutils literal notranslate"><span class="pre">layer</span></code> parameter.
For example, if a neural network layer is named <code class="docutils literal notranslate"><span class="pre">name</span></code>, then <code class="docutils literal notranslate"><span class="pre">layer='name[:Tensor]'</span></code>. In the <code class="docutils literal notranslate"><span class="pre">layer='output[:Tensor]</span></code> instance, the feature <code class="docutils literal notranslate"><span class="pre">output</span></code> of the last layer of LeNet is used, that is, <code class="docutils literal notranslate"><span class="pre">layer='output[:Tensor]</span></code>. In addition, the algorithm uses the KMeans function in sklearn to perform feature clustering analysis. The input data dimension of KMeans must be two-dimensional. Therefore, the features extracted by <code class="docutils literal notranslate"><span class="pre">layer</span></code> must be two-dimensional data, such as the fully-connected layer and ReLU layer in the LeNet example above.</p>
</section>
<section id="obtaining-an-optimal-concept-drift-detection-threshold">
<h2>Obtaining an Optimal Concept Drift Detection Threshold<a class="headerlink" href="#obtaining-an-optimal-concept-drift-detection-threshold" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>The optimal concept drift detection threshold is obtained based on the validation set <code class="docutils literal notranslate"><span class="pre">ds_eval</span></code> and its OOD label <code class="docutils literal notranslate"><span class="pre">ood_label</span></code>.</p>
<p>The validation set <code class="docutils literal notranslate"><span class="pre">ds_eval</span></code> can be constructed manually. For example, it consists of 50% of the MNIST dataset and 50% of the CIFAR-10 dataset. Therefore, the OOD label <code class="docutils literal notranslate"><span class="pre">ood_label</span></code> indicates that the label values of the first 50% are 0 and those of the last 50% are 1.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">num</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ds_eval</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ood_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># ID data = 0, OOD data = 1</span>
<span class="n">optimal_threshold</span> <span class="o">=</span> <span class="n">detector</span><span class="o">.</span><span class="n">get_optimal_threshold</span><span class="p">(</span><span class="n">ood_label</span><span class="p">,</span> <span class="n">ds_eval</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">ds_eval(numpy.ndarray)</span></code>: validation set, which contains only image data.
<code class="docutils literal notranslate"><span class="pre">ood_label(numpy.ndarray)</span></code>: OOD label of validation set <code class="docutils literal notranslate"><span class="pre">ds_eval</span></code>. Non-OOD samples are marked as 0, and OOD samples are marked as 1.</p>
<p>Certainly, if it is difficult for a user to obtain <code class="docutils literal notranslate"><span class="pre">ds_eval</span></code> and the OOD label <code class="docutils literal notranslate"><span class="pre">ood_label</span></code>, a value of <code class="docutils literal notranslate"><span class="pre">optimal_threshold</span></code> may be manually and flexibly set, and the value of <code class="docutils literal notranslate"><span class="pre">optimal_threshold</span></code> is a floating point number between [0, 1].</p>
</section>
<section id="executing-the-concept-drift-detection">
<h2>Executing the Concept Drift Detection<a class="headerlink" href="#executing-the-concept-drift-detection" title="Permalink to this headline">ÔÉÅ</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="n">detector</span><span class="o">.</span><span class="n">ood_predict</span><span class="p">(</span><span class="n">optimal_threshold</span><span class="p">,</span> <span class="n">ds_test</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">ds_test(numpy.ndarray)</span></code>: test set, which contains only image data.
<code class="docutils literal notranslate"><span class="pre">optimal_threshold(float)</span></code>: optimal threshold. You can obtain the values by running the <code class="docutils literal notranslate"><span class="pre">detector.get_optimal_threshold(ood_label,</span> <span class="pre">ds_eval)</span></code> command.
However, if it is difficult for a user to obtain <code class="docutils literal notranslate"><span class="pre">ds_eval</span></code> and the OOD label <code class="docutils literal notranslate"><span class="pre">ood_label</span></code>, a value of <code class="docutils literal notranslate"><span class="pre">optimal_threshold</span></code> may be manually and flexibly set, and the value of <code class="docutils literal notranslate"><span class="pre">optimal_threshold</span></code> is a floating point number between [0, 1].</p>
</section>
<section id="viewing-the-result">
<h2>Viewing the Result<a class="headerlink" href="#viewing-the-result" title="Permalink to this headline">ÔÉÅ</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">result(numpy.ndarray)</span></code>: one-dimensional array consisting of elements 0 and 1, corresponding to the OOD detection result of <code class="docutils literal notranslate"><span class="pre">ds_test</span></code>.
For example, if <code class="docutils literal notranslate"><span class="pre">ds_test</span></code> is a dataset consisting of five MNIST datasets and five CIFAR-10 datasets, the detection result is [0,0,0,0,0,1,1,1,1,1].</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="concept_drift_time_series.html" class="btn btn-neutral float-left" title="Implementing the Concept Drift Detection Application of Time Series Data" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="fault_injection.html" class="btn btn-neutral float-right" title="Implementing the Model Fault Injection and Evaluation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>