

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindarmour.adv_robustness.attacks &mdash; MindSpore master documentation</title>
  

  
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="mindarmour.adv_robustness.defenses" href="mindarmour.adv_robustness.defenses.html" />
    <link rel="prev" title="mindarmour" href="mindarmour.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindarmour_install.html">MindSpore Armour Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">AI Security</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluation_of_CNNCTC.html">Evaluating the Robustness of the OCR Model CNN-CTC</a></li>
<li class="toctree-l1"><a class="reference internal" href="dynamic_obfuscation_protection.html">Dynamic Model Obfuscation</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_encrypt_protection.html">Model Encryption Protection</a></li>
</ul>
<p class="caption"><span class="caption-text">AI Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_suppress_privacy.html">Protecting User Privacy with Suppress Privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">Using Membership Inference to Test Model Security</a></li>
</ul>
<p class="caption"><span class="caption-text">AI Reliability</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="concept_drift_time_series.html">Implementing the Concept Drift Detection Application of Time Series Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="concept_drift_images.html">Implementing the Concept Drift Detection Application of Image Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="fault_injection.html">Implementing the Model Fault Injection and Evaluation</a></li>
</ul>
<p class="caption"><span class="caption-text">API References</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mindarmour.html">mindarmour</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindarmour.adv_robustness.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.defenses.html">mindarmour.adv_robustness.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.detectors.html">mindarmour.adv_robustness.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.evaluations.html">mindarmour.adv_robustness.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.fuzz_testing.html">mindarmour.fuzz_testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.natural_robustness.transform.image.html">mindarmour.natural_robustness.transform.image</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.diff_privacy.html">mindarmour.privacy.diff_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.evaluation.html">mindarmour.privacy.evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.sup_privacy.html">mindarmour.privacy.sup_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.reliability.html">mindarmour.reliability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.utils.html">mindarmour.utils</a></li>
</ul>
<p class="caption"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design.html">Overall Security and Trustworthiness Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="differential_privacy_design.html">Differential Privacy Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="fuzzer_design.html">AI Model Security Testing Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="security_and_privacy.html">MindSpore Armour Module Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>mindarmour.adv_robustness.attacks</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/mindarmour.adv_robustness.attacks.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-mindarmour.adv_robustness.attacks">
<span id="module-mindarmour.adv_robustness.attacks"></span><span id="mindarmour-adv-robustness-attacks"></span><h1>mindarmour.adv_robustness.attacks<a class="headerlink" href="#module-mindarmour.adv_robustness.attacks" title="Permalink to this headline">¶</a></h1>
<p>This module includes classical black-box and white-box attack algorithms
in making adversarial examples.</p>
<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.FastGradientMethod">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">FastGradientMethod</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">eps=0.07</em>, <em class="sig-param">alpha=None</em>, <em class="sig-param">bounds=(0.0</em>, <em class="sig-param">1.0)</em>, <em class="sig-param">norm_level=2</em>, <em class="sig-param">is_targeted=False</em>, <em class="sig-param">loss_fn=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#FastGradientMethod"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.FastGradientMethod" title="Permalink to this definition">¶</a></dt>
<dd><p>This attack is a one-step attack based on gradients calculation, and
the norm of perturbations includes L1, L2 and Linf.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1412.6572">I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining
and harnessing adversarial examples,” in ICLR, 2015.</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation generated
by the attack to data range. Default: 0.07.</p></li>
<li><p><strong>alpha</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Proportion of single-step random perturbation to data range.
Default: None.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: (0.0, 1.0).</p></li>
<li><p><strong>norm_level</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>numpy.inf</em><em>]</em>) – Order of the norm.
Possible values: np.inf, 1 or 2. Default: 2.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, targeted attack. If False, untargeted
attack. Default: False.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>loss</em><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Loss function for optimization. If None, the input network             is already equipped with loss function. Default: None.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">FastGradientMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">FastGradientMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.RandomFastGradientMethod">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">RandomFastGradientMethod</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">eps=0.07</em>, <em class="sig-param">alpha=0.035</em>, <em class="sig-param">bounds=(0.0</em>, <em class="sig-param">1.0)</em>, <em class="sig-param">norm_level=2</em>, <em class="sig-param">is_targeted=False</em>, <em class="sig-param">loss_fn=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#RandomFastGradientMethod"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.RandomFastGradientMethod" title="Permalink to this definition">¶</a></dt>
<dd><p>Fast Gradient Method use Random perturbation.
An one-step attack based on gradients calculation. The adversarial noises
are generated based on the gradients of inputs, and then randomly perturbed.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1705.07204">Florian Tramer, Alexey Kurakin, Nicolas Papernot, “Ensemble
adversarial training: Attacks and defenses” in ICLR, 2018</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation generated
by the attack to data range. Default: 0.07.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step random perturbation to data range.
Default: 0.035.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: (0.0, 1.0).</p></li>
<li><p><strong>norm_level</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>numpy.inf</em><em>]</em>) – Order of the norm.
Possible values: np.inf, 1 or 2. Default: 2.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, targeted attack. If False, untargeted
attack. Default: False.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>loss</em><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Loss function for optimization. If None, the input network             is already equipped with loss function. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – eps is smaller than alpha!</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">RandomFastGradientMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">RandomFastGradientMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.FastGradientSignMethod">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">FastGradientSignMethod</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">eps=0.07</em>, <em class="sig-param">alpha=None</em>, <em class="sig-param">bounds=(0.0</em>, <em class="sig-param">1.0)</em>, <em class="sig-param">is_targeted=False</em>, <em class="sig-param">loss_fn=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#FastGradientSignMethod"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.FastGradientSignMethod" title="Permalink to this definition">¶</a></dt>
<dd><p>The Fast Gradient Sign Method attack calculates the gradient of the input
data, and then uses the sign of the gradient to create adversarial noises.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1412.6572">Ian J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining
and harnessing adversarial examples,” in ICLR, 2015</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation generated
by the attack to data range. Default: 0.07.</p></li>
<li><p><strong>alpha</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Proportion of single-step random perturbation to data range.
Default: None.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: (0.0, 1.0).</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, targeted attack. If False, untargeted
attack. Default: False.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Loss function for optimization. If None, the input network             is already equipped with loss function. Default: None.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">FastGradientSignMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">FastGradientSignMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.RandomFastGradientSignMethod">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">RandomFastGradientSignMethod</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">eps=0.07</em>, <em class="sig-param">alpha=0.035</em>, <em class="sig-param">bounds=(0.0</em>, <em class="sig-param">1.0)</em>, <em class="sig-param">is_targeted=False</em>, <em class="sig-param">loss_fn=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#RandomFastGradientSignMethod"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.RandomFastGradientSignMethod" title="Permalink to this definition">¶</a></dt>
<dd><p>Fast Gradient Sign Method using random perturbation.
The Random Fast Gradient Sign Method attack calculates the gradient of the input
data, and then uses the sign of the gradient with random perturbation
to create adversarial noises.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1705.07204">F. Tramer, et al., “Ensemble adversarial training: Attacks
and defenses,” in ICLR, 2018</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation generated
by the attack to data range. Default: 0.07.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step random perturbation to data range.
Default: 0.035.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: (0.0, 1.0).</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – True: targeted attack. False: untargeted attack.
Default: False.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Loss function for optimization. If None, the input network             is already equipped with loss function. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – eps is smaller than alpha!</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">RandomFastGradientSignMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">RandomFastGradientSignMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.LeastLikelyClassMethod">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">LeastLikelyClassMethod</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">eps=0.07</em>, <em class="sig-param">alpha=None</em>, <em class="sig-param">bounds=(0.0</em>, <em class="sig-param">1.0)</em>, <em class="sig-param">loss_fn=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#LeastLikelyClassMethod"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.LeastLikelyClassMethod" title="Permalink to this definition">¶</a></dt>
<dd><p>The Single Step Least-Likely Class Method, a variant of FGSM, targets the
least-likely class to generate the adversarial examples.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1705.07204">F. Tramer, et al., “Ensemble adversarial training: Attacks
and defenses,” in ICLR, 2018</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation generated
by the attack to data range. Default: 0.07.</p></li>
<li><p><strong>alpha</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Proportion of single-step random perturbation to data range.
Default: None.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: (0.0, 1.0).</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Loss function for optimization. If None, the input network             is already equipped with loss function. Default: None.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">LeastLikelyClassMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">LeastLikelyClassMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.RandomLeastLikelyClassMethod">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">RandomLeastLikelyClassMethod</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">eps=0.07</em>, <em class="sig-param">alpha=0.035</em>, <em class="sig-param">bounds=(0.0</em>, <em class="sig-param">1.0)</em>, <em class="sig-param">loss_fn=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#RandomLeastLikelyClassMethod"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.RandomLeastLikelyClassMethod" title="Permalink to this definition">¶</a></dt>
<dd><p>Least-Likely Class Method use Random perturbation.</p>
<p>The Single Step Least-Likely Class Method with Random Perturbation, a variant of Random FGSM,
targets the least-likely class to generate the adversarial examples.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1705.07204">F. Tramer, et al., “Ensemble adversarial training: Attacks
and defenses,” in ICLR, 2018</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation generated
by the attack to data range. Default: 0.07.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step random perturbation to data range.
Default: 0.035.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: (0.0, 1.0).</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Loss function for optimization. If None, the input network             is already equipped with loss function. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – eps is smaller than alpha!</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">RandomLeastLikelyClassMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">RandomLeastLikelyClassMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.IterativeGradientMethod">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">IterativeGradientMethod</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">eps=0.3</em>, <em class="sig-param">eps_iter=0.1</em>, <em class="sig-param">bounds=(0.0</em>, <em class="sig-param">1.0)</em>, <em class="sig-param">nb_iter=5</em>, <em class="sig-param">loss_fn=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#IterativeGradientMethod"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.IterativeGradientMethod" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract base class for all iterative gradient based attacks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of adversarial perturbation generated by the
attack to data range. Default: 0.3.</p></li>
<li><p><strong>eps_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation
generated by the attack to data range. Default: 0.1.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: (0.0, 1.0).</p></li>
<li><p><strong>nb_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration. Default: 5.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Loss function for optimization. If None, the input network             is already equipped with loss function. Default: None.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.IterativeGradientMethod.generate">
<em class="property">abstract </em><code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#IterativeGradientMethod.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.IterativeGradientMethod.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate adversarial examples based on input samples and original/target labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Benign input samples used as references to create
adversarial examples.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Original/target labels.                 For each input if it has more than one label, it is wrapped in a tuple.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#NotImplementedError" title="(in Python v3.8)"><strong>NotImplementedError</strong></a> – This function is not available in
    IterativeGradientMethod.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.BasicIterativeMethod">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">BasicIterativeMethod</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">eps=0.3</em>, <em class="sig-param">eps_iter=0.1</em>, <em class="sig-param">bounds=(0.0</em>, <em class="sig-param">1.0)</em>, <em class="sig-param">is_targeted=False</em>, <em class="sig-param">nb_iter=5</em>, <em class="sig-param">loss_fn=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#BasicIterativeMethod"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.BasicIterativeMethod" title="Permalink to this definition">¶</a></dt>
<dd><p>The Basic Iterative Method attack, an iterative FGSM method to generate
adversarial examples.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1607.02533">A. Kurakin, I. Goodfellow, and S. Bengio, “Adversarial examples
in the physical world,” in ICLR, 2017</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of adversarial perturbation generated by the
attack to data range. Default: 0.3.</p></li>
<li><p><strong>eps_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation
generated by the attack to data range. Default: 0.1.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: (0.0, 1.0).</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, targeted attack. If False, untargeted
attack. Default: False.</p></li>
<li><p><strong>nb_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration. Default: 5.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Loss function for optimization. If None, the input network             is already equipped with loss function. Default: None.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">BasicIterativeMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">BasicIterativeMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.BasicIterativeMethod.generate">
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#BasicIterativeMethod.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.BasicIterativeMethod.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Simple iterative FGSM method to generate adversarial examples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Benign input samples used as references to
create adversarial examples.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Original/target labels.                 For each input if it has more than one label, it is wrapped in a tuple.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, generated adversarial examples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.MomentumIterativeMethod">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">MomentumIterativeMethod</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">eps=0.3</em>, <em class="sig-param">eps_iter=0.1</em>, <em class="sig-param">bounds=(0.0</em>, <em class="sig-param">1.0)</em>, <em class="sig-param">is_targeted=False</em>, <em class="sig-param">nb_iter=5</em>, <em class="sig-param">decay_factor=1.0</em>, <em class="sig-param">norm_level=&quot;inf&quot;</em>, <em class="sig-param">loss_fn=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#MomentumIterativeMethod"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.MomentumIterativeMethod" title="Permalink to this definition">¶</a></dt>
<dd><p>The Momentum Iterative Method attack accelerates the gradient descent algorithm,
such as FGSM, FGM, and LLCM, by accumulating a velocity vector in the gradient
direction of the loss function across iterations, and thus generates the adversarial examples.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1710.06081">Y. Dong, et al., “Boosting adversarial attacks with
momentum,” arXiv:1710.06081, 2017</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of adversarial perturbation generated by the
attack to data range. Default: 0.3.</p></li>
<li><p><strong>eps_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation
generated by the attack to data range. Default: 0.1.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: (0.0, 1.0).</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, targeted attack. If False, untargeted
attack. Default: False.</p></li>
<li><p><strong>nb_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration. Default: 5.</p></li>
<li><p><strong>decay_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Decay factor in iterations. Default: 1.0.</p></li>
<li><p><strong>norm_level</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>numpy.inf</em><em>]</em>) – Order of the norm. Possible values:
np.inf, 1 or 2. Default: ‘inf’.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Loss function for optimization. If None, the input network             is already equipped with loss function. Default: None.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">MomentumIterativeMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">MomentumIterativeMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.MomentumIterativeMethod.generate">
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#MomentumIterativeMethod.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.MomentumIterativeMethod.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate adversarial examples based on input data and origin/target labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Benign input samples used as references to
create adversarial examples.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Original/target labels.                 For each input if it has more than one label, it is wrapped in a tuple.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, generated adversarial examples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.ProjectedGradientDescent">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">ProjectedGradientDescent</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">eps=0.3</em>, <em class="sig-param">eps_iter=0.1</em>, <em class="sig-param">bounds=(0.0</em>, <em class="sig-param">1.0)</em>, <em class="sig-param">is_targeted=False</em>, <em class="sig-param">nb_iter=5</em>, <em class="sig-param">norm_level=&quot;inf&quot;</em>, <em class="sig-param">loss_fn=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#ProjectedGradientDescent"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.ProjectedGradientDescent" title="Permalink to this definition">¶</a></dt>
<dd><p>The Projected Gradient Descent attack is a variant of the Basic Iterative
Method in which, after each iteration, the perturbation is projected on an
lp-ball of specified radius (in addition to clipping the values of the
adversarial sample so that it lies in the permitted data range). This is
the attack proposed by Madry et al. for adversarial training.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1706.06083">A. Madry, et al., “Towards deep learning models resistant to
adversarial attacks,” in ICLR, 2018</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of adversarial perturbation generated by the
attack to data range. Default: 0.3.</p></li>
<li><p><strong>eps_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of single-step adversarial perturbation
generated by the attack to data range. Default: 0.1.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: (0.0, 1.0).</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, targeted attack. If False, untargeted
attack. Default: False.</p></li>
<li><p><strong>nb_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration. Default: 5.</p></li>
<li><p><strong>norm_level</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>numpy.inf</em><em>]</em>) – Order of the norm. Possible values:
np.inf, 1 or 2. Default: ‘inf’.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Loss function for optimization. If None, the input network             is already equipped with loss function. Default: None.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">ProjectedGradientDescent</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">ProjectedGradientDescent</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.ProjectedGradientDescent.generate">
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#ProjectedGradientDescent.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.ProjectedGradientDescent.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Iteratively generate adversarial examples based on BIM method. The
perturbation is normalized by projected method with parameter norm_level .</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Benign input samples used as references to
create adversarial examples.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Original/target labels.                 For each input if it has more than one label, it is wrapped in a tuple.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, generated adversarial examples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.DiverseInputIterativeMethod">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">DiverseInputIterativeMethod</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">eps=0.3</em>, <em class="sig-param">bounds=(0.0</em>, <em class="sig-param">1.0)</em>, <em class="sig-param">is_targeted=False</em>, <em class="sig-param">prob=0.5</em>, <em class="sig-param">loss_fn=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#DiverseInputIterativeMethod"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.DiverseInputIterativeMethod" title="Permalink to this definition">¶</a></dt>
<dd><p>The Diverse Input Iterative Method attack follows the basic iterative method,
and applies random transformation to the input data at each iteration. Such transformation
on the input data could improve the transferability of the adversarial examples.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1803.06978">Xie, Cihang and Zhang, et al., “Improving Transferability of
Adversarial Examples With Input Diversity,” in CVPR, 2019</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of adversarial perturbation generated by the
attack to data range. Default: 0.3.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: (0.0, 1.0).</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, targeted attack. If False, untargeted
attack. Default: False.</p></li>
<li><p><strong>prob</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Transformation probability. Default: 0.5.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Loss function for optimization. If None, the input network             is already equipped with loss function. Default: None.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">DiverseInputIterativeMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">DiverseInputIterativeMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.MomentumDiverseInputIterativeMethod">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">MomentumDiverseInputIterativeMethod</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">eps=0.3</em>, <em class="sig-param">bounds=(0.0</em>, <em class="sig-param">1.0)</em>, <em class="sig-param">is_targeted=False</em>, <em class="sig-param">norm_level=&quot;l1&quot;</em>, <em class="sig-param">prob=0.5</em>, <em class="sig-param">loss_fn=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#MomentumDiverseInputIterativeMethod"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.MomentumDiverseInputIterativeMethod" title="Permalink to this definition">¶</a></dt>
<dd><p>The Momentum Diverse Input Iterative Method attack is a momentum iterative method,
and applies random transformation to the input data at each iteration. Such transformation
on the input data could improve the transferability of the adversarial examples.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1803.06978">Xie, Cihang and Zhang, et al., “Improving Transferability of
Adversarial Examples With Input Diversity,” in CVPR, 2019</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Proportion of adversarial perturbation generated by the
attack to data range. Default: 0.3.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data, indicating the data range.
In form of (clip_min, clip_max). Default: (0.0, 1.0).</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, targeted attack. If False, untargeted
attack. Default: False.</p></li>
<li><p><strong>norm_level</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>numpy.inf</em><em>]</em>) – Order of the norm. Possible values:
np.inf, 1 or 2. Default: ‘l1’.</p></li>
<li><p><strong>prob</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Transformation probability. Default: 0.5.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>Loss</em><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Loss function for optimization. If None, the input network             is already equipped with loss function. Default: None.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">MomentumDiverseInputIterativeMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">MomentumDiverseInputIterativeMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.DeepFool">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">DeepFool</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">num_classes</em>, <em class="sig-param">model_type=&quot;classification&quot;</em>, <em class="sig-param">reserve_ratio=0.3</em>, <em class="sig-param">max_iters=50</em>, <em class="sig-param">overshoot=0.02</em>, <em class="sig-param">norm_level=2</em>, <em class="sig-param">bounds=None</em>, <em class="sig-param">sparse=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/deep_fool.html#DeepFool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.DeepFool" title="Permalink to this definition">¶</a></dt>
<dd><p>DeepFool is an untargeted &amp; iterative attack achieved by moving the benign
sample to the nearest classification boundary and crossing the boundary.</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/abs/1511.04599">DeepFool: a simple and accurate method to fool deep neural
networks</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of labels of model output, which should be
greater than zero.</p></li>
<li><p><strong>model_type</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Tye type of targeted model. ‘classification’ and ‘detection’ are supported now.
default: ‘classification’.</p></li>
<li><p><strong>reserve_ratio</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – The percentage of objects that can be detected after attaks,
specifically for model_type=’detection’. Reserve_ratio should be in the range of (0, 1). Default: 0.3.</p></li>
<li><p><strong>max_iters</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Max iterations, which should be
greater than zero. Default: 50.</p></li>
<li><p><strong>overshoot</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Overshoot parameter. Default: 0.02.</p></li>
<li><p><strong>norm_level</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>numpy.inf</em><em>]</em>) – Order of the vector norm. Possible values: np.inf
or 2. Default: 2.</p></li>
<li><p><strong>bounds</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>]</em>) – Upper and lower bounds of data range. In form of (clip_min,
clip_max). Default: None.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, input labels are sparse-coded. If False,
input labels are onehot-coded. Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">DeepFool</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="n">input_shape</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">DeepFool</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">max_iters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">norm_level</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>                  <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_me</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">input_np</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">true_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">input_me</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">advs</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_np</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.DeepFool.generate">
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/deep_fool.html#DeepFool.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.DeepFool.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate adversarial examples based on input samples and original labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Input samples. The format of inputs should be numpy.ndarray if
model_type=’classification’. The format of inputs can be (input1, input2, …) or only one array if
model_type=’detection’.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Targeted labels or ground-truth labels. The format of labels should
be numpy.ndarray if model_type=’classification’. The format of labels should be (gt_boxes, gt_labels)
if model_type=’detection’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, adversarial examples.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#NotImplementedError" title="(in Python v3.8)"><strong>NotImplementedError</strong></a> – If norm_level is not in [2, np.inf, ‘2’, ‘inf’].</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.CarliniWagnerL2Attack">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">CarliniWagnerL2Attack</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">num_classes</em>, <em class="sig-param">box_min=0.0</em>, <em class="sig-param">box_max=1.0</em>, <em class="sig-param">bin_search_steps=5</em>, <em class="sig-param">max_iterations=1000</em>, <em class="sig-param">confidence=0</em>, <em class="sig-param">learning_rate=5e-3</em>, <em class="sig-param">initial_const=1e-2</em>, <em class="sig-param">abort_early_check_ratio=5e-2</em>, <em class="sig-param">targeted=False</em>, <em class="sig-param">fast=True</em>, <em class="sig-param">abort_early=True</em>, <em class="sig-param">sparse=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/carlini_wagner.html#CarliniWagnerL2Attack"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.CarliniWagnerL2Attack" title="Permalink to this definition">¶</a></dt>
<dd><p>The Carlini &amp; Wagner attack using L2 norm generates the adversarial examples
by utilizing two separate losses: an adversarial loss to make the generated example
actually adversarial, and a distance loss to control the quality of the adversarial example.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1608.04644">Nicholas Carlini, David Wagner: “Towards Evaluating
the Robustness of Neural Networks”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of labels of model output, which should be
greater than zero.</p></li>
<li><p><strong>box_min</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Lower bound of input of the target model. Default: 0.</p></li>
<li><p><strong>box_max</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Upper bound of input of the target model. Default: 1.0.</p></li>
<li><p><strong>bin_search_steps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of steps for the binary search
used to find the optimal trade-off constant between distance
and confidence. Default: 5.</p></li>
<li><p><strong>max_iterations</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The maximum number of iterations, which should be
greater than zero. Default: 1000.</p></li>
<li><p><strong>confidence</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Confidence of the output of adversarial examples.
Default: 0.</p></li>
<li><p><strong>learning_rate</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The learning rate for the attack algorithm.
Default: 5e-3.</p></li>
<li><p><strong>initial_const</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The initial trade-off constant to use to balance
the relative importance of perturbation norm and confidence
difference. Default: 1e-2.</p></li>
<li><p><strong>abort_early_check_ratio</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Check loss progress every ratio of
all iteration. Default: 5e-2.</p></li>
<li><p><strong>targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, targeted attack. If False, untargeted attack.
Default: False.</p></li>
<li><p><strong>fast</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, return the first found adversarial example.
If False, return the adversarial samples with smaller
perturbations. Default: True.</p></li>
<li><p><strong>abort_early</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, Adam will be aborted if the loss hasn’t
decreased for some time. If False, Adam will continue work until the
max iterations is arrived. Default: True.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, input labels are sparse-coded. If False,
input labels are onehot-coded. Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">CarliniWagnerL2Attack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">input_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">CarliniWagnerL2Attack</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">targeted</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_data</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_np</span><span class="p">,</span> <span class="n">label_np</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.CarliniWagnerL2Attack.generate">
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/carlini_wagner.html#CarliniWagnerL2Attack.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.CarliniWagnerL2Attack.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate adversarial examples based on input data and targeted labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Input samples.</p></li>
<li><p><strong>labels</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – The ground truth label of input samples
or target labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, generated adversarial examples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.JSMAAttack">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">JSMAAttack</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">num_classes</em>, <em class="sig-param">box_min=0.0</em>, <em class="sig-param">box_max=1.0</em>, <em class="sig-param">theta=1.0</em>, <em class="sig-param">max_iteration=1000</em>, <em class="sig-param">max_count=3</em>, <em class="sig-param">increase=True</em>, <em class="sig-param">sparse=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/jsma.html#JSMAAttack"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.JSMAAttack" title="Permalink to this definition">¶</a></dt>
<dd><p>Jacobian-based Saliency Map Attack is a targeted and iterative attack based on saliency
map of the input features. It uses the gradient of loss with each class labels with respect
to every component of the input. Then a saliency map is used to select the dimension which
produces the maximum error.</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/abs/1511.07528">The limitations of deep learning in adversarial settings</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Target model.</p></li>
<li><p><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of labels of model output, which should be
greater than zero.</p></li>
<li><p><strong>box_min</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Lower bound of input of the target model. Default: 0.</p></li>
<li><p><strong>box_max</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Upper bound of input of the target model. Default: 1.0.</p></li>
<li><p><strong>theta</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Change ratio of one pixel (relative to
input data range). Default: 1.0.</p></li>
<li><p><strong>max_iteration</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Maximum round of iteration. Default: 1000.</p></li>
<li><p><strong>max_count</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Maximum times to change each pixel. Default: 3.</p></li>
<li><p><strong>increase</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, increase perturbation. If False, decrease
perturbation. Default: True.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, input labels are sparse-coded. If False,
input labels are onehot-coded. Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">JSMAAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="n">input_shape</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">JSMAAttack</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">max_iteration</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">advs</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_np</span><span class="p">,</span> <span class="n">label_np</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.JSMAAttack.generate">
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/jsma.html#JSMAAttack.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.JSMAAttack.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate adversarial examples in batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Input samples.</p></li>
<li><p><strong>labels</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Target labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, adversarial samples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.LBFGS">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">LBFGS</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">eps=1e-5</em>, <em class="sig-param">bounds=(0.0</em>, <em class="sig-param">1.0)</em>, <em class="sig-param">is_targeted=True</em>, <em class="sig-param">nb_iter=150</em>, <em class="sig-param">search_iters=30</em>, <em class="sig-param">loss_fn=None</em>, <em class="sig-param">sparse=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/lbfgs.html#LBFGS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.LBFGS" title="Permalink to this definition">¶</a></dt>
<dd><p>In L-BFGS-B attack, the Limited-Memory BFGS optimizaiton algorithm is used
to minimize the distance between the inputs and the adversarial examples.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1510.05328">Pedro Tabacof, Eduardo Valle. “Exploring the Space of
Adversarial Images”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – The network of attacked model.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Attack step size. Default: 1e-5.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data. Default: (0.0, 1.0)</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, targeted attack. If False, untargeted
attack. Default: True.</p></li>
<li><p><strong>nb_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration of lbfgs-optimizer, which should be
greater than zero. Default: 150.</p></li>
<li><p><strong>search_iters</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of changes in step size, which should be
greater than zero. Default: 30.</p></li>
<li><p><strong>loss_fn</strong> (<em>Functions</em>) – Loss function of substitute model. Default: None.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, input labels are sparse-coded. If False,
input labels are onehot-coded. Default: False.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">LBFGS</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">LBFGS</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">is_targeted</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">7</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)[</span><span class="n">target_np</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_np</span><span class="p">,</span> <span class="n">target_np</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.LBFGS.generate">
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/lbfgs.html#LBFGS.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.LBFGS.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate adversarial examples based on input data and target labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Benign input samples used as references to create
adversarial examples.</p></li>
<li><p><strong>labels</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Original/target labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, generated adversarial examples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.GeneticAttack">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">GeneticAttack</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">model_type=&quot;classification&quot;</em>, <em class="sig-param">targeted=True</em>, <em class="sig-param">reserve_ratio=0.3</em>, <em class="sig-param">sparse=True</em>, <em class="sig-param">pop_size=6</em>, <em class="sig-param">mutation_rate=0.005</em>, <em class="sig-param">per_bounds=0.15</em>, <em class="sig-param">max_steps=1000</em>, <em class="sig-param">step_size=0.20</em>, <em class="sig-param">temp=0.3</em>, <em class="sig-param">bounds=(0</em>, <em class="sig-param">1.0)</em>, <em class="sig-param">adaptive=False</em>, <em class="sig-param">c=0.1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/genetic_attack.html#GeneticAttack"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.GeneticAttack" title="Permalink to this definition">¶</a></dt>
<dd><p>The Genetic Attack represents the black-box attack based on the genetic algorithm,
which belongs to differential evolution algorithms.</p>
<p>This attack was proposed by Moustafa Alzantot et al. (2018).</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1805.11090">Moustafa Alzantot, Yash Sharma, Supriyo Chakraborty,
“GeneticAttack: Practical Black-box Attacks with
Gradient-FreeOptimization”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="mindarmour.html#mindarmour.BlackModel" title="mindarmour.BlackModel"><em>BlackModel</em></a>) – Target model.</p></li>
<li><p><strong>model_type</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The type of targeted model. ‘classification’ and ‘detection’ are supported now.
default: ‘classification’.</p></li>
<li><p><strong>targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, turns on the targeted attack. If False,
turns on untargeted attack. It should be noted that only untargeted attack
is supported for model_type=’detection’, Default: True.</p></li>
<li><p><strong>reserve_ratio</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – The percentage of objects that can be detected after attacks,
specifically for model_type=’detection’. Reserve_ratio should be in the range of (0, 1). Default: 0.3.</p></li>
<li><p><strong>pop_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of particles, which should be greater than
zero. Default: 6.</p></li>
<li><p><strong>mutation_rate</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – The probability of mutations, which should be in the range of (0, 1).
Default: 0.005.</p></li>
<li><p><strong>per_bounds</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Maximum L_inf distance.</p></li>
<li><p><strong>max_steps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The maximum round of iteration for each adversarial
example. Default: 1000.</p></li>
<li><p><strong>step_size</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Attack step size. Default: 0.2.</p></li>
<li><p><strong>temp</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Sampling temperature for selection. Default: 0.3.
The greater the temp, the greater the differences between individuals’
selecting probabilities.</p></li>
<li><p><strong>bounds</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Upper and lower bounds of data. In form
of (clip_min, clip_max). Default: (0, 1.0).</p></li>
<li><p><strong>adaptive</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, turns on dynamic scaling of mutation
parameters. If false, turns on static mutation parameters.
Default: False.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, input labels are sparse-encoded. If False,
input labels are one-hot-encoded. Default: True.</p></li>
<li><p><strong>c</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Weight of perturbation loss. Default: 0.1.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">M</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Cell</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">GeneticAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">GeneticAttack</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)[</span><span class="n">y_test</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">adv_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.GeneticAttack.generate">
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/genetic_attack.html#GeneticAttack.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.GeneticAttack.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate adversarial examples based on input data and targeted labels (or ground_truth labels).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Input samples. The format of inputs should be numpy.ndarray if
model_type=’classification’. The format of inputs can be (input1, input2, …) or only one array if
model_type=’detection’.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Targeted labels or ground-truth labels. The format of labels should
be numpy.ndarray if model_type=’classification’. The format of labels should be (gt_boxes, gt_labels)
if model_type=’detection’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>numpy.ndarray, bool values for each attack result.</p></li>
<li><p>numpy.ndarray, generated adversarial examples.</p></li>
<li><p>numpy.ndarray, query times for each sample.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.HopSkipJumpAttack">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">HopSkipJumpAttack</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">init_num_evals=100</em>, <em class="sig-param">max_num_evals=1000</em>, <em class="sig-param">stepsize_search=&quot;geometric_progression&quot;</em>, <em class="sig-param">num_iterations=20</em>, <em class="sig-param">gamma=1.0</em>, <em class="sig-param">constraint=&quot;l2&quot;</em>, <em class="sig-param">batch_size=32</em>, <em class="sig-param">clip_min=0.0</em>, <em class="sig-param">clip_max=1.0</em>, <em class="sig-param">sparse=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/hop_skip_jump_attack.html#HopSkipJumpAttack"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.HopSkipJumpAttack" title="Permalink to this definition">¶</a></dt>
<dd><p>HopSkipJumpAttack proposed by Chen, Jordan and Wainwright is a
decision-based attack. The attack requires access to output labels of
target model.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1904.02144">Chen J, Michael I. Jordan, Martin J. Wainwright.
HopSkipJumpAttack: A Query-Efficient Decision-Based Attack. 2019.
arXiv:1904.02144</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="mindarmour.html#mindarmour.BlackModel" title="mindarmour.BlackModel"><em>BlackModel</em></a>) – Target model.</p></li>
<li><p><strong>init_num_evals</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The initial number of evaluations for gradient
estimation. Default: 100.</p></li>
<li><p><strong>max_num_evals</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The maximum number of evaluations for gradient
estimation. Default: 1000.</p></li>
<li><p><strong>stepsize_search</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Indicating how to search for stepsize; Possible
values are ‘geometric_progression’, ‘grid_search’.
Default: ‘geometric_progression’.</p></li>
<li><p><strong>num_iterations</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of iterations. Default: 20.</p></li>
<li><p><strong>gamma</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Used to set binary search threshold theta. Default: 1.0.
For l2 attack the binary search threshold <cite>theta</cite> is
<span class="math notranslate nohighlight">\(gamma / d^{3/2}\)</span>. For linf attack is <span class="math notranslate nohighlight">\(gamma / d^2\)</span>.
Default: 1.0.</p></li>
<li><p><strong>constraint</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The norm distance to optimize. Possible values are ‘l2’,
‘linf’. Default: l2.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Batch size. Default: 32.</p></li>
<li><p><strong>clip_min</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – The minimum image component value.
Default: 0.</p></li>
<li><p><strong>clip_max</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – The maximum image component value.
Default: 1.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, input labels are sparse-encoded. If False,
input labels are one-hot-encoded. Default: True.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If stepsize_search not in [‘geometric_progression’,
    ‘grid_search’]</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If constraint not in [‘l2’, ‘linf’]</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">HopSkipJumpAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">HopSkipJumpAttack</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">class_num</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">n</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">class_num</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">adv_x</span><span class="p">,</span> <span class="n">_</span><span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.HopSkipJumpAttack.generate">
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/hop_skip_jump_attack.html#HopSkipJumpAttack.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.HopSkipJumpAttack.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate adversarial images in a for loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Origin images.</p></li>
<li><p><strong>labels</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Target labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>numpy.ndarray, bool values for each attack result.</p></li>
<li><p>numpy.ndarray, generated adversarial examples.</p></li>
<li><p>numpy.ndarray, query times for each sample.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.HopSkipJumpAttack.set_target_images">
<code class="sig-name descname">set_target_images</code><span class="sig-paren">(</span><em class="sig-param">target_images</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/hop_skip_jump_attack.html#HopSkipJumpAttack.set_target_images"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.HopSkipJumpAttack.set_target_images" title="Permalink to this definition">¶</a></dt>
<dd><p>Setting target images for target attack.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target_images</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Target images.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.NES">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">NES</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">scene</em>, <em class="sig-param">max_queries=10000</em>, <em class="sig-param">top_k=-1</em>, <em class="sig-param">num_class=10</em>, <em class="sig-param">batch_size=128</em>, <em class="sig-param">epsilon=0.3</em>, <em class="sig-param">samples_per_draw=128</em>, <em class="sig-param">momentum=0.9</em>, <em class="sig-param">learning_rate=1e-3</em>, <em class="sig-param">max_lr=5e-2</em>, <em class="sig-param">min_lr=5e-4</em>, <em class="sig-param">sigma=1e-3</em>, <em class="sig-param">plateau_length=20</em>, <em class="sig-param">plateau_drop=2.0</em>, <em class="sig-param">adv_thresh=0.25</em>, <em class="sig-param">zero_iters=10</em>, <em class="sig-param">starting_eps=1.0</em>, <em class="sig-param">starting_delta_eps=0.5</em>, <em class="sig-param">label_only_sigma=1e-3</em>, <em class="sig-param">conservative=2</em>, <em class="sig-param">sparse=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/natural_evolutionary_strategy.html#NES"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.NES" title="Permalink to this definition">¶</a></dt>
<dd><p>The class is an implementation of the Natural Evolutionary Strategies Attack
Method. NES uses natural evolutionary strategies to estimate gradients to
improve query efficiency. NES covers three settings: Query-Limited setting,
Partial-Information setting and Label-Only setting. In the query-limit
setting, the attack has a limited number of queries to the target model but
access to the probabilities of all classes. In the partial-info setting,
the attack only has access to the probabilities for top-k classes.
In the label-only setting, the attack only has access to a list of k inferred
labels ordered by their predicted probabilities. In the Partial-Information
setting and Label-Only setting, NES do target attack so user need to use
set_target_images method to set target images of target classes.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1804.08598">Andrew Ilyas, Logan Engstrom, Anish Athalye, and Jessy Lin.
Black-box adversarial attacks with limited queries and information. In
ICML, July 2018</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="mindarmour.html#mindarmour.BlackModel" title="mindarmour.BlackModel"><em>BlackModel</em></a>) – Target model to be attacked.</p></li>
<li><p><strong>scene</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Scene in ‘Label_Only’, ‘Partial_Info’ or ‘Query_Limit’.</p></li>
<li><p><strong>max_queries</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Maximum query numbers to generate an adversarial example. Default: 10000.</p></li>
<li><p><strong>top_k</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – For Partial-Info or Label-Only setting, indicating how much (Top-k) information is
available for the attacker. For Query-Limited setting, this input should be set as -1. Default: -1.</p></li>
<li><p><strong>num_class</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of classes in dataset. Default: 10.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Batch size. Default: 128.</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Maximum perturbation allowed in attack. Default: 0.3.</p></li>
<li><p><strong>samples_per_draw</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of samples draw in antithetic sampling. Default: 128.</p></li>
<li><p><strong>momentum</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Momentum. Default: 0.9.</p></li>
<li><p><strong>learning_rate</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Learning rate. Default: 1e-3.</p></li>
<li><p><strong>max_lr</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Max Learning rate. Default: 5e-2.</p></li>
<li><p><strong>min_lr</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Min Learning rate. Default: 5e-4.</p></li>
<li><p><strong>sigma</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Step size of random noise. Default: 1e-3.</p></li>
<li><p><strong>plateau_length</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Length of plateau used in Annealing algorithm. Default: 20.</p></li>
<li><p><strong>plateau_drop</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Drop of plateau used in Annealing algorithm. Default: 2.0.</p></li>
<li><p><strong>adv_thresh</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Threshold of adversarial. Default: 0.25.</p></li>
<li><p><strong>zero_iters</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of points to use for the proxy score. Default: 10.</p></li>
<li><p><strong>starting_eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Starting epsilon used in Label-Only setting. Default: 1.0.</p></li>
<li><p><strong>starting_delta_eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Delta epsilon used in Label-Only setting. Default: 0.5.</p></li>
<li><p><strong>label_only_sigma</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Sigma used in Label-Only setting. Default: 1e-3.</p></li>
<li><p><strong>conservative</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Conservation used in epsilon decay, it will increase if no convergence. Default: 2.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, input labels are sparse-encoded. If False,
input labels are one-hot-encoded. Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">NES</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">SCENE</span> <span class="o">=</span> <span class="s1">&#39;Query_Limit&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TOP_K</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span><span class="o">=</span> <span class="n">NES</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">SCENE</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">TOP_K</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_class</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_image</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">orig_class</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_class</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span><span class="o">.</span><span class="n">set_target_images</span><span class="p">(</span><span class="n">target_image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tag</span><span class="p">,</span> <span class="n">adv</span><span class="p">,</span> <span class="n">queries</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">target_class</span><span class="p">]))</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.NES.generate">
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/natural_evolutionary_strategy.html#NES.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.NES.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate adversarial examples based on input data and target labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Benign input samples.</p></li>
<li><p><strong>labels</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Target labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>numpy.ndarray, bool values for each attack result.</p></li>
<li><p>numpy.ndarray, generated adversarial examples.</p></li>
<li><p>numpy.ndarray, query times for each sample.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the top_k less than 0 in Label-Only or Partial-Info setting.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the target_imgs is None in Label-Only or Partial-Info setting.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If scene is not in [‘Label_Only’, ‘Partial_Info’, ‘Query_Limit’]</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.NES.set_target_images">
<code class="sig-name descname">set_target_images</code><span class="sig-paren">(</span><em class="sig-param">target_images</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/natural_evolutionary_strategy.html#NES.set_target_images"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.NES.set_target_images" title="Permalink to this definition">¶</a></dt>
<dd><p>Set target samples for target attack in the Partial-Info setting or Label-Only setting.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target_images</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Target samples for target attack.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.PointWiseAttack">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">PointWiseAttack</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">max_iter=1000</em>, <em class="sig-param">search_iter=10</em>, <em class="sig-param">is_targeted=False</em>, <em class="sig-param">init_attack=None</em>, <em class="sig-param">sparse=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/pointwise_attack.html#PointWiseAttack"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.PointWiseAttack" title="Permalink to this definition">¶</a></dt>
<dd><p>The Pointwise Attack make sure use the minimum number of changed pixels to generate adversarial sample for each
original sample.Those changed pixels will use binary search to make sure the distance between adversarial sample
and original sample is as close as possible.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1805.09190">L. Schott, J. Rauber, M. Bethge, W. Brendel: “Towards the
first adversarially robust neural network model on MNIST”, ICLR (2019)</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="mindarmour.html#mindarmour.BlackModel" title="mindarmour.BlackModel"><em>BlackModel</em></a>) – Target model.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Max rounds of iteration to generate adversarial image. Default: 1000.</p></li>
<li><p><strong>search_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Max rounds of binary search. Default: 10.</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, targeted attack. If False, untargeted attack. Default: False.</p></li>
<li><p><strong>init_attack</strong> (<em>Union</em><em>[</em><a class="reference internal" href="mindarmour.html#mindarmour.Attack" title="mindarmour.Attack"><em>Attack</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Attack used to find a starting point. Default: None.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, input labels are sparse-encoded. If False, input labels are one-hot-encoded.
Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">PointWiseAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">PointWiseAttack</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">is_adv_list</span><span class="p">,</span> <span class="n">adv_list</span><span class="p">,</span> <span class="n">query_times_each_adv</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.PointWiseAttack.generate">
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/pointwise_attack.html#PointWiseAttack.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.PointWiseAttack.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate adversarial examples based on input samples and targeted labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Benign input samples used as references to create adversarial examples.</p></li>
<li><p><strong>labels</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – For targeted attack, labels are adversarial target labels.
For untargeted attack, labels are ground-truth labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>numpy.ndarray, bool values for each attack result.</p></li>
<li><p>numpy.ndarray, generated adversarial examples.</p></li>
<li><p>numpy.ndarray, query times for each sample.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.PSOAttack">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">PSOAttack</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">model_type=&quot;classification&quot;</em>, <em class="sig-param">targeted=False</em>, <em class="sig-param">reserve_ratio=0.3</em>, <em class="sig-param">sparse=True</em>, <em class="sig-param">step_size=0.5</em>, <em class="sig-param">per_bounds=0.6</em>, <em class="sig-param">c1=2.0</em>, <em class="sig-param">c2=2.0</em>, <em class="sig-param">c=2.0</em>, <em class="sig-param">pop_size=6</em>, <em class="sig-param">t_max=1000</em>, <em class="sig-param">pm=0.5</em>, <em class="sig-param">bounds=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/pso_attack.html#PSOAttack"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.PSOAttack" title="Permalink to this definition">¶</a></dt>
<dd><p>The PSO Attack represents the black-box attack based on Particle Swarm
Optimization algorithm, which belongs to differential evolution algorithms.
This attack was proposed by Rayan Mosli et al. (2019).</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1909.07490">Rayan Mosli, Matthew Wright, Bo Yuan, Yin Pan, “They Might NOT
Be Giants: Crafting Black-Box Adversarial Examples with Fewer Queries
Using Particle Swarm Optimization”, arxiv: 1909.07490, 2019.</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="mindarmour.html#mindarmour.BlackModel" title="mindarmour.BlackModel"><em>BlackModel</em></a>) – Target model.</p></li>
<li><p><strong>step_size</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Attack step size. Default: 0.5.</p></li>
<li><p><strong>per_bounds</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Relative variation range of perturbations. Default: 0.6.</p></li>
<li><p><strong>c1</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Weight coefficient. Default: 2.</p></li>
<li><p><strong>c2</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Weight coefficient. Default: 2.</p></li>
<li><p><strong>c</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – Weight of perturbation loss. Default: 2.</p></li>
<li><p><strong>pop_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of particles, which should be greater
than zero. Default: 6.</p></li>
<li><p><strong>t_max</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The maximum round of iteration for each adversarial example,
which should be greater than zero. Default: 1000.</p></li>
<li><p><strong>pm</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – The probability of mutations, which should be in the range of (0, 1). Default: 0.5.</p></li>
<li><p><strong>bounds</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Upper and lower bounds of data. In form of (clip_min,
clip_max). Default: None.</p></li>
<li><p><strong>targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, turns on the targeted attack. If False,
turns on untargeted attack. It should be noted that only untargeted attack
is supported for model_type=’detection’, Default: False.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, input labels are sparse-encoded. If False,
input labels are one-hot-encoded. Default: True.</p></li>
<li><p><strong>model_type</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The type of targeted model. ‘classification’ and ‘detection’ are supported now.
default: ‘classification’.</p></li>
<li><p><strong>reserve_ratio</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – The percentage of objects that can be detected after attacks,
specifically for model_type=’detection’. Reserve_ratio should be in the range of (0, 1). Default: 0.3.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Cell</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">PSOAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">PSOAttack</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">pm</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)[</span><span class="n">y_test</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">adv_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.PSOAttack.generate">
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/pso_attack.html#PSOAttack.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.PSOAttack.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate adversarial examples based on input data and
targeted labels (or ground_truth labels).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Input samples. The format of inputs should be numpy.ndarray if
model_type=’classification’. The format of inputs can be (input1, input2, …) or only one array if
model_type=’detection’.</p></li>
<li><p><strong>labels</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Targeted labels or ground-truth labels. The format of labels should
be numpy.ndarray if model_type=’classification’. The format of labels should be (gt_boxes, gt_labels)
if model_type=’detection’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>numpy.ndarray, bool values for each attack result.</p></li>
<li><p>numpy.ndarray, generated adversarial examples.</p></li>
<li><p>numpy.ndarray, query times for each sample.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.adv_robustness.attacks.SaltAndPepperNoiseAttack">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.adv_robustness.attacks.</code><code class="sig-name descname">SaltAndPepperNoiseAttack</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">bounds=(0.0</em>, <em class="sig-param">1.0)</em>, <em class="sig-param">max_iter=100</em>, <em class="sig-param">is_targeted=False</em>, <em class="sig-param">sparse=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/salt_and_pepper_attack.html#SaltAndPepperNoiseAttack"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.SaltAndPepperNoiseAttack" title="Permalink to this definition">¶</a></dt>
<dd><p>Increases the amount of salt and pepper noise  to generate adversarial samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="mindarmour.html#mindarmour.BlackModel" title="mindarmour.BlackModel"><em>BlackModel</em></a>) – Target model.</p></li>
<li><p><strong>bounds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Upper and lower bounds of data. In form of (clip_min, clip_max). Default: (0.0, 1.0)</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Max iteration to generate an adversarial example. Default: 100</p></li>
<li><p><strong>is_targeted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, targeted attack. If False, untargeted attack. Default: False.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, input labels are sparse-encoded. If False, input labels are one-hot-encoded.
Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">SaltAndPepperNoiseAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">SaltAndPepperNoiseAttack</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">adv_list</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.adv_robustness.attacks.SaltAndPepperNoiseAttack.generate">
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/salt_and_pepper_attack.html#SaltAndPepperNoiseAttack.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.SaltAndPepperNoiseAttack.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate adversarial examples based on input data and target labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – The original, unperturbed inputs.</p></li>
<li><p><strong>labels</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – The target labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>numpy.ndarray, bool values for each attack result.</p></li>
<li><p>numpy.ndarray, generated adversarial examples.</p></li>
<li><p>numpy.ndarray, query times for each sample.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="mindarmour.adv_robustness.defenses.html" class="btn btn-neutral float-right" title="mindarmour.adv_robustness.defenses" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="mindarmour.html" class="btn btn-neutral float-left" title="mindarmour" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>