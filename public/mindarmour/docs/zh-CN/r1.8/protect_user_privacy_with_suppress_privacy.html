

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>应用抑制隐私机制保护用户隐私 &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="模型加密保护" href="model_encrypt_protection.html" />
    <link rel="prev" title="应用差分隐私机制保护用户隐私" href="protect_user_privacy_with_differential_privacy.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindarmour_install.html">安装MindArmour</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI安全</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">使用NAD算法提升模型安全性</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">使用fuzz testing模块测试模型安全性</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">使用成员推理测试模型安全性</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluation_of_CNNCTC.html">对OCR模型CNN-CTC的鲁棒性评测</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI隐私</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">应用差分隐私机制保护用户隐私</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">应用抑制隐私机制保护用户隐私</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#概述">概述</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#mindarmour实现的抑制隐私">MindArmour实现的抑制隐私</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#实现阶段">实现阶段</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#导入需要的库文件">导入需要的库文件</a></li>
<li class="toctree-l3"><a class="reference internal" href="#参数配置">参数配置</a></li>
<li class="toctree-l3"><a class="reference internal" href="#预处理数据集">预处理数据集</a></li>
<li class="toctree-l3"><a class="reference internal" href="#建立模型">建立模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="#引入抑制隐私训练">引入抑制隐私训练</a></li>
<li class="toctree-l3"><a class="reference internal" href="#隐私保护效果测试">隐私保护效果测试</a></li>
<li class="toctree-l3"><a class="reference internal" href="#引用">引用</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_encrypt_protection.html">模型加密保护</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI可靠性</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="concept_drift_time_series.html">实现时序数据概念漂移检测应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="concept_drift_images.html">实现图像数据概念漂移检测应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="fault_injection.html">实现模型故障注入评估模型容错性</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.html">mindarmour</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.attacks.html">mindarmour.adv_robustness.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.defenses.html">mindarmour.adv_robustness.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.detectors.html">mindarmour.adv_robustness.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.evaluations.html">mindarmour.adv_robustness.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.fuzz_testing.html">mindarmour.fuzz_testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.natural_robustness.transform.image.html">mindarmour.natural_robustness.transform.image</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.diff_privacy.html">mindarmour.privacy.diff_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.evaluation.html">mindarmour.privacy.evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.sup_privacy.html">mindarmour.privacy.sup_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.reliability.html">mindarmour.reliability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.utils.html">mindarmour.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design.html">安全可信总体设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="differential_privacy_design.html">差分隐私设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="fuzzer_design.html">AI模型安全测试设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="security_and_privacy.html">MindArmour模块介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>应用抑制隐私机制保护用户隐私</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/protect_user_privacy_with_suppress_privacy.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="应用抑制隐私机制保护用户隐私">
<h1>应用抑制隐私机制保护用户隐私<a class="headerlink" href="#应用抑制隐私机制保护用户隐私" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.8/docs/mindarmour/docs/source_zh_cn/protect_user_privacy_with_suppress_privacy.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_source.png"></a></p>
<section id="概述">
<h2>概述<a class="headerlink" href="#概述" title="Permalink to this headline"></a></h2>
<p>抑制隐私是一种保护用户数据隐私的机制。抑制隐私是在AI训练过程中保护用户隐私的一种方法。通过去除模型中不重要的参数，使得其参数量得以大幅度的减少，减少了模型可能泄露的输入样本信息，从而大大降低通过模型逆向攻击获得原始样本的可能性。实验表明抑制隐私技术相对于差分隐私能够在某些模型的训练精度和隐私保护程度之间取得更好的平衡。</p>
<section id="mindarmour实现的抑制隐私">
<h3>MindArmour实现的抑制隐私<a class="headerlink" href="#mindarmour实现的抑制隐私" title="Permalink to this headline"></a></h3>
<p>MindArmour的抑制隐私模块Suppress-Privacy，实现了抑制隐私优化器。在模型训练过程中，不重要的参数会按照一定的比例逐渐地被设置为0，最终只保留5-10%的参数。</p>
<p>这里以LeNet模型，MNIST 数据集为例，说明如何在MindSpore上使用抑制隐私优化器训练神经网络模型。</p>
<blockquote>
<div><p>本例面向Ascend 910 AI处理器，你可以在这里下载完整的样例代码：<a class="reference external" href="https://gitee.com/mindspore/mindarmour/blob/r1.8/examples/privacy/sup_privacy/sup_privacy.py">https://gitee.com/mindspore/mindarmour/blob/r1.8/examples/privacy/sup_privacy/sup_privacy.py</a></p>
</div></blockquote>
</section>
</section>
<section id="实现阶段">
<h2>实现阶段<a class="headerlink" href="#实现阶段" title="Permalink to this headline"></a></h2>
<section id="导入需要的库文件">
<h3>导入需要的库文件<a class="headerlink" href="#导入需要的库文件" title="Permalink to this headline"></a></h3>
<p>下列是我们需要的公共模块、MindSpore相关模块和抑制隐私特性模块。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">easydict</span> <span class="kn">import</span> <span class="n">EasyDict</span> <span class="k">as</span> <span class="n">edict</span>

<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Accuracy</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision</span> <span class="k">as</span> <span class="nn">vision</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset.vision</span> <span class="kn">import</span> <span class="n">Inter</span>

<span class="kn">from</span> <span class="nn">examples.common.networks.lenet5.lenet5_net</span> <span class="kn">import</span> <span class="n">LeNet5</span>

<span class="kn">from</span> <span class="nn">mindarmour.privacy.sup_privacy</span> <span class="kn">import</span> <span class="n">SuppressModel</span>
<span class="kn">from</span> <span class="nn">mindarmour.privacy.sup_privacy</span> <span class="kn">import</span> <span class="n">SuppressMasker</span>
<span class="kn">from</span> <span class="nn">mindarmour.privacy.sup_privacy</span> <span class="kn">import</span> <span class="n">SuppressPrivacyFactory</span>
<span class="kn">from</span> <span class="nn">mindarmour.privacy.sup_privacy</span> <span class="kn">import</span> <span class="n">MaskLayerDes</span>

<span class="kn">from</span> <span class="nn">mindarmour.utils</span> <span class="kn">import</span> <span class="n">LogUtil</span>

<span class="n">LOGGER</span> <span class="o">=</span> <span class="n">LogUtil</span><span class="o">.</span><span class="n">get_instance</span><span class="p">()</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">set_level</span><span class="p">(</span><span class="s1">&#39;INFO&#39;</span><span class="p">)</span>
<span class="n">TAG</span> <span class="o">=</span> <span class="s1">&#39;Lenet5_Suppress_train&#39;</span>
</pre></div>
</div>
</section>
<section id="参数配置">
<h3>参数配置<a class="headerlink" href="#参数配置" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>设置运行环境、模型训练参数、checkpoint存储参数，batch_size参数建议不要超过64。更多配置可以参考<a class="reference external" href="https://gitee.com/mindspore/mindarmour/blob/r1.8/examples/privacy/sup_privacy/sup_privacy_config.py">https://gitee.com/mindspore/mindarmour/blob/r1.8/examples/privacy/sup_privacy/sup_privacy_config.py</a>。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cfg</span> <span class="o">=</span> <span class="n">edict</span><span class="p">({</span>
     <span class="s1">&#39;num_classes&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>  <span class="c1"># the number of classes of model&#39;s output</span>
     <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>  <span class="c1"># batch size for training</span>
     <span class="s1">&#39;image_height&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>  <span class="c1"># the height of training samples</span>
     <span class="s1">&#39;image_width&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>  <span class="c1"># the width of training samples</span>
     <span class="s1">&#39;keep_checkpoint_max&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>  <span class="c1"># the maximum number of checkpoint files would be saved</span>
     <span class="s1">&#39;device_target&#39;</span><span class="p">:</span> <span class="s1">&#39;Ascend&#39;</span><span class="p">,</span>  <span class="c1"># device used</span>
<span class="p">})</span>
</pre></div>
</div>
</li>
<li><p>配置必要的信息，包括环境信息、执行的模式。目前支持Ascend上的PyNative模式。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device_target</span><span class="p">)</span>
</pre></div>
</div>
<p>详细的接口配置信息，请参见<code class="docutils literal notranslate"><span class="pre">set_context</span></code>接口说明。</p>
</li>
</ol>
</section>
<section id="预处理数据集">
<h3>预处理数据集<a class="headerlink" href="#预处理数据集" title="Permalink to this headline"></a></h3>
<p>加载数据集并处理成MindSpore数据格式。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_mnist_dataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                           <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    create dataset for training or testing</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># define dataset</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MnistDataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>

    <span class="c1"># define operation parameters</span>
    <span class="n">resize_height</span><span class="p">,</span> <span class="n">resize_width</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span>
    <span class="n">rescale</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">255.0</span>
    <span class="n">shift</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1"># define map operations</span>
    <span class="n">resize_op</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="n">resize_height</span><span class="p">,</span> <span class="n">resize_width</span><span class="p">),</span>
                          <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">)</span>
    <span class="n">rescale_op</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="n">rescale</span><span class="p">,</span> <span class="n">shift</span><span class="p">)</span>
    <span class="n">hwc2chw_op</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="n">type_cast_op</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="c1"># apply map operations on images</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sparse</span><span class="p">:</span>
        <span class="n">one_hot_enco</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">OneHot</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">one_hot_enco</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span>
                      <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>
        <span class="n">type_cast_op</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">type_cast_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span>
                  <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">resize_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span>
                  <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">rescale_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span>
                  <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">hwc2chw_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span>
                  <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>

    <span class="c1"># apply DatasetOps</span>
    <span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">10000</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">buffer_size</span><span class="p">)</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat_size</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ds1</span>
</pre></div>
</div>
</section>
<section id="建立模型">
<h3>建立模型<a class="headerlink" href="#建立模型" title="Permalink to this headline"></a></h3>
<p>这里以LeNet模型为例，您也可以建立训练自己的模型。</p>
<p>加载LeNet网络，配置checkpoint、设置优化器类型，用上述定义的数据加载函数<code class="docutils literal notranslate"><span class="pre">generate_mnist_dataset</span></code>载入数据。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">networks_l5</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="n">config_ck</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                             <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">keep_checkpoint_max</span><span class="p">)</span>
<span class="n">ckpoint_cb</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;checkpoint_lenet&quot;</span><span class="p">,</span>
                             <span class="n">directory</span><span class="o">=</span><span class="s1">&#39;./trained_ckpt_file/&#39;</span><span class="p">,</span>
                             <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>

<span class="c1"># get training dataset</span>
<span class="n">ds_train</span> <span class="o">=</span> <span class="n">generate_mnist_dataset</span><span class="p">(</span><span class="s1">&#39;MNIST_unzip/train&#39;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="引入抑制隐私训练">
<h3>引入抑制隐私训练<a class="headerlink" href="#引入抑制隐私训练" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>配置抑制隐私优化器的参数</p>
<ul class="simple">
<li><p>定义AI模型的哪些层参与suppress操作。</p></li>
<li><p>实例化抑制隐私工厂类。</p></li>
<li><p>定义损失函数。</p></li>
<li><p>设置优化器类型。</p></li>
<li><p>如果样本数为60000，推荐的参数设置为end_epoch:10，start_epoch:3，mask_times:1000，lr:0.10，sparse_end:0.95，sparse_start:0.0。
这样相邻两次suppress操作的间隔大致在10~20个batch。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># layer_name (str): Layer name, get the name of one layer as following:</span>
<span class="c1">#    for layer in networks.get_parameters(expand=True):</span>
<span class="c1">#        if layer.name == &quot;conv&quot;: ...</span>
<span class="c1"># grad_idx (int): Grad layer index, get mask layer&#39;s index in grad tuple.</span>
<span class="c1"># is_add_noise (bool): If True, the weight of this layer can add noise.</span>
<span class="c1">#    If False, the weight of this layer can not add noise.</span>
<span class="c1"># is_lower_clip (bool): If true, the weights of this layer would be clipped to greater than an lower bound value.</span>
<span class="c1">#    If False, the weights of this layer won&#39;t be clipped.</span>
<span class="c1"># min_num (int): The number of weights left that not be suppressed, which need to be greater than 0.</span>
<span class="c1"># upper_bound (float): max value of weight in this layer, default value is 1.20 .</span>
<span class="n">masklayers_lenet5</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># determine which layer should be masked</span>
<span class="n">masklayers_lenet5</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MaskLayerDes</span><span class="p">(</span><span class="s2">&quot;conv1.weight&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">masklayers_lenet5</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MaskLayerDes</span><span class="p">(</span><span class="s2">&quot;conv2.weight&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span>
<span class="n">masklayers_lenet5</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MaskLayerDes</span><span class="p">(</span><span class="s2">&quot;fc1.weight&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">masklayers_lenet5</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MaskLayerDes</span><span class="p">(</span><span class="s2">&quot;fc2.weight&quot;</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">masklayers_lenet5</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MaskLayerDes</span><span class="p">(</span><span class="s2">&quot;fc3.weight&quot;</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span>

<span class="c1"># networks (Cell): The training network.</span>
<span class="c1"># mask_layers (list): Description of the training network layers that need to be suppressed.</span>
<span class="c1"># policy (str): Training policy for suppress privacy training. &quot;local_train&quot; means local training.</span>
<span class="c1"># end_epoch (int): The last epoch in suppress operations, 0 &lt; start_epoch &lt;= end_epoch &lt;= 100 .</span>
<span class="c1"># batch_num (int): The num of batch in an epoch, should be equal to num_samples/batch_size .</span>
<span class="c1"># start_epoch (int): The first epoch in suppress operations, 0 &lt; start_epoch &lt;= end_epoch &lt;= 100 .</span>
<span class="c1"># mask_times (int): The num of suppress operations.</span>
<span class="c1"># lr (Union[float, int]): Learning rate, 0 &lt; lr &lt;= 0.5 .</span>
<span class="c1"># sparse_end (float): The sparsity to reach, 0.0 &lt;= sparse_start &lt; sparse_end &lt; 1.0 .</span>
<span class="c1"># sparse_start (float): The sparsity to start, 0.0 &lt;= sparse_start &lt; sparse_end &lt; 1.0 .  </span>
<span class="n">suppress_ctrl_instance</span> <span class="o">=</span> <span class="n">SuppressPrivacyFactory</span><span class="p">()</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">networks_l5</span><span class="p">,</span>
                                                        <span class="n">masklayers_lenet5</span><span class="p">,</span>
                                                        <span class="n">policy</span><span class="o">=</span><span class="s2">&quot;local_train&quot;</span><span class="p">,</span>
                                                        <span class="n">end_epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                                        <span class="n">batch_num</span><span class="o">=</span><span class="mi">1875</span><span class="p">,</span>
                                                        <span class="n">start_epoch</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                                        <span class="n">mask_times</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                                                        <span class="n">lr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                                                        <span class="n">sparse_end</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
                                                        <span class="n">sparse_start</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="n">net_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">networks_l5</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mf">0.05</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>将LeNet模型包装成抑制隐私模型</p>
<ul class="simple">
<li><p>实例化抑制隐私模型类SuppressModel，用于执行模型训练过程。</p></li>
<li><p>实例化抑制隐私监测器SuppressMasker，用于在模型训练中选择合适时机对模型参数进行suppress(置零)操作。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create the suppress model for training.</span>
<span class="n">model_instance</span> <span class="o">=</span> <span class="n">SuppressModel</span><span class="p">(</span><span class="n">network</span><span class="o">=</span><span class="n">networks_l5</span><span class="p">,</span>
                                <span class="n">loss_fn</span><span class="o">=</span><span class="n">net_loss</span><span class="p">,</span>
                                <span class="n">optimizer</span><span class="o">=</span><span class="n">net_opt</span><span class="p">,</span>
                                <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">Accuracy</span><span class="p">()})</span>
<span class="n">model_instance</span><span class="o">.</span><span class="n">link_suppress_ctrl</span><span class="p">(</span><span class="n">suppress_ctrl_instance</span><span class="p">)</span>
<span class="n">suppress_masker</span> <span class="o">=</span> <span class="n">SuppressMasker</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_instance</span><span class="p">,</span> <span class="n">suppress_ctrl</span><span class="o">=</span><span class="n">suppress_ctrl_instance</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>模型训练与测试</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s2">&quot;============== Starting SUPP Training ==============&quot;</span><span class="p">)</span>
<span class="n">model_instance</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ckpoint_cb</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">LossMonitor</span><span class="p">(),</span> <span class="n">suppress_masker</span><span class="p">],</span>
                     <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s2">&quot;============== Starting SUPP Testing ==============&quot;</span><span class="p">)</span>
<span class="n">ds_eval</span> <span class="o">=</span> <span class="n">generate_mnist_dataset</span><span class="p">(</span><span class="s1">&#39;MNIST_unzip/test&#39;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">model_instance</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">ds_eval</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s2">&quot;============== SUPP Accuracy: </span><span class="si">%s</span><span class="s2">  ==============&quot;</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>运行命令</p>
<p>运行脚本，可在命令行输入命令：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>examples/privacy/sup_privacy/sup_privacy.py
</pre></div>
</div>
<p>其中<code class="docutils literal notranslate"><span class="pre">sup_privacy.py</span></code>替换成你的脚本的名字。</p>
</li>
<li><p>结果展示</p>
<p>不加抑制隐私的LeNet模型精度稳定在99%，使用抑制隐私LeNet模型收敛，精度稳定在97.5%左右。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>============== Starting SUPP Training ==============
...
============== Starting SUPP Testing ==============
...
============== SUPP Accuracy: 0.9745  ==============
</pre></div>
</div>
</li>
</ol>
</section>
<section id="隐私保护效果测试">
<h3>隐私保护效果测试<a class="headerlink" href="#隐私保护效果测试" title="Permalink to this headline"></a></h3>
<p>为了评估抑制隐私训练对数据集的保护效果，我们使用图像逆向攻击进行测试，
这种逆向攻击可以根据原始图片在神经网络某一层的输出来反向还原出原始图片，主要原因是网络在训练的过程中“记住”了训练集的特征，
这种攻击方法的原理可以参考<a class="reference external" href="https://arxiv.org/pdf/1412.0035.pdf">https://arxiv.org/pdf/1412.0035.pdf</a>，完整的代码实现可以参考<a class="reference external" href="https://gitee.com/mindspore/mindarmour/blob/r1.8/examples/privacy/inversion_attack/mnist_inversion_attack.py">https://gitee.com/mindspore/mindarmour/blob/r1.8/examples/privacy/inversion_attack/mnist_inversion_attack.py</a>
，下面介绍详细的测试步骤：</p>
<ol class="arabic">
<li><p>准备工作</p>
<p>为了和抑制隐私训练进行对比，我们需要先使用常规训练得到模型的CheckPoint文件。模型训练可以参考
<a class="reference external" href="https://gitee.com/mindspore/mindarmour/blob/r1.8/examples/common/networks/lenet5/mnist_train.py">mindarmour/examples/common/networks/lenet5</a> ，
它的目录结构如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>├── __init__.py
├── lenet5_net.py
└── mnist_train.py
</pre></div>
</div>
<p>其中<code class="docutils literal notranslate"><span class="pre">lenet5_net.py</span></code>为LeNet5的模型定义，<code class="docutils literal notranslate"><span class="pre">mnist_train.py</span></code>为LeNet5的常规训练脚本。在该目录下运行如下命令，即可生成包含模型CheckPoint文件的<code class="docutils literal notranslate"><span class="pre">trained_ckpt_file</span></code>文件夹。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>mnist_train.py
</pre></div>
</div>
<p>此外，由于下面的步骤7中需要用到新训练的模型进行攻击效果的评估，我们在生成<code class="docutils literal notranslate"><span class="pre">trained_ckpt_file</span></code>目录后，将<code class="docutils literal notranslate"><span class="pre">mnist_train.py</span></code>文件中的变量<code class="docutils literal notranslate"><span class="pre">ckpoint_cb</span></code>的生成命令改成：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ckpoint_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;checkpoint_lenet&quot;</span><span class="p">,</span>
                          <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;./new_trained_ckpt_file/&quot;</span><span class="p">,</span>
                          <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
</pre></div>
</div>
<p>其中<code class="docutils literal notranslate"><span class="pre">prefix</span></code>代表生成的CheckPoint文件名的前缀，<code class="docutils literal notranslate"><span class="pre">directory</span></code>代表CheckPoint文件的存放路径，再运行<code class="docutils literal notranslate"><span class="pre">mnist_train.py</span></code>，
就可以得到<code class="docutils literal notranslate"><span class="pre">new_trained_ckpt_file</span></code>文件夹及包含其中的模型文件。此时<code class="docutils literal notranslate"><span class="pre">examples/common/networks/lenet5</span></code>的目录结构应该如下所示：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span> ├── __init__.py
 ├── lenet5_net.py
 ├── mnist_train.py
 ├── new_trained_ckpt_file
 │   ├── checkpoint_lenet-10_1875.ckpt
 │   ├── checkpoint_lenet-1_1875.ckpt
 │   ├── checkpoint_lenet-2_1875.ckpt
 │   ├── checkpoint_lenet-3_1875.ckpt
 │   ├── checkpoint_lenet-4_1875.ckpt
 │   ├── checkpoint_lenet-5_1875.ckpt
 │   ├── checkpoint_lenet-6_1875.ckpt
 │   ├── checkpoint_lenet-7_1875.ckpt
 │   ├── checkpoint_lenet-8_1875.ckpt
 │   ├── checkpoint_lenet-9_1875.ckpt
 │   └── checkpoint_lenet-graph.meta
 └── trained_ckpt_file
     ├── checkpoint_lenet-10_1875.ckpt
     ├── checkpoint_lenet-1_1875.ckpt
     ├── checkpoint_lenet-2_1875.ckpt
     ├── checkpoint_lenet-3_1875.ckpt
     ├── checkpoint_lenet-4_1875.ckpt
     ├── checkpoint_lenet-5_1875.ckpt
     ├── checkpoint_lenet-6_1875.ckpt
     ├── checkpoint_lenet-7_1875.ckpt
     ├── checkpoint_lenet-8_1875.ckpt
     ├── checkpoint_lenet-9_1875.ckpt
     └── checkpoint_lenet-graph.meta
</pre></div>
</div>
</li>
<li><p>导入需要的模块</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">softmax</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindarmour.privacy.evaluation</span> <span class="kn">import</span> <span class="n">ImageInversionAttack</span>
<span class="kn">from</span> <span class="nn">mindarmour.utils</span> <span class="kn">import</span> <span class="n">LogUtil</span>
<span class="kn">from</span> <span class="nn">examples.common.networks.lenet5.lenet5_net</span> <span class="kn">import</span> <span class="n">LeNet5</span><span class="p">,</span> <span class="n">conv</span><span class="p">,</span> <span class="n">fc_with_initialize</span>
<span class="kn">from</span> <span class="nn">examples.common.dataset.data_processing</span> <span class="kn">import</span> <span class="n">generate_mnist_dataset</span>
<span class="n">LOGGER</span> <span class="o">=</span> <span class="n">LogUtil</span><span class="o">.</span><span class="n">get_instance</span><span class="p">()</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">set_level</span><span class="p">(</span><span class="s1">&#39;INFO&#39;</span><span class="p">)</span>
<span class="n">TAG</span> <span class="o">=</span> <span class="s1">&#39;InversionAttack&#39;</span>
</pre></div>
</div>
</li>
<li><p>构建逆向测试网络</p>
<p>为了更好地演示，我们取LeNet5的前面两个卷积层conv1、conv2和第一个全连接层fc1作为测试网络，于是攻击任务就是：根据某一图片从fc1输出的feature map来还原出该图片。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LeNet5_part</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Part of LeNet5 network.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet5_part</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">16</span><span class="o">*</span><span class="mi">5</span><span class="o">*</span><span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</li>
<li><p>将训练好的CheckPoint文件导入模型</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Checkpoint_path</span> <span class="o">=</span> <span class="s1">&#39;../../common/networks/lenet5/trained_ckpt_file/checkpoint_lenet-10_1875.ckpt&#39;</span>
<span class="n">load_dict</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">Checkpoint_path</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5_part</span><span class="p">()</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">load_dict</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>获取测试样本</p>
<p>我们取30张图片进行测试，保存好它们本身以及它们经过<code class="docutils literal notranslate"><span class="pre">LeNet5_part</span></code>的输出（即<code class="docutils literal notranslate"><span class="pre">target_features</span></code>）。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># get original data</span>
<span class="n">data_list</span> <span class="o">=</span> <span class="s2">&quot;../../common/dataset/MNIST/train&quot;</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">generate_mnist_dataset</span><span class="p">(</span><span class="n">data_list</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">batch_num</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">sample_num</span> <span class="o">=</span> <span class="mi">30</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">ds</span><span class="o">.</span><span class="n">create_tuple_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">true_labels</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">][:</span> <span class="n">sample_num</span><span class="p">]</span>
    <span class="n">target_features</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">images</span><span class="p">))</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[:</span><span class="n">sample_num</span><span class="p">]</span>
    <span class="n">original_images</span> <span class="o">=</span> <span class="n">images</span><span class="p">[:</span> <span class="n">sample_num</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">batch_num</span><span class="p">:</span>
        <span class="k">break</span>
</pre></div>
</div>
</li>
<li><p>进行逆向攻击</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inversion_attack</span> <span class="o">=</span> <span class="n">ImageInversionAttack</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">input_bound</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loss_weights</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">inversion_images</span> <span class="o">=</span> <span class="n">inversion_attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">target_features</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>攻击结果评估和展示</p>
<p>我们用matplotlib画出原始图像以及用逆向攻击还原出来的图像，并且调用<code class="docutils literal notranslate"><span class="pre">inversion_attack</span></code>的<code class="docutils literal notranslate"><span class="pre">evaluate</span></code>方法进行定量评估，
<code class="docutils literal notranslate"><span class="pre">evaluate</span></code>方法会返回<code class="docutils literal notranslate"><span class="pre">avg_l2_dis</span></code>，<code class="docutils literal notranslate"><span class="pre">avg_ssim</span></code>和<code class="docutils literal notranslate"><span class="pre">avg_confi</span></code>，分别表示原图与逆向还原的图像之间的平均L2
范数距离和平均结构相似性，以及逆向还原出来的图片在一个新模型上的推理结果（在其真实标签上的平均置信度）。
一般来说，<code class="docutils literal notranslate"><span class="pre">avg_l2_dis</span></code>越小、<code class="docutils literal notranslate"><span class="pre">avg_ssim</span></code>越大，则代表inversion_images与original_images越接近；而新的神经网络模型可以替代人眼对图片的可识别度做一个定量的评估（即<code class="docutils literal notranslate"><span class="pre">avg_confi</span></code>越高，说明inversion_image包含的语义信息与原图更为接近）。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plot_num</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">sample_num</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">plot_num</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">plot_num</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Original images&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gray</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">plot_num</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="n">plot_num</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Inverted images based on ordinary trained model&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gray</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">inversion_images</span><span class="p">[</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">net2</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="n">new_ckpt_path</span> <span class="o">=</span> <span class="s1">&#39;../../common/networks/lenet5/new_trained_ckpt_file/checkpoint_lenet-10_1875.ckpt&#39;</span>
<span class="n">new_load_dict</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">new_ckpt_path</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net2</span><span class="p">,</span> <span class="n">new_load_dict</span><span class="p">)</span>
<span class="n">pred_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">net2</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inversion_images</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">avg_l2_dis</span><span class="p">,</span> <span class="n">avg_ssim</span><span class="p">,</span> <span class="n">avg_confi</span> <span class="o">=</span> <span class="n">inversion_attack</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">original_images</span><span class="p">,</span> <span class="n">inversion_images</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">,</span> <span class="n">net2</span><span class="p">)</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s1">&#39;The average L2 distance between original images and inverted images is: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_l2_dis</span><span class="p">))</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s1">&#39;The average ssim value between original images and inverted images is: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_ssim</span><span class="p">))</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s1">&#39;The average prediction confidence on true labels of inverted images is: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_confi</span><span class="p">))</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s1">&#39;True labels of original images are:      </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">true_labels</span><span class="p">)</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s1">&#39;Predicted labels of inverted images are: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">pred_labels</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>实验结果</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>The average L2 distance between original images and inverted images is: 0.8294931122450715
The average ssim value between original images and inverted images is: 0.2429179625584347
The average prediction confidence on true labels of inverted images is: 0.9547292590141296
True labels of original images are:      [5 7 1 0 4 3 1 5 5 9 5 0 9 9 7 5 4 2 1 7 4 0 0 6 2 6 0 6 6 6]
Predicted labels of inverted images are: [5 7 1 0 4 3 1 5 5 9 5 0 9 9 7 5 4 2 1 7 4 0 0 6 2 6 0 6 6 6]
</pre></div>
</div>
<p><img alt="fuzz_seed" src="_images/inversion_ordinary.png" /></p>
<p>我们可以从inversion_images看出original_images的大概轮廓了，说明常规训练的模型很可能会导致训练集的隐私泄露。
<strong>为了验证抑制隐私训练得到的模型可以更好地保护训练数据的信息</strong>，我们将上述步骤4中的CheckPoint文件换成抑制隐私训练得到的CheckPoint文件，并执行上述步骤2至步骤7的过程，可以得到如下结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>The average L2 distance between original images and inverted images is: 0.862553358599391
The average ssim value between original images and inverted images is: 0.2644709319921787
The average prediction confidence on true labels of inverted images is: 0.5576204061508179
True labels of original images are:      [9 2 2 0 1 2 9 8 5 0 7 3 4 8 9 0 6 6 7 2 0 6 7 5 8 8 1 6 7 9]
Predicted labels of inverted images are: [8 2 2 0 1 2 7 8 5 0 7 3 4 8 9 7 6 6 7 2 0 6 7 5 8 8 1 5 7 9]
</pre></div>
</div>
<p><img alt="fuzz_seed" src="_images/inversion_sup.png" /></p>
<p>首先，从可视化上结果来看，基于抑制隐私训练得到的模型进行逆向攻击，效果很差；但这种情形下得到的avg_l2_dis和avg_ssim和上一种情形很接近，
这主要是由于avg_l2_dis和avg_ssim只能根据图片像素的均值和标准差比较图片之间的低阶信息，而avg_confi可以比较图片之间的高阶语义信息。</p>
<p>本实验使用的样本是MNIST数据集，这类图片较为简单，黑色背景占了图片的大部分区域，而包含主要信息的白色部分占据的区域较少。但可以看到，
基于抑制隐私模型得到的avg_confi明显低于上一组实验，这说明逆向构造出来的图片已经比较难被新模型识别出来了，这个结果和我们人眼观察的结果是一致的。</p>
</li>
</ol>
</section>
<section id="引用">
<h3>引用<a class="headerlink" href="#引用" title="Permalink to this headline"></a></h3>
<p>[1] Ligeng Zhu, Zhijian Liu, and Song Han. <a class="reference external" href="http://arxiv.org/pdf/1906.08935.pdf">Deep Leakage from Gradients</a>. NeurIPS, 2019.</p>
<p>[2] Aravindh Mahendran, Andrea Vedaldi. <a class="reference external" href="https://arxiv.org/pdf/1412.0035.pdf">Understanding Deep Image Representations by Inverting Them</a>. CVPR, 2015.</p>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="protect_user_privacy_with_differential_privacy.html" class="btn btn-neutral float-left" title="应用差分隐私机制保护用户隐私" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="model_encrypt_protection.html" class="btn btn-neutral float-right" title="模型加密保护" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>