<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindarmour.adv_robustness.attacks &mdash; MindSpore master 文档</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="next" title="mindarmour.adv_robustness.defenses" href="mindarmour.adv_robustness.defenses.html" />
    <link rel="prev" title="mindarmour" href="mindarmour.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindarmour_install.html">安装MindSpore Armour</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI安全</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">使用NAD算法提升模型安全性</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">使用fuzz testing模块测试模型安全性</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluation_of_CNNCTC.html">对OCR模型CNN-CTC的鲁棒性评测</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_encrypt_protection.html">模型加密保护</a></li>
<li class="toctree-l1"><a class="reference internal" href="dynamic_obfuscation_protection.html">模型动态混淆</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI隐私</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">应用差分隐私机制保护用户隐私</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_suppress_privacy.html">应用抑制隐私机制保护用户隐私</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">使用成员推理测试模型安全性</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI可靠性</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="concept_drift_time_series.html">实现时序数据概念漂移检测应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="concept_drift_images.html">实现图像数据概念漂移检测应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="fault_injection.html">实现模型故障注入评估模型容错性</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API参考</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mindarmour.html">mindarmour</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindarmour.adv_robustness.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.defenses.html">mindarmour.adv_robustness.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.detectors.html">mindarmour.adv_robustness.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.evaluations.html">mindarmour.adv_robustness.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.fuzz_testing.html">mindarmour.fuzz_testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.natural_robustness.transform.image.html">mindarmour.natural_robustness.transform.image</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.diff_privacy.html">mindarmour.privacy.diff_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.evaluation.html">mindarmour.privacy.evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.sup_privacy.html">mindarmour.privacy.sup_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.reliability.html">mindarmour.reliability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.utils.html">mindarmour.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design.html">安全可信总体设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="differential_privacy_design.html">差分隐私设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="fuzzer_design.html">AI模型安全测试设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="security_and_privacy.html">MindSpore Armour模块介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>mindarmour.adv_robustness.attacks</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/mindarmour.adv_robustness.attacks.rst.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="mindarmour-adv-robustness-attacks">
<h1>mindarmour.adv_robustness.attacks<a class="headerlink" href="#mindarmour-adv-robustness-attacks" title="永久链接至标题"></a></h1>
<p>本模块包括经典的黑盒和白盒攻击算法，以制作对抗样本。</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.FastGradientMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">FastGradientMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#FastGradientMethod"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.FastGradientMethod" title="打开链接"></a></dt>
<dd><p>基于梯度计算的单步攻击，扰动的范数包括 ‘L1’、’L2’和’Linf’。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1412.6572">I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing adversarial examples,” in ICLR, 2015.</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 目标模型。</p></li>
<li><p><strong>eps</strong> (float) - 攻击产生的单步对抗扰动占数据范围的比例。默认值：0.07。</p></li>
<li><p><strong>alpha</strong> (Union[float, None]) - 单步随机扰动与数据范围的比例。默认值：None。</p></li>
<li><p><strong>bounds</strong> (tuple) - 数据的上下界，表示数据范围。以(数据最小值, 数据最大值)的形式出现。默认值：(0.0, 1.0)。</p></li>
<li><p><strong>norm_level</strong> (Union[int, str, numpy.inf]) - 范数类型。
可取值：numpy.inf、1、2、’1’、’2’、’l1’、’l2’、’np.inf’、’inf’、’linf’。默认值：2。</p></li>
<li><p><strong>is_targeted</strong> (bool) - 如果为True，则为目标攻击。如果为False，则为无目标攻击。默认值：False。</p></li>
<li><p><strong>loss_fn</strong> (Union[loss, None]) - 用于优化的损失函数。如果为None，则输入网络已配备损失函数。默认值：None。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">FastGradientMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">FastGradientMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.RandomFastGradientMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">RandomFastGradientMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.035</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#RandomFastGradientMethod"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.RandomFastGradientMethod" title="打开链接"></a></dt>
<dd><p>使用随机扰动的快速梯度法（Fast Gradient Method）。
基于梯度计算的单步攻击，其对抗性噪声是根据输入的梯度生成的，然后加入随机扰动，从而生成对抗样本。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1705.07204">Florian Tramer, Alexey Kurakin, Nicolas Papernot, “Ensemble adversarial training: Attacks and defenses” in ICLR, 2018</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 目标模型。</p></li>
<li><p><strong>eps</strong> (float) - 攻击产生的单步对抗扰动占数据范围的比例。默认值：0.07。</p></li>
<li><p><strong>alpha</strong> (float) - 单步随机扰动与数据范围的比例。默认值：0.035。</p></li>
<li><p><strong>bounds</strong> (tuple) - 数据的上下界，表示数据范围。以(数据最小值，数据最大值)的形式出现。默认值：(0.0, 1.0)。</p></li>
<li><p><strong>norm_level</strong> (Union[int, str, numpy.inf]) - 范数类型。
可取值：numpy.inf、1、2、’1’、’2’、’l1’、’l2’、’np.inf’、’inf’、’linf’。默认值：2。</p></li>
<li><p><strong>is_targeted</strong> (bool) - 如果为True，则为目标攻击。如果为False，则为无目标攻击。默认值：False。</p></li>
<li><p><strong>loss_fn</strong> (Union[loss, None]) - 用于优化的损失函数。如果为None，则输入网络已配备损失函数。默认值：None。</p></li>
</ul>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>ValueError</strong> - <cite>eps</cite> 小于 <cite>alpha</cite> 。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">RandomFastGradientMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">RandomFastGradientMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.FastGradientSignMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">FastGradientSignMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#FastGradientSignMethod"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.FastGradientSignMethod" title="打开链接"></a></dt>
<dd><p>快速梯度下降法（Fast Gradient Sign Method）攻击计算输入数据的梯度，然后使用梯度的符号创建对抗性噪声。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1412.6572">Ian J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing adversarial examples,” in ICLR, 2015</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 目标模型。</p></li>
<li><p><strong>eps</strong> (float) - 攻击产生的单步对抗扰动占数据范围的比例。默认值：0.07。</p></li>
<li><p><strong>alpha</strong> (Union[float, None]) - 单步随机扰动与数据范围的比例。默认值：None。</p></li>
<li><p><strong>bounds</strong> (tuple) - 数据的上下界，表示数据范围。以(数据最小值，数据最大值)的形式出现。默认值：(0.0, 1.0)。</p></li>
<li><p><strong>is_targeted</strong> (bool) - 如果为True，则为目标攻击。如果为False，则为无目标攻击。默认值：False。</p></li>
<li><p><strong>loss_fn</strong> (Union[Loss, None]) - 用于优化的损失函数。如果为None，则输入网络已配备损失函数。默认值：None。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">FastGradientSignMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">FastGradientSignMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.RandomFastGradientSignMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">RandomFastGradientSignMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.035</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#RandomFastGradientSignMethod"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.RandomFastGradientSignMethod" title="打开链接"></a></dt>
<dd><p>快速梯度下降法（Fast Gradient Sign Method）使用随机扰动。
随机快速梯度符号法（Random Fast Gradient Sign Method）攻击计算输入数据的梯度，然后使用带有随机扰动的梯度符号来创建对抗性噪声。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1705.07204">F. Tramer, et al., “Ensemble adversarial training: Attacks and defenses,” in ICLR, 2018</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 目标模型。</p></li>
<li><p><strong>eps</strong> (float) - 攻击产生的单步对抗扰动占数据范围的比例。默认值：0.07。</p></li>
<li><p><strong>alpha</strong> (float) - 单步随机扰动与数据范围的比例。默认值：0.005。</p></li>
<li><p><strong>bounds</strong> (tuple) - 数据的上下界，表示数据范围。以(数据最小值，数据最大值)的形式出现。默认值：(0.0, 1.0)。</p></li>
<li><p><strong>is_targeted</strong> (bool) - 如果为True，则为目标攻击。如果为False，则为无目标攻击。默认值：False。</p></li>
<li><p><strong>loss_fn</strong> (Union[Loss, None]) - 用于优化的损失函数。如果为None，则输入网络已配备损失函数。默认值：None。</p></li>
</ul>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>ValueError</strong> - <cite>eps</cite> 小于 <cite>alpha</cite> 。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">RandomFastGradientSignMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">RandomFastGradientSignMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.LeastLikelyClassMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">LeastLikelyClassMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#LeastLikelyClassMethod"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.LeastLikelyClassMethod" title="打开链接"></a></dt>
<dd><p>单步最不可能类方法（Single Step Least-Likely Class Method）是FGSM的变体，它以最不可能类为目标，以生成对抗样本。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1705.07204">F. Tramer, et al., “Ensemble adversarial training: Attacks and defenses,” in ICLR, 2018</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 目标模型。</p></li>
<li><p><strong>eps</strong> (float) - 攻击产生的单步对抗扰动占数据范围的比例。默认值：0.07。</p></li>
<li><p><strong>alpha</strong> (Union[float, None]) - 单步随机扰动与数据范围的比例。默认值：None。</p></li>
<li><p><strong>bounds</strong> (tuple) - 数据的上下界，表示数据范围。以(数据最小值，数据最大值)的形式出现。默认值：(0.0, 1.0)。</p></li>
<li><p><strong>loss_fn</strong> (Union[Loss, None]) - 用于优化的损失函数。如果为None，则输入网络已配备损失函数。默认值：None。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">LeastLikelyClassMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">LeastLikelyClassMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.RandomLeastLikelyClassMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">RandomLeastLikelyClassMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.035</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/gradient_method.html#RandomLeastLikelyClassMethod"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.RandomLeastLikelyClassMethod" title="打开链接"></a></dt>
<dd><p>随机最不可能类攻击方法：以置信度最小类别对应的梯度加一个随机扰动为攻击方向。</p>
<p>具有随机扰动的单步最不可能类方法（Single Step Least-Likely Class Method）是随机FGSM的变体，它以最不可能类为目标，以生成对抗样本。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1705.07204">F. Tramer, et al., “Ensemble adversarial training: Attacks and defenses,” in ICLR, 2018</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 目标模型。</p></li>
<li><p><strong>eps</strong> (float) - 攻击产生的单步对抗扰动占数据范围的比例。默认值：0.07。</p></li>
<li><p><strong>alpha</strong> (float) - 单步随机扰动与数据范围的比例。默认值：0.005。</p></li>
<li><p><strong>bounds</strong> (tuple) - 数据的上下界，表示数据范围。以(数据最小值，数据最大值)的形式出现。默认值：(0.0, 1.0)。</p></li>
<li><p><strong>loss_fn</strong> (Union[Loss, None]) - 用于优化的损失函数。如果为None，则输入网络已配备损失函数。默认值：None。</p></li>
</ul>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>ValueError</strong> - <cite>eps</cite> 小于 <cite>alpha</cite> 。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">RandomLeastLikelyClassMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">RandomLeastLikelyClassMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.IterativeGradientMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">IterativeGradientMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#IterativeGradientMethod"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.IterativeGradientMethod" title="打开链接"></a></dt>
<dd><p>所有基于迭代梯度的攻击的抽象基类。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 目标模型。</p></li>
<li><p><strong>eps</strong> (float) - 攻击产生的对抗性扰动占数据范围的比例。默认值：0.3。</p></li>
<li><p><strong>eps_iter</strong> (float) - 攻击产生的单步对抗扰动占数据范围的比例。默认值：0.1。</p></li>
<li><p><strong>bounds</strong> (tuple) - 数据的上下界，表示数据范围。以(数据最小值，数据最大值)的形式出现。默认值：(0.0, 1.0)。</p></li>
<li><p><strong>nb_iter</strong> (int) - 迭代次数。默认值：5。</p></li>
<li><p><strong>loss_fn</strong> (Union[Loss, None]) - 用于优化的损失函数。如果为None，则输入网络已配备损失函数。默认值：None。</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.IterativeGradientMethod.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#IterativeGradientMethod.generate"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.IterativeGradientMethod.generate" title="打开链接"></a></dt>
<dd><p>根据输入样本和原始/目标标签生成对抗样本。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (Union[numpy.ndarray, tuple]) - 良性输入样本，用于创建对抗样本。</p></li>
<li><p><strong>labels</strong> (Union[numpy.ndarray, tuple]) - 原始/目标标签。若每个输入有多个标签，将它包装在元组中。</p></li>
</ul>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>NotImplementedError</strong> - 此函数在迭代梯度方法中不可用。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.BasicIterativeMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">BasicIterativeMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#BasicIterativeMethod"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.BasicIterativeMethod" title="打开链接"></a></dt>
<dd><p>基本迭代法（Basic Iterative Method）攻击，一种生成对抗示例的迭代FGSM方法。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1607.02533">A. Kurakin, I. Goodfellow, and S. Bengio, “Adversarial examples in the physical world,” in ICLR, 2017</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 目标模型。</p></li>
<li><p><strong>eps</strong> (float) - 攻击产生的对抗性扰动占数据范围的比例。默认值：0.3。</p></li>
<li><p><strong>eps_iter</strong> (float) - 攻击产生的单步对抗扰动占数据范围的比例。默认值：0.1。</p></li>
<li><p><strong>bounds</strong> (tuple) - 数据的上下界，表示数据范围。以(数据最小值，数据最大值)的形式出现。默认值：(0.0, 1.0)。</p></li>
<li><p><strong>is_targeted</strong> (bool) - 如果为True，则为目标攻击。如果为False，则为无目标攻击。默认值：False。</p></li>
<li><p><strong>nb_iter</strong> (int) - 迭代次数。默认值：5。</p></li>
<li><p><strong>loss_fn</strong> (Union[Loss, None]) - 用于优化的损失函数。如果为None，则输入网络已配备损失函数。默认值：None。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">BasicIterativeMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">BasicIterativeMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.BasicIterativeMethod.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#BasicIterativeMethod.generate"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.BasicIterativeMethod.generate" title="打开链接"></a></dt>
<dd><p>使用迭代FGSM方法生成对抗样本。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (Union[numpy.ndarray, tuple]) - 良性输入样本，用于创建对抗样本。</p></li>
<li><p><strong>labels</strong> (Union[numpy.ndarray, tuple]) - 原始/目标标签。若每个输入有多个标签，将它包装在元组中。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><ul class="simple">
<li><p><strong>numpy.ndarray</strong> - 生成的对抗样本。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.MomentumIterativeMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">MomentumIterativeMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decay_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'inf'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#MomentumIterativeMethod"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.MomentumIterativeMethod" title="打开链接"></a></dt>
<dd><p>动量迭代法（Momentum Iterative Method）攻击，通过在迭代中积累损失函数的梯度方向上的速度矢量，加速梯度下降算法，如FGSM、FGM和LLCM，从而生成对抗样本。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1710.06081">Y. Dong, et al., “Boosting adversarial attacks with momentum,” arXiv:1710.06081, 2017</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 目标模型。</p></li>
<li><p><strong>eps</strong> (float) - 攻击产生的对抗性扰动占数据范围的比例。默认值：0.3。</p></li>
<li><p><strong>eps_iter</strong> (float) - 攻击产生的单步对抗扰动占数据范围的比例。默认值：0.1。</p></li>
<li><p><strong>bounds</strong> (tuple) - 数据的上下界，表示数据范围。
以(数据最小值，数据最大值)的形式出现。默认值：(0.0, 1.0)。</p></li>
<li><p><strong>is_targeted</strong> (bool) - 如果为True，则为目标攻击。如果为False，则为无目标攻击。默认值：False。</p></li>
<li><p><strong>nb_iter</strong> (int) - 迭代次数。默认值：5。</p></li>
<li><p><strong>decay_factor</strong> (float) - 迭代中的衰变因子。默认值：1.0。</p></li>
<li><p><strong>norm_level</strong> (Union[int, str, numpy.inf]) - 范数类型。
可取值：numpy.inf、1、2、’1’、’2’、’l1’、’l2’、’np.inf’、’inf’、’linf’。默认值：numpy.inf。</p></li>
<li><p><strong>loss_fn</strong> (Union[Loss, None]) - 用于优化的损失函数。如果为None，则输入网络已配备损失函数。默认值：None。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">MomentumIterativeMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">MomentumIterativeMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.MomentumIterativeMethod.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#MomentumIterativeMethod.generate"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.MomentumIterativeMethod.generate" title="打开链接"></a></dt>
<dd><p>根据输入数据和原始/目标标签生成对抗样本。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (Union[numpy.ndarray, tuple]) - 良性输入样本，用于创建对抗样本。</p></li>
<li><p><strong>labels</strong> (Union[numpy.ndarray, tuple]) - 原始/目标标签。若每个输入有多个标签，将它包装在元组中。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><ul class="simple">
<li><p><strong>numpy.ndarray</strong> - 生成的对抗样本。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.ProjectedGradientDescent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">ProjectedGradientDescent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'inf'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#ProjectedGradientDescent"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.ProjectedGradientDescent" title="打开链接"></a></dt>
<dd><p>投影梯度下降（Projected Gradient Descent）攻击是基本迭代法的变体，在这种方法中，每次迭代之后，扰动被投影在指定半径的p范数球上（除了剪切对抗样本的值，使其位于允许的数据范围内）。这是Madry等人提出的用于对抗性训练的攻击。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1706.06083">A. Madry, et al., “Towards deep learning models resistant to adversarial attacks,” in ICLR, 2018</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 目标模型。</p></li>
<li><p><strong>eps</strong> (float) - 攻击产生的对抗性扰动占数据范围的比例。默认值：0.3。</p></li>
<li><p><strong>eps_iter</strong> (float) - 攻击产生的单步对抗扰动占数据范围的比例。默认值：0.1。</p></li>
<li><p><strong>bounds</strong> (tuple) - 数据的上下界，表示数据范围。以(数据最小值，数据最大值)的形式出现。默认值：(0.0, 1.0)。</p></li>
<li><p><strong>is_targeted</strong> (bool) - 如果为True，则为目标攻击。如果为False，则为无目标攻击。默认值：False。</p></li>
<li><p><strong>nb_iter</strong> (int) - 迭代次数。默认值：5。</p></li>
<li><p><strong>norm_level</strong> (Union[int, str, numpy.inf]) - 范数类型。
可取值：numpy.inf、1、2、’1’、’2’、’l1’、’l2’、’np.inf’、’inf’、’linf’。默认值：’numpy.inf’。</p></li>
<li><p><strong>loss_fn</strong> (Union[Loss, None]) - 用于优化的损失函数。如果为None，则输入网络已配备损失函数。默认值：None。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">ProjectedGradientDescent</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">ProjectedGradientDescent</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.ProjectedGradientDescent.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#ProjectedGradientDescent.generate"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.ProjectedGradientDescent.generate" title="打开链接"></a></dt>
<dd><p>基于BIM方法迭代生成对抗样本。通过带有参数norm_level的投影方法归一化扰动。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (Union[numpy.ndarray, tuple]) - 良性输入样本，用于创建对抗样本。</p></li>
<li><p><strong>labels</strong> (Union[numpy.ndarray, tuple]) - 原始/目标标签。若每个输入有多个标签，将它包装在元组中。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><ul class="simple">
<li><p><strong>numpy.ndarray</strong> - 生成的对抗样本。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.DiverseInputIterativeMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">DiverseInputIterativeMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#DiverseInputIterativeMethod"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.DiverseInputIterativeMethod" title="打开链接"></a></dt>
<dd><p>多样性输入迭代法（Diverse Input Iterative Method）攻击遵循基本迭代法，并在每次迭代时对输入数据应用随机转换。对输入数据的这种转换可以提高对抗样本的可转移性。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1803.06978">Xie, Cihang and Zhang, et al., “Improving Transferability of Adversarial Examples With Input Diversity,” in CVPR, 2019</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 目标模型。</p></li>
<li><p><strong>eps</strong> (float) - 攻击产生的对抗性扰动占数据范围的比例。默认值：0.3。</p></li>
<li><p><strong>bounds</strong> (tuple) - 数据的上下界，表示数据范围。以(数据最小值，数据最大值)的形式出现。默认值：(0.0, 1.0)。</p></li>
<li><p><strong>is_targeted</strong> (bool) - 如果为True，则为目标攻击。如果为False，则为无目标攻击。默认值：False。</p></li>
<li><p><strong>prob</strong> (float) - 对输入样本的转换概率。默认值：0.5。</p></li>
<li><p><strong>loss_fn</strong> (Union[Loss, None]) - 用于优化的损失函数。如果为None，则输入网络已配备损失函数。默认值：None。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">DiverseInputIterativeMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">DiverseInputIterativeMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.MomentumDiverseInputIterativeMethod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">MomentumDiverseInputIterativeMethod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'l1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/iterative_gradient_method.html#MomentumDiverseInputIterativeMethod"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.MomentumDiverseInputIterativeMethod" title="打开链接"></a></dt>
<dd><p>动量多样性输入迭代法（Momentum Diverse Input Iterative Method）攻击是一种动量迭代法，在每次迭代时对输入数据应用随机变换。对输入数据的这种转换可以提高对抗样本的可转移性。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1803.06978">Xie, Cihang and Zhang, et al., “Improving Transferability of Adversarial Examples With Input Diversity,” in CVPR, 2019</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 目标模型。</p></li>
<li><p><strong>eps</strong> (float) - 攻击产生的对抗性扰动占数据范围的比例。默认值：0.3。</p></li>
<li><p><strong>bounds</strong> (tuple) - 数据的上下界，表示数据范围。以(数据最小值，数据最大值)的形式出现。默认值：(0.0, 1.0)。</p></li>
<li><p><strong>is_targeted</strong> (bool) - 如果为True，则为目标攻击。如果为False，则为无目标攻击。默认值：False。</p></li>
<li><p><strong>norm_level</strong> (Union[int, str, numpy.inf]) - 范数类型。
可取值：numpy.inf、1、2、’1’、’2’、’l1’、’l2’、’np.inf’、’inf’、’linf’。默认值：’l1’。</p></li>
<li><p><strong>prob</strong> (float) - 对输入样本的转换概率。默认值：0.5。</p></li>
<li><p><strong>loss_fn</strong> (Union[Loss, None]) - 用于优化的损失函数。如果为None，则输入网络已配备损失函数。默认值：None。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">MomentumDiverseInputIterativeMethod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">MomentumDiverseInputIterativeMethod</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_x</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.DeepFool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">DeepFool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'classification'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reserve_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overshoot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/deep_fool.html#DeepFool"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.DeepFool" title="打开链接"></a></dt>
<dd><p>DeepFool是一种无目标的迭代攻击，通过将良性样本移动到最近的分类边界并跨越边界来实现。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1511.04599">DeepFool: a simple and accurate method to fool deep neural networks</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 目标模型。</p></li>
<li><p><strong>num_classes</strong> (int) - 模型输出的标签数，应大于零。</p></li>
<li><p><strong>model_type</strong> (str) - 目标模型的类型。现在支持’classification’和’detection’。默认值：’classification’。</p></li>
<li><p><strong>reserve_ratio</strong> (Union[int, float]) - 攻击后可检测到的对象百分比，仅当model_type=’detection’时有效。保留比率应在(0, 1)的范围内。默认值：0.3。</p></li>
<li><p><strong>max_iters</strong> (int) - 最大迭代次数，应大于零。默认值：50。</p></li>
<li><p><strong>overshoot</strong> (float) - 过冲参数。默认值：0.02。</p></li>
<li><p><strong>norm_level</strong> (Union[int, str, numpy.inf]) - 矢量范数类型。可取值：numpy.inf或2。默认值：2。</p></li>
<li><p><strong>bounds</strong> (Union[tuple, list]) - 数据范围的上下界。以(数据最小值，数据最大值)的形式出现。默认值：None。</p></li>
<li><p><strong>sparse</strong> (bool) - 如果为True，则输入标签为稀疏编码。如果为False，则输入标签为one-hot编码。默认值：True。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">DeepFool</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="n">input_shape</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">DeepFool</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">max_iters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">norm_level</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>                  <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_me</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">input_np</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">true_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">input_me</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">advs</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_np</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.DeepFool.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/deep_fool.html#DeepFool.generate"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.DeepFool.generate" title="打开链接"></a></dt>
<dd><p>根据输入样本和原始标签生成对抗样本。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (Union[numpy.ndarray, tuple]) - 输入样本。</p>
<ul>
<li><p>如果 <cite>model_type</cite> =’classification’，则输入的格式应为numpy.ndarray。输入的格式可以是(input1, input2, …)。</p></li>
<li><p>如果 <cite>model_type</cite> =’detection’，则只能是一个数组。</p></li>
</ul>
</li>
<li><p><strong>labels</strong> (Union[numpy.ndarray, tuple]) - 目标标签或ground-truth标签。</p>
<ul>
<li><p>如果 <cite>model_type</cite> =’classification’，标签的格式应为numpy.ndarray。</p></li>
<li><p>如果 <cite>model_type</cite> =’detection’，标签的格式应为(gt_boxes, gt_labels)。</p></li>
</ul>
</li>
</ul>
</dd>
<dt>返回：</dt><dd><ul class="simple">
<li><p><strong>numpy.ndarray</strong> - 对抗样本。</p></li>
</ul>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>NotImplementedError</strong> - <cite>norm_level</cite> 不在[2, numpy.inf, ‘2’, ‘inf’]中。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.CarliniWagnerL2Attack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">CarliniWagnerL2Attack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">box_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">box_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bin_search_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confidence</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.005</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_const</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abort_early_check_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fast</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abort_early</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/carlini_wagner.html#CarliniWagnerL2Attack"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.CarliniWagnerL2Attack" title="打开链接"></a></dt>
<dd><p>使用L2范数的Carlini &amp; Wagner攻击通过分别利用两个损失生成对抗样本：“对抗损失”可使生成的示例实际上是对抗性的，“距离损失”可以控制对抗样本的质量。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1608.04644">Nicholas Carlini, David Wagner: “Towards Evaluating the Robustness of Neural Networks”</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 目标模型。</p></li>
<li><p><strong>num_classes</strong> (int) - 模型输出的标签数，应大于零。</p></li>
<li><p><strong>box_min</strong> (float) - 目标模型输入的下界。默认值：0。</p></li>
<li><p><strong>box_max</strong> (float) - 目标模型输入的上界。默认值：1.0。</p></li>
<li><p><strong>bin_search_steps</strong> (int) - 用于查找距离和置信度之间的最优trade-off常数的二分查找步数。默认值：5。</p></li>
<li><p><strong>max_iterations</strong> (int) - 最大迭代次数，应大于零。默认值：1000。</p></li>
<li><p><strong>confidence</strong> (float) - 对抗样本输出的置信度。默认值：0。</p></li>
<li><p><strong>learning_rate</strong> (float) - 攻击算法的学习率。默认值：5e-3。</p></li>
<li><p><strong>initial_const</strong> (float) - 用于平衡扰动范数和置信度差异的初始trade-off常数。默认值：1e-2。</p></li>
<li><p><strong>abort_early_check_ratio</strong> (float) - 检查所有迭代中所有比率的损失进度。默认值：5e-2。</p></li>
<li><p><strong>targeted</strong> (bool) - 如果为True，则为目标攻击。如果为False，则为无目标攻击。默认值：False。</p></li>
<li><p><strong>fast</strong> (bool) - 如果为True，则返回第一个找到的对抗样本。如果为False，则返回扰动较小的对抗样本。默认值：True。</p></li>
<li><p><strong>abort_early</strong> (bool) - 是否提前终止。</p>
<ul>
<li><p>如果为True，则当损失在一段时间内没有减少，Adam将被中止。</p></li>
<li><p>如果为False，Adam将继续工作，直到到达最大迭代。默认值：True。</p></li>
</ul>
</li>
<li><p><strong>sparse</strong> (bool) - 如果为True，则输入标签为稀疏编码。如果为False，则输入标签为one-hot编码。默认值：True。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">CarliniWagnerL2Attack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">input_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">CarliniWagnerL2Attack</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">targeted</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv_data</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_np</span><span class="p">,</span> <span class="n">label_np</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.CarliniWagnerL2Attack.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/carlini_wagner.html#CarliniWagnerL2Attack.generate"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.CarliniWagnerL2Attack.generate" title="打开链接"></a></dt>
<dd><p>根据输入数据和目标标签生成对抗样本。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (numpy.ndarray) - 输入样本。</p></li>
<li><p><strong>labels</strong> (numpy.ndarray) - 输入样本的真值标签或目标标签。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><ul class="simple">
<li><p><strong>numpy.ndarray</strong> - 生成的对抗样本。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.JSMAAttack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">JSMAAttack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">box_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">box_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">theta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_count</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">increase</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/jsma.html#JSMAAttack"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.JSMAAttack" title="打开链接"></a></dt>
<dd><p>基于Jacobian的显著图攻击（Jacobian-based Saliency Map Attack）是一种基于输入特征显著图的有目标的迭代攻击。它使用每个类标签相对于输入的每个组件的损失梯度。然后，使用显著图来选择产生最大误差的维度。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1511.07528">The limitations of deep learning in adversarial settings</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 目标模型。</p></li>
<li><p><strong>num_classes</strong> (int) - 模型输出的标签数，应大于零。</p></li>
<li><p><strong>box_min</strong> (float) - 目标模型输入的下界。默认值：0。</p></li>
<li><p><strong>box_max</strong> (float) - 目标模型输入的上界。默认值：1.0。</p></li>
<li><p><strong>theta</strong> (float) - 一个像素的变化率（相对于输入数据范围）。默认值：1.0。</p></li>
<li><p><strong>max_iteration</strong> (int) - 迭代的最大轮次。默认值：1000。</p></li>
<li><p><strong>max_count</strong> (int) - 每个像素的最大更改次数。默认值：3。</p></li>
<li><p><strong>increase</strong> (bool) - 如果为True，则增加扰动。如果为False，则减少扰动。默认值：True。</p></li>
<li><p><strong>sparse</strong> (bool) - 如果为True，则输入标签为稀疏编码。如果为False，则输入标签为one-hot编码。默认值：True。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">JSMAAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="n">input_shape</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">JSMAAttack</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">max_iteration</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">advs</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_np</span><span class="p">,</span> <span class="n">label_np</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.JSMAAttack.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/jsma.html#JSMAAttack.generate"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.JSMAAttack.generate" title="打开链接"></a></dt>
<dd><p>批量生成对抗样本。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (numpy.ndarray) - 输入样本。</p></li>
<li><p><strong>labels</strong> (numpy.ndarray) - 目标标签。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><ul class="simple">
<li><p><strong>numpy.ndarray</strong> - 对抗样本。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.LBFGS">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">LBFGS</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">150</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_iters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/lbfgs.html#LBFGS"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.LBFGS" title="打开链接"></a></dt>
<dd><p>L-BFGS-B攻击使用有限内存BFGS优化算法来最小化输入与对抗样本之间的距离。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1510.05328">Pedro Tabacof, Eduardo Valle. “Exploring the Space of Adversarial Images”</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>network</strong> (Cell) - 被攻击模型的网络。</p></li>
<li><p><strong>eps</strong> (float) - 攻击步长。默认值：1e-5。</p></li>
<li><p><strong>bounds</strong> (tuple) - 数据的上下界。默认值：(0.0, 1.0)</p></li>
<li><p><strong>is_targeted</strong> (bool) - 如果为True，则为目标攻击。如果为False，则为无目标攻击。默认值：True。</p></li>
<li><p><strong>nb_iter</strong> (int) - lbfgs优化器的迭代次数，应大于零。默认值：150。</p></li>
<li><p><strong>search_iters</strong> (int) - 步长的变更数，应大于零。默认值：30。</p></li>
<li><p><strong>loss_fn</strong> (Functions) - 替代模型的损失函数。默认值：None。</p></li>
<li><p><strong>sparse</strong> (bool) - 如果为True，则输入标签为稀疏编码。如果为False，则输入标签为one-hot编码。默认值：False。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">LBFGS</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">LBFGS</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">is_targeted</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">7</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)[</span><span class="n">target_np</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adv</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_np</span><span class="p">,</span> <span class="n">target_np</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.LBFGS.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/lbfgs.html#LBFGS.generate"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.LBFGS.generate" title="打开链接"></a></dt>
<dd><p>根据输入数据和目标标签生成对抗样本。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (numpy.ndarray) - 良性输入样本，用于创建对抗样本。</p></li>
<li><p><strong>labels</strong> (numpy.ndarray) - 原始/目标标签。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><ul class="simple">
<li><p><strong>numpy.ndarray</strong> - 生成的对抗样本。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.GeneticAttack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">GeneticAttack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'classification'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reserve_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pop_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mutation_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.005</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.15</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adaptive</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/genetic_attack.html#GeneticAttack"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.GeneticAttack" title="打开链接"></a></dt>
<dd><p>遗传攻击（Genetic Attack）为基于遗传算法的黑盒攻击，属于差分进化算法。</p>
<p>此攻击是由Moustafa Alzantot等人（2018）提出的。</p>
<p>参考文献： <a class="reference external" href="https://arxiv.org/abs/1805.11090">Moustafa Alzantot, Yash Sharma, Supriyo Chakraborty, “GeneticAttack: Practical Black-box Attacks with Gradient-FreeOptimization”</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>model</strong> (BlackModel) - 目标模型。</p></li>
<li><p><strong>model_type</strong> (str) - 目标模型的类型。现在支持’classification’和’detection’。默认值：’classification’。</p></li>
<li><p><strong>targeted</strong> (bool) - 如果为True，则为目标攻击。如果为False，则为无目标攻击。 <cite>model_type</cite> =’detection’仅支持无目标攻击，默认值：True。</p></li>
<li><p><strong>reserve_ratio</strong> (Union[int, float]) - 攻击后可检测到的对象百分比，仅当 <cite>model_type</cite> =’detection’时有效。保留比率应在(0, 1)的范围内。默认值：0.3。</p></li>
<li><p><strong>pop_size</strong> (int) - 粒子的数量，应大于零。默认值：6。</p></li>
<li><p><strong>mutation_rate</strong> (Union[int, float]) - 突变的概率，应在（0,1）的范围内。默认值：0.005。</p></li>
<li><p><strong>per_bounds</strong> (Union[int, float]) - 扰动允许的最大无穷范数距离。</p></li>
<li><p><strong>max_steps</strong> (int) - 每个对抗样本的最大迭代轮次。默认值：1000。</p></li>
<li><p><strong>step_size</strong> (Union[int, float]) - 攻击步长。默认值：0.2。</p></li>
<li><p><strong>temp</strong> (Union[int, float]) - 用于选择的采样温度。默认值：0.3。温度越大，个体选择概率之间的差异就越大。</p></li>
<li><p><strong>bounds</strong> (Union[tuple, list, None]) - 数据的上下界。以(数据最小值，数据最大值)的形式出现。默认值：(0, 1.0)。</p></li>
<li><p><strong>adaptive</strong> (bool) - 为True，则打开突变参数的动态缩放。如果为false，则打开静态突变参数。默认值：False。</p></li>
<li><p><strong>sparse</strong> (bool) - 如果为True，则输入标签为稀疏编码。如果为False，则输入标签为one-hot编码。默认值：True。</p></li>
<li><p><strong>c</strong> (Union[int, float]) - 扰动损失的权重。默认值：0.1。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">M</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Cell</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">GeneticAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">GeneticAttack</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)[</span><span class="n">y_test</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">adv_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.GeneticAttack.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/genetic_attack.html#GeneticAttack.generate"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.GeneticAttack.generate" title="打开链接"></a></dt>
<dd><p>根据输入数据和目标标签（或ground_truth标签）生成对抗样本。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (Union[numpy.ndarray, tuple]) - 输入样本。</p>
<ul>
<li><p>如果 <cite>model_type</cite> =’classification’，则输入的格式应为numpy.ndarray。输入的格式可以是(input1, input2, …)。</p></li>
<li><p>如果 <cite>model_type</cite> =’detection’，则只能是一个数组。</p></li>
</ul>
</li>
<li><p><strong>labels</strong> (Union[numpy.ndarray, tuple]) - 目标标签或ground-truth标签。</p>
<ul>
<li><p>如果 <cite>model_type</cite> =’classification’，标签的格式应为numpy.ndarray。</p></li>
<li><p>如果 <cite>model_type</cite> =’detection’，标签的格式应为(gt_boxes, gt_labels)。</p></li>
</ul>
</li>
</ul>
</dd>
<dt>返回：</dt><dd><ul class="simple">
<li><p><strong>numpy.ndarray</strong> - 每个攻击结果的布尔值。</p></li>
<li><p><strong>numpy.ndarray</strong> - 生成的对抗样本。</p></li>
<li><p><strong>numpy.ndarray</strong> - 每个样本的查询次数。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.HopSkipJumpAttack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">HopSkipJumpAttack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_num_evals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_evals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stepsize_search</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'geometric_progression'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'l2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/hop_skip_jump_attack.html#HopSkipJumpAttack"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.HopSkipJumpAttack" title="打开链接"></a></dt>
<dd><p>Chen、Jordan和Wainwright提出的HopSkipJumpAttack是一种基于决策的攻击。此攻击需要访问目标模型的输出标签。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1904.02144">Chen J, Michael I. Jordan, Martin J. Wainwright. HopSkipJumpAttack: A Query-Efficient Decision-Based Attack. 2019. arXiv:1904.02144</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>model</strong> (BlackModel) - 目标模型。</p></li>
<li><p><strong>init_num_evals</strong> (int) - 梯度估计的初始评估数。默认值：100。</p></li>
<li><p><strong>max_num_evals</strong> (int) - 梯度估计的最大评估数。默认值：1000。</p></li>
<li><p><strong>stepsize_search</strong> (str) - 表示要如何搜索步长；</p>
<ul>
<li><p>可取值为’geometric_progression’或’grid_search’。默认值：’geometric_progression’。</p></li>
</ul>
</li>
<li><p><strong>num_iterations</strong> (int) - 迭代次数。默认值：20。</p></li>
<li><p><strong>gamma</strong> (float) - 用于设置二进制搜索阈值theta。默认值：1.0。
对于l2攻击，二进制搜索阈值 <cite>theta</cite> 为 <span class="math notranslate nohighlight">\(gamma / d^{3/2}\)</span> 。对于linf攻击是 <span class="math notranslate nohighlight">\(gamma / d^2\)</span> 。默认值：1.0。</p></li>
<li><p><strong>constraint</strong> (str) - 要优化距离的范数。可取值为’l2’或’linf’。默认值：’l2’。</p></li>
<li><p><strong>batch_size</strong> (int) - 批次大小。默认值：32。</p></li>
<li><p><strong>clip_min</strong> (float, optional) - 最小图像组件值。默认值：0。</p></li>
<li><p><strong>clip_max</strong> (float, optional) - 最大图像组件值。默认值：1。</p></li>
<li><p><strong>sparse</strong> (bool) - 如果为True，则输入标签为稀疏编码。如果为False，则输入标签为one-hot编码。默认值：True。</p></li>
</ul>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>ValueError</strong> - <cite>stepsize_search</cite> 不在[‘geometric_progression’,’grid_search’]中。</p></li>
<li><p><strong>ValueError</strong> - <cite>constraint</cite> 不在[‘l2’, ‘linf’]中</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">HopSkipJumpAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">HopSkipJumpAttack</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">class_num</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">n</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">class_num</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">adv_x</span><span class="p">,</span> <span class="n">_</span><span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.HopSkipJumpAttack.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/hop_skip_jump_attack.html#HopSkipJumpAttack.generate"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.HopSkipJumpAttack.generate" title="打开链接"></a></dt>
<dd><p>在for循环中生成对抗图像。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (numpy.ndarray) - 原始图像。</p></li>
<li><p><strong>labels</strong> (numpy.ndarray) - 目标标签。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><ul class="simple">
<li><p><strong>numpy.ndarray</strong> - 每个攻击结果的布尔值。</p></li>
<li><p><strong>numpy.ndarray</strong> - 生成的对抗样本。</p></li>
<li><p><strong>numpy.ndarray</strong> - 每个样本的查询次数。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.HopSkipJumpAttack.set_target_images">
<span class="sig-name descname"><span class="pre">set_target_images</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_images</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/hop_skip_jump_attack.html#HopSkipJumpAttack.set_target_images"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.HopSkipJumpAttack.set_target_images" title="打开链接"></a></dt>
<dd><p>设置目标图像进行目标攻击。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>target_images</strong> (numpy.ndarray) - 目标图像。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.NES">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">NES</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scene</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_queries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples_per_draw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0005</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plateau_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plateau_drop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adv_thresh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zero_iters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">starting_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">starting_delta_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_only_sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conservative</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/natural_evolutionary_strategy.html#NES"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.NES" title="打开链接"></a></dt>
<dd><p>该类是自然进化策略（Natural Evolutionary Strategies，NES）攻击法的实现。NES使用自然进化策略来估计梯度，以提高查询效率。NES包括三个设置：Query-Limited设置、Partial-Information置和Label-Only设置。</p>
<ul class="simple">
<li><p>在’query-limit’设置中，攻击对目标模型的查询数量有限，但可以访问所有类的概率。</p></li>
<li><p>在’partial-info’设置中，攻击仅有权访问top-k类的概率。</p></li>
<li><p>在’label-only’设置中，攻击只能访问按其预测概率排序的k个推断标签列表。</p></li>
</ul>
<p>在Partial-Information设置和Label-Only设置中，NES会进行目标攻击，因此用户需要使用set_target_images方法来设置目标类的目标图像。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1804.08598">Andrew Ilyas, Logan Engstrom, Anish Athalye, and Jessy Lin. Black-box adversarial attacks with limited queries and information. In ICML, July 2018</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>model</strong> (BlackModel) - 要攻击的目标模型。</p></li>
<li><p><strong>scene</strong> (str) - 确定算法的场景，可选值为：’Label_Only’、’Partial_Info’、’Query_Limit’。</p></li>
<li><p><strong>max_queries</strong> (int) - 生成对抗样本的最大查询编号。默认值：10000。</p></li>
<li><p><strong>top_k</strong> (int) - 用于’Partial-Info’或’Label-Only’设置，表示攻击者可用的（Top-k）信息数量。对于Query-Limited设置，此输入应设置为-1。默认值：-1。</p></li>
<li><p><strong>num_class</strong> (int) - 数据集中的类数。默认值：10。</p></li>
<li><p><strong>batch_size</strong> (int) - 批次大小。默认值：128。</p></li>
<li><p><strong>epsilon</strong> (float) - 攻击中允许的最大扰动。默认值：0.3。</p></li>
<li><p><strong>samples_per_draw</strong> (int) - 对偶采样中绘制的样本数。默认值：128。</p></li>
<li><p><strong>momentum</strong> (float) - 动量。默认值：0.9。</p></li>
<li><p><strong>learning_rate</strong> (float) - 学习率。默认值：1e-3。</p></li>
<li><p><strong>max_lr</strong> (float) - 最大学习率。默认值：5e-2。</p></li>
<li><p><strong>min_lr</strong> (float) - 最小学习率。默认值：5e-4。</p></li>
<li><p><strong>sigma</strong> (float) - 随机噪声的步长。默认值：1e-3。</p></li>
<li><p><strong>plateau_length</strong> (int) - 退火算法中使用的平台长度。默认值：20。</p></li>
<li><p><strong>plateau_drop</strong> (float) - 退火算法中使用的平台Drop。默认值：2.0。</p></li>
<li><p><strong>adv_thresh</strong> (float) - 对抗阈值。默认值：0.25。</p></li>
<li><p><strong>zero_iters</strong> (int) - 用于代理分数的点数。默认值：10。</p></li>
<li><p><strong>starting_eps</strong> (float) - Label-Only设置中使用的启动epsilon。默认值：1.0。</p></li>
<li><p><strong>starting_delta_eps</strong> (float) - Label-Only设置中使用的delta epsilon。默认值：0.5。</p></li>
<li><p><strong>label_only_sigma</strong> (float) - Label-Only设置中使用的Sigma。默认值：1e-3。</p></li>
<li><p><strong>conservative</strong> (int) - 用于epsilon衰变的守恒，如果没有收敛，它将增加。默认值：2。</p></li>
<li><p><strong>sparse</strong> (bool) - 如果为True，则输入标签为稀疏编码。如果为False，则输入标签为one-hot编码。默认值：True。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">NES</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">SCENE</span> <span class="o">=</span> <span class="s1">&#39;Query_Limit&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TOP_K</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span><span class="o">=</span> <span class="n">NES</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">SCENE</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">TOP_K</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_class</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_image</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">orig_class</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_class</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span><span class="o">.</span><span class="n">set_target_images</span><span class="p">(</span><span class="n">target_image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tag</span><span class="p">,</span> <span class="n">adv</span><span class="p">,</span> <span class="n">queries</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">target_class</span><span class="p">]))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.NES.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/natural_evolutionary_strategy.html#NES.generate"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.NES.generate" title="打开链接"></a></dt>
<dd><p>根据输入数据和目标标签生成对抗样本。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (numpy.ndarray) - 良性输入样本。</p></li>
<li><p><strong>labels</strong> (numpy.ndarray) - 目标标签。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><ul class="simple">
<li><p><strong>numpy.ndarray</strong> - 每个攻击结果的布尔值。</p></li>
<li><p><strong>numpy.ndarray</strong> - 生成的对抗样本。</p></li>
<li><p><strong>numpy.ndarray</strong> - 每个样本的查询次数。</p></li>
</ul>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>ValueError</strong> - 在’Label-Only’或’Partial-Info’设置中 <cite>top_k</cite> 小于0。</p></li>
<li><p><strong>ValueError</strong> - 在’Label-Only’或’Partial-Info’设置中target_imgs为None。</p></li>
<li><p><strong>ValueError</strong> - <cite>scene</cite> 不在[‘Label_Only’, ‘Partial_Info’, ‘Query_Limit’]中</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.NES.set_target_images">
<span class="sig-name descname"><span class="pre">set_target_images</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_images</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/natural_evolutionary_strategy.html#NES.set_target_images"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.NES.set_target_images" title="打开链接"></a></dt>
<dd><p>在’Partial-Info’或’Label-Only’设置中设置目标攻击的目标样本。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>target_images</strong> (numpy.ndarray) - 目标攻击的目标样本。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.PointWiseAttack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">PointWiseAttack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_attack</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/pointwise_attack.html#PointWiseAttack"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.PointWiseAttack" title="打开链接"></a></dt>
<dd><p>点式攻击（Pointwise Attack）确保使用最小数量的更改像素为每个原始样本生成对抗样本。那些更改的像素将使用二进制搜索，以确保对抗样本和原始样本之间的距离尽可能接近。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1805.09190">L. Schott, J. Rauber, M. Bethge, W. Brendel: “Towards the first adversarially robust neural network model on MNIST”, ICLR (2019)</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>model</strong> (BlackModel) - 目标模型。</p></li>
<li><p><strong>max_iter</strong> (int) - 生成对抗图像的最大迭代轮数。默认值：1000。</p></li>
<li><p><strong>search_iter</strong> (int) - 二进制搜索的最大轮数。默认值：10。</p></li>
<li><p><strong>is_targeted</strong> (bool) - 如果为True，则为目标攻击。如果为False，则为无目标攻击。默认值：False。</p></li>
<li><p><strong>init_attack</strong> (Union[Attack, None]) - 用于查找起点的攻击。默认值：None。</p></li>
<li><p><strong>sparse</strong> (bool) - 如果为True，则输入标签为稀疏编码。如果为False，则输入标签为one-hot编码。默认值：True。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">PointWiseAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">PointWiseAttack</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">is_adv_list</span><span class="p">,</span> <span class="n">adv_list</span><span class="p">,</span> <span class="n">query_times_each_adv</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.PointWiseAttack.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/pointwise_attack.html#PointWiseAttack.generate"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.PointWiseAttack.generate" title="打开链接"></a></dt>
<dd><p>根据输入样本和目标标签生成对抗样本。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (numpy.ndarray) - 良性输入样本，用于创建对抗样本。</p></li>
<li><p><strong>labels</strong> (numpy.ndarray) - 对于有目标的攻击，标签是对抗性的目标标签。对于无目标攻击，标签是ground-truth标签。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><ul class="simple">
<li><p><strong>numpy.ndarray</strong> - 每个攻击结果的布尔值。</p></li>
<li><p><strong>numpy.ndarray</strong> - 生成的对抗样本。</p></li>
<li><p><strong>numpy.ndarray</strong> - 每个样本的查询次数。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.PSOAttack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">PSOAttack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'classification'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reserve_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pop_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/pso_attack.html#PSOAttack"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.PSOAttack" title="打开链接"></a></dt>
<dd><p>PSO攻击表示基于粒子群优化（Particle Swarm Optimization）算法的黑盒攻击，属于进化算法。
此攻击由Rayan Mosli等人（2019）提出。</p>
<p>参考文献：<a class="reference external" href="https://arxiv.org/abs/1909.07490">Rayan Mosli, Matthew Wright, Bo Yuan, Yin Pan, “They Might NOT Be Giants: Crafting Black-Box Adversarial Examples with Fewer Queries Using Particle Swarm Optimization”, arxiv: 1909.07490, 2019.</a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>model</strong> (BlackModel) - 目标模型。</p></li>
<li><p><strong>step_size</strong> (Union[int, float]) - 攻击步长。默认值：0.5。</p></li>
<li><p><strong>per_bounds</strong> (Union[int, float]) - 扰动的相对变化范围。默认值：0.6。</p></li>
<li><p><strong>c1</strong> (Union[int, float]) - 权重系数。默认值：2。</p></li>
<li><p><strong>c2</strong> (Union[int, float]) - 权重系数。默认值：2。</p></li>
<li><p><strong>c</strong> (Union[int, float]) - 扰动损失的权重。默认值：2。</p></li>
<li><p><strong>pop_size</strong> (int) - 粒子的数量，应大于零。默认值：6。</p></li>
<li><p><strong>t_max</strong> (int) - 每个对抗样本的最大迭代轮数，应大于零。默认值：1000。</p></li>
<li><p><strong>pm</strong> (Union[int, float]) - 突变的概率，应在（0,1）的范围内。默认值：0.5。</p></li>
<li><p><strong>bounds</strong> (Union[list, tuple, None]) - 数据的上下界。以(数据最小值，数据最大值)的形式出现。默认值：None。</p></li>
<li><p><strong>targeted</strong> (bool) - 如果为True，则为目标攻击。如果为False，则为无目标攻击。 <cite>model_type</cite> =’detection’仅支持无目标攻击，默认值：False。</p></li>
<li><p><strong>sparse</strong> (bool) - 如果为True，则输入标签为稀疏编码。如果为False，则输入标签为one-hot编码。默认值：True。</p></li>
<li><p><strong>model_type</strong> (str) - 目标模型的类型。现在支持’classification’和’detection’。默认值：’classification’。</p></li>
<li><p><strong>reserve_ratio</strong> (Union[int, float]) - 攻击后可检测到的对象百分比，用于 <cite>model_type</cite> =’detection’模式。保留比率应在(0, 1)的范围内。默认值：0.3。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Cell</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">PSOAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">PSOAttack</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">pm</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)[</span><span class="n">y_test</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">adv_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.PSOAttack.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/pso_attack.html#PSOAttack.generate"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.PSOAttack.generate" title="打开链接"></a></dt>
<dd><p>根据输入数据和目标标签（或ground_truth标签）生成对抗样本。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (Union[numpy.ndarray, tuple]) - 输入样本。</p>
<ul>
<li><p>如果 <cite>model_type</cite> =’classification’，则输入的格式应为numpy.ndarray。输入的格式可以是(input1, input2, …)。</p></li>
<li><p>如果 <cite>model_type</cite> =’detection’，则只能是一个数组。</p></li>
</ul>
</li>
<li><p><strong>labels</strong> (Union[numpy.ndarray, tuple]) - 目标标签或ground-truth标签。</p>
<ul>
<li><p>如果 <cite>model_type</cite> =’classification’，标签的格式应为numpy.ndarray。</p></li>
<li><p>如果 <cite>model_type</cite> =’detection’，标签的格式应为(gt_boxes, gt_labels)。</p></li>
</ul>
</li>
</ul>
</dd>
<dt>返回：</dt><dd><ul class="simple">
<li><p><strong>numpy.ndarray</strong> - 每个攻击结果的布尔值。</p></li>
<li><p><strong>numpy.ndarray</strong> - 生成的对抗样本。</p></li>
<li><p><strong>numpy.ndarray</strong> - 每个样本的查询次数。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.SaltAndPepperNoiseAttack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindarmour.adv_robustness.attacks.</span></span><span class="sig-name descname"><span class="pre">SaltAndPepperNoiseAttack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_targeted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/salt_and_pepper_attack.html#SaltAndPepperNoiseAttack"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.SaltAndPepperNoiseAttack" title="打开链接"></a></dt>
<dd><p>增加椒盐噪声的量以生成对抗样本。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>model</strong> (BlackModel) - 目标模型。</p></li>
<li><p><strong>bounds</strong> (tuple) - 数据的上下界。以(数据最小值，数据最大值)的形式出现。默认值：(0.0, 1.0)。</p></li>
<li><p><strong>max_iter</strong> (int) - 生成对抗样本的最大迭代。默认值：100。</p></li>
<li><p><strong>is_targeted</strong> (bool) - 如果为True，则为目标攻击。如果为False，则为无目标攻击。默认值：False。</p></li>
<li><p><strong>sparse</strong> (bool) - 如果为True，则输入标签为稀疏编码。如果为False，则输入标签为one-hot编码。默认值：True。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour</span> <span class="kn">import</span> <span class="n">BlackModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindarmour.adv_robustness.attacks</span> <span class="kn">import</span> <span class="n">SaltAndPepperNoiseAttack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ModelToBeAttacked</span><span class="p">(</span><span class="n">BlackModel</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">ModelToBeAttacked</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelToBeAttacked</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack</span> <span class="o">=</span> <span class="n">SaltAndPepperNoiseAttack</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">adv_list</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindarmour.adv_robustness.attacks.SaltAndPepperNoiseAttack.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindarmour/adv_robustness/attacks/black/salt_and_pepper_attack.html#SaltAndPepperNoiseAttack.generate"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindarmour.adv_robustness.attacks.SaltAndPepperNoiseAttack.generate" title="打开链接"></a></dt>
<dd><p>根据输入数据和目标标签生成对抗样本。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (numpy.ndarray) - 原始的、未受扰动的输入。</p></li>
<li><p><strong>labels</strong> (numpy.ndarray) - 目标标签。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><ul class="simple">
<li><p><strong>numpy.ndarray</strong> - 每个攻击结果的布尔值。</p></li>
<li><p><strong>numpy.ndarray</strong> - 生成的对抗样本。</p></li>
<li><p><strong>numpy.ndarray</strong> - 每个样本的查询次数。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindarmour.html" class="btn btn-neutral float-left" title="mindarmour" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="mindarmour.adv_robustness.defenses.html" class="btn btn-neutral float-right" title="mindarmour.adv_robustness.defenses" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2022, MindSpore.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
        <script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>