

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindformers.trainer.Trainer &mdash; MindSpore master documentation</title>
  

  
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="mindformers.trainer.TrainingArguments" href="mindformers.trainer.TrainingArguments.html" />
    <link rel="prev" title="mindformers.trainer.TokenClassificationTrainer" href="mindformers.trainer.TokenClassificationTrainer.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Installation Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindformers_install.html">Confirm system environment information</a></li>
</ul>
<p class="caption"><span class="caption-text">BERT Fine adjustment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindformers_bert_finetune.html">Use BERT tuning in Mindformer</a></li>
</ul>
<p class="caption"><span class="caption-text">API References</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../mindformers.html">mindformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindformers.core.html">mindformers.core</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindformers.dataset.html">mindformers.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindformers.models.html">mindformers.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindformers.modules.html">mindformers.modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindformers.pipeline.html">mindformers.pipeline</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../mindformers.trainer.html">mindformers.trainer</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.BaseArgsConfig.html">mindformers.trainer.BaseArgsConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.CheckpointConfig.html">mindformers.trainer.CheckpointConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.CloudConfig.html">mindformers.trainer.CloudConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.ConfigArguments.html">mindformers.trainer.ConfigArguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.ContextConfig.html">mindformers.trainer.ContextConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.ContrastiveLanguageImagePretrainTrainer.html">mindformers.trainer.ContrastiveLanguageImagePretrainTrainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.DataLoaderConfig.html">mindformers.trainer.DataLoaderConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.DatasetConfig.html">mindformers.trainer.DatasetConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.ImageClassificationTrainer.html">mindformers.trainer.ImageClassificationTrainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.LRConfig.html">mindformers.trainer.LRConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.MaskedImageModelingTrainer.html">mindformers.trainer.MaskedImageModelingTrainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.MaskedLanguageModelingTrainer.html">mindformers.trainer.MaskedLanguageModelingTrainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.OptimizerConfig.html">mindformers.trainer.OptimizerConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.ParallelContextConfig.html">mindformers.trainer.ParallelContextConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.QuestionAnsweringTrainer.html">mindformers.trainer.QuestionAnsweringTrainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.RunnerConfig.html">mindformers.trainer.RunnerConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.TextClassificationTrainer.html">mindformers.trainer.TextClassificationTrainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.TokenClassificationTrainer.html">mindformers.trainer.TokenClassificationTrainer</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">mindformers.trainer.Trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.TrainingArguments.html">mindformers.trainer.TrainingArguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.TranslationTrainer.html">mindformers.trainer.TranslationTrainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.WrapperConfig.html">mindformers.trainer.WrapperConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindformers.trainer.ZeroShotImageClassificationTrainer.html">mindformers.trainer.ZeroShotImageClassificationTrainer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mindformers.wrapper.html">mindformers.wrapper</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../mindformers.trainer.html">mindformers.trainer</a> &raquo;</li>
        
      <li>mindformers.trainer.Trainer</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/trainer/mindformers.trainer.Trainer.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="mindformers-trainer-trainer">
<h1>mindformers.trainer.Trainer<a class="headerlink" href="#mindformers-trainer-trainer" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="mindformers.trainer.Trainer">
<em class="property">class </em><code class="sig-prename descclassname">mindformers.trainer.</code><code class="sig-name descname">Trainer</code><span class="sig-paren">(</span><em class="sig-param">args: Optional[Union[str</em>, <em class="sig-param">dict</em>, <em class="sig-param">ConfigArguments</em>, <em class="sig-param">TrainingArguments]] = None</em>, <em class="sig-param">task: Optional[str] = &quot;general&quot;</em>, <em class="sig-param">model: Optional[Union[str</em>, <em class="sig-param">Cell</em>, <em class="sig-param">BaseModel]] = None</em>, <em class="sig-param">train_dataset: Optional[Union[str</em>, <em class="sig-param">BaseDataset]] = None</em>, <em class="sig-param">eval_dataset: Optional[Union[str</em>, <em class="sig-param">BaseDataset]] = None</em>, <em class="sig-param">tokenizer: Optional[BaseTokenizer] = None</em>, <em class="sig-param">image_processor: Optional[BaseImageProcessor] = None</em>, <em class="sig-param">audio_processor: Optional[BaseAudioProcessor] = None</em>, <em class="sig-param">optimizers: Optional[Optimizer] = None</em>, <em class="sig-param">wrapper: Optional[TrainOneStepCell] = None</em>, <em class="sig-param">callbacks: Optional[Union[Callback</em>, <em class="sig-param">List[Callback]]] = None</em>, <em class="sig-param">eval_callbacks: Optional[Union[Callback</em>, <em class="sig-param">List[Callback]]] = None</em>, <em class="sig-param">compute_metrics: Optional[Union[dict</em>, <em class="sig-param">set]] = None</em>, <em class="sig-param">save_config: bool = False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindformers/trainer/trainer.html#Trainer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindformers.trainer.Trainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Trainer package to trainevaluatepredict class.</p>
<p>The trainer interface is used to quickly start training, evaluation and predict
for integrated tasks. It also allows users to customize the model, optimizer, dataset,
tokenizer, processor, train_one_step, callback, and metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>, </em><a class="reference internal" href="mindformers.trainer.ConfigArguments.html#mindformers.trainer.ConfigArguments" title="mindformers.trainer.ConfigArguments"><em>ConfigArguments</em></a><em>, </em><a class="reference internal" href="mindformers.trainer.TrainingArguments.html#mindformers.trainer.TrainingArguments" title="mindformers.trainer.TrainingArguments"><em>TrainingArguments</em></a><em>]</em><em>]</em>) – The task config which is used to
configure the dataset, the hyper-parameter, optimizer, etc. It support yaml path or
config dict or ConfigArguments class.
Default: None.</p></li>
<li><p><strong>task</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The task name supported.
Please refer to <a class="reference external" href="https://gitee.com/mindspore/transformer#%E4%BB%8B%E7%BB%8D">https://gitee.com/mindspore/transformer#%E4%BB%8B%E7%BB%8D</a>.
Default: ‘general’.</p></li>
<li><p><strong>model</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>Cell</em><em>, </em><a class="reference internal" href="../models/mindformers.models.BaseModel.html#mindformers.models.BaseModel" title="mindformers.models.BaseModel"><em>BaseModel</em></a><em>]</em><em>]</em>) – The network for trainer.
It support model name supported or BaseModel or MindSpore Cell class.
Supported model name can refer to <a class="reference external" href="https://gitee.com/mindspore/transformer#%E4%BB%8B%E7%BB%8D">https://gitee.com/mindspore/transformer#%E4%BB%8B%E7%BB%8D</a>.
Default: None.</p></li>
<li><p><strong>train_dataset</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference internal" href="../dataset/mindformers.dataset.BaseDataset.html#mindformers.dataset.BaseDataset" title="mindformers.dataset.BaseDataset"><em>BaseDataset</em></a><em>]</em><em>]</em>) – The training dataset. It support real dataset path or
BaseDateset class or MindSpore Dataset class.
Default: None.</p></li>
<li><p><strong>eval_dataset</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference internal" href="../dataset/mindformers.dataset.BaseDataset.html#mindformers.dataset.BaseDataset" title="mindformers.dataset.BaseDataset"><em>BaseDataset</em></a><em>]</em><em>]</em>) – The evaluate dataset. It support real dataset path or
BaseDateset class or MindSpore Dataset class.
Default: None.</p></li>
<li><p><strong>tokenizer</strong> (<em>Optional</em><em>[</em><em>BaseTokenizer</em><em>]</em>) – The tokenizer for text preprocessing. It support BaseTokenizer class.
Default: None.</p></li>
<li><p><strong>image_processor</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../models/mindformers.models.BaseImageProcessor.html#mindformers.models.BaseImageProcessor" title="mindformers.models.BaseImageProcessor"><em>BaseImageProcessor</em></a><em>]</em>) – The processor for image preprocessing.
It support BaseImageProcessor class.
Default: None.</p></li>
<li><p><strong>audio_processor</strong> (<em>Optional</em><em>[</em><em>BaseAudioProcessor</em><em>]</em>) – The processor for audio preprocessing.
It support BaseAudioProcessor class.
Default: None.</p></li>
<li><p><strong>optimizers</strong> (<em>Optional</em><em>[</em><em>Optimizer</em><em>]</em>) – The training network’s optimizer. It support Optimizer class of MindSpore.
Default: None.</p></li>
<li><p><strong>wrapper</strong> (<em>Optional</em><em>[</em><em>TrainOneStepCell</em><em>]</em>) – Wraps the <cite>network</cite> with the <cite>optimizer</cite>.
It support TrainOneStepCell class of MindSpore.
Default: None.</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Callback</em><em>, </em><em>List</em><em>[</em><em>Callback</em><em>]</em><em>]</em><em>]</em>) – The training callback function.
It support CallBack or CallBack List of MindSpore.
Default: None.</p></li>
<li><p><strong>eval_callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Callback</em><em>, </em><em>List</em><em>[</em><em>Callback</em><em>]</em><em>]</em><em>]</em>) – The evaluate callback function.
It support CallBack or CallBack List of MindSpore.
Default: None.</p></li>
<li><p><strong>compute_metrics</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#set" title="(in Python v3.8)"><em>set</em></a><em>]</em><em>]</em>) – The metric of evaluating.
It support dict or set in MindSpore’s Metric class.
Default: None.</p></li>
<li><p><strong>save_config</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Save current the config of task. Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#KeyError" title="(in Python v3.8)"><strong>KeyError</strong></a> – If ‘task’ or ‘model’ not in supported trainer.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindformers</span> <span class="kn">import</span> <span class="n">Trainer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.dataset</span> <span class="kn">import</span> <span class="n">GeneratorDataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">MyDataLoader</span><span class="p">:</span>
<span class="gp">... </span>   <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>       <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">64</span><span class="p">)]</span>
<span class="gp">...</span>
<span class="gp">... </span>   <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
<span class="gp">... </span>       <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
<span class="gp">...</span>
<span class="gp">... </span>   <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>       <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#1) input task name and model name to init trainer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;image_classification&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">model</span><span class="o">=</span><span class="s1">&#39;vit_base_p16&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">train_dataset</span><span class="o">=</span><span class="s1">&#39;data/imagenet/train&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#2) input config to init trainer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindformers.trainer.config_args</span> <span class="kn">import</span> <span class="n">ConfigArguments</span><span class="p">,</span> <span class="n">OptimizerConfig</span><span class="p">,</span> \
<span class="gp">... </span>    <span class="n">RunnerConfig</span><span class="p">,</span> <span class="n">LRConfig</span><span class="p">,</span> <span class="n">WrapperConfig</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">AdamWeightDecay</span><span class="p">,</span> <span class="n">WarmUpLR</span><span class="p">,</span> \
<span class="gp">... </span>    <span class="n">DynamicLossScaleUpdateCell</span><span class="p">,</span> <span class="n">TrainOneStepWithLossScaleCell</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">LossMonitor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">runner_config</span> <span class="o">=</span> <span class="n">RunnerConfig</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="mi">224</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr_schedule_config</span> <span class="o">=</span> <span class="n">LRConfig</span><span class="p">(</span><span class="n">lr_type</span><span class="o">=</span><span class="s1">&#39;WarmUpLR&#39;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim_config</span> <span class="o">=</span> <span class="n">OptimizerConfig</span><span class="p">(</span><span class="n">optim_type</span><span class="o">=</span><span class="s1">&#39;Adam&#39;</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.009</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr_schedule_config</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale</span> <span class="o">=</span> <span class="n">DynamicLossScaleUpdateCell</span><span class="p">(</span><span class="n">loss_scale_value</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">12</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale_window</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">wrapper_config</span> <span class="o">=</span> <span class="n">WrapperConfig</span><span class="p">(</span><span class="n">wrapper_type</span><span class="o">=</span><span class="s1">&#39;TrainOneStepWithLossScaleCell&#39;</span><span class="p">,</span> <span class="n">scale_sense</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">MyDataLoader</span><span class="p">(),</span> <span class="n">column_names</span><span class="o">=</span><span class="s1">&#39;image&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config</span> <span class="o">=</span> <span class="n">ConfigArguments</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">2022</span><span class="p">,</span> <span class="n">runner_config</span><span class="o">=</span><span class="n">runner_config</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">optimizer</span><span class="o">=</span><span class="n">optim_config</span><span class="p">,</span> <span class="n">runner_wrapper</span><span class="o">=</span><span class="n">wrapper_config</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;image_classification&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">model</span><span class="o">=</span><span class="s1">&#39;vit_base_p16&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">args</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#3) input instance to init trainer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindformers.models</span> <span class="kn">import</span> <span class="n">ViTForImageClassification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vit_model_with_loss</span> <span class="o">=</span> <span class="n">ViTForImageClassification</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr_schedule</span> <span class="o">=</span> <span class="n">WarmUpLR</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamWeightDecay</span><span class="p">(</span><span class="n">beta1</span><span class="o">=</span><span class="mf">0.009</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr_schedule</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">params</span><span class="o">=</span><span class="n">vit_model_with_loss</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_cb</span> <span class="o">=</span> <span class="n">LossMonitor</span><span class="p">(</span><span class="n">per_print_times</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">loss_cb</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;image_classification&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">model</span><span class="o">=</span><span class="n">vit_model_with_loss</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">args</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindformers.trainer.Trainer.build_network">
<code class="sig-name descname">build_network</code><span class="sig-paren">(</span><em class="sig-param">input_checkpoint: Optional[Union[str</em>, <em class="sig-param">bool]] = None</em>, <em class="sig-param">is_train: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindformers/trainer/trainer.html#Trainer.build_network"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindformers.trainer.Trainer.build_network" title="Permalink to this definition">¶</a></dt>
<dd><p>build network for trainer.</p>
</dd></dl>

<dl class="method">
<dt id="mindformers.trainer.Trainer.evaluate">
<code class="sig-name descname">evaluate</code><span class="sig-paren">(</span><em class="sig-param">eval_checkpoint: Optional[Union[str</em>, <em class="sig-param">bool]] = False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindformers/trainer/trainer.html#Trainer.evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindformers.trainer.Trainer.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate task for Trainer.
This function is used to evaluate the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>eval_checkpoint</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>]</em><em>]</em>) – Used to evaluate the weight of the network.
It support real checkpoint path or valid model name of mindformers or bool value.
if it’s true, the last checkpoint file saved from the previous training round is automatically used.
Default: False.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – if eval_checkpoint is not bool or str type.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindformers</span> <span class="kn">import</span> <span class="n">Trainer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;image_classification&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">model</span><span class="o">=</span><span class="s1">&#39;vit_base_p16&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">eval_dataset</span><span class="o">=</span><span class="s1">&#39;data/imagenet/train&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 1) default evaluate task to test model.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 2) evaluate task to auto load the last checkpoint.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_checkpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 3) evaluate task according to checkpoint path.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_checkpoint</span><span class="o">=</span><span class="s1">&#39;./output/rank_0/checkpoint/mindformers.ckpt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindformers.trainer.Trainer.get_eval_dataloader">
<code class="sig-name descname">get_eval_dataloader</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindformers/trainer/trainer.html#Trainer.get_eval_dataloader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindformers.trainer.Trainer.get_eval_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>get eval dataloader of mindspore.</p>
</dd></dl>

<dl class="method">
<dt id="mindformers.trainer.Trainer.get_last_checkpoint">
<code class="sig-name descname">get_last_checkpoint</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindformers/trainer/trainer.html#Trainer.get_last_checkpoint"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindformers.trainer.Trainer.get_last_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>get last checkpoint for resuming or finetune.</p>
</dd></dl>

<dl class="method">
<dt id="mindformers.trainer.Trainer.get_train_dataloader">
<code class="sig-name descname">get_train_dataloader</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindformers/trainer/trainer.html#Trainer.get_train_dataloader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindformers.trainer.Trainer.get_train_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>get train dataloader of mindspore.</p>
</dd></dl>

<dl class="method">
<dt id="mindformers.trainer.Trainer.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">predict_checkpoint: Optional[Union[str</em>, <em class="sig-param">bool]] = None</em>, <em class="sig-param">input_data: Optional[Union[GeneratorDataset</em>, <em class="sig-param">Tensor</em>, <em class="sig-param">np.ndarray</em>, <em class="sig-param">Image</em>, <em class="sig-param">str</em>, <em class="sig-param">list]] = None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindformers/trainer/trainer.html#Trainer.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindformers.trainer.Trainer.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict task for Trainer.
This function is used to predict the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>predict_checkpoint</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>]</em><em>]</em>) – Used to predict the weight of the network.
It support real checkpoint path or valid model name of mindformers or bool value.
if it’s true, the last checkpoint file saved from the previous training round is automatically used.
Default: False.</p></li>
<li><p><strong>input_data</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Tensor</em><em>, </em><em>np.ndarray</em><em>, </em><em>Image</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>]</em><em>]</em>) – The predict data. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>predict result (dict).</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – if predict_checkpoint is not bool or str type.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – if input_data is not Tensor or np.ndarray or Image or str or list.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindformers</span> <span class="kn">import</span> <span class="n">Trainer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;image_classification&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">model</span><span class="o">=</span><span class="s1">&#39;vit_base_p16&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_data</span> <span class="o">=</span> <span class="s2">&quot;./sunflower.png&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 1) predict task to auto load the last checkpoint.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">predict_checkpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_data</span><span class="o">=</span><span class="n">input_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 2) predict task according to checkpoint path.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">predict_checkpoint</span><span class="o">=</span><span class="s1">&#39;./output/rank_0/checkpoint/mindformers.ckpt&#39;</span><span class="p">,</span>
<span class="gp">... </span>                     <span class="n">input_data</span><span class="o">=</span><span class="n">input_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 3) download and auto load the checkpoint on obs and predict.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">input_data</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindformers.trainer.Trainer.save_config_to_yaml">
<code class="sig-name descname">save_config_to_yaml</code><span class="sig-paren">(</span><em class="sig-param">config: dict = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindformers/trainer/trainer.html#Trainer.save_config_to_yaml"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindformers.trainer.Trainer.save_config_to_yaml" title="Permalink to this definition">¶</a></dt>
<dd><p>save now config file to yaml file.</p>
</dd></dl>

<dl class="method">
<dt id="mindformers.trainer.Trainer.set_moe_config">
<code class="sig-name descname">set_moe_config</code><span class="sig-paren">(</span><em class="sig-param">expert_num=1</em>, <em class="sig-param">capacity_factor=1.1</em>, <em class="sig-param">aux_loss_factor=0.05</em>, <em class="sig-param">num_experts_chosen=1</em>, <em class="sig-param">expert_group_size=None</em>, <em class="sig-param">group_wise_a2a=False</em>, <em class="sig-param">comp_comm_parallel=False</em>, <em class="sig-param">comp_comm_parallel_degree=2</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindformers/trainer/trainer.html#Trainer.set_moe_config"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindformers.trainer.Trainer.set_moe_config" title="Permalink to this definition">¶</a></dt>
<dd><p>The configuration of MoE (Mixture of Expert).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>expert_num</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of experts employed. Default: 1</p></li>
<li><p><strong>capacity_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The factor is used to indicate how much to expand expert capacity,
which is &gt;=1.0. Default: 1.1.</p></li>
<li><p><strong>aux_loss_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The factor is used to indicate how much the load balance loss (produced by the
router) to be added to the entire model loss, which is &lt; 1.0. Default: 0.05.</p></li>
<li><p><strong>num_experts_chosen</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of experts is chosen by each token and it should not be larger
than expert_num. Default: 1.</p></li>
<li><p><strong>expert_group_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of tokens in each data parallel group. Default: None. This parameter is
effective only when in AUTO_PARALLEL mode, and NOT SHARDING_PROPAGATION.</p></li>
<li><p><strong>group_wise_a2a</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to enable group-wise alltoall communication, which can reduce communication
time by converting part of inter communication into intra communication. Default: False. This parameter
is effective only when model parallel &gt; 1 and data_parallel equal to expert parallel.</p></li>
<li><p><strong>comp_comm_parallel</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to enable ffn compute and communication parallel, which can reduce pure
communicattion time by splitting and overlapping compute and communication. Default: False.</p></li>
<li><p><strong>comp_comm_parallel_degree</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The split number of compute and communication. The larger the numbers,
the more overlap there will be but will consume more memory. Default: 2. This parameter is effective
only when comp_comm_parallel enable.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindformers.trainer</span> <span class="kn">import</span> <span class="n">Trainer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;image_classification&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">model</span><span class="o">=</span><span class="s1">&#39;vit_base_p16&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">train_dataset</span><span class="o">=</span><span class="s1">&#39;data/imagenet/train&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">eval_dataset</span><span class="o">=</span><span class="s1">&#39;data/imagenet/train&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span><span class="o">.</span><span class="n">set_moe_config</span><span class="p">(</span><span class="n">expert_num</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">capacity_factor</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">aux_loss_factor</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindformers.trainer.Trainer.set_parallel_config">
<code class="sig-name descname">set_parallel_config</code><span class="sig-paren">(</span><em class="sig-param">data_parallel=1</em>, <em class="sig-param">model_parallel=1</em>, <em class="sig-param">expert_parallel=1</em>, <em class="sig-param">pipeline_stage=1</em>, <em class="sig-param">micro_batch_num=1</em>, <em class="sig-param">optimizer_shard=False</em>, <em class="sig-param">gradient_aggregation_group=4</em>, <em class="sig-param">vocab_emb_dp=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindformers/trainer/trainer.html#Trainer.set_parallel_config"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindformers.trainer.Trainer.set_parallel_config" title="Permalink to this definition">¶</a></dt>
<dd><p>set_parallel_config for the setting global data parallel, model parallel and fusion group.
The parallel configure setting for Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_parallel</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The data parallel way. The input data will be sliced into n parts for each layer
according to the data parallel way. Default: 1.</p></li>
<li><p><strong>model_parallel</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The model parallel way. The parameters of dense layers in MultiheadAttention and
FeedForward layer will be sliced according to the model parallel way. Default: 1.</p></li>
<li><p><strong>expert_parallel</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The expert parallel way. This is effective only when MoE (Mixture of Experts)
is applied. This value specifies the number of partitions to split the experts into.</p></li>
<li><p><strong>pipeline_stage</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of the pipeline stage. Should be a positive value. Default: 1.</p></li>
<li><p><strong>micro_batch_num</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The micro size of the batches for the pipeline training. Default: 1.</p></li>
<li><p><strong>optimizer_shard</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to enable optimizer shard. Default False.</p></li>
<li><p><strong>gradient_aggregation_group</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The fusion group size of the optimizer state sharding. Default: 4.</p></li>
<li><p><strong>vocab_emb_dp</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Shard embedding in model parallel or data parallel. Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindformers.trainer</span> <span class="kn">import</span> <span class="n">Trainer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;image_classification&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">model</span><span class="o">=</span><span class="s1">&#39;vit_base_p16&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">train_dataset</span><span class="o">=</span><span class="s1">&#39;data/imagenet/train&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">eval_dataset</span><span class="o">=</span><span class="s1">&#39;data/imagenet/train&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span><span class="o">.</span><span class="n">set_parallel_config</span><span class="p">(</span><span class="n">data_parallel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">model_parallel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindformers.trainer.Trainer.set_recompute_config">
<code class="sig-name descname">set_recompute_config</code><span class="sig-paren">(</span><em class="sig-param">recompute=False</em>, <em class="sig-param">parallel_optimizer_comm_recompute=False</em>, <em class="sig-param">mp_comm_recompute=True</em>, <em class="sig-param">recompute_slice_activation=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindformers/trainer/trainer.html#Trainer.set_recompute_config"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindformers.trainer.Trainer.set_recompute_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Set recompute config.
TransformerRecomputeConfig for the setting recompute attributes for encoder/decoder layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>recompute</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Enable recomputation of the transformer block or not. Default: False.</p></li>
<li><p><strong>parallel_optimizer_comm_recompute</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Specifies whether the communication operator allgathers
introduced by optimizer shard are recomputed in auto parallel or semi auto parallel mode.
Default: False.</p></li>
<li><p><strong>mp_comm_recompute</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Specifies whether the model parallel communication operators
in the cell are recomputed in auto parallel or semi auto parallel mode. Default: True.</p></li>
<li><p><strong>recompute_slice_activation</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Slice the cell output which would remains in memory. Default: False.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindformers.trainer</span> <span class="kn">import</span> <span class="n">Trainer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;image_classification&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">model</span><span class="o">=</span><span class="s1">&#39;vit_base_p16&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">train_dataset</span><span class="o">=</span><span class="s1">&#39;data/imagenet/train&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">eval_dataset</span><span class="o">=</span><span class="s1">&#39;data/imagenet/train&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span><span class="o">.</span><span class="n">set_recompute_config</span><span class="p">(</span><span class="n">recompute</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindformers.trainer.Trainer.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">resume_or_finetune_from_checkpoint: Optional[Union[str</em>, <em class="sig-param">bool]] = False</em>, <em class="sig-param">initial_epoch: int = 0</em>, <em class="sig-param">do_eval: bool = False</em>, <em class="sig-param">do_finetune: bool = False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindformers/trainer/trainer.html#Trainer.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindformers.trainer.Trainer.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Train task for Trainer.
This function is used to train or fine-tune the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>resume_or_finetune_from_checkpoint</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>]</em><em>]</em>) – Used to restore training or fine-tune the weight of the network.
It support real checkpoint path or valid model name of mindformers or bool value.
if it’s true, the last checkpoint file saved from the previous training round is automatically used.
if do_finetune is true, this checkpoint will be used to finetune the network.
Default: False.</p></li>
<li><p><strong>initial_epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Epoch at which to start train, it used for resuming a previous training run.
Default: 0.</p></li>
<li><p><strong>do_eval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether evaluations are performed during training. Default: False.</p></li>
<li><p><strong>do_finetune</strong> – Whether to finetune network. When it’s true, resume_or_finetune_from_checkpoint must be input.
Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – if resume_or_finetune_from_checkpoint is not bool or str type.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindformers</span> <span class="kn">import</span> <span class="n">Trainer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;image_classification&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">model</span><span class="o">=</span><span class="s1">&#39;vit_base_p16&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">train_dataset</span><span class="o">=</span><span class="s1">&#39;data/imagenet/train&#39;</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">eval_dataset</span><span class="o">=</span><span class="s1">&#39;data/imagenet/train&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 1) default train task to reproduce model.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 2) eval network when train task to reproduce model.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">do_eval</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 3) resume train task to auto load the last checkpoint, if training break after 10 epochs.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">resume_or_finetune_from_checkpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 4) resume train task according to checkpoint path, if training break after 10 epochs.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">resume_or_finetune_from_checkpoint</span><span class="o">=</span><span class="s1">&#39;./output/rank_0/checkpoint/mindformers.ckpt&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 5) finetune train task according to resume_or_finetune_from_checkpoint.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">task_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">resume_or_finetune_from_checkpoint</span><span class="o">=</span><span class="s1">&#39;mae_vit_base_p16&#39;</span><span class="p">,</span> <span class="n">do_finetune</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="mindformers.trainer.TrainingArguments.html" class="btn btn-neutral float-right" title="mindformers.trainer.TrainingArguments" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="mindformers.trainer.TokenClassificationTrainer.html" class="btn btn-neutral float-left" title="mindformers.trainer.TokenClassificationTrainer" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>