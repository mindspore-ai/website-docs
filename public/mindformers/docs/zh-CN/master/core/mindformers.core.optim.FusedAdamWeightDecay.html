

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindformers.core.optim.FusedAdamWeightDecay &mdash; MindSpore master 文档</title>
  

  
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/translations.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="mindformers.dataset" href="../mindformers.dataset.html" />
    <link rel="prev" title="mindformers.core.metric.SQuADMetric" href="mindformers.core.metric.SQuADMetric.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindformers_install.html">确认系统环境信息</a></li>
</ul>
<p class="caption"><span class="caption-text">BERT微调</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindformers_bert_finetune.html">使用mindformers中的BERT微调</a></li>
</ul>
<p class="caption"><span class="caption-text">API参考</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../mindformers.html">mindformers</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../mindformers.core.html">mindformers.core</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../mindformers.core.html#id1">mindformers.core</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindformers.core.html#mindformers-core-callback">mindformers.core.callback</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindformers.core.html#mindformers-core-loss">mindformers.core.loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindformers.core.html#mindformers-core-lr">mindformers.core.lr</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindformers.core.html#mindformers-core-metric">mindformers.core.metric</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../mindformers.core.html#mindformers-core-optim">mindformers.core.optim</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">mindformers.core.optim.FusedAdamWeightDecay</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mindformers.dataset.html">mindformers.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindformers.models.html">mindformers.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindformers.modules.html">mindformers.modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindformers.pipeline.html">mindformers.pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindformers.trainer.html">mindformers.trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindformers.wrapper.html">mindformers.wrapper</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../mindformers.core.html">mindformers.core</a> &raquo;</li>
        
      <li>mindformers.core.optim.FusedAdamWeightDecay</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/core/mindformers.core.optim.FusedAdamWeightDecay.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="mindformers-core-optim-fusedadamweightdecay">
<h1>mindformers.core.optim.FusedAdamWeightDecay<a class="headerlink" href="#mindformers-core-optim-fusedadamweightdecay" title="永久链接至标题">¶</a></h1>
<dl class="class">
<dt id="mindformers.core.optim.FusedAdamWeightDecay">
<em class="property">class </em><code class="sig-prename descclassname">mindformers.core.optim.</code><code class="sig-name descname">FusedAdamWeightDecay</code><span class="sig-paren">(</span><em class="sig-param">params</em>, <em class="sig-param">learning_rate=1e-3</em>, <em class="sig-param">beta1=0.9</em>, <em class="sig-param">beta2=0.999</em>, <em class="sig-param">eps=1e-6</em>, <em class="sig-param">weight_decay=0.0</em>, <em class="sig-param">offload=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindformers/core/optim/optim.html#FusedAdamWeightDecay"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindformers.core.optim.FusedAdamWeightDecay" title="打开链接">¶</a></dt>
<dd><p>Implements the Adam algorithm to fix the weight decay. It is a complete operator, not a combination of other ops.</p>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>When separating parameter groups, the weight decay in each group will be applied on the parameters if the
weight decay is positive. When not separating parameter groups, the <cite>weight_decay</cite> in the API will be applied
on the parameters without ‘beta’ or ‘gamma’ in their names if <cite>weight_decay</cite> is positive.</p>
<p>To improve parameter groups performance, the customized order of parameters can be supported.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(在 Python v3.8)"><em>list</em></a><em>[</em><em>Parameter</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(在 Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(在 Python v3.8)"><em>dict</em></a><em>]</em><em>]</em>) – <p>When the <cite>params</cite> is a list of <cite>Parameter</cite> which will be updated,
the element in <cite>params</cite> must be class <cite>Parameter</cite>. When the <cite>params</cite> is a list of <cite>dict</cite>, the “params”,
“lr”, “weight_decay” and “order_params” are the keys can be parsed.</p>
<ul>
<li><p>params: Required. The value must be a list of <cite>Parameter</cite>.</p></li>
<li><p>lr: Optional. If “lr” is in the keys, the value of the corresponding learning rate will be used.
If not, the <cite>learning_rate</cite> in the API will be used.</p></li>
<li><p>weight_decay: Optional. If “weight_decay” is in the keys, the value of the corresponding weight decay
will be used. If not, the <cite>weight_decay</cite> in the API will be used.</p></li>
<li><p>order_params: Optional. If “order_params” is in the keys, the value must be the order of parameters and
the order will be followed in the optimizer. There are no other keys in the <cite>dict</cite> and the parameters
which in the ‘order_params’ must be in one of group parameters.</p></li>
</ul>
</p></li>
<li><p><strong>learning_rate</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(在 Python v3.8)"><em>float</em></a><em>, </em><em>Tensor</em><em>, </em><em>Iterable</em><em>, </em><em>LearningRateSchedule</em><em>]</em>) – A value or a graph for the learning rate.
When the learning_rate is an Iterable or a Tensor in a 1D dimension, use the dynamic learning rate, then
the i-th step will take the i-th value as the learning rate. When the learning_rate is LearningRateSchedule,
use dynamic learning rate, the i-th learning rate will be calculated during the process of training
according to the formula of LearningRateSchedule. When the learning_rate is a float or a Tensor in a zero
dimension, use fixed learning rate. Other cases are not supported. The float learning rate must be
equal to or greater than 0. If the type of <cite>learning_rate</cite> is int, it will be converted to float.
Default: 1e-3.</p></li>
<li><p><strong>beta1</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(在 Python v3.8)"><em>float</em></a>) – The exponential decay rate for the 1st moment estimations. Default: 0.9.
Should be in range (0.0, 1.0).</p></li>
<li><p><strong>beta2</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(在 Python v3.8)"><em>float</em></a>) – The exponential decay rate for the 2nd moment estimations. Default: 0.999.
Should be in range (0.0, 1.0).</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(在 Python v3.8)"><em>float</em></a>) – Term added to the denominator to improve numerical stability. Default: 1e-6.
Should be greater than 0.</p></li>
<li><p><strong>weight_decay</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(在 Python v3.8)"><em>float</em></a>) – Weight decay (L2 penalty). It must be equal to or greater than 0. Default: 0.0.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>gradients</strong> (tuple[Tensor]) - The gradients of <cite>params</cite>, the shape is the same as <cite>params</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>tuple[bool], all elements are True.</p>
</dd>
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">样例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#1) All parameters use the same learning rate and weight decay</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">FusedAdamWeightDecay</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#2) Use parameter groups and set different values</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">conv_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;conv&#39;</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">no_conv_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;conv&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">group_params</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">conv_params</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">},</span>
<span class="gp">... </span>                <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">no_conv_params</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">},</span>
<span class="gp">... </span>                <span class="p">{</span><span class="s1">&#39;order_params&#39;</span><span class="p">:</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()}]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">FusedAdamWeightDecay</span><span class="p">(</span><span class="n">group_params</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The conv_params&#39;s parameters will use default learning rate of 0.1 and weight decay of 0.01.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The no_conv_params&#39;s parameters will use learning rate of 0.01 and default weight decay of 0.0.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The final parameters order in which the optimizer will be followed is the value of &#39;order_params&#39;.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindformers.core.optim.FusedAdamWeightDecay.clone_state">
<code class="sig-name descname">clone_state</code><span class="sig-paren">(</span><em class="sig-param">prefix</em>, <em class="sig-param">init</em>, <em class="sig-param">forced_dtype=mstype.float32</em>, <em class="sig-param">is_follow=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindformers/core/optim/optim.html#FusedAdamWeightDecay.clone_state"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindformers.core.optim.FusedAdamWeightDecay.clone_state" title="打开链接">¶</a></dt>
<dd><p>Clone the parameters
parameter_tuple: ParameterTuple. The parameters of the network
prefix: str. The prefix name of the parameters
init: str. The initialization method
forced_dtype: mstype. The except the dtype to be cloned. If is_follow is True, forced_dtype will be ignored.</p>
<blockquote>
<div><p>Default: mstype.float32</p>
</div></blockquote>
<dl class="simple">
<dt>is_follow: bool. Is clone the parameters with the original dtype. If is_follow is True, the forced_dtype</dt><dd><p>argument will be ignored. Default: False.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../mindformers.dataset.html" class="btn btn-neutral float-right" title="mindformers.dataset" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="mindformers.core.metric.SQuADMetric.html" class="btn btn-neutral float-left" title="mindformers.core.metric.SQuADMetric" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>