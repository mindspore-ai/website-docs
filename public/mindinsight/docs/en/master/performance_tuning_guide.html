<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Performance Tuning Guide &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Performance Debugging Cases" href="performance_optimization.html" />
    <link rel="prev" title="Accuracy Problem Locating and Optimization Guide" href="accuracy_optimization.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_install.html">MindSpore Insight Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="summary_record.html">Collecting Summary Record</a></li>
<li class="toctree-l1"><a class="reference internal" href="dashboard.html">Viewing Dashboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="lineage_and_scalars_comparison.html">Viewing Lineage and Scalars Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_profiling.html">Performance Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="debugger.html">Debugger</a></li>
<li class="toctree-l1"><a class="reference internal" href="landscape.html">Training Optimization Process Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_commands.html">MindSpore Insight Commands</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tuning Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="accuracy_problem_preliminary_location.html">Guide to Locating Accuracy Problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="accuracy_optimization.html">Accuracy Problem Locating and Optimization Guide</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Performance Tuning Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#single-device-performance-tuning">Single Device Performance Tuning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#analyse-entry">Analyse Entry</a></li>
<li class="toctree-l3"><a class="reference internal" href="#long-step-interval">Long Step Interval</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#feed-mode">Feed Mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="#graph-mode">Graph Mode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#long-forward-and-backward-propagation">Long Forward And Backward Propagation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#long-step-tail">Long Step Tail</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#cluster-performance-tuning">Cluster Performance Tuning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#analyse-entry-1">Analyse Entry</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-parallel">Data Parallel</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-parallel">Model Parallel</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pipeline-parallel">Pipeline Parallel</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="performance_optimization.html">Performance Debugging Cases</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight.debugger.html">mindinsight.debugger</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="training_visual_design.html">Overall Design of Training Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_visual_design.html">Computational Graph Visualization Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_visual_design.html">Tensor Visualization Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler_design.html">Performance Profiling Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Performance Tuning Guide</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/performance_tuning_guide.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="performance-tuning-guide">
<h1>Performance Tuning Guide<a class="headerlink" href="#performance-tuning-guide" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/mindinsight/docs/source_en/performance_tuning_guide.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.svg" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>MindSpore Insight provides a number of indicators from the perspective of single device and cluster to help users find performance bottlenecks. This paper focuses on the explanation of methodology. The purpose is to guide users how to use these indicators to find the performance bottlenecks in the network step by step.
For the meaning of each indicator, users can refer to the following tutorials:</p>
<p><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling_ascend.html">Performance Profiling（Ascend）</a></p>
<p><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling_gpu.html">Performance Profiling（GPU）</a></p>
<p><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling_of_cluster.html">Cluster Performance Profiling</a></p>
</section>
<section id="single-device-performance-tuning">
<h2>Single Device Performance Tuning<a class="headerlink" href="#single-device-performance-tuning" title="Permalink to this headline"></a></h2>
<p>This document starts with the performance tuning of single device and help users quickly find the performance bottlenecks.</p>
<section id="analyse-entry">
<h3>Analyse Entry<a class="headerlink" href="#analyse-entry" title="Permalink to this headline"></a></h3>
<p>MindSpore Insight provides Step Trace as the performance analyse entry. Step Trace has three phases, users can observe these phases and determine where performance bottlenecks are first.</p>
<ul class="simple">
<li><p>Step Interval: If this phase takes a long time, it indicates that the data processing speed cannot keep up with the training speed.</p></li>
<li><p>Forward and Backward Propagation: This phase is the duration for executing the forward and backward operations on the network, which handles the main calculation work of a step.</p></li>
<li><p>Step Tail：This phase is the duration for performing parameter aggregation and update operations in parallel training.</p></li>
</ul>
<p>As shown in Figure 1:</p>
<p><img alt="step_trace.png" src="_images/step_trace.png" /></p>
<p><em>Figure 1: Step Trace</em></p>
</section>
<section id="long-step-interval">
<h3>Long Step Interval<a class="headerlink" href="#long-step-interval" title="Permalink to this headline"></a></h3>
<p>Ideally, the training data should be loaded and enhanced on the Host side and sent to the Device side before forward propagation begins, otherwise the chip’s calculations are wasted as a result of waiting for the training data. Users need to go to the data preparation page to further confirm whether there is a performance issue with the data processing or data transmission.</p>
<p><img alt="minddata_profile.png" src="_images/minddata_profile.png" /></p>
<p><em>Figure 2: Data Preparation Page</em></p>
<section id="feed-mode">
<h4>Feed Mode<a class="headerlink" href="#feed-mode" title="Permalink to this headline"></a></h4>
<p>Step 1：Please jump to the <code class="docutils literal notranslate"><span class="pre">step</span> <span class="pre">interval</span></code> tab on the <code class="docutils literal notranslate"><span class="pre">data</span> <span class="pre">preparation</span> <span class="pre">details</span></code> page to see how the size curve changes in the host queue. If the size in this queue is 0 in most cases, indicating that the data processing is a performance bottleneck, please refer to step 2 and continue to locate which operation should be optimized, otherwise the process of obtaining data from the iterator of the dataset module and sending it to device is a performance bottleneck, and users can continue to confirm in the following two steps:</p>
<ul>
<li><p>Make sure if there is time-consuming custom logic in the script after getting data from the iterator of the dataset module, such as additional data cleaning, conversion, etc(MindSpore Insight can not obtain the time spent by the customized logic and the user is required to obtain the duration manually). If so, the user is required to optimize for this custom logic. Code is shown below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">iterator</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Cifar100Dataset</span><span class="p">()</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">iterator</span><span class="p">:</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">item</span> <span class="o">=</span> <span class="n">transform_data</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="c1"># customized function</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">transform_time</span> <span class="o">=</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span>

    <span class="n">network</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="c1">#  feed data to the network</span>
</pre></div>
</div>
</li>
<li><p>If there is no time-consuming customized logic in the script, it indicates that sending data from host to device is time-consuming, please feedback to the <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore Community</a> .</p></li>
</ul>
<p>Step 2：Please jump to the <code class="docutils literal notranslate"><span class="pre">data</span> <span class="pre">processing</span></code> tab on the <code class="docutils literal notranslate"><span class="pre">data</span> <span class="pre">preparation</span> <span class="pre">details</span></code> page, observe the inter-operator queue, and determine which operation has a performance bottleneck in the data processing. Principles of judgment can be found in the <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling_ascend.html#data-preparation-performance-analysis">Performance Profiling</a> page. Users can reference <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/dataset/optimize.html">Optimizing the Data Processing</a> and try to optimize the data processing performance.</p>
</section>
<section id="graph-mode">
<h4>Graph Mode<a class="headerlink" href="#graph-mode" title="Permalink to this headline"></a></h4>
<p>Step 1：Please jump to the <code class="docutils literal notranslate"><span class="pre">step</span> <span class="pre">interval</span></code> tab on the <code class="docutils literal notranslate"><span class="pre">data</span> <span class="pre">preparation</span> <span class="pre">details</span></code> page to see how the size curve changes in the data queue.</p>
<ul class="simple">
<li><p>If size is not always 0 in the data queue, it indicates that the data preparation process is not the bottleneck. Based on daily tuning experience, the high probability of this is that GetNext operators are time-consuming, and users can go to the <code class="docutils literal notranslate"><span class="pre">Operator</span> <span class="pre">Time</span> <span class="pre">Consumption</span> <span class="pre">Rank</span></code> page to view GetNext operators in the AICPU tab. If it is confirmed that the GetNext operators take a long time, please feedback to the <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore Community</a> .</p></li>
<li><p>If there is 0 in the data queue, go to Step 2.</p></li>
</ul>
<p>Step 2: See how the size curve changes in the host queue. If none of the size in the queue is 0, it indicates that the process by which training data is sent from host to device is a performance bottleneck, please feedback to the <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore Community</a>. Otherwise it indicates that the data processing process is the performance bottleneck, please refer to Step 3 to continue to locate which operation of data processing has performance problems.</p>
<p>Step 3：Please jump to the <code class="docutils literal notranslate"><span class="pre">data</span> <span class="pre">processing</span></code> tab on the <code class="docutils literal notranslate"><span class="pre">data</span> <span class="pre">preparation</span> <span class="pre">details</span></code> page, observe the inter-operator queue, and determine which operation has a performance bottleneck in the data processing. Principles of judgment can be found in the <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling_ascend.html#data-preparation-performance-analysis">Performance Profiling</a> page. Users can reference <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/dataset/optimize.html">Optimizing the Data Processing</a> and try to optimize the data processing performance.</p>
</section>
</section>
<section id="long-forward-and-backward-propagation">
<h3>Long Forward And Backward Propagation<a class="headerlink" href="#long-forward-and-backward-propagation" title="Permalink to this headline"></a></h3>
<p>This phase mainly refers to the execution time of forward and reverse operators in the network. If this phase takes a long time, it is recommended that users analyze it in the following steps:</p>
<p>Step 1: Jump to the <code class="docutils literal notranslate"><span class="pre">Operator</span> <span class="pre">Time</span> <span class="pre">Consumption</span> <span class="pre">Rank</span></code> tab to see how much time each operator takes during training, focusing on the top-ranked operators. The main ideas to solve the long operator time consumption are as follows:</p>
<ul class="simple">
<li><p>Modify the float32 type to float16 without affecting precision;</p></li>
<li><p>If there are too many conversion operators (TransData, Cast-class operators) and the time consumption is obvious, the operators are manually added, analyze their necessity and remove the redundant Cast and TransData operators if they have no impact on the accuracy. If MindSpore automatically generates too many conversion operators, it may be that the MindSpore framework is not sufficiently optimized for some special cases. please go to <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore Community</a> for feedback.</p></li>
<li><p>If the time consumption of an operator is unreasonable, please give feedback to the <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore Community</a>.</p></li>
</ul>
<p>Step 2: Users can view the timeline page to observe information such as the start time of the operator, the time it takes, the execution sequence, and the concurrency between operators. Users can focus on the following two points:</p>
<ul class="simple">
<li><p>Whether the GetNext operator has parallel execution with the AICore operator. Normally, the GetNext operator is executed before the start of the corresponding iteration to ensure that the training data is available in advance. If you find that the GetNext operator is not executed earlier through the timeline page, it means that there is a problem with the framework scheduling of GetNext, please go to <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore Community</a> for feedback.</p></li>
<li><p>Whether there is free time between AICore operators. Usually the free time between AI CORE operators is caused by AI CPU operators and communication operators being executed, which is normal (of course, it also needs to be analyzed in conjunction with the user’s specific network). If users encounter a situation where no type of operator is executed during a certain period of time, which means that the framework has problems with the scheduling of AICore operators, please feedback to the <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore Community</a>.</p></li>
</ul>
</section>
<section id="long-step-tail">
<h3>Long Step Tail<a class="headerlink" href="#long-step-tail" title="Permalink to this headline"></a></h3>
<p>This phase mainly contains parameter update in the single device scenario. From the actual tuning experience, this phase is very short time-consuming and will not be the performance bottleneck in the single device. If user encounter a long step tail in single device scenario, please feedback to the <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore Community</a> .</p>
</section>
</section>
<section id="cluster-performance-tuning">
<h2>Cluster Performance Tuning<a class="headerlink" href="#cluster-performance-tuning" title="Permalink to this headline"></a></h2>
<p>The main factors affecting cluster performance are the following:</p>
<ul class="simple">
<li><p>Slow node: Because the collective communication operator is executed synchronously, if there are slow nodes in the cluster, the performance of the cluster will be delayed by the barrel effect.</p></li>
<li><p>Slow link: If there is a problem with some links in the cluster, resulting in less bandwidth, it can drag down the performance of the cluster.</p></li>
<li><p>Unreasonable division: Mainly for the model parallel and pipeline model.</p>
<ul>
<li><p>For the model parallel, If the two operator sharding strategies before and after are not consistent will lead to automatic insertion of <a class="reference external" href="https://www.mindspore.cn/docs/en/master/design/distributed_training_design.html">reschedule</a> , which will increase the communication operator to complete the data transformation, and excessive communication is the main factor affecting the cluster performance. Ideally, the shorter the communication time, the better the communication performance. When the pure communication time (only the communication operator execution time period, parallel execution time period of the communication operator and the computation operator can not be concerned because the communication time is hidden in the computation operator execution time) occupies a large proportion of the total time, the user needs to consider optimizing the operator sharding strategy to avoid the introduction of rescheduling, which makes the communication time increase.</p></li>
<li><p>For pipeline parallel, since different layers will be sliced into different stages, if the stage slicing is not reasonable, the amount of computation on each stage will be unbalanced, which will eventually lead to extra data waiting time between stages due to the lack of synchronization (as shown by the long time consumption of the Receive communication operator, which is used to receive data sent by other stages), so it is necessary to adjust the amount of computation on each stage to be as close to the average as possible.</p></li>
</ul>
</li>
</ul>
<p>For the main factors that affect cluster performance, MindSpore Insight provides different indicators for data parallel, model parallel, pipeline parallel, and hybrid parallel to help users quickly identify performance bottlenecks in the cluster.</p>
<section id="analyse-entry-1">
<h3>Analyse Entry<a class="headerlink" href="#analyse-entry-1" title="Permalink to this headline"></a></h3>
<p>The cluster step trace page, as analyse entry for cluster performance tuning, provides different performance indicators for different parallel policies to help users confirm whether there are factors in the cluster that are mentioned above that affect cluster performance. Users can view corresponding parallel policies below depending on their scenario. Note that for hybrid parallel, if there is pipeline parallel, please see the pipeline parallel section below. Otherwise, if there is model parallel, please see the model parallel section.</p>
<p>For clusters with fewer devices, users can directly observe the histogram to confirm the time-consuming phases of each device. For clusters with more devices, users can sort the different indicator columns to see the time-consuming distribution of all devices.</p>
</section>
<section id="data-parallel">
<h3>Data Parallel<a class="headerlink" href="#data-parallel" title="Permalink to this headline"></a></h3>
<p>For data parallel, the cluster step trace page provides step interval, forward and backward propagation, and step tail of all devices in the cluster.</p>
<p>Step 1：Observe the step interval in the cluster step trace page</p>
<ul class="simple">
<li><p>Users should make sure if the step interval of one device is much longer than others first. If yes, it indicates that this device is a slow node and has a performance problem in the data preparation phase and users can jump to the corresponding single device page. Refer to the <a class="reference internal" href="#long-step-interval"><span class="std std-doc">Long Step Interval</span></a> section of <code class="docutils literal notranslate"><span class="pre">Single</span> <span class="pre">Device</span> <span class="pre">Performance</span> <span class="pre">Tuning</span></code> to continue to locate the reasons why this phase takes a long time.</p></li>
<li><p>If the step interval time of all devices are very long, it means that there is room for optimization in this phase. Users can jump to the single device page of any device and referring to the <a class="reference internal" href="#long-step-interval"><span class="std std-doc">Long Step Interval</span></a> section of <code class="docutils literal notranslate"><span class="pre">Single</span> <span class="pre">Device</span> <span class="pre">Performance</span> <span class="pre">Tuning</span></code> to continue to locate the reasons why this phase takes a long time.</p></li>
</ul>
<p>Step 2：Observe the forward and backward propagation in the cluster step trace page</p>
<ul class="simple">
<li><p>Users should make sure if the forward and backward propagation of one device is much longer than others first. If yes, it indicates that this device is a slow node and has a performance problem in the data preparation phase and users can jump to the corresponding single device page. Refer to the <a class="reference internal" href="#long-forward-and-backward-propagation"><span class="std std-doc">Long Forward And Backward Propagation</span></a> section of <code class="docutils literal notranslate"><span class="pre">Single</span> <span class="pre">Device</span> <span class="pre">Performance</span> <span class="pre">Tuning</span></code> to continue to locate the reasons why this phase takes a long time.</p></li>
<li><p>If the forward and backward propagation time of all devices are very long, it means that there is room for optimization in this phase. Users can jump to the single device page of any device and referring to the <a class="reference internal" href="#long-forward-and-backward-propagation"><span class="std std-doc">Long Forward And Backward Propagation</span></a> section of <code class="docutils literal notranslate"><span class="pre">Single</span> <span class="pre">Device</span> <span class="pre">Performance</span> <span class="pre">Tuning</span></code> to continue to locate the reasons why this phase takes a long time.</p></li>
</ul>
<p>Step 3: Observe the step tail in the cluster step trace page</p>
<ul class="simple">
<li><p>Users should make sure if the step tail of one device is much longer than others first. If it is, it usually caused by slow node in the cluster. Users can refer to Step 1 and Step 2 to find the slow node.</p></li>
<li><p>If the step tail of all devices are essentially the same, and the phase is time-consuming, it is usually due to the long time taken by the AllReduce collective communication operators. Users can try to modify the all_reduce_fusion_config parameter to optimize the performance, and change <a class="reference external" href="https://mindspore.cn/tutorials/experts/en/master/parallel/overview.html">AllReduce Fusion Sharding Strategy</a> to reduce the time spent in this phase.</p></li>
</ul>
</section>
<section id="model-parallel">
<h3>Model Parallel<a class="headerlink" href="#model-parallel" title="Permalink to this headline"></a></h3>
<p>For model parallel, the cluster step trace page provides step interval, computation time, and communication time of all devices in the cluster.</p>
<p>Step 1: Observe the step interval in the cluster step trace page</p>
<p>Please refer to step 1 of <a class="reference internal" href="#data-parallel"><span class="std std-doc">Data Parallel</span></a>.</p>
<p>Step 2: Observe the computation time in the cluster step trace page</p>
<p>In the forward and backward propagation phase of model parallel, the calculation operators and the communication operators are alternately executed, and the slow nodes can not be found. So MindSpore Insight provides computation time to help users find slow node from cluster.
Please refer to step 2 of <a class="reference internal" href="#data-parallel"><span class="std std-doc">Data Parallel</span></a>.</p>
<p>Step 3: Observe the pure communication time in the cluster step trace page</p>
<p>On the premise of confirming that there is no slow node through step 1 and step 2, the pure communication time of each card in the cluster should be basically the same. If this phase takes a short time, it means that the communication time caused by re-distribution of operators is very short, and users do not need to consider optimizing the parallel strategy. Otherwise, users need to focus on analyzing whether the parallel strategy can be optimized.
Users need to have a certain understanding of the principle of model parallelism before continue to analyse. Please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/parallel/overview.html">Distributed Training</a> for the basic principles. The following steps are only to assist users in rationality analysis. Whether the parallel strategy has room for optimization and how to optimize it need users to make a judgment after specific analysis of their respective networks.</p>
<ul>
<li><p>If this stage takes a long time, the user can choose any one of the devices and observe its timeline. In the timeline, MindSpore Insight marks the pure communication time, refer to ‘Pure Communication Op’ below.</p>
<p><img alt="timeline.png" src="_images/timeline.png" /></p>
<p><em>Figure 3: Pure communication Op</em></p>
<p>In the process of analysis, users only need to pay attention to the pure communication time period, focusing on whether the insertion of the communication operator is reasonable, whether the time consumption of the communication operator is normal and so on.</p>
</li>
<li><p>If users find that a communication operator should not be inserted in theory but inserted actually, it indicates that the insert logic of MindSpore may be wrong, please feedback to the <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore Community</a> .</p></li>
<li><p>If users find that communication operator will not be inserted if users divide another operator, please change the parallel strategy and divide another operator to decrease communication operator.</p></li>
<li><p>If users find that one communication operator must be inserted but takes a very long time, please go to step 4 to continue analyse.</p></li>
</ul>
<p>Step 4：Users can go to the <code class="docutils literal notranslate"><span class="pre">cluster</span> <span class="pre">communication</span></code> page to check each time-consuming stage of the communication operator, as shown in the figure below.</p>
<p><img alt="operator_performance.png" src="_images/operator_performance.png" /></p>
<p><em>Figure 4: Communication Operator Stage</em></p>
<ul>
<li><p>If the communication duration is long, it means that the communication operator is communicating most of the time. Users can go to the <code class="docutils literal notranslate"><span class="pre">Link</span> <span class="pre">Information</span> <span class="pre">page</span></code> to observe the bandwidth to confirm whether there is a slow link that causes the communication time to be long. If there is a problem with the bandwidth of a link, users need to check the link and repair the link problem.</p>
<p><img alt="rank_id_link_info.png" src="_images/rank_id_link_info.png" /></p>
<p><em>Figure 5: Link Information</em></p>
</li>
<li><p>If the waiting duration is long, it means that there are slow nodes in the cluster, and users can confirm and repair the slow nodes through steps 1 and 2.</p></li>
<li><p>In addition to the communication and waiting time, there will be a Reduce time for AllReduce communication operators. If the time period is long, it means that the operator performing Reduce is abnormal. Please feedback to the <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore Community</a>.</p></li>
</ul>
</section>
<section id="pipeline-parallel">
<h3>Pipeline Parallel<a class="headerlink" href="#pipeline-parallel" title="Permalink to this headline"></a></h3>
<p>For pipeline parallel, the cluster step trace page provides step interval, stage time, computation time, communication time, communication time(including the receive operator only) and communication time(not including the receive operator) of all devices in the cluster.</p>
<p>Step 1: Observe the step interval in the cluster step trace page</p>
<p>Please refer to step 1 of <a class="reference internal" href="#data-parallel"><span class="std std-doc">Data Parallel</span></a>.</p>
<p>Step 2: Observe the stage time in the cluster step trace page</p>
<p>Ideally, the time consumed by each stage should be basically the same, otherwise a fast stage waiting for slow stage to send data can drag down the performance of the cluster. There are several main reasons for the inconsistency of each stage, which can be confirmed by the user one by one.</p>
<ul class="simple">
<li><p>Unbalanced FLOPs：Users can jump to the <code class="docutils literal notranslate"><span class="pre">FLOPs</span> <span class="pre">Heatmap</span> <span class="pre">Analyse</span></code> tab on <code class="docutils literal notranslate"><span class="pre">Resource</span> <span class="pre">Utilization</span></code> page to check the distribution of FLOPs. If there is a big difference in the FLOPs of each stage, users need to readjust the operators divided into each stage to try to ensure that the FLOPs of each stage is balanced.</p></li>
<li><p>Slow node：Users can screen the stage that takes a long time and sort the computation time to see if there is any obvious abnormality in this indicator of a device in the stage. If yes, the user can jump to the single card page, and refer to the subsection <a class="reference internal" href="#long-forward-and-backward-propagation"><span class="std std-doc">Long Forward And Backward Propagation</span></a> of “Single Device Performance Tuning” to continue positioning.</p></li>
<li><p>Due to operator division in a stage, more communication operators are inserted, which lengthens the whole time of the stage. Users can screen the stage that takes a long time and observe the proportion of pure communication time (not including the receive operator) in the stage to the total iteration time. If the proportion is high, please refer to step 3 of <a class="reference internal" href="#model-parallel"><span class="std std-doc">Model Parallel</span></a> to analyze whether the operator division can be optimized.</p></li>
</ul>
<p>Step 3: Observe the communication time (including the receive operator only) in the cluster step trace page</p>
<p>This indicator reflects the time that the current stage is waiting to receive data from other stages. Theoretically, when the time consumed by each stage is basically the same, there will be no long time-consuming phenomenon in this period. Users can also go to the <code class="docutils literal notranslate"><span class="pre">Timeline</span></code> page to check the execution sequence of the Receive operator, and analyze the rationality of the time consumption of the operator in combination with their respective networks if the Receive communication operator takes a long time.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="accuracy_optimization.html" class="btn btn-neutral float-left" title="Accuracy Problem Locating and Optimization Guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="performance_optimization.html" class="btn btn-neutral float-right" title="Performance Debugging Cases" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>