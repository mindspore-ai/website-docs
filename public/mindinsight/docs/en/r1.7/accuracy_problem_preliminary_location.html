<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Guide to Locating Accuracy Problems &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Accuracy Problem Locating and Optimization Guide" href="accuracy_optimization.html" />
    <link rel="prev" title="MindInsight Commands" href="mindinsight_commands.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_install.html">MindInsight Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="summary_record.html">Collecting Summary Record</a></li>
<li class="toctree-l1"><a class="reference internal" href="dashboard.html">Viewing Dashboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="lineage_and_scalars_comparison.html">Viewing Lineage and Scalars Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyper_parameters_auto_tuning.html">Use Mindoptimizer to Tune Hyperparameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrate_3rd_scripts_mindconverter.html">Migrating From Third Party Frameworks With MindConverter</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_profiling.html">Performance Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="debugger.html">Debugger</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_explanation.html">Explain Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="landscape.html">Training Optimization Process Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_commands.html">MindInsight Commands</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tuning Guide</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Guide to Locating Accuracy Problems</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#checklist-based-locating-method">Checklist-based Locating Method</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#instructions-for-using-the-checklist">Instructions for Using the Checklist</a></li>
<li class="toctree-l3"><a class="reference internal" href="#common-dataset-problems">Common Dataset Problems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#ds-01-the-dataset-contains-too-many-missing-values">ds.01 The dataset contains too many missing values</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ds-02-the-label-of-the-data-is-incorrect">ds.02 The label of the data is incorrect</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ds-03-the-number-of-samples-of-each-category-in-the-dataset-is-unbalanced-or-the-training-samples-of-some-categories-are-insufficient">ds.03 The number of samples of each category in the dataset is unbalanced or the training samples of some categories are insufficient</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ds-04-the-dataset-in-the-training-environment-is-different-from-the-standard-dataset">ds.04 The dataset in the training environment is different from the standard dataset</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#common-data-processing-algorithm-problems">Common Data Processing Algorithm Problems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dp-01-data-is-not-normalized-or-standardized">dp.01 Data is not normalized or standardized</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dp-02-the-data-processing-mode-is-incorrect-during-inference">dp.02: The data processing mode is incorrect during inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dp-03-datasets-are-not-shuffled-during-training">dp.03 Datasets are not shuffled during training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dp-04-when-data-padding-is-involved,-the-padding-mode-is-incorrect">dp.04: When data padding is involved, the padding mode is incorrect</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dp-05-the-multi-node-fragmentation-mode-is-incorrect-during-parallel-training">dp.05: The multi-node fragmentation mode is incorrect during parallel training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#common-hyperparameter-problems">Common Hyperparameter Problems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hp-01-the-learning-rate-is-too-high-or-too-low">hp.01 The learning rate is too high or too low</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hp-02-the-number-of-epochs-is-too-large-or-too-small">hp.02 The number of epochs is too large or too small</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hp-03-the-batch-size-is-too-large">hp.03 The batch size is too large</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#faqs-about-api-usage">FAQs About API Usage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#api-01-differences-between-mindspore-apis-and-other-framework-apis-are-not-noticed-when-using-apis">api.01 Differences between MindSpore APIs and other framework APIs are not noticed when using APIs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#api-02-the-mode-is-not-set-based-on-the-training-or-inference-scenario-when-the-api-is-used">api.02 The mode is not set based on the training or inference scenario when the API is used</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#common-computational-graph-structure-problems">Common Computational Graph Structure Problems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#cg-01-the-weight-is-improperly-shared">cg.01 The weight is improperly shared</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cg-02-the-weight-is-improperly-frozen">cg.02 The weight is improperly frozen</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cg-03-the-node-is-improperly-connected">cg.03 The node is improperly connected</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cg-04-the-loss-function-is-incorrect">cg.04 The loss function is incorrect</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#common-weight-initialization-problems">Common Weight Initialization Problems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#wi-01-the-initial-values-of-all-weights-are-0">wi.01 The initial values of all weights are 0</a></li>
<li class="toctree-l4"><a class="reference internal" href="#wi-02-the-loaded-pre-training-model-is-incorrect">wi.02 The loaded pre-training model is incorrect</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#common-mixed-precision-and-overflow-problems">Common Mixed Precision and Overflow Problems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#mp-01-overflow-occurs-during-training">mp.01 Overflow occurs during training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mp-02-during-mixed-precision-training,-the-loss-scale-is-not-correctly-set">mp.02 During mixed precision training, the loss scale is not correctly set</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mp-03-the-application-sequence-of-loss-scale-and-gradient-clip-is-incorrect">mp.03 The application sequence of loss scale and gradient clip is incorrect</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mp-04-when-computing-the-gradient-penalty,-the-gradient-is-not-restored-to-the-gradient-without-loss-scale">mp.04: When computing the gradient penalty, the gradient is not restored to the gradient without loss scale</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#symptom-comparison-based-locating-method">Symptom Comparison-based Locating Method</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#fixing-mindspore-script-randomness">Fixing MindSpore Script Randomness</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reproducing-the-accuracy-problem">Reproducing the Accuracy Problem</a></li>
<li class="toctree-l3"><a class="reference internal" href="#comparison-with-the-benchmark-script">Comparison with the Benchmark Script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#seeking-help">Seeking Help</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="accuracy_optimization.html">Accuracy Problem Locating and Optimization Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning_guide.html">Performance Tuning Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight.debugger.html">mindinsight.debugger</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindconverter.html">mindconverter</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="training_visual_design.html">Overall Design of Training Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_visual_design.html">Computational Graph Visualization Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_visual_design.html">Tensor Visualization Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler_design.html">Performance Profiling Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Guide to Locating Accuracy Problems</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/accuracy_problem_preliminary_location.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="guide-to-locating-accuracy-problems">
<h1>Guide to Locating Accuracy Problems<a class="headerlink" href="#guide-to-locating-accuracy-problems" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.7/docs/mindinsight/docs/source_en/accuracy_problem_preliminary_location.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.7/resource/_static/logo_source_en.png" /></a></p>
<p>This guide aims to provide algorithm developers with a brief and concise guidance for locating accuracy problems. For details about how to locate and optimize accuracy problems, see <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.7/accuracy_optimization.html">Accuracy Problem Locating and Optimization Guide</a>.</p>
<p>This guide is applicable to the scenario where the training script can run until the training is complete and the loss value of each training step is output. If an error occurs during training, rectify the fault based on the error information.</p>
<p>This guide assumes that you are capable of independently compiling deep learning training scripts and have a basic understanding of deep learning and MindSpore.</p>
<p>Two common methods are provided for preliminarily locating accuracy problems: checklist-based locating and symptom comparison-based locating. In practice, you use only one method. The checklist-based locating method is recommended. If a benchmark script (reference script for MindSpore script development) is available, you can use the symptom comparison-based locating method.</p>
<section id="checklist-based-locating-method">
<h2>Checklist-based Locating Method<a class="headerlink" href="#checklist-based-locating-method" title="Permalink to this headline"></a></h2>
<p>When an accuracy problem occurs, you can refer to the following checklist to check the accuracy. If any suspicious problems are found in the checklist, you should try to rectify the problems by referring to <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.7/accuracy_optimization.html">Accuracy Problem Locating and Optimization Guide</a>. If no suspicious problem is found after the checklist is used, you can use other methods to locate and optimize accuracy problems or refer to <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.7/accuracy_optimization.html">Accuracy Problem Locating and Optimization Guide</a>. If you suspect that the accuracy problem is related to the MindSpore framework, ensure that the problems listed in the checklist do not exist before seeking help. For details about how to seek help, see the end of this document.</p>
<section id="instructions-for-using-the-checklist">
<h3>Instructions for Using the Checklist<a class="headerlink" href="#instructions-for-using-the-checklist" title="Permalink to this headline"></a></h3>
<p>You are advised to copy the following checklist to a Word document, check the items one by one, fill in the conclusion in the Word document, and save the document. For complex problems, you are advised to paste related screenshots and code into the conclusion. The information can help us better determine your problem when you seek help from us.</p>
<p>In the “Check method” field, you can select an equivalent or more effective check method based on the actual situation.</p>
<p>In the “Conclusion” field, enter “Problem found”, “No problem”, or “N/A” based on the actual situation.</p>
</section>
<section id="common-dataset-problems">
<h3>Common Dataset Problems<a class="headerlink" href="#common-dataset-problems" title="Permalink to this headline"></a></h3>
<section id="ds-01-the-dataset-contains-too-many-missing-values">
<h4>ds.01 The dataset contains too many missing values<a class="headerlink" href="#ds-01-the-dataset-contains-too-many-missing-values" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>Missing values usually exist in the form of NaN and +/-Inf. Missing value symbols used in different datasets are different. When checking missing values, you need to determine the method of representing missing values in each field, and then use a counter to count the number of missing values in each field. In this way, you can understand the missing values in the dataset.</p>
<p>If the data contains missing values that are not processed, enter “Problem found” in the “Conclusion” field. In this case, you need to take proper measures to handle the problem. For details about the handling methods, see <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.7/accuracy_optimization.html">Accuracy Problem Locating and Optimization Guide</a>.</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="ds-02-the-label-of-the-data-is-incorrect">
<h4>ds.02 The label of the data is incorrect<a class="headerlink" href="#ds-02-the-label-of-the-data-is-incorrect" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>Use the sampling method to check whether the data labels are correct. This check is not required in scenarios without labels (for example, unsupervised learning).</p>
<p>If there are not many labels, you are advised to perform hierarchical sampling on the training data based on all labels to ensure that at least one sample is selected for each label. Then, check the selected samples. Select a proper sampling probability to ensure that the number of samples is about 50.</p>
<p>If there are a large number of labels, you are advised to randomly select 20 labels. Then, the training data is sampled based on the selected label to ensure that at least one sample is selected for each label. Select a proper sampling probability to ensure that the number of samples is about 50.</p>
<p>After obtaining the samples, check whether the data labels are correct in a proper visualization mode. For example, image data can be checked after being drawn using matplotlib, and text data can be directly printed on the screen for check.</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="ds-03-the-number-of-samples-of-each-category-in-the-dataset-is-unbalanced-or-the-training-samples-of-some-categories-are-insufficient">
<h4>ds.03 The number of samples of each category in the dataset is unbalanced or the training samples of some categories are insufficient<a class="headerlink" href="#ds-03-the-number-of-samples-of-each-category-in-the-dataset-is-unbalanced-or-the-training-samples-of-some-categories-are-insufficient" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>A counter is used to count the number of samples of each category, and then the standard deviation and bar chart are used to determine whether the number of samples is balanced. Generally, supervised deep learning algorithm can achieve acceptable accuracy in the case of 5000 labeled samples of each class. When there are more than 10 million labeled samples in the dataset, the model performance will exceed that of humans.</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="ds-04-the-dataset-in-the-training-environment-is-different-from-the-standard-dataset">
<h4>ds.04 The dataset in the training environment is different from the standard dataset<a class="headerlink" href="#ds-04-the-dataset-in-the-training-environment-is-different-from-the-standard-dataset" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>You are advised to check whether the datasets copied from the training environment are consistent with the same source dataset. Especially in parallel training, you are advised to check whether datasets are correctly stored on each machine. When using a known dataset, ensure that the dataset used in the training environment is consistent with the known dataset. The check procedure is as follows:</p>
<ol class="arabic simple">
<li><p>Check that the dataset file list of the ported model is the same as that of the benchmark model. The file list in the training environment should be recorded based on the actual training process. For example, record the dataset file list when creating a dataset in the training script.</p></li>
<li><p>Obtain the MD5 verification codes of the reference dataset file and the actual dataset file based on the file list. Ensure that the two groups of verification codes are the same.</p></li>
</ol>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
</section>
<section id="common-data-processing-algorithm-problems">
<h3>Common Data Processing Algorithm Problems<a class="headerlink" href="#common-data-processing-algorithm-problems" title="Permalink to this headline"></a></h3>
<section id="dp-01-data-is-not-normalized-or-standardized">
<h4>dp.01 Data is not normalized or standardized<a class="headerlink" href="#dp-01-data-is-not-normalized-or-standardized" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>Check the data processing code and ensure that necessary normalization or standardization is performed in the data processing code. Normalization or standardization refers to mapping data to a same scale. Common operation methods include resize, rescale, normalize, and the like.</p>
<p>For example:</p>
<p>Take the ResNet50 model in ModelZoo as an example. It can be seen that the model is normalized in the data processing code. Therefore, the conclusion is “No problem.”</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">trans</span> <span class="o">+=</span> <span class="p">[</span>
        <span class="n">C</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.4914</span><span class="p">,</span> <span class="mf">0.4822</span><span class="p">,</span> <span class="mf">0.4465</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2023</span><span class="p">,</span> <span class="mf">0.1994</span><span class="p">,</span> <span class="mf">0.2010</span><span class="p">]),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="p">]</span>
</pre></div>
</div>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="dp-02-the-data-processing-mode-is-incorrect-during-inference">
<h4>dp.02: The data processing mode is incorrect during inference<a class="headerlink" href="#dp-02-the-data-processing-mode-is-incorrect-during-inference" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>Check the data processing code of the training script and that of the inference script. Generally, the processing logic of the two scripts must be the same. It should be noted that some random operations (such as random rotation and random cropping) are generally used only for training sets. Random operation is not required during inference.</p>
<p>For example:</p>
<p>Take the ResNet50 model (CIFAR10 dataset) in ModelZoo as an example. The training script and inference script reuse the same data processing function. The do_train parameter is used to distinguish the training mode from the inference mode. Check the code. It is found that do_train affects only the two random data processing operators. It is used in training mode and is not used in inference mode. Other processing logic is the same. Therefore, the conclusion is “No problem.”</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">if</span> <span class="n">do_train</span><span class="p">:</span>
        <span class="n">trans</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="n">C</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span>
            <span class="n">C</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="p">]</span>
</pre></div>
</div>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="dp-03-datasets-are-not-shuffled-during-training">
<h4>dp.03 Datasets are not shuffled during training<a class="headerlink" href="#dp-03-datasets-are-not-shuffled-during-training" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>Check whether the shuffle function is enabled in the data processing code of the training script. Shuffling the data sequence helps avoid overfitting. If shuffling is not performed, or shuffling is insufficient, a model is always updated in a same data sequence, which severely limits selectability of a gradient optimization direction. As a result, fewer convergence points can be selected and overfitting is easy to occur. The shuffle function can be enabled in any of the following ways:</p>
<ol class="arabic simple">
<li><p>When creating a dataset, set shuffle to True. For example, the shuffle parameter in <a class="reference external" href="https://mindspore.cn/docs/en/r1.7/api_python/dataset/mindspore.dataset.Cifar10Dataset.html#mindspore.dataset.Cifar10Dataset">mindspore.dataset.Cifar10Dataset</a>.</p></li>
<li><p>The shuffle method, for example, <a class="reference external" href="https://mindspore.cn/docs/en/r1.7/api_python/dataset/mindspore.dataset.Cifar10Dataset.html#mindspore.dataset.Cifar10Dataset.shuffle">mindspore.dataset.Cifar10Dataset.shuffle</a>, is used during data processing.</p></li>
<li><p>If the Sampler is used, you can also enable the shuffle function provided by the Sampler. For example, the shuffle parameter in <a class="reference external" href="https://mindspore.cn/docs/en/r1.7/api_python/dataset/mindspore.dataset.PKSampler.html#mindspore.dataset.PKSampler">mindspore.dataset.PKSampler</a>.</p></li>
</ol>
<p>For example:
Take ResNet50 (CIFAR10 dataset) in ModelZoo as an example. The shuffle parameter is set to True when the dataset is created. Therefore, the conclusion is “No problem.”</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">if</span> <span class="n">device_num</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                     <span class="n">num_shards</span><span class="o">=</span><span class="n">device_num</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="n">rank_id</span><span class="p">)</span>
</pre></div>
</div>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="dp-04-when-data-padding-is-involved,-the-padding-mode-is-incorrect">
<h4>dp.04: When data padding is involved, the padding mode is incorrect<a class="headerlink" href="#dp-04-when-data-padding-is-involved,-the-padding-mode-is-incorrect" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>Check whether the position, mode, and value of data padding are consistent with the design. Data padding is to fill fake data so that the size and shape of the data meet the training requirements.</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="dp-05-the-multi-node-fragmentation-mode-is-incorrect-during-parallel-training">
<h4>dp.05: The multi-node fragmentation mode is incorrect during parallel training<a class="headerlink" href="#dp-05-the-multi-node-fragmentation-mode-is-incorrect-during-parallel-training" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>The data preprocessing may shard datasets to different nodes based on file name or number of files. This results in large differences between the user model and benchmark model or even files sharded repeatedly to a single node, as the file read API sorts file names differently on different nodes.</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
</section>
<section id="common-hyperparameter-problems">
<h3>Common Hyperparameter Problems<a class="headerlink" href="#common-hyperparameter-problems" title="Permalink to this headline"></a></h3>
<section id="hp-01-the-learning-rate-is-too-high-or-too-low">
<h4>hp.01 The learning rate is too high or too low<a class="headerlink" href="#hp-01-the-learning-rate-is-too-high-or-too-low" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>The range of learning rate can be preliminarily determined through a simple experiment. Specifically, select a large learning rate range (for example, from 0 to 0.5), and train several epochs (for example, 10). During training, the learning rate is increased linearly (or exponentially) iteratively, a relationship curve between the accuracy and the learning rate is obtained, as shown in the following figure. Pay attention to learning rates corresponding to parts whose accuracy starts to increase and does not increase in the curve. A learning rate when the accuracy starts to increase may be used as a lower limit of the learning rate, and a learning rate when the accuracy does not increase is used as an upper limit of the learning rate. A learning rate between the upper limit and the lower limit may be considered reasonable.</p>
<p><img alt="Relationship between the learning rate and accuracy" src="_images/check_learning_rate.png" /></p>
<p><em>Figure 1 Relationship between the learning rate and accuracy. This curve is obtained through training of eight epochs and referenced from (Smith, 2017)</em></p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="hp-02-the-number-of-epochs-is-too-large-or-too-small">
<h4>hp.02 The number of epochs is too large or too small<a class="headerlink" href="#hp-02-the-number-of-epochs-is-too-large-or-too-small" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>An epoch is a process of training a model using all data in a training set. The number of epochs indicates the number of times that the preceding process is performed. The loss curves of the training set and test set during training help determine the proper number of epochs. Generally, as the training is performed, the loss of the training set decreases continuously, and the loss of the validation set decreases first and then increases slowly. You need to select the epoch with the minimum loss of the validation set as the optimal number of epochs for training.</p>
<p><img alt="Epoch check" src="_images/check_epoch.png" /></p>
<p><em>Figure 2 Relationship between the epochs and loss. The blue curve is the loss curve of the training set, and the green curve is the loss curve of the validation set.</em></p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="hp-03-the-batch-size-is-too-large">
<h4>hp.03 The batch size is too large<a class="headerlink" href="#hp-03-the-batch-size-is-too-large" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>If the batch size is too large, the accuracy is reduced. Generally, 32 is a secure value, and 64, 128, and 256 are worth trying. You are advised to perform training on a small batch size and dataset to obtain the accuracy baseline. During training with a large batch size, pay attention to the accuracy change. If the accuracy is far away from the baseline, the batch size may be large. (The learning rate may not match the batch size. Generally, when the batch size is increased, the learning rate needs to be increased accordingly to keep the ratio of the batch size to the learning rate constant.)</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
</section>
<section id="faqs-about-api-usage">
<h3>FAQs About API Usage<a class="headerlink" href="#faqs-about-api-usage" title="Permalink to this headline"></a></h3>
<section id="api-01-differences-between-mindspore-apis-and-other-framework-apis-are-not-noticed-when-using-apis">
<h4>api.01 Differences between MindSpore APIs and other framework APIs are not noticed when using APIs<a class="headerlink" href="#api-01-differences-between-mindspore-apis-and-other-framework-apis-are-not-noticed-when-using-apis" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>MindSpore APIs are different from APIs of other frameworks. If the benchmark script is available, pay attention to the following:</p>
<ol class="arabic simple">
<li><p>Check whether the parameter initialization mode of the MindSpore script is the same as that of the benchmark script.</p></li>
<li><p>Check whether the default parameter values of some APIs in MindSpore and the parameter meanings are different from those in other frameworks.</p></li>
</ol>
<p>Here we list some important differences for you to check:</p>
<ol class="arabic simple">
<li><p>By default, the <a class="reference external" href="https://www.mindspore.cn/docs/en/r1.7/api_python/nn/mindspore.nn.Conv2d.html#mindspore.nn.Conv2d">Conv2d</a> operator of MindSpore does not have bias (has_bias = False), but the Conv2d operator of PyTorch has bias. By default, the weight of the Conv2d operator is Normal (0.0, 0.01). This initialization mode is different from that of PyTorch (Uniform) and TensorFlow (Uniform). For the comparison with PyTorch, see <a class="reference external" href="https://www.mindspore.cn/docs/en/r1.7/note/api_mapping/pytorch_diff/nn_Conv2d.html">Function Differences with torch.nn.Conv2d</a></p></li>
<li><p>For the <a class="reference external" href="https://www.mindspore.cn/docs/en/r1.7/api_python/nn/mindspore.nn.Dropout.html#mindspore.nn.Dropout">DropOut</a> operator of MindSpore, this parameter indicates the retention probability (keep_prob). For the DropOut operator of PyTorch, this parameter indicates the drop probability.</p></li>
<li><p>The default momentum value in <a class="reference external" href="https://www.mindspore.cn/docs/en/r1.7/api_python/nn/mindspore.nn.BatchNorm2d.html#mindspore.nn.BatchNorm2d">BatchNorm2d</a> of MindSpore is different from that of PyTorch. The default value is 0.1 in PyTorch and 0.9 in MindSpore. For the comparison with PyTorch, see <a class="reference external" href="https://www.mindspore.cn/docs/en/r1.7/note/api_mapping/pytorch_diff/BatchNorm2d.html">Function Differences with torch.nn.BatchNorm2d</a></p></li>
</ol>
<p>For details about API differences, see <a class="reference external" href="https://www.mindspore.cn/docs/en/r1.7/note/api_mapping/pytorch_api_mapping.html">https://www.mindspore.cn/docs/en/r1.7/note/api_mapping/pytorch_api_mapping.html</a>.</p>
<p>For example:</p>
<p>Take ResNet50 (CIFAR10 dataset) in ModelZoo as an example. According to the API difference list, the following APIs that may be different are used in the script: mindspore.nn.Conv2d and mindspore.nn.BatchNorm2d.</p>
<p>When Conv2d is used in the script, the weight_init mode is explicitly specified. When BatchNorm2d is used in the script, the momentum parameter is explicitly specified. The values of these parameters are consistent with the design. Therefore, the conclusion is “No problem.”</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="api-02-the-mode-is-not-set-based-on-the-training-or-inference-scenario-when-the-api-is-used">
<h4>api.02 The mode is not set based on the training or inference scenario when the API is used<a class="headerlink" href="#api-02-the-mode-is-not-set-based-on-the-training-or-inference-scenario-when-the-api-is-used" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>In the training script, this check is required when the model.train API is not used for training.</p>
<p>In the evaluation script, this check is required when the model.eval API is not used for evaluation.</p>
<p>In the inference script, this check is required when the model.predict API is not used for inference.</p>
<p>Determine whether the scenario is a training scenario and set cell.set_train() before calling a model. In the training scenario, call cell.set_train(True). In other scenarios, call cell.set_train(False).</p>
<p>Note:</p>
<p>For the BatchNorm operator in the mindspore.nn namespace, you are advised to retain the default value None of the <code class="docutils literal notranslate"><span class="pre">use_batch_statistics</span></code> parameter. When <code class="docutils literal notranslate"><span class="pre">use_batch_statistics</span></code> is set to the default value None, the BatchNorm operator determines whether to update the moving mean and moving variance parameters in each training step based on the mode specified by cell.set_train(). When the mode specified by cell.set_train() is True, the preceding two parameters are updated. When the mode specified by cell.set_train() is False, the preceding two parameters are not updated. If <code class="docutils literal notranslate"><span class="pre">use_batch_statistics=True</span></code> is set, the BatchNorm operator updates the moving mean and moving variance parameters even if cell.set_train(False) is set to indicate that the current scenario is not a training scenario.</p>
<p>For example:</p>
<p>Take ResNet50 (CIFAR10 dataset) in ModelZoo as an example. It uses the model.train and model.eval APIs in train.py and eval.py for training and inference, respectively. In infer.py, net.set_train (False) is explicitly called before inference. Therefore, the conclusion is “No problem.”</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
</section>
<section id="common-computational-graph-structure-problems">
<h3>Common Computational Graph Structure Problems<a class="headerlink" href="#common-computational-graph-structure-problems" title="Permalink to this headline"></a></h3>
<p>To check a computational graph structure, save the computational graph to a summary file by referring to <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.7/summary_record.html">Collecting Summary Record</a>, and then use <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.7/dashboard.html#computational-graph-visualization">MindInsight</a> to visualize the computational graph.</p>
<p>Conclusion:</p>
<p>Enter here.</p>
<section id="cg-01-the-weight-is-improperly-shared">
<h4>cg.01 The weight is improperly shared<a class="headerlink" href="#cg-01-the-weight-is-improperly-shared" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>The weight that should be shared is not shared or the weight that should not be shared is shared. On the MindInsight computing graph page, select a weight node, check whether the weight is shared based on the output node of the weight node, and view the name of the output node to obtain the code corresponding to the output node. The node whose name starts with Default is usually a node in the forward graph. Pay attention to the node. If the node name starts with Gradients or contains optimizer, the node is a backward graph or optimizer-related node. You can ignore it during the check. For example, to check the weight of Conv2d, enter conv2d in the search box in the upper right corner of the computational graph page, select any conv2d node that you are interested in, and find the input weight node of the node. Then you can check the weight node.</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="cg-02-the-weight-is-improperly-frozen">
<h4>cg.02 The weight is improperly frozen<a class="headerlink" href="#cg-02-the-weight-is-improperly-frozen" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>Check whether the freezing status of the weight is consistent with the design based on the code. There are two ways to freeze weights, both of which have obvious features in the code.</p>
<p>Method 1: Set requires_grad in <a class="reference external" href="https://www.mindspore.cn/docs/en/r1.7/api_python/mindspore/mindspore.Parameter.html#mindspore.Parameter">Parameter</a> to False.</p>
<p>Method 2: Use [stop_gradient](<a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.7/beginner/autograd.html">https://www.mindspore.cn/tutorials/en/r1.7/beginner/autograd.html</a># %E5%81%9C %E6%AD %A2%E8%AE %A1%E7%AE %97%E6%A2%AF %E5%BA %A6) to prevent the gradient from continuing to propagate backward. After all gradients that affect the weight are blocked, the update of the weight is actually blocked.</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="cg-03-the-node-is-improperly-connected">
<h4>cg.03 The node is improperly connected<a class="headerlink" href="#cg-03-the-node-is-improperly-connected" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>On the MindInsight computational graph page, check important model elements from top to bottom to ensure that these elements are displayed in the computational graph. For example, to check whether LeNet5 has node connection errors, you can expand the computational graph displayed on the MindInsight computational graph page layer by layer to ensure that important elements such as conv, relu, and fc exist in the computational graph and are correctly connected. The computational graph in the Gradients namespace is generated through MindSpore automatic differentiation and can be ignored during the check.</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="cg-04-the-loss-function-is-incorrect">
<h4>cg.04 The loss function is incorrect<a class="headerlink" href="#cg-04-the-loss-function-is-incorrect" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>When using the built-in loss function of MindSpore, check whether the type of the used loss function complies with the design. When using the customized loss function, check whether the code implementation of the loss function complies with the design. If necessary, manually implement a NumPy version and use the same input to check whether the output of the loss function of the MindSpore version is consistent with that of the NumPy version.</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
</section>
<section id="common-weight-initialization-problems">
<h3>Common Weight Initialization Problems<a class="headerlink" href="#common-weight-initialization-problems" title="Permalink to this headline"></a></h3>
<section id="wi-01-the-initial-values-of-all-weights-are-0">
<h4>wi.01 The initial values of all weights are 0<a class="headerlink" href="#wi-01-the-initial-values-of-all-weights-are-0" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>Check the weight initialization mode (excluding the optimizer status) in the script (including the explicitly specified initial weight value and the default weight initialized in APIs in some mindspore.nn namespaces) to see whether the weight is initialized to all 0s. Note that some parameters, such as bias, should be initialized to all 0s.</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="wi-02-the-loaded-pre-training-model-is-incorrect">
<h4>wi.02 The loaded pre-training model is incorrect<a class="headerlink" href="#wi-02-the-loaded-pre-training-model-is-incorrect" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>When loading a pre-trained or backbone model, ensure that the correct weight is loaded. When using backbone models such as ResNet, load the pre-trained model that matches the design and application scenario. If there is a benchmark script, ensure that the weight of the loaded pre-training model is the same as that of the pre-training model that can be used by the benchmark script.</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
</section>
<section id="common-mixed-precision-and-overflow-problems">
<h3>Common Mixed Precision and Overflow Problems<a class="headerlink" href="#common-mixed-precision-and-overflow-problems" title="Permalink to this headline"></a></h3>
<p>When you run a script on the Ascend backend or use the mixed precision function, you are advised to check the items in this section to determine whether mixed precision and overflow problems exist.</p>
<section id="mp-01-overflow-occurs-during-training">
<h4>mp.01 Overflow occurs during training<a class="headerlink" href="#mp-01-overflow-occurs-during-training" title="Permalink to this headline"></a></h4>
<p>Check method:
When the <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r1.7/others/mixed_precision.html">mixed precision</a> or the Ascend AI processor is used for training, you are advised to check whether overflow occurs.</p>
<p>When using the GPU, you can perform the overflow check through the check tensor overflow watchpoint in the <a class="reference external" href="https://mindspore.cn/mindinsight/docs/en/r1.7/debugger_online.html#anomaly-check-list">debugger</a>.</p>
<p>After the overflow problem is found, find and analyze the first overflow node. (For Ascend overflow data, find the node with the smallest timestamp based on the timestamp in the file name. For GPU overflow data, find the first node in the execution sequence.) Determine the overflow cause based on the input and output data of the operator.</p>
<p>The common solutions to the overflow problem are as follows:</p>
<ol class="arabic simple">
<li><p>Enable dynamic loss scale or set a proper static loss scale value. For details, see <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r1.7/others/mixed_precision.html">LossScale</a>. Note that when the static loss scale in the GPU scenario is directly used for Ascend training, unexpected frequent overflow may occur, affecting convergence. After the loss scale is enabled, you may need to perform multiple experiments to adjust the init_loss_scale (initial value), scale_factor, and scale_window of loss scale until there are few floating-point overflows during training.</p></li>
<li><p>If the overflow problem has a key impact on the accuracy and cannot be avoided, change the corresponding operator to the FP32 operator (the performance may be greatly affected after the adjustment).</p></li>
</ol>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="mp-02-during-mixed-precision-training,-the-loss-scale-is-not-correctly-set">
<h4>mp.02 During mixed precision training, the loss scale is not correctly set<a class="headerlink" href="#mp-02-during-mixed-precision-training,-the-loss-scale-is-not-correctly-set" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>When <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r1.7/others/mixed_precision.html">mixed precision</a> is used. You can use the default parameter values of DynamicLossScaleManager or FixedLossScaleManager for training. If there are too many overflow steps and the final accuracy is affected, adjust the value of loss_scale based on the overflow phenomenon. If gradient overflow occurs, decrease the value of loss_scale (by dividing the original value of loss_scale by 2). If gradient underflow occurs, increase the value of loss_scale (by multiplying the original value of loss_scale by 2). In most cases, training on the Ascend AI processor is performed with mixed precision. The computation feature of the Ascend AI processor is different from that of the GPU mixed precision. Therefore, you may need to adjust the value of the LossScaleManager hyperparameter to a value different from that on the GPU based on the training result to ensure the precision.</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="mp-03-the-application-sequence-of-loss-scale-and-gradient-clip-is-incorrect">
<h4>mp.03 The application sequence of loss scale and gradient clip is incorrect<a class="headerlink" href="#mp-03-the-application-sequence-of-loss-scale-and-gradient-clip-is-incorrect" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>Gradient clip forcibly adjusts the gradient to a smaller value when the gradient is greater than a threshold. Gradient clip has a good effect on the gradient explosion problem in RNNs. If both <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r1.7/others/mixed_precision.html">loss scale</a> and gradient clip are used, perform this check. Check the code to ensure that the application object of gradient clip is the original gradient value obtained by dividing the loss scale.</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
<section id="mp-04-when-computing-the-gradient-penalty,-the-gradient-is-not-restored-to-the-gradient-without-loss-scale">
<h4>mp.04: When computing the gradient penalty, the gradient is not restored to the gradient without loss scale<a class="headerlink" href="#mp-04-when-computing-the-gradient-penalty,-the-gradient-is-not-restored-to-the-gradient-without-loss-scale" title="Permalink to this headline"></a></h4>
<p>Check method:</p>
<p>Gradient penalty is a technique that adds a gradient to a cost function to constrain the gradient length. If both <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r1.7/others/mixed_precision.html">loss scale</a> and gradient penalty are used, perform this check. Check whether the entered gradient is a gradient without loss scale when computing the gradient penalty item. For example, a gradient substituted for the loss scale may be first divided by the loss scale, and then is used to compute the gradient penalty item.</p>
<p>Conclusion:</p>
<p>Enter here.</p>
</section>
</section>
</section>
<section id="symptom-comparison-based-locating-method">
<h2>Symptom Comparison-based Locating Method<a class="headerlink" href="#symptom-comparison-based-locating-method" title="Permalink to this headline"></a></h2>
<p>If the scripts, hyperparameters, and datasets are not modified and the same scripts are run for multiple times on the new version, the accuracy deteriorates (compared with the old version). In this case, contact us for help and provide related information.</p>
<p>If the benchmark script in another framework is available, you can compare the MindSpore script with the benchmark script to preliminarily locate the problem. The benchmark script refers to the script referenced by the image during MindSpore script development. That is, most details in the MindSpore script are determined by the benchmark script. In the migration scenario, the migrated script is generally a benchmark script.</p>
<p>The procedure is as follows:</p>
<section id="fixing-mindspore-script-randomness">
<h3>Fixing MindSpore Script Randomness<a class="headerlink" href="#fixing-mindspore-script-randomness" title="Permalink to this headline"></a></h3>
</section>
<section id="reproducing-the-accuracy-problem">
<h3>Reproducing the Accuracy Problem<a class="headerlink" href="#reproducing-the-accuracy-problem" title="Permalink to this headline"></a></h3>
<p>After the randomness is fixed, check whether the accuracy problem recurs.</p>
<p>If the problem does not recur, the accuracy problem is related to the operations performed when the randomness is fixed. You can determine the operation that causes the problem based on the sequence of unfixed network, unfixed dataset, unfixed initialization weight, unfixed hyperparameter, and unfixed global random number seed. In this way, you can determine the cause of the problem and optimize the training script accordingly.</p>
<p>If the problem occurs occasionally in a random or determined step, or occurs inevitably in a random step, check whether all random factors are fixed based on the check result of the loss curve in the preceding steps.</p>
<p>If the problem occurs inevitably in a step, you can try to locate the problem in the first or second step to facilitate subsequent symptom comparison and problem locating. Specifically, assuming that the problem occurs in the Dth step, try to save a checkpoint of the (D-1)th step, which is marked as checkpoint (D-1), enable the dataset to skip the corresponding data, and then load checkpoint (D-1) to train. In this case, the problem occurs in the second step (the initial step is recorded as the first step).</p>
</section>
<section id="comparison-with-the-benchmark-script">
<h3>Comparison with the Benchmark Script<a class="headerlink" href="#comparison-with-the-benchmark-script" title="Permalink to this headline"></a></h3>
<p>The comparison with the benchmark script is a great help to locate the accuracy problem. Compare the MindSpore script with the benchmark script to check whether errors exist in the MindSpore script and fix the randomness of the benchmark script so that the loss curve can be compared with that in the MindSpore script.</p>
<p>You are advised to perform the check in simulation mode and compare the results line by line. Run the training scripts with the same parameters. During the execution, ensure that the logic of the MindSpore script is the same as that of the benchmark script and the meanings of the running parameters are consistent. Generally, the confirmation scope is limited to the code compiled by the developer (the code of the deep learning framework does not need to be enabled). During the implementation, pay attention to the following aspects:</p>
<ol class="arabic simple">
<li><p>Ensure that the global random number seeds in the benchmark script are fixed.</p></li>
<li><p>Check whether the hyperparameters are consistent and fix the hyperparameters in the benchmark script.</p></li>
<li><p>Check whether the dataset and data processing are consistent, and fix the data processing method and data sequence in the benchmark script.</p></li>
<li><p>Check whether the network structures are consistent and delete random operators from the network.</p></li>
<li><p>Check whether the weight initialization is consistent. You are advised to load the checkpoint file with the same value for the MindSpore script and benchmark script. If the network structures are the same, the checkpoint file of a framework can be converted into the checkpoint file of another framework by simply replacing the weight name.</p></li>
<li><p>It is strongly recommended that the mixed precision be enabled in the benchmark script. If an accuracy problem occurs after the mixed precision function of the benchmark script is enabled, the algorithm needs to be optimized to ensure that the algorithm can converge at the mixed precision.</p></li>
</ol>
<p>During the comparison, you need to compare the parameters written in the script and pay attention to the default values of the parameters that are not written in the script. For example, for the Conv2d operator of MindSpore, has_bias is set to False by default and Normal (0.0, 0.01) is used to initialize the weight. For the Conv2d operator of PyTorch, has_bias is set to True by default and the initialization mode is different. For details about the API differences between MindSpore and PyTorch, see <a class="reference external" href="https://www.mindspore.cn/docs/en/r1.7/note/api_mapping/pytorch_api_mapping.html">https://www.mindspore.cn/docs/en/r1.7/note/api_mapping/pytorch_api_mapping.html</a>.</p>
<p>After the preceding comparison and fixing processes are executed, some MindSpore scripts are inconsistent. After the inconsistency is rectified, the accuracy problem is solved. If the inconsistency is rectified but the problem persists, run the MindSpore script and benchmark script with the same dataset and parameters to compare the loss.</p>
<ol class="arabic simple">
<li><p>If the loss of the first step is different, the two scripts may be inconsistent or the randomness is not fixed.</p></li>
<li><p>If the loss of the first step is the same and the loss of the second step is different, inconsistency occurs in the backward computation or weight update of the first step, or in the forward computation of the second step. You need to check whether the optimizer and input data of the MindSpore script are consistent with those of the benchmark script. If the MindSpore script is consistent with the benchmark script and the randomness is fixed, collect related information and contact us for help.</p></li>
</ol>
<p>If the loss values of the first and second steps are the same, you can further compare the entire loss curve. If the entire loss curve is basically the same, there is a high probability that the benchmark script has an accuracy problem. If the entire loss curve has a bifurcation, the bifurcation location is the key to locate the accuracy problem.</p>
<p>Note that some operators on the Ascend AI processor do not support FP32 implementation. Therefore, when comparing MindSpore on the Ascend AI processor with MindSpore on the Ascend AI processor, you need to enable the mixed precision in the benchmark script to determine the upper limit of the precision when the mixed precision is enabled.</p>
</section>
</section>
<section id="seeking-help">
<h2>Seeking Help<a class="headerlink" href="#seeking-help" title="Permalink to this headline"></a></h2>
<p>Use either of the preceding methods to locate the problem. If no doubtful point is found, the script does not have obvious problems. In this case, perform optimization by referring to <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.7/accuracy_optimization.html">Accuracy Optimization Suggestions</a>. If you find any doubt based on symptom comparison, determine whether you need to locate the problem by yourself or contact MindSpore for help based on the information in the locating method. If any doubt or problem is found in the checklist, locate the problem by referring to the <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.7/accuracy_optimization.html">Accuracy Problem Locating and Optimization Guide</a>.</p>
<p>If you encounter an accuracy problem and want to seek help from MindSpore, provide related materials to help us better determine and solve your problem. You are advised to provide the following materials:</p>
<ol class="arabic simple">
<li><p>If you use a checklist, you are advised to add the conclusions of the checklist to the attachment.</p></li>
<li><p>If you use the symptom comparison-based locating method, you are advised to take screenshots of the symptom (including the MindSpore script and benchmark script) and fix the random MindSpore script and benchmark script, add the minimum dataset and running environment (for example, MindSpore version, GPU or Ascend) required for reproducing the problem to the attachment.</p></li>
<li><p>You are advised to add the executable script, minimum dataset, and running environment description (for example, MindSpore version, GPU or Ascend) that can reproduce the problem to the attachment.</p></li>
</ol>
<p>Link: <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues/new">https://gitee.com/mindspore/mindspore/issues/new</a></p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline"></a></h2>
<p>Smith, L. N. (2017). Cyclical learning rates for training neural networks. Proceedings - 2017 IEEE Winter Conference on Applications of Computer Vision, WACV 2017, 464–472. <a class="reference external" href="https://doi.org/10.1109/WACV.2017.58">https://doi.org/10.1109/WACV.2017.58</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindinsight_commands.html" class="btn btn-neutral float-left" title="MindInsight Commands" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="accuracy_optimization.html" class="btn btn-neutral float-right" title="Accuracy Problem Locating and Optimization Guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>