<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Performance Profiling (GPU-Graph) &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Cluster Performance Profiling" href="performance_profiling_of_cluster.html" />
    <link rel="prev" title="Performance Profiling (Ascend-PyNative)" href="performance_profiling_ascend_pynative.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_install.html">MindInsight Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="summary_record.html">Collecting Summary Record</a></li>
<li class="toctree-l1"><a class="reference internal" href="dashboard.html">Viewing Dashboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="lineage_and_scalars_comparison.html">Viewing Lineage and Scalars Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyper_parameters_auto_tuning.html">Use Mindoptimizer to Tune Hyperparameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrate_3rd_scripts_mindconverter.html">Migrating From Third Party Frameworks With MindConverter</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="performance_profiling.html">Performance Profiling</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="performance_profiling_ascend.html">Performance Profiling (Ascend-Graph)</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_profiling_ascend_pynative.html">Performance Profiling (Ascend-PyNative)</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Performance Profiling (GPU-Graph)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#operation-process">Operation Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="#preparing-the-training-script">Preparing the Training Script</a></li>
<li class="toctree-l3"><a class="reference internal" href="#launching-mindinsight">Launching MindInsight</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training-performance">Training Performance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#operator-performance-analysis">Operator Performance Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="#timeline-analysis">Timeline Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-trace-analysis">Step Trace Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-preparation-analysis">Data Preparation Analysis</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#resource-utilization">Resource Utilization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#cpu-utilization-analysis">CPU Utilization Analysis</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#notices">Notices</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="performance_profiling_of_cluster.html">Cluster Performance Profiling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="debugger.html">Debugger</a></li>
<li class="toctree-l1"><a class="reference internal" href="landscape.html">Training Optimization Process Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_commands.html">MindInsight Commands</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tuning Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="accuracy_problem_preliminary_location.html">Guide to Locating Accuracy Problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="accuracy_optimization.html">Accuracy Problem Locating and Optimization Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning_guide.html">Performance Tuning Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight.debugger.html">mindinsight.debugger</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="training_visual_design.html">Overall Design of Training Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_visual_design.html">Computational Graph Visualization Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_visual_design.html">Tensor Visualization Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler_design.html">Performance Profiling Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="performance_profiling.html">Performance Profiling</a> &raquo;</li>
      <li>Performance Profiling (GPU-Graph)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/performance_profiling_gpu.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="performance-profiling-gpu-graph">
<h1>Performance Profiling (GPU-Graph)<a class="headerlink" href="#performance-profiling-gpu-graph" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.8/docs/mindinsight/docs/source_en/performance_profiling_gpu.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_source_en.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>This article describes how to use MindSpore Profiler for performance debugging on GPU.</p>
</section>
<section id="operation-process">
<h2>Operation Process<a class="headerlink" href="#operation-process" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>Prepare a training script, add profiler APIs in the training script and run the training script.</p></li>
<li><p>Start MindInsight and specify the summary-base-dir using startup parameters, note that summary-base-dir is the parent directory of the directory created by Profiler. For example, the directory created by Profiler is <code class="docutils literal notranslate"><span class="pre">/home/user/code/data/</span></code>, the summary-base-dir should be <code class="docutils literal notranslate"><span class="pre">/home/user/code</span></code>. After MindInsight is started, access the visualization page based on the IP address and port number. The default access IP address is <code class="docutils literal notranslate"><span class="pre">http://127.0.0.1:8080</span></code>.</p></li>
<li><p>Find the training in the list, click the performance profiling link and view the data on the web page.</p></li>
</ul>
<blockquote>
<div><p>By default, common users do not have the permission to access the NVIDIA GPU performance counters on the target device.</p>
<p>If common users need to use the profiler performance statistics capability in the training script, configure the permission by referring to the following description:</p>
<p><a class="reference external" href="https://developer.nvidia.com/nvidia-development-tools-solutions-err-nvgpuctrperm-cupti">https://developer.nvidia.com/nvidia-development-tools-solutions-err-nvgpuctrperm-cupti</a></p>
</div></blockquote>
</section>
<section id="preparing-the-training-script">
<h2>Preparing the Training Script<a class="headerlink" href="#preparing-the-training-script" title="Permalink to this headline"></a></h2>
<p>To enable the performance profiling of neural networks, MindSpore Profiler APIs should be added into the script.</p>
<ul>
<li><p>The MindSpore <code class="docutils literal notranslate"><span class="pre">Profiler</span></code> object needs to be initialized after <code class="docutils literal notranslate"><span class="pre">set_context</span></code> is set.</p>
<blockquote>
<div><p>In multi-card training scene, <code class="docutils literal notranslate"><span class="pre">Profiler</span></code> object needs to be initialized after <code class="docutils literal notranslate"><span class="pre">set_auto_parallel_context</span></code>.</p>
<p>Only the output_path in parameters is working in GPU now.</p>
</div></blockquote>
</li>
<li><p>At the end of the training, <code class="docutils literal notranslate"><span class="pre">Profiler.analyse</span></code> should be called to finish profiling and generate the performance analysis results.</p></li>
</ul>
<p>The sample code is the same as that in the Ascend chip: <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.8/performance_profiling_ascend.html#preparing-the-training-script">https://www.mindspore.cn/mindinsight/docs/en/r1.8/performance_profiling_ascend.html#preparing-the-training-script</a>.</p>
<p>In GPU scenarios, users can customize the callback mode to collect performance data. Data preparation stage and data sinking mode do not support this mode.</p>
<p>The following is the example：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="k">class</span> <span class="nc">StopAtStep</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start_step</span><span class="p">,</span> <span class="n">stop_step</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StopAtStep</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_step</span> <span class="o">=</span> <span class="n">start_step</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_step</span> <span class="o">=</span> <span class="n">stop_step</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span> <span class="o">=</span> <span class="n">Profiler</span><span class="p">(</span><span class="n">start_profile</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">step_num</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span>
        <span class="k">if</span> <span class="n">step_num</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_step</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">step_num</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span>
        <span class="k">if</span> <span class="n">step_num</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_step</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
</pre></div>
</div>
<p>The code above is just an example. Users should implement callback by themselves.</p>
</section>
<section id="launching-mindinsight">
<h2>Launching MindInsight<a class="headerlink" href="#launching-mindinsight" title="Permalink to this headline"></a></h2>
<p>The MindInsight launch command can refer to <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.8/mindinsight_commands.html">MindInsight Commands</a>.</p>
</section>
<section id="training-performance">
<h2>Training Performance<a class="headerlink" href="#training-performance" title="Permalink to this headline"></a></h2>
<p>Users can access the Training Performance by selecting a specific training from the training list, and click the performance profiling link. And the Training Performance only supports operation analysis, Timeline Analysis, Step Trace Analysis and Data Preparation Analysis now, other modules will be published soon.</p>
<p><img alt="performance_overall.png" src="_images/performance_overall.png" /></p>
<p><em>Figure 1: Overall Performance</em></p>
<p>Figure 1 displays the overall performance of the training, including the overall data of Step Trace, Operator Performance, Data Preparation Performance and Timeline:</p>
<ul class="simple">
<li><p>Operator Performance: It will collect the average execution time of operators and operator types. The overall performance page will show the pie graph for different operator types.</p></li>
<li><p>Timeline: It will collect execution time for operations and CUDA activity. The tasks will be shown on the time axis. The overall performance page will show the statistics for tasks.</p></li>
<li><p>Step Trace: It will divide the training steps into several stages and collect execution time for each stage. The overall performance page will show the step trace graph.</p></li>
<li><p>Data Preparation Performance: It will analyse the performance of the data input stages. The overall performance page will show the number of steps that may be the bottleneck for these stages.</p></li>
</ul>
<p>Users can click the detail link to see the details of each components.</p>
<section id="operator-performance-analysis">
<h3>Operator Performance Analysis<a class="headerlink" href="#operator-performance-analysis" title="Permalink to this headline"></a></h3>
<section id="visual-analysis-of-operator-performance">
<h4>Visual Analysis of Operator Performance<a class="headerlink" href="#visual-analysis-of-operator-performance" title="Permalink to this headline"></a></h4>
<p>The operator performance analysis component is used to display the execution time of the operators (include GPU operator,CUDA kernel,HOSTCPU operator) when MindSpore is run.</p>
<p><img alt="gpu_op_ui_profiler.png" src="_images/gpu_op_ui_profiler.png" /></p>
<p><em>Figure 2: Statistics for Operator Types</em></p>
<p>Figure 2 displays the statistics for the operator types, including:</p>
<ul class="simple">
<li><p>Choose a pie or a bar graph to show the proportion time occupied by each operator type. The time of one operator type is calculated by accumulating the execution time of operators belong to this type.</p></li>
<li><p>Display top 20 operator types with the longest average execution time, show the proportion of total time and average execution time (ms) of each operator type.</p></li>
</ul>
<p>The bottom half of Figure 2 displays the statistics table for the operators’ details, including:</p>
<ul class="simple">
<li><p>Choose All: Display statistics for the operators, including operator position information, type, execution time, full scope time, etc. The table will be sorted by average execution time by default.</p></li>
<li><p>Choose Type: Display statistics for the operator types, including operator type name, execution time, execution frequency and proportion of total time, average execution time. Users can click on each line to query for all the operators belong to this type.</p></li>
<li><p>Search: There is a search box on the right, which supports fuzzy search for operators/operator types.</p></li>
</ul>
<p><img alt="gpu_activity_profiler.png" src="_images/gpu_activity_profiler.png" /></p>
<p><em>Figure 3: Statistics for Kernel Activities</em></p>
<p>Figure 3 displays the statistics for the Kernel, including:</p>
<ul class="simple">
<li><p>A pie graph to show the proportion time occupied by each kernel activity and the execution time of each kernel activity.</p></li>
<li><p>Kernel information list: information list includes information, such as activity name, operation name, execution frequency, total time, average time, and so on.</p></li>
<li><p>Search: performs fuzzy search through name (activity name)/<code class="docutils literal notranslate"><span class="pre">op_full_name</span></code> (name of the operator).</p></li>
</ul>
</section>
<section id="operator-interface-analysis">
<h4>Operator Interface Analysis<a class="headerlink" href="#operator-interface-analysis" title="Permalink to this headline"></a></h4>
<p>Users can query the performance data of the specified CUDA operator and HOSTCPU operator by using <code class="docutils literal notranslate"><span class="pre">profiler.op_analyze</span> <span class="pre">(op_name=&quot;XXX&quot;)</span></code> interface .The queried performance data is the operator execution side (<code class="docutils literal notranslate"><span class="pre">op_side</span></code>), execution times (<code class="docutils literal notranslate"><span class="pre">op_occurrences</span></code>), total operator execution time (<code class="docutils literal notranslate"><span class="pre">op_total_time(us)</span></code>) and average operator execution time (<code class="docutils literal notranslate"><span class="pre">op_avg_time(us)</span></code>) under different tensor input (<code class="docutils literal notranslate"><span class="pre">input_shape</span></code>). The data is in JSON format and can be quickly viewed by using the JSON parsing tool. The interface is used as follows:</p>
<p>Example 1:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="c1"># Profiler init.</span>
<span class="n">profiler</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Profiler</span><span class="p">()</span>
<span class="c1"># Train or eval model.</span>
<span class="n">train_net</span><span class="p">()</span>
<span class="n">profiler</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
<span class="n">operation_info</span> <span class="o">=</span> <span class="n">profiler</span><span class="o">.</span><span class="n">op_analyse</span><span class="p">(</span><span class="s1">&#39;Conv2D&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">operation_info</span><span class="p">)</span>  <span class="c1"># json</span>
</pre></div>
</div>
<p>Example 2:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="c1"># Profiler init.</span>
<span class="n">profiler</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Profiler</span><span class="p">(</span><span class="n">output_path</span><span class="o">=</span><span class="s2">&quot;my_profiler_path&quot;</span><span class="p">)</span>
<span class="n">operation_info</span> <span class="o">=</span> <span class="n">profiler</span><span class="o">.</span><span class="n">op_analyse</span><span class="p">([</span><span class="s1">&#39;Conv2D&#39;</span><span class="p">,</span> <span class="s1">&#39;BiasAdd&#39;</span><span class="p">])</span>  <span class="c1"># str or list</span>
<span class="nb">print</span><span class="p">(</span><span class="n">operation_info</span><span class="p">)</span>  <span class="c1"># json</span>
</pre></div>
</div>
<p>Description:</p>
<ul class="simple">
<li><p>The performance data obtained from the GPU platform by using this interface is CUDA kernel data. The performance data fields(<code class="docutils literal notranslate"><span class="pre">op_occurrences</span></code>, <code class="docutils literal notranslate"><span class="pre">op_total_time(us)</span></code>, <code class="docutils literal notranslate"><span class="pre">op_avg_time(us)</span></code>) data is derived from the (<code class="docutils literal notranslate"><span class="pre">occurrences(times)</span></code>, <code class="docutils literal notranslate"><span class="pre">total_duration(us)</span></code>, <code class="docutils literal notranslate"><span class="pre">avg_duration(us/time)</span></code>) information in the kernel information list shown in Figure 3. The difference is that CUDA operator performance data obtained by using the operator performance interface will be summarized according to the type of the operator(Primitive operator type) and distinguished according to the input tensor information of the operator. To view specific operator information, launch MindInsight to view detailed CUDA kernel performance data.</p></li>
<li><p>In heterogeneous scenarios, the CPU performance data fields (<code class="docutils literal notranslate"><span class="pre">op_occurrences</span></code>, <code class="docutils literal notranslate"><span class="pre">op_total_time(us)</span></code>, <code class="docutils literal notranslate"><span class="pre">op_avg_time(us)</span></code>) came from the information (<code class="docutils literal notranslate"><span class="pre">op_occurrences(times)</span></code>, <code class="docutils literal notranslate"><span class="pre">op_total_time(us)</span></code>, <code class="docutils literal notranslate"><span class="pre">op_avg_time(us/time)</span></code>) on the HOST CPU page. The difference is that the CPU operator performance data obtained by using the operator performance interface is summarized according to the type of the operator (Primitive operator type) and distinguished according to the input tensor information of the operator. To view specific operator information, launch MindInsight to view detailed CPU kernel performance data.</p></li>
<li><p>For the <code class="docutils literal notranslate"><span class="pre">op_analyse()</span></code> interface, the device_id parameter is used to specify which card’s operator performance data to parse, which defaults to <code class="docutils literal notranslate"><span class="pre">device_id=0</span></code> when the interface is parsing based on offline data.</p></li>
</ul>
</section>
</section>
<section id="timeline-analysis">
<h3>Timeline Analysis<a class="headerlink" href="#timeline-analysis" title="Permalink to this headline"></a></h3>
<p>The usage is almost the same as that in Ascend. The difference is GPU Timeline displays the operation information and CUDA activity.</p>
<p>The usage is described as follows:</p>
<p><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.8/performance_profiling_ascend.html#timeline-analysis">https://www.mindspore.cn/mindinsight/docs/en/r1.8/performance_profiling_ascend.html#timeline-analysis</a></p>
</section>
<section id="step-trace-analysis">
<h3>Step Trace Analysis<a class="headerlink" href="#step-trace-analysis" title="Permalink to this headline"></a></h3>
<p>The usage is almost the same as that in Ascend. (<strong>Note that step trace do not support heterogeneous training scene.</strong>)</p>
<p>The usage is described as follows:</p>
<p><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.8/performance_profiling_ascend.html#step-trace-analysis">https://www.mindspore.cn/mindinsight/docs/en/r1.8/performance_profiling_ascend.html#step-trace-analysis</a></p>
</section>
<section id="data-preparation-analysis">
<h3>Data Preparation Analysis<a class="headerlink" href="#data-preparation-analysis" title="Permalink to this headline"></a></h3>
<p>The usage is almost the same as that in Ascend.</p>
<p>The usage is described as follows:</p>
<p><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.8/performance_profiling_ascend.html#data-preparation-performance-analysis">https://www.mindspore.cn/mindinsight/docs/en/r1.8/performance_profiling_ascend.html#data-preparation-performance-analysis</a></p>
</section>
</section>
<section id="resource-utilization">
<h2>Resource Utilization<a class="headerlink" href="#resource-utilization" title="Permalink to this headline"></a></h2>
<p>Resource utilization includes cpu usage analysis.</p>
<p><img alt="resource_visibility_gpu.png" src="_images/resource_visibility_gpu.png" /></p>
<p><em>Figure 4：Overview of resource utilization</em></p>
<p>Overview of resource utilization：Including CPU utilization analysis. You can view the details by clicking the View Details button in the upper right corner.</p>
<section id="cpu-utilization-analysis">
<h3>CPU Utilization Analysis<a class="headerlink" href="#cpu-utilization-analysis" title="Permalink to this headline"></a></h3>
<p>The usage is almost the same as that in Ascend.</p>
<p>The usage is described as follows:</p>
<p><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.8/performance_profiling_ascend.html#cpu-utilization-analysis">https://www.mindspore.cn/mindinsight/docs/en/r1.8/performance_profiling_ascend.html#cpu-utilization-analysis</a></p>
</section>
</section>
<section id="notices">
<h2>Notices<a class="headerlink" href="#notices" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>Currently the performance debugging is not supported in PyNative mode.</p></li>
<li><p>Currently the training and inference process does not support performance debugging, and only the performance debugging for the individual training or inference is supported.</p></li>
<li><p>GPU does not support memory performance data collection.</p></li>
<li><p>To use performance debugging in GPU scenarios, you must use the root permission.</p></li>
<li><p>GPU performance debugging does not support dynamic Shape scenarios, multi-subgraph scenarios, and control flow scenarios.</p></li>
<li><p>Performance debugging in GPU scenarios depends on CUDA environment variables. Please <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">LD_LIBRARY_PATH=${CUDA_HOME}/extras/CUPTI/lib64:$LD_LIBRARY_PATH</span></code> before using Profiler. The CUDA_HOME needs to be replaced with the local CUDA path.</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="performance_profiling_ascend_pynative.html" class="btn btn-neutral float-left" title="Performance Profiling (Ascend-PyNative)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="performance_profiling_of_cluster.html" class="btn btn-neutral float-right" title="Cluster Performance Profiling" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>