<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>性能调试（Ascend） &mdash; MindSpore master 文档</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="next" title="性能调试（GPU）" href="performance_profiling_gpu.html" />
    <link rel="prev" title="性能调试" href="performance_profiling.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_install.html">安装MindSpore Insight</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">使用指南</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="summary_record.html">收集Summary数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="dashboard.html">查看训练看板</a></li>
<li class="toctree-l1"><a class="reference internal" href="lineage_and_scalars_comparison.html">查看溯源和对比看板</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrate_3rd_scripts_mindconverter.html">使用MindConverter迁移模型定义脚本</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="performance_profiling.html">性能调试</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">性能调试（Ascend）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#概述">概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#操作流程">操作流程</a></li>
<li class="toctree-l3"><a class="reference internal" href="#准备训练脚本">准备训练脚本</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#方式一-修改训练脚本">方式一：修改训练脚本</a></li>
<li class="toctree-l4"><a class="reference internal" href="#方式二-环境变量使能">方式二：环境变量使能</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#启动mindspore-insight">启动MindSpore Insight</a></li>
<li class="toctree-l3"><a class="reference internal" href="#训练性能">训练性能</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#迭代轨迹分析">迭代轨迹分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#算子性能分析">算子性能分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#计算量分析">计算量分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#数据准备性能分析">数据准备性能分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#timeline分析">Timeline分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#动态shape迭代分析">动态shape迭代分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#msprof工具辅助分析">Msprof工具辅助分析</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#host侧耗时分析">Host侧耗时分析</a></li>
<li class="toctree-l3"><a class="reference internal" href="#资源利用">资源利用</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#cpu利用率分析">CPU利用率分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#内存使用情况分析">内存使用情况分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#host侧内存使用情况">Host侧内存使用情况</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#离线解析">离线解析</a></li>
<li class="toctree-l3"><a class="reference internal" href="#规格">规格</a></li>
<li class="toctree-l3"><a class="reference internal" href="#注意事项">注意事项</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="performance_profiling_gpu.html">性能调试（GPU）</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_profiling_of_cluster.html">集群性能调试</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="debugger.html">调试器</a></li>
<li class="toctree-l1"><a class="reference internal" href="landscape.html">训练优化过程可视化</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_commands.html">MindSpore Insight相关命令</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">调优指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="accuracy_problem_preliminary_location.html">精度问题初步定位指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="accuracy_optimization.html">精度问题详细定位和调优指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning_guide.html">性能调优指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_optimization.html">性能调试案例</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight.debugger.html">mindinsight.debugger</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="training_visual_design.html">训练可视总体设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_visual_design.html">计算图可视设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_visual_design.html">张量可视设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler_design.html">性能调试设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="performance_profiling.html">性能调试</a> &raquo;</li>
      <li>性能调试（Ascend）</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/performance_profiling_ascend.rst.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="性能调试ascend">
<h1>性能调试（Ascend）<a class="headerlink" href="#性能调试ascend" title="永久链接至标题"></a></h1>
<a class="reference external image-reference" href="https://gitee.com/mindspore/docs/blob/master/docs/mindinsight/docs/source_zh_cn/performance_profiling_ascend.rst"><img alt="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.png" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.png" /></a>
<section id="概述">
<h2>概述<a class="headerlink" href="#概述" title="永久链接至标题"></a></h2>
<p>本教程介绍如何在Ascend AI处理器上使用MindSpore Profiler进行性能调试。</p>
</section>
<section id="操作流程">
<h2>操作流程<a class="headerlink" href="#操作流程" title="永久链接至标题"></a></h2>
<ul class="simple">
<li><p>准备训练脚本，并在训练脚本中调用性能调试接口，接着运行训练脚本。</p></li>
<li><p>启动MindSpore Insight，并通过启动参数指定summary-base-dir目录(summary-base-dir是Profiler所创建目录的父目录)，例如训练时Profiler创建的文件夹绝对路径为<code class="docutils literal notranslate"><span class="pre">/home/user/code/data</span></code>，则summary-base-dir设为<code class="docutils literal notranslate"><span class="pre">/home/user/code</span></code>。启动成功后，根据IP和端口访问可视化界面，默认访问地址为
<code class="docutils literal notranslate"><span class="pre">http://127.0.0.1:8080</span></code>。</p></li>
<li><p>在训练列表找到对应训练，点击性能分析，即可在页面中查看训练性能数据。</p></li>
</ul>
</section>
<section id="准备训练脚本">
<h2>准备训练脚本<a class="headerlink" href="#准备训练脚本" title="永久链接至标题"></a></h2>
<p>收集神经网络性能数据有两种方式，可以使用以下任意一种方式使能Profiler。</p>
<section id="方式一-修改训练脚本">
<h3>方式一：修改训练脚本<a class="headerlink" href="#方式一-修改训练脚本" title="永久链接至标题"></a></h3>
<p>在训练脚本中添加MindSpore Profiler相关接口。</p>
<ul>
<li><p>在训练开始前，初始化MindSpore <code class="docutils literal notranslate"><span class="pre">Profiler</span></code>对象，Profiler开启收集性能数据。</p>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>Profiler支持的参数可以参考：
<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/mindspore/mindspore.Profiler.html#mindspore.Profiler">Profiler API</a> 。
Profiler初始化之前需要确定device_id。</p>
</div>
</li>
<li><p>在训练结束后，调用<code class="docutils literal notranslate"><span class="pre">Profiler.analyse()</span></code>停止性能数据收集并生成性能分析结果。</p></li>
</ul>
<p><strong>按条件开启样例：</strong></p>
<p>用户可以通过设置初始化参数start_profile为False来决定暂时不开启Profiler，然后通过调用start函数来在适当的时机开启Profiler，再调用stop函数停止收集数据，最后调用analyse解析数据。
可以是基于epoch或者step开启和关闭Profiler，只收集指定step区间或者epoch区间的数据。基于step或者基于epoch性能数据的收集有两种方式，一种是用户自定义训练，另一种是借助Callback基于step或者epoch开启关闭Profiler。</p>
<ul>
<li><p>自定义训练：</p>
<p>MindSpore函数式编程用例使用Profiler进行自定义训练，可以在指定的step区间或者epoch区间开启或者关闭收集Profiler性能数据。<a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/sample_code/mindinsight/profiler/profiling_step.py">基于step开启Profiler完整代码样例</a>。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">profiler</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Profiler</span><span class="p">(</span><span class="n">start_profile</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">data_loader</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
    <span class="n">train</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">100</span><span class="p">:</span>
        <span class="n">profiler</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">200</span><span class="p">:</span>
        <span class="n">profiler</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

<span class="n">profiler</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
</pre></div>
</div>
</li>
<li><p>自定义Callback</p>
<ul>
<li><p>对于数据非下沉模式，只有在每个step结束后才有机会告知CANN开启和停止，因此需要基于step开启和关闭。
<a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/sample_code/mindinsight/profiler/profiling_feed_step.py">自定义Callback基于step开启Profiler完整代码样例</a>。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="k">class</span> <span class="nc">StopAtStep</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start_step</span><span class="p">,</span> <span class="n">stop_step</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StopAtStep</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_step</span> <span class="o">=</span> <span class="n">start_step</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_step</span> <span class="o">=</span> <span class="n">stop_step</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Profiler</span><span class="p">(</span><span class="n">start_profile</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s1">&#39;./data_step&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">step_num</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span>
        <span class="k">if</span> <span class="n">step_num</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_step</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_train_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">step_num</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span>
        <span class="k">if</span> <span class="n">step_num</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_step</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
</pre></div>
</div>
</li>
<li><p>对于数据下沉模式，只有在每个epoch结束后才有机会告知CANN开启和停止，因此需要基于epoch开启和关闭。可根据自定义Callback基于step开启Profiler样例代码修改训练脚本。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">StopAtEpoch</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start_epoch</span><span class="p">,</span> <span class="n">stop_epoch</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StopAtEpoch</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span> <span class="o">=</span> <span class="n">start_epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_epoch</span> <span class="o">=</span> <span class="n">stop_epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Profiler</span><span class="p">(</span><span class="n">start_profile</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s1">&#39;./data_epoch&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">epoch_num</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span>
        <span class="k">if</span> <span class="n">epoch_num</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">epoch_num</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span>
        <span class="k">if</span> <span class="n">epoch_num</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_epoch</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
<p><strong>非条件开启样例：</strong></p>
<ul>
<li><p>样例一：MindSpore函数式编程用例中使用Profiler收集性能数据，部分样例代码如下所示。<a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/sample_code/mindinsight/profiler/profiling_sample.py">完整代码样例</a> 。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Init Profiler.</span>
<span class="c1"># Note that the Profiler should be initialized before model training.</span>
<span class="n">profiler</span> <span class="o">=</span> <span class="n">Profiler</span><span class="p">(</span><span class="n">output_path</span><span class="o">=</span><span class="s2">&quot;profiler_data&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">forward_fn</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">logits</span>


<span class="c1"># Get gradient function</span>
<span class="n">grad_fn</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">forward_fn</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="nd">@ms</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Define function of one-step training&quot;&quot;&quot;</span>
    <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">_</span><span class="p">),</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">grad_fn</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>


<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">train_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>

<span class="n">profiler</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
</pre></div>
</div>
</li>
<li><p>样例二：使用model.train进行网络训练，完整代码如下所示。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">generator</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">yield</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">net</span><span class="p">):</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">])</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>

    <span class="c1"># Init Profiler</span>
    <span class="c1"># Note that the Profiler should be initialized before model.train</span>
    <span class="n">profiler</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Profiler</span><span class="p">(</span><span class="n">output_path</span><span class="o">=</span><span class="s1">&#39;./profiler_data&#39;</span><span class="p">)</span>

    <span class="c1"># Train Model</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="n">train</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

    <span class="c1"># Profiler end</span>
    <span class="n">profiler</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="方式二-环境变量使能">
<h3>方式二：环境变量使能<a class="headerlink" href="#方式二-环境变量使能" title="永久链接至标题"></a></h3>
<p>在运行网络脚本前，配置Profiler相关配置项。</p>
<p>说明：</p>
<ul class="simple">
<li><p>该功能尚未支持Ascend 910B芯片场景，敬请期待。</p></li>
<li><p>使用环境变量使能方式，请在脚本开始执行之前通过环境变量设置好device id。禁止在脚本中通过set_context函数设置device id。</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MS_PROFILER_OPTIONS</span><span class="o">=</span><span class="s1">&#39;{&quot;start&quot;: true, &quot;output_path&quot;: &quot;/XXX&quot;, &quot;profile_memory&quot;: false, &quot;profile_communication&quot;: false, &quot;aicore_metrics&quot;: 0, &quot;l2_cache&quot;: false}&#39;</span>
</pre></div>
</div>
<ul class="simple">
<li><p><cite>start</cite> (bool，必选) - 设置为true，表示使能Profiler；设置成false，表示关闭性能数据收集，默认值：false。</p></li>
<li><p><cite>output_path</cite> (str, 可选) - 表示输出数据的路径（绝对路径）。默认值：”./data”。</p></li>
<li><p><cite>op_time</cite> (bool, 可选) - 表示是否收集算子性能数据，默认值：true。</p></li>
<li><p><cite>profile_memory</cite> (bool，可选) - 表示是否收集Tensor内存数据。当值为true时，收集这些数据。使用此参数时，<cite>op_time</cite> 必须设置成true。默认值：false。</p></li>
<li><p><cite>profile_communication</cite> (bool, 可选) - 表示是否在多设备训练中收集通信性能数据。当值为true时，收集这些数据。在单台设备训练中，该参数的设置无效。使用此参数时，<cite>op_time</cite> 必须设置成true。默认值：false。</p></li>
<li><p><cite>aicore_metrics</cite> (int, 可选) - 设置AI Core指标类型，使用此参数时，<cite>op_time</cite> 必须设置成true。默认值：0。</p></li>
<li><p><cite>l2_cache</cite> (bool, 可选) - 设置是否收集l2缓存数据，默认值：false。</p></li>
<li><p><cite>timeline_limit</cite> (int, 可选) - 设置限制timeline文件存储上限大小（单位M），使用此参数时，<cite>op_time</cite> 必须设置成true。默认值：500。</p></li>
<li><p><cite>data_process</cite> (bool, 可选) - 表示是否收集数据准备性能数据，默认值：true。</p></li>
<li><p><cite>parallel_strategy</cite> (bool, 可选) - 表示是否收集并行策略性能数据， 默认值：true。</p></li>
<li><p><cite>profile_framework</cite> (str, 可选) - 是否需要收集Host侧的内存和时间，可选参数为[“all”, “time”, “memory”, null]。默认值：”all”。</p></li>
</ul>
</section>
</section>
<section id="启动mindspore-insight">
<h2>启动MindSpore Insight<a class="headerlink" href="#启动mindspore-insight" title="永久链接至标题"></a></h2>
<p>启动命令请参考：
<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/master/mindinsight_commands.html">MindSpore Insight相关命令</a> 。</p>
</section>
<section id="训练性能">
<h2>训练性能<a class="headerlink" href="#训练性能" title="永久链接至标题"></a></h2>
<p>用户从训练列表中选择指定的训练，点击性能调试，可以查看该次训练的性能数据。</p>
<figure class="align-default">
<img alt="performance_overall.png" src="_images/performance_overall.png" />
</figure>
<p><em>图：性能数据总览</em></p>
<p>上图展示了性能数据总览页面，包含了迭代轨迹（Step
Trace）、算子性能、数据准备性能和Timeline等组件的数据总体呈现。各组件展示的数据如下：</p>
<ul class="simple">
<li><p>迭代轨迹：将训练step划分为几个阶段，统计每个阶段的耗时，按时间线进行展示；总览页展示了迭代轨迹图。</p></li>
<li><p>算子性能：统计单算子以及各算子类型的执行时间，进行排序展示；总览页中展示了各算子类型时间占比的饼状图。</p></li>
<li><p>数据准备性能：统计训练数据准备各阶段的性能情况；总览页中展示了各阶段性能可能存在瓶颈的step数目。</p></li>
<li><p>Timeline：按设备统计每个stream中task的耗时情况，在时间轴排列展示；总览页展示了Timeline中stream和task的汇总情况。</p></li>
</ul>
<p>用户可以点击查看详情链接，进入某个组件页面进行详细分析。MindSpore Insight也会对性能数据进行分析，在左侧的智能小助手中给出性能调试的建议。</p>
<section id="迭代轨迹分析">
<h3>迭代轨迹分析<a class="headerlink" href="#迭代轨迹分析" title="永久链接至标题"></a></h3>
<p>使用迭代轨迹分析组件可以快速了解训练各阶段在总时长中的占比情况。迭代轨迹将训练的一个step划分为迭代间隙
(两次step执行的间隔时间)、前向与反向执行、all
reduce、参数更新等几个阶段，并显示出每个阶段的时长，帮助用户定界出性能瓶颈所在的执行阶段。</p>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>迭代轨迹目前仅支持Graph模式单图场景，暂不支持PyNative、异构、多子图等场景。</p>
</div>
<figure class="align-default">
<img alt="step_trace.png" src="_images/step_trace.png" />
</figure>
<p><em>图：迭代轨迹分析</em></p>
<p>上图展示了迭代轨迹分析页面。在迭代轨迹详情中，会展示各阶段在训练step中的起止时间，默认显示的是各step的平均值，用户也可以在下拉菜单选择某个step查看该step的迭代轨迹情况。</p>
<p>页面下方显示了迭代间隙、前后向计算、迭代拖尾时间随着step的变化曲线等，用户可以据此判断某个阶段是否存在性能优化空间。其中：</p>
<ul class="simple">
<li><p><strong>迭代间隙：</strong>
主要负责从数据队列中读取数据，如果该部分耗时较长，建议前往数据准备部分进一步分析。</p></li>
<li><p><strong>前后向计算：</strong>
执行网络中的前向算子以及反向算子，承载了一个step主要的计算工作，如果该部分耗时较长，建议前往算子统计或时间线中进一步分析。</p></li>
<li><p><strong>迭代拖尾：</strong>
主要在多卡场景下执行参数聚合、参数更新操作，包括前后向计算结束到参数更新完成的时间。如果该部分耗时较长，建议查看<code class="docutils literal notranslate"><span class="pre">all_reduce</span></code>耗时以及并行情况。</p></li>
</ul>
<div class="line-block">
<div class="line">迭代轨迹在做阶段划分时，需要识别前向计算开始的算子和反向计算结束的算子。为了降低用户使用Profiler的门槛，MindSpore会对这两个算子做自动识别，方法为：</div>
<div class="line">前向计算开始的算子指定为<code class="docutils literal notranslate"><span class="pre">get_next</span></code>算子之后连接的第一个算子，反向计算结束的算子指定为最后一次all
reduce之前连接的算子。<strong>Profiler不保证在所有情况下自动识别的结果和用户的预期一致，用户可以根据网络的特点自行调整</strong>，调整方法如下：</div>
</div>
<ul class="simple">
<li><p>设置<code class="docutils literal notranslate"><span class="pre">PROFILING_FP_START</span></code>环境变量指定前向计算开始的算子，如<code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">PROFILING_FP_START=fp32_vars/conv2d/BatchNorm</span></code>。</p></li>
<li><p>设置<code class="docutils literal notranslate"><span class="pre">PROFILING_BP_END</span></code>环境变量指定反向计算结束的算子，如<code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">PROFILING_BP_END=loss_scale/gradients/AddN_70</span></code>。</p></li>
</ul>
</section>
<section id="算子性能分析">
<h3>算子性能分析<a class="headerlink" href="#算子性能分析" title="永久链接至标题"></a></h3>
<p>使用算子性能分析组件可以对MindSpore运行过程中的各个算子的执行时间进行统计展示(包括AICORE、AICPU、HOSTCPU算子)。</p>
<ul class="simple">
<li><p>AICORE算子：AI Core 算子是昇腾 AI
处理器计算核心的主要构成，负责执行向量和张量相关的计算密集型算子。TBE（Tensor
Boost Engine）是一种在TVM（Tensor Virtual
Machine）框架基础上扩展的算子开发工具，用户可使用 TBE 进行 AI Core
算子信息注册。</p></li>
<li><p>AICPU算子：AI CPU算子是AI CPU负责执行昇腾处理器中海思 SoC
的CPU类算子（包括控制算子、标量和向量等通用计算）。MindSpore中同一个算子可能会同时拥有
AI Core 算子和AI CPU算子，框架会优先选择 AI Core 算子，没有 AI Core
算子或者不满足选择的场景下，会调用AI CPU算子。</p></li>
<li><p>HOSTCPU算子：Host侧CPU主要负责将图或者算子下发到昇腾芯片，根据实际需求也可以在Host侧CPU上开发算子。HOSTCPU算子特指运行在Host侧CPU上的算子。</p></li>
</ul>
<figure class="align-default">
<img alt="op_type_statistics.png" src="_images/op_type_statistics.PNG" />
</figure>
<p><em>图：算子类别统计分析</em></p>
<p>上图展示了按算子类别进行统计分析的结果，包含以下内容：</p>
<ul class="simple">
<li><p>可以选择饼图/柱状图展示各算子类别的时间占比，每个算子类别的执行时间会统计属于该类别的算子执行时间总和。</p></li>
<li><p>统计前20个占比时间最长的算子类别，展示其时间所占的百分比以及具体的执行时间（微秒）。</p></li>
</ul>
<figure class="align-default">
<img alt="op_statistics.png" src="_images/op_statistics.PNG" />
</figure>
<p><em>图：算子统计分析</em></p>
<p>上图展示了算子性能统计表，包含以下内容：</p>
<ul class="simple">
<li><p>选择全部：按单个算子的统计结果进行排序展示，展示维度包括算子名称、算子类型、算子执行平均时间、算子执行频次、算子全称、算子信息等；默认按算子执行时间排序。</p></li>
<li><p>选择分类：按算子类别的统计结果进行排序展示，展示维度包括算子分类名称、算子类别执行时间、执行频次、占总时间的比例等。点击每个算子类别，可以进一步查看该类别下所有单个算子的统计信息。</p></li>
<li><p>搜索：在右侧搜索框中输入字符串，支持对算子名称/类别进行模糊搜索。</p></li>
</ul>
</section>
<section id="计算量分析">
<h3>计算量分析<a class="headerlink" href="#计算量分析" title="永久链接至标题"></a></h3>
<p>计算量分析模块可展示实际计算量相关数据，包括算子粒度、模型粒度的计算量数据。实际计算量是指在设备上运行时的计算量，区别于理论计算量，例如Ascend910设备上矩阵运算单元处理的是16x16大小的矩阵，所以实际运行时会对原始数据做补齐到16等操作。
目前仅支持AICORE设备上的计算量统计。计算量相关数据包括如下四个指标：</p>
<ul class="simple">
<li><p>FLOPs(cube)：cube浮点运算次数，单位为M（10^6次）。</p></li>
<li><p>FLOPS(cube)：cube每秒浮点运算次数，单位为G/秒（10^9次/秒）。</p></li>
<li><p>FLOPs(vec)：vector浮点运算次数，单位为M（10^6次）。</p></li>
<li><p>FLOPS(vec)：vector每秒浮点运算次数，单位为G/秒（10^9次/秒）。</p></li>
</ul>
<figure class="align-default">
<img alt="flops_statistics.png" src="_images/flops-single-card.png" />
</figure>
<p><em>图：计算量统计分析</em></p>
<p>上图的红框中包括了算子粒度、模型粒度的计算量数据。</p>
</section>
<section id="数据准备性能分析">
<h3>数据准备性能分析<a class="headerlink" href="#数据准备性能分析" title="永久链接至标题"></a></h3>
<p>使用数据准备性能分析组件可以对训练数据准备过程进行性能分析。数据准备过程可以分为三个阶段：数据处理pipeline、数据发送至Device以及Device侧读取训练数据。数据准备性能分析组件会对每个阶段的处理性能进行详细分析，并将分析结果进行展示。</p>
<figure class="align-default">
<img alt="minddata_profile.png" src="_images/data_profile.png" />
</figure>
<p><em>图：数据准备性能分析</em></p>
<p>上图展示了数据准备性能分析页面，包含迭代间隙、数据处理两个TAB页面。</p>
<p>迭代间隙TAB页主要用来分析数据准备三个阶段是否存在性能瓶颈，数据队列图是分析判断的重要依据：</p>
<ul class="simple">
<li><p>数据队列Size代表Device侧从队列取数据时队列的长度，如果数据队列Size为0，则训练会一直等待，直到队列中有数据才会开始某个step的训练；如果数据队列Size大于0，则训练可以快速取到数据，数据准备不是该step的瓶颈所在。</p></li>
<li><p>主机队列Size可以推断出数据处理和发送速度，如果主机队列Size为0，表示数据处理速度慢而数据发送速度快，需要加快数据处理。</p></li>
<li><p>如果主机队列Size一直较大，而数据队列的Size持续很小，则数据发送有可能存在性能瓶颈。</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>队列Size是取数据的时候记录的值，获取主机队列和数据队列数据是都异步执行，因此主机队列step数、数据队列step数、用户训练的step数都可能不一样。</p>
</div>
<figure class="align-default">
<img alt="data_op_profile.png" src="_images/data_op_profile.png" />
</figure>
<p><em>图：数据处理pipeline分析</em></p>
<p>上图展示了数据处理TAB页面，可以对数据处理pipeline做进一步分析。不同的数据操作之间使用队列进行数据交换，队列的长度可以反映出操作处理数据的快慢，进而推断出pipeline中的瓶颈操作所在。</p>
<p>算子队列的平均使用率代表队列中已有数据Size除以队列最大数据Size的平均值，使用率越高说明队列中数据积累越多。算子队列关系展示了数据处理pipeline中的操作以及它们之间的连接情况，点击某个队列可以在下方查看该队列中数据Size随着时间的变化曲线，以及与数据队列连接的操作信息等。对数据处理pipeline的分析有如下建议：</p>
<ul class="simple">
<li><p>当操作左边连接的Queue使用率都比较高，右边连接的Queue使用率比较低，该操作可能是性能瓶颈。</p></li>
<li><p>对于最左侧的操作，如果其右边所有Queue的使用率都比较低，该操作可能是性能瓶颈。</p></li>
<li><p>对于最右侧的操作，如果其左边所有Queue的使用率都比较高，该操作可能是性能瓶颈。</p></li>
</ul>
<p>对于不同的类型的数据处理操作，有如下优化建议：</p>
<ul class="simple">
<li><p>如果Dataset加载操作是性能瓶颈，建议增加<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>。</p></li>
<li><p>如果GeneratorOp操作是性能瓶颈，建议增加<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>，并尝试将其替换为<code class="docutils literal notranslate"><span class="pre">MindRecordDataset</span></code>。</p></li>
<li><p>如果MapOp操作是性能瓶颈，建议增加<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>，如果其映射的是Python数据处理操作，可以尝试优化脚本。</p></li>
<li><p>如果BatchOp操作是性能瓶颈，建议调整<code class="docutils literal notranslate"><span class="pre">prefetch_size</span></code>的大小。</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>获取数据准备性能数据，需要使用MindSpore Dataset模块定义数据预处理pipeline。</p>
</div>
</section>
<section id="timeline分析">
<h3>Timeline分析<a class="headerlink" href="#timeline分析" title="永久链接至标题"></a></h3>
<p>Timeline组件可以展示：</p>
<ul class="simple">
<li><p>算子分配到哪个设备（AICPU、AICORE、HOSTCPU）执行。</p></li>
<li><p>MindSpore对该网络的流切分策略。</p></li>
<li><p>算子在Device上的执行序列和执行时长。</p></li>
<li><p>训练的Step数（暂不支持动态Shape场景、多图场景和异构训练场景，这些场景下Step数据可能不准确）。</p></li>
<li><p>算子的<code class="docutils literal notranslate"><span class="pre">Scope</span> <span class="pre">Name</span></code>信息，可以选择展示多少层<code class="docutils literal notranslate"><span class="pre">Scope</span> <span class="pre">Name</span></code>信息并下载对应的timeline文件。例如某算子的全名为：<code class="docutils literal notranslate"><span class="pre">Default/network/lenet5/Conv2D-op11</span></code>，则该算子的第一层Scope
Name为<code class="docutils literal notranslate"><span class="pre">Default</span></code>、第二层为<code class="docutils literal notranslate"><span class="pre">network</span></code>。如果选择展示两层<code class="docutils literal notranslate"><span class="pre">Scope</span> <span class="pre">Name</span></code>信息，则会展示<code class="docutils literal notranslate"><span class="pre">Default</span></code>和<code class="docutils literal notranslate"><span class="pre">network</span></code>。</p></li>
</ul>
<p>通过分析Timeline，用户可以对训练过程进行细粒度分析：</p>
<ul class="simple">
<li><p>从High Level层面，可以分析流切分方法是否合理、迭代间隙和拖尾时间是否过长等。</p></li>
<li><p>从Low Level层面，可以分析算子执行时间等。</p></li>
</ul>
<p>用户可以点击总览页面Timeline部分的下载按钮，将Timeline数据文件
(json格式) 保存至本地，再通过工具查看Timeline的详细信息。推荐使用
<code class="docutils literal notranslate"><span class="pre">chrome://tracing</span></code> 或者 <a class="reference external" href="https://ui.perfetto.dev/#!/">Perfetto</a>
做Timeline展示。</p>
<ul class="simple">
<li><p>Chrome tracing：点击左上角“load”加载文件。</p></li>
<li><p>Perfetto：点击左侧“Open trace file”加载文件。</p></li>
</ul>
<figure class="align-default">
<img alt="timeline.png" src="_images/timeline.png" />
</figure>
<p><em>图：Timeline分析</em></p>
<p>Timeline主要包含如下几个部分：</p>
<ul>
<li><p>Device及其stream
list：包含Device上的stream列表，每个stream由task执行序列组成，一个task是其中的一个小方块，大小代表执行时间长短。</p>
<p>各个颜色块表示算子执行的起始时间及时长。timeline的详细解释如下：</p>
<ul class="simple">
<li><p>Process AI Core Op：包含在AI Core上执行的算子的时间线。</p>
<ul>
<li><p>Step：训练迭代数。</p></li>
<li><p>Scope Name：算子的Scope Name。</p></li>
<li><p>Stream #ID：在该stream上执行的算子。</p></li>
</ul>
</li>
<li><p>Process AI CPU Op：在AI CPU上执行的算子的时间线。</p></li>
<li><p>Process Communication Op：包含通信算子执行的时间线。</p></li>
<li><p>Process Host CPU Op：在Host CPU上执行的算子的时间线。</p></li>
<li><p>Process Op Overlap
Analyse：所有计算算子与通信算子合并后的时间线，可用于分析通信时间占比。</p>
<ul>
<li><p>Merged Computation Op：为所有计算（AI Core、AI CPU、Host
CPU）算子合并后的时间线。</p></li>
<li><p>Merged Communication Op：为所有通信算子合并后的时间线。</p></li>
<li><p>Pure Communication
Op：纯通信时间（通信算子的执行时间去除与计算算子时间重叠部分后的时间线）。</p></li>
<li><p>Free
Time：空闲时间（既没有通信算子也没有计算算子在执行的时间线）。</p></li>
</ul>
</li>
</ul>
</li>
<li><p>算子信息：选中某个task后，可以显示该task对应算子的信息，包括名称、type等。</p></li>
</ul>
<p>可以使用W/A/S/D来放大、缩小地查看Timeline图信息。</p>
</section>
<section id="动态shape迭代分析">
<h3>动态shape迭代分析<a class="headerlink" href="#动态shape迭代分析" title="永久链接至标题"></a></h3>
<p>当训练网络为动态shape网络时，使用算子耗时（按迭代）组件可以对MindSpore运行过程中各个算子的执行时间进行统计展示（包括AICPU算子、AICORE算子），可以快速了解训练各迭代中各算子耗时的波动情况以及算子在不同的迭代中的shape信息。</p>
<figure class="align-default">
<img alt="dynamic_shape_summary.png" src="_images/dynamic_shape_summary.png" />
</figure>
<p><em>图：算子耗时（按迭代）统计</em></p>
<p>上图展示了不同类型算子的迭代耗时分析详情，可通过筛选指定算子类型，查看指定类型的算子的迭代耗时曲线（这里展示的耗时是不同算子类型执行的平均耗时）。</p>
<figure class="align-default">
<img alt="dynamic_shape_detail.png" src="_images/dynamic_shape_detail.png" />
</figure>
<p><em>图：算子耗时详情（按迭代）统计</em></p>
<p>上图展示了不同算子实例的迭代耗时分析详情，通过筛选指定算子名称，查看指定算子实例的迭代耗时曲线。</p>
<figure class="align-default">
<img alt="dynamic_shape_info.png" src="_images/dynamic_shape_info.png" />
</figure>
<p><em>图：算子shape信息（按迭代）</em></p>
<p>上图展示了特定step的算子shape信息，可点击曲线的对应点来查看指定算子实例的shape信息。</p>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>动态shape网络目前仅支持算子耗时（按迭代）、算子耗时统计排名、数据准备、时间线、CPU资源利用以及并行策略功能模块，暂不支持迭代轨迹、内存使用、集群通信功能。</p>
</div>
</section>
<section id="msprof工具辅助分析">
<h3>Msprof工具辅助分析<a class="headerlink" href="#msprof工具辅助分析" title="永久链接至标题"></a></h3>
<p>用户可以通过profiler收集aicore详细数据，然后通过Msprof工具进行解析查看。</p>
<p>样例代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">profiler</span> <span class="o">=</span> <span class="n">Profiler</span><span class="p">(</span><span class="n">output_path</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">aicore_metrics</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">l2_cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>aicore_metrics设置AI Core指标类型，l2_cache设置是否收集l2缓存数据，参数说明请参考API文档。</p>
<p>MindSpore Profiler支持通过Msprof命令行方式采集网络性能数据，关于Msprof工具采集与解析的使用方法及性能数据说明请参见 <code class="docutils literal notranslate"><span class="pre">CANN</span> <span class="pre">开发工具指南</span></code> 文档的 <a class="reference external" href="https://support.huawei.com/enterprise/zh/doc/EDOC1100234052/2c2140b0">Profiling工具使用指南（训练）</a> 章节。</p>
</section>
</section>
<section id="host侧耗时分析">
<h2>Host侧耗时分析<a class="headerlink" href="#host侧耗时分析" title="永久链接至标题"></a></h2>
<p>如果开启了Host侧时间收集功能，在训练结束后可以在指定目录下查看各阶段的Host侧耗时情况。例如，Profiler实例化时，指定output_path=”/XXX/profiler_output”，Host侧耗时数据会保存在”/XXX/profiler_output/profiler/host_info”目录下，文件格式为json，前缀为timeline_，后缀为rank_id。Host侧耗时文件可以用 <code class="docutils literal notranslate"><span class="pre">chrome://tracing</span></code> 来展示。可以使用W/S/A/D来放大、缩小、左移、右移地查看耗时信息。</p>
</section>
<section id="资源利用">
<h2>资源利用<a class="headerlink" href="#资源利用" title="永久链接至标题"></a></h2>
<p>资源利用包括CPU利用率和内存使用情况分析。</p>
<figure class="align-default">
<img alt="resource_visibility.png" src="_images/resource_visibility.png" />
</figure>
<p><em>图：资源利用总览</em></p>
<p>上图展示了资源利用总览页面，包括CPU利用率分析与内存使用情况分析。通过点击右上角的<code class="docutils literal notranslate"><span class="pre">查看详情</span></code>按钮可以查看详细信息。</p>
<section id="cpu利用率分析">
<h3>CPU利用率分析<a class="headerlink" href="#cpu利用率分析" title="永久链接至标题"></a></h3>
<p>CPU利用率分析，主要起到辅助性能调试的作用。根据Queue
size确定了性能瓶颈后，可以根据CPU利用率辅助对性能进行调试（用户利用率过低，增加线程数；系统利用率过大，减小线程数）。
CPU利用率包含整机CPU利用率、进程CPU利用率、Data pipeline操作CPU利用率。</p>
<figure class="align-default">
<img alt="device_cpu_utilization.png" src="_images/device_cpu_utilization.png" />
</figure>
<p><em>图：整机CPU利用率</em></p>
<p>整机CPU利用率：展示设备在训练过程中整体的CPU使用情况，包含用户利用率、系统利用率、空闲利用率、IO利用率、当前活跃进程数、上下文切换次数。如果用户利用率较低，可以尝试增大操作线程数，增加CPU使用情况；如果系统利用率较大，同时上下文切换次数、CPU等待处理的进程较大，说明需要相应减少线程个数。</p>
<figure class="align-default">
<img alt="process_cpu_utilization.png" src="_images/process_cpu_utilizaton.png" />
</figure>
<p><em>图：进程利用率</em></p>
<p>进程利用率：展示单个进程的CPU占用情况。整机利用率和进程利用率结合，可以确定训练过程中是否有其他进程影响训练。</p>
<figure class="align-default">
<img alt="data_op_cpu_utilization.png" src="_images/data_op_utilization.png" />
</figure>
<p><em>图：算子利用率</em></p>
<p>算子利用率：展示Data
pipeline单个操作占用的CPU利用率。可以根据实际情况，调整对应操作的线程数。如果线程数不大，占用CPU较多，可以考虑优化代码。</p>
<p>CPU利用率常用场景:</p>
<ul class="simple">
<li><p>网络调试人员根据Queue
size判断是Data性能有瓶颈，可以结合整机利用率和算子利用率作为辅助尝试调整线程数。</p></li>
<li><p>开发人员可以查看算子利用率，如果某一个操作比较耗CPU利用率，可以考虑优化该操作。</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>默认采样间隔为1000ms，用户可以通过<code class="docutils literal notranslate"><span class="pre">mindspore.dataset.config.get_monitor_sampling_interval()</span></code>来改变采样间隔。详情参考：
<a class="reference external" href="https://mindspore.cn/docs/zh-CN/master/api_python/dataset/mindspore.dataset.config.set_monitor_sampling_interval.html#mindspore.dataset.config.set_monitor_sampling_interval">dataset API sampling interval</a> 。</p>
</div>
</section>
<section id="内存使用情况分析">
<h3>内存使用情况分析<a class="headerlink" href="#内存使用情况分析" title="永久链接至标题"></a></h3>
<p>该页面用于展示模型在<strong>Device侧</strong>的内存使用情况，是<strong>基于理论值的理想预估</strong>。页面内容包括：</p>
<ul class="simple">
<li><p>模型的内存分配概览，包括总可用内存、峰值内存等信息。</p></li>
<li><p>模型运行过程中，占用内存大小随执行顺序的变化。</p></li>
<li><p>模型运行过程中，每个执行算子的内存使用分解情况。</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>内存使用情况分析暂不支持异构训练场景。</p>
</div>
<figure class="align-default">
<img alt="memory.png" src="_images/memory.png" />
</figure>
<p><em>图：内存使用情况页面</em></p>
<p>用户可以结合<code class="docutils literal notranslate"><span class="pre">内存分配概览</span></code>提供的信息以及折线图的变化趋势来了解内存使用的大致情况，除此之外，从折线图里还可以获得更多细节信息，包括：</p>
<ul class="simple">
<li><p>局部缩放：折线图下方有缩放滚动条，用户可以通过调节其大小对折线图进行放大或缩小，以便观察细节。</p></li>
<li><p>前向开始和反向结束位置：通常情况下，用户可以在折线图上观察到模型的前向开始和反向结束的执行位置。</p></li>
<li><p>执行算子信息：鼠标悬浮在折线图上的某处，可以看到对应位置的执行算子信息，包括算子执行顺序编号、算子名称、算子占用内存、模型在当前位置占用的总内存，以及与前一执行位置的相对内存变化。</p></li>
<li><p>算子内存分配情况：鼠标点击折线图上的某一位置，位于折线图下方的<code class="docutils literal notranslate"><span class="pre">算子内存分配</span></code>模块会将该执行位置的内存使用分解情况展示出来。<code class="docutils literal notranslate"><span class="pre">算子内存分配</span></code>模块展示了对应执行位置的内存分解情况，也即，当前执行位置的已占用内存分配给了哪些算子的输出张量。该模块给用户提供了更丰富的信息，包括张量名称、张量大小、张量类型、数据类型、形状、格式，以及张量内存活跃的生命周期。</p></li>
</ul>
<figure class="align-default">
<img alt="memory_graphics.png" src="_images/memory_graphics.png" />
</figure>
<p><em>图：内存使用折线图</em></p>
</section>
<section id="host侧内存使用情况">
<h3>Host侧内存使用情况<a class="headerlink" href="#host侧内存使用情况" title="永久链接至标题"></a></h3>
<p>如果开启了Host侧内存收集功能，在训练结束后可以在指定目录下查看内存使用情况。例如，Profiler实例化时，指定output_path=”/XXX/profiler_output”，Host侧内存数据会保存在”/XXX/profiler_output/profiler/host_info”目录下，文件格式为csv，前缀为host_memory_，后缀为rank_id。表头的含义如下：</p>
<ul class="simple">
<li><p>tid：收集Host侧内存时当前线程的线程号。</p></li>
<li><p>pid：收集Host侧内存时当前进程的进程号。</p></li>
<li><p>parent_pid：收集Host侧内存时当前进程的父进程的进程号。</p></li>
<li><p>module_name：收集Host侧内存的组件名，一个组件包含一个或多个event。</p></li>
<li><p>event：收集Host侧内存的事件名，一个event包含一个或多个stage。</p></li>
<li><p>stage：收集Host侧内存的阶段名。</p></li>
<li><p>level：0表示框架开发者使用，1表示用户（算法工程师）使用。</p></li>
<li><p>start_end：stage开始或结束的标记，0表示开始标记，1表示结束标记，2表示不区分开始或结束。</p></li>
<li><p>custom_info：框架开发者用于定位性能问题的组件自定义信息，可能为空。</p></li>
<li><p>memory_usage：Host侧内存占用，单位为kB，0表示当前阶段没有收集内存数据。</p></li>
<li><p>time_stamp：时间戳，单位为us。</p></li>
</ul>
</section>
</section>
<section id="离线解析">
<h2>离线解析<a class="headerlink" href="#离线解析" title="永久链接至标题"></a></h2>
<p>当训练进程出错导致异常退出时，性能文件不能被完全保存下来，Profiler提供了离线解析功能。目前离线解析仅支持解析Host侧内存和Host侧耗时。</p>
<p>例如，训练脚本的部分代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="o">...</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">net</span><span class="p">):</span>
    <span class="o">...</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>

    <span class="c1"># Init Profiler</span>
    <span class="c1"># Note that the Profiler should be initialized before model.train</span>
    <span class="n">profiler</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Profiler</span><span class="p">(</span><span class="n">output_path</span><span class="o">=</span><span class="s1">&#39;/path/to/profiler_data&#39;</span><span class="p">)</span>

    <span class="c1"># Train Model</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="n">train</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>  <span class="c1"># Error occur.</span>

    <span class="c1"># Profiler end</span>
    <span class="n">profiler</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
</pre></div>
</div>
<p>假如上述代码在训练过程中出现异常，导致没有执行到最后一行的profiler.analyse()，那么性能数据就不会被完全解析。这时可以用离线接口来解析数据，示例代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Profiler</span>

<span class="n">profiler</span> <span class="o">=</span> <span class="n">Profiler</span><span class="p">(</span><span class="n">start_profile</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">profiler</span><span class="o">.</span><span class="n">analyse</span><span class="p">(</span><span class="n">offline_path</span><span class="o">=</span><span class="s1">&#39;/path/to/profiler_data&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>离线解析之后，就可以在/path/to/profiler_data/profiler/host_info目录查看Host侧数据了。</p>
</section>
<section id="规格">
<h2>规格<a class="headerlink" href="#规格" title="永久链接至标题"></a></h2>
<ul>
<li><p>为了控制性能测试时生成数据的大小，大型网络建议性能调试的step数目限制在10以内。</p>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>控制step数目可以通过控制训练数据集的大小来实现，如<code class="docutils literal notranslate"><span class="pre">mindspore.dataset.MindDataset</span></code>类中的<code class="docutils literal notranslate"><span class="pre">num_samples</span></code>参数可以控制数据集大小，详情参考：
<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/dataset/mindspore.dataset.MindDataset.html">dataset API</a> 。</p>
</div>
</li>
<li><p>Timeline数据的解析比较耗时，且一般几个step的数据即足够分析出结果。出于数据解析和UI展示性能的考虑，Profiler最多展示20M数据（对大型网络20M可以显示10+条step的信息）。</p></li>
</ul>
</section>
<section id="注意事项">
<h2>注意事项<a class="headerlink" href="#注意事项" title="永久链接至标题"></a></h2>
<ul class="simple">
<li><p>训练加推理过程暂不支持性能调试，目前支持单独训练或推理的性能调试。</p></li>
<li><p>迭代轨迹目前仅支持Graph模式单图场景，暂不支持PyNative、异构、多子图等场景。</p></li>
<li><p>基于step开启、基于epoch开启、迭代轨迹分析和集群分析仅支持Graph模式。</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="performance_profiling.html" class="btn btn-neutral float-left" title="性能调试" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="performance_profiling_gpu.html" class="btn btn-neutral float-right" title="性能调试（GPU）" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2022, MindSpore.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>