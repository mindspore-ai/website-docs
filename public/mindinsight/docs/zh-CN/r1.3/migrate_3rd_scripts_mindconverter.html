<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>使用工具迁移模型定义脚本 &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="性能调试" href="performance_profiling.html" />
    <link rel="prev" title="使用mindoptimizer进行超参调优" href="hyper_parameters_auto_tuning.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_install.html">安装MindInsight</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">使用指南</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="summary_record.html">收集Summary数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="dashboard.html">查看训练看板</a></li>
<li class="toctree-l1"><a class="reference internal" href="lineage_and_scalars_comparison.html">查看溯源和对比看板</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyper_parameters_auto_tuning.html">使用mindoptimizer进行超参调优</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">使用工具迁移模型定义脚本</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id2">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">安装</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id4">用法</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pytorch">PyTorch模型脚本迁移</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tensorflow">TensorFlow模型脚本迁移</a></li>
<li class="toctree-l3"><a class="reference internal" href="#onnx">ONNX模型文件迁移</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id5">使用场景</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id6">使用示例</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#ast">基于AST的脚本转换示例</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">基于图结构的脚本生成示例</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id8">TensorFlow模型脚本生成示例</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id9">ONNX模型文件生成示例</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#mindconverter">MindConverter错误码速查表</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id10">MindConverter支持的模型列表</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id11">注意事项</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="performance_profiling.html">性能调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="debugger.html">调试器</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_explanation.html">解释模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_commands.html">MindInsight相关命令</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="training_visual_design.html">训练可视总体设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_visual_design.html">计算图可视设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_visual_design.html">张量可视设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler_design.html">性能调试设计</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>使用工具迁移模型定义脚本</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/migrate_3rd_scripts_mindconverter.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="id1">
<h1>使用工具迁移模型定义脚本<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">模型开发</span></code> <code class="docutils literal notranslate"><span class="pre">初级</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.3/docs/mindinsight/docs/source_zh_cn/migrate_3rd_scripts_mindconverter.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.3/resource/_static/logo_source.png"></a></p>
<section id="id2">
<h2>概述<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<p>MindConverter是一款用于将PyTorch（ONNX）、TensorFlow（PB）模型转换到MindSpore模型定义脚本以及权重文件的工具。结合转换报告的信息，用户只需对转换后的脚本进行微小的改动，即可实现快速迁移。</p>
</section>
<section id="id3">
<h2>安装<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h2>
<p>此工具为MindInsight的子模块，安装MindInsight后，即可使用MindConverter，MindInsight安装请参考该<a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.3/README_CN.md#">安装文档</a>。</p>
<p>除安装MindInsight之外，还需要安装下列依赖库：</p>
<ol class="arabic simple">
<li><p>TensorFlow不作为MindInsight明确声明的依赖库。若想使用基于图结构的脚本生成工具，需要用户手动安装TensorFlow（MindConverter推荐使用TensorFlow 1.15.x版本）。</p></li>
<li><p>ONNX（&gt;=1.8.0）、ONNXRUNTIME（&gt;=1.5.2）、ONNXOPTIMIZER（&gt;=0.1.2）不作为MindInsight明确声明的依赖库，若想使用基于图结构的脚本生成工具，必须安装上述三方库。若想使用TensorFlow（MindConverter推荐使用TensorFlow 1.15.x版本）模型脚本迁移需要额外安装TF2ONNX（&gt;=1.7.1）。</p></li>
</ol>
</section>
<section id="id4">
<h2>用法<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h2>
<p>MindConverter提供命令行（Command-line interface, CLI）的使用方式，命令如下。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>usage: mindconverter [-h] [--version] [--in_file IN_FILE]
                     [--model_file MODEL_FILE] [--shape SHAPE [SHAPE ...]]
                     [--input_nodes INPUT_NODES [INPUT_NODES ...]]
                     [--output_nodes OUTPUT_NODES [OUTPUT_NODES ...]]
                     [--output OUTPUT] [--report REPORT]

optional arguments:
  -h, --help            show this help message and exit
  --version             show program version number and exit
  --in_file IN_FILE     Specify path for script file to use AST schema to do
                        script conversation.
  --model_file MODEL_FILE
                        Tensorflow(.pb) or ONNX(.onnx) model file path is
                        expected to do script generation based on graph
                        schema. When `--in_file` and `--model_file` are both
                        provided, use AST schema as default.
  --shape SHAPE [SHAPE ...]
                        Expected input tensor shape of `--model_file`. It is
                        required when use graph based schema. Both order and
                        number should be consistent with `--input_nodes`.
                        Given that (1,128) and (1,512) are shapes of input_1
                        and input_2 separately. Usage: --shape 1,128 1,512
  --input_nodes INPUT_NODES [INPUT_NODES ...]
                        Input node(s) name of `--model_file`. It is required
                        when use graph based schema. Both order and number
                        should be consistent with `--shape`. Given that both
                        input_1 and input_2 are inputs of model. Usage:
                        --input_nodes input_1 input_2
  --output_nodes OUTPUT_NODES [OUTPUT_NODES ...]
                        Output node(s) name of `--model_file`. It is required
                        when use graph based schema. Given that both output_1
                        and output_2 are outputs of model. Usage:
                        --output_nodes output_1 output_2
  --output OUTPUT       Optional, specify path for converted script file
                        directory. Default output directory is `output` folder
                        in the current working directory.
  --report REPORT       Optional, specify report directory. Default is
                        converted script directory.
</pre></div>
</div>
<section id="pytorch">
<h3>PyTorch模型脚本迁移<a class="headerlink" href="#pytorch" title="Permalink to this headline"></a></h3>
<p><strong>MindConverter仅提供基于抽象语法树（Abstract syntax tree, AST）的PyTorch脚本迁移</strong>：指定<code class="docutils literal notranslate"><span class="pre">--in_file</span></code>的值，将使用基于AST的脚本转换方案；</p>
<blockquote>
<div><p>若同时指定了<code class="docutils literal notranslate"><span class="pre">--in_file</span></code>，<code class="docutils literal notranslate"><span class="pre">--model_file</span></code>将默认使用AST方案进行脚本迁移。</p>
</div></blockquote>
<p>其中，<code class="docutils literal notranslate"><span class="pre">--output</span></code>与<code class="docutils literal notranslate"><span class="pre">--report</span></code>参数可省略。若省略，MindConverter将在当前工作目录（Working directory）下自动创建<code class="docutils literal notranslate"><span class="pre">output</span></code>目录，将生成的脚本、转换报告输出至该目录。</p>
<blockquote>
<div><p>若需要使用MindConverter计算图方案进行PyTorch模型脚本迁移，建议将PyTorch模型转换为ONNX，再使用ONNX文件进行模型脚本迁移，详情见<a class="reference external" href="https://pytorch.org/docs/stable/onnx.html">PyTorch使用说明</a>。</p>
</div></blockquote>
</section>
<section id="tensorflow">
<h3>TensorFlow模型脚本迁移<a class="headerlink" href="#tensorflow" title="Permalink to this headline"></a></h3>
<p><strong>MindConverter提供基于图结构的脚本生成方案</strong>：指定<code class="docutils literal notranslate"><span class="pre">--model_file</span></code>、<code class="docutils literal notranslate"><span class="pre">--shape</span></code>、<code class="docutils literal notranslate"><span class="pre">--input_nodes</span></code>、<code class="docutils literal notranslate"><span class="pre">--output_nodes</span></code>进行脚本迁移。</p>
<blockquote>
<div><p>AST方案不支持TensorFlow模型脚本迁移，TensorFlow脚本迁移仅支持基于图结构的方案。</p>
</div></blockquote>
<p>若省略<code class="docutils literal notranslate"><span class="pre">--output</span></code>与<code class="docutils literal notranslate"><span class="pre">--report</span></code>参数，MindConverter将在当前工作目录（Working directory）下自动创建<code class="docutils literal notranslate"><span class="pre">output</span></code>目录，将生成的脚本、转换报告、权重文件、权重映射表输出至该目录。</p>
</section>
<section id="onnx">
<h3>ONNX模型文件迁移<a class="headerlink" href="#onnx" title="Permalink to this headline"></a></h3>
<p><strong>MindConverter提供基于图结构的脚本生成方案</strong>：指定<code class="docutils literal notranslate"><span class="pre">--model_file</span></code>、<code class="docutils literal notranslate"><span class="pre">--shape</span></code>、<code class="docutils literal notranslate"><span class="pre">--input_nodes</span></code>、<code class="docutils literal notranslate"><span class="pre">--output_nodes</span></code>进行脚本迁移。</p>
<blockquote>
<div><p>AST方案不支持ONNX模型文件迁移，ONNX文件迁移仅支持基于图结构的方案。</p>
</div></blockquote>
<p>若省略<code class="docutils literal notranslate"><span class="pre">--output</span></code>与<code class="docutils literal notranslate"><span class="pre">--report</span></code>参数，MindConverter将在当前工作目录（Working directory）下自动创建<code class="docutils literal notranslate"><span class="pre">output</span></code>目录，将生成的脚本、转换报告、权重文件、权重映射表输出至该目录。</p>
</section>
</section>
<section id="id5">
<h2>使用场景<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h2>
<p>MindConverter提供两种技术方案，以应对不同脚本迁移场景：</p>
<ol class="arabic simple">
<li><p>用户希望迁移后脚本保持原脚本结构（包括变量、函数、类命名等与原脚本保持一致）；</p></li>
<li><p>用户希望迁移后脚本保持较高的转换率，尽量少的修改、甚至不需要修改，即可实现迁移后模型脚本的执行。</p></li>
</ol>
<p>对于上述第一种场景，推荐用户使用基于AST的方案进行转换（AST方案仅支持PyTorch脚本转换），AST方案通过对原PyTorch脚本的抽象语法树进行解析、编辑，将其替换为MindSpore的抽象语法树，再利用抽象语法树生成代码。理论上，AST方案支持任意模型脚本迁移，但语法树解析操作受原脚本用户编码风格影响，可能导致同一模型的不同脚本最终的转换率存在一定差异。</p>
<p>对于上述第二种场景，推荐用户使用基于图结构的脚本生成方案，计算图作为一种标准的模型描述语言，可以消除用户代码风格多样导致的脚本转换率不稳定的问题。在已支持算子的情况下，该方案可提供优于AST方案的转换率。</p>
<p>目前已基于计算机视觉领域典型模型对图结构的脚本转换方案进行测试。</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>基于图结构的脚本生成方案，由于要以推理模式加载ONNX、TensorFlow模型，会导致转换后网络中Dropout算子丢失，需要用户手动补齐。</p></li>
<li><p>基于图结构的脚本生成方案持续优化中。</p></li>
</ol>
</div></blockquote>
</section>
<section id="id6">
<h2>使用示例<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h2>
<section id="ast">
<h3>基于AST的脚本转换示例<a class="headerlink" href="#ast" title="Permalink to this headline"></a></h3>
<p>若用户希望使用基于AST的方案进行脚本迁移，假设原PyTorch脚本路径为<code class="docutils literal notranslate"><span class="pre">/home/user/model.py</span></code>，希望将脚本输出至<code class="docutils literal notranslate"><span class="pre">/home/user/output</span></code>，转换报告输出至<code class="docutils literal notranslate"><span class="pre">/home/user/output/report</span></code>，则脚本转换命令为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>mindconverter --in_file /home/user/model.py \
              --output /home/user/output \
              --report /home/user/output/report
</pre></div>
</div>
<p>转换报告中，对于未转换的代码行形式为如下，其中x, y指明的是原PyTorch脚本中代码的行、列号。对于未成功转换的算子，可参考<a class="reference external" href="https://www.mindspore.cn/docs/note/zh-CN/r1.3/index.html#operator_api">MindSporeAPI映射查询功能</a> 手动对代码进行迁移。对于工具无法迁移的算子，会保留原脚本中的代码。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>line x:y: [UnConvert] &#39;operator&#39; didn&#39;t convert. ...
</pre></div>
</div>
<p>转换报告示例如下所示：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span> [Start Convert]
 [Insert] &#39;import mindspore.ops as ops&#39; is inserted to the converted file.
 line 1:0: [Convert] &#39;import torch&#39; is converted to &#39;import mindspore&#39;.
 ...
 line 157:23: [UnConvert] &#39;nn.AdaptiveAvgPool2d&#39; didn&#39;t convert. Maybe could convert to mindspore.ops.operations.ReduceMean.
 ...
 [Convert Over]
</pre></div>
</div>
<p>对于部分未成功转换的算子，报告中会提供修改建议，如<code class="docutils literal notranslate"><span class="pre">line</span> <span class="pre">157:23</span></code>，MindConverter建议将<code class="docutils literal notranslate"><span class="pre">torch.nn.AdaptiveAvgPool2d</span></code>替换为<code class="docutils literal notranslate"><span class="pre">mindspore.ops.operations.ReduceMean</span></code>。</p>
</section>
<section id="id7">
<h3>基于图结构的脚本生成示例<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h3>
<section id="id8">
<h4>TensorFlow模型脚本生成示例<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h4>
<p>使用TensorFlow模型脚本迁移，需要先将TensorFlow模型导出为pb格式，并且获取模型输入节点、输出节点名称。TensorFlow pb模型导出可参考<a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.3/mindinsight/mindconverter/docs/tensorflow_model_exporting_cn.md#">TensorFlow Pb模型导出教程</a>。</p>
<p>假设输入节点名称为<code class="docutils literal notranslate"><span class="pre">input_1:0</span></code>，输出节点名称为<code class="docutils literal notranslate"><span class="pre">predictions/Softmax:0</span></code>，模型输入样本尺寸为<code class="docutils literal notranslate"><span class="pre">1,224,224,3</span></code>，模型绝对路径为<code class="docutils literal notranslate"><span class="pre">xxx/frozen_model.pb</span></code>，希望将脚本、权重文件输出至<code class="docutils literal notranslate"><span class="pre">/home/user/output</span></code>，转换报告以及权重映射表输出至<code class="docutils literal notranslate"><span class="pre">/home/user/output/report</span></code>，则脚本生成命令为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>mindconverter --model_file /home/user/xxx/frozen_model.pb --shape 1,224,224,3 \
              --input_nodes input_1:0 \
              --output_nodes predictions/Softmax:0 \
              --output /home/user/output \
              --report /home/user/output/report
</pre></div>
</div>
<p>执行该命令，MindSpore代码文件、权重文件、权重映射表和转换报告生成至相应目录。</p>
<p>由于基于图结构方案属于生成式方法，转换过程中未参考原TensorFlow脚本，因此生成的转换报告中涉及的代码行、列号均指生成后脚本。</p>
<p>另外对于未成功转换的算子，在代码中会相应的标识该节点输入、输出Tensor的shape（以<code class="docutils literal notranslate"><span class="pre">input_shape</span></code>, <code class="docutils literal notranslate"><span class="pre">output_shape</span></code>标识），便于用户手动修改。以Reshape算子为例，将生成如下代码：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                                    <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="c1"># Suppose input of `reshape` is x.</span>
        <span class="n">reshape_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="o">...</span>

</pre></div>
</div>
<p>通过<code class="docutils literal notranslate"><span class="pre">input_shape</span></code>、<code class="docutils literal notranslate"><span class="pre">output_shape</span></code>参数，用户可以十分便捷地完成算子替换，替换结果如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="o">...</span>

<span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                                 <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="c1"># Suppose input of `reshape` is x.</span>
        <span class="n">reshape_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>
        <span class="o">...</span>

</pre></div>
</div>
<blockquote>
<div><p>其中<code class="docutils literal notranslate"><span class="pre">--output</span></code>与<code class="docutils literal notranslate"><span class="pre">--report</span></code>参数可省略，若省略，该命令将在当前工作目录（Working directory）下自动创建<code class="docutils literal notranslate"><span class="pre">output</span></code>目录，将生成的脚本、转换报告输出至该目录。</p>
</div></blockquote>
<p>映射表中分别保存算子在MindSpore中的权重信息（<code class="docutils literal notranslate"><span class="pre">converted_weight</span></code>）和在原始框架中的权重信息（<code class="docutils literal notranslate"><span class="pre">source_weight</span></code>）。</p>
<p>权重映射表示例如下所示：</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;resnet50&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;converted_weight&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;conv2d_0.weight&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;shape&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                    </span><span class="mi">64</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">3</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">7</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">7</span>
<span class="w">                </span><span class="p">],</span>
<span class="w">                </span><span class="nt">&quot;data_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Float32&quot;</span>
<span class="w">            </span><span class="p">},</span>
<span class="w">            </span><span class="nt">&quot;source_weight&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;conv1.weight&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;shape&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                    </span><span class="mi">64</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">3</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">7</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">7</span>
<span class="w">                </span><span class="p">],</span>
<span class="w">                </span><span class="nt">&quot;data_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;float32&quot;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="id9">
<h4>ONNX模型文件生成示例<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h4>
<p>使用ONNX模型文件迁移，需要先从.onnx文件中获取模型输入节点、输出节点名称。获取ONNX模输入、输出节点名称，可使用 <a class="reference external" href="https://github.com/lutzroeder/netron">Netron</a> 工具查看。</p>
<p>假设输入节点名称为<code class="docutils literal notranslate"><span class="pre">input_1:0</span></code>、输出节点名称为<code class="docutils literal notranslate"><span class="pre">predictions/Softmax:0</span></code>，模型输入样本尺寸为<code class="docutils literal notranslate"><span class="pre">1,3,224,224</span></code>，则可使用如下命令进行脚本生成：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>mindconverter --model_file /home/user/xxx/model.onnx --shape 1,3,224,224 \
              --input_nodes input_1:0 \
              --output_nodes predictions/Softmax:0 \
              --output /home/user/output \
              --report /home/user/output/report
</pre></div>
</div>
<p>执行该命令，MindSpore代码文件、权重文件、权重映射表和转换报告生成至相应目录。</p>
<p>由于基于图结构方案属于生成式方法，转换过程中未参考ONNX文件，因此生成的转换报告中涉及的代码行、列号均指生成后脚本。</p>
<p>另外，对于未成功转换的算子，在代码中会相应的标识该节点输入、输出Tensor的shape（以<code class="docutils literal notranslate"><span class="pre">input_shape</span></code>、<code class="docutils literal notranslate"><span class="pre">output_shape</span></code>标识），便于用户手动修改，示例见<strong>TensorFlow模型脚本生成示例</strong>。</p>
</section>
</section>
</section>
<section id="mindconverter">
<h2>MindConverter错误码速查表<a class="headerlink" href="#mindconverter" title="Permalink to this headline"></a></h2>
<p>MindConverter错误码定义，请参考<a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.3/mindinsight/mindconverter/docs/error_code_definition_cn.md#">链接</a>。</p>
</section>
<section id="id10">
<h2>MindConverter支持的模型列表<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h2>
<p><a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.3/mindinsight/mindconverter/docs/supported_model_list_cn.md#">支持的模型列表（如下模型已基于x86 Ubuntu发行版，PyTorch 1.5.0以及TensorFlow 1.15.0测试通过）</a>。</p>
</section>
<section id="id11">
<h2>注意事项<a class="headerlink" href="#id11" title="Permalink to this headline"></a></h2>
<ol class="arabic simple">
<li><p>脚本转换工具本质上为算子驱动，对于MindConverter未维护的ONNX算子与MindSpore算子映射，将会出现相应的算子无法转换的问题，对于该类算子，用户可手动修改，或基于MindConverter实现映射关系，向MindInsight仓库贡献。</p></li>
<li><p>在使用基于计算图的迁移时，MindConverter会根据<code class="docutils literal notranslate"><span class="pre">--shape</span></code>参数将模型输入的批次大小（batch size）、句子长度（sequence length）、图片尺寸（image shape）等尺寸相关参数固定下来，用户需要保证基于MindSpore重训练、推理时输入shape与转换时一致；若需要调整输入尺寸，请重新指定<code class="docutils literal notranslate"><span class="pre">--shape</span></code>进行转换或修改转换后脚本中涉及张量尺寸变更操作相应的操作数。</p></li>
<li><p>脚本文件和权重文件输出于同一个目录下，转换报告和权重映射表输出于同一目录下。</p></li>
<li><p>模型文件的安全性与一致性请用户自行保证。</p></li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="hyper_parameters_auto_tuning.html" class="btn btn-neutral float-left" title="使用mindoptimizer进行超参调优" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="performance_profiling.html" class="btn btn-neutral float-right" title="性能调试" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>