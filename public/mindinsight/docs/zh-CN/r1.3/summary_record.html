<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>收集Summary数据 &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="查看训练看板" href="dashboard.html" />
    <link rel="prev" title="安装MindInsight" href="mindinsight_install.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_install.html">安装MindInsight</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">使用指南</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">收集Summary数据</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">操作流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">准备训练脚本</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#summarycollector">方式一：通过SummaryCollector自动收集</a></li>
<li class="toctree-l3"><a class="reference internal" href="#summarysummarycollector">方式二：结合Summary算子和SummaryCollector，自定义收集网络中的数据</a></li>
<li class="toctree-l3"><a class="reference internal" href="#callback">方式三：自定义Callback记录数据</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">方式四：进阶用法，自定义训练循环</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">分布式训练场景</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">使用技巧：记录梯度信息</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#mindinsight">运行MindInsight</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id7">注意事项</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dashboard.html">查看训练看板</a></li>
<li class="toctree-l1"><a class="reference internal" href="lineage_and_scalars_comparison.html">查看溯源和对比看板</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyper_parameters_auto_tuning.html">使用mindoptimizer进行超参调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrate_3rd_scripts_mindconverter.html">使用工具迁移模型定义脚本</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_profiling.html">性能调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="debugger.html">调试器</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_explanation.html">解释模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_commands.html">MindInsight相关命令</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="training_visual_design.html">训练可视总体设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_visual_design.html">计算图可视设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_visual_design.html">张量可视设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler_design.html">性能调试设计</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>收集Summary数据</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/summary_record.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="summary">
<h1>收集Summary数据<a class="headerlink" href="#summary" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">模型调优</span></code> <code class="docutils literal notranslate"><span class="pre">中级</span></code> <code class="docutils literal notranslate"><span class="pre">高级</span></code></p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.3/docs/mindinsight/docs/source_zh_cn/summary_record.md"><img alt="查看源文件" src="https://gitee.com/mindspore/docs/raw/r1.3/resource/_static/logo_source.png" /></a>  
<a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/r1.3/notebook/mindspore_mindinsight_dashboard.ipynb"><img alt="查看Notebook" src="https://gitee.com/mindspore/docs/raw/r1.3/resource/_static/logo_notebook.png" /></a></p>
<section id="id1">
<h2>概述<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<p>训练过程中的标量、图像、计算图以及模型超参等信息记录到文件中，通过可视化界面供用户查看。</p>
</section>
<section id="id2">
<h2>操作流程<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>准备训练脚本，并在训练脚本中指定标量、图像、计算图、模型超参等信息记录到summary日志文件，接着运行训练脚本。</p></li>
<li><p>启动MindInsight，并通过启动参数指定summary日志文件目录，启动成功后，根据IP和端口访问可视化界面，默认访问地址为 <code class="docutils literal notranslate"><span class="pre">http://127.0.0.1:8080</span></code>。</p></li>
<li><p>在训练过程中，有数据写入summary日志文件时，即可在页面中<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.3/dashboard.html">查看训练看板中可视的数据</a>。</p></li>
</ul>
<blockquote>
<div><p>在ModelArts中查看可视数据，可参考<a class="reference external" href="https://support.huaweicloud.com/engineers-modelarts/modelarts_23_0050.html">ModelArts上管理可视化作业</a>。</p>
</div></blockquote>
</section>
<section id="id3">
<h2>准备训练脚本<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h2>
<p>当前MindSpore支持将标量、图像、计算图、模型超参等信息保存到summary日志文件中，并通过可视化界面进行展示。计算图数据仅能在图模式下记录。</p>
<p>MindSpore目前支持多种方式将数据记录到summary日志文件中。</p>
<section id="summarycollector">
<h3>方式一：通过SummaryCollector自动收集<a class="headerlink" href="#summarycollector" title="Permalink to this headline"></a></h3>
<p>在MindSpore中通过 <code class="docutils literal notranslate"><span class="pre">Callback</span></code> 机制提供支持快速简易地收集一些常见的信息，包括计算图，损失值，学习率，参数权重等信息的 <code class="docutils literal notranslate"><span class="pre">Callback</span></code>, 叫做 <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code>。</p>
<p>在编写训练脚本时，仅需要实例化 <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code>，并将其应用到 <code class="docutils literal notranslate"><span class="pre">model.train</span></code> 或者 <code class="docutils literal notranslate"><span class="pre">model.eval</span></code> 中，
即可自动收集一些常见信息。<code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> 详细的用法可以参考 <code class="docutils literal notranslate"><span class="pre">API</span></code> 文档中 <code class="docutils literal notranslate"><span class="pre">mindspore.train.callback.SummaryCollector</span></code>。</p>
<p>样例代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore.nn.metrics</span> <span class="kn">import</span> <span class="n">Accuracy</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">SummaryCollector</span>


<span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                     <span class="n">has_bias</span><span class="o">=</span><span class="n">has_bias</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="n">pad_mode</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">fc_with_initialize</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="n">has_bias</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">AlexNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;AlexNet&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">phase</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlexNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv5</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">include_top</span> <span class="o">=</span> <span class="n">include_top</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">include_top</span><span class="p">:</span>
            <span class="n">dropout_ratio</span> <span class="o">=</span> <span class="mf">0.65</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span>
                <span class="n">dropout_ratio</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">*</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_ratio</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;define network&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv5</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">include_top</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>

    <span class="n">network</span> <span class="o">=</span> <span class="n">AlexNet</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">Accuracy</span><span class="p">()})</span>

    <span class="c1"># How to create a valid dataset instance,</span>
    <span class="c1"># for detail, see the https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/quick_start/quick_start.html document.</span>
    <span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;./dataset_path&#39;</span><span class="p">)</span>

    <span class="c1"># Init a SummaryCollector callback instance, and use it in model.train or model.eval</span>
    <span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">,</span> <span class="n">collect_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Note: dataset_sink_mode should be set to False, else you should modify collect freq in SummaryCollector</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">ds_eval</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;./dataset_path&#39;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">ds_eval</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">])</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">train</span><span class="p">()</span>

</pre></div>
</div>
<blockquote>
<div><ol class="arabic simple">
<li><p>使用summary功能时，建议将<code class="docutils literal notranslate"><span class="pre">model.train</span></code>的<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code>参数设置为<code class="docutils literal notranslate"><span class="pre">False</span></code>。请参考文末的注意事项。</p></li>
<li><p>使用summary功能时，需要将代码放置到<code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">__name__</span> <span class="pre">==</span> <span class="pre">&quot;__main__&quot;</span></code>中运行。详情请<a class="reference external" href="https://docs.python.org/zh-cn/3.7/library/multiprocessing.html#multiprocessing-programming">参考Python官网介绍</a>。</p></li>
</ol>
</div></blockquote>
</section>
<section id="summarysummarycollector">
<h3>方式二：结合Summary算子和SummaryCollector，自定义收集网络中的数据<a class="headerlink" href="#summarysummarycollector" title="Permalink to this headline"></a></h3>
<p>MindSpore除了提供 <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> 能够自动收集一些常见数据，还提供了Summary算子，支持在网络中自定义收集其他的数据，比如每一个卷积层的输入，或在损失函数中的损失值等。</p>
<p>当前支持的Summary算子:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/ops/mindspore.ops.ScalarSummary.html">ScalarSummary</a>：记录标量数据</p></li>
<li><p><a class="reference external" href="https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/ops/mindspore.ops.TensorSummary.html">TensorSummary</a>：记录张量数据</p></li>
<li><p><a class="reference external" href="https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/ops/mindspore.ops.ImageSummary.html">ImageSummary</a>：记录图片数据</p></li>
<li><p><a class="reference external" href="https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/ops/mindspore.ops.HistogramSummary.html">HistogramSummary</a>：将张量数据转为直方图数据记录</p></li>
</ul>
<p>记录方式如下面的步骤所示。</p>
<p>步骤一：在继承 <code class="docutils literal notranslate"><span class="pre">nn.Cell</span></code> 的衍生类的 <code class="docutils literal notranslate"><span class="pre">construct</span></code> 函数中调用Summary算子来采集图像或标量数据或者其他数据。</p>
<p>比如，定义网络时，在网络的 <code class="docutils literal notranslate"><span class="pre">construct</span></code> 中记录图像数据；定义损失函数时，在损失函数的 <code class="docutils literal notranslate"><span class="pre">construct</span></code>中记录损失值。</p>
<p>如果要记录动态学习率，可以定义优化器时，在优化器的 <code class="docutils literal notranslate"><span class="pre">construct</span></code> 中记录学习率。</p>
<p>样例代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Optimizer</span>


<span class="k">class</span> <span class="nc">CrossEntropyLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Loss function definition.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CrossEntropyLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cross_entropy</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">OneHot</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># Init ScalarSummary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scalar_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ScalarSummary</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">logits</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">label</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>

        <span class="c1"># Record loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scalar_summary</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>


<span class="k">class</span> <span class="nc">MyOptimizer</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimizer definition.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="o">...</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="c1"># Initialize ScalarSummary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scalar_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ScalarSummary</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">HistogramSummary</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="c1"># Record learning rate here</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scalar_summary</span><span class="p">(</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>

        <span class="c1"># Record weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1"># Record gradient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;.gradient&quot;</span><span class="p">,</span> <span class="n">grads</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="o">...</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Net definition.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="o">...</span>

        <span class="c1"># Init ImageSummary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ImageSummary</span><span class="p">()</span>
        <span class="c1"># Init TensorSummary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensor_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">TensorSummary</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="c1"># Record image by Summary operator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_summary</span><span class="p">(</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        <span class="c1"># Record tensor by Summary operator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensor_summary</span><span class="p">(</span><span class="s2">&quot;tensor&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        <span class="o">...</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
<blockquote>
<div><ol class="arabic simple">
<li><p>同一种Summary算子中，给数据设置的名字不能重复，否则数据收集和展示都会出现非预期行为。比如使用两个 <code class="docutils literal notranslate"><span class="pre">ScalarSummary</span></code> 算子收集标量数据，给两个标量设置的名字不能是相同的。</p></li>
<li><p>summary算子仅支持图模式，需要在<code class="docutils literal notranslate"><span class="pre">nn.Cell</span></code>的<code class="docutils literal notranslate"><span class="pre">construct</span></code>中使用。暂不支持PyNative模式。</p></li>
</ol>
</div></blockquote>
<p>步骤二：在训练脚本中，实例化 <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code>，并将其应用到 <code class="docutils literal notranslate"><span class="pre">model.train</span></code>。</p>
<p>样例代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">SummaryCollector</span>
<span class="o">...</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optim</span> <span class="o">=</span> <span class="n">MyOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">Accuracy</span><span class="p">()})</span>

    <span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;./dataset_path&#39;</span><span class="p">)</span>

    <span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">,</span> <span class="n">collect_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">])</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="callback">
<h3>方式三：自定义Callback记录数据<a class="headerlink" href="#callback" title="Permalink to this headline"></a></h3>
<p>MindSpore支持自定义Callback, 并允许在自定义Callback中将数据记录到summary日志文件中，
并通过可视化页面进行查看。</p>
<p>下面的伪代码则展示在CNN网络中，开发者可以利用带有原始标签和预测标签的网络输出，生成混淆矩阵的图片,
然后通过 <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code> 模块记录到summary日志文件中。
<code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code> 详细的用法可以参考 <code class="docutils literal notranslate"><span class="pre">API</span></code> 文档中 <code class="docutils literal notranslate"><span class="pre">mindspore.train.summary.SummaryRecord</span></code>。</p>
<p>样例代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">Callback</span>
<span class="kn">from</span> <span class="nn">mindspore.train.summary</span> <span class="kn">import</span> <span class="n">SummaryRecord</span>

<span class="k">class</span> <span class="nc">ConfusionMatrixCallback</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">summary_dir</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_summary_dir</span> <span class="o">=</span> <span class="n">summary_dir</span>

    <span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># init you summary record in here, when the train script run, it will be inited before training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span> <span class="o">=</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_summary_dir</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">exc_args</span><span class="p">):</span>
        <span class="c1"># Note: you must close the summary record, it will release the process pool resource</span>
        <span class="c1"># else your training script will not exit from training.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>

        <span class="c1"># create a confusion matric image, and record it to summary file</span>
        <span class="n">confusion_matrix</span> <span class="o">=</span> <span class="n">create_confusion_matrix</span><span class="p">(</span><span class="n">cb_params</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s1">&#39;image&#39;</span><span class="p">,</span> <span class="s1">&#39;confusion_matrix&#39;</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span><span class="p">)</span>

<span class="c1"># init you train script</span>
<span class="o">...</span>

<span class="n">confusion_matrix</span> <span class="o">=</span> <span class="n">ConfusionMatrixCallback</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">confusion_matrix</span><span class="p">])</span>
</pre></div>
</div>
<p>上面的三种方式，支持记录计算图, 损失值等多种数据。除此以外，MindSpore还支持保存训练中其他阶段的计算图，通过
将训练脚本中 <code class="docutils literal notranslate"><span class="pre">context.set_context</span></code> 的 <code class="docutils literal notranslate"><span class="pre">save_graphs</span></code> 选项设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code>, 可以记录其他阶段的计算图，其中包括算子融合后的计算图。</p>
<p>在保存的文件中，<code class="docutils literal notranslate"><span class="pre">ms_output_after_hwopt.pb</span></code> 即为算子融合后的计算图，可以使用可视化页面对其进行查看。</p>
</section>
<section id="id4">
<h3>方式四：进阶用法，自定义训练循环<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<p>如果训练时不是使用MindSpore提供的 <code class="docutils literal notranslate"><span class="pre">Model</span></code> 接口，而是模仿 <code class="docutils literal notranslate"><span class="pre">Model</span></code> 的 <code class="docutils literal notranslate"><span class="pre">train</span></code> 接口自由控制循环的迭代次数。则可以模拟 <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code>，使用下面的方式记录summary算子数据。详细的自定义训练循环教程，请<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/train.html#%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AE%AD%E7%BB%83%E5%BE%AA%E7%8E%AF">参考官网教程</a>。</p>
<p>下面的例子，将演示如何使用summary算子以及 <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code> 的 <code class="docutils literal notranslate"><span class="pre">add_value</span></code> 接口在自定义训练循环中记录数据。更多 <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code> 的教程，请<a class="reference external" href="https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/mindspore.train.html#mindspore.train.summary.SummaryRecord">参考Python API文档</a>。需要说明的是，<code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code>不会自动记录计算图，您需要手动传入继承了<code class="docutils literal notranslate"><span class="pre">Cell</span></code>的网络实例以记录计算图。此外，生成计算图的内容仅包含您在<code class="docutils literal notranslate"><span class="pre">construct</span></code>方法中使用到的代码和函数。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.train.summary</span> <span class="kn">import</span> <span class="n">SummaryRecord</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="k">class</span> <span class="nc">LeNet5</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_class</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet5</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_class</span> <span class="o">=</span> <span class="n">num_class</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="o">...</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">image_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ImageSummary</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensor_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">TensorSummary</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_summary</span><span class="p">(</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensor_summary</span><span class="p">(</span><span class="s1">&#39;after_conv1&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="o">...</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="o">...</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
    <span class="c1"># Note1: An instance of the network should be passed to SummaryRecord if you want to record</span>
    <span class="c1"># computational graph.</span>
    <span class="k">with</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">,</span> <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">)</span> <span class="k">as</span> <span class="n">summary_record</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">for</span> <span class="n">inputs</span> <span class="ow">in</span> <span class="n">dataset_helper</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>
                <span class="n">current_step</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset_helper</span><span class="p">)</span> <span class="o">+</span> <span class="n">step</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;step: </span><span class="si">{0}</span><span class="s2">, losses: </span><span class="si">{1}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">current_step</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()))</span>

                <span class="c1"># Note2: The output should be a scalar, and use &#39;add_value&#39; method to record loss.</span>
                <span class="c1"># Note3: You must use the &#39;record(step)&#39; method to record the data of this step.</span>
                <span class="n">summary_record</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s1">&#39;scalar&#39;</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
                <span class="n">summary_record</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">current_step</span><span class="p">)</span>

                <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">train</span><span class="p">()</span>

</pre></div>
</div>
</section>
<section id="id5">
<h3>分布式训练场景<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h3>
<p>由于<code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code>和<code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code>写数据是非进程安全的。所以在单机多卡的场景中，需要确保每张卡保存数据的目录不一样。在分布式场景下，我们通过<code class="docutils literal notranslate"><span class="pre">get_rank</span></code>函数设置summary目录。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">summary_dir</span> <span class="o">=</span> <span class="s2">&quot;summary_dir&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">get_rank</span><span class="p">())</span>
</pre></div>
</div>
<p>示例代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.communication.management</span> <span class="kn">import</span> <span class="n">get_rank</span>

<span class="o">...</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Init a SummaryCollector callback instance, and use it in model.train or model.eval</span>
<span class="n">summary_dir</span> <span class="o">=</span> <span class="s2">&quot;summary_dir&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">get_rank</span><span class="p">())</span>
<span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="n">summary_dir</span><span class="p">,</span> <span class="n">collect_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Note: dataset_sink_mode should be set to False, else you should modify collect freq in SummaryCollector</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">ds_eval</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="id6">
<h3>使用技巧：记录梯度信息<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<p>除了上述使用方式外，使用summary算子时还有一个记录梯度信息的技巧。请注意此技巧需要和上述的某一种使用方式同时使用。</p>
<p>通过继承原有优化器类的方法可以插入summary算子读取梯度信息。样例代码片段如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="o">...</span>

<span class="c1"># Define a new optimizer class by inheriting your original optimizer.</span>
<span class="k">class</span> <span class="nc">MyOptimizer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_original_construct</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">construct</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">HistogramSummary</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;.gradient&quot;</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="c1"># Record gradient.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gradient_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">grads</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_original_construct</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>

<span class="o">...</span>

<span class="c1"># Initialize your model with the newly defined optimizer.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">MyOptimizer</span><span class="p">(</span><span class="n">arg1</span><span class="o">=</span><span class="n">arg1value</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>
<section id="mindinsight">
<h2>运行MindInsight<a class="headerlink" href="#mindinsight" title="Permalink to this headline"></a></h2>
<p>按照上面教程完成数据收集后，启动MindInsight，即可可视化收集到的数据。启动MindInsight时，
需要通过 <code class="docutils literal notranslate"><span class="pre">--summary-base-dir</span></code> 参数指定summary日志文件目录。</p>
<p>其中指定的summary日志文件目录可以是一次训练的输出目录，也可以是多次训练输出目录的父目录。</p>
<p>一次训练的输出目录结构如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─summary_dir
    events.out.events.summary.1596869898.hostname_MS
    events.out.events.summary.1596869898.hostname_lineage
</pre></div>
</div>
<p>启动命令：</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>mindinsight<span class="w"> </span>start<span class="w"> </span>--summary-base-dir<span class="w"> </span>./summary_dir
</pre></div>
</div>
<p>多次训练的输出目录结构如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─summary
    ├─summary_dir1
    │      events.out.events.summary.1596869898.hostname_MS
    │      events.out.events.summary.1596869898.hostname_lineage
    │
    └─summary_dir2
            events.out.events.summary.1596869998.hostname_MS
            events.out.events.summary.1596869998.hostname_lineage
</pre></div>
</div>
<p>启动命令:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>mindinsight<span class="w"> </span>start<span class="w"> </span>--summary-base-dir<span class="w"> </span>./summary
</pre></div>
</div>
<p>启动成功后，通过浏览器访问 <code class="docutils literal notranslate"><span class="pre">http://127.0.0.1:8080</span></code> 地址，即可查看可视化页面。</p>
<p>停止MindInsight命令：</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>mindinsight<span class="w"> </span>stop
</pre></div>
</div>
<p>更多参数设置，请点击查看<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.3/mindinsight_commands.html">MindInsight相关命令</a>页面。</p>
</section>
<section id="id7">
<h2>注意事项<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h2>
<ol class="arabic">
<li><p>为了控制列出summary文件目录的用时，MindInsight最多支持发现999个summary文件目录。</p></li>
<li><p>不能同时使用多个 <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code> 实例 （<code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> 中使用了 <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code>）。</p>
<p>如果在 <code class="docutils literal notranslate"><span class="pre">model.train</span></code> 或者 <code class="docutils literal notranslate"><span class="pre">model.eval</span></code> 的callback列表中使用两个及以上的 <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> 实例，则视为同时使用 <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code>，可能导致记录数据失败。</p>
<p>自定义callback中如果使用 <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code>，则其不能和 <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> 同时使用。</p>
<p>正确代码:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">])</span>

<span class="o">...</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">])</span>
</pre></div>
</div>
<p>错误代码：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="n">summary_collector1</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="s1">&#39;./summary_dir1&#39;</span><span class="p">)</span>
<span class="n">summary_collector2</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="s1">&#39;./summary_dir2&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector1</span><span class="p">,</span> <span class="n">summary_collector2</span><span class="p">])</span>
</pre></div>
</div>
<p>错误代码：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="c1"># Note: the &#39;ConfusionMatrixCallback&#39; is user-defined, and it uses SummaryRecord to record data.</span>
<span class="n">confusion_callback</span> <span class="o">=</span> <span class="n">ConfusionMatrixCallback</span><span class="p">(</span><span class="s1">&#39;./summary_dir1&#39;</span><span class="p">)</span>
<span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="s1">&#39;./summary_dir2&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">confusion_callback</span><span class="p">,</span> <span class="n">summary_collector</span><span class="p">])</span>
</pre></div>
</div>
</li>
<li><p>每个summary日志文件目录中，应该只放置一次训练的数据。一个summary日志目录中如果存放了多次训练的summary数据，MindInsight在可视化数据时会将这些训练的summary数据进行叠加展示，可能会与预期可视化效果不相符。</p></li>
<li><p>使用summary功能时，建议将<code class="docutils literal notranslate"><span class="pre">model.train</span></code>方法的<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code>参数设置为<code class="docutils literal notranslate"><span class="pre">False</span></code>，从而以<code class="docutils literal notranslate"><span class="pre">step</span></code>作为<code class="docutils literal notranslate"><span class="pre">collect_freq</span></code>参数的单位收集数据。当<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code>为<code class="docutils literal notranslate"><span class="pre">True</span></code>时，将以<code class="docutils literal notranslate"><span class="pre">epoch</span></code>作为<code class="docutils literal notranslate"><span class="pre">collect_freq</span></code>的单位，此时建议手动设置<code class="docutils literal notranslate"><span class="pre">collect_freq</span></code>参数。<code class="docutils literal notranslate"><span class="pre">collect_freq</span></code>参数默认值为<code class="docutils literal notranslate"><span class="pre">10</span></code>。</p></li>
<li><p>每个step保存的数据量，最大限制为2147483647Bytes。如果超出该限制，则无法记录该step的数据，并出现错误。</p></li>
<li><p>PyNative模式下，<code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> 能够正常使用，但不支持记录计算图以及不支持使用Summary算子。</p></li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindinsight_install.html" class="btn btn-neutral float-left" title="安装MindInsight" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="dashboard.html" class="btn btn-neutral float-right" title="查看训练看板" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>