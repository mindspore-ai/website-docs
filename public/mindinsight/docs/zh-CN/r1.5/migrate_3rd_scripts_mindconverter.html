<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>使用MindConverter迁移模型定义脚本 &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="性能调试" href="performance_profiling.html" />
    <link rel="prev" title="使用mindoptimizer进行超参调优" href="hyper_parameters_auto_tuning.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_install.html">安装MindInsight</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">使用指南</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="summary_record.html">收集Summary数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="dashboard.html">查看训练看板</a></li>
<li class="toctree-l1"><a class="reference internal" href="lineage_and_scalars_comparison.html">查看溯源和对比看板</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyper_parameters_auto_tuning.html">使用mindoptimizer进行超参调优</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">使用MindConverter迁移模型定义脚本</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">工具概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">快速开始</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">环境依赖</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id4">迁移方案</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id5">实践步骤</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id6">第0步：导出模型文件</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">第1步：转换模型定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id8">第2步：转换数据处理</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id9">第3步：转换模型训练</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">第4步：转换模型推理</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id11">命令行参数说明</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id12">模型支持列表</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id13">错误码速查表</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id14">常见问题</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#arm">ARM环境安装依赖组件</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tensorflow">TensorFlow模型导出</a></li>
<li class="toctree-l3"><a class="reference internal" href="#forward">整改forward参数列表</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mindspore">MindSpore模型内嵌到原框架</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id15">转换报告与权重映射表</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ast">基于AST转换脚本</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="performance_profiling.html">性能调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="debugger.html">调试器</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_explanation.html">解释模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_commands.html">MindInsight相关命令</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">精度调优指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="accuracy_problem_preliminary_location.html">精度问题初步定位指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="accuracy_optimization.html">精度问题详细定位和调优指南</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="training_visual_design.html">训练可视总体设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_visual_design.html">计算图可视设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_visual_design.html">张量可视设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler_design.html">性能调试设计</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>使用MindConverter迁移模型定义脚本</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/migrate_3rd_scripts_mindconverter.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="mindconverter">
<h1>使用MindConverter迁移模型定义脚本<a class="headerlink" href="#mindconverter" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.5/docs/mindinsight/docs/source_zh_cn/migrate_3rd_scripts_mindconverter.md"><img alt="查看源文件" src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source.png" /></a></p>
<section id="id1">
<h2>工具概述<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<p>MindConverter是一款模型迁移工具，可将PyTorch(ONNX)或Tensorflow(PB)模型快速迁移到MindSpore框架下使用。模型文件（ONNX/PB）包含网络模型结构（<code class="docutils literal notranslate"><span class="pre">network</span></code>）与权重信息（<code class="docutils literal notranslate"><span class="pre">weights</span></code>），迁移后将生成MindSpore框架下的模型定义脚本（<code class="docutils literal notranslate"><span class="pre">model.py</span></code>）与权重文件（<code class="docutils literal notranslate"><span class="pre">ckpt</span></code>）。</p>
<p><img alt="mindconverter-overview" src="_images/mindconverter-overview.png" /></p>
</section>
<section id="id2">
<h2>快速开始<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<p>MindConverter属于MindInsight的子模块，安装MindInsight后，即可使用MindConverter，MindInsight安装请参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/mindinsight_install.html">安装文档</a>。MindConverter命令行如下，更多CLI参数请参考<span class="xref myst">命令行参数说明</span>。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>mindconverter<span class="w"> </span>--model_file<span class="w"> </span>/path/to/model_file<span class="w"> </span>--shape<span class="w"> </span>SHAPE<span class="w"> </span>--input_nodes<span class="w"> </span>INPUTS<span class="w"> </span>--output_nodes<span class="w"> </span>OUTPUTS
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--model_file</span></code>指定模型文件路径，模型文件支持<code class="docutils literal notranslate"><span class="pre">onnx</span></code>或<code class="docutils literal notranslate"><span class="pre">pb</span></code>格式。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--shape</span></code>指定模型输入shape信息，多输入场景以空格分隔。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--input_nodes</span></code>指定模型输入节点名称，多输入场景以空格分隔。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--output_nodes</span></code>指定模型输出节点名称，多输出场景以空格分隔。</p></li>
<li><p>转换结果默认输出到<code class="docutils literal notranslate"><span class="pre">$PWD/output</span></code>。</p></li>
</ul>
</section>
<section id="id3">
<h2>环境依赖<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h2>
<p>使用MindConverter前需要安装以下依赖包，建议在x86环境下安装。ARM环境请参考<span class="xref myst">常见问题</span>。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 安装配套版本的MindSpore（以r1.2版本为例）</span>
pip<span class="w"> </span>install<span class="w"> </span>mindspore~<span class="o">=</span><span class="m">1</span>.2.0

<span class="c1"># 安装onnx相关的依赖包</span>
pip<span class="w"> </span>install<span class="w"> </span>onnx~<span class="o">=</span><span class="m">1</span>.8.0
pip<span class="w"> </span>install<span class="w"> </span>onnxoptimizer~<span class="o">=</span><span class="m">0</span>.1.2
pip<span class="w"> </span>install<span class="w"> </span>onnxruntime~<span class="o">=</span><span class="m">1</span>.5.2

<span class="c1"># 如果使用 Tensorflow PB 文件转换，则需安装tf2onnx</span>
pip<span class="w"> </span>install<span class="w"> </span>tf2onnx~<span class="o">=</span><span class="m">1</span>.7.1
</pre></div>
</div>
</section>
<section id="id4">
<h2>迁移方案<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h2>
<p>一个网络模型工程，通常包含以下四个主要组成部分，各部分的迁移指引如下：</p>
<ul class="simple">
<li><p>模型定义（<code class="docutils literal notranslate"><span class="pre">model.py</span></code>）</p>
<ol class="arabic simple">
<li><p>使用MindConverter工具转换模型结构。</p></li>
<li><p>手工调整可读性（可选）。</p></li>
<li><p>转换后的模型内嵌到原框架工程，验证转换等价性，参考<span class="xref myst">常见问题</span>。</p></li>
</ol>
</li>
<li><p>数据处理（<code class="docutils literal notranslate"><span class="pre">dataset.py</span></code>）</p>
<ol class="arabic simple">
<li><p>内置数据集可查询<a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/zh-CN/r1.5/api_mapping/pytorch_api_mapping.html">接口映射</a>辅助转换。</p></li>
<li><p>自定义数据集与相关数据处理，可参考<span class="xref myst">转换模板</span>。</p></li>
</ol>
</li>
<li><p>模型训练（<code class="docutils literal notranslate"><span class="pre">train.py</span></code>）</p>
<ol class="arabic simple">
<li><p>损失函数（<code class="docutils literal notranslate"><span class="pre">loss_fn</span></code>），可查询<a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/zh-CN/r1.5/api_mapping/pytorch_api_mapping.html">接口映射</a>或自定义实现。</p></li>
<li><p>优化器（<code class="docutils literal notranslate"><span class="pre">optimizer</span></code>），可查询<a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/zh-CN/r1.5/api_mapping/pytorch_api_mapping.html">接口映射</a>或自定义实现。</p></li>
<li><p>模型训练的代码比较灵活，代码组织风格与MindSpore图模式差异较大，建议自行实现，参考<span class="xref myst">转换模板</span>。</p></li>
</ol>
</li>
<li><p>模型推理（<code class="docutils literal notranslate"><span class="pre">eval.py</span></code>）</p>
<ol class="arabic simple">
<li><p>度量指标（<code class="docutils literal notranslate"><span class="pre">metric</span></code>），可查询<a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/zh-CN/r1.5/api_mapping/pytorch_api_mapping.html">接口映射</a>或自定义实现。</p></li>
<li><p>模型推理的代码比较灵活，代码组织风格与MindSpore图模式差异较大，建议自行实现，参考<span class="xref myst">转换模板</span>。</p></li>
</ol>
</li>
</ul>
</section>
<section id="id5">
<h2>实践步骤<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h2>
<section id="id6">
<h3>第0步：导出模型文件<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<p>以PyTorch框架为例导出ONNX模型文件（Tensorflow框架请参考<span class="xref myst">常见问题</span>），需要Pytorch算子支持相应的ONNX算子，详情参考<a class="reference external" href="https://pytorch.org/docs/stable/onnx.html#supported-operators">Pytorch</a>与<a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#">ONNX</a>的算子列表，操作步骤如下：</p>
<ol class="arabic">
<li><p>下载网络模型工程的源码、权重文件、数据集。</p></li>
<li><p>分析模型定义代码，整改<code class="docutils literal notranslate"><span class="pre">forward</span></code>函数的入参列表，确保入参均为Tensor类型，参考<span class="xref myst">常见问题</span>。</p></li>
<li><p>从模型推理的代码中，识别模型对象（<code class="docutils literal notranslate"><span class="pre">model</span></code>）与输入的<code class="docutils literal notranslate"><span class="pre">shape</span></code>信息，导出ONNX文件。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">project.model</span> <span class="kn">import</span> <span class="n">Model</span> <span class="k">as</span> <span class="n">PyTorchModel</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">PyTorchModel</span><span class="p">()</span>
<span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">input_shape</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="s1">&#39;/path/to/model.onnx&#39;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>验证ONNX模型与原脚本精度是否一致。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">onnxruntime</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span><span class="s1">&#39;/path/to/model.onnx&#39;</span><span class="p">)</span>
<span class="n">input_node</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="n">input_node</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/path/to/input.npy&#39;</span><span class="p">)})</span>
<span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/path/to/output.npy&#39;</span><span class="p">))</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="id7">
<h3>第1步：转换模型定义<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h3>
<p>执行MindConverter CLI命令，生成MindSpore模型文件（<code class="docutils literal notranslate"><span class="pre">model.py</span></code>）、权重信息（<code class="docutils literal notranslate"><span class="pre">ckpt</span></code>）、<span class="xref myst">转换报告与权重映射表</span>。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>mindconverter<span class="w"> </span>--model_file<span class="w"> </span>/path/to/model.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--shape<span class="w"> </span><span class="m">1</span>,3,224,224<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--input_nodes<span class="w"> </span>input_node_name<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--output_nodes<span class="w"> </span>output_node_name
</pre></div>
</div>
<p>使用ONNX模型文件迁移，需要先从<code class="docutils literal notranslate"><span class="pre">.onnx</span></code>文件中获取模型输入节点<code class="docutils literal notranslate"><span class="pre">shape</span></code>、输入节点名称、输出节点名称，推荐使用<a class="reference external" href="https://github.com/lutzroeder/netron">Netron</a>工具加载ONNX模型文件，获取上述信息。</p>
<p>模型文件（<code class="docutils literal notranslate"><span class="pre">model.py</span></code>）与权重信息（<code class="docutils literal notranslate"><span class="pre">ckpt</span></code>）可用于验证模型迁移的等价性，也可用于导出<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/save_model.html#mindir">MindIR</a>格式文件。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">project.model</span> <span class="kn">import</span> <span class="n">Network</span> <span class="k">as</span> <span class="n">MindSporeNetwork</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">MindSporeNetwork</span><span class="p">()</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="s1">&#39;network.ckpt&#39;</span><span class="p">)</span>
<span class="n">mindspore</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>

<span class="n">input_data</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/path/to/input.npy&#39;</span><span class="p">))</span>
<span class="n">output_benchmark</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/path/to/output.npy&#39;</span><span class="p">))</span>

<span class="c1"># 验证迁移等价性</span>
<span class="n">output_data</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">output_data</span><span class="p">,</span> <span class="n">output_benchmark</span><span class="p">)</span>

<span class="c1"># 导出MindIR文件</span>
<span class="n">mindspore</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">input_data</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;network_name&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;MINDIR&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>注意事项：</p>
<ol class="arabic simple">
<li><p>由于模型转换工具以推理模式加载ONNX文件，转换后会导致网络中Dropout算子丢失，需要用户手动补齐。</p></li>
<li><p>模型转换工具本质上为算子驱动，对于MindConverter未维护的ONNX算子与MindSpore算子映射，将会出现相应的算子无法转换的问题，对于该类算子，用户可手动修改，或基于MindConverter实现映射关系，向MindInsight仓库<a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.5/mindinsight/mindconverter/tutorial/add_operator_mapper_base_tutorial.ipynb">贡献</a>。</p></li>
<li><p>在使用基于计算图的迁移时，MindConverter会根据<code class="docutils literal notranslate"><span class="pre">--shape</span></code>参数将模型输入的批次大小（batch size）、句子长度（sequence length）、图片尺寸（image shape）等尺寸相关参数固定下来，用户需要保证基于MindSpore重训练、推理时输入shape与转换时一致；若需要调整输入尺寸，请重新指定<code class="docutils literal notranslate"><span class="pre">--shape</span></code>进行转换，或修改转换后脚本中涉及张量尺寸变更操作相应的操作数。</p></li>
<li><p>脚本文件和权重文件输出于同一个目录下，转换报告和权重映射表输出于同一个目录下。</p></li>
<li><p>模型文件的安全性与一致性请用户自行保证。</p></li>
</ol>
</section>
<section id="id8">
<h3>第2步：转换数据处理<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h3>
<p>内置数据集可直接查询<a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/zh-CN/r1.5/api_mapping/pytorch_api_mapping.html">接口映射</a>，自定义数据集需要自行实现，更多转换方案可参考<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/dataset_sample.html">编程指南</a>。</p>
<p>PyTorch源码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="k">class</span> <span class="nc">CustomDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">records</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>
        <span class="c1"># 定义数据增强</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)),</span>
        <span class="p">])</span>
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="c1"># 执行数据增强</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">records</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">CustomDataset</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
<p>对应MindSpore代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.dataset</span> <span class="kn">import</span> <span class="n">GeneratorDataset</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset.vision</span> <span class="kn">import</span> <span class="n">py_transforms</span> <span class="k">as</span> <span class="n">transforms</span>

<span class="k">class</span> <span class="nc">CustomGenerator</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">records</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>
        <span class="c1"># 定义数据增强</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)),</span>
        <span class="p">])</span>
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="c1"># 执行数据增强</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">records</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">CustomGenerator</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id9">
<h3>第3步：转换模型训练<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h3>
<p>损失函数（loss_fn）可查询<a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/zh-CN/r1.5/api_mapping/pytorch_api_mapping.html">接口映射</a>或自定义实现，更多转换方案可参考<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/loss.html">编程指南</a>。</p>
<p>优化器（optimizer）可查询<a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/zh-CN/r1.5/api_mapping/pytorch_api_mapping.html">接口映射</a>或自定义实现，更多转换方案可参考<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/optim.html">编程指南</a>。</p>
<p>模型训练的代码比较灵活，代码组织风格与MindSpore图模式差异较大，建议自行实现，更多转换方案可参考<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/train_and_eval.html">编程指南</a>。</p>
<p>PyTorch源码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">project.model</span> <span class="kn">import</span> <span class="n">Network</span> <span class="k">as</span> <span class="n">PyTorchNetwork</span>

<span class="c1"># 创建网络模型实例</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">PyTorchNetwork</span><span class="p">()</span>

<span class="c1"># 定义优化器与学习率</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>

<span class="c1"># 执行模型训练</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCH_SIZE</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<p>对应MindSpore代码（Low-Level API）如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">project.model</span> <span class="kn">import</span> <span class="n">Network</span> <span class="k">as</span> <span class="n">MindSporeNetwork</span>

<span class="c1"># 创建网络模型实例</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">MindSporeNetwork</span><span class="p">()</span>

<span class="c1"># 定义学习率与优化器</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ExponentialDecayLR</span><span class="p">(</span><span class="n">LEARNING_RATE</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">scheduler</span><span class="p">)</span>

<span class="c1"># 执行模型训练</span>
<span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">WithLossCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>
<span class="n">train_network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
<span class="n">train_network</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>
<span class="n">data_iterator</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_tuple_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="n">EPOCH_SIZE</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCH_SIZE</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">data_iterator</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">train_network</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
<p>对应MindSpore代码（High-Level API）如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">project.model</span> <span class="kn">import</span> <span class="n">Network</span> <span class="k">as</span> <span class="n">MindSporeNetwork</span>

<span class="c1"># 创建网络模型实例</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">MindSporeNetwork</span><span class="p">()</span>

<span class="c1"># 定义学习率与优化器</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ExponentialDecayLR</span><span class="p">(</span><span class="n">LEARNING_RATE</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">scheduler</span><span class="p">)</span>

<span class="c1"># 执行模型训练</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">EPOCH_SIZE</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id10">
<h3>第4步：转换模型推理<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h3>
<p>度量指标（<code class="docutils literal notranslate"><span class="pre">metric</span></code>），可查询<a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/zh-CN/r1.5/api_mapping/pytorch_api_mapping.html">接口映射</a>或自定义实现。</p>
<p>模型推理的代码比较灵活，代码组织风格与MindSpore图模式差异较大，建议自行实现，更多转换方案可参考<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/multi_platform_inference_ascend_910.html">编程指南</a>。</p>
<p>PyTorch源码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">project.model</span> <span class="kn">import</span> <span class="n">Network</span> <span class="k">as</span> <span class="n">PyTorchNetwork</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">PyTorchNetwork</span><span class="p">()</span>
<span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
<p>对应MindSpore代码（Low-Level API）如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">project.model</span> <span class="kn">import</span> <span class="n">Network</span> <span class="k">as</span> <span class="n">MindSporeNetwork</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">MindSporeNetwork</span><span class="p">()</span>
<span class="n">data_iterator</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_tuple_iterator</span><span class="p">()</span>
<span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">data_iterator</span><span class="p">:</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
<p>对应MindSpore代码（High-Level API）如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">project.model</span> <span class="kn">import</span> <span class="n">Network</span> <span class="k">as</span> <span class="n">MindSporeNetwork</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">MindSporeNetwork</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id11">
<h2>命令行参数说明<a class="headerlink" href="#id11" title="Permalink to this headline"></a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>usage:<span class="w"> </span>mindconverter<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span><span class="o">[</span>--version<span class="o">]</span>
<span class="w">                     </span><span class="o">[</span>--model_file<span class="w"> </span>MODEL_FILE<span class="o">]</span><span class="w"> </span><span class="o">[</span>--shape<span class="w"> </span>SHAPE<span class="w"> </span><span class="o">[</span>SHAPE<span class="w"> </span>...<span class="o">]]</span>
<span class="w">                     </span><span class="o">[</span>--input_nodes<span class="w"> </span>INPUT_NODES<span class="w"> </span><span class="o">[</span>INPUT_NODES<span class="w"> </span>...<span class="o">]]</span>
<span class="w">                     </span><span class="o">[</span>--output_nodes<span class="w"> </span>OUTPUT_NODES<span class="w"> </span><span class="o">[</span>OUTPUT_NODES<span class="w"> </span>...<span class="o">]]</span>
<span class="w">                     </span><span class="o">[</span>--output<span class="w"> </span>OUTPUT<span class="o">]</span><span class="w"> </span><span class="o">[</span>--report<span class="w"> </span>REPORT<span class="o">]</span>
</pre></div>
</div>
<p>参数含义如下：</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>参数名</p></th>
<th class="text-center head"><p>必填</p></th>
<th class="head"><p>功能描述</p></th>
<th class="text-center head"><p>类型</p></th>
<th class="text-center head"><p>默认值</p></th>
<th class="text-center head"><p>取值示例</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>-h, –help</p></td>
<td class="text-center"><p>否</p></td>
<td><p>显示帮助信息</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>-</p></td>
</tr>
<tr class="row-odd"><td><p>–version</p></td>
<td class="text-center"><p>否</p></td>
<td><p>显示版本信息</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>-</p></td>
</tr>
<tr class="row-even"><td><p>–model_file</p></td>
<td class="text-center"><p>是</p></td>
<td><p>指定模型文件路径</p></td>
<td class="text-center"><p>String</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>/path/to/model.onnx</p></td>
</tr>
<tr class="row-odd"><td><p>–shape</p></td>
<td class="text-center"><p>是</p></td>
<td><p>指定模型输入shape信息，多输入场景以空格分隔</p></td>
<td class="text-center"><p>String</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>1,3,224,224</p></td>
</tr>
<tr class="row-even"><td><p>–input_nodes</p></td>
<td class="text-center"><p>是</p></td>
<td><p>指定模型输入节点名称，多输入场景以空格分隔</p></td>
<td class="text-center"><p>String</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>input_1:0</p></td>
</tr>
<tr class="row-odd"><td><p>–output_nodes</p></td>
<td class="text-center"><p>是</p></td>
<td><p>指定模型输出节点名称，多输出场景以空格分隔</p></td>
<td class="text-center"><p>String</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>output_1:0 output_2:0</p></td>
</tr>
<tr class="row-even"><td><p>–output</p></td>
<td class="text-center"><p>否</p></td>
<td><p>指定转换生成文件的保存目录</p></td>
<td class="text-center"><p>String</p></td>
<td class="text-center"><p>$PWD</p></td>
<td class="text-center"><p>/path/to/output/dir</p></td>
</tr>
<tr class="row-odd"><td><p>–report</p></td>
<td class="text-center"><p>否</p></td>
<td><p>指定转换报告文件的保存目录</p></td>
<td class="text-center"><p>String</p></td>
<td class="text-center"><p>$PWD</p></td>
<td class="text-center"><p>/path/to/report/dir</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id12">
<h2>模型支持列表<a class="headerlink" href="#id12" title="Permalink to this headline"></a></h2>
<p>MindConverter已支持转换的模型列表，请参考<a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.5/mindinsight/mindconverter/docs/supported_model_list_cn.md#">链接</a>。</p>
</section>
<section id="id13">
<h2>错误码速查表<a class="headerlink" href="#id13" title="Permalink to this headline"></a></h2>
<p>MindConverter错误码定义，请参考<a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.5/mindinsight/mindconverter/docs/error_code_definition_cn.md#">链接</a>。</p>
</section>
<section id="id14">
<h2>常见问题<a class="headerlink" href="#id14" title="Permalink to this headline"></a></h2>
<section id="arm">
<h3>ARM环境安装依赖组件<a class="headerlink" href="#arm" title="Permalink to this headline"></a></h3>
<p>ARM环境下使用模型迁移工具，需要源码编译安装<code class="docutils literal notranslate"><span class="pre">protobuf</span></code>/<code class="docutils literal notranslate"><span class="pre">onnx</span></code>/<code class="docutils literal notranslate"><span class="pre">onnxoptimizer</span></code>，编译过程可能涉及其他系统组件，现编译报错需要人工排查，因此建议切换到x86环境中使用模型迁移工具。</p>
<ol class="arabic">
<li><p>源码编译安装<code class="docutils literal notranslate"><span class="pre">protobuf</span></code>（参考 <a class="reference external" href="https://github.com/onnx/onnx">ONNX</a>）与cpp后端。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 编译安装 protobuf</span>
git<span class="w"> </span>clone<span class="w"> </span>https://github.com/protocolbuffers/protobuf.git
<span class="nb">cd</span><span class="w"> </span>protobuf
git<span class="w"> </span>checkout<span class="w"> </span>v3.16.0
git<span class="w"> </span>submodule<span class="w"> </span>update<span class="w"> </span>--init<span class="w"> </span>--recursive
mkdir<span class="w"> </span>build_source
<span class="nb">cd</span><span class="w"> </span>build_source
cmake<span class="w"> </span>../cmake<span class="w"> </span>-Dprotobuf_BUILD_SHARED_LIBS<span class="o">=</span>OFF<span class="w"> </span>-DCMAKE_INSTALL_PREFIX<span class="o">=</span>/usr/local/protobuf<span class="w"> </span>-DCMAKE_INSTALL_SYSCONFDIR<span class="o">=</span>/etc<span class="w"> </span>-DCMAKE_POSITION_INDEPENDENT_CODE<span class="o">=</span>ON<span class="w"> </span>-Dprotobuf_BUILD_TESTS<span class="o">=</span>OFF<span class="w"> </span>-DCMAKE_BUILD_TYPE<span class="o">=</span>Release
make<span class="w"> </span>-j<span class="k">$(</span>nproc<span class="k">)</span>
make<span class="w"> </span>install

<span class="c1"># 安装cpp后端</span>
<span class="nb">cd</span><span class="w"> </span>../python
python<span class="w"> </span>setup.py<span class="w"> </span>install<span class="w"> </span>--cpp_implementation
</pre></div>
</div>
</li>
<li><p>设置<code class="docutils literal notranslate"><span class="pre">protobuf</span></code>环境变量。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">PROTOBUF_PATH</span><span class="o">=</span>/usr/local/protobuf
<span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PROTOBUF_PATH</span>/bin:<span class="nv">$PATH</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">PKG_CONFIG_PATH</span><span class="o">=</span><span class="nv">$PROTOBUF_PATH</span>/lib/pkgconfig
<span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$PROTOBUF_PATH</span>/lib:<span class="nv">$LD_LIBRARY_PATH</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">LIBRARY_PATH</span><span class="o">=</span><span class="nv">$PROTOBUF_PATH</span>/lib:<span class="nv">$LIBRARY_PATH</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION</span><span class="o">=</span>cpp
</pre></div>
</div>
</li>
<li><p>验证<code class="docutils literal notranslate"><span class="pre">protobuf</span></code>的cpp后端。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">google.protobuf.internal</span> <span class="kn">import</span> <span class="n">api_implementation</span>
<span class="nb">print</span><span class="p">(</span><span class="n">api_implementation</span><span class="o">.</span><span class="n">Type</span><span class="p">())</span>
</pre></div>
</div>
</li>
<li><p>安装<code class="docutils literal notranslate"><span class="pre">protobuf</span></code>后，需要通过源码编译方式，重新安装<code class="docutils literal notranslate"><span class="pre">onnx</span></code>，以保证<code class="docutils literal notranslate"><span class="pre">onnx</span></code>基于静态库编译的<code class="docutils literal notranslate"><span class="pre">protobuf</span></code>运行，详情参考 <a class="reference external" href="https://github.com/onnx/onnx">安装指引</a>。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/onnx/onnx.git
<span class="nb">cd</span><span class="w"> </span>onnx
git<span class="w"> </span>submodule<span class="w"> </span>update<span class="w"> </span>--init<span class="w"> </span>--recursive
<span class="c1"># prefer lite proto</span>
<span class="nb">set</span><span class="w"> </span><span class="nv">CMAKE_ARGS</span><span class="o">=</span>-DONNX_USE_LITE_PROTO<span class="o">=</span>ON
pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.
</pre></div>
</div>
</li>
<li><p>源码编译安装<code class="docutils literal notranslate"><span class="pre">onnxoptimizer</span></code>，详情参考 <a class="reference external" href="https://github.com/onnx/optimizer">安装指引</a>。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>--recursive<span class="w"> </span>https://github.com/onnx/optimizer<span class="w"> </span>onnxoptimizer
<span class="nb">cd</span><span class="w"> </span>onnxoptimizer
pip3<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.
</pre></div>
</div>
</li>
<li><p>安装<code class="docutils literal notranslate"><span class="pre">onnxruntime</span></code>。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>onnxruntime~<span class="o">=</span><span class="m">1</span>.5.2
</pre></div>
</div>
</li>
</ol>
</section>
<section id="tensorflow">
<h3>TensorFlow模型导出<a class="headerlink" href="#tensorflow" title="Permalink to this headline"></a></h3>
<p>Tensorflow模型导出PB文件，进而映射成ONNX算子，需要Tensorflow算子支持相应的ONNX算子，详情参考<a class="reference external" href="https://github.com/onnx/tensorflow-onnx/blob/master/support_status.md#">Tensorflow</a>与<a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#">ONNX</a>的算子列表。使用Keras构建模型的用户，可尝试如下方法进行导出：</p>
<p>TensorFlow 1.x版本</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="kn">import</span> <span class="n">graph_io</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.applications.inception_v3</span> <span class="kn">import</span> <span class="n">InceptionV3</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">InceptionV3</span><span class="p">()</span>
<span class="n">INPUT_NODES</span> <span class="o">=</span> <span class="p">[</span><span class="n">ipt</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">ipt</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">]</span>
<span class="n">OUTPUT_NODES</span> <span class="o">=</span> <span class="p">[</span><span class="n">opt</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>

<span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">set_learning_phase</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>
<span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">graph_inf</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">graph_util</span><span class="o">.</span><span class="n">remove_training_nodes</span><span class="p">(</span><span class="n">session</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_graph_def</span><span class="p">())</span>
    <span class="n">graph_frozen</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">graph_util</span><span class="o">.</span><span class="n">convert_variables_to_constants</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">graph_inf</span><span class="p">,</span> <span class="n">OUTPUT_NODES</span><span class="p">)</span>
    <span class="n">graph_io</span><span class="o">.</span><span class="n">write_graph</span><span class="p">(</span><span class="n">graph_frozen</span><span class="p">,</span> <span class="n">logdir</span><span class="o">=</span><span class="s2">&quot;/path/to/output/dir&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;model.pb&quot;</span><span class="p">,</span> <span class="n">as_text</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input nodes name: </span><span class="si">{</span><span class="n">INPUT_NODES</span><span class="si">}</span><span class="s2">, output nodes name: </span><span class="si">{</span><span class="n">OUTPUT_NODES</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>TensorFlow 2.x版本</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework.convert_to_constants</span> <span class="kn">import</span> <span class="n">convert_variables_to_constants_v2</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.applications</span> <span class="kn">import</span> <span class="n">InceptionV3</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">InceptionV3</span><span class="p">()</span>
<span class="n">spec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">full_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">get_concrete_function</span><span class="p">(</span><span class="n">spec</span><span class="p">)</span>
<span class="n">frozen_func</span> <span class="o">=</span> <span class="n">convert_variables_to_constants_v2</span><span class="p">(</span><span class="n">full_model</span><span class="p">)</span>
<span class="n">frozen_func</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_graph_def</span><span class="p">()</span>
<span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">write_graph</span><span class="p">(</span><span class="n">frozen_func</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">logdir</span><span class="o">=</span><span class="s2">&quot;/path/to/output/dir&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;model.pb&quot;</span><span class="p">,</span> <span class="n">as_text</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>TensorFlow不作为MindInsight明确声明的依赖库，若想使用基于图结构的模型转换工具，需要手动安装<a class="reference external" href="https://github.com/tensorflow/tensorflow">TensorFlow</a>。</p>
</section>
<section id="forward">
<h3>整改forward参数列表<a class="headerlink" href="#forward" title="Permalink to this headline"></a></h3>
<p>某些模型的<code class="docutils literal notranslate"><span class="pre">forward</span></code>参数列表中，包含非Tensor类型的入参，示例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op</span> <span class="o">=</span> <span class="n">Operator</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">LossFunction</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">loss</span>
</pre></div>
</div>
<p>其中 label 不是Tensor类型的入参，需要进行整改：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op</span> <span class="o">=</span> <span class="n">Operator</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</section>
<section id="mindspore">
<h3>MindSpore模型内嵌到原框架<a class="headerlink" href="#mindspore" title="Permalink to this headline"></a></h3>
<p>将MindSpore的模型内嵌到PyTorch脚本中，结合权重信息，验证转换的等价性。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">project.model</span> <span class="kn">import</span> <span class="n">Network</span> <span class="k">as</span> <span class="n">MindSporeNetwork</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">MindSporeNetwork</span><span class="p">()</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="s1">&#39;network.ckpt&#39;</span><span class="p">)</span>
<span class="n">mindspore</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>

<span class="n">data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
    <span class="n">ms_data</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">ms_output</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">ms_data</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">ms_output</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id15">
<h3>转换报告与权重映射表<a class="headerlink" href="#id15" title="Permalink to this headline"></a></h3>
<p>对于未成功转换的算子，转换报告记录未转换的代码行与算子信息，同时在代码中标识该节点输入/输出的<code class="docutils literal notranslate"><span class="pre">shape</span></code>（分别表示为<code class="docutils literal notranslate"><span class="pre">input_shape</span></code>与<code class="docutils literal notranslate"><span class="pre">output_shape</span></code>），便于用户手动修改。以<code class="docutils literal notranslate"><span class="pre">Reshape</span></code>算子为例，将生成如下代码：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Suppose input of `reshape` is x.</span>
        <span class="n">reshape_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># skip codes ...</span>
</pre></div>
</div>
<p>通过<code class="docutils literal notranslate"><span class="pre">input_shape</span></code>、<code class="docutils literal notranslate"><span class="pre">output_shape</span></code>参数，用户可以便捷地完成算子替换，替换结果如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>

<span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Suppose input of `reshape` is x.</span>
        <span class="n">reshape_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>
        <span class="c1"># skip codes ...</span>
</pre></div>
</div>
<p>权重映射表保存算子在MindSpore中的权重信息（<code class="docutils literal notranslate"><span class="pre">converted_weight</span></code>）和在原始框架中的权重信息（<code class="docutils literal notranslate"><span class="pre">source_weight</span></code>），示例如下：</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;resnet50&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;converted_weight&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;conv2d_0.weight&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;shape&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">64</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">],</span>
<span class="w">        </span><span class="nt">&quot;data_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Float32&quot;</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="nt">&quot;source_weight&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;conv1.weight&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;shape&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">64</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">],</span>
<span class="w">        </span><span class="nt">&quot;data_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;float32&quot;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="ast">
<h3>基于AST转换脚本<a class="headerlink" href="#ast" title="Permalink to this headline"></a></h3>
<p>MindConverter支持基于AST的方案进行PyTorch脚本迁移，通过对原脚本的抽象语法树进行解析、编辑，将其替换为MindSpore的抽象语法树，再利用抽象语法树生成代码。</p>
<blockquote>
<div><p>抽象语法树语法树解析操作受原脚本用户编码风格影响，可能导致同一模型的不同脚本最终的转换率存在一定差异，因此AST方案已调整为DEPRECATED状态，将在r2.0版本移除。</p>
</div></blockquote>
<p>假设原PyTorch脚本路径为<code class="docutils literal notranslate"><span class="pre">/path/to/model.py</span></code>，用户希望将脚本输出至<code class="docutils literal notranslate"><span class="pre">/path/to/output/dir</span></code>，转换命令如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mindconverter<span class="w"> </span>--in_file<span class="w"> </span>/path/to/model.py<span class="w"> </span>--output<span class="w"> </span>/path/to/output/dir
</pre></div>
</div>
<p>转换报告中，对于未转换的代码行形式为如下，其中x, y指明的是原PyTorch脚本中代码的行、列号。对于未成功转换的算子，可参考<a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/zh-CN/r1.5/api_mapping/pytorch_api_mapping.html">MindSporeAPI映射查询功能</a>手动对代码进行迁移。对于工具无法迁移的算子，会保留原脚本中的代码。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>line x:y: [UnConvert] &#39;operator&#39; didn&#39;t convert. ...
</pre></div>
</div>
<p>以下转换报告示例中，对于部分未成功转换的算子，转换报告提供修改建议：如<code class="docutils literal notranslate"><span class="pre">line</span> <span class="pre">157:23</span></code>，将<code class="docutils literal notranslate"><span class="pre">torch.nn.AdaptiveAvgPool2d</span></code>替换为<code class="docutils literal notranslate"><span class="pre">mindspore.ops.ReduceMean</span></code>。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span> [Start Convert]
 [Insert] &#39;from mindspore import ops&#39; is inserted to the converted file.
 line 1:0: [Convert] &#39;import torch&#39; is converted to &#39;import mindspore&#39;.
 ...
 line 157:23: [UnConvert] &#39;nn.AdaptiveAvgPool2d&#39; didn&#39;t convert. Maybe could convert to mindspore.ops.ReduceMean.
 ...
 [Convert Over]
</pre></div>
</div>
<p>AST方案不支持以下场景：</p>
<ol class="arabic">
<li><p>部分类和方法目前无法转换。</p>
<ul class="simple">
<li><p>使用<code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>的<code class="docutils literal notranslate"><span class="pre">shape</span></code>，<code class="docutils literal notranslate"><span class="pre">ndim</span></code>和<code class="docutils literal notranslate"><span class="pre">dtype</span></code>成员</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.nn.AdaptiveXXXPoolXd</span></code>和<code class="docutils literal notranslate"><span class="pre">torch.nn.functional.adaptive_XXX_poolXd()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.nn.functional.Dropout</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.unsqueeze()</span></code>和<code class="docutils literal notranslate"><span class="pre">torch.Tensor.unsqueeze()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.chunk()</span></code>和<code class="docutils literal notranslate"><span class="pre">torch.Tensor.chunk()</span></code></p></li>
</ul>
</li>
<li><p>继承的父类是<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code>的子类。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 代码片段摘自torchvision.models.mobilenet</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">ConvBNReLU</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
   <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_planes</span><span class="p">,</span> <span class="n">out_planes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
       <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
       <span class="nb">super</span><span class="p">(</span><span class="n">ConvBNReLU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
           <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">out_planes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
           <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_planes</span><span class="p">),</span>
           <span class="n">nn</span><span class="o">.</span><span class="n">ReLU6</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
       <span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="hyper_parameters_auto_tuning.html" class="btn btn-neutral float-left" title="使用mindoptimizer进行超参调优" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="performance_profiling.html" class="btn btn-neutral float-right" title="性能调试" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>