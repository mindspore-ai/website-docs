<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>集群性能调试（Ascend） &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="调试器" href="debugger.html" />
    <link rel="prev" title="性能调试（GPU）" href="performance_profiling_gpu.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_install.html">安装MindInsight</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">使用指南</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="summary_record.html">收集Summary数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="dashboard.html">查看训练看板</a></li>
<li class="toctree-l1"><a class="reference internal" href="lineage_and_scalars_comparison.html">查看溯源和对比看板</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyper_parameters_auto_tuning.html">使用mindoptimizer进行超参调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrate_3rd_scripts_mindconverter.html">使用MindConverter迁移模型定义脚本</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="performance_profiling.html">性能调试</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="performance_profiling_ascend.html">性能调试（Ascend）</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_profiling_gpu.html">性能调试（GPU）</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">集群性能调试（Ascend）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">操作流程</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">分布式训练</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">收集集群性能数据</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mindinsight">启动MindInsight</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">训练性能</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id6">集群迭代轨迹分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id7">集群通信与计算重叠时间分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8">集群通信性能分析</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id9">资源利用</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id10">集群内存使用情况分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#flops">集群FLOPs热力图分析</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id11">策略感知</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id12">计算图探索</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id14">算子策略矩阵</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id15">流水线并行视图</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id16">算子堆叠与边隐藏</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id17">规格</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id18">注意事项</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="debugger.html">调试器</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_explanation.html">解释模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="landscape.html">训练优化过程可视化</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_commands.html">MindInsight相关命令</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">精度调优指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="accuracy_problem_preliminary_location.html">精度问题初步定位指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="accuracy_optimization.html">精度问题详细定位和调优指南</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">性能调优指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning_guide.html">性能调优指南</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight.debugger.html">mindinsight.debugger</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindconverter.html">mindconverter</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="training_visual_design.html">训练可视总体设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_visual_design.html">计算图可视设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_visual_design.html">张量可视设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler_design.html">性能调试设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="performance_profiling.html">性能调试</a> &raquo;</li>
      <li>集群性能调试（Ascend）</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/performance_profiling_ascend_of_cluster.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="ascend">
<h1>集群性能调试（Ascend）<a class="headerlink" href="#ascend" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.6/docs/mindinsight/docs/source_zh_cn/performance_profiling_ascend_of_cluster.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.6/resource/_static/logo_source.png"></a></p>
<section id="id1">
<h2>概述<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<p>本教程介绍如何在Ascend AI处理器上使用MindSpore Profiler进行集群训练性能调试。</p>
</section>
<section id="id2">
<h2>操作流程<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>搭建分布式训练环境，准备分布式训练脚本，并在训练脚本中调用性能调试接口，接着运行训练脚本。</p></li>
<li><p>收集集群训练性能数据。</p></li>
<li><p>启动MindInsight，并通过启动参数指定summary-base-dir目录(summary-base-dir是Profiler所创建目录的父目录)，例如训练时Profiler创建的文件夹绝对路径为<code class="docutils literal notranslate"><span class="pre">/home/user/code/data</span></code>，则summary-base-dir设为<code class="docutils literal notranslate"><span class="pre">/home/user/code</span></code>。启动成功后，根据IP和端口访问可视化界面，默认访问地址为 <code class="docutils literal notranslate"><span class="pre">http://127.0.0.1:8080</span></code>。</p></li>
<li><p>在训练列表找到对应集群训练，点击性能分析，即可在页面中查看集群性能数据。</p></li>
</ul>
</section>
<section id="id3">
<h2>分布式训练<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h2>
<p>分布式训练请参考<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.6/distributed_training_ascend.html">分布式训练教程</a>。</p>
</section>
<section id="id4">
<h2>收集集群性能数据<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h2>
<p>多机多卡训练的时候，一次集群训练后，性能数据分布在各个主机上（host节点）。要进行集群性能分析，需要将所有主机上的性能数据收集到一台主机上进行分析。考虑到集群运行环境的复杂以及相关的权限问题、登录问题，比较合理的方式是让用户去收集集群性能数据。
下面是一次分布式集群训练后，使用脚本收集性能数据的过程，用户可以参照此脚本进行集群性能数据收集。</p>
<p>脚本程序说明：脚本程序首先创建了集群作业文件夹，然后利用SSHPass技术进行非交互式的远程拷贝（避免了手动认证，手动输入密码），将集群中各个host节点的数据拷贝到集群作业文件夹中。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>

<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;==============================================================================================================&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Please run the script as: &quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;bash collect_cluster_profiler_data.sh&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;for example: bash collect_cluster_profiler_data.sh cluster_hccl_config_path cluster_account_config_path cluster_train_id host_train_id is_absolute_path&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;==============================================================================================================&quot;</span>

<span class="nv">SSH</span><span class="o">=</span><span class="s2">&quot;ssh -o StrictHostKeyChecking=no&quot;</span>
<span class="nv">SCP</span><span class="o">=</span><span class="s2">&quot;scp -o StrictHostKeyChecking=no&quot;</span>

<span class="c1"># Get the node list in the cluster.</span>
get_cluster_list<span class="o">()</span>
<span class="o">{</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">cluster_config</span><span class="o">=</span><span class="nv">$1</span>
<span class="w">        </span>cat<span class="w"> </span><span class="si">${</span><span class="nv">cluster_config</span><span class="si">}</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>python3<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import sys,json;[print(node) for node in json.load(sys.stdin)[&quot;cluster&quot;].keys()]&#39;</span>
<span class="o">}</span>

<span class="c1"># Get the account number of node.</span>
get_node_user<span class="o">()</span>
<span class="o">{</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">cluster_config</span><span class="o">=</span><span class="nv">$1</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">node</span><span class="o">=</span><span class="nv">$2</span>
<span class="w">        </span>cat<span class="w"> </span><span class="si">${</span><span class="nv">cluster_config</span><span class="si">}</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>python3<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import sys,json;print(json.load(sys.stdin)[&quot;cluster&quot;][&#39;</span><span class="se">\&quot;</span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="se">\&quot;</span><span class="s1">&#39;][&quot;user&quot;])&#39;</span>
<span class="o">}</span>

<span class="c1"># Get the password of node.</span>
get_node_passwd<span class="o">()</span>
<span class="o">{</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">cluster_config</span><span class="o">=</span><span class="nv">$1</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">node</span><span class="o">=</span><span class="nv">$2</span>
<span class="w">        </span>cat<span class="w"> </span><span class="si">${</span><span class="nv">cluster_config</span><span class="si">}</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>python3<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import sys,json;print(json.load(sys.stdin)[&quot;cluster&quot;][&#39;</span><span class="se">\&quot;</span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="se">\&quot;</span><span class="s1">&#39;][&quot;passwd&quot;])&#39;</span>
<span class="o">}</span>

<span class="c1"># Copy data from remote node to local node.</span>
rscp_pass<span class="o">()</span>
<span class="o">{</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">node</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$1</span><span class="s2">&quot;</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">user</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$2</span><span class="s2">&quot;</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">passwd</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$3</span><span class="s2">&quot;</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">src</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$4</span><span class="s2">&quot;</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">target</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$5</span><span class="s2">&quot;</span>
<span class="w">        </span>sshpass<span class="w"> </span>-p<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">passwd</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="si">${</span><span class="nv">SCP</span><span class="si">}</span><span class="w"> </span>-r<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">user</span><span class="si">}</span><span class="s2">&quot;</span>@<span class="s2">&quot;</span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="s2">&quot;</span>:<span class="s2">&quot;</span><span class="si">${</span><span class="nv">src</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">target</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="o">}</span>

<span class="nv">cluster_hccl_config_path</span><span class="o">=</span><span class="nv">$1</span>
<span class="nv">cluster_account_config_path</span><span class="o">=</span><span class="nv">$2</span>
<span class="nv">cluster_train_id</span><span class="o">=</span><span class="nv">$3</span>
<span class="nv">host_train_id</span><span class="o">=</span><span class="nv">$4</span>
<span class="nv">is_absolute_path</span><span class="o">=</span><span class="nv">$5</span>

<span class="nv">node_list</span><span class="o">=</span><span class="k">$(</span>get_cluster_list<span class="w"> </span><span class="si">${</span><span class="nv">cluster_account_config_path</span><span class="si">}</span><span class="k">)</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;-----begin----&quot;</span>

<span class="nv">target_dir</span><span class="o">=</span><span class="si">${</span><span class="nv">cluster_train_id</span><span class="si">}</span>/profiler/
<span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span>!<span class="w"> </span>-d<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">target_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
mkdir<span class="w"> </span>-p<span class="w"> </span><span class="si">${</span><span class="nv">target_dir</span><span class="si">}</span>
<span class="k">fi</span>

<span class="k">for</span><span class="w"> </span>node<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="si">${</span><span class="nv">node_list</span><span class="si">}</span>
<span class="k">do</span>
<span class="w"> </span><span class="nv">user</span><span class="o">=</span><span class="k">$(</span>get_node_user<span class="w"> </span><span class="si">${</span><span class="nv">cluster_account_config_path</span><span class="si">}</span><span class="w"> </span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="k">)</span>
<span class="w"> </span><span class="nv">passwd</span><span class="o">=</span><span class="k">$(</span>get_node_passwd<span class="w"> </span><span class="si">${</span><span class="nv">cluster_account_config_path</span><span class="si">}</span><span class="w"> </span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="k">)</span>
<span class="w"> </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;------------------</span><span class="si">${</span><span class="nv">user</span><span class="si">}</span><span class="s2">@</span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="s2">---------------------&quot;</span>

<span class="w"> </span><span class="c1"># Eight devices data</span>
<span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="nv">$is_absolute_path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;0&#39;</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="k">then</span>
<span class="w"> </span><span class="nv">device_regex</span><span class="o">=</span><span class="k">$(</span>basename<span class="w"> </span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$host_train_id</span><span class="k">))</span>
<span class="w"> </span><span class="nv">output</span><span class="o">=</span><span class="k">$(</span>basename<span class="w"> </span><span class="nv">$host_train_id</span><span class="k">)</span>
<span class="w"> </span><span class="nv">grandfather_host_train_id</span><span class="o">=</span><span class="k">$(</span>dirname<span class="w"> </span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$host_train_id</span><span class="k">))</span>
<span class="w"> </span><span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span>i&lt;<span class="m">8</span><span class="p">;</span>i++<span class="o">))</span><span class="p">;</span>
<span class="w"> </span><span class="k">do</span>
<span class="w">   </span><span class="nv">src_dir</span><span class="o">=</span><span class="si">${</span><span class="nv">grandfather_host_train_id</span><span class="si">}</span>/<span class="si">${</span><span class="nv">device_regex</span><span class="si">}${</span><span class="nv">i</span><span class="si">}</span>/<span class="si">${</span><span class="nv">output</span><span class="si">}</span>*/profiler/*.*
<span class="w">   </span><span class="k">$(</span>rscp_pass<span class="w"> </span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="w"> </span><span class="si">${</span><span class="nv">user</span><span class="si">}</span><span class="w"> </span><span class="si">${</span><span class="nv">passwd</span><span class="si">}</span><span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">src_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="si">${</span><span class="nv">target_dir</span><span class="si">}</span><span class="k">)</span>
<span class="w"> </span><span class="k">done</span>
<span class="w"> </span><span class="k">elif</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="nv">$is_absolute_path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;1&#39;</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="k">then</span>
<span class="w"> </span><span class="nv">src_dir</span><span class="o">=</span><span class="si">${</span><span class="nv">host_train_id</span><span class="si">}</span>/profiler/*.*
<span class="w"> </span><span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span>i&lt;<span class="m">8</span><span class="p">;</span>i++<span class="o">))</span><span class="p">;</span>
<span class="w"> </span><span class="k">do</span>
<span class="w">   </span><span class="k">$(</span>rscp_pass<span class="w"> </span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="w"> </span><span class="si">${</span><span class="nv">user</span><span class="si">}</span><span class="w"> </span><span class="si">${</span><span class="nv">passwd</span><span class="si">}</span><span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">src_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="si">${</span><span class="nv">target_dir</span><span class="si">}</span><span class="k">)</span>
<span class="w"> </span><span class="k">done</span>
<span class="w"> </span><span class="k">else</span>
<span class="w"> </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;The value of is_absolute_path can only be 0 or 1.&quot;</span>
<span class="w"> </span><span class="nb">exit</span><span class="w"> </span><span class="m">1</span>
<span class="w"> </span><span class="k">fi</span>
<span class="k">done</span>
</pre></div>
</div>
<p>脚本参数说明：</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">cluster_hccl_config_path</span></code> 为多卡环境的组网信息文件路径。内容格式如下：</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1.0&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;server_count&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;server_list&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;server_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;10.xxx.xxx.1&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.1.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0&quot;</span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.2.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.3.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2&quot;</span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;3&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.4.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;3&quot;</span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;4&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.1.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;4&quot;</span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;5&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.2.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;5&quot;</span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;6&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.3.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;6&quot;</span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;7&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.4.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;7&quot;</span><span class="p">}],</span>
<span class="w">         </span><span class="nt">&quot;host_nic_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;reserve&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="p">],</span>
<span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;completed&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">cluster_account_config_path</span></code> 为各主机账号密码配置文件路径，内容格式如下：</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;rank_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;cluster&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;10.xxx.xxx.1&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;user&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;root&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;passwd&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;xxx&quot;</span>
<span class="w">                </span><span class="p">},</span>
<span class="w">                </span><span class="nt">&quot;10.xxx.xxx.2&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;user&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;root&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;passwd&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;xxx&quot;</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">              </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">cluster_train_id</span></code> 集群性能数据汇总保存的路径，比如<code class="docutils literal notranslate"><span class="pre">/home/summary/run1</span></code>、<code class="docutils literal notranslate"><span class="pre">/home/summary/run2</span></code> 其中<code class="docutils literal notranslate"><span class="pre">run1</span></code>和<code class="docutils literal notranslate"><span class="pre">run2</span></code>分别保存两次集群训练的所有性能数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">host_train_id</span></code> 集群训练中，用户设置的性能数据保存路径。当性能数据保存路径设置为绝对路径时，<code class="docutils literal notranslate"><span class="pre">host_train_id</span></code>的值即为用户设置的值。比如值为<code class="docutils literal notranslate"><span class="pre">/data/run</span></code>时，多卡性能数据均保存在<code class="docutils literal notranslate"><span class="pre">/data/run/profiler</span></code>中（<code class="docutils literal notranslate"><span class="pre">profliler</span></code>文件夹由程序自动创建），<code class="docutils literal notranslate"><span class="pre">host_train_id</span></code>值应该设置为<code class="docutils literal notranslate"><span class="pre">/data/run</span></code>。当性能数据保存路径设置为相对路径时，多卡性能数据可能保存在不同的文件夹中。比如<code class="docutils literal notranslate"><span class="pre">/data/run/device0/data/profiler</span></code>、<code class="docutils literal notranslate"><span class="pre">/data/run/device1/data/profiler</span></code>。它们的共性路径为<code class="docutils literal notranslate"><span class="pre">/data/run/device/data/profiler</span></code>，每张卡的性能数据保存路径为<code class="docutils literal notranslate"><span class="pre">/data/run/device{device_id}/data/profiler</span></code>。<code class="docutils literal notranslate"><span class="pre">host_train_id</span></code>值应该设置为<code class="docutils literal notranslate"><span class="pre">/data/run/device/data</span></code>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">is_absolute_path</span></code> 在需要收集的集群性能数据中，单机多卡数据是否保存在同一个目录中。若是，设置为1；不是，设置为0。</p></li>
</ul>
<p>通过脚本收集到的集群性能目录结构为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>|-- run
    |-- profiler
        |-- step_trace_raw_{rank_id}_detail_time.csv
</pre></div>
</div>
<blockquote>
<div><p>集群性能目录和单卡性能目录格式进行了统一。</p>
</div></blockquote>
<p>在MindInsight r1.3以及之前的版本中，集群性能目录结构如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>|-- run
    |-- hccl.json
    |-- host_ips_mapping.txt
    |-- cluster_profiler
        |-- 1
        |   |-- profiler
        |       |-- step_trace_raw_0_detail_time.csv
</pre></div>
</div>
<p>通过数据转换脚本，可以将用户使用MindInsight r1.3以及之前的版本创建的集群性能目录转换为当前支持的集群性能目录。可以从官网下载<a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.6/docs/sample_code/transform_cluster_profiler_data.py">集群目录转换脚本</a>。</p>
</section>
<section id="mindinsight">
<h2>启动MindInsight<a class="headerlink" href="#mindinsight" title="Permalink to this headline"></a></h2>
<p>启动命令请参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.6/mindinsight_commands.html">MindInsight相关命令</a>。</p>
</section>
<section id="id5">
<h2>训练性能<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h2>
<p>用户从训练列表中选择指定的训练，点击性能调试，点击<code class="docutils literal notranslate"><span class="pre">集群</span></code>Table标签，可以以集群视角展示本次训练性能数据。集群训练性能包括集群迭代轨迹分析、集群通信性能分析。</p>
<p><img alt="cluster_summary.png" src="_images/cluster_summary.png" /></p>
<p><em>图1：集群训练性能总览</em></p>
<p>图1为集群训练性能总揽，是对集群迭代轨迹组件、集群通信性能组件的总体呈现。各组件展示内容如下：</p>
<ul class="simple">
<li><p>集群迭代轨迹：展示集群中所有卡的迭代轨迹信息；总览页面展示了集群迭代轨迹性能。</p></li>
<li><p>集群通信性能: 展示集群中所有卡的通信性能以及全网链路性能；总览页面展示了集群通信性能。</p></li>
<li><p>集群性能优化小助手：左侧小助手提供集群训练时可能存在的性能瓶颈点，用户可以根据提示进行训练性能优化。</p></li>
</ul>
<section id="id6">
<h3>集群迭代轨迹分析<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<p>使用集群迭代轨迹分析组件，可以找出集群训练中的慢主机、慢卡。
集群迭代轨迹分析组件展示所有卡的迭代信息，包括迭代间隙、前反向、迭代拖尾，均支持排序操作。其中迭代间隙反映了数据处理阶段的快慢，通过卡的迭代间隙时间可以反映出对应主机处理数据的快慢。卡的前反向时间反映了卡的计算能力。迭代拖尾反映了all_reduce耗时以及并行情况。</p>
<p><img alt="cluster_iterative_trajectory.png" src="_images/cluster_iterative_trajectory.png" /></p>
<p><em>图2：集群迭代轨迹</em></p>
<p>图2展示了集群迭代轨迹分析页面，默认展示卡的性能平均值，支持查询特定step下的卡的迭代轨迹信息。通过点击单卡中的详情连接，也可以跳转到单卡的详细性能展示页面，查询详细的单卡性能数据。</p>
<p><img alt="single_car_performance_overall.png" src="_images/single_car_performance_overall.png" /></p>
<p><em>图3：单卡性能信息</em></p>
<p>图3展示集群中单卡性能信息，单卡性能信息请参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.6/performance_profiling_ascend.html">单卡性能信息</a>。</p>
</section>
<section id="id7">
<h3>集群通信与计算重叠时间分析<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h3>
<p>集群通信与计算重叠时间分析组件用于流水并行和模型并行场景，可以找出集群训练中的慢主机、慢卡。</p>
<p>集群通信与计算重叠时间分析组件新增了五项指标：纯通信时间（仅包含Receive算子）、state时间、纯通信时间、计算时间、纯通信时间（不包含Receive算子）。</p>
<ul class="simple">
<li><p>纯通信时间（仅包含Receive算子）：只有点对点（Receive）通信算子执行、计算算子不执行的时间段。该时间反应的是Pipeline并行各stage间的不同步情况。</p></li>
<li><p>stage时间：各个stage的耗时时长，该值为step时长减去该step内receive通信算子的时长。通过该指标可以查看哪个stage的耗时最长。</p></li>
<li><p>纯通信时间：只有通信算子执行、计算算子不执行的时间段。如果该部分耗时较长，说明通信耗时对性能影响较大。</p></li>
<li><p>计算时间：AI Core算子执行的时间总和，用于判断是否有慢的卡。时间越长，说明对应的卡执行速度越慢。</p></li>
<li><p>纯通信时间（不包含Receive算子）：只有除Receive通信算子外的其它通信算子执行、计算算子不执行的时间段。该时间段占的比例越大，需要考虑是否可以调整该stage内算子的切分策略，降低该时间段的耗时时长。</p></li>
</ul>
<p><img alt="cluster_pipeline-parallel_analyse.png" src="_images/cluster_pipeline-parallel_analyse_zh.png" /></p>
<p><em>图4：流水并行模式分析</em></p>
<p>图4展示了流水并行场景下页面展示的内容，默认展示所有step的平均数值。页面中展示了迭代间隙时间、纯接收时间、阶段时间、纯通信时间、计算时间、纯集合通信时间。由于整个网络的计算图被切分为多个阶段的子图，阶段时间可用于定位慢的阶段，通过选择阶段编号可以筛选出同一阶段的卡，在阶段内部可用模型并行场景的思路定位瓶颈。</p>
<p><img alt="cluster_model-parallel_analyse.png" src="_images/cluster_model-parallel_analyse_zh.png" /></p>
<p><em>图5：模型并行模式分析</em></p>
<p>图5展示了模型并行场景（此处指层内模型并行）下页面展示的内容，默认展示所有step的平均数值。页面中展示了迭代间隙时间、纯通信时间、计算时间。计算时间可用于定位慢卡，如果没有慢卡，查看通信时间与计算时间占比，若通信时间占比较大，考虑是否有慢链路。</p>
</section>
<section id="id8">
<h3>集群通信性能分析<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h3>
<p>集群通信性能组件从两个维度来展示集群通信性能信息，以卡为粒度展示和全网链路展示。</p>
<p><img alt="cluster_communication_info.png" src="_images/cluster_communication_info.png" /></p>
<p><em>图6：集群通信性能分析</em></p>
<p>图6展示了集群通信性能分析页面，包含逻辑卡通信性能以及全网链路信息（所有逻辑卡链路信息）。</p>
<p>逻辑卡通信性能TAB页主要用来展示逻辑卡的通信性能，包括通信时间、等待时间、算子详情、逻辑卡链路信息。</p>
<ul class="simple">
<li><p>通信时间：表示通信算子的通信耗时。如果通信耗时过长，有可能是某条链路有问题，可以通过链路带宽定位到具体的链路。通信时间计算方式为统计SDMA链路（server内通信）和RDMA链路（server间通信）的通信算子总耗时。如果是SDMA链路，取<code class="docutils literal notranslate"><span class="pre">Reduce</span> <span class="pre">inline</span></code>和<code class="docutils literal notranslate"><span class="pre">Memcpy</span></code>算子总时间作为通信时间；如果是RDMA链路，取连续三个算子<code class="docutils literal notranslate"><span class="pre">RDMASendPayload</span></code>、<code class="docutils literal notranslate"><span class="pre">RDMASendNotify</span></code>、<code class="docutils literal notranslate"><span class="pre">Notify</span> <span class="pre">Wait</span></code>的总时间为通信时间。</p></li>
<li><p>等待时间：也可称为同步时间。卡间进行通信前，首先会进行同步，确保通信的两张卡同步完成，再进行通信。等待时间计算方式为统计所有<code class="docutils literal notranslate"><span class="pre">Notify</span> <span class="pre">Wait</span></code>算子总耗时并减去RDMA链路通信时间中的<code class="docutils literal notranslate"><span class="pre">Notify</span> <span class="pre">Wait</span></code>算子耗时。</p></li>
<li><p>算子详情：以算子粒度展示通信性能，包括该通信算子的通信时长、等待时长、链路信息。</p></li>
<li><p>逻辑卡链路信息：显示源卡为该卡或者目的卡为该卡的链路信息。链路信息包括通信时间、通信量、带宽（通信量除以通信时间）、链路类型。其中链路类型包含SDMA链路（server内通信链路）和RDMA链路（server间通信链路）。点击详情后，通过弹窗的方式展示。</p></li>
</ul>
<p><img alt="operator_performance.png" src="_images/operator_performance.png" /></p>
<p><em>图7：算子性能信息</em></p>
<p><img alt="rank_id_link_info.png" src="_images/rank_id_link_info.png" /></p>
<p><em>图8:逻辑卡链路信息</em></p>
<p>全网链路信息TAB页面展示所有逻辑卡的链路信息，提供源卡、目的卡、链路类型的选择。</p>
<p><img alt="rank_ids_link_info.png" src="_images/rank_ids_link_info.png" /></p>
<p><em>图9：全网链路信息</em></p>
<p>默认不收集通信性能数据，需要通过<code class="docutils literal notranslate"><span class="pre">mindspore.profiler.Profiler</span></code>中的<code class="docutils literal notranslate"><span class="pre">profile_communication</span></code>参数像<code class="docutils literal notranslate"><span class="pre">Profiler(profile_communication=True)</span></code>一样打开通信性能数据开关。只有多卡训练才能产生通信算子性能数据，在单卡训练场景中设置该参数是无效的。</p>
<p>使用MindInsight可视化通信性能数据需要安装Ascend 910 AI处理器配套软件包提供的通信性能数据解析whl包，whl包随配套软件包发布，参考如下命令完成安装。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>/usr/local/Ascend/tools/hccl_parser-<span class="o">{</span>version<span class="o">}</span>-py3-none-any.whl
</pre></div>
</div>
</section>
</section>
<section id="id9">
<h2>资源利用<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h2>
<section id="id10">
<h3>集群内存使用情况分析<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h3>
<p>该页面展示了并行场景下，模型在<strong>Device侧</strong>的内存使用情况，是<strong>基于理论值的理想预估</strong>。页面内容包括：</p>
<ul class="simple">
<li><p>集群设备的分布情况，使用了哪些服务器的哪些设备。</p></li>
<li><p>集群设备的内存峰值情况，即内存峰值与可用内存占比。</p></li>
<li><p>点击某个设备，可以跳转至该设备的内存详情页面。</p></li>
</ul>
<p><img alt="cluster_memory.png" src="_images/cluster_memory.png" /></p>
<p><em>图10：集群内存概览页面</em></p>
<blockquote>
<div><p>内存使用情况分析暂不支持异构训练场景。</p>
</div></blockquote>
</section>
<section id="flops">
<h3>集群FLOPs热力图分析<a class="headerlink" href="#flops" title="Permalink to this headline"></a></h3>
<p>该页面展示了并行场景下，每个设备的FLOPs（浮点运算次）数据，热力图反映了设备之间FLOPs的相对大小。页面内容包括：</p>
<ul class="simple">
<li><p>集群设备的分布情况，使用了哪些服务器的哪些设备。</p></li>
<li><p>集群设备之间FLOPs的相对大小，每个设备对应矩形块颜色代表当前设备FLOPs与所有设备中最大FLOPs的比值。</p></li>
<li><p>点击某个设备，可以跳转至该设备的算子耗时详情页面，含有FLOPs的详细数据。</p></li>
</ul>
<p><img alt="cluster_flops.png" src="_images/cluster_flops.png" /></p>
<p><em>图11：集群FLOPs概览页面</em></p>
</section>
</section>
<section id="id11">
<h2>策略感知<a class="headerlink" href="#id11" title="Permalink to this headline"></a></h2>
<p>策略感知包括计算图探索、并行策略分析等功能模块。</p>
<section id="id12">
<h3>计算图探索<a class="headerlink" href="#id12" title="Permalink to this headline"></a></h3>
<section id="id13">
<h4>总体介绍<a class="headerlink" href="#id13" title="Permalink to this headline"></a></h4>
<p><img alt="image-20211118132511452" src="_images/profiler_strategy_graph_zh.png" /></p>
<p><em>图12：策略感知视图页面</em></p>
<p>页面右上角会显示本次训练的并行方式，上图展示出本次训练采用的并行方式是自动并行。</p>
<p>用户可根据stage选择计算图进行探索，使用图选择器可选择计算图的特定模块（正向图、反向图、重计算图）进行通信结点的抽取。</p>
<p>页面左上角为<code class="docutils literal notranslate"><span class="pre">流水线并行视图</span></code>，当训练为流水线并行训练时，该视图展示stage之间数据发送和接收关系。点击其中的算子可以跳转到图中。</p>
<p>在页面中间展示计算图，方形的结点为<code class="docutils literal notranslate"><span class="pre">聚合结点</span></code>，可以对其进行双击打开或者关闭该节点，椭圆形为普通算子。</p>
<p>聚合结点未展开时，会显示该聚合结点内各类特殊算子的数量，主要展示三类算子：含切分策略算子、重排布算子、梯度聚合算子。重排布算子是两个算子之间如果上一个算子的输出无法与下一个算子进行运算，则会自动插入一个重排布算子实现排布变换，更多细节可以参考<code class="docutils literal notranslate"><span class="pre">设计文档</span></code>中的<code class="docutils literal notranslate"><span class="pre">分布式训练设计</span></code>章节。</p>
<p>鼠标单击选中某个结点（算子或聚合结点）后，右侧结点属性面板能够展示对应结点的输入输出、切分策略等信息，面板中的输入输出算子点击可跟踪。</p>
</section>
</section>
<section id="id14">
<h3>算子策略矩阵<a class="headerlink" href="#id14" title="Permalink to this headline"></a></h3>
<p><img alt="image-20211118133144763" src="_images/profiler_strategy_graph_strategy.png" /></p>
<p><em>图13：算子策略矩阵</em></p>
<p>算子的某项输入存在切分策略时，会在该算子下方呈现一个策略矩阵，一行表示一项输入，小格子中的数字表示算子在对应维度上的切分份数。</p>
<p>鼠标悬浮在策略矩阵上，能够高亮对应的边。结合计算图中结点的输入输出定位功能，用户能够分析算子切分策略设计的合理性，调整切分策略。</p>
<p>需要注意的是，在计算图中没有绘制常量，因此针对常量的切分策略不会体现在图中。</p>
</section>
<section id="id15">
<h3>流水线并行视图<a class="headerlink" href="#id15" title="Permalink to this headline"></a></h3>
<p><img alt="image-20211118125032089" src="_images/profiler_strategy_graph_pipeline.png" /></p>
<p><em>图14：流水线并行视图</em></p>
<p>采用了流水线并行策略时，点击页面左上角的按钮，即可展开流水线并行视图。该视图展示了流水线并行中，每个stage的Send（红色矩形）和Receive算子（绿色矩形）及不同stage之间Send、Receive算子的对应关系。视图中的算子支持点击操作，在计算图中定位。</p>
<p>用户可以结合流水线并行视图，评估stage切分的合理性，直观地分析出流水线并行策略的设计细节，micro-batch数量等信息。</p>
</section>
<section id="id16">
<h3>算子堆叠与边隐藏<a class="headerlink" href="#id16" title="Permalink to this headline"></a></h3>
<p><img alt="image-20211118125032089" src="_images/profiler_strategy_graph_stack.png" /></p>
<p><em>图15：算子堆叠</em></p>
<p>在计算图中，在聚合结点中如果同类型的算子数量过多，则会对其进行堆叠展示，双击可以展开查看算子。</p>
<p><img alt="image-20211118125032089" src="_images/profiler_strategy_hideline.png" /></p>
<p><em>图16：查看被隐藏边</em></p>
<p>为了避免线过于零乱，部分不重要的边会被隐藏，鼠标悬浮在聚合结点周围的圆圈上面，可以看到被隐藏的边。</p>
</section>
</section>
<section id="id17">
<h2>规格<a class="headerlink" href="#id17" title="Permalink to this headline"></a></h2>
<ul>
<li><p>为了控制性能测试时生成数据的大小，大型网络建议性能调试的step数目限制在10以内。</p>
<blockquote>
<div><p>控制step数目可以通过控制训练数据集的大小来实现，如<code class="docutils literal notranslate"><span class="pre">mindspore.dataset.MindDataset</span></code>类中的<code class="docutils literal notranslate"><span class="pre">num_samples</span></code>参数可以控制数据集大小，详情参考：</p>
<p><a class="reference external" href="https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/dataset/mindspore.dataset.MindDataset.html">https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/dataset/mindspore.dataset.MindDataset.html</a></p>
</div></blockquote>
</li>
</ul>
</section>
<section id="id18">
<h2>注意事项<a class="headerlink" href="#id18" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>PyNative模式下暂不支持性能调试。</p></li>
<li><p>训练加推理过程暂不支持性能调试，目前支持单独训练或推理的性能调试。</p></li>
<li><p>性能调试暂不支持动态shape场景、多子图场景和控制流场景。</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="performance_profiling_gpu.html" class="btn btn-neutral float-left" title="性能调试（GPU）" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="debugger.html" class="btn btn-neutral float-right" title="调试器" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>