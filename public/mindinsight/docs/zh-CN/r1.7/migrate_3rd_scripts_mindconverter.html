

<!DOCTYPE html>
<html class="writer-html5" lang="cn" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>使用MindConverter迁移模型定义脚本 &mdash; MindSpore master 文档</title>
  

  
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="next" title="性能调试" href="performance_profiling.html" />
    <link rel="prev" title="使用mindoptimizer进行超参调优" href="hyper_parameters_auto_tuning.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_install.html">安装MindInsight</a></li>
</ul>
<p class="caption"><span class="caption-text">使用指南</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="summary_record.html">收集Summary数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="dashboard.html">查看训练看板</a></li>
<li class="toctree-l1"><a class="reference internal" href="lineage_and_scalars_comparison.html">查看溯源和对比看板</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyper_parameters_auto_tuning.html">使用mindoptimizer进行超参调优</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">使用MindConverter迁移模型定义脚本</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#工具概述">工具概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#快速开始">快速开始</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#使用命令行">使用命令行</a></li>
<li class="toctree-l3"><a class="reference internal" href="#使用api">使用API</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#工具安装">工具安装</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#环境依赖">环境依赖</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#使用命令行-1">使用命令行</a></li>
<li class="toctree-l4"><a class="reference internal" href="#使用api-1">使用API</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#安装方式">安装方式</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pip安装">pip安装</a></li>
<li class="toctree-l4"><a class="reference internal" href="#源码编译安装">源码编译安装</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#迁移方案">迁移方案</a></li>
<li class="toctree-l2"><a class="reference internal" href="#实践步骤">实践步骤</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#第0步-导出模型文件">第0步：导出模型文件</a></li>
<li class="toctree-l3"><a class="reference internal" href="#第1步-转换模型定义">第1步：转换模型定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="#第2步-转换数据处理">第2步：转换数据处理</a></li>
<li class="toctree-l3"><a class="reference internal" href="#第3步-转换模型训练">第3步：转换模型训练</a></li>
<li class="toctree-l3"><a class="reference internal" href="#第4步-转换模型推理">第4步：转换模型推理</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#命令行参数说明">命令行参数说明</a></li>
<li class="toctree-l2"><a class="reference internal" href="#模型支持列表">模型支持列表</a></li>
<li class="toctree-l2"><a class="reference internal" href="#错误码速查表">错误码速查表</a></li>
<li class="toctree-l2"><a class="reference internal" href="#常见问题">常见问题</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#arm环境安装依赖组件">ARM环境安装依赖组件</a></li>
<li class="toctree-l3"><a class="reference internal" href="#判断模型输入shape的形式">判断模型输入shape的形式</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tensorflow模型导出">TensorFlow模型导出</a></li>
<li class="toctree-l3"><a class="reference internal" href="#整改forward参数列表">整改forward参数列表</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mindspore模型内嵌到原框架">MindSpore模型内嵌到原框架</a></li>
<li class="toctree-l3"><a class="reference internal" href="#转换报告与权重映射表">转换报告与权重映射表</a></li>
<li class="toctree-l3"><a class="reference internal" href="#基于ast转换脚本">基于AST转换脚本</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="performance_profiling.html">性能调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="debugger.html">调试器</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_explanation.html">解释模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="landscape.html">训练优化过程可视化</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_commands.html">MindInsight相关命令</a></li>
</ul>
<p class="caption"><span class="caption-text">调优指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="accuracy_problem_preliminary_location.html">精度问题初步定位指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="accuracy_optimization.html">精度问题详细定位和调优指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning_guide.html">性能调优指南</a></li>
</ul>
<p class="caption"><span class="caption-text">API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight.debugger.html">mindinsight.debugger</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindconverter.html">mindconverter</a></li>
</ul>
<p class="caption"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="training_visual_design.html">训练可视总体设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_visual_design.html">计算图可视设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_visual_design.html">张量可视设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler_design.html">性能调试设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>使用MindConverter迁移模型定义脚本</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/migrate_3rd_scripts_mindconverter.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="使用mindconverter迁移模型定义脚本">
<h1>使用MindConverter迁移模型定义脚本<a class="headerlink" href="#使用mindconverter迁移模型定义脚本" title="永久链接至标题">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.7/docs/mindinsight/docs/source_zh_cn/migrate_3rd_scripts_mindconverter.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.7/resource/_static/logo_source.png"></a></p>
<div class="section" id="工具概述">
<h2>工具概述<a class="headerlink" href="#工具概述" title="永久链接至标题">¶</a></h2>
<p>MindConverter是一款模型迁移工具，可将PyTorch(ONNX)或Tensorflow(PB)模型快速迁移到MindSpore框架下使用。模型文件（ONNX/PB）包含网络模型结构（<code class="docutils literal notranslate"><span class="pre">network</span></code>）与权重信息（<code class="docutils literal notranslate"><span class="pre">weights</span></code>），迁移后将生成MindSpore框架下的模型定义脚本（<code class="docutils literal notranslate"><span class="pre">model.py</span></code>）与权重文件（<code class="docutils literal notranslate"><span class="pre">ckpt</span></code>）。</p>
<p><img alt="mindconverter-overview" src="_images/mindconverter-overview.png" /></p>
<p>此外，本工具支持通过在PyTorch网络脚本中增加API(<code class="docutils literal notranslate"><span class="pre">pytorch2mindspore</span></code>)的方式，将PyTorch网络模型迁移到MindSpore框架下。</p>
</div>
<div class="section" id="快速开始">
<h2>快速开始<a class="headerlink" href="#快速开始" title="永久链接至标题">¶</a></h2>
<p>安装MindConverter请参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.7/migrate_3rd_scripts_mindconverter.html#%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85">工具安装</a>，安装完成后可获得命令行和API如下：</p>
<div class="section" id="使用命令行">
<h3>使用命令行<a class="headerlink" href="#使用命令行" title="永久链接至标题">¶</a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>mindconverter --model_file /path/to/model_file --shape SHAPE --input_nodes INPUTS --output_nodes OUTPUTS
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--model_file</span></code>指定模型文件路径，模型文件支持<code class="docutils literal notranslate"><span class="pre">onnx</span></code>或<code class="docutils literal notranslate"><span class="pre">pb</span></code>格式。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--shape</span></code>指定模型输入shape信息，多输入场景以空格分隔。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--input_nodes</span></code>指定模型输入节点名称，多输入场景以空格分隔。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--output_nodes</span></code>指定模型输出节点名称，多输出场景以空格分隔。</p></li>
<li><p>转换结果默认输出到<code class="docutils literal notranslate"><span class="pre">$PWD/output</span></code>。</p></li>
</ul>
<p>注意事项：</p>
<ol class="simple">
<li><p>模型文件为<code class="docutils literal notranslate"><span class="pre">onnx</span></code>格式，如果模型输入shape是静态数值，只需要指定<code class="docutils literal notranslate"><span class="pre">--model_file</span></code>即可完成转换；否则需要指定<code class="docutils literal notranslate"><span class="pre">--shape</span></code>和<code class="docutils literal notranslate"><span class="pre">--input_nodes</span></code>才可完成转换；<code class="docutils literal notranslate"><span class="pre">--output_nodes</span></code>可省略。模型输入shape判断请参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.7/migrate_3rd_scripts_mindconverter.html#%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98">常见问题</a>。</p></li>
<li><p>模型文件为<code class="docutils literal notranslate"><span class="pre">pb</span></code>格式，无特殊场景。</p></li>
</ol>
<p>更多CLI参数请参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.7/migrate_3rd_scripts_mindconverter.html#%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E">命令行参数说明</a>。</p>
</div>
<div class="section" id="使用api">
<h3>使用API<a class="headerlink" href="#使用api" title="永久链接至标题">¶</a></h3>
<p>在PyTorch网络脚本中添加如下代码。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindconverter</span> <span class="kn">import</span> <span class="n">pytorch2mindspore</span>
<span class="n">pytorch2mindspore</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dummy_inputs</span><span class="p">)</span>
</pre></div>
</div>
<p>API使用方法请参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.7/mindconverter.html">MindConvrter API描述</a>。</p>
</div>
</div>
<div class="section" id="工具安装">
<h2>工具安装<a class="headerlink" href="#工具安装" title="永久链接至标题">¶</a></h2>
<div class="section" id="环境依赖">
<h3>环境依赖<a class="headerlink" href="#环境依赖" title="永久链接至标题">¶</a></h3>
<p>使用MindConverter前需要安装以下依赖包，建议在x86环境下安装。ARM环境请参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.7/migrate_3rd_scripts_mindconverter.html#arm%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%BE%9D%E8%B5%96%E7%BB%84%E4%BB%B6">常见问题</a>。</p>
<div class="section" id="使用命令行-1">
<h4>使用命令行<a class="headerlink" href="#使用命令行-1" title="永久链接至标题">¶</a></h4>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 安装配套版本的MindSpore（以r1.2版本为例）</span>
pip install mindspore~<span class="o">=</span><span class="m">1</span>.2.0

<span class="c1"># 安装onnx相关的依赖包</span>
pip install onnx~<span class="o">=</span><span class="m">1</span>.8.0
pip install onnxoptimizer~<span class="o">=</span><span class="m">0</span>.1.2
pip install onnxruntime~<span class="o">=</span><span class="m">1</span>.5.2

<span class="c1"># 如果使用 Tensorflow PB 文件转换，则需安装tf2onnx</span>
pip install tf2onnx~<span class="o">=</span><span class="m">1</span>.7.1
</pre></div>
</div>
</div>
<div class="section" id="使用api-1">
<h4>使用API<a class="headerlink" href="#使用api-1" title="永久链接至标题">¶</a></h4>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 安装配套版本的MindSpore（以r1.6版本为例）</span>
pip install mindspore~<span class="o">=</span><span class="m">1</span>.6.0

<span class="c1"># 安装Torch (建议使用Torch官方的LTS版本1.8.2)</span>
pip install <span class="nv">torch</span><span class="o">==</span><span class="m">1</span>.8.2+cpu -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html
</pre></div>
</div>
</div>
</div>
<div class="section" id="安装方式">
<h3>安装方式<a class="headerlink" href="#安装方式" title="永久链接至标题">¶</a></h3>
<p>可以采用pip或源码编译方式进行安装。</p>
<div class="section" id="pip安装">
<h4>pip安装<a class="headerlink" href="#pip安装" title="永久链接至标题">¶</a></h4>
<p>安装PyPI上的版本:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install mindconverter
</pre></div>
</div>
<p>安装自定义版本:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/<span class="o">{</span>version<span class="o">}</span>/MindInsight/any/mindconverter-<span class="o">{</span>version<span class="o">}</span>-py3-none-any.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple
</pre></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p>在联网状态下，安装whl包时会自动下载MindConverter安装包的依赖项（依赖项详情参见<a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.7/ecosystem_tools/mindconverter/requirements.txt">requirements.txt</a>），其余情况需自行安装。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">{version}</span></code>表示MindConverter版本号，例如下载1.6.0版本MindConverter时，<code class="docutils literal notranslate"><span class="pre">{version}</span></code>应写为1.6.0。</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="源码编译安装">
<h4>源码编译安装<a class="headerlink" href="#源码编译安装" title="永久链接至标题">¶</a></h4>
<p>从代码仓下载源码</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone https://gitee.com/mindspore/mindinsight.git -b r1.7
</pre></div>
</div>
<p>编译安装MindConverter，可选择以下任意一种安装方式：</p>
<ol>
<li><p>在源码根目录下执行如下命令。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> mindinsight/ecosystem_tools/mindconverter
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
python setup.py install
</pre></div>
</div>
</li>
<li><p>构建<code class="docutils literal notranslate"><span class="pre">whl</span></code>包进行安装。</p>
<p>进入源码的根目录，先执行<code class="docutils literal notranslate"><span class="pre">build</span></code>目录下的MindConverter编译脚本，再执行命令安装<code class="docutils literal notranslate"><span class="pre">output</span></code>目录下生成的<code class="docutils literal notranslate"><span class="pre">whl</span></code>包。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> mindinsight
bash build/build.sh mindconverter
pip install output/mindverter-<span class="o">{</span>version<span class="o">}</span>-py3-none-any.whl -i https://pypi.tuna.tsinghua.edu.cn/simple
</pre></div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="section" id="迁移方案">
<h2>迁移方案<a class="headerlink" href="#迁移方案" title="永久链接至标题">¶</a></h2>
<p>一个网络模型工程，通常包含以下四个主要组成部分，各部分的迁移指引如下：</p>
<ul class="simple">
<li><p>模型定义（<code class="docutils literal notranslate"><span class="pre">model.py</span></code>）</p>
<ol class="simple">
<li><p>使用MindConverter工具转换模型结构。</p></li>
<li><p>手工调整可读性（可选）。</p></li>
<li><p>转换后的模型内嵌到原框架工程，验证转换等价性，参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.7/migrate_3rd_scripts_mindconverter.html#mindspore%E6%A8%A1%E5%9E%8B%E5%86%85%E5%B5%8C%E5%88%B0%E5%8E%9F%E6%A1%86%E6%9E%B6">常见问题</a>。</p></li>
</ol>
</li>
<li><p>数据处理（<code class="docutils literal notranslate"><span class="pre">dataset.py</span></code>）</p>
<ol class="simple">
<li><p>内置数据集可查询<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.7/note/api_mapping/pytorch_api_mapping.html">接口映射</a>辅助转换。</p></li>
<li><p>自定义数据集与相关数据处理，可参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.7/migrate_3rd_scripts_mindconverter.html#%E7%AC%AC2%E6%AD%A5-%E8%BD%AC%E6%8D%A2%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86">转换模板</a>。</p></li>
</ol>
</li>
<li><p>模型训练（<code class="docutils literal notranslate"><span class="pre">train.py</span></code>）</p>
<ol class="simple">
<li><p>损失函数（<code class="docutils literal notranslate"><span class="pre">loss_fn</span></code>），可查询<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.7/note/api_mapping/pytorch_api_mapping.html">接口映射</a>或自定义实现。</p></li>
<li><p>优化器（<code class="docutils literal notranslate"><span class="pre">optimizer</span></code>），可查询<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.7/note/api_mapping/pytorch_api_mapping.html">接口映射</a>或自定义实现。</p></li>
<li><p>模型训练的代码比较灵活，代码组织风格与MindSpore图模式差异较大，建议自行实现，参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.7/migrate_3rd_scripts_mindconverter.html#%E7%AC%AC3%E6%AD%A5-%E8%BD%AC%E6%8D%A2%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83">转换模板</a>。</p></li>
</ol>
</li>
<li><p>模型推理（<code class="docutils literal notranslate"><span class="pre">eval.py</span></code>）</p>
<ol class="simple">
<li><p>度量指标（<code class="docutils literal notranslate"><span class="pre">metric</span></code>），可查询<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.7/note/api_mapping/pytorch_api_mapping.html">接口映射</a>或自定义实现。</p></li>
<li><p>模型推理的代码比较灵活，代码组织风格与MindSpore图模式差异较大，建议自行实现，参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.7/migrate_3rd_scripts_mindconverter.html#%E7%AC%AC4%E6%AD%A5-%E8%BD%AC%E6%8D%A2%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86">转换模板</a>。</p></li>
</ol>
</li>
</ul>
</div>
<div class="section" id="实践步骤">
<h2>实践步骤<a class="headerlink" href="#实践步骤" title="永久链接至标题">¶</a></h2>
<div class="section" id="第0步-导出模型文件">
<h3>第0步：导出模型文件<a class="headerlink" href="#第0步-导出模型文件" title="永久链接至标题">¶</a></h3>
<p>以PyTorch框架为例导出ONNX模型文件（Tensorflow框架请参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.7/migrate_3rd_scripts_mindconverter.html#tensorflow%E6%A8%A1%E5%9E%8B%E5%AF%BC%E5%87%BA">常见问题</a>），需要Pytorch算子支持相应的ONNX算子，详情参考<a class="reference external" href="https://pytorch.org/docs/stable/onnx.html#supported-operators">Pytorch</a>与<a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md">ONNX</a>的算子列表，操作步骤如下：</p>
<ol>
<li><p>下载网络模型工程的源码、权重文件、数据集。</p></li>
<li><p>分析模型定义代码，整改<code class="docutils literal notranslate"><span class="pre">forward</span></code>函数的入参列表，确保入参均为Tensor类型，参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.7/migrate_3rd_scripts_mindconverter.html#%E6%95%B4%E6%94%B9forward%E5%8F%82%E6%95%B0%E5%88%97%E8%A1%A8">常见问题</a>。</p></li>
<li><p>从模型推理的代码中，识别模型对象（<code class="docutils literal notranslate"><span class="pre">model</span></code>）与输入的<code class="docutils literal notranslate"><span class="pre">shape</span></code>信息，导出ONNX文件。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># 根据实际情况替换以下类路径</span>
<span class="kn">from</span> <span class="nn">customized.path.to.pytorch.model</span> <span class="kn">import</span> <span class="n">PyTorchNetwork</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">PyTorchNetwork</span><span class="p">()</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/path/to/weights.pth&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">param_dict</span><span class="p">)</span>

<span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="s1">&#39;/path/to/model.onnx&#39;</span><span class="p">,</span> <span class="n">opset_version</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>验证ONNX模型与原脚本精度是否一致。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">onnxruntime</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span><span class="s1">&#39;/path/to/model.onnx&#39;</span><span class="p">)</span>
<span class="n">input_node</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="n">input_node</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/path/to/input.npy&#39;</span><span class="p">)})</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/path/to/output.npy&#39;</span><span class="p">))</span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="第1步-转换模型定义">
<h3>第1步：转换模型定义<a class="headerlink" href="#第1步-转换模型定义" title="永久链接至标题">¶</a></h3>
<p>执行MindConverter CLI命令，生成MindSpore模型文件（<code class="docutils literal notranslate"><span class="pre">model.py</span></code>）、权重信息（<code class="docutils literal notranslate"><span class="pre">ckpt</span></code>）、<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.7/migrate_3rd_scripts_mindconverter.html#%E8%BD%AC%E6%8D%A2%E6%8A%A5%E5%91%8A%E4%B8%8E%E6%9D%83%E9%87%8D%E6%98%A0%E5%B0%84%E8%A1%A8">转换报告与权重映射表</a>。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>mindconverter --model_file /path/to/model.onnx
</pre></div>
</div>
<p>如果需要从<code class="docutils literal notranslate"><span class="pre">.onnx</span></code>文件中获取模型输入节点<code class="docutils literal notranslate"><span class="pre">shape</span></code>、输入节点名称、输出节点名称，推荐使用<a class="reference external" href="https://github.com/lutzroeder/netron">Netron</a>工具加载ONNX模型文件，获取上述信息。</p>
<p>模型文件（<code class="docutils literal notranslate"><span class="pre">model.py</span></code>）与权重信息（<code class="docutils literal notranslate"><span class="pre">ckpt</span></code>）可用于验证模型迁移的等价性，也可用于导出<a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r1.7/advanced/train/save.html#%E5%AF%BC%E5%87%BAmindir%E6%A0%BC%E5%BC%8F%E6%96%87%E4%BB%B6">MindIR</a>格式文件。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># 根据实际情况替换以下类路径</span>
<span class="kn">from</span> <span class="nn">customized.path.to.mindspore.model</span> <span class="kn">import</span> <span class="n">MindSporeNetwork</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">MindSporeNetwork</span><span class="p">()</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="s1">&#39;network.ckpt&#39;</span><span class="p">)</span>
<span class="n">mindspore</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>

<span class="n">input_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/path/to/input.npy&#39;</span><span class="p">)</span>
<span class="n">output_benchmark</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/path/to/output.npy&#39;</span><span class="p">)</span>

<span class="c1"># 验证迁移等价性</span>
<span class="n">output_data</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">input_data</span><span class="p">))</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">output_data</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">output_benchmark</span><span class="p">)</span>

<span class="c1"># 导出MindIR文件</span>
<span class="n">mindspore</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">input_data</span><span class="p">)),</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;your_network_name&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;MINDIR&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>注意事项：</p>
<ol class="simple">
<li><p>由于模型转换工具以推理模式加载ONNX文件，转换后会导致网络中Dropout算子丢失，需要用户手动补齐。</p></li>
<li><p>模型转换工具本质上为算子驱动，对于MindConverter未维护的ONNX算子与MindSpore算子映射，将会出现相应的算子无法转换的问题，对于该类算子，用户可手动修改，或基于MindConverter实现映射关系，向MindInsight仓库<a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.7/ecosystem_tools/mindconverter/tutorial/add_onnx2mindspore_operator_mapper_advanced_tutorial.ipynb">贡献</a>。</p></li>
<li><p>在使用基于计算图的迁移时，MindConverter会根据<code class="docutils literal notranslate"><span class="pre">--shape</span></code>参数将模型输入的批次大小（batch size）、句子长度（sequence length）、图片尺寸（image shape）等尺寸相关参数固定下来，用户需要保证基于MindSpore重训练、推理时输入shape与转换时一致；若需要调整输入尺寸，请重新指定<code class="docutils literal notranslate"><span class="pre">--shape</span></code>进行转换，或修改转换后脚本中涉及张量尺寸变更操作相应的操作数。</p></li>
<li><p>脚本文件和权重文件输出于同一个目录下，转换报告和权重映射表输出于同一个目录下。</p></li>
<li><p>模型文件的安全性与一致性请用户自行保证。</p></li>
</ol>
</div>
<div class="section" id="第2步-转换数据处理">
<h3>第2步：转换数据处理<a class="headerlink" href="#第2步-转换数据处理" title="永久链接至标题">¶</a></h3>
<p>内置数据集可直接查询<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.7/note/api_mapping/pytorch_api_mapping.html">接口映射</a>，自定义数据集需要自行实现，更多转换方案可参考<a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r1.7/advanced/dataset.html">数据处理</a>。</p>
<p>PyTorch源码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="k">class</span> <span class="nc">CustomDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">records</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>
        <span class="c1"># 定义数据增强</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)),</span>
        <span class="p">])</span>
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="c1"># 执行数据增强</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">records</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">CustomDataset</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
<p>对应MindSpore代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.dataset</span> <span class="kn">import</span> <span class="n">GeneratorDataset</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset</span> <span class="kn">import</span> <span class="n">py_transforms</span> <span class="k">as</span> <span class="n">transforms</span>

<span class="k">class</span> <span class="nc">CustomGenerator</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">records</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>
        <span class="c1"># 定义数据增强</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)),</span>
        <span class="p">])</span>
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="c1"># 执行数据增强</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">records</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">CustomGenerator</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="第3步-转换模型训练">
<h3>第3步：转换模型训练<a class="headerlink" href="#第3步-转换模型训练" title="永久链接至标题">¶</a></h3>
<p>损失函数（loss_fn）可查询<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.7/note/api_mapping/pytorch_api_mapping.html">接口映射</a>或自定义实现，更多转换方案可参考<a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r1.7/advanced/network/loss.html">损失函数</a>。</p>
<p>优化器（optimizer）可查询<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.7/note/api_mapping/pytorch_api_mapping.html">接口映射</a>或自定义实现，更多转换方案可参考<a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r1.7/advanced/network/optim.html">优化器</a>。</p>
<p>模型训练的代码比较灵活，代码组织风格与MindSpore图模式差异较大，建议自行实现，更多转换方案可参考<a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r1.7/advanced/network.html">网络构建</a>。</p>
<p>PyTorch源码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># 根据实际情况替换以下类路径</span>
<span class="kn">from</span> <span class="nn">customized.path.to.pytorch.model</span> <span class="kn">import</span> <span class="n">PyTorchNetwork</span>

<span class="c1"># 创建网络模型实例</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">PyTorchNetwork</span><span class="p">()</span>

<span class="c1"># 定义优化器与学习率</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">DECAY_RATE</span><span class="p">)</span>

<span class="c1"># 执行模型训练</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCH_SIZE</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<p>对应MindSpore代码（Low-Level API）如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="c1"># 根据实际情况替换以下类路径</span>
<span class="kn">from</span> <span class="nn">customized.path.to.mindspore.model</span> <span class="kn">import</span> <span class="n">MindSporeNetwork</span>

<span class="c1"># 创建网络模型实例</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">MindSporeNetwork</span><span class="p">()</span>

<span class="c1"># 定义学习率与优化器</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ExponentialDecayLR</span><span class="p">(</span><span class="n">LEARNING_RATE</span><span class="p">,</span> <span class="n">decay_rate</span><span class="o">=</span><span class="n">DECAY_RATE</span><span class="p">,</span> <span class="n">decay_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">scheduler</span><span class="p">)</span>

<span class="c1"># 执行模型训练</span>
<span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">WithLossCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>
<span class="n">train_network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
<span class="n">train_network</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>
<span class="n">data_iterator</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_tuple_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="n">EPOCH_SIZE</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCH_SIZE</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">data_iterator</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">train_network</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
<p>对应MindSpore代码（High-Level API）如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="c1"># 根据实际情况替换以下类路径</span>
<span class="kn">from</span> <span class="nn">customized.path.to.mindspore.model</span> <span class="kn">import</span> <span class="n">MindSporeNetwork</span>

<span class="c1"># 创建网络模型实例</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">MindSporeNetwork</span><span class="p">()</span>

<span class="c1"># 定义学习率与优化器</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ExponentialDecayLR</span><span class="p">(</span><span class="n">LEARNING_RATE</span><span class="p">,</span> <span class="n">decay_rate</span><span class="o">=</span><span class="n">DECAY_RATE</span><span class="p">,</span> <span class="n">decay_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">scheduler</span><span class="p">)</span>

<span class="c1"># 执行模型训练</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">EPOCH_SIZE</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="第4步-转换模型推理">
<h3>第4步：转换模型推理<a class="headerlink" href="#第4步-转换模型推理" title="永久链接至标题">¶</a></h3>
<p>度量指标（<code class="docutils literal notranslate"><span class="pre">metric</span></code>），可查询<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.7/note/api_mapping/pytorch_api_mapping.html">接口映射</a>或自定义实现。</p>
<p>模型推理的代码比较灵活，代码组织风格与MindSpore图模式差异较大，建议自行实现，更多转换方案可参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r1.7/infer/inference.html">模型推理</a>。</p>
<p>PyTorch源码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># 根据实际情况替换以下类路径</span>
<span class="kn">from</span> <span class="nn">customized.path.to.pytorch.model</span> <span class="kn">import</span> <span class="n">PyTorchNetwork</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">PyTorchNetwork</span><span class="p">()</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/path/to/weights.path&#39;</span><span class="p">)</span>
<span class="n">network</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">param_dict</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</pre></div>
</div>
<p>对应MindSpore代码（Low-Level API）如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>

<span class="c1"># 根据实际情况替换以下类路径</span>
<span class="kn">from</span> <span class="nn">customized.path.to.mindspore.model</span> <span class="kn">import</span> <span class="n">MindSporeNetwork</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">MindSporeNetwork</span><span class="p">()</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="s1">&#39;/path/to/weights.ckpt&#39;</span><span class="p">)</span>
<span class="n">mindspore</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>

<span class="n">data_iterator</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_tuple_iterator</span><span class="p">()</span>
<span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">data_iterator</span><span class="p">:</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</pre></div>
</div>
<p>对应MindSpore代码（High-Level API）如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="c1"># 根据实际情况替换以下类路径</span>
<span class="kn">from</span> <span class="nn">customized.path.to.mindspore.model</span> <span class="kn">import</span> <span class="n">MindSporeNetwork</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">MindSporeNetwork</span><span class="p">()</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="s1">&#39;/path/to/weights.ckpt&#39;</span><span class="p">)</span>
<span class="n">mindspore</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;accuracy&#39;</span><span class="p">})</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="命令行参数说明">
<h2>命令行参数说明<a class="headerlink" href="#命令行参数说明" title="永久链接至标题">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>usage: mindconverter <span class="o">[</span>-h<span class="o">]</span> <span class="o">[</span>--version<span class="o">]</span>
                     <span class="o">[</span>--model_file MODEL_FILE<span class="o">]</span> <span class="o">[</span>--shape SHAPE <span class="o">[</span>SHAPE ...<span class="o">]]</span>
                     <span class="o">[</span>--input_nodes INPUT_NODES <span class="o">[</span>INPUT_NODES ...<span class="o">]]</span>
                     <span class="o">[</span>--output_nodes OUTPUT_NODES <span class="o">[</span>OUTPUT_NODES ...<span class="o">]]</span>
                     <span class="o">[</span>--output OUTPUT<span class="o">]</span> <span class="o">[</span>--report REPORT<span class="o">]</span>
</pre></div>
</div>
<p>参数含义如下：</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>参数名</th>
<th style="text-align: center;">必填</th>
<th>功能描述</th>
<th style="text-align: center;">类型</th>
<th style="text-align: center;">默认值</th>
<th style="text-align: center;">取值示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>-h, --help</td>
<td style="text-align: center;">否</td>
<td>显示帮助信息</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td>--version</td>
<td style="text-align: center;">否</td>
<td>显示版本信息</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td>--model_file</td>
<td style="text-align: center;">是</td>
<td>指定模型文件路径</td>
<td style="text-align: center;">String</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">/path/to/model.onnx</td>
</tr>
<tr>
<td>--shape</td>
<td style="text-align: center;">是</td>
<td>指定模型输入shape信息，多输入场景以空格分隔</td>
<td style="text-align: center;">String</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">1,3,224,224</td>
</tr>
<tr>
<td>--input_nodes</td>
<td style="text-align: center;">是</td>
<td>指定模型输入节点名称，多输入场景以空格分隔</td>
<td style="text-align: center;">String</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">input_1:0</td>
</tr>
<tr>
<td>--output_nodes</td>
<td style="text-align: center;">是</td>
<td>指定模型输出节点名称，多输出场景以空格分隔</td>
<td style="text-align: center;">String</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">output_1:0 output_2:0</td>
</tr>
<tr>
<td>--output</td>
<td style="text-align: center;">否</td>
<td>指定转换生成文件的保存目录</td>
<td style="text-align: center;">String</td>
<td style="text-align: center;">$PWD</td>
<td style="text-align: center;">/path/to/output/dir</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="模型支持列表">
<h2>模型支持列表<a class="headerlink" href="#模型支持列表" title="永久链接至标题">¶</a></h2>
<p>MindConverter已支持转换的模型列表，请参考<a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.7/ecosystem_tools/mindconverter/docs/supported_model_list_cn.md">链接</a>。</p>
</div>
<div class="section" id="错误码速查表">
<h2>错误码速查表<a class="headerlink" href="#错误码速查表" title="永久链接至标题">¶</a></h2>
<p>MindConverter错误码定义，请参考<a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.7/ecosystem_tools/mindconverter/docs/error_code_definition_cn.md">链接</a>。</p>
</div>
<div class="section" id="常见问题">
<h2>常见问题<a class="headerlink" href="#常见问题" title="永久链接至标题">¶</a></h2>
<div class="section" id="arm环境安装依赖组件">
<h3>ARM环境安装依赖组件<a class="headerlink" href="#arm环境安装依赖组件" title="永久链接至标题">¶</a></h3>
<p>ARM环境下使用模型迁移工具，需要源码编译安装<code class="docutils literal notranslate"><span class="pre">protobuf</span></code>/<code class="docutils literal notranslate"><span class="pre">onnx</span></code>/<code class="docutils literal notranslate"><span class="pre">onnxoptimizer</span></code>，编译过程可能涉及其他系统组件，现编译报错需要人工排查，因此建议切换到x86环境中使用模型迁移工具。</p>
<ol>
<li><p>源码编译安装<code class="docutils literal notranslate"><span class="pre">protobuf</span></code>（参考 <a class="reference external" href="https://github.com/onnx/onnx">ONNX</a>）与cpp后端。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 编译安装 protobuf</span>
git clone https://github.com/protocolbuffers/protobuf.git
<span class="nb">cd</span> protobuf
git checkout v3.16.0
git submodule update --init --recursive
mkdir build_source
<span class="nb">cd</span> build_source
cmake ../cmake -Dprotobuf_BUILD_SHARED_LIBS<span class="o">=</span>OFF -DCMAKE_INSTALL_PREFIX<span class="o">=</span>/usr/local/protobuf -DCMAKE_INSTALL_SYSCONFDIR<span class="o">=</span>/etc -DCMAKE_POSITION_INDEPENDENT_CODE<span class="o">=</span>ON -Dprotobuf_BUILD_TESTS<span class="o">=</span>OFF -DCMAKE_BUILD_TYPE<span class="o">=</span>Release
make -j<span class="k">$(</span>nproc<span class="k">)</span>
make install

<span class="c1"># 安装cpp后端</span>
<span class="nb">cd</span> ../python
python setup.py install --cpp_implementation
</pre></div>
</div>
</li>
<li><p>设置<code class="docutils literal notranslate"><span class="pre">protobuf</span></code>环境变量。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">PROTOBUF_PATH</span><span class="o">=</span>/usr/local/protobuf
<span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span><span class="nv">$PROTOBUF_PATH</span>/bin:<span class="nv">$PATH</span>
<span class="nb">export</span> <span class="nv">PKG_CONFIG_PATH</span><span class="o">=</span><span class="nv">$PROTOBUF_PATH</span>/lib/pkgconfig
<span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$PROTOBUF_PATH</span>/lib:<span class="nv">$LD_LIBRARY_PATH</span>
<span class="nb">export</span> <span class="nv">LIBRARY_PATH</span><span class="o">=</span><span class="nv">$PROTOBUF_PATH</span>/lib:<span class="nv">$LIBRARY_PATH</span>
<span class="nb">export</span> <span class="nv">PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION</span><span class="o">=</span>cpp
</pre></div>
</div>
</li>
<li><p>验证<code class="docutils literal notranslate"><span class="pre">protobuf</span></code>的cpp后端。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">google.protobuf.internal</span> <span class="kn">import</span> <span class="n">api_implementation</span>
<span class="nb">print</span><span class="p">(</span><span class="n">api_implementation</span><span class="o">.</span><span class="n">Type</span><span class="p">())</span>
</pre></div>
</div>
</li>
<li><p>安装<code class="docutils literal notranslate"><span class="pre">protobuf</span></code>后，需要通过源码编译方式，重新安装<code class="docutils literal notranslate"><span class="pre">onnx</span></code>，以保证<code class="docutils literal notranslate"><span class="pre">onnx</span></code>基于静态库编译的<code class="docutils literal notranslate"><span class="pre">protobuf</span></code>运行，详情参考 <a class="reference external" href="https://github.com/onnx/onnx">安装指引</a>。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/onnx/onnx.git
<span class="nb">cd</span> onnx
git submodule update --init --recursive
<span class="c1"># prefer lite proto</span>
<span class="nb">set</span> <span class="nv">CMAKE_ARGS</span><span class="o">=</span>-DONNX_USE_LITE_PROTO<span class="o">=</span>ON
pip install -e .
</pre></div>
</div>
</li>
<li><p>源码编译安装<code class="docutils literal notranslate"><span class="pre">onnxoptimizer</span></code>，详情参考 <a class="reference external" href="https://github.com/onnx/optimizer">安装指引</a>。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>git clone --recursive https://github.com/onnx/optimizer onnxoptimizer
<span class="nb">cd</span> onnxoptimizer
pip3 install -e .
</pre></div>
</div>
</li>
<li><p>安装<code class="docutils literal notranslate"><span class="pre">onnxruntime</span></code>。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip install onnxruntime~<span class="o">=</span><span class="m">1</span>.5.2
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="判断模型输入shape的形式">
<h3>判断模型输入shape的形式<a class="headerlink" href="#判断模型输入shape的形式" title="永久链接至标题">¶</a></h3>
<p>使用<a class="reference external" href="https://github.com/lutzroeder/netron">Netron</a>工具加载ONNX模型文件，点击最上面的一个节点，观察侧栏中<code class="docutils literal notranslate"><span class="pre">INPUTS</span></code>里每一个输入的type，如果type是一个具体数值，如<code class="docutils literal notranslate"><span class="pre">int64[1,9]</span></code>，那么当前输入为静态；否则为动态，如<code class="docutils literal notranslate"><span class="pre">int64[batch,sequence]</span></code>。</p>
</div>
<div class="section" id="tensorflow模型导出">
<h3>TensorFlow模型导出<a class="headerlink" href="#tensorflow模型导出" title="永久链接至标题">¶</a></h3>
<p>Tensorflow模型导出PB文件，进而映射成ONNX算子，需要Tensorflow算子支持相应的ONNX算子，详情参考<a class="reference external" href="https://github.com/onnx/tensorflow-onnx/blob/master/support_status.md">Tensorflow</a>与<a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md">ONNX</a>的算子列表。使用Keras构建模型的用户，可尝试如下方法进行导出：</p>
<p>TensorFlow 1.x版本</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="kn">import</span> <span class="n">graph_io</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.applications.inception_v3</span> <span class="kn">import</span> <span class="n">InceptionV3</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">InceptionV3</span><span class="p">()</span>
<span class="n">INPUT_NODES</span> <span class="o">=</span> <span class="p">[</span><span class="n">ipt</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">ipt</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">]</span>
<span class="n">OUTPUT_NODES</span> <span class="o">=</span> <span class="p">[</span><span class="n">opt</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>

<span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">set_learning_phase</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>
<span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">graph_inf</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">graph_util</span><span class="o">.</span><span class="n">remove_training_nodes</span><span class="p">(</span><span class="n">session</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_graph_def</span><span class="p">())</span>
    <span class="n">graph_frozen</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">graph_util</span><span class="o">.</span><span class="n">convert_variables_to_constants</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">graph_inf</span><span class="p">,</span> <span class="n">OUTPUT_NODES</span><span class="p">)</span>
    <span class="n">graph_io</span><span class="o">.</span><span class="n">write_graph</span><span class="p">(</span><span class="n">graph_frozen</span><span class="p">,</span> <span class="n">logdir</span><span class="o">=</span><span class="s2">&quot;/path/to/output/dir&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;model.pb&quot;</span><span class="p">,</span> <span class="n">as_text</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input nodes name: </span><span class="si">{</span><span class="n">INPUT_NODES</span><span class="si">}</span><span class="s2">, output nodes name: </span><span class="si">{</span><span class="n">OUTPUT_NODES</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>TensorFlow 2.x版本</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework.convert_to_constants</span> <span class="kn">import</span> <span class="n">convert_variables_to_constants_v2</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.applications</span> <span class="kn">import</span> <span class="n">InceptionV3</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">InceptionV3</span><span class="p">()</span>
<span class="n">spec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">full_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">get_concrete_function</span><span class="p">(</span><span class="n">spec</span><span class="p">)</span>
<span class="n">frozen_func</span> <span class="o">=</span> <span class="n">convert_variables_to_constants_v2</span><span class="p">(</span><span class="n">full_model</span><span class="p">)</span>
<span class="n">frozen_func</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_graph_def</span><span class="p">()</span>
<span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">write_graph</span><span class="p">(</span><span class="n">frozen_func</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">logdir</span><span class="o">=</span><span class="s2">&quot;/path/to/output/dir&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;model.pb&quot;</span><span class="p">,</span> <span class="n">as_text</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>TensorFlow不作为MindConverter明确声明的依赖库，若想使用基于图结构的模型转换工具，需要手动安装<a class="reference external" href="https://github.com/tensorflow/tensorflow">TensorFlow</a>。</p>
</div>
<div class="section" id="整改forward参数列表">
<h3>整改forward参数列表<a class="headerlink" href="#整改forward参数列表" title="永久链接至标题">¶</a></h3>
<p>某些模型的<code class="docutils literal notranslate"><span class="pre">forward</span></code>参数列表中，包含非Tensor类型的入参，示例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op</span> <span class="o">=</span> <span class="n">Operator</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">LossFunction</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">loss</span>
</pre></div>
</div>
<p>其中 label 不是Tensor类型的入参，需要进行整改：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op</span> <span class="o">=</span> <span class="n">Operator</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</div>
<div class="section" id="mindspore模型内嵌到原框架">
<h3>MindSpore模型内嵌到原框架<a class="headerlink" href="#mindspore模型内嵌到原框架" title="永久链接至标题">¶</a></h3>
<p>将MindSpore的模型内嵌到PyTorch脚本中，结合权重信息，验证转换的等价性。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="c1"># 根据实际情况替换以下类路径</span>
<span class="kn">from</span> <span class="nn">customized.path.to.mindspore.model</span> <span class="kn">import</span> <span class="n">MindSporeNetwork</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">MindSporeNetwork</span><span class="p">()</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="s1">&#39;network.ckpt&#39;</span><span class="p">)</span>
<span class="n">mindspore</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>

<span class="n">data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
    <span class="n">ms_data</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">ms_output</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">ms_data</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">ms_output</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="转换报告与权重映射表">
<h3>转换报告与权重映射表<a class="headerlink" href="#转换报告与权重映射表" title="永久链接至标题">¶</a></h3>
<p>对于未成功转换的算子，转换报告记录未转换的代码行与算子信息，同时在代码中标识该节点输入/输出的<code class="docutils literal notranslate"><span class="pre">shape</span></code>（分别表示为<code class="docutils literal notranslate"><span class="pre">input_shape</span></code>与<code class="docutils literal notranslate"><span class="pre">output_shape</span></code>），便于用户手动修改。以<code class="docutils literal notranslate"><span class="pre">Reshape</span></code>算子为例，将生成如下代码：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Suppose input of `reshape` is x.</span>
        <span class="n">reshape_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># skip codes ...</span>
</pre></div>
</div>
<p>通过<code class="docutils literal notranslate"><span class="pre">input_shape</span></code>、<code class="docutils literal notranslate"><span class="pre">output_shape</span></code>参数，用户可以便捷地完成算子替换，替换结果如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>

<span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Suppose input of `reshape` is x.</span>
        <span class="n">reshape_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>
        <span class="c1"># skip codes ...</span>
</pre></div>
</div>
<p>权重映射表保存算子在MindSpore中的权重信息（<code class="docutils literal notranslate"><span class="pre">converted_weight</span></code>）和在原始框架中的权重信息（<code class="docutils literal notranslate"><span class="pre">source_weight</span></code>），示例如下：</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="nt">&quot;resnet50&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="nt">&quot;converted_weight&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;conv2d_0.weight&quot;</span><span class="p">,</span>
        <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
        <span class="nt">&quot;data_type&quot;</span><span class="p">:</span> <span class="s2">&quot;Float32&quot;</span>
      <span class="p">},</span>
      <span class="nt">&quot;source_weight&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;conv1.weight&quot;</span><span class="p">,</span>
        <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
        <span class="nt">&quot;data_type&quot;</span><span class="p">:</span> <span class="s2">&quot;float32&quot;</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="基于ast转换脚本">
<h3>基于AST转换脚本<a class="headerlink" href="#基于ast转换脚本" title="永久链接至标题">¶</a></h3>
<p>MindConverter支持基于AST的方案进行PyTorch脚本迁移，通过对原脚本的抽象语法树进行解析、编辑，将其替换为MindSpore的抽象语法树，再利用抽象语法树生成代码。</p>
<blockquote>
<div><p>抽象语法树语法树解析操作受原脚本用户编码风格影响，可能导致同一模型的不同脚本最终的转换率存在一定差异，因此AST方案已调整为DEPRECATED状态，将在r2.0版本移除。</p>
</div></blockquote>
<p>假设原PyTorch脚本路径为<code class="docutils literal notranslate"><span class="pre">/path/to/model.py</span></code>，用户希望将脚本输出至<code class="docutils literal notranslate"><span class="pre">/path/to/output/dir</span></code>，转换命令如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mindconverter --in_file /path/to/model.py --output /path/to/output/dir
</pre></div>
</div>
<p>转换报告中，对于未转换的代码行形式为如下，其中x, y指明的是原PyTorch脚本中代码的行、列号。对于未成功转换的算子，可参考<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.7/note/api_mapping/pytorch_api_mapping.html">MindSporeAPI映射查询功能</a>手动对代码进行迁移。对于工具无法迁移的算子，会保留原脚本中的代码。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>line x:y: [UnConvert] &#39;operator&#39; didn&#39;t convert. ...
</pre></div>
</div>
<p>以下转换报告示例中，对于部分未成功转换的算子，转换报告提供修改建议：如<code class="docutils literal notranslate"><span class="pre">line</span> <span class="pre">157:23</span></code>，将<code class="docutils literal notranslate"><span class="pre">torch.nn.AdaptiveAvgPool2d</span></code>替换为<code class="docutils literal notranslate"><span class="pre">mindspore.ops.ReduceMean</span></code>。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span> [Start Convert]
 [Insert] &#39;from mindspore import ops&#39; is inserted to the converted file.
 line 1:0: [Convert] &#39;import torch&#39; is converted to &#39;import mindspore&#39;.
 ...
 line 157:23: [UnConvert] &#39;nn.AdaptiveAvgPool2d&#39; didn&#39;t convert. Maybe could convert to mindspore.ops.ReduceMean.
 ...
 [Convert Over]
</pre></div>
</div>
<p>AST方案不支持以下场景：</p>
<ol>
<li><p>部分类和方法目前无法转换。</p>
<ul class="simple">
<li><p>使用<code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>的<code class="docutils literal notranslate"><span class="pre">shape</span></code>，<code class="docutils literal notranslate"><span class="pre">ndim</span></code>和<code class="docutils literal notranslate"><span class="pre">dtype</span></code>成员</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.nn.AdaptiveXXXPoolXd</span></code>和<code class="docutils literal notranslate"><span class="pre">torch.nn.functional.adaptive_XXX_poolXd()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.nn.functional.Dropout</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.unsqueeze()</span></code>和<code class="docutils literal notranslate"><span class="pre">torch.Tensor.unsqueeze()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.chunk()</span></code>和<code class="docutils literal notranslate"><span class="pre">torch.Tensor.chunk()</span></code></p></li>
</ul>
</li>
<li><p>继承的父类是<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code>的子类。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 代码片段摘自torchvision.models.mobilenet</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">ConvBNReLU</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
   <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_planes</span><span class="p">,</span> <span class="n">out_planes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
       <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
       <span class="nb">super</span><span class="p">(</span><span class="n">ConvBNReLU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
           <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">out_planes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
           <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_planes</span><span class="p">),</span>
           <span class="n">nn</span><span class="o">.</span><span class="n">ReLU6</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
       <span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="performance_profiling.html" class="btn btn-neutral float-right" title="性能调试" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="hyper_parameters_auto_tuning.html" class="btn btn-neutral float-left" title="使用mindoptimizer进行超参调优" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2021, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>