<!DOCTYPE html>
<html class="writer-html5" lang="cn" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>集群性能调试 &mdash; MindSpore master 文档</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="next" title="调试器" href="debugger.html" />
    <link rel="prev" title="性能调试（GPU-Graph）" href="performance_profiling_gpu.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_install.html">安装MindInsight</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">使用指南</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="summary_record.html">收集Summary数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="dashboard.html">查看训练看板</a></li>
<li class="toctree-l1"><a class="reference internal" href="lineage_and_scalars_comparison.html">查看溯源和对比看板</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyper_parameters_auto_tuning.html">使用mindoptimizer进行超参调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrate_3rd_scripts_mindconverter.html">使用MindConverter迁移模型定义脚本</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="performance_profiling.html">性能调试</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="performance_profiling_ascend.html">性能调试（Ascend-Graph）</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_profiling_ascend_pynative.html">性能调试（Ascend-PyNative）</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_profiling_gpu.html">性能调试（GPU-Graph）</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">集群性能调试</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#概述">概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#操作流程">操作流程</a></li>
<li class="toctree-l3"><a class="reference internal" href="#分布式训练">分布式训练</a></li>
<li class="toctree-l3"><a class="reference internal" href="#收集集群性能数据">收集集群性能数据</a></li>
<li class="toctree-l3"><a class="reference internal" href="#启动mindinsight">启动MindInsight</a></li>
<li class="toctree-l3"><a class="reference internal" href="#训练性能">训练性能</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#集群迭代轨迹分析">集群迭代轨迹分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#集群通信与计算重叠时间分析">集群通信与计算重叠时间分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#集群通信性能分析">集群通信性能分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#规格">规格</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#资源利用">资源利用</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#集群内存使用情况分析">集群内存使用情况分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#集群flops热力图分析">集群FLOPs热力图分析</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#策略感知">策略感知</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#计算图探索">计算图探索</a></li>
<li class="toctree-l4"><a class="reference internal" href="#算子策略矩阵">算子策略矩阵</a></li>
<li class="toctree-l4"><a class="reference internal" href="#流水线并行视图">流水线并行视图</a></li>
<li class="toctree-l4"><a class="reference internal" href="#算子堆叠与边隐藏">算子堆叠与边隐藏</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#执行总览">执行总览</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#计算图执行序分析">计算图执行序分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#各设备算子执行时间线分析">各设备算子执行时间线分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="#各设备时间信息概览">各设备时间信息概览</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#规格-1">规格</a></li>
<li class="toctree-l3"><a class="reference internal" href="#注意事项">注意事项</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="debugger.html">调试器</a></li>
<li class="toctree-l1"><a class="reference internal" href="landscape.html">训练优化过程可视化</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_commands.html">MindInsight相关命令</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">调优指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="accuracy_problem_preliminary_location.html">精度问题初步定位指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="accuracy_optimization.html">精度问题详细定位和调优指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning_guide.html">性能调优指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_optimization.html">性能调试案例</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindinsight.debugger.html">mindinsight.debugger</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="training_visual_design.html">训练可视总体设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_visual_design.html">计算图可视设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_visual_design.html">张量可视设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler_design.html">性能调试设计</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="performance_profiling.html">性能调试</a> &raquo;</li>
      <li>集群性能调试</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/performance_profiling_of_cluster.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="集群性能调试">
<h1>集群性能调试<a class="headerlink" href="#集群性能调试" title="永久链接至标题"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.9/docs/mindinsight/docs/source_zh_cn/performance_profiling_of_cluster.md"><img alt="查看源文件" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.9/resource/_static/logo_source.png" /></a></p>
<section id="概述">
<h2>概述<a class="headerlink" href="#概述" title="永久链接至标题"></a></h2>
<p>本教程介绍如何在（Ascend/GPU） AI处理器上使用MindSpore Profiler进行集群训练性能调试，集群训练数据收集的支持情况如下表：</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>性能数据</p></th>
<th class="head"><p>支持设备</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>集群迭代轨迹</p></td>
<td><p>Ascend、GPU</p></td>
</tr>
<tr class="row-odd"><td><p>集群通信与计算重叠时间分析</p></td>
<td><p>Ascend、GPU</p></td>
</tr>
<tr class="row-even"><td><p>集群通信性能分析</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>资源利用</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-even"><td><p>策略感知</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>执行总览</p></td>
<td><p>Ascend</p></td>
</tr>
</tbody>
</table>
</section>
<section id="操作流程">
<h2>操作流程<a class="headerlink" href="#操作流程" title="永久链接至标题"></a></h2>
<ol class="arabic simple">
<li><p>搭建分布式训练环境，准备分布式训练脚本，并在训练脚本中调用性能调试接口，接着运行训练脚本。</p></li>
<li><p>收集集群训练性能数据。</p></li>
<li><p>启动MindInsight，并通过启动参数指定summary-base-dir目录(summary-base-dir是Profiler所创建目录的父目录)，例如训练时Profiler创建的文件夹绝对路径为<code class="docutils literal notranslate"><span class="pre">/home/user/code/data</span></code>，则summary-base-dir设为<code class="docutils literal notranslate"><span class="pre">/home/user/code</span></code>。启动成功后，根据IP和端口访问可视化界面，默认访问地址为 <code class="docutils literal notranslate"><span class="pre">http://127.0.0.1:8080</span></code>。</p></li>
<li><p>在训练列表找到对应集群训练，点击性能分析，即可在页面中查看集群性能数据。</p></li>
</ol>
<blockquote>
<div><p>本文图片均来源Ascend AI处理器，不同设备展示有差异之处会另外进行说明。</p>
</div></blockquote>
</section>
<section id="分布式训练">
<h2>分布式训练<a class="headerlink" href="#分布式训练" title="永久链接至标题"></a></h2>
<p>Ascend分布式训练请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r1.9/parallel/train_ascend.html">分布式训练教程</a>。</p>
<p>GPU分布式训练请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r1.9/parallel/train_gpu.html">分布式训练教程</a>。</p>
</section>
<section id="收集集群性能数据">
<h2>收集集群性能数据<a class="headerlink" href="#收集集群性能数据" title="永久链接至标题"></a></h2>
<p>多机多卡训练的时候，一次集群训练后，性能数据分布在各个主机上（host节点）。要进行集群性能分析，需要将所有主机上的性能数据收集到一台主机上进行分析。考虑到集群运行环境的复杂以及相关的权限问题、登录问题，比较合理的方式是让用户去收集集群性能数据。
下面是一次分布式集群训练后，使用脚本收集性能数据的过程，用户可以参照此脚本进行集群性能数据收集。</p>
<p>脚本程序说明：脚本程序首先创建了集群作业文件夹，然后利用SSHPass技术进行非交互式的远程拷贝（避免了手动认证，手动输入密码），将集群中各个host节点的数据拷贝到集群作业文件夹中。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>

<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;==============================================================================================================&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Please run the script as: &quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;bash collect_cluster_profiler_data.sh&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;for example: bash collect_cluster_profiler_data.sh cluster_hccl_config_path cluster_account_config_path cluster_train_id host_train_id is_absolute_path&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;==============================================================================================================&quot;</span>

<span class="nv">SSH</span><span class="o">=</span><span class="s2">&quot;ssh -o StrictHostKeyChecking=no&quot;</span>
<span class="nv">SCP</span><span class="o">=</span><span class="s2">&quot;scp -o StrictHostKeyChecking=no&quot;</span>

<span class="c1"># Get the node list in the cluster.</span>
get_cluster_list<span class="o">()</span>
<span class="o">{</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">cluster_config</span><span class="o">=</span><span class="nv">$1</span>
<span class="w">        </span>cat<span class="w"> </span><span class="si">${</span><span class="nv">cluster_config</span><span class="si">}</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>python3<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import sys,json;[print(node) for node in json.load(sys.stdin)[&quot;cluster&quot;].keys()]&#39;</span>
<span class="o">}</span>

<span class="c1"># Get the account number of node.</span>
get_node_user<span class="o">()</span>
<span class="o">{</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">cluster_config</span><span class="o">=</span><span class="nv">$1</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">node</span><span class="o">=</span><span class="nv">$2</span>
<span class="w">        </span>cat<span class="w"> </span><span class="si">${</span><span class="nv">cluster_config</span><span class="si">}</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>python3<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import sys,json;print(json.load(sys.stdin)[&quot;cluster&quot;][&#39;</span><span class="se">\&quot;</span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="se">\&quot;</span><span class="s1">&#39;][&quot;user&quot;])&#39;</span>
<span class="o">}</span>

<span class="c1"># Get the password of node.</span>
get_node_passwd<span class="o">()</span>
<span class="o">{</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">cluster_config</span><span class="o">=</span><span class="nv">$1</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">node</span><span class="o">=</span><span class="nv">$2</span>
<span class="w">        </span>cat<span class="w"> </span><span class="si">${</span><span class="nv">cluster_config</span><span class="si">}</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>python3<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import sys,json;print(json.load(sys.stdin)[&quot;cluster&quot;][&#39;</span><span class="se">\&quot;</span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="se">\&quot;</span><span class="s1">&#39;][&quot;passwd&quot;])&#39;</span>
<span class="o">}</span>

<span class="c1"># Copy data from remote node to local node.</span>
rscp_pass<span class="o">()</span>
<span class="o">{</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">node</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$1</span><span class="s2">&quot;</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">user</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$2</span><span class="s2">&quot;</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">passwd</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$3</span><span class="s2">&quot;</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">src</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$4</span><span class="s2">&quot;</span>
<span class="w">        </span><span class="nb">local</span><span class="w"> </span><span class="nv">target</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$5</span><span class="s2">&quot;</span>
<span class="w">        </span>sshpass<span class="w"> </span>-p<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">passwd</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="si">${</span><span class="nv">SCP</span><span class="si">}</span><span class="w"> </span>-r<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">user</span><span class="si">}</span><span class="s2">&quot;</span>@<span class="s2">&quot;</span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="s2">&quot;</span>:<span class="s2">&quot;</span><span class="si">${</span><span class="nv">src</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">target</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="o">}</span>

<span class="nv">cluster_hccl_config_path</span><span class="o">=</span><span class="nv">$1</span>
<span class="nv">cluster_account_config_path</span><span class="o">=</span><span class="nv">$2</span>
<span class="nv">cluster_train_id</span><span class="o">=</span><span class="nv">$3</span>
<span class="nv">host_train_id</span><span class="o">=</span><span class="nv">$4</span>
<span class="nv">is_absolute_path</span><span class="o">=</span><span class="nv">$5</span>

<span class="nv">node_list</span><span class="o">=</span><span class="k">$(</span>get_cluster_list<span class="w"> </span><span class="si">${</span><span class="nv">cluster_account_config_path</span><span class="si">}</span><span class="k">)</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;-----begin----&quot;</span>

<span class="nv">target_dir</span><span class="o">=</span><span class="si">${</span><span class="nv">cluster_train_id</span><span class="si">}</span>/profiler/
<span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span>!<span class="w"> </span>-d<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">target_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
mkdir<span class="w"> </span>-p<span class="w"> </span><span class="si">${</span><span class="nv">target_dir</span><span class="si">}</span>
<span class="k">fi</span>

<span class="k">for</span><span class="w"> </span>node<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="si">${</span><span class="nv">node_list</span><span class="si">}</span>
<span class="k">do</span>
<span class="w"> </span><span class="nv">user</span><span class="o">=</span><span class="k">$(</span>get_node_user<span class="w"> </span><span class="si">${</span><span class="nv">cluster_account_config_path</span><span class="si">}</span><span class="w"> </span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="k">)</span>
<span class="w"> </span><span class="nv">passwd</span><span class="o">=</span><span class="k">$(</span>get_node_passwd<span class="w"> </span><span class="si">${</span><span class="nv">cluster_account_config_path</span><span class="si">}</span><span class="w"> </span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="k">)</span>
<span class="w"> </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;------------------</span><span class="si">${</span><span class="nv">user</span><span class="si">}</span><span class="s2">@</span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="s2">---------------------&quot;</span>

<span class="w"> </span><span class="c1"># Eight devices data</span>
<span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="nv">$is_absolute_path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;0&#39;</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="k">then</span>
<span class="w"> </span><span class="nv">device_regex</span><span class="o">=</span><span class="k">$(</span>basename<span class="w"> </span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$host_train_id</span><span class="k">))</span>
<span class="w"> </span><span class="nv">output</span><span class="o">=</span><span class="k">$(</span>basename<span class="w"> </span><span class="nv">$host_train_id</span><span class="k">)</span>
<span class="w"> </span><span class="nv">grandfather_host_train_id</span><span class="o">=</span><span class="k">$(</span>dirname<span class="w"> </span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$host_train_id</span><span class="k">))</span>
<span class="w"> </span><span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span>i&lt;<span class="m">8</span><span class="p">;</span>i++<span class="o">))</span><span class="p">;</span>
<span class="w"> </span><span class="k">do</span>
<span class="w">   </span><span class="nv">src_dir</span><span class="o">=</span><span class="si">${</span><span class="nv">grandfather_host_train_id</span><span class="si">}</span>/<span class="si">${</span><span class="nv">device_regex</span><span class="si">}${</span><span class="nv">i</span><span class="si">}</span>/<span class="si">${</span><span class="nv">output</span><span class="si">}</span>*/profiler/*.*
<span class="w">   </span><span class="k">$(</span>rscp_pass<span class="w"> </span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="w"> </span><span class="si">${</span><span class="nv">user</span><span class="si">}</span><span class="w"> </span><span class="si">${</span><span class="nv">passwd</span><span class="si">}</span><span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">src_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="si">${</span><span class="nv">target_dir</span><span class="si">}</span><span class="k">)</span>
<span class="w"> </span><span class="k">done</span>
<span class="w"> </span><span class="k">elif</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="nv">$is_absolute_path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;1&#39;</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="k">then</span>
<span class="w"> </span><span class="nv">src_dir</span><span class="o">=</span><span class="si">${</span><span class="nv">host_train_id</span><span class="si">}</span>/profiler/*.*
<span class="w"> </span><span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span>i&lt;<span class="m">8</span><span class="p">;</span>i++<span class="o">))</span><span class="p">;</span>
<span class="w"> </span><span class="k">do</span>
<span class="w">   </span><span class="k">$(</span>rscp_pass<span class="w"> </span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="w"> </span><span class="si">${</span><span class="nv">user</span><span class="si">}</span><span class="w"> </span><span class="si">${</span><span class="nv">passwd</span><span class="si">}</span><span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">src_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="si">${</span><span class="nv">target_dir</span><span class="si">}</span><span class="k">)</span>
<span class="w"> </span><span class="k">done</span>
<span class="w"> </span><span class="k">else</span>
<span class="w"> </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;The value of is_absolute_path can only be 0 or 1.&quot;</span>
<span class="w"> </span><span class="nb">exit</span><span class="w"> </span><span class="m">1</span>
<span class="w"> </span><span class="k">fi</span>
<span class="k">done</span>
</pre></div>
</div>
<p>脚本参数说明：</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">cluster_hccl_config_path</span></code> 为多卡环境的组网信息文件路径。内容格式如下：</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1.0&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;server_count&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;server_list&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;server_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;10.xxx.xxx.1&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.1.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0&quot;</span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.2.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.3.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2&quot;</span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;3&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.4.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;3&quot;</span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;4&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.1.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;4&quot;</span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;5&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.2.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;5&quot;</span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;6&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.3.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;6&quot;</span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;7&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.4.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;7&quot;</span><span class="p">}],</span>
<span class="w">         </span><span class="nt">&quot;host_nic_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;reserve&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="p">],</span>
<span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;completed&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">cluster_account_config_path</span></code> 为各主机账号密码配置文件路径，内容格式如下：</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;rank_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;cluster&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;10.xxx.xxx.1&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;user&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;root&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;passwd&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;xxx&quot;</span>
<span class="w">                </span><span class="p">},</span>
<span class="w">                </span><span class="nt">&quot;10.xxx.xxx.2&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;user&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;root&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;passwd&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;xxx&quot;</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">              </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">cluster_train_id</span></code> 集群性能数据汇总保存的路径，比如<code class="docutils literal notranslate"><span class="pre">/home/summary/run1</span></code>、<code class="docutils literal notranslate"><span class="pre">/home/summary/run2</span></code> 其中<code class="docutils literal notranslate"><span class="pre">run1</span></code>和<code class="docutils literal notranslate"><span class="pre">run2</span></code>分别保存两次集群训练的所有性能数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">host_train_id</span></code> 集群训练中，用户设置的性能数据保存路径。当性能数据保存路径设置为绝对路径时，<code class="docutils literal notranslate"><span class="pre">host_train_id</span></code>的值即为用户设置的值。比如值为<code class="docutils literal notranslate"><span class="pre">/data/run</span></code>时，多卡性能数据均保存在<code class="docutils literal notranslate"><span class="pre">/data/run/profiler</span></code>中（<code class="docutils literal notranslate"><span class="pre">profliler</span></code>文件夹由程序自动创建），<code class="docutils literal notranslate"><span class="pre">host_train_id</span></code>值应该设置为<code class="docutils literal notranslate"><span class="pre">/data/run</span></code>。当性能数据保存路径设置为相对路径时，多卡性能数据可能保存在不同的文件夹中。比如<code class="docutils literal notranslate"><span class="pre">/data/run/device0/data/profiler</span></code>、<code class="docutils literal notranslate"><span class="pre">/data/run/device1/data/profiler</span></code>。它们的共性路径为<code class="docutils literal notranslate"><span class="pre">/data/run/device/data/profiler</span></code>，每张卡的性能数据保存路径为<code class="docutils literal notranslate"><span class="pre">/data/run/device{device_id}/data/profiler</span></code>。<code class="docutils literal notranslate"><span class="pre">host_train_id</span></code>值应该设置为<code class="docutils literal notranslate"><span class="pre">/data/run/device/data</span></code>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">is_absolute_path</span></code> 在需要收集的集群性能数据中，单机多卡数据是否保存在同一个目录中。若是，设置为1；不是，设置为0。</p></li>
</ul>
<p>通过脚本收集到的集群性能目录结构为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>|-- run
    |-- profiler
        |-- step_trace_raw_{rank_id}_detail_time.csv
</pre></div>
</div>
<blockquote>
<div><p>集群性能目录和单卡性能目录格式进行了统一。</p>
</div></blockquote>
<p>在MindInsight r1.3以及之前的版本中，集群性能目录结构如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>|-- run
    |-- hccl.json
    |-- host_ips_mapping.txt
    |-- cluster_profiler
        |-- 1
        |   |-- profiler
        |       |-- step_trace_raw_0_detail_time.csv
</pre></div>
</div>
<p>通过数据转换脚本，可以将用户使用MindInsight r1.3以及之前的版本创建的集群性能目录转换为当前支持的集群性能目录。可以从官网下载<a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.9/docs/sample_code/transform_cluster_profiler_data.py">集群目录转换脚本</a>。</p>
<blockquote>
<div><p>以上为Ascend AI处理器关于收集集群性能数据的介绍，GPU集群训练请参考GPU分布式训练教程。</p>
</div></blockquote>
</section>
<section id="启动mindinsight">
<h2>启动MindInsight<a class="headerlink" href="#启动mindinsight" title="永久链接至标题"></a></h2>
<p>启动命令请参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.9/mindinsight_commands.html">MindInsight相关命令</a>。</p>
</section>
<section id="训练性能">
<h2>训练性能<a class="headerlink" href="#训练性能" title="永久链接至标题"></a></h2>
<p>用户从训练列表中选择指定的训练，点击性能调试，点击<code class="docutils literal notranslate"><span class="pre">集群</span></code>Table标签，可以以集群视角展示本次训练性能数据。集群训练性能包括集群迭代轨迹分析、集群通信性能分析。</p>
<p><img alt="cluster_summary.png" src="_images/cluster_summary.png" /></p>
<p><em>图1：集群训练性能总览</em></p>
<p>图1为集群训练性能总揽，是对集群迭代轨迹组件、集群通信性能组件的总体呈现。各组件展示内容如下：</p>
<ul class="simple">
<li><p>集群迭代轨迹：展示集群中所有卡的迭代轨迹信息；总览页面展示了集群迭代轨迹性能。</p></li>
<li><p>集群通信性能: 展示集群中所有卡的通信性能以及全网链路性能；总览页面展示了集群通信性能。</p></li>
<li><p>集群性能优化小助手：左侧小助手提供集群训练时可能存在的性能瓶颈点，用户可以根据提示进行训练性能优化。</p></li>
</ul>
<blockquote>
<div><p>GPU上目前仅支持集群迭代轨迹的展示，用户可查看集群迭代轨迹性能，左侧小助手提供一篇关于集群性能调优的文档，用户可点击进一步了解。</p>
</div></blockquote>
<section id="集群迭代轨迹分析">
<h3>集群迭代轨迹分析<a class="headerlink" href="#集群迭代轨迹分析" title="永久链接至标题"></a></h3>
<p>使用集群迭代轨迹分析组件，可以找出集群训练中的慢主机、慢卡。
集群迭代轨迹分析组件展示所有卡的迭代信息，包括迭代间隙、前反向、迭代拖尾，均支持排序操作。其中迭代间隙反映了数据处理阶段的快慢，通过卡的迭代间隙时间可以反映出对应主机处理数据的快慢。卡的前反向时间反映了卡的计算能力。迭代拖尾反映了all_reduce耗时以及并行情况。</p>
<p><img alt="cluster_iterative_trajectory.png" src="_images/cluster_iterative_trajectory.png" /></p>
<p><em>图2：集群迭代轨迹</em></p>
<p>图2展示了集群迭代轨迹分析页面，默认展示卡的性能平均值，支持查询特定step下的卡的迭代轨迹信息。通过点击单卡中的详情连接，也可以跳转到单卡的详细性能展示页面，查询详细的单卡性能数据。</p>
<p><img alt="single_car_performance_overall.png" src="_images/single_car_performance_overall.png" /></p>
<p><em>图3：单卡性能信息</em></p>
<p>图3展示集群中单卡性能信息，单卡性能信息请参考<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.9/performance_profiling_ascend.html">单卡性能信息</a>。</p>
</section>
<section id="集群通信与计算重叠时间分析">
<h3>集群通信与计算重叠时间分析<a class="headerlink" href="#集群通信与计算重叠时间分析" title="永久链接至标题"></a></h3>
<p>集群通信与计算重叠时间分析组件用于流水并行和模型并行场景，可以找出集群训练中的慢主机、慢卡。</p>
<p>集群通信与计算重叠时间分析组件新增了五项指标：纯通信时间（仅包含Receive算子）、state时间、纯通信时间、计算时间、纯通信时间（不包含Receive算子）。</p>
<ul class="simple">
<li><p>纯通信时间（仅包含Receive算子）：只有点对点（Receive）通信算子执行、计算算子不执行的时间段。该时间反应的是Pipeline并行各stage间的不同步情况。</p></li>
<li><p>stage时间：各个stage的耗时时长，该值为step时长减去该step内receive通信算子的时长。通过该指标可以查看哪个stage的耗时最长。</p></li>
<li><p>纯通信时间：只有通信算子执行、计算算子不执行的时间段。如果该部分耗时较长，说明通信耗时对性能影响较大。</p></li>
<li><p>计算时间：AI Core算子执行的时间总和，用于判断是否有慢的卡。时间越长，说明对应的卡执行速度越慢。</p></li>
<li><p>纯通信时间（不包含Receive算子）：只有除Receive通信算子外的其它通信算子执行、计算算子不执行的时间段。该时间段占的比例越大，需要考虑是否可以调整该stage内算子的切分策略，降低该时间段的耗时时长。</p></li>
</ul>
<p><img alt="cluster_pipeline-parallel_analyse.png" src="_images/cluster_pipeline-parallel_analyse_zh.png" /></p>
<p><em>图4：流水并行模式分析</em></p>
<p>图4展示了流水并行场景下页面展示的内容，默认展示所有step的平均数值。页面中展示了迭代间隙时间、纯接收时间、阶段时间、纯通信时间、计算时间、纯集合通信时间。由于整个网络的计算图被切分为多个阶段的子图，阶段时间可用于定位慢的阶段，通过选择阶段编号可以筛选出同一阶段的卡，在阶段内部可用模型并行场景的思路定位瓶颈。</p>
<p><img alt="cluster_model-parallel_analyse.png" src="_images/cluster_model-parallel_analyse_zh.png" /></p>
<p><em>图5：模型并行模式分析</em></p>
<p>图5展示了模型并行场景（此处指层内模型并行）下页面展示的内容，默认展示所有step的平均数值。页面中展示了迭代间隙时间、纯通信时间、计算时间。计算时间可用于定位慢卡，如果没有慢卡，查看通信时间与计算时间占比，若通信时间占比较大，考虑是否有慢链路。</p>
</section>
<section id="集群通信性能分析">
<h3>集群通信性能分析<a class="headerlink" href="#集群通信性能分析" title="永久链接至标题"></a></h3>
<p>集群通信性能组件从两个维度来展示集群通信性能信息，以卡为粒度展示和全网链路展示。</p>
<p><img alt="cluster_communication_info.png" src="_images/cluster_communication_info.png" /></p>
<p><em>图6：集群通信性能分析</em></p>
<p>图6展示了集群通信性能分析页面，包含逻辑卡通信性能以及全网链路信息（所有逻辑卡链路信息）。</p>
<p>逻辑卡通信性能TAB页主要用来展示逻辑卡的通信性能，包括通信时间、等待时间、算子详情、逻辑卡链路信息。</p>
<ul class="simple">
<li><p>通信时间：表示通信算子的通信耗时。如果通信耗时过长，有可能是某条链路有问题，可以通过链路带宽定位到具体的链路。通信时间计算方式为统计SDMA链路（server内通信）和RDMA链路（server间通信）的通信算子总耗时。如果是SDMA链路，取<code class="docutils literal notranslate"><span class="pre">Reduce</span> <span class="pre">inline</span></code>和<code class="docutils literal notranslate"><span class="pre">Memcpy</span></code>算子总时间作为通信时间；如果是RDMA链路，取连续三个算子<code class="docutils literal notranslate"><span class="pre">RDMASendPayload</span></code>、<code class="docutils literal notranslate"><span class="pre">RDMASendNotify</span></code>、<code class="docutils literal notranslate"><span class="pre">Notify</span> <span class="pre">Wait</span></code>的总时间为通信时间。</p></li>
<li><p>等待时间：也可称为同步时间。卡间进行通信前，首先会进行同步，确保通信的两张卡同步完成，再进行通信。等待时间计算方式为统计所有<code class="docutils literal notranslate"><span class="pre">Notify</span> <span class="pre">Wait</span></code>算子总耗时并减去RDMA链路通信时间中的<code class="docutils literal notranslate"><span class="pre">Notify</span> <span class="pre">Wait</span></code>算子耗时。</p></li>
<li><p>算子详情：以算子粒度展示通信性能，包括该通信算子的通信时长、等待时长、链路信息。</p></li>
<li><p>逻辑卡链路信息：显示源卡为该卡或者目的卡为该卡的链路信息。链路信息包括通信时间、通信量、带宽（通信量除以通信时间）、链路类型。其中链路类型包含SDMA链路（server内通信链路）和RDMA链路（server间通信链路）。点击详情后，通过弹窗的方式展示。</p></li>
</ul>
<p>节点链接图展示了设备及通信链路的情况。图中每个节点代表一个设备，节点的大小编码该设备总通信时长。节点的颜色编码了该设备通信时间占通信与等待总时间的比例，即：通信时间/（通信时间+等待时间），颜色越深，表示该设备等待时间越短。等待时间短的设备可能是慢节点。节点可拖拽移动，节点间的边表示通信链路。</p>
<p><img alt="communication_matrix.png" src="_images/communication_matrix.png" /></p>
<p><em>图7：算子性能信息</em></p>
<p>图7展示了在节点链接图中刷选部分设备后，呈现的邻接矩阵。邻接矩阵展示了各设备之间通信链路的情况。在每个格子中，第一行、第三行展示的是链路的通信时间、流量的统计值。邻接矩阵第二行、第四行、第五行的盒须图，反映了链路中通信时间、流量、带宽指标上所有通信算子的分布情况。图中红色框框出的离群点，表示该算子占据了该链路的绝大部分带宽。用户可通过邻接矩阵定位异常通信链路及异常通信算子。</p>
<p>鼠标右键点击邻接矩阵任意位置可回到节点链接图。</p>
<p><img alt="operator_performance.png" src="_images/operator_performance.png" /></p>
<p><em>图8：算子性能信息</em></p>
<p><img alt="rank_id_link_info.png" src="_images/rank_id_link_info.png" /></p>
<p><em>图9:逻辑卡链路信息</em></p>
<p>全网链路信息TAB页面展示所有逻辑卡的链路信息，提供源卡、目的卡、链路类型的选择。</p>
<p><img alt="rank_ids_link_info.png" src="_images/rank_ids_link_info.png" /></p>
<p><em>图10：全网链路信息</em></p>
<p>默认不收集通信性能数据，需要通过<code class="docutils literal notranslate"><span class="pre">mindspore.Profiler</span></code>中的<code class="docutils literal notranslate"><span class="pre">profile_communication</span></code>参数像<code class="docutils literal notranslate"><span class="pre">Profiler(profile_communication=True)</span></code>一样打开通信性能数据开关。只有多卡训练才能产生通信算子性能数据，在单卡训练场景中设置该参数是无效的。</p>
<p>使用MindInsight可视化通信性能数据需要安装Ascend 910 AI处理器配套软件包提供的通信性能数据解析whl包，whl包随配套软件包发布，参考如下命令完成安装。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>/usr/local/Ascend/latest/tools/hccl_parser-<span class="o">{</span>version<span class="o">}</span>-py3-none-any.whl
</pre></div>
</div>
</section>
<section id="规格">
<h3>规格<a class="headerlink" href="#规格" title="永久链接至标题"></a></h3>
<p>出于对数据解析性能的考虑，当前对开启集群通信生成的文件数量进行了限制，目前MindSpore侧生成的原始通信性能文件（.trace后缀命名）数量上限为500。当通信原始数据超出上限，可能出现集群通信step数与集群迭代轨迹step数不一致的情况。</p>
</section>
</section>
<section id="资源利用">
<h2>资源利用<a class="headerlink" href="#资源利用" title="永久链接至标题"></a></h2>
<section id="集群内存使用情况分析">
<h3>集群内存使用情况分析<a class="headerlink" href="#集群内存使用情况分析" title="永久链接至标题"></a></h3>
<p>该页面展示了并行场景下，模型在<strong>Device侧</strong>的内存使用情况，是<strong>基于理论值的理想预估</strong>。页面内容包括：</p>
<ul class="simple">
<li><p>集群设备的分布情况，使用了哪些服务器的哪些设备。</p></li>
<li><p>集群设备的内存峰值情况，即内存峰值与可用内存占比。</p></li>
<li><p>点击某个设备，可以跳转至该设备的内存详情页面。</p></li>
</ul>
<p><img alt="cluster_memory.png" src="_images/cluster_memory.png" /></p>
<p><em>图11：集群内存概览页面</em></p>
<blockquote>
<div><p>内存使用情况分析暂不支持异构训练场景。</p>
</div></blockquote>
</section>
<section id="集群flops热力图分析">
<h3>集群FLOPs热力图分析<a class="headerlink" href="#集群flops热力图分析" title="永久链接至标题"></a></h3>
<p>该页面展示了并行场景下，每个设备的FLOPs（浮点运算次）数据，热力图反映了设备之间FLOPs的相对大小。页面内容包括：</p>
<ul class="simple">
<li><p>集群设备的分布情况，使用了哪些服务器的哪些设备。</p></li>
<li><p>集群设备之间FLOPs的相对大小，每个设备对应矩形块颜色代表当前设备FLOPs与所有设备中最大FLOPs的比值。</p></li>
<li><p>点击某个设备，可以跳转至该设备的算子耗时详情页面，含有FLOPs的详细数据。</p></li>
</ul>
<p><img alt="cluster_flops.png" src="_images/cluster_flops.png" /></p>
<p><em>图12：集群FLOPs概览页面</em></p>
</section>
</section>
<section id="策略感知">
<h2>策略感知<a class="headerlink" href="#策略感知" title="永久链接至标题"></a></h2>
<p>策略感知包括计算图探索、并行策略分析等功能模块。</p>
<section id="计算图探索">
<h3>计算图探索<a class="headerlink" href="#计算图探索" title="永久链接至标题"></a></h3>
<section id="总体介绍">
<h4>总体介绍<a class="headerlink" href="#总体介绍" title="永久链接至标题"></a></h4>
<p><img alt="image-20211118132511452" src="_images/profiler_strategy_graph_zh.png" /></p>
<p><em>图13：策略感知视图页面</em></p>
<p>页面右上角会显示本次训练的并行方式，上图展示出本次训练采用的并行方式是自动并行。</p>
<p>用户可根据stage选择计算图进行探索，使用图选择器可选择计算图的特定模块（正向图、反向图、重计算图）进行通信结点的抽取。</p>
<p>页面左上角为<code class="docutils literal notranslate"><span class="pre">流水线并行视图</span></code>，当训练为流水线并行训练时，该视图展示stage之间数据发送和接收关系。点击其中的算子可以跳转到图中。</p>
<p>在页面中间展示计算图，方形的结点为<code class="docutils literal notranslate"><span class="pre">聚合结点</span></code>，可以对其进行双击打开或者关闭该节点，椭圆形为普通算子。</p>
<p>聚合结点未展开时，会显示该聚合结点内各类特殊算子的数量，主要展示三类算子：含切分策略算子、重排布算子、梯度聚合算子。重排布算子是两个算子之间如果上一个算子的输出无法与下一个算子进行运算，则会自动插入一个重排布算子实现排布变换，更多细节可以参考<code class="docutils literal notranslate"><span class="pre">设计文档</span></code>中的<code class="docutils literal notranslate"><span class="pre">分布式训练设计</span></code>章节。</p>
<p>鼠标单击选中某个结点（算子或聚合结点）后，右侧结点属性面板能够展示对应结点的输入输出、切分策略等信息，面板中的输入输出算子点击可跟踪。</p>
</section>
</section>
<section id="算子策略矩阵">
<h3>算子策略矩阵<a class="headerlink" href="#算子策略矩阵" title="永久链接至标题"></a></h3>
<p><img alt="image-20211118133144763" src="_images/profiler_strategy_graph_strategy.png" /></p>
<p><em>图14：算子策略矩阵</em></p>
<p>算子的某项输入存在切分策略时，会在该算子下方呈现一个策略矩阵，一行表示一项输入，小格子中的数字表示算子在对应维度上的切分份数。</p>
<p>鼠标悬浮在策略矩阵上，能够高亮对应的边。结合计算图中结点的输入输出定位功能，用户能够分析算子切分策略设计的合理性，调整切分策略。</p>
<p>需要注意的是，在计算图中没有绘制常量，因此针对常量的切分策略不会体现在图中。</p>
</section>
<section id="流水线并行视图">
<h3>流水线并行视图<a class="headerlink" href="#流水线并行视图" title="永久链接至标题"></a></h3>
<p><img alt="image-20211118125032089" src="_images/profiler_strategy_graph_pipeline.png" /></p>
<p><em>图15：流水线并行视图</em></p>
<p>采用了流水线并行策略时，点击页面左上角的按钮，即可展开流水线并行视图。该视图展示了流水线并行中，每个stage的Send（红色矩形）和Receive算子（绿色矩形）及不同stage之间Send、Receive算子的对应关系。视图中的算子支持点击操作，在计算图中定位。</p>
<p>用户可以结合流水线并行视图，评估stage切分的合理性，直观地分析出流水线并行策略的设计细节，micro-batch数量等信息。</p>
</section>
<section id="算子堆叠与边隐藏">
<h3>算子堆叠与边隐藏<a class="headerlink" href="#算子堆叠与边隐藏" title="永久链接至标题"></a></h3>
<p><img alt="image-20211118125032089" src="_images/profiler_strategy_graph_stack.png" /></p>
<p><em>图16：算子堆叠</em></p>
<p>在计算图中，在聚合结点中如果同类型的算子数量过多，则会对其进行堆叠展示，双击可以展开查看算子。</p>
<p><img alt="image-20211118125032089" src="_images/profiler_strategy_hideline.png" /></p>
<p><em>图17：查看被隐藏边</em></p>
<p>为了避免线过于零乱，部分不重要的边会被隐藏，鼠标悬浮在聚合结点周围的圆圈上面，可以看到被隐藏的边。</p>
</section>
</section>
<section id="执行总览">
<h2>执行总览<a class="headerlink" href="#执行总览" title="永久链接至标题"></a></h2>
<p>用户从训练列表中选择指定的训练，点击性能调试，点击<code class="docutils literal notranslate"><span class="pre">集群</span></code>标签，可以以集群视角展示本次训练性能数据。
执行总览包括计算图执行序分析、各设备算子执行时间线分析、各step各设备时间信息概览。</p>
<p><img alt="execution_overview.png" src="_images/execution_overview.png" /></p>
<p><em>图18：集群执行总览</em></p>
<section id="计算图执行序分析">
<h3>计算图执行序分析<a class="headerlink" href="#计算图执行序分析" title="永久链接至标题"></a></h3>
<p>执行总览页面上方即为并行策略视图。</p>
<p><img alt="parallel_strategy_view.png" src="_images/parallel_strategy_view.png" /></p>
<p><em>图19：并行策略视图</em></p>
<p>在此计算图中，算子依据执行序，从左向右布局。画布支持拖动，放缩观察。各类算子用不同颜色区分，视图最上方显示图例。</p>
<p>左侧为命名空间选择器，勾选命名空间后，计算图中对应算子会产生颜色光晕标识。</p>
<p>当并行训练采用流水线并行模式，该视图上会呈现所有stage的计算图，各stage计算图之间通过Send、Receive算子对应，进行横向排布。用户能够在计算图缩略图获得对流水线并行执行流程的整体感知。</p>
<p><img alt="timeline_minimap.png" src="_images/timeline_minimap.png" /></p>
<p><em>图20：时间线缩略图</em></p>
<p>右侧提供特殊算子统计功能及结点属性面板。
特殊算子包括三类：含切分策略算子、重排布算子、梯度聚合算子。</p>
</section>
<section id="各设备算子执行时间线分析">
<h3>各设备算子执行时间线分析<a class="headerlink" href="#各设备算子执行时间线分析" title="永久链接至标题"></a></h3>
<p>执行总览页面中部为Marey视图。</p>
<p><img alt="marey_graph.png" src="_images/marey_graph.png" /></p>
<p><em>图21：Marey视图</em></p>
<p>在Marey视图中，每个设备对应三个色块和一条时间线。三个色块展示各stage各设备FLOPs（浮点运算次数，用于衡量模型/算法复杂度），FLOPS（每秒浮点运算次数，用于衡量硬件的性能）与PeakMem（峰值内存）。对于FLOPs和FLOPS，展示当前设备值/各设备最大值，对于PeakMem，展示设备峰值占用内存/设备总内存。</p>
<p><img alt="marey_timeline.png" src="_images/marey_timeline.png" /></p>
<p><em>图22：Marey时间线</em></p>
<p>如图22所示，时间线中，绿色表示计算算子，橙色表示通信算子。同在一个pipeline stage中的设备，在其上执行的算子基本相同，每个设备有一条时间轴，我们在时间轴上标注出算子执行的开始和结束时间，然后连接多边形，填充颜色。该视图可以定位如下两类问题：</p>
<p><img alt="marey_exception.png" src="_images/marey_exception.png" /></p>
<p><em>图23：Marey时间线异常</em></p>
<p>如图23(a)所示，当一个算子在各设备上的执行时间都显著长于其它的算子，可能是该算子融合切分策略不合理。
如图23(b)所示，当一个算子在某个设备上执行时间显著长于其它设备，可能是训练设备出现了慢节点。</p>
<p>时间线支持的交互有刷选放大，双击缩小，鼠标悬浮查看算子执行时间戳信息等。</p>
<p>视图左侧stage设备树可以根据需要进行聚合或展开。stage的时间线上展示的是同一个stage中各设备相同算子实际执行时间的并集。</p>
<p>每条时间线上扩展出折线图，深色线表示FLOPs变化，浅色线表示内存变化。</p>
<p><img alt="marey_memory_flops.png" src="_images/marey_memory_flops.png" /></p>
<p><em>图24：Marey时间线中的折线</em></p>
<p>如上图所示，内存占用量在红框内有明显峰值，可结合时间线分析设备执行情况。</p>
</section>
<section id="各设备时间信息概览">
<h3>各设备时间信息概览<a class="headerlink" href="#各设备时间信息概览" title="永久链接至标题"></a></h3>
<p>执行总览页面底部为时间总览视图。</p>
<p><img alt="time_view.png" src="_images/time_view.png" /></p>
<p><em>图25：时间总览视图</em></p>
<p>时间总览视图为双y轴图，左侧展示的训练时间，右侧展示的通信的耗时。本视图展示各个step所有设备的训练时间，每个设备的平均通信时间与等待时间，用户将鼠标悬浮在对应step上，弹出的小卡片中可以看到具体的数值。该视图作为用户的分析入口，若用户判定某个step统计数据存在异常，用户可选中对应step，Marey视图将显示对应step各设备执行时间线，用户可进行进一步分析。</p>
</section>
</section>
<section id="规格-1">
<h2>规格<a class="headerlink" href="#规格-1" title="永久链接至标题"></a></h2>
<ul>
<li><p>为了控制性能测试时生成数据的大小，大型网络建议性能调试的step数目限制在10以内。</p>
<blockquote>
<div><p>控制step数目可以通过控制训练数据集的大小来实现，如<code class="docutils literal notranslate"><span class="pre">mindspore.dataset.MindDataset</span></code>类中的<code class="docutils literal notranslate"><span class="pre">num_samples</span></code>参数可以控制数据集大小，详情参考：</p>
<p><a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.9/api_python/dataset/mindspore.dataset.MindDataset.html">https://www.mindspore.cn/docs/zh-CN/r1.9/api_python/dataset/mindspore.dataset.MindDataset.html</a></p>
</div></blockquote>
</li>
</ul>
</section>
<section id="注意事项">
<h2>注意事项<a class="headerlink" href="#注意事项" title="永久链接至标题"></a></h2>
<ul class="simple">
<li><p>PyNative模式下暂不支持性能调试。</p></li>
<li><p>训练加推理过程暂不支持性能调试，目前支持单独训练或推理的性能调试。</p></li>
<li><p>性能调试暂不支持动态shape场景、多子图场景和控制流场景。</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="performance_profiling_gpu.html" class="btn btn-neutral float-left" title="性能调试（GPU-Graph）" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="debugger.html" class="btn btn-neutral float-right" title="调试器" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>