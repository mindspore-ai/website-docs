<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>The Application of Quantum Neural Network in NLP &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/mathjax/MathJax-3.2.2/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="VQE Application in Quantum Chemistry Computing" href="vqe_for_quantum_chemistry.html" />
    <link rel="prev" title="Quantum Approximate Optimization Algorithm" href="quantum_approximate_optimization_algorithm.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindquantum_install.html">MindSpore Quantum Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="parameterized_quantum_circuit.html">Variational Quantum Circuit</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantum_simulator.html">Quantum simulator</a></li>
<li class="toctree-l1"><a class="reference internal" href="initial_experience_of_quantum_neural_network.html">Initial experience of quantum neural network</a></li>
<li class="toctree-l1"><a class="reference internal" href="get_gradient_of_PQC_with_mindquantum.html">Advanced Gradient Calculation of Variational Quantum Circuits</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_operations_of_quantum_circuit.html">Advanced Operations of Quantum Circuit</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantum_measurement.html">Quantum Measurement</a></li>
<li class="toctree-l1"><a class="reference internal" href="noise.html">Noisy Quantum Circuit</a></li>
<li class="toctree-l1"><a class="reference internal" href="noise_simulator.html">Noise simulator</a></li>
<li class="toctree-l1"><a class="reference internal" href="qubit_mapping.html">Qubit Mapping</a></li>
<li class="toctree-l1"><a class="reference internal" href="bloch_sphere.html">Bloch Sphere</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Variational Quantum Algorithm</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="classification_of_iris_by_qnn.html">Classification of IRIS by Quantum Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantum_approximate_optimization_algorithm.html">Quantum Approximate Optimization Algorithm</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">The Application of Quantum Neural Network in NLP</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#data-pre-processing">Data Pre-processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#encoding-circuit">Encoding Circuit</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ansatz-circuit">Ansatz Circuit</a></li>
<li class="toctree-l2"><a class="reference internal" href="#measurement">Measurement</a></li>
<li class="toctree-l2"><a class="reference internal" href="#quantum-word-embedding-layer">Quantum Word Embedding Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#classical-word-embedding-layer">Classical Word Embedding Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="vqe_for_quantum_chemistry.html">VQE Application in Quantum Chemistry Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="equivalence_checking_of_PQC.html">Equivalence Checking of Parameterized Quantum Circuits</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">General Quantum Algorithm</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quantum_phase_estimation.html">Quantum Phase Estimation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="grover_search_algorithm.html">Grover search and Long algorithms based on MindSpore Quantum</a></li>
<li class="toctree-l1"><a class="reference internal" href="shor_algorithm.html">Shor’s algorithm based on MindSpore Quantum</a></li>
<li class="toctree-l1"><a class="reference internal" href="hhl_algorithm.html">HHL Algorithm</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="overview.html">overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindquantum.dtype.html">mindquantum.dtype</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindquantum.core.html">mindquantum.core</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindquantum.simulator.html">mindquantum.simulator</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindquantum.framework.html">mindquantum.framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindquantum.algorithm.html">mindquantum.algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindquantum.device.html">mindquantum.device</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindquantum.io.html">mindquantum.io</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindquantum.engine.html">mindquantum.engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindquantum.utils.html">mindquantum.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>The Application of Quantum Neural Network in NLP</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/qnn_for_nlp.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="the-application-of-quantum-neural-network-in-nlp">
<h1>The Application of Quantum Neural Network in NLP<a class="headerlink" href="#the-application-of-quantum-neural-network-in-nlp" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/master/mindquantum/en/mindspore_qnn_for_nlp.ipynb"><img alt="Download Notebook" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_notebook_en.svg" /></a>  <a class="reference external" href="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/master/mindquantum/en/mindspore_qnn_for_nlp.py"><img alt="Download Code" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_download_code_en.svg" /></a>  <a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/mindquantum/docs/source_en/qnn_for_nlp.ipynb"><img alt="View source on Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.svg" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>Word embedding plays a key role in natural language processing. It embeds a high-dimension word vector to lower dimension space. When more information is added to the neural network, the training task will become more difficult. By taking advantage of the characteristics of quantum mechanics (e.g., state superposition and entanglement), a quantum neural network can process such classical information during training, thereby improving the accuracy of convergence. In the following, we will build a
simple mixed quantum neural network for completing word embedding task.</p>
<p>Import relevant dependencies of the tutorial.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindquantum.framework</span> <span class="kn">import</span> <span class="n">MQLayer</span>
<span class="kn">from</span> <span class="nn">mindquantum.core.gates</span> <span class="kn">import</span> <span class="n">RX</span><span class="p">,</span> <span class="n">RY</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">H</span>
<span class="kn">from</span> <span class="nn">mindquantum.core.circuit</span> <span class="kn">import</span> <span class="n">Circuit</span><span class="p">,</span> <span class="n">UN</span>
<span class="kn">from</span> <span class="nn">mindquantum.core.operators</span> <span class="kn">import</span> <span class="n">Hamiltonian</span><span class="p">,</span> <span class="n">QubitOperator</span>
</pre></div>
</div>
</div>
<p>This tutorial implements a <a class="reference external" href="https://blog.csdn.net/u010665216/article/details/78724856">CBOW model</a>, which predicts a word based on its position. For example, “I love natural language processing”, this sentence can be divided by five words, which are [“I”, “love”, “natural”, “language”, “processing”]. When the selected window is 2, the task to be completed would be to predict the word “natural” given [“I”, “love”, “language”, “processing”]. In the following, we will build a quantum neural
network for word embedding to deal with the this task.</p>
<p><img alt="quantum word embedding" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindquantum/docs/source_zh_cn/images/qcbow.png" /></p>
<p>Here, the encoding information of “I”, “love”, “language”, and “processing” will be encoded to the quantum circuit. This quantum circuit to be trained consists of four Ansatz circuits. At last, we measure the qubit in the <span class="math notranslate nohighlight">\(\text{Z}\)</span> base vector for the quantum circuit end. The number of measured qubits is determined by the embedded dimenson.</p>
</section>
<section id="data-pre-processing">
<h2>Data Pre-processing<a class="headerlink" href="#data-pre-processing" title="Permalink to this headline"></a></h2>
<p>It is necessary to form a dictionary for the setence to be processed and determine the samples according to the size of the window.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">GenerateWordDictAndSample</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">all_words</span> <span class="o">=</span> <span class="n">corpus</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">word_set</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">all_words</span><span class="p">))</span>
    <span class="n">word_set</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
    <span class="n">word_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">w</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_set</span><span class="p">)}</span>
    <span class="n">sampling</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_words</span><span class="p">[</span><span class="n">window</span><span class="p">:</span><span class="o">-</span><span class="n">window</span><span class="p">]):</span>
        <span class="n">around</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">index</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">window</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">index</span> <span class="o">+</span> <span class="n">window</span><span class="p">:</span>
                <span class="n">around</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">all_words</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">sampling</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">around</span><span class="p">,</span> <span class="n">all_words</span><span class="p">[</span><span class="n">index</span> <span class="o">+</span> <span class="n">window</span><span class="p">]])</span>
    <span class="k">return</span> <span class="n">word_dict</span><span class="p">,</span> <span class="n">sampling</span>

<span class="n">word_dict</span><span class="p">,</span> <span class="n">sample</span> <span class="o">=</span> <span class="n">GenerateWordDictAndSample</span><span class="p">(</span><span class="s2">&quot;I love natural language processing&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">word_dict</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;word dict size: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_dict</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;samples: &#39;</span><span class="p">,</span> <span class="n">sample</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;number of samples: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;I&#39;: 0, &#39;language&#39;: 1, &#39;love&#39;: 2, &#39;natural&#39;: 3, &#39;processing&#39;: 4}
word dict size:  5
samples:  [[[&#39;I&#39;, &#39;love&#39;, &#39;language&#39;, &#39;processing&#39;], &#39;natural&#39;]]
number of samples:  1
</pre></div></div>
</div>
<p>According to the above information, the size of the dictionary is 5 and it is enough to select a sample.</p>
</section>
<section id="encoding-circuit">
<h2>Encoding Circuit<a class="headerlink" href="#encoding-circuit" title="Permalink to this headline"></a></h2>
<p>For simplification, we use the RX rotation gate to construct the encoding circuit. The structure is as follows.</p>
<p><img alt="encoder circuit" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindquantum/docs/source_zh_cn/images/encoder.png" /></p>
<p>We apply a <code class="docutils literal notranslate"><span class="pre">`RX</span></code> &lt;<a class="reference external" href="https://www.mindspore.cn/mindquantum/docs/en/master/core/gates/mindquantum.core.gates.RX.html">https://www.mindspore.cn/mindquantum/docs/en/master/core/gates/mindquantum.core.gates.RX.html</a>&gt;`__ rotation gate to each quantum qubit.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">GenerateEncoderCircuit</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">prefix</span> <span class="ow">and</span> <span class="n">prefix</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;_&#39;</span><span class="p">:</span>
        <span class="n">prefix</span> <span class="o">+=</span> <span class="s1">&#39;_&#39;</span>
    <span class="n">circ</span> <span class="o">=</span> <span class="n">Circuit</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">):</span>
        <span class="n">circ</span> <span class="o">+=</span> <span class="n">RX</span><span class="p">(</span><span class="n">prefix</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">circ</span><span class="o">.</span><span class="n">as_encoder</span><span class="p">()</span>

<span class="n">GenerateEncoderCircuit</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;e&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">svg</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="_images/qnn_for_nlp_5_0.svg" src="_images/qnn_for_nlp_5_0.svg" /></div>
</div>
<p><span class="math notranslate nohighlight">\(\left|0\right&gt;\)</span> and <span class="math notranslate nohighlight">\(\left|1\right&gt;\)</span> are used to mark the two states of a two-level qubit. According to the state superposition theory, qubit can also be in the superposition of these two states:</p>
<div class="math notranslate nohighlight">
\[\left|\psi\right&gt;=\alpha\left|0\right&gt;+\beta\left|1\right&gt;\]</div>
<p>For the quantum state of a <span class="math notranslate nohighlight">\(n\)</span> bits, it can be in a <span class="math notranslate nohighlight">\(2^n\)</span> Hilbert space. For the dictionary composed by the above 5 words, we only need <span class="math notranslate nohighlight">\(\lceil \log_2 5 \rceil=3\)</span> qubits to complete the encoding task, which demonstrates the superiority of quantum computing.</p>
<p>For example. given the word “love” in the above dictionary, its corresponding label is 2, represented by <code class="docutils literal notranslate"><span class="pre">010</span></code> in the binary format. We only need to set <code class="docutils literal notranslate"><span class="pre">e_0</span></code>, <code class="docutils literal notranslate"><span class="pre">e_1</span></code>, and <code class="docutils literal notranslate"><span class="pre">e_2</span></code> to <span class="math notranslate nohighlight">\(0\)</span>, <span class="math notranslate nohighlight">\(\pi\)</span>, and <span class="math notranslate nohighlight">\(0\)</span> respectively.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindquantum.simulator</span> <span class="kn">import</span> <span class="n">Simulator</span>

<span class="n">n_qubits</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of qubits of this quantum circuit</span>
<span class="n">label</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># label need to encode</span>
<span class="n">label_bin</span> <span class="o">=</span> <span class="nb">bin</span><span class="p">(</span><span class="n">label</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">,</span> <span class="s1">&#39;0&#39;</span><span class="p">)</span>  <span class="c1"># binary form of label</span>
<span class="n">label_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">label_bin</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># parameter value of encoder</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">GenerateEncoderCircuit</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;e&#39;</span><span class="p">)</span>  <span class="c1"># encoder circuit</span>
<span class="n">encoder_params_names</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">params_name</span>  <span class="c1"># parameter names of encoder</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Label is: &quot;</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Binary label is: &quot;</span><span class="p">,</span> <span class="n">label_bin</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Parameters of encoder is: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">label_array</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Encoder circuit is: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">encoder</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Encoder parameter names are: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">encoder_params_names</span><span class="p">)</span>

<span class="n">state</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">get_qs</span><span class="p">(</span><span class="n">pr</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">encoder_params_names</span><span class="p">,</span> <span class="n">label_array</span><span class="p">)))</span>
<span class="n">amp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Amplitude of quantum state is: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">amp</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Label in quantum state is: &quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">amp</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Label is:  2
Binary label is:  010
Parameters of encoder is:
 [0.      3.14159 0.     ]
Encoder circuit is:

      ┏━━━━━━━━━┓
q0: ──┨ RX(e_0) ┠───
      ┗━━━━━━━━━┛
      ┏━━━━━━━━━┓
q1: ──┨ RX(e_1) ┠───
      ┗━━━━━━━━━┛
      ┏━━━━━━━━━┓
q2: ──┨ RX(e_2) ┠───
      ┗━━━━━━━━━┛
Encoder parameter names are:
 [&#39;e_0&#39;, &#39;e_1&#39;, &#39;e_2&#39;]
Amplitude of quantum state is:
 [0. 0. 1. 0. 0. 0. 0. 0.]
Label in quantum state is:  2
</pre></div></div>
</div>
<p>Through the above verification, for the data with label 2, the position where the largest amplitude of the quantum state is finally obtained is also 2. Therefore, the obtained quantum state is exactly the encoding information of input label. We summarize the process of generating parameter values through data encoding information into the following function.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">GenerateTrainData</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">word_dict</span><span class="p">):</span>
    <span class="n">n_qubits</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="nb">max</span><span class="p">(</span><span class="n">word_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()))))</span>
    <span class="n">data_x</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">data_y</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">around</span><span class="p">,</span> <span class="n">center</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
        <span class="n">data_x</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">around</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">word_dict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
            <span class="n">label_bin</span> <span class="o">=</span> <span class="nb">bin</span><span class="p">(</span><span class="n">label</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">,</span> <span class="s1">&#39;0&#39;</span><span class="p">)</span>
            <span class="n">label_array</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">label_bin</span><span class="p">]</span>
            <span class="n">data_x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">label_array</span><span class="p">)</span>
        <span class="n">data_y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word_dict</span><span class="p">[</span><span class="n">center</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data_x</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data_y</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

<span class="n">GenerateTrainData</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">word_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(array([[0.       , 0.       , 0.       , 0.       , 3.1415927, 0.       ,
         3.1415927, 0.       , 0.       , 0.       , 0.       , 3.1415927]],
       dtype=float32),
 array([3], dtype=int32))
</pre></div></div>
</div>
<p>According to the above result, we merge the encoding information of these 4 input words into a longer vector for further usage of the neural network.</p>
</section>
<section id="ansatz-circuit">
<h2>Ansatz Circuit<a class="headerlink" href="#ansatz-circuit" title="Permalink to this headline"></a></h2>
<p>There is a variety of selections for the Ansatz circuits. We select the below quantum circuit as the Ansatz circuit. A single unit of the Ansatz circuit consists of a <a class="reference external" href="https://www.mindspore.cn/mindquantum/docs/en/master/core/gates/mindquantum.core.gates.RY.html">RY</a> gate and a <a class="reference external" href="https://www.mindspore.cn/mindquantum/docs/en/master/core/gates/mindquantum.core.gates.CNOTGate.html">CNOT</a> gate. The full Ansatz circuit can be obtained by repeating <span class="math notranslate nohighlight">\(p\)</span> times over this single unit.</p>
<p><img alt="ansatz circuit" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindquantum/docs/source_zh_cn/images/ansatz.png" /></p>
<p>The following function is defined to construct the Ansatz circuit.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">GenerateAnsatzCircuit</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">prefix</span> <span class="ow">and</span> <span class="n">prefix</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;_&#39;</span><span class="p">:</span>
        <span class="n">prefix</span> <span class="o">+=</span> <span class="s1">&#39;_&#39;</span>
    <span class="n">circ</span> <span class="o">=</span> <span class="n">Circuit</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">layers</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">):</span>
            <span class="n">circ</span> <span class="o">+=</span> <span class="n">RY</span><span class="p">(</span><span class="n">prefix</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">l</span> <span class="o">%</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n_qubits</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&lt;</span> <span class="n">n_qubits</span><span class="p">:</span>
                <span class="n">circ</span> <span class="o">+=</span> <span class="n">X</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">circ</span><span class="o">.</span><span class="n">as_ansatz</span><span class="p">()</span>

<span class="n">GenerateAnsatzCircuit</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">svg</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="_images/qnn_for_nlp_11_0.svg" src="_images/qnn_for_nlp_11_0.svg" /></div>
</div>
</section>
<section id="measurement">
<h2>Measurement<a class="headerlink" href="#measurement" title="Permalink to this headline"></a></h2>
<p>We treat the measurements of different qubits as the data after dimension reduction. This process is similar to qubit encoding. For example, when we want to reduce the dimension of the word vector to 5, we can process the data in the 3rd dimension as follows:</p>
<ul class="simple">
<li><p>3 in the binary format is 00011.</p></li>
<li><p>Measure the expectation value of the Z0Z1 hams at the quantum circuit end.</p></li>
</ul>
<p>The below function gives the hams to generate the data in all dimension, where n_qubits represents the number of qubits, dims represents the dimension of word embedding.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">GenerateEmbeddingHamiltonian</span><span class="p">(</span><span class="n">dims</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">):</span>
    <span class="n">hams</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dims</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">bin</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="s1">&#39;1&#39;</span><span class="p">:</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">+</span> <span class="s1">&#39;Z&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">j</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span>
        <span class="n">hams</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Hamiltonian</span><span class="p">(</span><span class="n">QubitOperator</span><span class="p">(</span><span class="n">s</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">hams</span>

<span class="n">GenerateEmbeddingHamiltonian</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[1 [Z0], 1 [Z1], 1 [Z0 Z1], 1 [Z2], 1 [Z0 Z2]]
</pre></div></div>
</div>
</section>
<section id="quantum-word-embedding-layer">
<h2>Quantum Word Embedding Layer<a class="headerlink" href="#quantum-word-embedding-layer" title="Permalink to this headline"></a></h2>
<p>The quantum word embedding layer combines the above-mentioned encoding quantum circuit, the quantum circuit to be trained, and the measurement of hams. <code class="docutils literal notranslate"><span class="pre">num_embedding</span></code> words can be embedded into a word vector with <code class="docutils literal notranslate"><span class="pre">embedding_dim</span></code> dimension. Here, a Hadamard gate is added at the beginning of the quantum circuit. The initialization state is set to average superposition state for improving the representation ability of the quantum neural network.</p>
<p>In the following, we define a quantum embedding layer and it returns a quantum circuit simulation operator.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">QEmbedding</span><span class="p">(</span><span class="n">num_embedding</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">):</span>
    <span class="n">n_qubits</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">num_embedding</span><span class="p">)))</span>
    <span class="n">hams</span> <span class="o">=</span> <span class="n">GenerateEmbeddingHamiltonian</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">)</span>
    <span class="n">circ</span> <span class="o">=</span> <span class="n">Circuit</span><span class="p">()</span>
    <span class="n">circ</span> <span class="o">=</span> <span class="n">UN</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">)</span>
    <span class="n">encoder_param_name</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ansatz_param_name</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">window</span><span class="p">):</span>
        <span class="n">encoder</span> <span class="o">=</span> <span class="n">GenerateEncoderCircuit</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">,</span> <span class="s1">&#39;Encoder_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>
        <span class="n">ansatz</span> <span class="o">=</span> <span class="n">GenerateAnsatzCircuit</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="s1">&#39;Ansatz_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>
        <span class="n">encoder</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
        <span class="n">circ</span> <span class="o">+=</span> <span class="n">encoder</span>
        <span class="n">circ</span> <span class="o">+=</span> <span class="n">ansatz</span>
        <span class="n">encoder_param_name</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">params_name</span><span class="p">)</span>
        <span class="n">ansatz_param_name</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">ansatz</span><span class="o">.</span><span class="n">params_name</span><span class="p">)</span>
    <span class="n">grad_ops</span> <span class="o">=</span> <span class="n">Simulator</span><span class="p">(</span><span class="s1">&#39;mqvector&#39;</span><span class="p">,</span> <span class="n">circ</span><span class="o">.</span><span class="n">n_qubits</span><span class="p">)</span><span class="o">.</span><span class="n">get_expectation_with_grad</span><span class="p">(</span><span class="n">hams</span><span class="p">,</span>
                                                                              <span class="n">circ</span><span class="p">,</span>
                                                                              <span class="n">parallel_worker</span><span class="o">=</span><span class="n">n_threads</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">MQLayer</span><span class="p">(</span><span class="n">grad_ops</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The training model is similar to a classical network, composed by an embedded layer and two fully-connected layers. However, the embedded layer here is constructed by a quantum neural network. The following defines the quantum neural network CBOW.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CBOW</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_embedding</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">,</span>
                 <span class="n">hidden_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CBOW</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">QEmbedding</span><span class="p">(</span><span class="n">num_embedding</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span>
                                    <span class="n">layers</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_embedding</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">embed</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
<p>In the following, we use a longer sentence for training. Firstly, we define <code class="docutils literal notranslate"><span class="pre">LossMonitorWithCollection</span></code> to supervise the convergence process and record the loss.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LossMonitorWithCollection</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LossMonitor</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">per_print_times</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LossMonitorWithCollection</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">per_print_times</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">begin_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total time used: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">end_time</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">begin_time</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_begin_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_print_times</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_print_times</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">net_outputs</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>

        <span class="n">cur_step_in_epoch</span> <span class="o">=</span> <span class="p">(</span><span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">batch_num</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">loss</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;epoch: </span><span class="si">{}</span><span class="s2"> step: </span><span class="si">{}</span><span class="s2">. Invalid loss, terminating training.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span><span class="p">,</span> <span class="n">cur_step_in_epoch</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_print_times</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_print_times</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">epoch: </span><span class="si">%+3s</span><span class="s2"> step: </span><span class="si">%+3s</span><span class="s2"> time: </span><span class="si">%5.5s</span><span class="s2">, loss is </span><span class="si">%5.5s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span><span class="p">,</span> <span class="n">cur_step_in_epoch</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch_begin_time</span><span class="p">,</span> <span class="n">loss</span><span class="p">),</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Next, embed a long setence by using the quantum <code class="docutils literal notranslate"><span class="pre">CBOW</span></code>. This command sets the thread of the quantum simulators to 4. When the number of qubits to be simulated is large, more threads can be set to improve the simulation efficiency.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;We are about to study the idea of a computational process.</span>
<span class="s2">Computational processes are abstract beings that inhabit computers.</span>
<span class="s2">As they evolve, processes manipulate other abstract things called data.</span>
<span class="s2">The evolution of a process is directed by a pattern of rules</span>
<span class="s2">called a program. People create programs to direct processes. In effect,</span>
<span class="s2">we conjure the spirits of the computer with our spells.&quot;&quot;&quot;</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">window_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">word_dict</span><span class="p">,</span> <span class="n">sample</span> <span class="o">=</span> <span class="n">GenerateWordDictAndSample</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="n">window_size</span><span class="p">)</span>
<span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span> <span class="o">=</span> <span class="n">GenerateTrainData</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">word_dict</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">({</span>
    <span class="s2">&quot;around&quot;</span><span class="p">:</span> <span class="n">train_x</span><span class="p">,</span>
    <span class="s2">&quot;center&quot;</span><span class="p">:</span> <span class="n">train_y</span>
<span class="p">},</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">CBOW</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word_dict</span><span class="p">),</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
<span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="n">net_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="n">loss_monitor</span> <span class="o">=</span> <span class="n">LossMonitorWithCollection</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">,</span> <span class="n">net_opt</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">350</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">loss_monitor</span><span class="p">],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
epoch:  25 step:  20 time: 0.247, loss is 0.103
epoch:  50 step:  20 time: 0.265, loss is 0.049
epoch:  75 step:  20 time: 0.259, loss is 0.031
epoch: 100 step:  20 time: 0.245, loss is 0.022
epoch: 125 step:  20 time: 0.249, loss is 0.019
epoch: 150 step:  20 time: 0.270, loss is 0.020
epoch: 175 step:  20 time: 0.305, loss is 0.020
epoch: 200 step:  20 time: 0.234, loss is 0.023
epoch: 225 step:  20 time: 0.236, loss is 0.026
epoch: 250 step:  20 time: 0.231, loss is 0.021
epoch: 275 step:  20 time: 0.240, loss is 0.024
epoch: 300 step:  20 time: 0.281, loss is 0.022
epoch: 325 step:  20 time: 0.235, loss is 0.018
epoch: 350 step:  20 time: 0.255, loss is 0.018
Total time used: 91.56754469871521
</pre></div></div>
</div>
<p>Print the loss value during convergence:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_monitor</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Steps&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/qnn_for_nlp_23_0.png" src="_images/qnn_for_nlp_23_0.png" />
</div>
</div>
<p>The method of printing the parameters of the quantum embedded layer is as follows:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([ 8.11327994e-02, -3.34400564e-01, -1.23247825e-01,  5.81944704e-01,
       -4.20968421e-03,  3.15563884e-05,  2.42589042e-01,  8.80479038e-01,
       -1.43023849e-01, -6.37480104e-03,  2.73182592e-03,  1.65943671e-02,
        2.39036694e-01, -2.39808977e-01, -6.56178296e-01,  2.62607052e-03,
       -9.76558731e-05, -7.48617807e-03,  4.85512346e-01,  8.62547606e-02,
        1.09600239e-02, -1.94667071e-01,  5.48206130e-03,  2.82003220e-05,
        2.83775508e-01, -3.44718695e-01,  2.57234443e-02, -1.58091113e-01,
       -5.39550185e-03, -1.15225427e-02,  2.88938046e-01, -5.74903965e-01,
       -2.53041506e-01, -1.81123063e-01, -5.67151117e-04, -3.33190081e-03,
        3.47066782e-02,  2.39473388e-01,  1.34246838e+00, -9.32823777e-01,
        1.55618461e-03,  1.34847098e-04,  7.36262277e-02, -1.90044902e-02,
       -1.26371592e-01,  4.32286650e-01, -3.66644454e-05, -1.36820097e-02,
        7.11344108e-02, -3.02037269e-01, -1.80939063e-01,  4.20952231e-01,
       -6.96726423e-03, -3.31268320e-03,  2.85857711e-02,  2.78895229e-01,
       -2.74261057e-01,  1.94433972e-01, -1.66424108e-03, -2.27207807e-03,
        6.26490265e-02, -1.98727295e-01, -1.25026256e-01, -1.52513385e-01,
       -5.60277607e-03, -7.44100334e-03,  4.44238521e-02, -6.64802119e-02,
        1.55135123e-02, -1.33805767e-01,  1.74699686e-02, -1.28326667e-02],
      dtype=float32)
</pre></div></div>
</div>
</section>
<section id="classical-word-embedding-layer">
<h2>Classical Word Embedding Layer<a class="headerlink" href="#classical-word-embedding-layer" title="Permalink to this headline"></a></h2>
<p>Here, we construct a classical CBOW neural network with the classical word embedding layer. This classical CBOW is compared with the quantum one.</p>
<p>Firstly, we construct the classical CBOW neural network and the parameters are similar to the ones in the quantum CBOW.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CBOWClassical</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_embedding</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CBOWClassical</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">window</span> <span class="o">*</span> <span class="n">embedding_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embedding</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_embedding</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Reshape</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">embed</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">embed</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
<p>Generate the dataset for the classical CBOW neural network.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_x</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
    <span class="n">around</span><span class="p">,</span> <span class="n">center</span> <span class="o">=</span> <span class="n">i</span>
    <span class="n">train_y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word_dict</span><span class="p">[</span><span class="n">center</span><span class="p">])</span>
    <span class="n">train_x</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">around</span><span class="p">:</span>
        <span class="n">train_x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word_dict</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
<span class="n">train_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_y</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_x shape: &quot;</span><span class="p">,</span> <span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_y shape: &quot;</span><span class="p">,</span> <span class="n">train_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
train_x shape:  (58, 4)
train_y shape:  (58,)
</pre></div></div>
</div>
<p>Train the classical CBOW network.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">({</span>
    <span class="s2">&quot;around&quot;</span><span class="p">:</span> <span class="n">train_x</span><span class="p">,</span>
    <span class="s2">&quot;center&quot;</span><span class="p">:</span> <span class="n">train_y</span>
<span class="p">},</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">CBOWClassical</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word_dict</span><span class="p">),</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
<span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="n">net_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="n">loss_monitor</span> <span class="o">=</span> <span class="n">LossMonitorWithCollection</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">,</span> <span class="n">net_opt</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">350</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">loss_monitor</span><span class="p">],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
epoch:  25 step:  20 time: 0.022, loss is 0.627
epoch:  50 step:  20 time: 0.028, loss is 0.011
epoch:  75 step:  20 time: 0.026, loss is 0.003
epoch: 100 step:  20 time: 0.022, loss is 0.002
epoch: 125 step:  20 time: 0.017, loss is 0.001
epoch: 150 step:  20 time: 0.021, loss is 0.001
epoch: 175 step:  20 time: 0.027, loss is 0.000
epoch: 200 step:  20 time: 0.019, loss is 0.000
epoch: 225 step:  20 time: 0.019, loss is 0.000
epoch: 250 step:  20 time: 0.019, loss is 0.000
epoch: 275 step:  20 time: 0.018, loss is 0.000
epoch: 300 step:  20 time: 0.025, loss is 0.000
epoch: 325 step:  20 time: 0.018, loss is 0.000
epoch: 350 step:  20 time: 0.017, loss is 0.000
Total time used: 8.476526975631714
</pre></div></div>
</div>
<p>Print the loss value during convergence:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_monitor</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Steps&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/qnn_for_nlp_33_0.png" src="_images/qnn_for_nlp_33_0.png" />
</div>
</div>
<p>According to the above result, it can be seen that the quantum word embedding model generated by the quantum simulation can complete the word embedding task perfectly. When classical computers cannot handle the large quantity of data, the quantum computers can easily deal with large data.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindquantum.utils.show_info</span> <span class="kn">import</span> <span class="n">InfoTable</span>

<span class="n">InfoTable</span><span class="p">(</span><span class="s1">&#39;mindquantum&#39;</span><span class="p">,</span> <span class="s1">&#39;scipy&#39;</span><span class="p">,</span> <span class="s1">&#39;numpy&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table border="1">
  <tr>
    <th>Software</th>
    <th>Version</th>
  </tr>
<tr><td>mindquantum</td><td>0.9.11</td></tr>
<tr><td>scipy</td><td>1.10.1</td></tr>
<tr><td>numpy</td><td>1.23.5</td></tr>
<tr>
    <th>System</th>
    <th>Info</th>
</tr>
<tr><td>Python</td><td>3.9.16</td></tr><tr><td>OS</td><td>Linux x86_64</td></tr><tr><td>Memory</td><td>8.3 GB</td></tr><tr><td>CPU Max Thread</td><td>8</td></tr><tr><td>Date</td><td>Mon Jan  1 01:34:10 2024</td></tr>
</table></div>
</div>
</section>
<section id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline"></a></h2>
<p>[1] Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean. <a class="reference external" href="https://arxiv.org/pdf/1301.3781.pdf">Efficient Estimation of Word Representations in Vector Space</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="quantum_approximate_optimization_algorithm.html" class="btn btn-neutral float-left" title="Quantum Approximate Optimization Algorithm" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="vqe_for_quantum_chemistry.html" class="btn btn-neutral float-right" title="VQE Application in Quantum Chemistry Computing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>