<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>One-click Conversion from DNN to BNN &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Using the Uncertainty Evaluation Toolbox" href="using_the_uncertainty_toolbox.html" />
    <link rel="prev" title="Using the VAE" href="using_the_vae.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="using_bnn.html">Using BNN to Implement an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="using_the_vae.html">Using the VAE</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">One-click Conversion from DNN to BNN</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">One-click Conversion from DNN to BNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-dnn-model">Defining the DNN Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-loss-function-and-optimizer">Defining the Loss Function and Optimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#function-1-converting-the-entire-model">Function 1: Converting the Entire Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#function-2-converting-a-layer-of-a-specified-type">Function 2: Converting a Layer of a Specified Type</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="using_the_uncertainty_toolbox.html">Using the Uncertainty Evaluation Toolbox</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability.html">Deep Probabilistic Programming Library</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.probability.html">mindspore.nn.probability</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>One-click Conversion from DNN to BNN</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/one_click_conversion_from_dnn_to_bnn.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="one-click-conversion-from-dnn-to-bnn">
<h1>One-click Conversion from DNN to BNN<a class="headerlink" href="#one-click-conversion-from-dnn-to-bnn" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.6/docs/probability/docs/source_en/one_click_conversion_from_dnn_to_bnn.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.6/resource/_static/logo_source_en.png"></a></p>
<section id="id1">
<h2>One-click Conversion from DNN to BNN<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<p>For DNN researchers unfamiliar with the Bayesian model, MDP provides an advanced API <code class="docutils literal notranslate"><span class="pre">TransformToBNN</span></code> to convert the DNN model into the BNN model with one click. Currently, the API can be used in the LeNet, ResNet, MobileNet and VGG models. This example describes how to use the <code class="docutils literal notranslate"><span class="pre">TransformToBNN</span></code> API in the transforms module to convert DNNs into BNNs with one click. The overall process is as follows:</p>
<ol class="arabic simple">
<li><p>Define a DNN model.</p></li>
<li><p>Define the loss function and optimizer.</p></li>
<li><p>Function 1: Convert the entire model.</p></li>
<li><p>Function 2: Convert a layer of a specified type.</p></li>
</ol>
<blockquote>
<div><p>This example is for the GPU or Ascend 910 AI processor platform. You can download the complete sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.6/tests/st/probability/transforms">https://gitee.com/mindspore/mindspore/tree/r1.6/tests/st/probability/transforms</a>.</p>
</div></blockquote>
<section id="defining-the-dnn-model">
<h3>Defining the DNN Model<a class="headerlink" href="#defining-the-dnn-model" title="Permalink to this headline"></a></h3>
<p>The deep neural network (DNN) model used in this example is LeNet5. After the definition is complete, print the name of its neural layer. Since the main convolutional layer and pooling layer are at the conversion level, this example also shows the conversion information of these two calculation layers in a targeted manner.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">Normal</span>

<span class="k">class</span> <span class="nc">LeNet5</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Lenet network structure.&quot;&quot;&quot;</span>
    <span class="c1"># define the operator required</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_class</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet5</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_channel</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="n">num_class</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>

    <span class="c1"># use the preceding operators to construct networks</span>
    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<p>For the classic DNN model LeNet5 network convolutional layer has two layers conv1, conv2, fully connected layer is 3 layers: fc1, fc2, fc3.</p>
</section>
<section id="defining-the-loss-function-and-optimizer">
<h3>Defining the Loss Function and Optimizer<a class="headerlink" href="#defining-the-loss-function-and-optimizer" title="Permalink to this headline"></a></h3>
<p>In this example, the loss function used is the cross-entropy loss function <code class="docutils literal notranslate"><span class="pre">nn.SoftmaxCrossEntropyWithLogits</span></code>, and the optimizer is the <code class="docutils literal notranslate"><span class="pre">Adam</span></code> function, which is <code class="docutils literal notranslate"><span class="pre">nn.AdamWeightDecay</span></code>.</p>
<p>Because the BNN of the entire model needs to be converted, it is necessary to associate the DNN network, loss function and optimizer into a complete calculation network, namely <code class="docutils literal notranslate"><span class="pre">train_network</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pprint</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">WithLossCell</span><span class="p">,</span> <span class="n">TrainOneStepCell</span>
<span class="kn">from</span> <span class="nn">mindspore.nn.probability</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span><span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;GPU&quot;</span><span class="p">)</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdamWeightDecay</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
<span class="c1">#optimizer = nn.Momentum(network.trainable_params(), lr, momentum)</span>
<span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">WithLossCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
<span class="n">train_network</span> <span class="o">=</span> <span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>

<span class="n">DNN_layer_name</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()]</span>
<span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">DNN_layer_name</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[&#39;conv1.weight&#39;,
 &#39;conv2.weight&#39;,
 &#39;fc1.weight&#39;,
 &#39;fc1.bias&#39;,
 &#39;fc2.weight&#39;,
 &#39;fc2.bias&#39;,
 &#39;fc3.weight&#39;,
 &#39;fc3.bias&#39;]
</pre></div>
</div>
<p>The above-mentioned print information is the name of the convolutional layer and the fully connected layer that are not currently converted.</p>
</section>
<section id="function-1-converting-the-entire-model">
<h3>Function 1: Converting the Entire Model<a class="headerlink" href="#function-1-converting-the-entire-model" title="Permalink to this headline"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">TransformToBNN</span></code> API in the <code class="docutils literal notranslate"><span class="pre">transforms</span></code> can convert the entire DNN model into a BNN model. The definition is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">bnn_transformer</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">TransformToBNN</span><span class="p">(</span><span class="n">train_network</span><span class="p">,</span> <span class="mi">60000</span><span class="p">,</span> <span class="mf">0.000001</span><span class="p">)</span>
<span class="n">train_bnn_network</span> <span class="o">=</span> <span class="n">bnn_transformer</span><span class="o">.</span><span class="n">transform_to_bnn_model</span><span class="p">()</span>

<span class="n">BNN_layer_name</span> <span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()]</span>
<span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">BNN_layer_name</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[&#39;conv1.weight_posterior.mean&#39;,
 &#39;conv1.weight_posterior.untransformed_std&#39;,
 &#39;conv2.weight_posterior.mean&#39;,
 &#39;conv2.weight_posterior.untransformed_std&#39;,
 &#39;fc1.weight_posterior.mean&#39;,
 &#39;fc1.weight_posterior.untransformed_std&#39;,
 &#39;fc1.bias_posterior.mean&#39;,
 &#39;fc1.bias_posterior.untransformed_std&#39;,
 &#39;fc2.weight_posterior.mean&#39;,
 &#39;fc2.weight_posterior.untransformed_std&#39;,
 &#39;fc2.bias_posterior.mean&#39;,
 &#39;fc2.bias_posterior.untransformed_std&#39;,
 &#39;fc3.weight_posterior.mean&#39;,
 &#39;fc3.weight_posterior.untransformed_std&#39;,
 &#39;fc3.bias_posterior.mean&#39;,
 &#39;fc3.bias_posterior.untransformed_std&#39;]
</pre></div>
</div>
<p>The above-mentioned printed information is the convolutional layer and fully connected name after the overall conversion into a Bayesian network (BNN).</p>
</section>
<section id="function-2-converting-a-layer-of-a-specified-type">
<h3>Function 2: Converting a Layer of a Specified Type<a class="headerlink" href="#function-2-converting-a-layer-of-a-specified-type" title="Permalink to this headline"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">transform_to_bnn_layer</span></code> method can convert a layer of a specified type (nn.Dense or nn.Conv2d) in the DNN model into a corresponding Bayesian layer. The definition is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span> <span class="n">transform_to_bnn_layer</span><span class="p">(</span><span class="n">dnn_layer</span><span class="p">,</span> <span class="n">bnn_layer</span><span class="p">,</span> <span class="n">get_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">add_args</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</pre></div>
</div>
<p>Parameter explanation:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dnn_layer</span></code>: Specify which type of DNN layer to convert into BNN layer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bnn_layer</span></code>: Specify which type of BNN layer the DNN layer will be converted into.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_args</span></code>: Specify which parameters to get from the DNN layer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">add_args</span></code>: Specify which parameters of the BNN layer to re-assign.</p></li>
</ul>
<p>The code to convert the Dense layer in the DNN model into the corresponding Bayesian layer <code class="docutils literal notranslate"><span class="pre">DenseReparam</span></code> in MindSpore is as follows:</p>
<p>The <code class="docutils literal notranslate"><span class="pre">dnn_layer</span></code> parameter specifies a type of a DNN layer to be converted into a BNN layer, and the <code class="docutils literal notranslate"><span class="pre">bnn_layer</span></code> parameter specifies a type of a BNN layer to be converted into a DNN layer, <code class="docutils literal notranslate"><span class="pre">get_args</span></code> and <code class="docutils literal notranslate"><span class="pre">add_args</span></code> specify parameters obtained from the DNN layer and the parameters to be re-assigned to the BNN layer, respectively.</p>
<p>The code for converting a Dense layer in a DNN model into a corresponding Bayesian layer <code class="docutils literal notranslate"><span class="pre">DenseReparam</span></code> in MindSpore is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.nn.probability</span> <span class="kn">import</span> <span class="n">bnn_layers</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdamWeightDecay</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
<span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">WithLossCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
<span class="n">train_network</span> <span class="o">=</span> <span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
<span class="n">bnn_transformer</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">TransformToBNN</span><span class="p">(</span><span class="n">train_network</span><span class="p">,</span> <span class="mi">60000</span><span class="p">,</span> <span class="mf">0.000001</span><span class="p">)</span>
<span class="n">train_bnn_network</span> <span class="o">=</span> <span class="n">bnn_transformer</span><span class="o">.</span><span class="n">transform_to_bnn_layer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">,</span> <span class="n">bnn_layers</span><span class="o">.</span><span class="n">DenseReparam</span><span class="p">)</span>
</pre></div>
</div>
<p>Execute the following code to view the structure of the converted network:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">DNN_layer_name</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()]</span>
<span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">DNN_layer_name</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[&#39;conv1.weight&#39;,
 &#39;conv2.weight&#39;,
 &#39;fc1.weight_posterior.mean&#39;,
 &#39;fc1.weight_posterior.untransformed_std&#39;,
 &#39;fc1.bias_posterior.mean&#39;,
 &#39;fc1.bias_posterior.untransformed_std&#39;,
 &#39;fc2.weight_posterior.mean&#39;,
 &#39;fc2.weight_posterior.untransformed_std&#39;,
 &#39;fc2.bias_posterior.mean&#39;,
 &#39;fc2.bias_posterior.untransformed_std&#39;,
 &#39;fc3.weight_posterior.mean&#39;,
 &#39;fc3.weight_posterior.untransformed_std&#39;,
 &#39;fc3.bias_posterior.mean&#39;,
 &#39;fc3.bias_posterior.untransformed_std&#39;]
</pre></div>
</div>
<p>As shown in the preceding information, the LeNet network transformed by <code class="docutils literal notranslate"><span class="pre">transform_to_bnn_layer</span></code> converts all the specified fully connected layers into Bayesian layers.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="using_the_vae.html" class="btn btn-neutral float-left" title="Using the VAE" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="using_the_uncertainty_toolbox.html" class="btn btn-neutral float-right" title="Using the Uncertainty Evaluation Toolbox" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>