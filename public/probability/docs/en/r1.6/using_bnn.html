<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Using BNN to Implement an Image Classification Application &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Using the VAE" href="using_the_vae.html" />
    <link rel="prev" title="MindSpore Probability Documents" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Using BNN to Implement an Image Classification Application</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#using-bnn">Using BNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="#environment-preparation">Environment Preparation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#data-preparation">Data Preparation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#downloading-the-dataset">Downloading the Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-dataset-enhancement-method">Defining the Dataset Enhancement Method</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-bnn">Defining the BNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-loss-function-and-optimizer">Defining the Loss Function and Optimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training-the-network">Training the Network</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="using_the_vae.html">Using the VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="one_click_conversion_from_dnn_to_bnn.html">One-click Conversion from DNN to BNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="using_the_uncertainty_toolbox.html">Using the Uncertainty Evaluation Toolbox</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability.html">Deep Probabilistic Programming Library</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.probability.html">mindspore.nn.probability</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Using BNN to Implement an Image Classification Application</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/using_bnn.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="using-bnn-to-implement-an-image-classification-application">
<h1>Using BNN to Implement an Image Classification Application<a class="headerlink" href="#using-bnn-to-implement-an-image-classification-application" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.6/docs/probability/docs/source_en/using_bnn.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.6/resource/_static/logo_source_en.png"></a></p>
<p>Deep learning models have a strong fitting capability, while Bayesian theory has a good explainable capability. MindSpore Deep Probability Programming combines deep learning and Bayesian learning. By setting the network weight to distribution, introducing hidden space distribution, etc., the distribution can be sampled forward propagation, which introduces uncertainty and enhances The robustness and interpretability of the model are improved.</p>
<p>This chapter will introduce in detail the application of Bayesian neural network in deep probabilistic programming on MindSpore. Before starting to practice, make sure that you have correctly installed MindSpore 0.7.0-beta and above.</p>
<blockquote>
<div><p>This example is for the GPU or Ascend 910 AI processor platform. You can download the complete sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.6/tests/st/probability/bnn_layers">https://gitee.com/mindspore/mindspore/tree/r1.6/tests/st/probability/bnn_layers</a>.<br />
BNN only supports GRAPH mode now, please set <code class="docutils literal notranslate"><span class="pre">context.set_context(mode=context.GRAPH_MODE)</span></code> in your code.</p>
</div></blockquote>
<section id="using-bnn">
<h2>Using BNN<a class="headerlink" href="#using-bnn" title="Permalink to this headline"></a></h2>
<p>BNN is a basic model composed of probabilistic model and neural network. Its weight is not a definite value, but a distribution. The following example describes how to use the <code class="docutils literal notranslate"><span class="pre">bnn_layers</span></code> module in MDP to implement a BNN, and then use the BNN to implement a simple image classification function. The overall process is as follows:</p>
<ol class="arabic simple">
<li><p>Process the MNIST dataset.</p></li>
<li><p>Define the Bayes LeNet.</p></li>
<li><p>Define the loss function and optimizer.</p></li>
<li><p>Load and train the dataset.</p></li>
</ol>
<blockquote>
<div><p>This example is for the GPU or Ascend 910 AI processor platform. You can download the complete sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.6/tests/st/probability/bnn_layers">https://gitee.com/mindspore/mindspore/tree/r1.6/tests/st/probability/bnn_layers</a>.
BNN only supports GRAPH mode now, please set <code class="docutils literal notranslate"><span class="pre">context.set_context(mode=context.GRAPH_MODE)</span></code> in your code.</p>
</div></blockquote>
</section>
<section id="environment-preparation">
<h2>Environment Preparation<a class="headerlink" href="#environment-preparation" title="Permalink to this headline"></a></h2>
<p>Set the training mode to graph mode and the computing platform to GPU.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;GPU&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="data-preparation">
<h2>Data Preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline"></a></h2>
<section id="downloading-the-dataset">
<h3>Downloading the Dataset<a class="headerlink" href="#downloading-the-dataset" title="Permalink to this headline"></a></h3>
<p>Download the MNIST dataset and unzip it to the specified location, execute the following command:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="k">def</span> <span class="nf">download_dataset</span><span class="p">(</span><span class="n">dataset_url</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="n">dataset_url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">save_path</span><span class="p">):</span>
        <span class="k">return</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">dataset_url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verify</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">res</span><span class="o">.</span><span class="n">iter_content</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">512</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">chunk</span><span class="p">:</span>
                <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>

<span class="n">train_path</span> <span class="o">=</span> <span class="s2">&quot;datasets/MNIST_Data/train&quot;</span>
<span class="n">test_path</span> <span class="o">=</span> <span class="s2">&quot;datasets/MNIST_Data/test&quot;</span>

<span class="n">download_dataset</span><span class="p">(</span><span class="s2">&quot;https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/train-labels-idx1-ubyte&quot;</span><span class="p">,</span> <span class="n">train_path</span><span class="p">)</span>
<span class="n">download_dataset</span><span class="p">(</span><span class="s2">&quot;https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/train-images-idx3-ubyte&quot;</span><span class="p">,</span> <span class="n">train_path</span><span class="p">)</span>
<span class="n">download_dataset</span><span class="p">(</span><span class="s2">&quot;https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/t10k-labels-idx1-ubyte&quot;</span><span class="p">,</span> <span class="n">test_path</span><span class="p">)</span>
<span class="n">download_dataset</span><span class="p">(</span><span class="s2">&quot;https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/t10k-images-idx3-ubyte&quot;</span><span class="p">,</span> <span class="n">test_path</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./datasets/MNIST_Data
├── test
│   ├── t10k-images-idx3-ubyte
│   └── t10k-labels-idx1-ubyte
└── train
    ├── train-images-idx3-ubyte
    └── train-labels-idx1-ubyte

2 directories, 4 files
</pre></div>
</div>
</section>
<section id="defining-the-dataset-enhancement-method">
<h3>Defining the Dataset Enhancement Method<a class="headerlink" href="#defining-the-dataset-enhancement-method" title="Permalink to this headline"></a></h3>
<p>The original training dataset of the MNIST dataset is 60,000 single-channel digital images with <span class="math notranslate nohighlight">\(28\times28\)</span> pixels. The LeNet5 network containing the Bayesian layer used in this training received the training data tensor as <code class="docutils literal notranslate"><span class="pre">(32,1</span> <span class="pre">,32,32)</span></code>, through the custom create_dataset function to enhance the original dataset to meet the training requirements of the data, the specific enhancement operation explanation can refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.6/quick_start.html">Quick Start for Beginners</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset.vision.c_transforms</span> <span class="k">as</span> <span class="nn">CV</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.transforms.c_transforms</span> <span class="k">as</span> <span class="nn">C</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset.vision</span> <span class="kn">import</span> <span class="n">Inter</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dataset</span> <span class="k">as</span> <span class="n">ds</span>

<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                   <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># define dataset</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MnistDataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>

    <span class="c1"># define some parameters needed for data enhancement and rough justification</span>
    <span class="n">resize_height</span><span class="p">,</span> <span class="n">resize_width</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span>
    <span class="n">rescale</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">255.0</span>
    <span class="n">shift</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">rescale_nml</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mf">0.3081</span>
    <span class="n">shift_nml</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="mf">0.1307</span> <span class="o">/</span> <span class="mf">0.3081</span>

    <span class="c1"># according to the parameters, generate the corresponding data enhancement method</span>
    <span class="n">c_trans</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">CV</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="n">resize_height</span><span class="p">,</span> <span class="n">resize_width</span><span class="p">),</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">),</span>
        <span class="n">CV</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="n">rescale_nml</span><span class="p">,</span> <span class="n">shift_nml</span><span class="p">),</span>
        <span class="n">CV</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="n">rescale</span><span class="p">,</span> <span class="n">shift</span><span class="p">),</span>
        <span class="n">CV</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="p">]</span>
    <span class="n">type_cast_op</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="c1"># using map to apply operations to a dataset</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">type_cast_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">c_trans</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>

    <span class="c1"># process the generated dataset</span>
    <span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">10000</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">buffer_size</span><span class="p">)</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat_size</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mnist_ds</span>
</pre></div>
</div>
</section>
<section id="defining-the-bnn">
<h3>Defining the BNN<a class="headerlink" href="#defining-the-bnn" title="Permalink to this headline"></a></h3>
<p>In the classic LeNet5 network, the data goes through the following calculation process: convolution 1-&gt;activation-&gt;pooling-&gt;convolution 2-&gt;activation-&gt;pooling-&gt;dimensionality reduction-&gt;full connection 1-&gt;full connection 2-&gt; Fully connected 3.</p>
<p>In this example, a probabilistic programming method will be introduced, using the <code class="docutils literal notranslate"><span class="pre">bnn_layers</span></code> module to transform the convolutional layer and the fully connected layer into a Bayesian layer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.nn.probability</span> <span class="kn">import</span> <span class="n">bnn_layers</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>


<span class="k">class</span> <span class="nc">BNNLeNet5</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_class</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BNNLeNet5</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_class</span> <span class="o">=</span> <span class="n">num_class</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">bnn_layers</span><span class="o">.</span><span class="n">ConvReparam</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">bnn_layers</span><span class="o">.</span><span class="n">ConvReparam</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">bnn_layers</span><span class="o">.</span><span class="n">DenseReparam</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">bnn_layers</span><span class="o">.</span><span class="n">DenseReparam</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">bnn_layers</span><span class="o">.</span><span class="n">DenseReparam</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_class</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">BNNLeNet5</span><span class="p">(</span><span class="n">num_class</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>conv1.weight_posterior.mean
conv1.weight_posterior.untransformed_std
conv2.weight_posterior.mean
conv2.weight_posterior.untransformed_std
fc1.weight_posterior.mean
fc1.weight_posterior.untransformed_std
fc1.bias_posterior.mean
fc1.bias_posterior.untransformed_std
fc2.weight_posterior.mean
fc2.weight_posterior.untransformed_std
fc2.bias_posterior.mean
fc2.bias_posterior.untransformed_std
fc3.weight_posterior.mean
fc3.weight_posterior.untransformed_std
fc3.bias_posterior.mean
fc3.bias_posterior.untransformed_std
</pre></div>
</div>
<p>The printed information shows that the convolutional layer and the fully connected layer of the LeNet network constructed with the <code class="docutils literal notranslate"><span class="pre">bnn_layers</span></code> module are both Bayesian layers.</p>
</section>
<section id="defining-the-loss-function-and-optimizer">
<h3>Defining the Loss Function and Optimizer<a class="headerlink" href="#defining-the-loss-function-and-optimizer" title="Permalink to this headline"></a></h3>
<p>Next, you need to define the loss function and the optimizer. The loss function is the training target of deep learning, also called the objective function. It can be understood as the distance between the output of the neural network (Logits) and the label (Labels), which is a scalar data.</p>
<p>Common loss functions include mean square error, L2 loss, Hinge loss, and cross entropy. Cross entropy is usually used for image classification.</p>
<p>The optimizer is used for neural network solution (training). Because of the large scale of neural network parameters, the stochastic gradient descent (SGD) algorithm and its improved algorithm are used in deep learning to solve the problem. MindSpore encapsulates common optimizers, such as <code class="docutils literal notranslate"><span class="pre">SGD</span></code>, <code class="docutils literal notranslate"><span class="pre">Adam</span></code>, and <code class="docutils literal notranslate"><span class="pre">Momemtum</span></code>. In this example, the <code class="docutils literal notranslate"><span class="pre">Adam</span></code> optimizer is used. Generally, two parameters need to be set: learning rate (<code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>) and weight attenuation (<code class="docutils literal notranslate"><span class="pre">weight_decay</span></code>).</p>
<p>An example of the code for defining the loss function and optimizer in MindSpore is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="c1"># loss function definition</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>

<span class="c1"># optimization definition</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdamWeightDecay</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="training-the-network">
<h3>Training the Network<a class="headerlink" href="#training-the-network" title="Permalink to this headline"></a></h3>
<p>The training process of BNN is similar to that of DNN. The only difference is that <code class="docutils literal notranslate"><span class="pre">WithLossCell</span></code> is replaced with <code class="docutils literal notranslate"><span class="pre">WithBNNLossCell</span></code> applicable to BNN. In addition to the <code class="docutils literal notranslate"><span class="pre">backbone</span></code> and <code class="docutils literal notranslate"><span class="pre">loss_fn</span></code> parameters, the <code class="docutils literal notranslate"><span class="pre">dnn_factor</span></code> and <code class="docutils literal notranslate"><span class="pre">bnn_factor</span></code> parameters are added to <code class="docutils literal notranslate"><span class="pre">WithBNNLossCell</span></code>. <code class="docutils literal notranslate"><span class="pre">dnn_factor</span></code> is a coefficient of the overall network loss computed by a loss function, and <code class="docutils literal notranslate"><span class="pre">bnn_factor</span></code> is a coefficient of the KL divergence of each Bayesian layer. The two parameters are used to balance the overall network loss and the KL divergence of the Bayesian layer, preventing the overall network loss from being covered by a large KL divergence.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dnn_factor</span></code> is the coefficient of the overall network loss calculated by the loss function.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bnn_factor</span></code> is the coefficient of the KL divergence of each Bayesian layer.</p></li>
</ul>
<p>The code examples of <code class="docutils literal notranslate"><span class="pre">train_model</span></code> and <code class="docutils literal notranslate"><span class="pre">validate_model</span></code> in MindSpore are as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">train_net</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
    <span class="n">accs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">loss_sum</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">()):</span>
        <span class="n">train_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">train_net</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
        <span class="n">log_output</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_output</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">label</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
        <span class="n">accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>
        <span class="n">loss_sum</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>

    <span class="n">loss_sum</span> <span class="o">=</span> <span class="n">loss_sum</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">accs</span><span class="p">)</span>
    <span class="n">acc_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">accs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss_sum</span><span class="p">,</span> <span class="n">acc_mean</span>


<span class="k">def</span> <span class="nf">validate_model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
    <span class="n">accs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">()):</span>
        <span class="n">train_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
        <span class="n">log_output</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_output</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">label</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
        <span class="n">accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>

    <span class="n">acc_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">accs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">acc_mean</span>
</pre></div>
</div>
<p>Perform training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">TrainOneStepCell</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">bnn_layers</span><span class="o">.</span><span class="n">WithBNNLossCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">dnn_factor</span><span class="o">=</span><span class="mi">60000</span><span class="p">,</span> <span class="n">bnn_factor</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">)</span>
<span class="n">train_bnn_network</span> <span class="o">=</span> <span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
<span class="n">train_bnn_network</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>

<span class="n">train_set</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;./datasets/MNIST_Data/train&#39;</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">test_set</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;./datasets/MNIST_Data/test&#39;</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">epoch</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">train_bnn_network</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">train_set</span><span class="p">)</span>

    <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">validate_model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">test_set</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch: </span><span class="si">{}</span><span class="s1"> </span><span class="se">\t</span><span class="s1">Training Loss: </span><span class="si">{:.4f}</span><span class="s1"> </span><span class="se">\t</span><span class="s1">Training Accuracy: </span><span class="si">{:.4f}</span><span class="s1"> </span><span class="se">\t</span><span class="s1">validation Accuracy: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span>
          <span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">valid_acc</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Epoch: 1    Training Loss: 21444.8605   Training Accuracy: 0.8928    validation Accuracy: 0.9513
Epoch: 2    Training Loss: 9396.3887    Training Accuracy: 0.9536    validation Accuracy: 0.9635
Epoch: 3    Training Loss: 7320.2412    Training Accuracy: 0.9641    validation Accuracy: 0.9674
Epoch: 4    Training Loss: 6221.6970    Training Accuracy: 0.9685    validation Accuracy: 0.9731
Epoch: 5    Training Loss: 5450.9543    Training Accuracy: 0.9725    validation Accuracy: 0.9733
Epoch: 6    Training Loss: 4898.9741    Training Accuracy: 0.9754    validation Accuracy: 0.9767
Epoch: 7    Training Loss: 4505.7502    Training Accuracy: 0.9775    validation Accuracy: 0.9784
Epoch: 8    Training Loss: 4099.8783    Training Accuracy: 0.9797    validation Accuracy: 0.9791
Epoch: 9    Training Loss: 3795.2288    Training Accuracy: 0.9810    validation Accuracy: 0.9796
Epoch: 10    Training Loss: 3581.4254    Training Accuracy: 0.9823    validation Accuracy: 0.9773
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="MindSpore Probability Documents" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="using_the_vae.html" class="btn btn-neutral float-right" title="Using the VAE" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>