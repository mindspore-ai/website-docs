<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ReplayBuffer Usage Introduction &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Reinforcement Learning Environment Access" href="environment.html" />
    <link rel="prev" title="Deep Q Learning (DQN) with MindSpore Reinforcement" href="dqn.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="reinforcement_install.html">MindSpore Reinforcement Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="custom_config_info.html">MindSpore RL Configuration Instruction</a></li>
<li class="toctree-l1"><a class="reference internal" href="dqn.html">Deep Q Learning (DQN) with MindSpore Reinforcement</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">ReplayBuffer Usage Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#brief-introduction-of-replaybuffer">Brief Introduction of ReplayBuffer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#replaybuffer-implementation-of-mindspore-reinforcement-learning">ReplayBuffer Implementation of MindSpore Reinforcement Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#parameter-explanation">Parameter Explanation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#functions-introduction">Functions Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#1-insert">1 Insert</a></li>
<li class="toctree-l4"><a class="reference internal" href="#2-search">2 Search</a></li>
<li class="toctree-l4"><a class="reference internal" href="#3-sample">3 Sample</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#uniformreplaybuffer-introduction-of-mindspore-reinforcement-learning">UniformReplayBuffer Introduction of MindSpore Reinforcement Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#creation-of-uniformreplaybuffer">Creation of UniformReplayBuffer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-the-created-uniformreplaybuffer">Using the Created UniformReplayBuffer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="environment.html">Reinforcement Learning Environment Access</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="reinforcement.html">mindspore_rl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>ReplayBuffer Usage Introduction</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/replaybuffer.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="replaybuffer-usage-introduction">
<h1>ReplayBuffer Usage Introduction<a class="headerlink" href="#replaybuffer-usage-introduction" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/master/docs/reinforcement/docs/source_en/replaybuffer.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png"></a></p>
<section id="brief-introduction-of-replaybuffer">
<h2>Brief Introduction of ReplayBuffer<a class="headerlink" href="#brief-introduction-of-replaybuffer" title="Permalink to this headline"></a></h2>
<p>In reinforcement learning, ReplayBuffer is a common basic data storage method, whose functions is to store the data obtained from the interaction of an intelligent body with its environment.</p>
<p>Solve the following problems by using ReplayBuffer:</p>
<ol class="arabic simple">
<li><p>Stored historical data can be extracted by sampling to break the correlation of training data, so that the sampled data have independent and identically distributed characteristics.</p></li>
<li><p>Provide temporary storage of data and improve the utilization of data.</p></li>
</ol>
</section>
<section id="replaybuffer-implementation-of-mindspore-reinforcement-learning">
<h2>ReplayBuffer Implementation of MindSpore Reinforcement Learning<a class="headerlink" href="#replaybuffer-implementation-of-mindspore-reinforcement-learning" title="Permalink to this headline"></a></h2>
<p>Typically, algorithms people use native Python data structures or Numpy data structures to construct ReplayBuffer, or general reinforcement learning frameworks also provide standard API encapsulation. The difference is that MindSpore implements the ReplayBuffer structure on the device side. On the one hand, the structure can reduce the frequent copying of data between Host and Device when using GPU hardware, and on the other hand, expressing the ReplayBuffer in the form of MindSpore operator can build a complete IR graph and enable various graph optimizations of MindSpore GRAPH_MODE to improve the overall performance.</p>
<p>In MindSpore, two kinds of ReplayBuffer are provided, UniformReplayBuffer and PriorityReplayBuffer, which are used for common FIFO storage and storage with priority, respectively. The following is an example of UniformReplayBuffer implementation and usage.</p>
<p>ReplayBuffer is represented as a List of Tensors, and each Tensor represents a set of data stored by column (e.g., a set of [state, action, reward]). The data that is newly put into the UniformReplayBuffer is updated in a FIFO mechanism with insert, search, and sample functions.</p>
<section id="parameter-explanation">
<h3>Parameter Explanation<a class="headerlink" href="#parameter-explanation" title="Permalink to this headline"></a></h3>
<p>Create a UniformReplayBuffer with the initialization parameters batch_size, capacity, shapes, and types.</p>
<ul class="simple">
<li><p>batch_size indicates the size of the data at a time for sample, an integer value.</p></li>
<li><p>capacity indicates the total capacity of the created UniformReplayBuffer, an integer value.</p></li>
<li><p>shapes indicates the shape size of each set of data in Buffer, expressed as a list.</p></li>
<li><p>types indicates the data type corresponding to each set of data in the Buffer, represented as a list.</p></li>
</ul>
</section>
<section id="functions-introduction">
<h3>Functions Introduction<a class="headerlink" href="#functions-introduction" title="Permalink to this headline"></a></h3>
<section id="1-insert">
<h4>1 Insert<a class="headerlink" href="#1-insert" title="Permalink to this headline"></a></h4>
<p>The insert method takes a set of data as input, and needs to satisfy that the shape and type of the data are the same as the created UniformReplayBuffer parameters. No output.
To simulate the FIFO characteristics of a circular queue, we use two cursors to determine the head and effective length count of the queue. The following figure shows the process of several insertion operations.</p>
<ol class="arabic simple">
<li><p>The total size of the buffer is 6. In the initial state, the cursor head and count are both 0.</p></li>
<li><p>After inserting a batch_size of 2, the current head is unchanged and count is added by 2.</p></li>
<li><p>After continuing to insert a batch_size of 4, the queue is full and the count is 6.</p></li>
<li><p>After continuing to insert a batch_size of 2, overwrite updates the old data and adds 2 to the head.</p></li>
</ol>
<p><img alt="insert schematic diagram" src="https://gitee.com/mindspore/docs/blob/master/docs/reinforcement/docs/source_zh_cn/images/insert.png" /></p>
</section>
<section id="2-search">
<h4>2 Search<a class="headerlink" href="#2-search" title="Permalink to this headline"></a></h4>
<p>The search method accepts an index as an input, indicating the specific location of the data to be found. The output is a set of Tensor, as shown in the following figure:</p>
<ol class="arabic simple">
<li><p>If the UniformReplayBuffer is just full or not full, the corresponding data is found directly according to the index.</p></li>
<li><p>For data that has been overwritten, remap it by cursors.</p></li>
</ol>
<p><img alt="get_item schematic diagram" src="https://gitee.com/mindspore/docs/blob/master/docs/reinforcement/docs/source_zh_cn/images/get.png" /></p>
</section>
<section id="3-sample">
<h4>3 Sample<a class="headerlink" href="#3-sample" title="Permalink to this headline"></a></h4>
<p>The sampling method has no input and the output is a set of Tensor with the size of the batch_size when the UniformReplayBuffer is created. This is shown in the following figure:
Assuming that batch_size is 3, a random set of indexes will be generated in the operator, and this random set of indexes has two cases:</p>
<ol class="arabic simple">
<li><p>Order preserving: each index means the real data position, which needs to be remapped by cursor operation.</p></li>
<li><p>No order preserving: each index does not represent the real position and is obtained directly.</p></li>
</ol>
<p>Both approaches have a slight impact on randomness, and the default is to use no order preserving to get the best performance.</p>
<p><img alt="sample schematic diagram" src="https://gitee.com/mindspore/docs/blob/master/docs/reinforcement/docs/source_zh_cn/images/sample.png" /></p>
</section>
</section>
</section>
<section id="uniformreplaybuffer-introduction-of-mindspore-reinforcement-learning">
<h2>UniformReplayBuffer Introduction of MindSpore Reinforcement Learning<a class="headerlink" href="#uniformreplaybuffer-introduction-of-mindspore-reinforcement-learning" title="Permalink to this headline"></a></h2>
<section id="creation-of-uniformreplaybuffer">
<h3>Creation of UniformReplayBuffer<a class="headerlink" href="#creation-of-uniformreplaybuffer" title="Permalink to this headline"></a></h3>
<p>MindSpore Reinforcement Learning provides a standard ReplayBuffer API. The user can use the ReplayBuffer created by the framework by means of a configuration file, shaped like the configuration file of <a class="reference external" href="https://github.com/mindspore-lab/mindrl/tree/master/mindspore_rl/algorithm/dqn/config.py">dqn</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;replay_buffer&#39;</span><span class="p">:</span>
    <span class="p">{</span><span class="s1">&#39;number&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
     <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">UniformReplayBuffer</span><span class="p">,</span>
     <span class="s1">&#39;capacity&#39;</span><span class="p">:</span> <span class="mi">100000</span><span class="p">,</span>
     <span class="s1">&#39;data_shape&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="mi">4</span><span class="p">,),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,)],</span>
     <span class="s1">&#39;data_type&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">foat32</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span>
     <span class="s1">&#39;sample_size&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">}</span>
</pre></div>
</div>
<p>Alternatively, users can use the interfaces directly to create the required data structures:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_rl.core.uniform_replay_buffer</span> <span class="kn">import</span> <span class="n">UniformReplayBuffer</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="n">sample_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">capacity</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">shapes</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">4</span><span class="p">,),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,)]</span>
<span class="n">types</span> <span class="o">=</span> <span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">]</span>
<span class="n">replaybuffer</span> <span class="o">=</span> <span class="n">UniformReplayBuffer</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,</span> <span class="n">capacity</span><span class="p">,</span> <span class="n">shapes</span><span class="p">,</span> <span class="n">types</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="using-the-created-uniformreplaybuffer">
<h3>Using the Created UniformReplayBuffer<a class="headerlink" href="#using-the-created-uniformreplaybuffer" title="Permalink to this headline"></a></h3>
<p>Take <a class="reference external" href="https://github.com/mindspore-lab/mindrl/tree/master/mindspore_rl/core/uniform_replay_buffer.py">UniformReplayBuffer</a> created in the form of an API to perform data manipulation as an example:</p>
<ul class="simple">
<li><p>Insert operation</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">state</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">action</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">reward</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">new_state</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">replaybuffer</span><span class="o">.</span><span class="n">insert</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">new_state</span><span class="p">])</span>
<span class="n">replaybuffer</span><span class="o">.</span><span class="n">insert</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">new_state</span><span class="p">])</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Search operation</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span> <span class="o">=</span> <span class="n">replaybuffer</span><span class="o">.</span><span class="n">get_item</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Sample operation</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">replaybuffer</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Reset operation</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">replaybuffer</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The size of the current buffer used</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">size</span> <span class="o">=</span> <span class="n">replaybuffer</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Determine if the current buffer is full</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">replaybuffer</span><span class="o">.</span><span class="n">full</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Full use of this buffer.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="dqn.html" class="btn btn-neutral float-left" title="Deep Q Learning (DQN) with MindSpore Reinforcement" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="environment.html" class="btn btn-neutral float-right" title="Reinforcement Learning Environment Access" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>