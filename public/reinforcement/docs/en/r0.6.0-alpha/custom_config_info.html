

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>MindSpore RL Configuration Instruction &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Deep Q Learning (DQN) with MindSpore Reinforcement" href="dqn.html" />
    <link rel="prev" title="MindSpore Reinforcement Installation" href="reinforcement_install.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="reinforcement_install.html">MindSpore Reinforcement Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">MindSpore RL Configuration Instruction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#configuration-details">Configuration Details</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#policy-configuration">Policy Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#environment-configuration">Environment Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#actor-configuration">Actor Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#replaybuffer-configuration">ReplayBuffer Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#learner-configuration">Learner Configuration</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dqn.html">Deep Q Learning (DQN) with MindSpore Reinforcement</a></li>
<li class="toctree-l1"><a class="reference internal" href="replaybuffer.html">ReplayBuffer Usage Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="environment.html">Reinforcement Learning Environment Access</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="reinforcement.html">mindspore_rl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">MindSpore Reinforcement Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>MindSpore RL Configuration Instruction</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/custom_config_info.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="mindspore-rl-configuration-instruction">
<h1>MindSpore RL Configuration Instruction<a class="headerlink" href="#mindspore-rl-configuration-instruction" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r2.0.0-alpha/docs/reinforcement/docs/source_en/custom_config_info.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0.0-alpha/resource/_static/logo_source_en.png"></a>
  </p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>Recent years, deep reinforcement learning is developing by leaps and bounds, new algorithms come out every year. To offer high scalability and reuable reinforcement framework, MindSpore RL separates an algorithm into several parts, such as Actor, Learner, Policy, Environment, ReplayBuffer, etc. Moreover, due to the complexity of deep reinforcement learning algorithm, its performance is largely influenced by different hyper-parameters. MindSpore RL provides centeral configuration API, which decouples the algorithm from deployment and execution considerations to help users adjust model and algorithm conveniently.</p>
<p>This instruction uses DQN algorithm as an example to introduce how to use this configuration API, and help users customize their algorithms.</p>
<p>You can obtain the code of DQN algorithm from <a class="reference external" href="https://gitee.com/mindspore/reinforcement/tree/r0.6.0-alpha/example/dqn">https://gitee.com/mindspore/reinforcement/tree/r0.6.0-alpha/example/dqn</a>.</p>
</section>
<section id="configuration-details">
<h2>Configuration Details<a class="headerlink" href="#configuration-details" title="Permalink to this headline"></a></h2>
<p>MindSpore RL uses <code class="docutils literal notranslate"><span class="pre">algorithm_config</span></code> to define each algorithm component and corresponding hyper-parameters. <code class="docutils literal notranslate"><span class="pre">algorithm_config</span></code> is a Python dictionary, which describes actor, learner, policy, collect_environment, eval_environment and replay buffer respectively. Framework can arrange the execution and deployment, which means that user only needs to focus on the algorithm design.</p>
<p>The following code defines a set of algorithm configurations and uses <code class="docutils literal notranslate"><span class="pre">algorithm_config</span></code> to create a <code class="docutils literal notranslate"><span class="pre">Session</span></code>. <code class="docutils literal notranslate"><span class="pre">Session</span></code> is responsible for allocating resources and executing computational graph compilation and execution.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_rl.mindspore_rl</span> <span class="kn">import</span> <span class="n">Session</span>
<span class="n">algorithm_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;actor&#39;</span><span class="p">:</span> <span class="p">{</span><span class="o">...</span><span class="p">},</span>
    <span class="s1">&#39;learner&#39;</span><span class="p">:</span> <span class="p">{</span><span class="o">...</span><span class="p">},</span>
    <span class="s1">&#39;policy_and_network&#39;</span><span class="p">:</span> <span class="p">{</span><span class="o">...</span><span class="p">},</span>
    <span class="s1">&#39;collect_environment&#39;</span><span class="p">:</span> <span class="p">{</span><span class="o">...</span><span class="p">},</span>
    <span class="s1">&#39;eval_environment&#39;</span><span class="p">:</span> <span class="p">{</span><span class="o">...</span><span class="p">},</span>
    <span class="s1">&#39;replay_buffer&#39;</span><span class="p">:</span> <span class="p">{</span><span class="o">...</span><span class="p">}</span>
<span class="p">}</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">Session</span><span class="p">(</span><span class="n">algorithm_config</span><span class="p">)</span>
<span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>Each parameter and their instruction in algorithm_config will be described below.</p>
<section id="policy-configuration">
<h3>Policy Configuration<a class="headerlink" href="#policy-configuration" title="Permalink to this headline"></a></h3>
<p>Policy is usually used to determine the behaviour (or action) that agent will execute in the next step, it takes <code class="docutils literal notranslate"><span class="pre">type</span></code> and <code class="docutils literal notranslate"><span class="pre">params</span></code> as the subitems.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">type</span></code> : specify the name of Policy, Actor determines the action through Policy. In deep reinforcement learning, Policy usually uses deep neural network to extract the feature of environment, and outputs the action in the next step.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">params</span></code> : specify the parameter that used during creating the instance of Policy. One thing should be noticed is that <code class="docutils literal notranslate"><span class="pre">type</span></code> and <code class="docutils literal notranslate"><span class="pre">params</span></code> need to be matched.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dqn.src.dqn</span> <span class="kn">import</span> <span class="n">DQNPolicy</span>

<span class="n">policy_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;epsi_high&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>        <span class="c1"># epsi_high/epsi_low/decay control the proportion of exploitation and exploration</span>
    <span class="s1">&#39;epsi_low&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>         <span class="c1"># epsi_high：the highest probability of exploration，epsi_low：the lowest probability of exploration，</span>
    <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>            <span class="c1"># decay：the step decay</span>
    <span class="s1">&#39;state_space_dim&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>    <span class="c1"># the dimension of state space，0 means that it will read from the environment automatically</span>
    <span class="s1">&#39;action_space_dim&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>   <span class="c1"># the dimension of action space，0 means that it will read from the environment automatically</span>
    <span class="s1">&#39;hidden_size&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>      <span class="c1"># the dimension of hidden layer</span>
<span class="p">}</span>

<span class="n">algorithm_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="s1">&#39;policy_and_network&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">DQNPolicy</span><span class="p">,</span>
        <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">policy_params</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="o">...</span>
<span class="p">}</span>
</pre></div>
</div>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>key</p></th>
<th class="text-center head"><p>Type</p></th>
<th class="text-center head"><p>Range</p></th>
<th class="text-center head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>type</p></td>
<td class="text-center"><p>Class</p></td>
<td class="text-center"><p>The user-defined class</p></td>
<td class="text-center"><p>This type is the same name as user-defined class</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>params(optional)</p></td>
<td class="text-center"><p>Dictionary</p></td>
<td class="text-center"><p>Any value with key value format or None</p></td>
<td class="text-center"><p>Customized parameter, user can input any value with key value format</p></td>
</tr>
</tbody>
</table>
</section>
<section id="environment-configuration">
<h3>Environment Configuration<a class="headerlink" href="#environment-configuration" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">collect_environment</span></code> and <code class="docutils literal notranslate"><span class="pre">eval_environment</span></code> are used to collect experience during interaction with environment and evaluate model after training respectively. <code class="docutils literal notranslate"><span class="pre">number</span></code>,  <code class="docutils literal notranslate"><span class="pre">type</span></code> and <code class="docutils literal notranslate"><span class="pre">params</span></code> need to be provided to create their instances.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">number</span></code>: number of environment used in the algorithm.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">type</span></code> : specify the name of environment, which could be either environment from MindSpore RL, such as <code class="docutils literal notranslate"><span class="pre">GymEnvironment</span></code> or user defined environment.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">params</span></code> : specify the parameter that used during creating the instance of environment. One thing should be noticed is that <code class="docutils literal notranslate"><span class="pre">type</span></code> and <code class="docutils literal notranslate"><span class="pre">params</span></code> need to be matched.</p></li>
</ul>
<p>The following example defines the configuration of environment. Framework will create a<code class="docutils literal notranslate"><span class="pre">CartPole-v0</span></code> environment like <code class="docutils literal notranslate"><span class="pre">Environment(name='CartPole-v0')</span></code> . The configuration of <code class="docutils literal notranslate"><span class="pre">collect_environment</span></code> and <code class="docutils literal notranslate"><span class="pre">eval_environment</span></code> are the same.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_rl.environment</span> <span class="kn">import</span> <span class="n">GymEnvironment</span>
<span class="n">collect_env_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;CartPole-v0&#39;</span><span class="p">}</span>
<span class="n">eval_env_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;CartPole-v0&#39;</span><span class="p">}</span>
<span class="n">algorithm_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="s1">&#39;collect_environment&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">GymEnvironment</span><span class="p">,</span>            <span class="c1"># the class name of environment</span>
        <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">collect_env_params</span>       <span class="c1"># parameter of environment</span>
    <span class="p">},</span>
    <span class="s1">&#39;eval_environment&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;number&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">GymEnvironment</span><span class="p">,</span>            <span class="c1"># the class name of environment</span>
        <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">eval_env_params</span>          <span class="c1"># parameter of environment</span>
    <span class="p">},</span>
    <span class="o">...</span>
<span class="p">}</span>
</pre></div>
</div>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>key</p></th>
<th class="text-center head"><p>Type</p></th>
<th class="text-center head"><p>Range</p></th>
<th class="text-center head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>number (optional)</p></td>
<td class="text-center"><p>Integer</p></td>
<td class="text-center"><p>[1, +∞)</p></td>
<td class="text-center"><p>When user fills the number of environment, number must be larger than 0. When user does not fill it, framework will not wrap environment by  <code class="docutils literal notranslate"><span class="pre">MultiEnvironmentWrapper</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>num_parallel(optional)</p></td>
<td class="text-center"><p>Integer</p></td>
<td class="text-center"><p>[1, number]</p></td>
<td class="text-center"><p>If user does not fill it, the environment will run in parallel by default. User can fill num_parallel: 1 to turn off the parallel environment, or enter their own parallel configuration</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>type</p></td>
<td class="text-center"><p>Class</p></td>
<td class="text-center"><p>The subclass of environment that is user-defined and implemented</p></td>
<td class="text-center"><p>The class name of environment</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>params</p></td>
<td class="text-center"><p>Dictionary</p></td>
<td class="text-center"><p>Any value with key value format or None</p></td>
<td class="text-center"><p>Customized parameter, user can input any value with key value format</p></td>
</tr>
</tbody>
</table>
</section>
<section id="actor-configuration">
<h3>Actor Configuration<a class="headerlink" href="#actor-configuration" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Actor</span></code> is charge of interacting with environment. Generally, <code class="docutils literal notranslate"><span class="pre">Actor</span></code> interacts with <code class="docutils literal notranslate"><span class="pre">Env</span></code> through <code class="docutils literal notranslate"><span class="pre">Policy</span></code>. Some algorithms will store the experience which obtained during the interaction into <code class="docutils literal notranslate"><span class="pre">ReplayBuffer</span></code>. Therefore, <code class="docutils literal notranslate"><span class="pre">Actor</span></code> will take <code class="docutils literal notranslate"><span class="pre">Policy</span></code> , <code class="docutils literal notranslate"><span class="pre">Environment</span></code> and <code class="docutils literal notranslate"><span class="pre">ReplayBuffer</span></code>. In Actor configuration, <code class="docutils literal notranslate"><span class="pre">policies</span></code>  and <code class="docutils literal notranslate"><span class="pre">networks</span></code> need to specify the name of member variable in <code class="docutils literal notranslate"><span class="pre">Policy</span></code>.</p>
<p>The following code defines the configuration of  <code class="docutils literal notranslate"><span class="pre">DQNActor</span></code> . Framework will create the instance of Actor like <code class="docutils literal notranslate"><span class="pre">DQNActor(algorithm_config['actor'])</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">algorithm_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="s1">&#39;actor&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;number&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>                                                        <span class="c1"># the number of Actor</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">DQNActor</span><span class="p">,</span>                                                   <span class="c1"># the class name of Actor</span>
        <span class="s1">&#39;policies&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;init_policy&#39;</span><span class="p">,</span> <span class="s1">&#39;collect_policy&#39;</span><span class="p">,</span> <span class="s1">&#39;eval_policy&#39;</span><span class="p">],</span>       <span class="c1"># Take the policies that called init_policy, collect_policy and eval_policy in Policy class as input to create the instance of actor</span>
        <span class="s1">&#39;share_env&#39;</span><span class="p">:</span> <span class="kc">True</span>                                                   <span class="c1"># Whether the environment is shared by each actor</span>
    <span class="p">}</span>
    <span class="o">...</span>
<span class="p">}</span>
</pre></div>
</div>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>key</p></th>
<th class="text-center head"><p>Type</p></th>
<th class="text-center head"><p>Range</p></th>
<th class="text-center head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>number</p></td>
<td class="text-center"><p>Integer</p></td>
<td class="text-center"><p>[1, +∞)</p></td>
<td class="text-center"><p>Number of Actor, currently only support 1</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>type</p></td>
<td class="text-center"><p>Class</p></td>
<td class="text-center"><p>The subclass of actor that is user-defined and implemented</p></td>
<td class="text-center"><p>This type is the same name as the subclass of actor that is user-defined and implemented</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>params(optional)</p></td>
<td class="text-center"><p>Dictionary</p></td>
<td class="text-center"><p>Any value with key value format or None</p></td>
<td class="text-center"><p>Customized parameter, user can input any value with key value format</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>policies</p></td>
<td class="text-center"><p>List of String</p></td>
<td class="text-center"><p>Same variable name as the user-defined policies</p></td>
<td class="text-center"><p>Every string in list must correspond one-to-one with the name of the policies initialized in the user-defined policy class</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>networks(optional)</p></td>
<td class="text-center"><p>List of String</p></td>
<td class="text-center"><p>Same variable name as the user-defined networks</p></td>
<td class="text-center"><p>Every string in list must correspond one-to-one with the name of the networks initialized in the user-defined policy class</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>share_env(optional)</p></td>
<td class="text-center"><p>Boolean</p></td>
<td class="text-center"><p>True or False</p></td>
<td class="text-center"><p>Default: True, means every actor will share one <code class="docutils literal notranslate"><span class="pre">collect_environment</span></code>. Else, we will create an instance of <code class="docutils literal notranslate"><span class="pre">collect_environment</span></code> for each actor.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="replaybuffer-configuration">
<h3>ReplayBuffer Configuration<a class="headerlink" href="#replaybuffer-configuration" title="Permalink to this headline"></a></h3>
<p>For part of algorithms, <code class="docutils literal notranslate"><span class="pre">ReplayBuffer</span></code> is used to store experience which is obtained by interaction between actor and environment. Then experience will be used to train the network.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">algorithm_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="s1">&#39;replay_buffer&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;number&#39;</span><span class="p">:</span> <span class="mi">1</span>
                      <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">ReplayBuffer</span><span class="p">,</span>
                      <span class="s1">&#39;capacity&#39;</span><span class="p">:</span> <span class="mi">100000</span><span class="p">,</span>                                            <span class="c1"># the capacity of ReplayBuffer</span>
                      <span class="s1">&#39;sample_size&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>                                             <span class="c1"># sample Batch Size</span>
                      <span class="s1">&#39;data_shape&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="mi">4</span><span class="p">,),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,)],</span>                        <span class="c1"># the dimension info of ReplayBuffer</span>
                      <span class="s1">&#39;data_type&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">]},</span>  <span class="c1"># the data type of ReplayBuffer</span>
<span class="p">}</span>
</pre></div>
</div>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>key</p></th>
<th class="text-center head"><p>Type</p></th>
<th class="text-center head"><p>Range</p></th>
<th class="text-center head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>number</p></td>
<td class="text-center"><p>Integer</p></td>
<td class="text-center"><p>[1, +∞)</p></td>
<td class="text-center"><p>Number of replaybuffer created</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>type</p></td>
<td class="text-center"><p>Class</p></td>
<td class="text-center"><p>User-defined or provided ReplayBuffer class</p></td>
<td class="text-center"><p>This type is the same name as the user-defined or provided ReplayBuffer class</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>capacity</p></td>
<td class="text-center"><p>Integer</p></td>
<td class="text-center"><p>[0, +∞)</p></td>
<td class="text-center"><p>The capacity of ReplayBuffer</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>data_shape</p></td>
<td class="text-center"><p>List of Integer Tuple</p></td>
<td class="text-center"><p>[0, +∞)</p></td>
<td class="text-center"><p>The first number of tuple must equal to number of environment</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>data_type</p></td>
<td class="text-center"><p>List of mindspore data type</p></td>
<td class="text-center"><p>Belongs to MindSpore data type</p></td>
<td class="text-center"><p>The length of this list must equal to the length of data_shape</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>sample_size(optional)</p></td>
<td class="text-center"><p>Integer</p></td>
<td class="text-center"><p>[0, capacity]</p></td>
<td class="text-center"><p>The maximum value is the capacity of replay buffer. Default 1</p></td>
</tr>
</tbody>
</table>
</section>
<section id="learner-configuration">
<h3>Learner Configuration<a class="headerlink" href="#learner-configuration" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Learner</span></code> is used to update the weights of neural network according to experience. <code class="docutils literal notranslate"><span class="pre">Learner</span></code> holds the DNN which is defined in <code class="docutils literal notranslate"><span class="pre">Policy</span></code> (the name of member variable in <code class="docutils literal notranslate"><span class="pre">Policy</span></code> match with the contains in <code class="docutils literal notranslate"><span class="pre">networks</span></code>), which is used to calculate the loss and update the weights of neural network.</p>
<p>The following code defines the configuration of <code class="docutils literal notranslate"><span class="pre">DQNLearner</span></code> . Framework will create the instance of Learner like <code class="docutils literal notranslate"><span class="pre">DQNLearner(algorithm_config['learner'])</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dqn.src.dqn</span> <span class="kn">import</span> <span class="n">DQNLearner</span>
<span class="n">learner_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span>
                  <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>                          <span class="c1"># learning rate</span>
                 <span class="p">}</span>  
<span class="n">algorithm_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="s1">&#39;learner&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;number&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>                                      <span class="c1"># the number of Learner</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">DQNLearner</span><span class="p">,</span>                               <span class="c1"># the class name of Learner</span>
        <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">learner_params</span><span class="p">,</span>                         <span class="c1"># the decay rate</span>
        <span class="s1">&#39;networks&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;policy_network&#39;</span><span class="p">,</span> <span class="s1">&#39;target_network&#39;</span><span class="p">]</span>  <span class="c1"># Learner takes the policy_network and target_network from DQNPolicy as input argument to update the network</span>
    <span class="p">},</span>
    <span class="o">...</span>
<span class="p">}</span>
</pre></div>
</div>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>key</p></th>
<th class="text-center head"><p>Type</p></th>
<th class="text-center head"><p>Range</p></th>
<th class="text-center head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>number</p></td>
<td class="text-center"><p>Integer</p></td>
<td class="text-center"><p>[1, +∞)</p></td>
<td class="text-center"><p>Number of Actor, currently only support 1</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>type</p></td>
<td class="text-center"><p>Class</p></td>
<td class="text-center"><p>The user-defined and implement subclass of learner</p></td>
<td class="text-center"><p>This type is the same name as the subclass of learner that is user-defined and implemented</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>params</p></td>
<td class="text-center"><p>Dictionary</p></td>
<td class="text-center"><p>Any value with key value format or None</p></td>
<td class="text-center"><p>Customized parameter, user can input any value with key value format.</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>networks</p></td>
<td class="text-center"><p>List of String</p></td>
<td class="text-center"><p>Same variable name as the user-defined network</p></td>
<td class="text-center"><p>Every string in list must match with networks’ name which is user initialized in  defined policy class</p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="reinforcement_install.html" class="btn btn-neutral float-left" title="MindSpore Reinforcement Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="dqn.html" class="btn btn-neutral float-right" title="Deep Q Learning (DQN) with MindSpore Reinforcement" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>