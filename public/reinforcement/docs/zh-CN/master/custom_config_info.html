<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>强化学习配置说明 &mdash; MindSpore master 文档</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script src="_static/translations.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="next" title="使用MindSpore Reinforcement实现深度Q学习（DQN）" href="dqn.html" />
    <link rel="prev" title="安装MindSpore Reinforcement" href="reinforcement_install.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="reinforcement_install.html">安装MindSpore Reinforcement</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">使用指南</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">强化学习配置说明</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#概述">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#算法相关参数配置">算法相关参数配置</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#policy配置参数">Policy配置参数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#environment配置参数">Environment配置参数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#actor配置参数">Actor配置参数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#replaybuffer配置参数">ReplayBuffer配置参数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#learner配置参数">Learner配置参数</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dqn.html">使用MindSpore Reinforcement实现深度Q学习（DQN）</a></li>
<li class="toctree-l1"><a class="reference internal" href="replaybuffer.html">ReplayBuffer 使用说明</a></li>
<li class="toctree-l1"><a class="reference internal" href="environment.html">强化学习环境接入</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="reinforcement.html">mindspore_rl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>强化学习配置说明</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/custom_config_info.md.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="强化学习配置说明">
<h1>强化学习配置说明<a class="headerlink" href="#强化学习配置说明" title="永久链接至标题"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/reinforcement/docs/source_zh_cn/custom_config_info.md"><img alt="查看源文件" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.svg" /></a>
  </p>
<section id="概述">
<h2>概述<a class="headerlink" href="#概述" title="永久链接至标题"></a></h2>
<p>深度强化学习作为当前发展最快的方向之一，新算法层出不穷。MindSpore Reinforcement将强化学习算法建模为Actor、Learner、Policy、Environment、ReplayBuffer等对象，从而提供易扩展、高重用的强化学习框架。与此同时，深度强化学习算法相对复杂，网络训练效果受到众多参数影响，MindSpore Reinforcement提供了集中的参数配置接口，将算法实现和部署细节进行分离，同时便于用户快速调整模型算法。</p>
<p>本文以DQN算法为例介绍如何使用MindSpore Reinforcement算法和训练参数配置接口，帮助用户快速定制和调整强化学习算法。</p>
<p>您可以从<a class="reference external" href="https://github.com/mindspore-lab/mindrl/tree/master/example/dqn">https://github.com/mindspore-lab/mindrl/tree/master/example/dqn</a>获取DQN算法代码。</p>
</section>
<section id="算法相关参数配置">
<h2>算法相关参数配置<a class="headerlink" href="#算法相关参数配置" title="永久链接至标题"></a></h2>
<p>MindSpore-RL使用<code class="docutils literal notranslate"><span class="pre">algorithm_config</span></code>定义逻辑组件和相应的超参配置。<code class="docutils literal notranslate"><span class="pre">algorithm_config</span></code>是一个Python字典，分别描述actor、learner、policy_and_network、collect_environment、eval_environment和replaybuffer。框架可以基于配置执行算法，用户仅需聚焦算法设计。</p>
<p>下述代码定义了一组算法配置，并使用algorithm_config创建<code class="docutils literal notranslate"><span class="pre">Session</span></code>，<code class="docutils literal notranslate"><span class="pre">Session</span></code>负责分配资源并执行计算图编译和执行。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_rl.mindspore_rl</span> <span class="kn">import</span> <span class="n">Session</span>
<span class="n">algorithm_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;actor&#39;</span><span class="p">:</span> <span class="p">{</span><span class="o">...</span><span class="p">},</span>
    <span class="s1">&#39;learner&#39;</span><span class="p">:</span> <span class="p">{</span><span class="o">...</span><span class="p">},</span>
    <span class="s1">&#39;policy_and_network&#39;</span><span class="p">:</span> <span class="p">{</span><span class="o">...</span><span class="p">},</span>
    <span class="s1">&#39;collect_environment&#39;</span><span class="p">:</span> <span class="p">{</span><span class="o">...</span><span class="p">},</span>
    <span class="s1">&#39;eval_environment&#39;</span><span class="p">:</span> <span class="p">{</span><span class="o">...</span><span class="p">},</span>
    <span class="s1">&#39;replay_buffer&#39;</span><span class="p">:</span> <span class="p">{</span><span class="o">...</span><span class="p">}</span>
<span class="p">}</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">Session</span><span class="p">(</span><span class="n">algorithm_config</span><span class="p">)</span>
<span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>下文将详细介绍algorithm_config中各个参数含义及使用方式。</p>
<section id="policy配置参数">
<h3>Policy配置参数<a class="headerlink" href="#policy配置参数" title="永久链接至标题"></a></h3>
<p>Policy通常用于智能体决策下一步需要执行的行为，算法中需要policy类型名<code class="docutils literal notranslate"><span class="pre">type</span></code>和参数<code class="docutils literal notranslate"><span class="pre">params</span></code>：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">type</span></code>：指定Policy的类型，Actor通过Policy决策应该采取的动作。在深度强化学习中，Policy通常采用深度神经网络提取环境特征，并输出下一步采取的动作。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">params</span></code>：指定实例化相应Policy的参数。这里需要注意的是，<code class="docutils literal notranslate"><span class="pre">params</span></code>和<code class="docutils literal notranslate"><span class="pre">type</span></code>需要匹配。</p></li>
</ul>
<p>以下样例中定义策略和参数配置，Policy是由用户定义的<code class="docutils literal notranslate"><span class="pre">DQNPolicy</span></code>，并指定了epsilon greedy衰减参数，学习率，网络模型隐层等参数，框架会采用<code class="docutils literal notranslate"><span class="pre">DQNPolicy(policy_params)</span></code>方式创建Policy对象。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dqn.src.dqn</span> <span class="kn">import</span> <span class="n">DQNPolicy</span>

<span class="n">policy_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;epsi_high&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>        <span class="c1"># epsi_high/epsi_low/decay共同控制探索-利用比例</span>
    <span class="s1">&#39;epsi_low&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>         <span class="c1"># epsi_high：最大探索比例，epsi_low：最低探索比例，decay：衰减步长</span>
    <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
    <span class="s1">&#39;state_space_dim&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>    <span class="c1"># 状态空间维度大小，0表示从外部环境中读取状态空间信息</span>
    <span class="s1">&#39;action_space_dim&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>   <span class="c1"># 动作空间维度大小，0表示从外部环境中获取动作空间信息</span>
    <span class="s1">&#39;hidden_size&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>      <span class="c1"># 隐层维度</span>
<span class="p">}</span>

<span class="n">algorithm_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="s1">&#39;policy_and_network&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">DQNPolicy</span><span class="p">,</span>
        <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">policy_params</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="o">...</span>
<span class="p">}</span>
</pre></div>
</div>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>键值</p></th>
<th class="text-center head"><p>类型</p></th>
<th class="text-center head"><p>范围</p></th>
<th class="text-center head"><p>说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>type</p></td>
<td class="text-center"><p>Class</p></td>
<td class="text-center"><p>用户定义的继承learner并实现虚函数的类</p></td>
<td class="text-center"><p>和用户定义的继承learner并实现虚函数的类名相同</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>params(可选)</p></td>
<td class="text-center"><p>Dictionary</p></td>
<td class="text-center"><p>任意key value形式的值或者None</p></td>
<td class="text-center"><p>自定义参数，用户可以通过key value的形式传入任何值</p></td>
</tr>
</tbody>
</table>
</section>
<section id="environment配置参数">
<h3>Environment配置参数<a class="headerlink" href="#environment配置参数" title="永久链接至标题"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">collect_environment</span></code>和<code class="docutils literal notranslate"><span class="pre">eval_environment</span></code>分别表示运行过程中收集数据的环境和用来评估模型的环境，算法中需要指定类型名<code class="docutils literal notranslate"><span class="pre">number</span></code>，<code class="docutils literal notranslate"><span class="pre">type</span></code>和参数<code class="docutils literal notranslate"><span class="pre">params</span></code>：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">number</span></code>：在算法中所需要的环境数量。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">type</span></code>：指定环境的类型名，这里可以是Reinforcement内置的环境，例如<code class="docutils literal notranslate"><span class="pre">Environment</span></code>，也可以是用户自定义的环境类型。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">params</span></code>：指定实例化相应外部环境的参数。需要注意的是，<code class="docutils literal notranslate"><span class="pre">params</span></code>和<code class="docutils literal notranslate"><span class="pre">type</span></code>需要匹配。</p></li>
</ul>
<p>以下样例中定义了外部环境配置，框架会采用<code class="docutils literal notranslate"><span class="pre">Environment(name='CartPole-v0')</span></code>方式创建<code class="docutils literal notranslate"><span class="pre">CartPole-v0</span></code>外部环境。<code class="docutils literal notranslate"><span class="pre">collect_environment</span></code>和<code class="docutils literal notranslate"><span class="pre">eval_environment</span></code>的配置参数是一样的。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_rl.environment</span> <span class="kn">import</span> <span class="n">GymEnvironment</span>
<span class="n">collect_env_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;CartPole-v0&#39;</span><span class="p">}</span>
<span class="n">eval_env_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;CartPole-v0&#39;</span><span class="p">}</span>
<span class="n">algorithm_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="s1">&#39;collect_environment&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;number&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">GymEnvironment</span><span class="p">,</span>            <span class="c1"># 外部环境类名</span>
        <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">collect_env_params</span>       <span class="c1"># 环境参数</span>
    <span class="p">},</span>
    <span class="s1">&#39;eval_environment&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;number&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">GymEnvironment</span><span class="p">,</span>            <span class="c1"># 外部环境类名</span>
        <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">eval_env_params</span>          <span class="c1"># 环境参数</span>
    <span class="p">},</span>
    <span class="o">...</span>
<span class="p">}</span>
</pre></div>
</div>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>键值</p></th>
<th class="text-center head"><p>类型</p></th>
<th class="text-center head"><p>范围</p></th>
<th class="text-center head"><p>说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>number(可选)</p></td>
<td class="text-center"><p>Integer</p></td>
<td class="text-center"><p>[1, +∞)</p></td>
<td class="text-center"><p>当用户选择填写number这项时，填入的环境数量至少为1个。当用户不选择填入number这项时，框架会直接创建环境实例而不会调用<code class="docutils literal notranslate"><span class="pre">MultiEnvironmentWrapper</span></code>类来包装环境</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>num_parallel(可选)</p></td>
<td class="text-center"><p>Integer</p></td>
<td class="text-center"><p>[1, number]</p></td>
<td class="text-center"><p>不填时默认开启环境并行。用户可通过填写num_parallel: 1来关闭环境并行，或者配置自己需要的并行参数。</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>type</p></td>
<td class="text-center"><p>Class</p></td>
<td class="text-center"><p>Environment类的子类</p></td>
<td class="text-center"><p>外部环境类名</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>params(可选)</p></td>
<td class="text-center"><p>Dictionary</p></td>
<td class="text-center"><p>任意key value形式的值或者None</p></td>
<td class="text-center"><p>自定义参数，用户可以通过key value的形式传入任何值</p></td>
</tr>
</tbody>
</table>
</section>
<section id="actor配置参数">
<h3>Actor配置参数<a class="headerlink" href="#actor配置参数" title="永久链接至标题"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Actor</span></code>负责与外部环境交互。通常<code class="docutils literal notranslate"><span class="pre">Actor</span></code>需要基于<code class="docutils literal notranslate"><span class="pre">Policy</span></code> 与<code class="docutils literal notranslate"><span class="pre">Env</span></code>交互，部分算法中还会将交互得到的经验存入<code class="docutils literal notranslate"><span class="pre">ReplayBuffer</span></code>中，因此<code class="docutils literal notranslate"><span class="pre">Actor</span></code>会持有<code class="docutils literal notranslate"><span class="pre">Policy</span></code>和<code class="docutils literal notranslate"><span class="pre">Environment</span></code>，并且按需创建<code class="docutils literal notranslate"><span class="pre">ReplayBuffer</span></code>。<code class="docutils literal notranslate"><span class="pre">Actor配置参数</span></code>中，<code class="docutils literal notranslate"><span class="pre">policies/networks</span></code>指定<code class="docutils literal notranslate"><span class="pre">Policy</span></code>中的成员对象名称。</p>
<p>以下代码中定义<code class="docutils literal notranslate"><span class="pre">DQNActor</span></code>配置，框架会采用<code class="docutils literal notranslate"><span class="pre">DQNActor(algorithm_config['actor'])</span></code>方式创建Actor。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">algorithm_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="s1">&#39;actor&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;number&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>                                                        <span class="c1"># Actor个数</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">DQNActor</span><span class="p">,</span>                                                   <span class="c1"># Actor类名</span>
        <span class="s1">&#39;policies&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;init_policy&#39;</span><span class="p">,</span> <span class="s1">&#39;collect_policy&#39;</span><span class="p">,</span> <span class="s1">&#39;eval_policy&#39;</span><span class="p">],</span>       <span class="c1"># 从Policy中提取名为init_policy/collect_policy/eval_policy成员对象，用于构建Actor</span>
        <span class="s1">&#39;share_env&#39;</span><span class="p">:</span> <span class="kc">True</span>                                                   <span class="c1"># 每个actor是否共享环境</span>
    <span class="p">}</span>
    <span class="o">...</span>
<span class="p">}</span>
</pre></div>
</div>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>键值</p></th>
<th class="text-center head"><p>类型</p></th>
<th class="text-center head"><p>范围</p></th>
<th class="text-center head"><p>说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>number</p></td>
<td class="text-center"><p>Integer</p></td>
<td class="text-center"><p>[1, +∞)</p></td>
<td class="text-center"><p>目前actor数量暂时不支持1以外的数值</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>type</p></td>
<td class="text-center"><p>Class</p></td>
<td class="text-center"><p>用户定义的继承actor并实现虚函数的类</p></td>
<td class="text-center"><p>和用户定义的继承actor并实现虚函数的类名相同</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>params(可选)</p></td>
<td class="text-center"><p>Dictionary</p></td>
<td class="text-center"><p>任意key value形式的值或者None</p></td>
<td class="text-center"><p>自定义参数，用户可以通过key value的形式传入任何值</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>policies</p></td>
<td class="text-center"><p>List of String</p></td>
<td class="text-center"><p>和用户定义的策略变量名相同</p></td>
<td class="text-center"><p>列表中的所有String都应该和用户定义的策略类中初始化的策略变量名一一对应</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>networks(可选)</p></td>
<td class="text-center"><p>List of String</p></td>
<td class="text-center"><p>和用户定义的网络变量名相同</p></td>
<td class="text-center"><p>列表中的所有String都应该和用户定义的策略类中初始化的网络变量名一一对应</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>share_env(可选)</p></td>
<td class="text-center"><p>Boolean</p></td>
<td class="text-center"><p>True 或 False</p></td>
<td class="text-center"><p>默认值为True, 即各个actor共享一个环境。如果为False, 则单独为每个actor创建一个collect环境实例</p></td>
</tr>
</tbody>
</table>
</section>
<section id="replaybuffer配置参数">
<h3>ReplayBuffer配置参数<a class="headerlink" href="#replaybuffer配置参数" title="永久链接至标题"></a></h3>
<p>在部分算法中，<code class="docutils literal notranslate"><span class="pre">ReplayBuffer</span></code>用于储存Actor和环境交互的经验。之后会从<code class="docutils literal notranslate"><span class="pre">ReplayBuffer</span></code>中取出数据，用于网络训练。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_rl.core.replay_buffer</span> <span class="kn">import</span> <span class="n">ReplayBuffer</span>
<span class="n">algorithm_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="s1">&#39;replay_buffer&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;number&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                      <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">ReplayBuffer</span><span class="p">,</span>
                      <span class="s1">&#39;capacity&#39;</span><span class="p">:</span> <span class="mi">100000</span><span class="p">,</span>                                           <span class="c1"># ReplayBuffer容量</span>
                      <span class="s1">&#39;sample_size&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>                                            <span class="c1"># 采样Batch Size</span>
                      <span class="s1">&#39;data_shape&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="mi">4</span><span class="p">,),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,)],</span>                       <span class="c1"># ReplayBuffer的维度信息</span>
                      <span class="s1">&#39;data_type&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">]},</span> <span class="c1"># ReplayBuffer数据类型</span>
<span class="p">}</span>
</pre></div>
</div>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>键值</p></th>
<th class="text-center head"><p>类型</p></th>
<th class="text-center head"><p>范围</p></th>
<th class="text-center head"><p>说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>number</p></td>
<td class="text-center"><p>Integer</p></td>
<td class="text-center"><p>[1, +∞)</p></td>
<td class="text-center"><p>需要的Buffer数量</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>type</p></td>
<td class="text-center"><p>Class</p></td>
<td class="text-center"><p>用户定义或者框架提供的ReplayBuffer类</p></td>
<td class="text-center"><p>用户定义或者框架提供的ReplayBuffer的类名相同</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>capacity</p></td>
<td class="text-center"><p>Integer</p></td>
<td class="text-center"><p>[0, +∞)</p></td>
<td class="text-center"><p>ReplayBuffer容量</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>data_shape</p></td>
<td class="text-center"><p>List of Integer Tuple</p></td>
<td class="text-center"><p>[0, +∞)</p></td>
<td class="text-center"><p>Tuple中的第一个值需要和环境数量相等，如是单环境则不填</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>data_type</p></td>
<td class="text-center"><p>List of mindspore data type</p></td>
<td class="text-center"><p>需要是MindSpore的数据类型</p></td>
<td class="text-center"><p>data_type的长度和data_shape的长度相同</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>sample_size(可选)</p></td>
<td class="text-center"><p>Integer</p></td>
<td class="text-center"><p>[0, capacity]</p></td>
<td class="text-center"><p>值必须小于capacity。不填时，默认为1</p></td>
</tr>
</tbody>
</table>
</section>
<section id="learner配置参数">
<h3>Learner配置参数<a class="headerlink" href="#learner配置参数" title="永久链接至标题"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Learner</span></code>负责基于历史经验对网络权重进行更新。<code class="docutils literal notranslate"><span class="pre">Learner</span></code>中持有<code class="docutils literal notranslate"><span class="pre">Policy</span></code>中定义的DNN网络（由<code class="docutils literal notranslate"><span class="pre">networks</span></code>指定<code class="docutils literal notranslate"><span class="pre">Policy</span></code>的成员对象名称），用于损失函数计算和网络权重更新。</p>
<p>以下代码中定义<code class="docutils literal notranslate"><span class="pre">DQNLearner</span></code>配置，框架会采用<code class="docutils literal notranslate"><span class="pre">DQNLearner(algorithm_config['learner'])</span></code>方式创建Learner。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dqn.src.dqn</span> <span class="kn">import</span> <span class="n">DQNLearner</span>
<span class="n">learner_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span>
                  <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>             <span class="c1"># 学习率</span>
                 <span class="p">}</span>  
<span class="n">algorithm_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="s1">&#39;learner&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;number&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>                                      <span class="c1"># Learner个数</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">DQNLearner</span><span class="p">,</span>                               <span class="c1"># Learner类名</span>
        <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">learner_params</span><span class="p">,</span>                         <span class="c1"># Learner 需要的参数</span>
        <span class="s1">&#39;networks&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;policy_network&#39;</span><span class="p">,</span> <span class="s1">&#39;target_network&#39;</span><span class="p">]</span>  <span class="c1"># Learner从Policy中提取名为target_net/policy_network成员对象，用于更新</span>
    <span class="p">},</span>
    <span class="o">...</span>
<span class="p">}</span>
</pre></div>
</div>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>键值</p></th>
<th class="text-center head"><p>类型</p></th>
<th class="text-center head"><p>范围</p></th>
<th class="text-center head"><p>说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>number</p></td>
<td class="text-center"><p>Integer</p></td>
<td class="text-center"><p>[1, +∞)</p></td>
<td class="text-center"><p>目前learner数量暂时不支持1以外的数值</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>type</p></td>
<td class="text-center"><p>Class</p></td>
<td class="text-center"><p>用户定义的继承learner并实现虚函数的类</p></td>
<td class="text-center"><p>和用户定义的继承learner并实现虚函数的类名相同</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>params(可选)</p></td>
<td class="text-center"><p>Dictionary</p></td>
<td class="text-center"><p>任意key value形式的值或者None</p></td>
<td class="text-center"><p>自定义参数，用户可以通过key value的形式传入任何值</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>networks</p></td>
<td class="text-center"><p>List of String</p></td>
<td class="text-center"><p>和定义的网络名变量相同</p></td>
<td class="text-center"><p>列表中的所有String都应该和用户定义的策略类中初始化的网络变量名一一对应</p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="reinforcement_install.html" class="btn btn-neutral float-left" title="安装MindSpore Reinforcement" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="dqn.html" class="btn btn-neutral float-right" title="使用MindSpore Reinforcement实现深度Q学习（DQN）" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2022, MindSpore.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>