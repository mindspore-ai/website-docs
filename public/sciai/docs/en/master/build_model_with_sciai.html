<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Building Neural Networks with SciAI &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script><script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="sciai.architecture" href="sciai.architecture.html" />
    <link rel="prev" title="Model Library" href="model_library.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">MindSpore SciAI Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Launching Instruction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="launch_with_scripts.html">Launching Model with Scripts</a></li>
<li class="toctree-l1"><a class="reference internal" href="launch_with_api.html">Launching Model with API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Library</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_library.html">Model Library</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorial</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Building Neural Networks with SciAI</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#model-building-basics">Model Building Basics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#setup-neural-networks">Setup Neural Networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loss-definition">Loss Definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-training-and-evaluation">Model Training and Evaluation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#model-building-extension">Model Building Extension</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#loss-definition-1">Loss Definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-training-and-evaluation-1">Model Training and Evaluation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="sciai.architecture.html">sciai.architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="sciai.common.html">sciai.common</a></li>
<li class="toctree-l1"><a class="reference internal" href="sciai.context.html">sciai.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="sciai.operators.html">sciai.operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="sciai.utils.html">sciai.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Building Neural Networks with SciAI</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/build_model_with_sciai.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="building-neural-networks-with-sciai">
<h1>Building Neural Networks with SciAI<a class="headerlink" href="#building-neural-networks-with-sciai" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/sciai/docs/source_en/build_model_with_sciai.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.svg" /></a>  </p>
<p>SciAI base framework consists of several modules covering network setup, network training, validation and auxiliary functions.</p>
<p>The following examples indicates the fundamental processes in using SciAI to build a neural network model.</p>
<blockquote>
<div><p>You can download the full sample code here:
<a class="reference external" href="https://gitee.com/mindspore/mindscience/tree/master/SciAI/tutorial">https://gitee.com/mindspore/mindscience/tree/master/SciAI/tutorial</a></p>
</div></blockquote>
<section id="model-building-basics">
<h2>Model Building Basics<a class="headerlink" href="#model-building-basics" title="Permalink to this headline"></a></h2>
<p>The principle of setting up a neural network in ScAI is the same as in <a class="reference external" href="https://www.mindspore.cn/tutorials/en/master/beginner/model.html">MindSpore</a>, but in SciAI it is much easier.</p>
<p>This chapter takes a Multi-Layer Percetron(MLP) as example, introduces how to train a network to solve the following equation.</p>
<div class="math notranslate nohighlight">
\[
f(x) = {x_1}^2 + sin(x_2)
\]</div>
<p>For the codes of this part, please refer to the <a class="reference external" href="https://gitee.com/mindspore/mindscience/blob/master/SciAI/tutorial/example_net.py">codes</a>.</p>
<section id="setup-neural-networks">
<h3>Setup Neural Networks<a class="headerlink" href="#setup-neural-networks" title="Permalink to this headline"></a></h3>
<p>The following code segment creates a multi-layer perceptron with 2-D input, 1-D output and two 5-D hidden layers.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sciai.architecture</span> <span class="kn">import</span> <span class="n">MLP</span>
<span class="kn">from</span> <span class="nn">sciai.common.initializer</span> <span class="kn">import</span> <span class="n">XavierTruncNormal</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">layers</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">XavierTruncNormal</span><span class="p">(),</span> <span class="n">bias_init</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">MLP</span></code> will use normal distribution to initialize the weights, and initialize bias with zeros by default. The activation function is <code class="docutils literal notranslate"><span class="pre">tanh</span></code> by default.</p>
<p>At meantime, <code class="docutils literal notranslate"><span class="pre">MLP</span></code> accepts various initialization method and all <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/mindspore.nn.html">activation functions</a> provided by MindSpore, as well as those designed for scientific computing.</p>
</section>
<section id="loss-definition">
<h3>Loss Definition<a class="headerlink" href="#loss-definition" title="Permalink to this headline"></a></h3>
<p>We define the loss function as a sub-class of <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/nn/mindspore.nn.Cell.html">Cell</a>, and calculate the loss in method <code class="docutils literal notranslate"><span class="pre">construct</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">sciai.architecture</span> <span class="kn">import</span> <span class="n">MSE</span>

<span class="k">class</span> <span class="nc">ExampleLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="n">MSE</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
        <span class="n">y_predict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">y_predict</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span>

<span class="n">net_loss</span> <span class="o">=</span> <span class="n">ExampleLoss</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</pre></div>
</div>
<p>The current loss predicted by <code class="docutils literal notranslate"><span class="pre">net</span></code> can be calculated by calling <code class="docutils literal notranslate"><span class="pre">net_loss</span></code> directly and taking the input <code class="docutils literal notranslate"><span class="pre">x</span></code> as the parameter with the true value <code class="docutils literal notranslate"><span class="pre">y_true</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]])</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">0.72942554</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;loss value: &quot;</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_true</span><span class="p">))</span>
<span class="c1"># expected output</span>
<span class="o">...</span>
<span class="n">loss</span> <span class="n">value</span><span class="p">:</span> <span class="mf">0.3026065</span>
</pre></div>
</div>
</section>
<section id="model-training-and-evaluation">
<h3>Model Training and Evaluation<a class="headerlink" href="#model-training-and-evaluation" title="Permalink to this headline"></a></h3>
<p>Then, by creating instance of trainer class provided by SciAI, we can start training with datasets.
In this case, we randomly sample the equation mentioned above to generate dataset <code class="docutils literal notranslate"><span class="pre">x_train</span></code> and <code class="docutils literal notranslate"><span class="pre">y_true</span></code> for training.</p>
<p>The code segment for training is given as follows, indicating several abilities of SciAI.
The trainer class <code class="docutils literal notranslate"><span class="pre">TrainCellWithCallBack</span></code> is similar to <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/nn/mindspore.nn.TrainOneStepCell.html">MindSpore.nn.TrainOneStepCell</a>,
which needs network <code class="docutils literal notranslate"><span class="pre">net_loss</span></code> and optimizer as parameters and provides callbacks for scientific computation.
Callbacks include printing loss values and time consumption during training and automatic <code class="docutils literal notranslate"><span class="pre">ckpt</span></code> files saving.
The following code wll print the <code class="docutils literal notranslate"><span class="pre">loss</span></code> and time consumption every 100 epochs and save the current model as <code class="docutils literal notranslate"><span class="pre">ckpt</span></code> file every 1000 epochs.
SciAI provides the tool <code class="docutils literal notranslate"><span class="pre">to_tensor</span></code>, which converts multiple numpy data to <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> conveniently.
Use <code class="docutils literal notranslate"><span class="pre">log_config</span></code> to specify the target directory for automatically saving the <code class="docutils literal notranslate"><span class="pre">TrainCellWithCallBack</span></code> callback printouts, as well as those printed by the user using <code class="docutils literal notranslate"><span class="pre">print_log</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">sciai.common</span> <span class="kn">import</span> <span class="n">TrainCellWithCallBack</span>
<span class="kn">from</span> <span class="nn">sciai.context.context</span> <span class="kn">import</span> <span class="n">init_project</span>
<span class="kn">from</span> <span class="nn">sciai.utils</span> <span class="kn">import</span> <span class="n">to_tensor</span><span class="p">,</span> <span class="n">print_log</span><span class="p">,</span> <span class="n">log_config</span>

<span class="c1"># Get the correct platform automatically and set to GRAPH_MODE by default.</span>
<span class="n">init_project</span><span class="p">()</span>
<span class="c1"># Auto log saving</span>
<span class="n">log_config</span><span class="p">(</span><span class="s2">&quot;./logs&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The function to be learned to&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net_loss</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">TrainCellWithCallBack</span><span class="p">(</span><span class="n">net_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss_interval</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">time_interval</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">ckpt_interval</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1"># Randomly collect ground truth</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="c1"># Convert to Tensor data type</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_true</span><span class="p">))</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10001</span><span class="p">):</span>
    <span class="n">trainer</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
<span class="n">print_log</span><span class="p">(</span><span class="s2">&quot;Finished&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The expected output is as follows.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>./example_net.py
<span class="c1"># expected output</span>
...
step:<span class="w"> </span><span class="m">0</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.5189553,<span class="w"> </span>interval:<span class="w"> </span><span class="m">2</span>.7039313316345215s,<span class="w"> </span>total:<span class="w"> </span><span class="m">2</span>.7039313316345215s
step:<span class="w"> </span><span class="m">100</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.080132075,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.11984062194824219s,<span class="w"> </span>total:<span class="w"> </span><span class="m">2</span>.8237719535827637s
step:<span class="w"> </span><span class="m">200</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.055663396,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.09104156494140625s,<span class="w"> </span>total:<span class="w"> </span><span class="m">2</span>.91481351852417s
step:<span class="w"> </span><span class="m">300</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.032194577,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.09095025062561035s,<span class="w"> </span>total:<span class="w"> </span><span class="m">3</span>.0057637691497803s
step:<span class="w"> </span><span class="m">400</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.015914217,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.09099435806274414s,<span class="w"> </span>total:<span class="w"> </span><span class="m">3</span>.0967581272125244s
...
Finished
</pre></div>
</div>
<p>When the training of <code class="docutils literal notranslate"><span class="pre">net</span></code> is finished and loss converges, we can use the net to predict the value at <code class="docutils literal notranslate"><span class="pre">x</span></code> by calling <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">net(x)</span></code>.
Continue to randomly sample a number of positions <code class="docutils literal notranslate"><span class="pre">x_val</span></code> for validation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x_val</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">x_val</span><span class="p">))</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="n">print_log</span><span class="p">(</span><span class="s2">&quot;y_true:&quot;</span><span class="p">)</span>
<span class="n">print_log</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
<span class="n">print_log</span><span class="p">(</span><span class="s2">&quot;y_pred:&quot;</span><span class="p">)</span>
<span class="n">print_log</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
<p>The expected output is as follows. After training, the predicted values are close to those obtained by numerical calculation.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># expected output</span>
y_true:
<span class="o">[[</span><span class="m">0</span>.34606973<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.70457536<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.90531053<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.84420218<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.48239506<span class="o">]]</span>
y_pred:
<span class="o">[[</span><span class="m">0</span>.34271246<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.70356864<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.89893466<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.8393946<span class="w"> </span><span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.47805673<span class="o">]]</span>
</pre></div>
</div>
</section>
</section>
<section id="model-building-extension">
<h2>Model Building Extension<a class="headerlink" href="#model-building-extension" title="Permalink to this headline"></a></h2>
<p>User can solve more complicated problems with SciAI, for example Physics-Informed Neural Network(PINN). This chapter introduces how to use MLP to solve the following Partial Differential Equation(PDE) with SciAI.</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial{f}}{\partial{x}} - 2 \frac{f}{x} + {x}^2 {y}^2 = 0
\]</div>
<p>The boundary conditions are defined to be</p>
<div class="math notranslate nohighlight">
\[
f(0) = 0, f(1) = 1.
\]</div>
<p>Under those boundary conditions, the analytic solution of this PDE is</p>
<div class="math notranslate nohighlight">
\[
f(x) = \frac{x^2}{0.2 x^5 + 0.8}.
\]</div>
<p>For the codes of this part, please refer to <a class="reference external" href="https://gitee.com/mindspore/mindscience/blob/master/SciAI/tutorial/example_grad_net.py">codes</a>.</p>
<section id="loss-definition-1">
<h3>Loss Definition<a class="headerlink" href="#loss-definition-1" title="Permalink to this headline"></a></h3>
<p>Similar to the loss definition in the last chapter, the loss should be defined as a child class of <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/nn/mindspore.nn.Cell.html">Cell</a>.</p>
<p>The difference is that in this loss function, the partial derivative of the original function needs to be calculated.
SciAI provides tool <code class="docutils literal notranslate"><span class="pre">operators.grad</span></code> for this situation. Through setting the input and output index, we can calculate the derivative of certain inputs w.r.t. certain output.
In this problem, the dimensions of input and output are 1, therefore, we set <code class="docutils literal notranslate"><span class="pre">input_index</span></code> and <code class="docutils literal notranslate"><span class="pre">output_index</span></code> to 0.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">sciai.architecture</span> <span class="kn">import</span> <span class="n">MSE</span><span class="p">,</span> <span class="n">MLP</span>
<span class="kn">from</span> <span class="nn">sciai.operators</span> <span class="kn">import</span> <span class="n">grad</span>

<span class="k">class</span> <span class="nc">ExampleLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Loss definition class&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dy_dx</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">net</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">,</span> <span class="n">output_index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">input_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># partial differential definition</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="n">MSE</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_bc</span><span class="p">,</span> <span class="n">y_bc_true</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">dy_dx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dy_dx</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">domain_res</span> <span class="o">=</span> <span class="n">dy_dx</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">ops</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">ops</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">ops</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>  <span class="c1"># PDE residual error</span>

        <span class="n">y_bc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">x_bc</span><span class="p">)</span>
        <span class="n">bc_res</span> <span class="o">=</span> <span class="n">y_bc_true</span> <span class="o">-</span> <span class="n">y_bc</span>  <span class="c1"># Boundary conditions residual</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">domain_res</span><span class="p">)</span> <span class="o">+</span> <span class="mi">10</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">bc_res</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="model-training-and-evaluation-1">
<h3>Model Training and Evaluation<a class="headerlink" href="#model-training-and-evaluation-1" title="Permalink to this headline"></a></h3>
<p>Executing training and evaluation by launching the script in the terminal, we can get the following expected outputs. The predictions <code class="docutils literal notranslate"><span class="pre">y_pred</span></code> are close to the true values <code class="docutils literal notranslate"><span class="pre">y_true</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>./example_grad_net.py
<span class="c1"># expected output</span>
...
step:<span class="w"> </span><span class="m">0</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">3</span>.1961572,<span class="w"> </span>interval:<span class="w"> </span><span class="m">3</span>.117840051651001s,<span class="w"> </span>total:<span class="w"> </span><span class="m">3</span>.117840051651001s
step:<span class="w"> </span><span class="m">100</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">1</span>.0862937,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.23533344268798828s,<span class="w"> </span>total:<span class="w"> </span><span class="m">3</span>.353173494338989s
step:<span class="w"> </span><span class="m">200</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.7334847,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.21307134628295898s,<span class="w"> </span>total:<span class="w"> </span><span class="m">3</span>.566244840621948s
step:<span class="w"> </span><span class="m">300</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.5629723,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.19696831703186035s,<span class="w"> </span>total:<span class="w"> </span><span class="m">3</span>.763213157653809s
step:<span class="w"> </span><span class="m">400</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.4133342,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.20153212547302246s,<span class="w"> </span>total:<span class="w"> </span><span class="m">3</span>.964745283126831s
...
Finished
y_true:
<span class="o">[[</span><span class="m">0</span>.02245186<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.99459697<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.04027248<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.12594332<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.39779923<span class="o">]]</span>
y_pred:
<span class="o">[[</span><span class="m">0</span>.02293926<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.99337316<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.03924912<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.12166673<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.4006738<span class="w"> </span><span class="o">]]</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="model_library.html" class="btn btn-neutral float-left" title="Model Library" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="sciai.architecture.html" class="btn btn-neutral float-right" title="sciai.architecture" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>