<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>使用SciAI构建神经网络 &mdash; MindSpore master 文档</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script src="_static/translations.js"></script><script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/mathjax/MathJax-3.2.2/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="next" title="sciai.architecture" href="sciai.architecture.html" />
    <link rel="prev" title="网络模型库" href="model_library.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">MindSpore SciAI安装</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">启动指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="launch_with_scripts.html">脚本启动模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="launch_with_api.html">调用API启动模型</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型列表</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_library.html">网络模型库</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">教学示例</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">使用SciAI构建神经网络</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#模型构建基础">模型构建基础</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#模型搭建">模型搭建</a></li>
<li class="toctree-l3"><a class="reference internal" href="#损失函数定义">损失函数定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="#模型训练与推理">模型训练与推理</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#模型构建拓展">模型构建拓展</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#损失函数定义-1">损失函数定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="#模型训练与推理-1">模型训练与推理</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="sciai.architecture.html">sciai.architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="sciai.common.html">sciai.common</a></li>
<li class="toctree-l1"><a class="reference internal" href="sciai.context.html">sciai.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="sciai.operators.html">sciai.operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="sciai.utils.html">sciai.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>使用SciAI构建神经网络</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/build_model_with_sciai.md.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="使用sciai构建神经网络">
<h1>使用SciAI构建神经网络<a class="headerlink" href="#使用sciai构建神经网络" title="永久链接至标题"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/sciai/docs/source_zh_cn/build_model_with_sciai.md"><img alt="查看源文件" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.svg" /></a>  </p>
<p>SciAI基础框架由若干基础模块构成，涵盖有神经网络搭建、训练、验证以及其他辅助函数等。</p>
<p>如下的示例展示了使用SciAI构建神经网络模型并进行训练的流程。</p>
<blockquote>
<div><p>你可以在这里下载完整的样例代码：
<a class="reference external" href="https://gitee.com/mindspore/mindscience/tree/master/SciAI/tutorial">https://gitee.com/mindspore/mindscience/tree/master/SciAI/tutorial</a></p>
</div></blockquote>
<section id="模型构建基础">
<h2>模型构建基础<a class="headerlink" href="#模型构建基础" title="永久链接至标题"></a></h2>
<p>使用SciAI基础框架创建神经网络的原理与<a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/master/beginner/model.html">使用MindSpore构建网络</a>一致，但过程将会十分简便。</p>
<p>本章节以一个多层感知器为例，介绍了使用SciAI训练并求解如下方程。</p>
<div class="math notranslate nohighlight">
\[
f(x) = {x_1}^2 + sin(x_2)
\]</div>
<p>该部分完整代码请参考<a class="reference external" href="https://gitee.com/mindspore/mindscience/blob/master/SciAI/tutorial/example_net.py">代码</a>。</p>
<section id="模型搭建">
<h3>模型搭建<a class="headerlink" href="#模型搭建" title="永久链接至标题"></a></h3>
<p>如下示例代码创建了一个输入维度为2，输出维度为1，包含两层维度为5的中间层的多层感知器。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sciai.architecture</span> <span class="kn">import</span> <span class="n">MLP</span>
<span class="kn">from</span> <span class="nn">sciai.common.initializer</span> <span class="kn">import</span> <span class="n">XavierTruncNormal</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">layers</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">XavierTruncNormal</span><span class="p">(),</span> <span class="n">bias_init</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">MLP</span></code>将默认使用正态分布随机生成网络权重，偏差<code class="docutils literal notranslate"><span class="pre">bias</span></code>默认为0，激活函数默认为<code class="docutils literal notranslate"><span class="pre">tanh</span></code>。</p>
<p><code class="docutils literal notranslate"><span class="pre">MLP</span></code>同时接受多样化的初始化方式和MindSpore提供的所有<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/mindspore.nn.html">激活函数</a>，以及专为科学计算设计的激活函数。</p>
</section>
<section id="损失函数定义">
<h3>损失函数定义<a class="headerlink" href="#损失函数定义" title="永久链接至标题"></a></h3>
<p>损失函数定义为<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/nn/mindspore.nn.Cell.html#mindspore.nn.Cell">Cell</a>的子类，并将损失的计算方法写在方法<code class="docutils literal notranslate"><span class="pre">construct</span></code>中。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">sciai.architecture</span> <span class="kn">import</span> <span class="n">MSE</span>

<span class="k">class</span> <span class="nc">ExampleLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="n">MSE</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
        <span class="n">y_predict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">y_predict</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span>

<span class="n">net_loss</span> <span class="o">=</span> <span class="n">ExampleLoss</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</pre></div>
</div>
<p>此时，通过直接调用<code class="docutils literal notranslate"><span class="pre">net_loss</span></code>，并将输入<code class="docutils literal notranslate"><span class="pre">x</span></code>与真实值<code class="docutils literal notranslate"><span class="pre">y_true</span></code>作为参数，便可计算得到当前<code class="docutils literal notranslate"><span class="pre">net</span></code>预测的损失。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]])</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">0.72942554</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;loss value: &quot;</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_true</span><span class="p">))</span>
<span class="c1"># expected output</span>
<span class="o">...</span>
<span class="n">loss</span> <span class="n">value</span><span class="p">:</span> <span class="mf">0.3026065</span>
</pre></div>
</div>
</section>
<section id="模型训练与推理">
<h3>模型训练与推理<a class="headerlink" href="#模型训练与推理" title="永久链接至标题"></a></h3>
<p>得到损失函数后，我们即可使用SciAI框架中已封装好的训练类，使用数据集进行训练。
在本案例中，我们对方程进行随机采样，生成数据集<code class="docutils literal notranslate"><span class="pre">x_train</span></code>与<code class="docutils literal notranslate"><span class="pre">y_true</span></code>进行训练。</p>
<p>模型训练部分代码如下所示，其中主要展示了SciAI若干功能。
模型训练类<code class="docutils literal notranslate"><span class="pre">TrainCellWithCallBack</span></code>，其与<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/nn/mindspore.nn.TrainOneStepCell.html#mindspore.nn.TrainOneStepCell">MindSpore.nn.TrainOneStepCell</a>功能基本一致，
需要提供网络<code class="docutils literal notranslate"><span class="pre">net_loss</span></code>与优化器作为参数，并为科学计算功能增加了回调功能。
回调包括打印训练<code class="docutils literal notranslate"><span class="pre">loss</span></code>值、训练时间、自动保存<code class="docutils literal notranslate"><span class="pre">ckpt</span></code>文件。
如下的案例代码将会每100个训练周期打印<code class="docutils literal notranslate"><span class="pre">loss</span></code>值与训练时间，并在每1000个训练周期保存当前模型参数为<code class="docutils literal notranslate"><span class="pre">ckpt</span></code>文件。
SciAI提供<code class="docutils literal notranslate"><span class="pre">to_tensor</span></code>工具，可以方便地将多个<code class="docutils literal notranslate"><span class="pre">numpy</span></code>数据同时转换为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>类型。
使用<code class="docutils literal notranslate"><span class="pre">log_config</span></code>指定目标目录，用于自动保存<code class="docutils literal notranslate"><span class="pre">TrainCellWithCallBack</span></code>的回调打印，以及用户使用<code class="docutils literal notranslate"><span class="pre">print_log</span></code>所打印的内容。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">sciai.common</span> <span class="kn">import</span> <span class="n">TrainCellWithCallBack</span>
<span class="kn">from</span> <span class="nn">sciai.context</span> <span class="kn">import</span> <span class="n">init_project</span>
<span class="kn">from</span> <span class="nn">sciai.utils</span> <span class="kn">import</span> <span class="n">to_tensor</span><span class="p">,</span> <span class="n">print_log</span><span class="p">,</span> <span class="n">log_config</span>

<span class="c1"># Get the correct platform automatically and set to GRAPH_MODE by default.</span>
<span class="n">init_project</span><span class="p">()</span>
<span class="c1"># Auto log saving</span>
<span class="n">log_config</span><span class="p">(</span><span class="s2">&quot;./logs&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The function to be learned to&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net_loss</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">TrainCellWithCallBack</span><span class="p">(</span><span class="n">net_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss_interval</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">time_interval</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">ckpt_interval</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1"># Randomly collect ground truth</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="c1"># Convert to Tensor data type</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_true</span><span class="p">))</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10001</span><span class="p">):</span>
    <span class="n">trainer</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
<span class="n">print_log</span><span class="p">(</span><span class="s2">&quot;Finished&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>预期运行结果如下。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>./example_net.py
<span class="c1"># expected output</span>
...
step:<span class="w"> </span><span class="m">0</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.5189553,<span class="w"> </span>interval:<span class="w"> </span><span class="m">2</span>.7039313316345215s,<span class="w"> </span>total:<span class="w"> </span><span class="m">2</span>.7039313316345215s
step:<span class="w"> </span><span class="m">100</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.080132075,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.11984062194824219s,<span class="w"> </span>total:<span class="w"> </span><span class="m">2</span>.8237719535827637s
step:<span class="w"> </span><span class="m">200</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.055663396,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.09104156494140625s,<span class="w"> </span>total:<span class="w"> </span><span class="m">2</span>.91481351852417s
step:<span class="w"> </span><span class="m">300</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.032194577,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.09095025062561035s,<span class="w"> </span>total:<span class="w"> </span><span class="m">3</span>.0057637691497803s
step:<span class="w"> </span><span class="m">400</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.015914217,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.09099435806274414s,<span class="w"> </span>total:<span class="w"> </span><span class="m">3</span>.0967581272125244s
...
Finished
</pre></div>
</div>
<p>在训练结束并且损失收敛时，通过调用<code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">net(x)</span></code>即可得到<code class="docutils literal notranslate"><span class="pre">x</span></code>处的预测值<code class="docutils literal notranslate"><span class="pre">y</span></code>。
继续随机采样若干位置<code class="docutils literal notranslate"><span class="pre">x_val</span></code>用于验证。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x_val</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">x_val</span><span class="p">))</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="n">print_log</span><span class="p">(</span><span class="s2">&quot;y_true:&quot;</span><span class="p">)</span>
<span class="n">print_log</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
<span class="n">print_log</span><span class="p">(</span><span class="s2">&quot;y_pred:&quot;</span><span class="p">)</span>
<span class="n">print_log</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
<p>预期运行结果如下。经过训练，模型的预测值接近数值计算结果。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># expected output</span>
y_true:
<span class="o">[[</span><span class="m">0</span>.34606973<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.70457536<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.90531053<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.84420218<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.48239506<span class="o">]]</span>
y_pred:
<span class="o">[[</span><span class="m">0</span>.34271246<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.70356864<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.89893466<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.8393946<span class="w"> </span><span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.47805673<span class="o">]]</span>
</pre></div>
</div>
</section>
</section>
<section id="模型构建拓展">
<h2>模型构建拓展<a class="headerlink" href="#模型构建拓展" title="永久链接至标题"></a></h2>
<p>使用SciAI可以求解更为复杂的问题，例如物理驱动的神经网络（PINN）。该章节继续以一个多层感知器为例，介绍使用SciAI训练并求解如下偏微分方程。</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial{f}}{\partial{x}} - 2 \frac{f}{x} + {x}^2 {y}^2 = 0
\]</div>
<p>边界条件定义如下。</p>
<div class="math notranslate nohighlight">
\[
f(0) = 0, f(1) = 1
\]</div>
<p>在此边界条件下，函数的解析解为：</p>
<div class="math notranslate nohighlight">
\[
f(x) = \frac{x^2}{0.2 x^5 + 0.8}
\]</div>
<p>该部分完整代码请参考<a class="reference external" href="https://gitee.com/mindspore/mindscience/blob/master/SciAI/tutorial/example_grad_net.py">代码</a>。</p>
<section id="损失函数定义-1">
<h3>损失函数定义<a class="headerlink" href="#损失函数定义-1" title="永久链接至标题"></a></h3>
<p>与上一章中损失函数定义基本一致，需要定义损失为<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/nn/mindspore.nn.Cell.html#mindspore.nn.Cell">Cell</a>的子类。</p>
<p>不同的是在该损失函数中，需要计算原函数的偏导。
SciAI为此提供了便捷的工具<code class="docutils literal notranslate"><span class="pre">operators.grad</span></code>，通过设置网络输入与输出的索引，可以计算某个输入对某个输出的偏导值。
在该问题中，输入输出维度均为1，因此设置<code class="docutils literal notranslate"><span class="pre">input_index</span></code>与<code class="docutils literal notranslate"><span class="pre">output_index</span></code>为0。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">sciai.architecture</span> <span class="kn">import</span> <span class="n">MSE</span><span class="p">,</span> <span class="n">MLP</span>
<span class="kn">from</span> <span class="nn">sciai.operators</span> <span class="kn">import</span> <span class="n">grad</span>

<span class="k">class</span> <span class="nc">ExampleLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Loss definition class&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dy_dx</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">net</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">,</span> <span class="n">output_index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">input_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># partial differential definition</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="n">MSE</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_bc</span><span class="p">,</span> <span class="n">y_bc_true</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">dy_dx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dy_dx</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">domain_res</span> <span class="o">=</span> <span class="n">dy_dx</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">ops</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">ops</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">ops</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>  <span class="c1"># PDE residual error</span>

        <span class="n">y_bc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">x_bc</span><span class="p">)</span>
        <span class="n">bc_res</span> <span class="o">=</span> <span class="n">y_bc_true</span> <span class="o">-</span> <span class="n">y_bc</span>  <span class="c1"># Boundary conditions residual</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">domain_res</span><span class="p">)</span> <span class="o">+</span> <span class="mi">10</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">bc_res</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="模型训练与推理-1">
<h3>模型训练与推理<a class="headerlink" href="#模型训练与推理-1" title="永久链接至标题"></a></h3>
<p>通过终端执行脚本文件，执行训练与推理，得到如下预期结果。最终预测值<code class="docutils literal notranslate"><span class="pre">y_pred</span></code>与真实值<code class="docutils literal notranslate"><span class="pre">y_true</span></code>基本接近。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>./example_grad_net.py
<span class="c1"># expected output</span>
...
step:<span class="w"> </span><span class="m">0</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">3</span>.1961572,<span class="w"> </span>interval:<span class="w"> </span><span class="m">3</span>.117840051651001s,<span class="w"> </span>total:<span class="w"> </span><span class="m">3</span>.117840051651001s
step:<span class="w"> </span><span class="m">100</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">1</span>.0862937,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.23533344268798828s,<span class="w"> </span>total:<span class="w"> </span><span class="m">3</span>.353173494338989s
step:<span class="w"> </span><span class="m">200</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.7334847,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.21307134628295898s,<span class="w"> </span>total:<span class="w"> </span><span class="m">3</span>.566244840621948s
step:<span class="w"> </span><span class="m">300</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.5629723,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.19696831703186035s,<span class="w"> </span>total:<span class="w"> </span><span class="m">3</span>.763213157653809s
step:<span class="w"> </span><span class="m">400</span>,<span class="w"> </span>loss:<span class="w"> </span><span class="m">0</span>.4133342,<span class="w"> </span>interval:<span class="w"> </span><span class="m">0</span>.20153212547302246s,<span class="w"> </span>total:<span class="w"> </span><span class="m">3</span>.964745283126831s
...
Finished
y_true:
<span class="o">[[</span><span class="m">0</span>.02245186<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.99459697<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.04027248<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.12594332<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.39779923<span class="o">]]</span>
y_pred:
<span class="o">[[</span><span class="m">0</span>.02293926<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.99337316<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.03924912<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.12166673<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="m">0</span>.4006738<span class="w"> </span><span class="o">]]</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="model_library.html" class="btn btn-neutral float-left" title="网络模型库" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="sciai.architecture.html" class="btn btn-neutral float-right" title="sciai.architecture" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 MindSpore.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>