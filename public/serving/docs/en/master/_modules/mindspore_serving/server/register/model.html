<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore_serving.server.register.model &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../serving_install.html">MindSpore Serving Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../serving_example.html">MindSpore Serving-based Inference Service Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../serving_distributed_example.html">MindSpore Serving-based Distributed Inference Service Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../serving_grpc.html">gRPC-based MindSpore Serving Access</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../serving_restful.html">RESTful-based MindSpore Serving Access</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../serving_model.html">Servable Provided Through Model Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../serving_multi_subgraphs.html">Service Deployment with Multiple Subgraphs and Stateful Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../server.html">mindspore_serving.server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../client.html">mindspore_serving.client</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
      <li>mindspore_serving.server.register.model</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for mindspore_serving.server.register.model</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2020 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ============================================================================</span>
<span class="sd">&quot;&quot;&quot;Servable declaration interface&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">mindspore_serving._mindspore_serving</span> <span class="kn">import</span> <span class="n">ModelMeta_</span><span class="p">,</span> <span class="n">ServableRegister_</span><span class="p">,</span> <span class="n">ModelContext_</span>

<span class="kn">from</span> <span class="nn">mindspore_serving</span> <span class="kn">import</span> <span class="n">log</span> <span class="k">as</span> <span class="n">logger</span>
<span class="kn">from</span> <span class="nn">mindspore_serving.server.common</span> <span class="kn">import</span> <span class="n">check_type</span><span class="p">,</span> <span class="n">deprecated</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">get_servable_dir</span>

<span class="n">g_declared_models</span> <span class="o">=</span> <span class="p">[]</span>


<span class="nd">@deprecated</span><span class="p">(</span><span class="s2">&quot;1.5.0&quot;</span><span class="p">,</span> <span class="s2">&quot;mindspore_serving.server.register.declare_model&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">declare_servable</span><span class="p">(</span><span class="n">servable_file</span><span class="p">,</span> <span class="n">model_format</span><span class="p">,</span> <span class="n">with_batch_dim</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">without_batch_dim_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    declare one model.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        &#39;register.declare_servable&#39; is deprecated from version 1.5.0 and will be removed in a future version, use</span>
<span class="sd">        :class:`mindspore_serving.server.register.declare_model` instead.</span>

<span class="sd">    Args:</span>
<span class="sd">        servable_file (Union[str, list[str]]): Model files name.</span>
<span class="sd">        model_format (str): Model format, ``&quot;OM&quot;`` or ``&quot;MindIR&quot;``, case ignored.</span>
<span class="sd">        with_batch_dim (bool, optional): Whether the first shape dim of the inputs and outputs of model is batch dim.</span>
<span class="sd">            Default: ``True``.</span>
<span class="sd">        options (Union[AclOptions, GpuOptions], optional): Options of model, supports AclOptions or GpuOptions.</span>
<span class="sd">            Default: ``None``.</span>
<span class="sd">        without_batch_dim_inputs (Union[int, tuple[int], list[int]], optional): Index of inputs that without batch</span>
<span class="sd">            dim when `with_batch_dim` is ``True``. Default: ``None``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: The type or value of the parameters are invalid.</span>

<span class="sd">    Return:</span>
<span class="sd">        Model, identification of this model, used as input of add_stage.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">declare_model</span><span class="p">(</span><span class="n">servable_file</span><span class="p">,</span> <span class="n">model_format</span><span class="p">,</span> <span class="n">with_batch_dim</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">without_batch_dim_inputs</span><span class="p">)</span>


<div class="viewcode-block" id="Model"><a class="viewcode-back" href="../../../../server.html#mindspore_serving.server.register.Model">[docs]</a><span class="k">class</span> <span class="nc">Model</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Indicate a model. User should not construct Model object directly, it&#39;s need to be returned from `declare_model`</span>
<span class="sd">    or `declare_servable`</span>

<span class="sd">    Args:</span>
<span class="sd">        model_key (str): Model key identifies the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_key</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_key</span> <span class="o">=</span> <span class="n">model_key</span>

<div class="viewcode-block" id="Model.call"><a class="viewcode-back" href="../../../../server.html#mindspore_serving.server.register.Model.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">subgraph</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Invoke the model inference interface based on instances.</span>

<span class="sd">        Args:</span>
<span class="sd">            args : tuple/list of instances, or inputs of one instance.</span>
<span class="sd">            subgraph (int, optional): Subgraph index, used when there are multiply sub-graphs in one model.</span>
<span class="sd">                Default: ``0``.</span>

<span class="sd">        Return:</span>
<span class="sd">            Tuple of instances when input parameter &#39;args&#39; is tuple/list, or outputs of one instance.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: Inputs are invalid.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_serving.server import register</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset.vision.c_transforms as VC</span>
<span class="sd">            &gt;&gt;&gt; model = register.declare_model(model_file=&quot;resnet_bs32.mindir&quot;, model_format=&quot;MindIR&quot;) # batch_size=32</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; def preprocess(image):</span>
<span class="sd">            ...     decode = VC.Decode()</span>
<span class="sd">            ...     resize = VC.Resize([224, 224])</span>
<span class="sd">            ...     normalize = VC.Normalize(mean=[125.307, 122.961, 113.8575], std=[51.5865, 50.847, 51.255])</span>
<span class="sd">            ...     hwc2chw = VC.HWC2CHW()</span>
<span class="sd">            ...     image = decode(image)</span>
<span class="sd">            ...     image = resize(image) # [3,224,224]</span>
<span class="sd">            ...     image = normalize(image) # [3,224,224]</span>
<span class="sd">            ...     image = hwc2chw(image) # [3,224,224]</span>
<span class="sd">            ...     return input</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; def postprocess(score):</span>
<span class="sd">            &gt;&gt;&gt;     return np.argmax(score)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; def call_resnet_model(image):</span>
<span class="sd">            ...     image = preprocess(image)</span>
<span class="sd">            ...     score = model.call(image)  # for only one instance</span>
<span class="sd">            ...     return postprocess(score)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; def call_resnet_model_batch(instances):</span>
<span class="sd">            ...     input_instances = []</span>
<span class="sd">            ...     for instance in instances:</span>
<span class="sd">            ...         image = instance[0] # only one input</span>
<span class="sd">            ...         image = preprocess(image) # [3,224,224]</span>
<span class="sd">            ...         input_instances.append([image])</span>
<span class="sd">            ...     output_instances = model.call(input_instances)  # for multiply instances</span>
<span class="sd">            ...     for instance in output_instances:</span>
<span class="sd">            ...         score = instance[0]  # only one output for each instance</span>
<span class="sd">            ...         index = postprocess(score)</span>
<span class="sd">            ...         yield index</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; @register.register_method(output_names=[&quot;index&quot;])</span>
<span class="sd">            &gt;&gt;&gt; def predict_v1(image):  # without pipeline, call model with only one instance a time</span>
<span class="sd">            ...     index = register.add_stage(call_resnet_model, image, outputs_count=1)</span>
<span class="sd">            ...     return index</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; @register.register_method(output_names=[&quot;index&quot;])</span>
<span class="sd">            &gt;&gt;&gt; def predict_v2(image):  # without pipeline, call model with maximum 32 instances a time</span>
<span class="sd">            ...     index = register.add_stage(call_resnet_model_batch, image, outputs_count=1, batch_size=32)</span>
<span class="sd">            ...     return index</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; @register.register_method(output_names=[&quot;index&quot;])</span>
<span class="sd">            &gt;&gt;&gt; def predict_v3(image):  # pipeline</span>
<span class="sd">            ...     image = register.add_stage(preprocess, image, outputs_count=1)</span>
<span class="sd">            ...     score = register.add_stage(model, image, outputs_count=1)</span>
<span class="sd">            ...     index = register.add_stage(postprocess, score, outputs_count=1)</span>
<span class="sd">            ...     return index</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_type</span><span class="o">.</span><span class="n">check_int</span><span class="p">(</span><span class="s2">&quot;subgraph&quot;</span><span class="p">,</span> <span class="n">subgraph</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">subgraph_str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">if</span> <span class="n">subgraph</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">subgraph_str</span> <span class="o">=</span> <span class="s2">&quot; ,subgraph=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">subgraph</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">args</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model(</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_key</span><span class="si">}{</span><span class="n">subgraph_str</span><span class="si">}</span><span class="s2">).call() failed: no inputs provided, the inputs &quot;</span>
                               <span class="sa">f</span><span class="s2">&quot;can be call(x1, x2) for single instance or call([[x1, x2], [x1, x2]]) for multi &quot;</span>
                               <span class="sa">f</span><span class="s2">&quot;instances.&quot;</span><span class="p">)</span>
        <span class="n">instances</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">instance_format</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="n">instance_format</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model(</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_key</span><span class="si">}{</span><span class="n">subgraph_str</span><span class="si">}</span><span class="s2">).call() failed: inputs format invalid, &quot;</span>
                                       <span class="sa">f</span><span class="s2">&quot;the inputs can be call(x1, x2) for single instance or &quot;</span>
                                       <span class="sa">f</span><span class="s2">&quot; call([[x1, x2], [x1, x2]]) for multi instances.&quot;</span><span class="p">)</span>
                <span class="n">instances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">instance</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">instances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">args</span><span class="p">))</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">ServableRegister_</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">instances</span><span class="p">),</span> <span class="n">subgraph</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">instance_format</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">output</span>
        <span class="k">return</span> <span class="n">output</span></div></div>


<span class="k">def</span> <span class="nf">append_declared_model</span><span class="p">(</span><span class="n">model_key</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">g_declared_models</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">model_key</span><span class="p">)</span>
    <span class="n">g_declared_models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<div class="viewcode-block" id="declare_model"><a class="viewcode-back" href="../../../../server.html#mindspore_serving.server.register.declare_model">[docs]</a><span class="k">def</span> <span class="nf">declare_model</span><span class="p">(</span><span class="n">model_file</span><span class="p">,</span> <span class="n">model_format</span><span class="p">,</span> <span class="n">with_batch_dim</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">without_batch_dim_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">config_file</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Declare one model when importing servable_config.py of one servable.</span>

<span class="sd">    Note:</span>
<span class="sd">        This interface should take effect when importing servable_config.py by the serving server. Therefore, it&#39;s</span>
<span class="sd">        recommended that this interface be used globally in servable_config.py.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        The parameter &#39;options&#39; is deprecated from version 1.6.0 and will be removed in a future version, use</span>
<span class="sd">        parameter &#39;context&#39; instead.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_file (Union[str, list[str]]): Model files name.</span>
<span class="sd">        model_format (str): Model format, ``&quot;OM&quot;``, ``&quot;MindIR&quot;`` or ``&quot;MindIR_Lite&quot;``, case ignored.</span>
<span class="sd">        with_batch_dim (bool, optional): Whether the first shape dim of the inputs and outputs of model is batch dim.</span>
<span class="sd">            Default: ``True``.</span>
<span class="sd">        options (Union[AclOptions, GpuOptions], optional): Options of model, supports AclOptions or GpuOptions.</span>
<span class="sd">            Default: ``None``.</span>
<span class="sd">        context (Context): Context is used to store environment variables during execution. If the value is ``None``,</span>
<span class="sd">            Serving uses the default device context based on the deployed device. Default: ``None``.</span>
<span class="sd">        without_batch_dim_inputs (Union[int, tuple[int], list[int]], optional): Index of inputs that without batch</span>
<span class="sd">            dim when `with_batch_dim` is ``True``. For example, if the shape of input 0 does not include the</span>
<span class="sd">            batch dimension, `without_batch_dim_inputs` can be set to `(0,)`. Default: ``None``.</span>
<span class="sd">        config_file (str, optional): Config file for model to set mix precision inference. The file path can be an</span>
<span class="sd">            absolute path or a relative path to the directory in which servable_config.py resides.</span>
<span class="sd">            Default: ``None``.</span>

<span class="sd">    Return:</span>
<span class="sd">        Model, identification of this model, can be used for `Model.call` or as the inputs of `add_stage`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: The type or value of the parameters are invalid.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">check_type</span><span class="o">.</span><span class="n">check_bool</span><span class="p">(</span><span class="s1">&#39;with_batch_dim&#39;</span><span class="p">,</span> <span class="n">with_batch_dim</span><span class="p">)</span>

    <span class="n">meta</span> <span class="o">=</span> <span class="n">ModelMeta_</span><span class="p">()</span>
    <span class="n">model_file</span> <span class="o">=</span> <span class="n">check_type</span><span class="o">.</span><span class="n">check_and_as_str_tuple_list</span><span class="p">(</span><span class="s1">&#39;model_file&#39;</span><span class="p">,</span> <span class="n">model_file</span><span class="p">)</span>
    <span class="n">meta</span><span class="o">.</span><span class="n">common_meta</span><span class="o">.</span><span class="n">servable_name</span> <span class="o">=</span> <span class="n">get_servable_dir</span><span class="p">()</span>
    <span class="n">meta</span><span class="o">.</span><span class="n">common_meta</span><span class="o">.</span><span class="n">model_key</span> <span class="o">=</span> <span class="s2">&quot;;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">model_file</span><span class="p">)</span>
    <span class="n">meta</span><span class="o">.</span><span class="n">common_meta</span><span class="o">.</span><span class="n">with_batch_dim</span> <span class="o">=</span> <span class="n">with_batch_dim</span>
    <span class="k">if</span> <span class="n">without_batch_dim_inputs</span><span class="p">:</span>
        <span class="n">without_batch_dim_inputs</span> <span class="o">=</span> <span class="n">check_type</span><span class="o">.</span><span class="n">check_and_as_int_tuple_list</span><span class="p">(</span><span class="s1">&#39;without_batch_dim_inputs&#39;</span><span class="p">,</span>
                                                                          <span class="n">without_batch_dim_inputs</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">meta</span><span class="o">.</span><span class="n">common_meta</span><span class="o">.</span><span class="n">without_batch_dim_inputs</span> <span class="o">=</span> <span class="n">without_batch_dim_inputs</span>

    <span class="c1"># init local servable meta info</span>
    <span class="n">check_type</span><span class="o">.</span><span class="n">check_str</span><span class="p">(</span><span class="s1">&#39;model_format&#39;</span><span class="p">,</span> <span class="n">model_format</span><span class="p">)</span>
    <span class="n">model_format</span> <span class="o">=</span> <span class="n">model_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">model_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;om&quot;</span><span class="p">,</span> <span class="s2">&quot;mindir&quot;</span><span class="p">,</span> <span class="s2">&quot;mindir_opt&quot;</span><span class="p">,</span> <span class="s2">&quot;mindir_lite&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;model format can only be OM, MindIR or MindIR_Lite, case ignored&quot;</span><span class="p">)</span>

    <span class="n">meta</span><span class="o">.</span><span class="n">local_meta</span><span class="o">.</span><span class="n">model_file</span> <span class="o">=</span> <span class="n">model_file</span>
    <span class="n">meta</span><span class="o">.</span><span class="n">local_meta</span><span class="o">.</span><span class="n">set_model_format</span><span class="p">(</span><span class="n">model_format</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">context</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">Context</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parameter &#39;context&#39; should be Context, but gotten </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">context</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">meta</span><span class="o">.</span><span class="n">local_meta</span><span class="o">.</span><span class="n">model_context</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">model_context</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="p">(</span><span class="n">GpuOptions</span><span class="p">,</span> <span class="n">AclOptions</span><span class="p">)):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;&#39;options&#39; will be deprecated in the future, we recommend using &#39;context&#39;, if these two parameters &quot;</span>
            <span class="s2">&quot;are both set, options will be ignored&quot;</span><span class="p">)</span>
        <span class="n">meta</span><span class="o">.</span><span class="n">local_meta</span><span class="o">.</span><span class="n">model_context</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">context</span><span class="o">.</span><span class="n">model_context</span>
    <span class="k">elif</span> <span class="n">options</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parameter &#39;options&#39; should be None, GpuOptions or AclOptions, but &quot;</span>
                           <span class="sa">f</span><span class="s2">&quot;gotten </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">options</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">config_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">check_type</span><span class="o">.</span><span class="n">check_str</span><span class="p">(</span><span class="s2">&quot;config_file&quot;</span><span class="p">,</span> <span class="n">config_file</span><span class="p">)</span>
        <span class="n">meta</span><span class="o">.</span><span class="n">local_meta</span><span class="o">.</span><span class="n">config_file</span> <span class="o">=</span> <span class="n">config_file</span>

    <span class="n">ServableRegister_</span><span class="o">.</span><span class="n">declare_model</span><span class="p">(</span><span class="n">meta</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Declare model, model_file: </span><span class="si">{</span><span class="n">model_file</span><span class="si">}</span><span class="s2"> , model_format: </span><span class="si">{</span><span class="n">model_format</span><span class="si">}</span><span class="s2">,  with_batch_dim: &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">with_batch_dim</span><span class="si">}</span><span class="s2">, options: </span><span class="si">{</span><span class="n">options</span><span class="si">}</span><span class="s2">, without_batch_dim_inputs: </span><span class="si">{</span><span class="n">without_batch_dim_inputs</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;, context: </span><span class="si">{</span><span class="n">context</span><span class="si">}</span><span class="s2">, config file: </span><span class="si">{</span><span class="n">config_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">append_declared_model</span><span class="p">(</span><span class="n">meta</span><span class="o">.</span><span class="n">common_meta</span><span class="o">.</span><span class="n">model_key</span><span class="p">)</span></div>


<div class="viewcode-block" id="Context"><a class="viewcode-back" href="../../../../server.html#mindspore_serving.server.register.Context">[docs]</a><span class="k">class</span> <span class="nc">Context</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Context is used to customize device configurations. If Context is not specified, MindSpore Serving uses the default</span>
<span class="sd">    device configurations. When inference backend is MindSpore Lite and the device type is Ascend or Gpu, the extra</span>
<span class="sd">    `CPUDeviceInfo` will be used.</span>

<span class="sd">    Args:</span>
<span class="sd">        thread_num (int, optional): Set the number of threads at runtime. Only valid when using mindspore lite.</span>
<span class="sd">        thread_affinity_core_list (tuple[int], list[int], optional): Set the thread lists to CPU cores.</span>
<span class="sd">            Only valid when inference backend is MindSpore Lite.</span>
<span class="sd">        enable_parallel (bool, optional): Set the status whether to perform model inference or training in parallel.</span>
<span class="sd">            Only valid when inference backend is MindSpore Lite.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: type or value of input parameters are invalid.</span>

<span class="sd">    Examples:</span>
<span class="sd">            &gt;&gt;&gt; from mindspore_serving.server import register</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; context = register.Context(thread_num=1, thread_affinity_core_list=[1,2], enable_parallel=True)</span>
<span class="sd">            &gt;&gt;&gt; context.append_device_info(register.GPUDeviceInfo(precision_mode=&quot;fp16&quot;))</span>
<span class="sd">            &gt;&gt;&gt; model = declare_model(model_file=&quot;tensor_add.mindir&quot;, model_format=&quot;MindIR&quot;, context=context)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_context</span> <span class="o">=</span> <span class="n">ModelContext_</span><span class="p">()</span>
        <span class="n">val_set_fun</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;thread_num&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_thread_num</span><span class="p">,</span>
            <span class="s2">&quot;thread_affinity_core_list&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_thread_affinity_core_list</span><span class="p">,</span>
            <span class="s2">&quot;enable_parallel&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_enable_parallel</span>
        <span class="p">}</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">val_set_fun</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Set context failed, unsupported option &quot;</span> <span class="o">+</span> <span class="n">k</span><span class="p">)</span>
            <span class="n">val_set_fun</span><span class="p">[</span><span class="n">k</span><span class="p">](</span><span class="n">v</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device_types</span> <span class="o">=</span> <span class="p">[]</span>

<div class="viewcode-block" id="Context.append_device_info"><a class="viewcode-back" href="../../../../server.html#mindspore_serving.server.register.Context.append_device_info">[docs]</a>    <span class="k">def</span> <span class="nf">append_device_info</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device_info</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Append one user-defined device info to the context</span>

<span class="sd">         Args:</span>
<span class="sd">            device_info (Union[CPUDeviceInfo, GPUDeviceInfo, AscendDeviceInfo]): User-defined device info for one</span>
<span class="sd">                device, otherwise default values are used. You can customize device info for each device, and the system</span>
<span class="sd">                selects the required device info based on the actual backend device and MindSpore inference package.</span>

<span class="sd">         Raises:</span>
<span class="sd">            RuntimeError: type or value of input parameters are invalid.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device_info</span><span class="p">,</span> <span class="n">DeviceInfoContext</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parameter &#39;device_info&#39; should instance of CPUDeviceInfo, GPUDeviceInfo, or &quot;</span>
                               <span class="sa">f</span><span class="s2">&quot;AscendDeviceInfo, but actually </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">device_info</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># pylint: disable=protected-access</span>
        <span class="n">info_map</span> <span class="o">=</span> <span class="n">device_info</span><span class="o">.</span><span class="n">_as_context_map</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">info_map</span><span class="p">[</span><span class="s2">&quot;device_type&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Invalid DeviceInfoContext, device_type cannot be empty&quot;</span><span class="p">)</span>
        <span class="n">device_type</span> <span class="o">=</span> <span class="n">info_map</span><span class="p">[</span><span class="s2">&quot;device_type&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">device_type</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_types</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Device info of type </span><span class="si">{</span><span class="n">device_type</span><span class="si">}</span><span class="s2"> has already been appended&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">device_type</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_context</span><span class="o">.</span><span class="n">append_device_info</span><span class="p">(</span><span class="n">info_map</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_set_thread_num</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
        <span class="n">check_type</span><span class="o">.</span><span class="n">check_int</span><span class="p">(</span><span class="s2">&quot;thread_num&quot;</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_context</span><span class="o">.</span><span class="n">thread_num</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">_set_thread_affinity_core_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
        <span class="n">check_type</span><span class="o">.</span><span class="n">check_int_tuple_list</span><span class="p">(</span><span class="s2">&quot;thread_affinity_core_list&quot;</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_context</span><span class="o">.</span><span class="n">thread_affinity_core_list</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">_set_enable_parallel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
        <span class="n">check_type</span><span class="o">.</span><span class="n">check_bool</span><span class="p">(</span><span class="s2">&quot;enable_parallel&quot;</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">val</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_context</span><span class="o">.</span><span class="n">enable_parallel</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_context</span><span class="o">.</span><span class="n">enable_parallel</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;thread_num: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_context</span><span class="o">.</span><span class="n">thread_num</span><span class="si">}</span><span class="s2">, thread_affinity_core_list: &quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_context</span><span class="o">.</span><span class="n">thread_affinity_core_list</span><span class="si">}</span><span class="s2">, enable_parallel: &quot;</span> \
              <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_context</span><span class="o">.</span><span class="n">enable_parallel</span><span class="si">}</span><span class="s2">, device_list, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_context</span><span class="o">.</span><span class="n">device_list</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">return</span> <span class="n">res</span></div>


<span class="k">class</span> <span class="nc">DeviceInfoContext</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Initialize context&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_as_context_map</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transfer device info to dict of str,str&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>


<div class="viewcode-block" id="CPUDeviceInfo"><a class="viewcode-back" href="../../../../server.html#mindspore_serving.server.register.CPUDeviceInfo">[docs]</a><span class="k">class</span> <span class="nc">CPUDeviceInfo</span><span class="p">(</span><span class="n">DeviceInfoContext</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper class to set cpu device info.</span>

<span class="sd">    Args:</span>
<span class="sd">        precision_mode(str, optional): Option of model precision, and the value can be ``&quot;origin&quot;``, ``&quot;fp16&quot;``.</span>
<span class="sd">            ``&quot;origin&quot;`` indicates that inference is performed with the preciesion defined in the model, and</span>
<span class="sd">            ``&quot;fp16&quot;`` indicates that inference is performed based on FP16 precision.</span>
<span class="sd">            Default: ``&quot;origin&quot;``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: Cpu option is invalid, or value is not str.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore_serving.server import register</span>
<span class="sd">        &gt;&gt;&gt; context = register.Context()</span>
<span class="sd">        &gt;&gt;&gt; context.append_device_info(register.CPUDeviceInfo(precision_mode=&quot;fp16&quot;))</span>
<span class="sd">        &gt;&gt;&gt; model = register.declare_model(model_file=&quot;deeptext.ms&quot;, model_format=&quot;MindIR_Lite&quot;, context=context)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CPUDeviceInfo</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">precision_mode</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="n">val_set_fun</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;precision_mode&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_precision_mode</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">val_set_fun</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Set cpu device info failed, unsupported option &quot;</span> <span class="o">+</span> <span class="n">k</span><span class="p">)</span>
            <span class="n">val_set_fun</span><span class="p">[</span><span class="n">k</span><span class="p">](</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_as_context_map</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_set_precision_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
        <span class="n">check_type</span><span class="o">.</span><span class="n">check_str</span><span class="p">(</span><span class="s2">&quot;precision_mode&quot;</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">val</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;origin&quot;</span><span class="p">,</span> <span class="s2">&quot;fp16&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cpu device info &#39;precision_mode&#39; can only be &#39;origin&#39;, &#39;fp16&#39;. given &#39;</span><span class="si">{</span><span class="n">val</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">precision_mode</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">_as_context_map</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transfer cpu device info to dict of str,str&quot;&quot;&quot;</span>
        <span class="n">context_map</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">precision_mode</span><span class="p">:</span>
            <span class="n">context_map</span><span class="p">[</span><span class="s2">&quot;precision_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">precision_mode</span>
        <span class="n">context_map</span><span class="p">[</span><span class="s2">&quot;device_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>
        <span class="k">return</span> <span class="n">context_map</span></div>


<div class="viewcode-block" id="GPUDeviceInfo"><a class="viewcode-back" href="../../../../server.html#mindspore_serving.server.register.GPUDeviceInfo">[docs]</a><span class="k">class</span> <span class="nc">GPUDeviceInfo</span><span class="p">(</span><span class="n">DeviceInfoContext</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper class to set gpu device info.</span>

<span class="sd">    Args:</span>
<span class="sd">        precision_mode(str, optional): Option of model precision, and the value can be ``&quot;origin&quot;``, ``&quot;fp16&quot;``.</span>
<span class="sd">            ``&quot;origin&quot;`` indicates that inference is performed with the preciesion defined in the model, and</span>
<span class="sd">            ``&quot;fp16&quot;`` indicates that inference is performed based on FP16 precision.</span>
<span class="sd">            Default: ``&quot;origin&quot;``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: Gpu option is invalid, or value is not str.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore_serving.server import register</span>
<span class="sd">        &gt;&gt;&gt; context = register.Context()</span>
<span class="sd">        &gt;&gt;&gt; context.append_device_info(register.GPUDeviceInfo(precision_mode=&quot;fp16&quot;))</span>
<span class="sd">        &gt;&gt;&gt; model = register.declare_model(model_file=&quot;deeptext.mindir&quot;, model_format=&quot;MindIR&quot;, context=context)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GPUDeviceInfo</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">precision_mode</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="n">val_set_fun</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;precision_mode&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_precision_mode</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">val_set_fun</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Set gpu device info failed, unsupported option &quot;</span> <span class="o">+</span> <span class="n">k</span><span class="p">)</span>
            <span class="n">val_set_fun</span><span class="p">[</span><span class="n">k</span><span class="p">](</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_as_context_map</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_set_precision_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set option &#39;precision_mode&#39;, which means inference operator selection, and the value can be &quot;origin&quot;,</span>
<span class="sd">        &quot;fp16&quot;, default &quot;origin&quot;.</span>

<span class="sd">        Args:</span>
<span class="sd">            val (str): Value of option &#39;precision_mode&#39;. &quot;origin&quot; inference with model definition.</span>
<span class="sd">            &quot;fp16&quot; enable FP16 operator selection, with FP32 fallback. Default: &quot;origin&quot;.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: The type of value is not str, or the value is invalid.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_type</span><span class="o">.</span><span class="n">check_str</span><span class="p">(</span><span class="s1">&#39;precision_mode&#39;</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">val</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;origin&quot;</span><span class="p">,</span> <span class="s2">&quot;fp16&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gpu device info &#39;precision_mode&#39; can only be &#39;origin&#39;, &#39;fp16&#39;. given &#39;</span><span class="si">{</span><span class="n">val</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">precision_mode</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">_as_context_map</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transfer gpu device info to dict of str,str&quot;&quot;&quot;</span>
        <span class="n">context_map</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">precision_mode</span><span class="p">:</span>
            <span class="n">context_map</span><span class="p">[</span><span class="s2">&quot;precision_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">precision_mode</span>
        <span class="n">context_map</span><span class="p">[</span><span class="s2">&quot;device_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;gpu&quot;</span>
        <span class="k">return</span> <span class="n">context_map</span></div>


<div class="viewcode-block" id="AscendDeviceInfo"><a class="viewcode-back" href="../../../../server.html#mindspore_serving.server.register.AscendDeviceInfo">[docs]</a><span class="k">class</span> <span class="nc">AscendDeviceInfo</span><span class="p">(</span><span class="n">DeviceInfoContext</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper class to set Ascend device infos.</span>

<span class="sd">    Args:</span>
<span class="sd">        insert_op_cfg_path (str, optional): Path of aipp config file.</span>
<span class="sd">        input_format (str, optional): Manually specify the model input format, the value can be ``&quot;ND&quot;``, ``&quot;NCHW&quot;``,</span>
<span class="sd">            ``&quot;NHWC&quot;``, ``&quot;CHWN&quot;``, ``&quot;NC1HWC0&quot;``, or ``&quot;NHWC1C0&quot;``.</span>
<span class="sd">        input_shape (str, optional): Manually specify the model input shape, such as</span>
<span class="sd">            ``&quot;input_op_name1: n1,c2,h3,w4;input_op_name2: n4,c3,h2,w1&quot;``.</span>
<span class="sd">        output_type (str, optional): Manually specify the model output type, the value can be ``&quot;FP16&quot;``, ``&quot;UINT8&quot;``</span>
<span class="sd">            or ``&quot;FP32&quot;``. Default: ``&quot;FP32&quot;``.</span>
<span class="sd">        precision_mode (str, optional): Model precision mode, the value can be ``&quot;force_fp16&quot;``,</span>
<span class="sd">            ``&quot;allow_fp32_to_fp16&quot;``, ``&quot;must_keep_origin_dtype&quot;`` or ``&quot;allow_mix_precision&quot;``.</span>
<span class="sd">            Default: ``&quot;force_fp16&quot;``.</span>
<span class="sd">        op_select_impl_mode (str, optional): The operator selection mode, the value can be ``&quot;high_performance&quot;`` or</span>
<span class="sd">            ``&quot;high_precision&quot;``. Default: ``&quot;high_performance&quot;``.</span>
<span class="sd">        fusion_switch_config_path (str, optional): Configuration file path of the convergence rule, including graph</span>
<span class="sd">             convergence and UB convergence. The system has built-in graph convergence and UB convergence rules, which</span>
<span class="sd">             are enableed by default. You can disable the rules specified in the file by setting this parameter.</span>
<span class="sd">        buffer_optimize_mode (str, optional): The value can be ``&quot;l1_optimize&quot;``, ``&quot;l2_optimize&quot;``,</span>
<span class="sd">            ``&quot;off_optimize&quot;`` or ``&quot;l1_and_l2_optimize&quot;``. Default: ``&quot;l2_optimize&quot;``.</span>
<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: Ascend device info is invalid.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore_serving.server import register</span>
<span class="sd">        &gt;&gt;&gt; context = register.Context()</span>
<span class="sd">        &gt;&gt;&gt; context.append_device_info(register.AscendDeviceInfo(input_format=&quot;NCHW&quot;))</span>
<span class="sd">        &gt;&gt;&gt; model = register.declare_model(model_file=&quot;deeptext.ms&quot;, model_format=&quot;MindIR_Lite&quot;, context=context)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AscendDeviceInfo</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">insert_op_cfg_path</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_format</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">precision_mode</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op_select_impl_mode</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fusion_switch_config_path</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer_optimize_mode</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="n">val_set_fun</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;insert_op_cfg_path&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_insert_op_cfg_path</span><span class="p">,</span>
                       <span class="s2">&quot;input_format&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_input_format</span><span class="p">,</span>
                       <span class="s2">&quot;input_shape&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_input_shape</span><span class="p">,</span>
                       <span class="s2">&quot;output_type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_output_type</span><span class="p">,</span>
                       <span class="s2">&quot;precision_mode&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_precision_mode</span><span class="p">,</span>
                       <span class="s2">&quot;op_select_impl_mode&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_op_select_impl_mode</span><span class="p">,</span>
                       <span class="s2">&quot;fusion_switch_config_path&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_fusion_switch_config_path</span><span class="p">,</span>
                       <span class="s2">&quot;buffer_optimize_mode&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_buffer_optimize_mode</span><span class="p">}</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">val_set_fun</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Set ascend device info failed, unsupported parameter &quot;</span> <span class="o">+</span> <span class="n">k</span><span class="p">)</span>
            <span class="n">val_set_fun</span><span class="p">[</span><span class="n">k</span><span class="p">](</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_as_context_map</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_set_insert_op_cfg_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set option &#39;insert_op_cfg_path&#39;</span>

<span class="sd">        Args:</span>
<span class="sd">            val (str): Value of option &#39;insert_op_cfg_path&#39;.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: The type of value is not str.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_type</span><span class="o">.</span><span class="n">check_str</span><span class="p">(</span><span class="s1">&#39;insert_op_cfg_path&#39;</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">insert_op_cfg_path</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">_set_input_format</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set option &#39;input_format&#39;, manually specify the model input format, and the value can be</span>
<span class="sd">        &quot;ND&quot;, &quot;NCHW&quot;, &quot;NHWC&quot;, &quot;CHWN&quot;, &quot;NC1HWC0&quot;, or &quot;NHWC1C0&quot;.</span>

<span class="sd">        Args:</span>
<span class="sd">            val (str): Value of option &#39;input_format&#39;, and the value can be &quot;ND&quot;, &quot;NCHW&quot;, &quot;NHWC&quot;,</span>
<span class="sd">                &quot;CHWN&quot;, &quot;NC1HWC0&quot;, or &quot;NHWC1C0&quot;.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: The type of value is not str, or the value is invalid.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_type</span><span class="o">.</span><span class="n">check_str</span><span class="p">(</span><span class="s1">&#39;input_format&#39;</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">val</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;ND&quot;</span><span class="p">,</span> <span class="s2">&quot;NCHW&quot;</span><span class="p">,</span> <span class="s2">&quot;NHWC&quot;</span><span class="p">,</span> <span class="s2">&quot;CHWN&quot;</span><span class="p">,</span> <span class="s2">&quot;NC1HWC0&quot;</span><span class="p">,</span> <span class="s2">&quot;NHWC1C0&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ascend device info &#39;input_format&#39; can only be &#39;ND&#39;, &#39;NCHW&#39;, &#39;NHWC&#39;, &#39;CHWN&#39;, &#39;NC1HWC0&#39;&quot;</span>
                               <span class="sa">f</span><span class="s2">&quot;, or &#39;NHWC1C0&#39;, actually given &#39;</span><span class="si">{</span><span class="n">val</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_format</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">_set_input_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set option &#39;input_shape&#39;, manually specify the model input shape, such as</span>
<span class="sd">        &quot;input_op_name1: n1,c2,h3,w4;input_op_name2: n4,c3,h2,w1&quot;.</span>

<span class="sd">        Args:</span>
<span class="sd">            val (str): Value of option &#39;input_shape&#39;.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: The type of value is not str, or the value is invalid.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_type</span><span class="o">.</span><span class="n">check_str</span><span class="p">(</span><span class="s1">&#39;input_shape&#39;</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">_set_output_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set option &#39;output_type&#39;, manually specify the model output type, and the value can be &quot;FP16&quot;, &quot;UINT8&quot;, or</span>
<span class="sd">        &quot;FP32&quot;, default &quot;FP32&quot;.</span>

<span class="sd">        Args:</span>
<span class="sd">            val (str): Value of option &#39;output_type&#39;, and the value can be &quot;FP16&quot;, &quot;UINT8&quot;, or &quot;FP32&quot;, default &quot;FP32&quot;.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: The type of value is not str, or the value is invalid.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_type</span><span class="o">.</span><span class="n">check_str</span><span class="p">(</span><span class="s1">&#39;output_type&#39;</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">val</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;FP32&quot;</span><span class="p">,</span> <span class="s2">&quot;FP16&quot;</span><span class="p">,</span> <span class="s2">&quot;UINT8&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ascend device info &#39;op_select_impl_mode&#39; can only be &#39;FP32&#39;(default), &#39;FP16&#39; or &quot;</span>
                               <span class="sa">f</span><span class="s2">&quot;&#39;UINT8&#39;, actually given &#39;</span><span class="si">{</span><span class="n">val</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">_set_precision_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set option &#39;precision_mode&#39;,  which means operator selection mode, and the value can be &quot;force_fp16&quot;，</span>
<span class="sd">        &quot;force_fp16&quot;, &quot;must_keep_origin_dtype&quot;, or &quot;allow_mix_precision&quot;, default &quot;force_fp16&quot;.</span>

<span class="sd">        Args:</span>
<span class="sd">            val (str): Value of option &#39;precision_mode&#39;, and the value can be &quot;force_fp16&quot;， &quot;force_fp16&quot;,</span>
<span class="sd">                &quot;must_keep_origin_dtype&quot;, or &quot;allow_mix_precision&quot;, default &quot;force_fp16&quot;.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: The type of value is not str, or the value is invalid.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_type</span><span class="o">.</span><span class="n">check_str</span><span class="p">(</span><span class="s1">&#39;precision_mode&#39;</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">val</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;force_fp16&quot;</span><span class="p">,</span> <span class="s2">&quot;allow_fp32_to_fp16&quot;</span><span class="p">,</span> <span class="s2">&quot;must_keep_origin_dtype&quot;</span><span class="p">,</span> <span class="s2">&quot;allow_mix_precision&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ascend device info &#39;precision_mode&#39; can only be &#39;force_fp16&#39;(default), &quot;</span>
                               <span class="sa">f</span><span class="s2">&quot;&#39;allow_fp32_to_fp16&#39; &#39;must_keep_origin_dtype&#39; or &#39;allow_mix_precision&#39;, &quot;</span>
                               <span class="sa">f</span><span class="s2">&quot;actually given &#39;</span><span class="si">{</span><span class="n">val</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">precision_mode</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">_set_op_select_impl_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set option &#39;op_select_impl_mode&#39;, which means model precision mode, and the value can be &quot;high_performance&quot;</span>
<span class="sd">        or &quot;high_precision&quot;,  default &quot;high_performance&quot;.</span>

<span class="sd">        Args:</span>
<span class="sd">            val (str): Value of option &#39;op_select_impl_mode&#39;，which can be &quot;high_performance&quot; or &quot;high_precision&quot;,</span>
<span class="sd">                default &quot;high_performance&quot;.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: The type of value is not str, or the value is invalid.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_type</span><span class="o">.</span><span class="n">check_str</span><span class="p">(</span><span class="s1">&#39;op_select_impl_mode&#39;</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">val</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;high_performance&quot;</span><span class="p">,</span> <span class="s2">&quot;high_precision&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ascend device info &#39;op_select_impl_mode&#39; can only be &#39;high_performance&#39;(default) or &quot;</span>
                               <span class="sa">f</span><span class="s2">&quot;&#39;high_precision&#39;, actually given &#39;</span><span class="si">{</span><span class="n">val</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op_select_impl_mode</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">_set_fusion_switch_config_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
        <span class="n">check_type</span><span class="o">.</span><span class="n">check_str</span><span class="p">(</span><span class="s1">&#39;fusion_switch_config_path&#39;</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fusion_switch_config_path</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">_set_buffer_optimize_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
        <span class="n">check_type</span><span class="o">.</span><span class="n">check_str</span><span class="p">(</span><span class="s1">&#39;buffer_optimize_mode&#39;</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">val</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;l1_optimize&quot;</span><span class="p">,</span> <span class="s2">&quot;l2_optimize&quot;</span><span class="p">,</span> <span class="s2">&quot;off_optimize&quot;</span><span class="p">,</span> <span class="s2">&quot;l1_and_l2_optimize&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ascend device info &#39;buffer_optimize_mode&#39; can only be &#39;off_optimize&#39;(default), &quot;</span>
                               <span class="sa">f</span><span class="s2">&quot;&#39;l1_optimize&#39;, &#39;l2_optimize&#39; or &#39;l1_and_l2_optimize&#39;, actually given &#39;</span><span class="si">{</span><span class="n">val</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer_optimize_mode</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">_as_context_map</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transfer acl device info to dict of str,str&quot;&quot;&quot;</span>
        <span class="n">context_map</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">insert_op_cfg_path</span><span class="p">:</span>
            <span class="n">context_map</span><span class="p">[</span><span class="s2">&quot;insert_op_cfg_path&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">insert_op_cfg_path</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_format</span><span class="p">:</span>
            <span class="n">context_map</span><span class="p">[</span><span class="s2">&quot;input_format&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_format</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span><span class="p">:</span>
            <span class="n">context_map</span><span class="p">[</span><span class="s2">&quot;input_shape&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span><span class="p">:</span>
            <span class="n">context_map</span><span class="p">[</span><span class="s2">&quot;output_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">precision_mode</span><span class="p">:</span>
            <span class="n">context_map</span><span class="p">[</span><span class="s2">&quot;precision_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">precision_mode</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">op_select_impl_mode</span><span class="p">:</span>
            <span class="n">context_map</span><span class="p">[</span><span class="s2">&quot;op_select_impl_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op_select_impl_mode</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_optimize_mode</span><span class="p">:</span>
            <span class="n">context_map</span><span class="p">[</span><span class="s2">&quot;buffer_optimize_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_optimize_mode</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion_switch_config_path</span><span class="p">:</span>
            <span class="n">context_map</span><span class="p">[</span><span class="s2">&quot;fusion_switch_config_path&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion_switch_config_path</span>
        <span class="n">context_map</span><span class="p">[</span><span class="s2">&quot;device_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;ascend&quot;</span>
        <span class="k">return</span> <span class="n">context_map</span></div>


<span class="k">class</span> <span class="nc">AclOptions</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper class to set Ascend device infos.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        &#39;AclOptions&#39; is deprecated from version 1.6.0 and will be removed in a future version, use</span>
<span class="sd">        :class:`mindspore_serving.server.register.AscendDeviceInfo` instead.</span>

<span class="sd">    Args:</span>
<span class="sd">        insert_op_cfg_path (str, optional): Path of aipp config file.</span>
<span class="sd">        input_format (str, optional): Manually specify the model input format, the value can be ``&quot;ND&quot;``, ``&quot;NCHW&quot;``,</span>
<span class="sd">            ``&quot;NHWC&quot;``, ``&quot;CHWN&quot;``, ``&quot;NC1HWC0&quot;``, or ``&quot;NHWC1C0&quot;``.</span>
<span class="sd">        input_shape (str, optional): Manually specify the model input shape, such as</span>
<span class="sd">            ``&quot;input_op_name1: n1,c2,h3,w4;input_op_name2: n4,c3,h2,w1&quot;``.</span>
<span class="sd">        output_type (str, optional): Manually specify the model output type, the value can be ``&quot;FP16&quot;``, ``&quot;UINT8&quot;`` or</span>
<span class="sd">            ``&quot;FP32&quot;``. Default: ``&quot;FP32&quot;``.</span>
<span class="sd">        precision_mode (str, optional): Model precision mode, the value can be ``&quot;force_fp16&quot;``,</span>
<span class="sd">            ``&quot;allow_fp32_to_fp16&quot;``, ``&quot;must_keep_origin_dtype&quot;`` or ``&quot;allow_mix_precision&quot;``.</span>
<span class="sd">            Default: ``&quot;force_fp16&quot;``.</span>
<span class="sd">        op_select_impl_mode (str, optional): The operator selection mode, the value can be ``&quot;high_performance&quot;`` or</span>
<span class="sd">            ``&quot;high_precision&quot;``. Default: ``&quot;high_performance&quot;``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: Acl option is invalid, or value is not str.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore_serving.server import register</span>
<span class="sd">        &gt;&gt;&gt; options = register.AclOptions(op_select_impl_mode=&quot;high_precision&quot;, precision_mode=&quot;allow_fp32_to_fp16&quot;)</span>
<span class="sd">        &gt;&gt;&gt; register.declare_servable(servable_file=&quot;deeptext.mindir&quot;, model_format=&quot;MindIR&quot;, options=options)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AclOptions</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;&#39;AclOptions&#39; is deprecated from version 1.6.0 and will be removed in a future version, &quot;</span>
                       <span class="s2">&quot;use &#39;mindspore_serving.server.register.AscendDeviceInfo&#39; instead.&quot;</span><span class="p">)</span>
        <span class="n">device_info</span> <span class="o">=</span> <span class="n">AscendDeviceInfo</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context</span> <span class="o">=</span> <span class="n">Context</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="o">.</span><span class="n">append_device_info</span><span class="p">(</span><span class="n">device_info</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">GpuOptions</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper class to set gpu options.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        &#39;GpuOptions&#39; is deprecated from version 1.6.0 and will be removed in a future version, use</span>
<span class="sd">        :class:`mindspore_serving.server.register.GPUDeviceInfo` instead.</span>

<span class="sd">    Args:</span>
<span class="sd">        precision_mode(str, optional): inference operator selection, and the value can be ``&quot;origin&quot;``, ``&quot;fp16&quot;``.</span>
<span class="sd">            Default: ``&quot;origin&quot;``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: Gpu option is invalid, or value is not str.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore_serving.server import register</span>
<span class="sd">        &gt;&gt;&gt; options = register.GpuOptions(precision_mode=&quot;origin&quot;)</span>
<span class="sd">        &gt;&gt;&gt; register.declare_servable(servable_file=&quot;deeptext.mindir&quot;, model_format=&quot;MindIR&quot;, options=options)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GpuOptions</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;&#39;GpuOptions&#39; is deprecated from version 1.6.0 and will be removed in a future version, &quot;</span>
                       <span class="s2">&quot;use &#39;mindspore_serving.server.register.GPUDeviceInfo&#39; instead.&quot;</span><span class="p">)</span>
        <span class="n">device_info</span> <span class="o">=</span> <span class="n">GPUDeviceInfo</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context</span> <span class="o">=</span> <span class="n">Context</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="o">.</span><span class="n">append_device_info</span><span class="p">(</span><span class="n">device_info</span><span class="p">)</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>