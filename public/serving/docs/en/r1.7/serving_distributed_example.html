<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>MindSpore Serving-based Distributed Inference Service Deployment &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="gRPC-based MindSpore Serving Access" href="serving_grpc.html" />
    <link rel="prev" title="MindSpore Serving-based Inference Service Deployment" href="serving_example.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="serving_install.html">MindSpore Serving Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="serving_example.html">MindSpore Serving-based Inference Service Deployment</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">MindSpore Serving-based Distributed Inference Service Deployment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#environment-preparation">Environment Preparation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#exporting-a-distributed-model">Exporting a Distributed Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deploying-the-distributed-inference-service">Deploying the Distributed Inference Service</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#starting-serving-server">Starting Serving Server</a></li>
<li class="toctree-l4"><a class="reference internal" href="#starting-agent">Starting Agent</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#executing-inference">Executing Inference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="serving_grpc.html">gRPC-based MindSpore Serving Access</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_restful.html">RESTful-based MindSpore Serving Access</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_model.html">Servable Provided Through Model Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_multi_subgraphs.html">Service Deployment with Multiple Subgraphs and Stateful Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="server.html">mindspore_serving.server</a></li>
<li class="toctree-l1"><a class="reference internal" href="client.html">mindspore_serving.client</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>MindSpore Serving-based Distributed Inference Service Deployment</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/serving_distributed_example.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="mindspore-serving-based-distributed-inference-service-deployment">
<h1>MindSpore Serving-based Distributed Inference Service Deployment<a class="headerlink" href="#mindspore-serving-based-distributed-inference-service-deployment" title="Permalink to this headline"></a></h1>
<p>Translator: <a class="reference external" href="https://gitee.com/xiaoxinniuniu">xiaoxiaozhang</a></p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.7/docs/serving/docs/source_en/serving_distributed_example.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.7/resource/_static/logo_source_en.png" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>Distributed inference means that multiple cards are used in the inference phase, in order to solve the problem that too many parameters are in the very large scale neural network and the model cannot be fully loaded into a single card for inference, multi-cards can be used for distributed inference. This document describes the process of deploying the distributed inference service, which is similar to the process of deploying the <a class="reference external" href="https://www.mindspore.cn/serving/docs/en/r1.7/serving_example.html">single-card inference service</a>, and these two can refer to each other.</p>
<p>The architecture of the distributed inference service shows as follows：</p>
<p><img alt="image" src="_images/distributed_servable.png" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">Main</span></code> process provides an interface for client access, manages <code class="docutils literal notranslate"><span class="pre">Distributed</span> <span class="pre">Worker</span></code> process, and performs task management and distribution; <code class="docutils literal notranslate"><span class="pre">Distributed</span> <span class="pre">Worker</span></code> automatically schedule <code class="docutils literal notranslate"><span class="pre">Agent</span></code> processes based on model configurations to complete distributed inference; Each <code class="docutils literal notranslate"><span class="pre">Agent</span></code> contains a slice of the distributed model, occupies a device, and loads the model to performance inference.</p>
<p>The preceding figure shows the scenario where rank_size is 16 and stage_size is 2. Each stage contains 8 <code class="docutils literal notranslate"><span class="pre">Agent</span></code>s and occupies 8 devices. rank_size indicates the number of devices used in inference, stage indicates a pipeline segment, and stage_size indicates the number of pipeline segments. The <code class="docutils literal notranslate"><span class="pre">Distributed</span> <span class="pre">Worker</span></code> sends an inference requests to the <code class="docutils literal notranslate"><span class="pre">Agent</span></code>s and obtains the inference result from the <code class="docutils literal notranslate"><span class="pre">Agent</span></code>s. <code class="docutils literal notranslate"><span class="pre">Agent</span></code>s communicate with each other using HCCL.</p>
<p>Currently, the distributed model has the following restrictions:</p>
<ul class="simple">
<li><p>The model of the first stage receives the same input data.</p></li>
<li><p>The models of other stages do not receive data.</p></li>
<li><p>All models of the latter stage return the same data.</p></li>
<li><p>Only Ascend 910 inference is supported.</p></li>
</ul>
<p>The following uses a simple distributed network MatMul as an example to demonstrate the deployment process.</p>
<section id="environment-preparation">
<h3>Environment Preparation<a class="headerlink" href="#environment-preparation" title="Permalink to this headline"></a></h3>
<p>Before running the sample network, ensure that MindSpore Serving has been properly installed and the environment variables are configured. To install and configure MindSpore Serving on your PC, go to the <a class="reference external" href="https://www.mindspore.cn/serving/docs/en/r1.7/serving_install.html">MindSpore Serving installation page</a>.</p>
</section>
<section id="exporting-a-distributed-model">
<h3>Exporting a Distributed Model<a class="headerlink" href="#exporting-a-distributed-model" title="Permalink to this headline"></a></h3>
<p>For details about the files required for exporting distributed models, see the <a class="reference external" href="https://gitee.com/mindspore/serving/tree/r1.7/example/matmul_distributed/export_model">export_model directory</a>, the following files are required:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>export_model
├── distributed_inference.py
├── export_model.sh
├── net.py
└── rank_table_8pcs.json
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">net.py</span></code> contains the definition of MatMul network.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">distributed_inference.py</span></code> is used to configure distributed parameters.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">export_model.sh</span></code> creates <code class="docutils literal notranslate"><span class="pre">device</span></code> directory on the current host and exports model files corresponding to <code class="docutils literal notranslate"><span class="pre">device</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rank_table_8pcs.json</span></code> is a json file for configuring the multi-cards network. For details, see <a class="reference external" href="https://gitee.com/mindspore/models/tree/r1.7/utils/hccl_tools">rank_table</a>.</p></li>
</ul>
<p>Use <a class="reference external" href="https://gitee.com/mindspore/serving/blob/r1.7/example/matmul_distributed/export_model/net.py">net.py</a> to construct a network that contains the MatMul and Neg operators.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Cell</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">matmul_size</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">matmul_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">matmul_size</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">matmul_weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">matmul_np</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">matmul</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="n">transpose_a</span><span class="o">=</span><span class="n">transpose_a</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="n">transpose_b</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neg</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Neg</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">strategy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">matmul</span><span class="o">.</span><span class="n">shard</span><span class="p">(</span><span class="n">strategy</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul_weight</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<p>Use <a class="reference external" href="https://gitee.com/mindspore/serving/blob/r1.7/example/matmul_distributed/export_model/distributed_inference.py">distributed_inference.py</a> to configure the distributed model. Refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r1.7/parallel/distributed_inference.html">Distributed inference</a>。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">net</span> <span class="kn">import</span> <span class="n">Net</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span><span class="p">,</span> <span class="n">Model</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">export</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>


<span class="k">def</span> <span class="nf">test_inference</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;distributed inference after distributed training&quot;&quot;&quot;</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
    <span class="n">init</span><span class="p">(</span><span class="n">backend_name</span><span class="o">=</span><span class="s2">&quot;hccl&quot;</span><span class="p">)</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">full_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parallel_mode</span><span class="o">=</span><span class="s2">&quot;semi_auto_parallel&quot;</span><span class="p">,</span>
                                      <span class="n">device_num</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">group_ckpt_save_file</span><span class="o">=</span><span class="s2">&quot;./group_config.pb&quot;</span><span class="p">)</span>

    <span class="n">predict_data</span> <span class="o">=</span> <span class="n">create_predict_data</span><span class="p">()</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">matmul_size</span><span class="o">=</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">infer_predict_layout</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">predict_data</span><span class="p">))</span>
    <span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict_network</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">predict_data</span><span class="p">),</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">&quot;matmul&quot;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s2">&quot;MINDIR&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">create_predict_data</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;user-defined predict data&quot;&quot;&quot;</span>
    <span class="n">inputs_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">96</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">inputs_np</span><span class="p">)</span>
</pre></div>
</div>
<p>Run <a class="reference external" href="https://gitee.com/mindspore/serving/blob/r1.7/example/matmul_distributed/export_model/export_model.sh">export_model.sh</a> to export the distributed model. After the command is executed successfully, the <code class="docutils literal notranslate"><span class="pre">model</span></code> directory is created in the upper-level directory. The structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>model
├── device0
│   ├── group_config.pb
│   └── matmul.mindir
├── device1
├── device2
├── device3
├── device4
├── device5
├── device6
└── device7
</pre></div>
</div>
<p>Each <code class="docutils literal notranslate"><span class="pre">device</span></code> directory contains two files, <code class="docutils literal notranslate"><span class="pre">group_config.pb</span></code> and <code class="docutils literal notranslate"><span class="pre">matmul.mindir</span></code>, which represent the model group configuration file and model file respectively.</p>
</section>
<section id="deploying-the-distributed-inference-service">
<h3>Deploying the Distributed Inference Service<a class="headerlink" href="#deploying-the-distributed-inference-service" title="Permalink to this headline"></a></h3>
<p>For details about how to start the distributed inference service, refer to <a class="reference external" href="https://gitee.com/mindspore/serving/tree/r1.7/example/matmul_distributed">matmul_distributed</a>, the following files are required:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>matmul_distributed
├── serving_agent.py
├── serving_server.py
├── matmul
│   └── servable_config.py
├── model
└── rank_table_8pcs.json
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model</span></code> is the directory for storing model files.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">serving_server.py</span></code> is the script for starting services, including <code class="docutils literal notranslate"><span class="pre">Main</span></code> process and <code class="docutils literal notranslate"><span class="pre">Distributed</span> <span class="pre">Worker</span></code> process.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">serving_agent.py</span></code> is the script for starting <code class="docutils literal notranslate"><span class="pre">Agent</span></code>s.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">servable_config.py</span></code> is the <a class="reference external" href="https://www.mindspore.cn/serving/docs/en/r1.7/serving_model.html">Model Configuration File</a>. It declares a distributed model with rank_size 8 and stage_size 1 through <code class="docutils literal notranslate"><span class="pre">declare_distributed_servable</span></code>, and defines a method <code class="docutils literal notranslate"><span class="pre">predict</span></code> for distributed servable.</p></li>
</ul>
<p>The content of the model configuration file is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">distributed</span>
<span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">register</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">distributed</span><span class="o">.</span><span class="n">declare_servable</span><span class="p">(</span><span class="n">rank_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stage_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">with_batch_dim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="nd">@register</span><span class="o">.</span><span class="n">register_method</span><span class="p">(</span><span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
<section id="starting-serving-server">
<h4>Starting Serving Server<a class="headerlink" href="#starting-serving-server" title="Permalink to this headline"></a></h4>
<p>Use <a class="reference external" href="https://gitee.com/mindspore/serving/blob/r1.7/example/matmul_distributed/serving_server.py">serving_server.py</a> to call <code class="docutils literal notranslate"><span class="pre">distributed.start_servable</span></code> method to deploy the serving sever, including the <code class="docutils literal notranslate"><span class="pre">Main</span></code> and <code class="docutils literal notranslate"><span class="pre">Distributed</span> <span class="pre">Worker</span></code> processes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">mindspore_serving</span> <span class="kn">import</span> <span class="n">server</span>
<span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">distributed</span>


<span class="k">def</span> <span class="nf">start</span><span class="p">():</span>
    <span class="n">servable_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">realpath</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">distributed</span><span class="o">.</span><span class="n">start_servable</span><span class="p">(</span><span class="n">servable_dir</span><span class="p">,</span> <span class="s2">&quot;matmul&quot;</span><span class="p">,</span>
                               <span class="n">rank_table_json_file</span><span class="o">=</span><span class="s2">&quot;rank_table_8pcs.json&quot;</span><span class="p">,</span>
                               <span class="n">version_number</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                               <span class="n">distributed_address</span><span class="o">=</span><span class="s2">&quot;127.0.0.1:6200&quot;</span><span class="p">,</span>
                               <span class="n">wait_agents_time_in_seconds</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">server</span><span class="o">.</span><span class="n">start_grpc_server</span><span class="p">(</span><span class="s2">&quot;127.0.0.1:5500&quot;</span><span class="p">)</span>
    <span class="n">server</span><span class="o">.</span><span class="n">start_restful_server</span><span class="p">(</span><span class="s2">&quot;127.0.0.1:1500&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">start</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">servable_dir</span></code> is the directory for storing a servable.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">servable_name</span></code> is the name of the servable, which corresponds to a directory for storing model configuration files.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rank_table_json_file</span></code> is the JSON file for configuring multi-cards network.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">distributed_address</span></code> is the address of the <code class="docutils literal notranslate"><span class="pre">Distributed</span> <span class="pre">Worker</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">wait_agents_time_in_seconds</span></code> specifies the duration of waiting for all <code class="docutils literal notranslate"><span class="pre">Agent</span></code>s to be registered, the default value 0 means it will wait forever.</p></li>
</ul>
</section>
<section id="starting-agent">
<h4>Starting Agent<a class="headerlink" href="#starting-agent" title="Permalink to this headline"></a></h4>
<p>Use <a class="reference external" href="https://gitee.com/mindspore/serving/blob/r1.7/example/matmul_distributed/serving_agent.py">serving_agent.py</a> to call <code class="docutils literal notranslate"><span class="pre">startup_agents</span></code> method to start 8 <code class="docutils literal notranslate"><span class="pre">Agent</span></code> processes on the current host. <code class="docutils literal notranslate"><span class="pre">Agent</span></code>s obtain rank_tables from <code class="docutils literal notranslate"><span class="pre">Distributed</span> <span class="pre">Worker</span></code> so that <code class="docutils literal notranslate"><span class="pre">Agent</span></code>s can communicate with each other using HCCL.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">distributed</span>


<span class="k">def</span> <span class="nf">start_agents</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Start all the agents in current machine&quot;&quot;&quot;</span>
    <span class="n">model_files</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">group_configs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">):</span>
        <span class="n">model_files</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;model/device</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/matmul.mindir&quot;</span><span class="p">)</span>
        <span class="n">group_configs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;model/device</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/group_config.pb&quot;</span><span class="p">)</span>

    <span class="n">distributed</span><span class="o">.</span><span class="n">startup_agents</span><span class="p">(</span><span class="n">distributed_address</span><span class="o">=</span><span class="s2">&quot;127.0.0.1:6200&quot;</span><span class="p">,</span> <span class="n">model_files</span><span class="o">=</span><span class="n">model_files</span><span class="p">,</span>
                               <span class="n">group_config_files</span><span class="o">=</span><span class="n">group_configs</span><span class="p">,</span> <span class="n">agent_start_port</span><span class="o">=</span><span class="mi">7000</span><span class="p">,</span>
                               <span class="n">agent_ip</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rank_start</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">start_agents</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">distributed_address</span></code> is the address of the <code class="docutils literal notranslate"><span class="pre">Distributed</span> <span class="pre">Worker</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model_files</span></code> is a list of model file paths.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">group_config_files</span></code> is a list of model group configuration file paths.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">agent_start_port</span></code> is the start port used by the <code class="docutils literal notranslate"><span class="pre">Agent</span></code>. The default value is 7000.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">agent_ip</span></code> is the IP address of an <code class="docutils literal notranslate"><span class="pre">Agent</span></code>. The default value is None. The IP address used by the <code class="docutils literal notranslate"><span class="pre">Agent</span></code> to communicate with the <code class="docutils literal notranslate"><span class="pre">Distributed</span> <span class="pre">Worker</span></code> is obtained from rank_table by default. If the IP address is unavailable, you need to set both <code class="docutils literal notranslate"><span class="pre">agent_ip</span></code> and <code class="docutils literal notranslate"><span class="pre">rank_start</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rank_start</span></code> is the start rank_id of the current server, the default value is None.</p></li>
</ul>
</section>
</section>
<section id="executing-inference">
<h3>Executing Inference<a class="headerlink" href="#executing-inference" title="Permalink to this headline"></a></h3>
<p>To access the inference service through gRPC, the client needs to specify the network address of the gRPC server. Run <a class="reference external" href="https://gitee.com/mindspore/serving/blob/r1.7/example/matmul_distributed/serving_client.py">serving_client.py</a> to call the <code class="docutils literal notranslate"><span class="pre">predict</span></code> method of matmul distributed model, execute inference.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore_serving.client</span> <span class="kn">import</span> <span class="n">Client</span>


<span class="k">def</span> <span class="nf">run_matmul</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run client of distributed matmul&quot;&quot;&quot;</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s2">&quot;localhost:5500&quot;</span><span class="p">,</span> <span class="s2">&quot;matmul&quot;</span><span class="p">,</span> <span class="s2">&quot;predict&quot;</span><span class="p">)</span>
    <span class="n">instance</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)}</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;result:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">run_matmul</span><span class="p">()</span>
</pre></div>
</div>
<p>The following return value indicates that the Serving distributed inference service has correctly executed the inference of MatMul net:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>result:
[{&#39;y&#39;: array([[-48., -48., -48., ..., -48., -48., -48.],
      [-48., -48., -48., ..., -48., -48., -48.],
      [-48., -48., -48., ..., -48., -48., -48.],
      ...,
      [-48., -48., -48., ..., -48., -48., -48.],
      [-48., -48., -48., ..., -48., -48., -48.],
      [-48., -48., -48., ..., -48., -48., -48.]], dtype=float32)}]
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="serving_example.html" class="btn btn-neutral float-left" title="MindSpore Serving-based Inference Service Deployment" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="serving_grpc.html" class="btn btn-neutral float-right" title="gRPC-based MindSpore Serving Access" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>