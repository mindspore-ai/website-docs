<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>MindSpore Serving-based Inference Service Deployment &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="MindSpore Serving-based Distributed Inference Service Deployment" href="serving_distributed_example.html" />
    <link rel="prev" title="MindSpore Serving Installation" href="serving_install.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="serving_install.html">MindSpore Serving Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">MindSpore Serving-based Inference Service Deployment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#preparing-the-environment">Preparing the Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="#downloading-the-example">Downloading the Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="#exporting-the-model">Exporting the Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#deploying-the-serving-inference-service">Deploying the Serving Inference Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#configuring-the-service">Configuring the Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="#starting-the-service">Starting the Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#inference-execution">Inference Execution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="serving_distributed_example.html">MindSpore Serving-based Distributed Inference Service Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_grpc.html">gRPC-based MindSpore Serving Access</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_restful.html">RESTful-based MindSpore Serving Access</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_model.html">Servable Provided Through Model Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_multi_subgraphs.html">Service Deployment with Multiple Subgraphs and Stateful Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="server.html">mindspore_serving.server</a></li>
<li class="toctree-l1"><a class="reference internal" href="client.html">mindspore_serving.client</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>MindSpore Serving-based Inference Service Deployment</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/serving_example.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="mindspore-serving-based-inference-service-deployment">
<h1>MindSpore Serving-based Inference Service Deployment<a class="headerlink" href="#mindspore-serving-based-inference-service-deployment" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.2/docs/serving/docs/source_en/serving_example.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.2/resource/_static/logo_source_en.svg" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>MindSpore Serving is a lightweight and high-performance service module that helps MindSpore developers efficiently deploy online inference services in the production environment. After completing model training on MindSpore, you can export the MindSpore model and use MindSpore Serving to create an inference service for the model.</p>
<p>The following uses a simple <code class="docutils literal notranslate"><span class="pre">Add</span></code> network as an example to describe how to use MindSpore Serving.</p>
</section>
<section id="preparing-the-environment">
<h2>Preparing the Environment<a class="headerlink" href="#preparing-the-environment" title="Permalink to this headline"></a></h2>
<p>Before running the sample network, ensure that MindSpore Serving has been properly installed and the environment variables are configured. To install and configure MindSpore Serving on your PC, go to the <a class="reference external" href="https://www.mindspore.cn/serving/docs/en/r2.0/serving_install.html">MindSpore Serving installation page</a>.</p>
</section>
<section id="downloading-the-example">
<h2>Downloading the Example<a class="headerlink" href="#downloading-the-example" title="Permalink to this headline"></a></h2>
<p>Please download the <a class="reference external" href="https://gitee.com/mindspore/serving/tree/r2.0/example/tensor_add/">add example</a> first.</p>
</section>
<section id="exporting-the-model">
<h2>Exporting the Model<a class="headerlink" href="#exporting-the-model" title="Permalink to this headline"></a></h2>
<p>In the directory <code class="docutils literal notranslate"><span class="pre">export_model</span></code>, use <a class="reference external" href="https://gitee.com/mindspore/serving/blob/r2.0/example/tensor_add/export_model/add_model.py">add_model.py</a> to build a network with only the Add operator and export the MindSpore inference deployment model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">copyfile</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Define Net of add&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Add</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_</span><span class="p">,</span> <span class="n">y_</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;construct add net&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span> <span class="n">y_</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">export_net</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Export add net of 2x2 + 2x2, and copy output model `tensor_add.mindir` to directory ../add/1&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">add</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">add</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;tensor_add&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;MINDIR&#39;</span><span class="p">)</span>
    <span class="n">dst_dir</span> <span class="o">=</span> <span class="s1">&#39;../add/1&#39;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">dst_dir</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">OSError</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="n">dst_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dst_dir</span><span class="p">,</span> <span class="s1">&#39;tensor_add.mindir&#39;</span><span class="p">)</span>
    <span class="n">copyfile</span><span class="p">(</span><span class="s1">&#39;tensor_add.mindir&#39;</span><span class="p">,</span> <span class="n">dst_file</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;copy tensor_add.mindir to &quot;</span> <span class="o">+</span> <span class="n">dst_dir</span> <span class="o">+</span> <span class="s2">&quot; success&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">export_net</span><span class="p">()</span>
</pre></div>
</div>
<p>To use MindSpore for neural network definition, inherit <code class="docutils literal notranslate"><span class="pre">mindspore.nn.Cell</span></code>. (A <code class="docutils literal notranslate"><span class="pre">Cell</span></code> is a base class of all neural networks.) Define each layer of a neural network in the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> method in advance, and then define the <code class="docutils literal notranslate"><span class="pre">construct</span></code> method to complete the forward construction of the neural network. Use <code class="docutils literal notranslate"><span class="pre">export</span></code> of the <code class="docutils literal notranslate"><span class="pre">mindspore</span></code> module to export the model file.
For more detailed examples, see <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.2/beginner/quick_start.html">Quick Start for Beginners</a>.</p>
<p>Execute the <code class="docutils literal notranslate"><span class="pre">add_model.py</span></code> script to generate the <code class="docutils literal notranslate"><span class="pre">tensor_add.mindir</span></code> file. The input of the model is two 2D tensors with shape [2,2], and the output is the sum of the two input tensors.</p>
</section>
<section id="deploying-the-serving-inference-service">
<h2>Deploying the Serving Inference Service<a class="headerlink" href="#deploying-the-serving-inference-service" title="Permalink to this headline"></a></h2>
<section id="configuring-the-service">
<h3>Configuring the Service<a class="headerlink" href="#configuring-the-service" title="Permalink to this headline"></a></h3>
<p>Start Serving with the following files:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>tensor_add
├── add/
│   │── servable_config.py
│   └── 1/
│       └── tensor_add.mindir
└── serving_server.py
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">serving_server.py</span></code>: Script file for starting the service.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">add</span></code>: Model folder, which is named after the model name.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tensor_add.mindir</span></code>: Model file generated by the network in the previous step, which is stored in folder 1 (the number indicates the version number). Different versions are stored in different folders. The version number must be a string of digits. By default, the latest model file is started.</p></li>
<li><p><a class="reference external" href="https://gitee.com/mindspore/serving/blob/r2.0/example/tensor_add/add/servable_config.py">servable_config.py</a>: <a class="reference external" href="https://www.mindspore.cn/serving/docs/en/r2.0/serving_model.html">Model configuration file</a>, which defines the model processing functions, including the <code class="docutils literal notranslate"><span class="pre">add_common</span></code> and <code class="docutils literal notranslate"><span class="pre">add_cast</span></code> methods. <code class="docutils literal notranslate"><span class="pre">add_common</span></code> defines an addition operation whose input is two pieces of float32 data, and <code class="docutils literal notranslate"><span class="pre">add_cast</span></code> defines an addition operation whose input is data with its type converted to float32.</p></li>
</ul>
<p>Content of the configuration file:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">register</span>


<span class="k">def</span> <span class="nf">add_trans_datatype</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;define preprocess, this example has two inputs and two outputs&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">x1</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">x2</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>


<span class="c1"># when with_batch_dim is set to False, only 2x2 add is supported</span>
<span class="c1"># when with_batch_dim is set to True(default), Nx2 add is supported, while N is viewed as batch</span>
<span class="c1"># float32 inputs/outputs</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">declare_model</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s2">&quot;tensor_add.mindir&quot;</span><span class="p">,</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR&quot;</span><span class="p">,</span> <span class="n">with_batch_dim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="c1"># register add_common method in add</span>
<span class="nd">@register</span><span class="o">.</span><span class="n">register_method</span><span class="p">(</span><span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">add_common</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>  <span class="c1"># only support float32 inputs</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;method add_common data flow definition, only call model&quot;&quot;&quot;</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>


<span class="c1"># register add_cast method in add</span>
<span class="nd">@register</span><span class="o">.</span><span class="n">register_method</span><span class="p">(</span><span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">add_cast</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;method add_cast data flow definition, only preprocessing and call model&quot;&quot;&quot;</span>
    <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">add_trans_datatype</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># cast input to float32</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
</section>
<section id="starting-the-service">
<h3>Starting the Service<a class="headerlink" href="#starting-the-service" title="Permalink to this headline"></a></h3>
<p>Run the <a class="reference external" href="https://gitee.com/mindspore/serving/blob/r2.0/example/tensor_add/serving_server.py">serving_server.py</a> script to start the Serving server:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">mindspore_serving</span> <span class="kn">import</span> <span class="n">server</span>


<span class="k">def</span> <span class="nf">start</span><span class="p">():</span>
    <span class="n">servable_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">realpath</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

    <span class="n">servable_config</span> <span class="o">=</span> <span class="n">server</span><span class="o">.</span><span class="n">ServableStartConfig</span><span class="p">(</span><span class="n">servable_directory</span><span class="o">=</span><span class="n">servable_dir</span><span class="p">,</span> <span class="n">servable_name</span><span class="o">=</span><span class="s2">&quot;add&quot;</span><span class="p">,</span>
                                                 <span class="n">device_ids</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">server</span><span class="o">.</span><span class="n">start_servables</span><span class="p">(</span><span class="n">servable_configs</span><span class="o">=</span><span class="n">servable_config</span><span class="p">)</span>

    <span class="n">server</span><span class="o">.</span><span class="n">start_grpc_server</span><span class="p">(</span><span class="n">address</span><span class="o">=</span><span class="s2">&quot;127.0.0.1:5500&quot;</span><span class="p">)</span>
    <span class="n">server</span><span class="o">.</span><span class="n">start_restful_server</span><span class="p">(</span><span class="n">address</span><span class="o">=</span><span class="s2">&quot;127.0.0.1:1500&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">start</span><span class="p">()</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">start_servables</span></code> in the above startup script will load and run two inference copies of <code class="docutils literal notranslate"><span class="pre">add</span></code> on devices 0 and 1, and the inference requests from the client will be split to the two inference copies.</p>
<p>If the following log information is displayed on the server, the gRPC and RESTful services are started successfully.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Serving gRPC server start success, listening on 127.0.0.1:5500
Serving RESTful server start success, listening on 127.0.0.1:1500
</pre></div>
</div>
</section>
</section>
<section id="inference-execution">
<h2>Inference Execution<a class="headerlink" href="#inference-execution" title="Permalink to this headline"></a></h2>
<p>The client can access the inference service through either <a class="reference external" href="https://www.mindspore.cn/serving/docs/en/r2.0/serving_grpc.html">gRPC</a> or <a class="reference external" href="https://www.mindspore.cn/serving/docs/en/r2.0/serving_restful.html">RESTful</a>. The following uses gRPC as an example.
Execute <a class="reference external" href="https://gitee.com/mindspore/serving/blob/r2.0/example/tensor_add/serving_client.py">serving_client.py</a> to start the Python client.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore_serving.client</span> <span class="kn">import</span> <span class="n">Client</span>


<span class="k">def</span> <span class="nf">run_add_common</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;invoke servable add method add_common&quot;&quot;&quot;</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s2">&quot;127.0.0.1:5500&quot;</span><span class="p">,</span> <span class="s2">&quot;add&quot;</span><span class="p">,</span> <span class="s2">&quot;add_common&quot;</span><span class="p">)</span>
    <span class="n">instances</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># instance 1</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">instances</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;x1&quot;</span><span class="p">:</span> <span class="n">x1</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">:</span> <span class="n">x2</span><span class="p">})</span>

    <span class="c1"># instance 2</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">instances</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;x1&quot;</span><span class="p">:</span> <span class="n">x1</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">:</span> <span class="n">x2</span><span class="p">})</span>

    <span class="c1"># instance 3</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">instances</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;x1&quot;</span><span class="p">:</span> <span class="n">x1</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">:</span> <span class="n">x2</span><span class="p">})</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">instances</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">run_add_cast</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;invoke servable add method add_cast&quot;&quot;&quot;</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s2">&quot;127.0.0.1:5500&quot;</span><span class="p">,</span> <span class="s2">&quot;add&quot;</span><span class="p">,</span> <span class="s2">&quot;add_cast&quot;</span><span class="p">)</span>
    <span class="n">instances</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">instances</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;x1&quot;</span><span class="p">:</span> <span class="n">x1</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">:</span> <span class="n">x2</span><span class="p">})</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">instances</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">run_add_common</span><span class="p">()</span>
    <span class="n">run_add_cast</span><span class="p">()</span>
</pre></div>
</div>
<p>Use the <code class="docutils literal notranslate"><span class="pre">Client</span></code> class defined by <code class="docutils literal notranslate"><span class="pre">mindspore_serving.client</span></code>. The client defines two cases to call two model methods. In the <code class="docutils literal notranslate"><span class="pre">run_add_common</span></code> case with three pairs of float32 arrays, each pair of arrays are added up. In the <code class="docutils literal notranslate"><span class="pre">run_add_cast</span></code> case, two int32 arrays are added up. If the results of the two cases are displayed as follows, the Serving has properly executed the <code class="docutils literal notranslate"><span class="pre">Add</span></code> network inference.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[{&#39;y&#39;: array([[2. , 2.],
        [2.,  2.]], dtype=float32)},{&#39;y&#39;: array([[4. , 4.],
        [4.,  4.]], dtype=float32)},{&#39;y&#39;: array([[6. , 6.],
        [6.,  6.]], dtype=float32)}]
[{&#39;y&#39;: array([[2. , 2.],
        [2.,  2.]], dtype=float32)}]
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="serving_install.html" class="btn btn-neutral float-left" title="MindSpore Serving Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="serving_distributed_example.html" class="btn btn-neutral float-right" title="MindSpore Serving-based Distributed Inference Service Deployment" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>