

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore_serving.server &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="mindspore_serving.client" href="client.html" />
    <link rel="prev" title="实现多子图和有状态模型的服务部署" href="serving_multi_subgraphs.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="serving_install.html">安装MindSpore Serving</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">使用指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="serving_example.html">基于MindSpore Serving部署推理服务</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_distributed_example.html">基于MindSpore Serving部署分布式推理服务</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_grpc.html">基于gRPC接口访问MindSpore Serving服务</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_restful.html">基于RESTful接口访问MindSpore Serving服务</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_model.html">通过配置模型提供Servable</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_multi_subgraphs.html">实现多子图和有状态模型的服务部署</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API参考</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindspore_serving.server</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#mindspore-serving-server-register">mindspore_serving.server.register</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mindspore-serving-server-distributed">mindspore_serving.server.distributed</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="client.html">mindspore_serving.client</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>mindspore_serving.server</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/server.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="mindspore-serving-server">
<h1>mindspore_serving.server<a class="headerlink" href="#mindspore-serving-server" title="Permalink to this headline"></a></h1>
<p>MindSpore Serving是一个轻量级、高性能的服务模块，旨在帮助MindSpore开发者在生产环境中高效部署在线推理服务。</p>
<p>用户可通过MindSpore Serving server API启动服务，启动gRPC和RESTful（HTTP）服务器。其中一个服务一般可由一个模型或者一组模型组合提供。客户端通过gRPC和RESTful（HTTP）服务器发送推理任务，接收推理结果。</p>
<dl class="py function">
<dt class="sig sig-object py" id="mindspore_serving.server.start_grpc_server">
<span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.</span></span><span class="sig-name descname"><span class="pre">start_grpc_server</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">address</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_msg_mb_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ssl_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/master/_master.html#start_grpc_server"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.start_grpc_server" title="Permalink to this definition"></a></dt>
<dd><p>启动gRPC服务器，用于Serving客户端和Serving服务器之间的通信。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>address</strong> (str) - gRPC服务器地址，地址可以是 <cite>{ip}:{port}</cite> 或 <cite>unix:{unix_domain_file_path}</cite> 。</p>
<ul>
<li><p><cite>{ip}:{port}</cite> - Internet domain socket地址。</p></li>
<li><p><cite>unix:{unix_domain_file_path}</cite> - Unix domain socket地址，用于与同一台计算机上的多个进程通信。 <cite>{unix_domain_file_path}</cite> 可以是相对路径或绝对路径，但文件所在的目录必须已经存在。</p></li>
</ul>
</li>
<li><p><strong>max_msg_mb_size</strong> (int, optional) - 可接收的最大gRPC消息大小（MB），取值范围[1, 512]。默认值：100。</p></li>
<li><p><strong>ssl_config</strong> (mindspore_serving.server.SSLConfig, optional) - 服务器的SSL配置，如果None，则禁用SSL。默认值：None。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 启动gRPC服务器失败：参数校验失败，gRPC地址错误或端口重复。</p></li>
</ul>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_serving</span> <span class="kn">import</span> <span class="n">server</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">server</span><span class="o">.</span><span class="n">start_grpc_server</span><span class="p">(</span><span class="s2">&quot;0.0.0.0:5500&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore_serving.server.start_restful_server">
<span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.</span></span><span class="sig-name descname"><span class="pre">start_restful_server</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">address</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_msg_mb_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ssl_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/master/_master.html#start_restful_server"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.start_restful_server" title="Permalink to this definition"></a></dt>
<dd><p>启动RESTful服务器，用于Serving客户端和Serving服务器之间的通信。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>address</strong> (str) - RESTful服务器地址，地址应为Internet domain socket地址。</p></li>
<li><p><strong>max_msg_mb_size</strong> (int, optional) - 最大可接收的RESTful消息大小，以MB为单位，取值范围[1, 512]。默认值：100。</p></li>
<li><p><strong>ssl_config</strong> (mindspore_serving.server.SSLConfig, optional) - 服务器的SSL配置，如果是None，则禁用SSL。默认值：None。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 启动RESTful服务器失败：参数校验失败，RESTful地址错误或端口重复。</p></li>
</ul>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_serving</span> <span class="kn">import</span> <span class="n">server</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">server</span><span class="o">.</span><span class="n">start_restful_server</span><span class="p">(</span><span class="s2">&quot;0.0.0.0:5900&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore_serving.server.stop">
<span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.</span></span><span class="sig-name descname"><span class="pre">stop</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/master/_master.html#stop"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.stop" title="Permalink to this definition"></a></dt>
<dd><p>停止Serving服务器的运行。</p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_serving</span> <span class="kn">import</span> <span class="n">server</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">server</span><span class="o">.</span><span class="n">start_grpc_server</span><span class="p">(</span><span class="s2">&quot;0.0.0.0:5500&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">server</span><span class="o">.</span><span class="n">start_restful_server</span><span class="p">(</span><span class="s2">&quot;0.0.0.0:1500&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">server</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore_serving.server.start_servables">
<span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.</span></span><span class="sig-name descname"><span class="pre">start_servables</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">servable_configs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_lite</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/_server.html#start_servables"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.start_servables" title="Permalink to this definition"></a></dt>
<dd><p>用于Serving服务器中启动一个或多个服务，一个模型可结合预处理、后处理提供一个服务，多个模型也可串接组合提供一个服务。</p>
<p>本接口可以用来启动多个不同的服务。一个服务可以部署在多个设备上，其中每个设备运行一个服务副本。</p>
<p>在Ascend 910硬件平台上，每个服务的每个副本都独占一个设备。不同的服务或同一服务的不同版本需要部署在不同的设备上。在Ascend 310/310P和GPU硬件平台上，一个设备可以被多个服务共享，不同服务或同一服务的不同版本可以部署在同一设备上，实现设备复用。</p>
<p>如何配置模型提供服务请查看
<a class="reference external" href="https://www.mindspore.cn/serving/docs/zh-CN/r1.8/serving_example.html">基于MindSpore Serving部署推理服务</a> 和
<a class="reference external" href="https://www.mindspore.cn/serving/docs/zh-CN/r1.8/serving_model.html">通过配置模型提供Servable</a> 。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>servable_configs</strong> (Union[ServableStartConfig, list[ServableStartConfig], tuple[ServableStartConfig]]) - 一个或多个服务的启动配置。</p></li>
<li><p><strong>enable_lite</strong> (bool) - 是否使用MindSpore Lite推理后端。 默认值：False。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 启动一个或多个服务失败。相关日志可查看本Serving服务器启动脚本所在目录的子目录serving_logs。</p></li>
</ul>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">os</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_serving</span> <span class="kn">import</span> <span class="n">server</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">servable_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">resnet_config</span> <span class="o">=</span> <span class="n">server</span><span class="o">.</span><span class="n">ServableStartConfig</span><span class="p">(</span><span class="n">servable_dir</span><span class="p">,</span> <span class="s2">&quot;resnet&quot;</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">add_config</span> <span class="o">=</span> <span class="n">server</span><span class="o">.</span><span class="n">ServableStartConfig</span><span class="p">(</span><span class="n">servable_dir</span><span class="p">,</span> <span class="s2">&quot;add&quot;</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">server</span><span class="o">.</span><span class="n">start_servables</span><span class="p">(</span><span class="n">servable_configs</span><span class="o">=</span><span class="p">(</span><span class="n">resnet_config</span><span class="p">,</span> <span class="n">add_config</span><span class="p">))</span>  <span class="c1"># press Ctrl+C to stop</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">server</span><span class="o">.</span><span class="n">start_grpc_server</span><span class="p">(</span><span class="s2">&quot;0.0.0.0:5500&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_serving.server.ServableStartConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.</span></span><span class="sig-name descname"><span class="pre">ServableStartConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">servable_directory</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">servable_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_ids</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">version_number</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_parallel_workers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dec_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dec_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'AES-GCM'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/_servable_local.html#ServableStartConfig"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.ServableStartConfig" title="Permalink to this definition"></a></dt>
<dd><p>启动一个服务的配置。详情请查看
<a class="reference external" href="https://www.mindspore.cn/serving/docs/zh-CN/r1.8/serving_example.html">基于MindSpore Serving部署推理服务</a> 和
<a class="reference external" href="https://www.mindspore.cn/serving/docs/zh-CN/r1.8/serving_model.html">通过配置模型提供Servable</a> 。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>servable_directory</strong> (str) - 服务所在的目录。预期有一个名为 <cite>servable_name</cite> 的目录。</p></li>
<li><p><strong>servable_name</strong> (str) - 服务名称。</p></li>
<li><p><strong>device_ids</strong> (Union[int, list[int], tuple[int]], optional) - 模型部署和运行的设备列表，列表中的每个会设备将部署和运行一个服务副本。当设备类型为Nvidia GPU、Ascend 310/310P/910时使用。默认值：None。</p></li>
<li><p><strong>version_number</strong> (int, optional) - 要加载的服务的版本号。版本号应为正整数，从1开始，0表示加载最新版本。默认值：0。</p></li>
<li><p><strong>device_type</strong> (str, optional) - 模型部署的目标设备类型，目前支持”Ascend”、”GPU”、”CPU”和None。默认值：None。</p>
<ul>
<li><p>“Ascend”：目标设备为Ascend 310/310P/910等。</p></li>
<li><p>“GPU”：目标设备为Nvidia GPU。</p></li>
<li><p>“CPU”：目标设备为CPU。</p></li>
<li><p>None：系统根据实际的后端设备和MindSpor推理包决定目标设备，推荐使用默认值None。</p></li>
</ul>
</li>
<li><p><strong>num_parallel_workers</strong> (int, optional) - 处理Python任务的进程数，用于提高预处理、后处理等Python任务的处理能力。值小于 <cite>device_ids</cite> 的长度时，处理Python任务的进程数为 <cite>device_ids</cite> 的长度。默认值：0。</p></li>
<li><p><strong>dec_key</strong> (bytes, optional) - 用于解密的字节类型密钥。有效长度为16、24或32。默认值：None。</p></li>
<li><p><strong>dec_mode</strong> (str, optional) - 指定解密模式，设置 <cite>dec_key</cite> 时生效。值可为： <cite>‘AES-GCM’</cite> 或 <cite>‘AES-CBC’</cite> 。默认值： <cite>‘AES-GCM’</cite> 。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 参数的类型或值无效。</p></li>
</ul>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_serving.server.SSLConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.</span></span><span class="sig-name descname"><span class="pre">SSLConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">certificate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">private_key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_ca</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verify_client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/master/_master.html#SSLConfig"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.SSLConfig" title="Permalink to this definition"></a></dt>
<dd><p>Serving服务器中，使能gRPC或RESTful服务器SSL功能时，SSL的参数配置。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>certificate</strong> (str) - PEM编码的证书链内容，如果值为None，则表示不使用证书链。</p></li>
<li><p><strong>private_key</strong> (str) - PEM编码的私钥内容，如果值为None，则表示不使用私钥。</p></li>
<li><p><strong>custom_ca</strong> (str, optional) - PEM编码的根证书内容。当 <cite>verify_client</cite> 为True时， <cite>custom_ca</cite> 必须指定。当 <cite>verify_client</cite> 为False时，将忽略此参数。默认值：None。</p></li>
<li><p><strong>verify_client</strong> (bool, optional) - 如果 <cite>verify_client</cite> 为True，则启用客户端服务器双向认证。如果为False，则仅启用客户端对服务器的单向认证。默认值：False。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 参数的类型或值无效。</p></li>
</ul>
</dd></dl>

<section id="mindspore-serving-server-register">
<h2>mindspore_serving.server.register<a class="headerlink" href="#mindspore-serving-server-register" title="Permalink to this headline"></a></h2>
<p>服务注册接口，在服务的servable_config.py配置文件中使用。如何配置servable_config.py文件，请查看
<a class="reference external" href="https://www.mindspore.cn/serving/docs/zh-CN/r1.8/serving_model.html">通过配置模型提供Servable</a> 。</p>
<dl class="py function">
<dt class="sig sig-object py" id="mindspore_serving.server.register.declare_model">
<span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.register.</span></span><span class="sig-name descname"><span class="pre">declare_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_file</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_format</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_batch_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">without_batch_dim_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/register/model.html#declare_model"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.register.declare_model" title="Permalink to this definition"></a></dt>
<dd><p>在服务的servable_config.py配置文件中使用，用于声明一个模型。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>本接口需要在Serving服务器导入servable_config.py时生效。因此，建议在servable_config.py中全局使用此接口。</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>参数 <cite>options</cite> 从1.6.0版本中已弃用，并将在未来版本中删除，请改用参数 <cite>context</cite> 。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>model_file</strong> (Union[str, list[str]]) - 模型文件名。</p></li>
<li><p><strong>model_format</strong> (str) - 模型格式，”OM”、”MindIR” 或”MindIR_Lite”，忽略大小写。</p></li>
<li><p><strong>with_batch_dim</strong> (bool, optional) - 模型输入和输出的shape第一个维度是否是batch维度。默认值：True。</p></li>
<li><p><strong>options</strong> (Union[AclOptions, GpuOptions], optional) - 模型的选项，支持 <cite>AclOptions</cite> 或 <cite>GpuOptions</cite> 。默认值：None。</p></li>
<li><p><strong>context</strong> (Context) - 用于配置设备环境的上下文信息，值为None时，Serving将依据部署的设备设置默认的设备上下文。默认值：None。</p></li>
<li><p><strong>without_batch_dim_inputs</strong> (Union[int, tuple[int], list[int]], optional) - 当 <cite>with_batch_dim</cite> 为True时，用于指定shape不包括batch维度的模型输入的索引，比如模型输入0的shape不包括batch维度，则 <cite>without_batch_dim_inputs</cite> 可赋值为 <cite>(0,)</cite> 。默认值：None。</p></li>
<li><p><strong>config_file</strong> (str, optional) - 用于设置混合精度推理的配置文件。文件路径可以是servable_config.py所在目录的绝对路径或相对路径。默认值：None。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p><cite>Model</cite> ，此模型的标识，可以用来调用 <cite>Model.call</cite> 或作为 <cite>add_stage</cite> 的输入。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 参数的类型或值无效。</p></li>
</ul>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_serving.server.register.Model">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.register.</span></span><span class="sig-name descname"><span class="pre">Model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_key</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/register/model.html#Model"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.register.Model" title="Permalink to this definition"></a></dt>
<dd><p>用于表示一个声明的模型。用户不应该直接构造 <cite>Model</cite> 对象，而是来自于 <cite>declare_model</cite> 或 <cite>declare_servable</cite> 的返回。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>model_key</strong> (str) - 模型的唯一标志。</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore_serving.server.register.Model.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subgraph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/register/model.html#Model.call"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.register.Model.call" title="Permalink to this definition"></a></dt>
<dd><p>调用模型推理接口。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>subgraph</strong> (int, optional) - 子图索引，当一个模型中存在多个子图时使用。</p></li>
<li><p><strong>args</strong> - 实例的元组/列表，或一个实例的输入。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>当输入参数 <cite>args</cite> 为元组/列表时，返回为instances的元组，当前输入 <cite>args</cite> 为一个实例的输入时，输出为这个实例的输出。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 输入无效。</p></li>
</ul>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">register</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.dataset.vision.c_transforms</span> <span class="k">as</span> <span class="nn">VC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">declare_model</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s2">&quot;resnet_bs32.mindir&quot;</span><span class="p">,</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR&quot;</span><span class="p">)</span> <span class="c1"># batch_size=32</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">decode</span> <span class="o">=</span> <span class="n">VC</span><span class="o">.</span><span class="n">Decode</span><span class="p">()</span>
<span class="gp">... </span>    <span class="n">resize</span> <span class="o">=</span> <span class="n">VC</span><span class="o">.</span><span class="n">Resize</span><span class="p">([</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span>
<span class="gp">... </span>    <span class="n">normalize</span> <span class="o">=</span> <span class="n">VC</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">125.307</span><span class="p">,</span> <span class="mf">122.961</span><span class="p">,</span> <span class="mf">113.8575</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">51.5865</span><span class="p">,</span> <span class="mf">50.847</span><span class="p">,</span> <span class="mf">51.255</span><span class="p">])</span>
<span class="gp">... </span>    <span class="n">hwc2chw</span> <span class="o">=</span> <span class="n">VC</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
<span class="gp">... </span>    <span class="n">image</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">image</span> <span class="o">=</span> <span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="c1"># [3,224,224]</span>
<span class="gp">... </span>    <span class="n">image</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="c1"># [3,224,224]</span>
<span class="gp">... </span>    <span class="n">image</span> <span class="o">=</span> <span class="n">hwc2chw</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="c1"># [3,224,224]</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="nb">input</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">postprocess</span><span class="p">(</span><span class="n">score</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">call_resnet_model</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">image</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>  <span class="c1"># for only one instance</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">postprocess</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">call_resnet_model_batch</span><span class="p">(</span><span class="n">instances</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">input_instances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">instances</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">image</span> <span class="o">=</span> <span class="n">instance</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># only one input</span>
<span class="gp">... </span>        <span class="n">image</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="c1"># [3,224,224]</span>
<span class="gp">... </span>        <span class="n">input_instances</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">image</span><span class="p">])</span>
<span class="gp">... </span>    <span class="n">output_instances</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">input_instances</span><span class="p">)</span>  <span class="c1"># for multiply instances</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">output_instances</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">score</span> <span class="o">=</span> <span class="n">instance</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># only one output for each instance</span>
<span class="gp">... </span>        <span class="n">index</span> <span class="o">=</span> <span class="n">postprocess</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">yield</span> <span class="n">index</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nd">@register</span><span class="o">.</span><span class="n">register_method</span><span class="p">(</span><span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;index&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">predict_v1</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>  <span class="c1"># without pipeline, call model with only one instance a time</span>
<span class="gp">... </span>    <span class="n">index</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">call_resnet_model</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">index</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nd">@register</span><span class="o">.</span><span class="n">register_method</span><span class="p">(</span><span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;index&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">predict_v2</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>  <span class="c1"># without pipeline, call model with maximum 32 instances a time</span>
<span class="gp">... </span>    <span class="n">index</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">call_resnet_model_batch</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">index</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nd">@register</span><span class="o">.</span><span class="n">register_method</span><span class="p">(</span><span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;index&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">predict_v3</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>  <span class="c1"># pipeline</span>
<span class="gp">... </span>    <span class="n">image</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">preprocess</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">score</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">index</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">postprocess</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">index</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_serving.server.register.AscendDeviceInfo">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.register.</span></span><span class="sig-name descname"><span class="pre">AscendDeviceInfo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/register/model.html#AscendDeviceInfo"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.register.AscendDeviceInfo" title="Permalink to this definition"></a></dt>
<dd><p>用于设置Ascend设备配置。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>insert_op_cfg_path</strong> (str, optional) - AIPP配置文件的路径。</p></li>
<li><p><strong>input_format</strong> (str, optional) - 模型输入格式，取值可以是 <cite>“ND”</cite> 、 <cite>“NCHW”</cite> 、 <cite>“NHWC”</cite> 、 <cite>“CHWN”</cite> 、 <cite>“NC1HWC0”</cite> 或 <cite>“NHWC1C0”</cite> 。</p></li>
<li><p><strong>input_shape</strong> (str, optional) - 模型输入形状，如 <cite>“input_op_name1: n1,c2,h3,w4;input_op_name2: n4,c3,h2,w1”</cite> 。</p></li>
<li><p><strong>output_type</strong> (str, optional) - 模型输出类型，值可以是 <cite>“FP16”</cite> 、 <cite>“UINT8”</cite> 或 <cite>“FP32”</cite> ，默认值： <cite>“FP32”</cite> 。</p></li>
<li><p><strong>precision_mode</strong> (str, optional) - 模型精度模式，取值可以是 <cite>“force_fp16”</cite> 、 <cite>“allow_fp32_to_fp16”</cite> 、 <cite>“must_keep_origin_dtype”</cite> 或者 <cite>“allow_mix_precision”</cite> 。默认值： <cite>“force_fp16”</cite> 。</p></li>
<li><p><strong>op_select_impl_mode</strong> (str, optional) - 运算符选择模式，值可以是 <cite>“high_performance”</cite> 或 <cite>“high_precision”</cite> 。默认值： <cite>“high_performance”</cite> 。</p></li>
<li><p><strong>fusion_switch_config_path</strong> (str, optional) - 融合配置文件路径，包括图融合和UB融合。系统内置图融合和UB融合规则，默认启用。您可以通过设置此参数禁用指定的融合规则。</p></li>
<li><p><strong>buffer_optimize_mode</strong> (str, optional) - 数据缓存优化策略，值可以是 <cite>“l1_optimize”</cite> 、 <cite>“l2_optimize”</cite> 、 <cite>“off_optimize”</cite> 或者 <cite>“l1_and_l2_optimize”</cite> 。默认 <cite>“l2_optimize”</cite> 。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - Ascend设备配置无效。</p></li>
</ul>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">register</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">Context</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">append_device_info</span><span class="p">(</span><span class="n">register</span><span class="o">.</span><span class="n">AscendDeviceInfo</span><span class="p">(</span><span class="n">input_format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">declare_model</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s2">&quot;deeptext.ms&quot;</span><span class="p">,</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR_Lite&quot;</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_serving.server.register.CPUDeviceInfo">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.register.</span></span><span class="sig-name descname"><span class="pre">CPUDeviceInfo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/register/model.html#CPUDeviceInfo"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.register.CPUDeviceInfo" title="Permalink to this definition"></a></dt>
<dd><p>用于CPU设备配置。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>precision_mode</strong> (str, optional) - 推理精度选项，值可以是 <cite>“origin”</cite> 或 <cite>“fp16”</cite> ， <cite>“origin”</cite> 表示以模型中指定精度进行推理， <cite>“fp16”</cite> 表示以FP16精度进行推理。默认值： <cite>“origin”</cite> 。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 选项无效，或值类型不是字符串。</p></li>
</ul>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">register</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">Context</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">append_device_info</span><span class="p">(</span><span class="n">register</span><span class="o">.</span><span class="n">CPUDeviceInfo</span><span class="p">(</span><span class="n">precision_mode</span><span class="o">=</span><span class="s2">&quot;fp16&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">declare_model</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s2">&quot;deeptext.ms&quot;</span><span class="p">,</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR_Lite&quot;</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_serving.server.register.GPUDeviceInfo">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.register.</span></span><span class="sig-name descname"><span class="pre">GPUDeviceInfo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/register/model.html#GPUDeviceInfo"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.register.GPUDeviceInfo" title="Permalink to this definition"></a></dt>
<dd><p>用于GPU设备配置。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>precision_mode</strong> (str, optional) - 推理精度选项，值可以是 <cite>“origin”</cite> 或 <cite>“fp16”</cite> ， <cite>“origin”</cite> 表示以模型中指定精度进行推理， <cite>“fp16”</cite> 表示以FP16精度进行推理。默认值： <cite>“origin”</cite> 。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 选项无效，或值类型不是字符串。</p></li>
</ul>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">register</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">Context</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">append_device_info</span><span class="p">(</span><span class="n">register</span><span class="o">.</span><span class="n">GPUDeviceInfo</span><span class="p">(</span><span class="n">precision_mode</span><span class="o">=</span><span class="s2">&quot;fp16&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">declare_model</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s2">&quot;deeptext.mindir&quot;</span><span class="p">,</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR&quot;</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_serving.server.register.Context">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.register.</span></span><span class="sig-name descname"><span class="pre">Context</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/register/model.html#Context"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.register.Context" title="Permalink to this definition"></a></dt>
<dd><p>Context用于自定义设备配置，如果不指定Context，MindSpore Serving将使用默认设备配置。当使用推理后端为MindSpore Lite，且目标设备为Ascend或Nvidia GPU时，模型部分算子可能运行在CPU设备上，将额外配置 <cite>CPUDeviceInfo</cite> 。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>thread_num</strong> (int, optional) - 设置运行时的CPU线程数量，该选项仅当推理后端为MindSpore Lite有效。</p></li>
<li><p><strong>thread_affinity_core_list</strong> (tuple[int], list[int], optional) - 设置运行时的CPU绑核列表，该选项仅当推理后端为MindSpore Lite有效。</p></li>
<li><p><strong>enable_parallel</strong> (bool, optional) - 设置运行时是否支持并行，该选项仅当推理后端为MindSpore Lite有效。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 输入参数的类型或值无效。</p></li>
</ul>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">register</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">Context</span><span class="p">(</span><span class="n">thread_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">thread_affinity_core_list</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">enable_parallel</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">append_device_info</span><span class="p">(</span><span class="n">register</span><span class="o">.</span><span class="n">GPUDeviceInfo</span><span class="p">(</span><span class="n">precision_mode</span><span class="o">=</span><span class="s2">&quot;fp16&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">declare_model</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s2">&quot;tensor_add.mindir&quot;</span><span class="p">,</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR&quot;</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore_serving.server.register.Context.append_device_info">
<span class="sig-name descname"><span class="pre">append_device_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device_info</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/register/model.html#Context.append_device_info"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.register.Context.append_device_info" title="Permalink to this definition"></a></dt>
<dd><p>用于添加一个用户自定义的设备配置。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>device_info</strong> (Union[CPUDeviceInfo, GPUDeviceInfo, AscendDeviceInfo]) - 用户自定义设备配置，用户不指定设备配置时将使用默认值。可以为每个可能的设备自定义设备配置，系统根据实际的后端设备和推理包选择所需的设备信息。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 输入参数的类型或值无效。</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore_serving.server.register.register_method">
<span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.register.</span></span><span class="sig-name descname"><span class="pre">register_method</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_names</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/register/method.html#register_method"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.register.register_method" title="Permalink to this definition"></a></dt>
<dd><p>在服务的servable_config.py配置文件中使用，用于注册服务的方法，一个服务可以包括一个或多个方法，每个方法可基于模型提供不同的功能，客户端访问服务时需要指定服务和方法。MindSpore Serving支持由多个Python函数和多个模型组合串接提供服务。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>本接口需要在Serving服务器导入servable_config.py时生效。因此，建议在servable_config.py中全局使用此接口。</p>
</div>
<p>此接口将定义方法的签名和处理流程。</p>
<p>签名包括方法名称、方法的输入和输出名称。当Serving客户端访问服务时，客户端需要指定服务名称、方法名称，并提供一个或多个推理实例。每个实例通过输入名称指定输入数据，并通过输出名称获取输出结果。</p>
<p>处理流程由一个或多个阶段（stage）组成，每个阶段可以是一个Python函数或模型。即，一个方法的处理流程可以包括一个或多个Python函数和一个或多个模型。此外，接口还定义了这些阶段之间的数据流。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>output_names</strong> (Union[str, tuple[str], list[str]]) - 指定方法的输出名称。输入名称通过注册函数的参数名称指定。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 参数的类型或值无效，或发生其他错误。</p></li>
</ul>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">register</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">add_model</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">declare_model</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s2">&quot;tensor_add.mindir&quot;</span><span class="p">,</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sub_model</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">declare_model</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s2">&quot;tensor_sub.mindir&quot;</span><span class="p">,</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nd">@register</span><span class="o">.</span><span class="n">register_method</span><span class="p">(</span><span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span> <span class="c1"># register predict method in servable</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">):</span> <span class="c1"># x1+x2-x3</span>
<span class="gp">... </span>    <span class="n">y</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">add_model</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">y</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">sub_model</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x3</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore_serving.server.register.add_stage">
<span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.register.</span></span><span class="sig-name descname"><span class="pre">add_stage</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs_count</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/register/method.html#add_stage"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.register.add_stage" title="Permalink to this definition"></a></dt>
<dd><p>在服务的 <cite>servable_config.py</cite> 中，通过 <cite>register_method</cite> 装饰（wrap）Python函数定义服务的一个方法（method），本接口用于定义这个方法中的一个运行步骤（stage），可以是一个Python函数或者模型。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>入参 <cite>args</cite> 的长度应等于函数或模型的输入个数。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>stage</strong> (Union(function, Model)) - 用户定义的Python函数或由 <cite>declare_model</cite> 返回 <cite>Model</cite> 对象。</p></li>
<li><p><strong>outputs_count</strong> (int) - 用户定义的Python函数或模型的输出个数。</p></li>
<li><p><strong>batch_size</strong> (int, optional) - 仅当stage是Python函数，且函数一次可以处理多实例时，此参数有效。默认值：None。</p>
<ul>
<li><p>None，函数的输入将是一个实例的输入。</p></li>
<li><p>0，函数的输入将是实例的元组对象，实例元组的最大长度由服务器根据模型的batch大小确定。</p></li>
<li><p>int value &gt;= 1，函数的输入将是实例的元组对象，实例元组的最大长度是 <cite>batch_size</cite> 指定的值。</p></li>
</ul>
</li>
<li><p><strong>args</strong> - stage输入占位符，可以是 <cite>register_method</cite> 装饰（wrap）的函数的输入或其他 <cite>add_stage</cite> 的输出。 <cite>args</cite> 的长度应等于Python函数或模型的输入数量。</p></li>
<li><p><strong>tag</strong> (str, optional) - stage的自定义标签，如”preprocess”，默认值：None。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 参数的类型或值无效，或发生其他错误。</p></li>
</ul>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">register</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">add_model</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">declare_model</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s2">&quot;tensor_add.mindir&quot;</span><span class="p">,</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">x1</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">x2</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nd">@register</span><span class="o">.</span><span class="n">register_method</span><span class="p">(</span><span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span> <span class="c1"># register add_common method in add</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">add_common</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">preprocess</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># call preprocess in stage 1</span>
<span class="gp">... </span>    <span class="n">y</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">add_model</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># call add model in stage 2</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="mindspore-serving-server-distributed">
<h2>mindspore_serving.server.distributed<a class="headerlink" href="#mindspore-serving-server-distributed" title="Permalink to this headline"></a></h2>
<p>Serving服务器启动分布式模型服务的接口。如何配置和启动分布式模型，请查看
<a class="reference external" href="https://www.mindspore.cn/serving/docs/zh-CN/r1.8/serving_distributed_example.html">基于MindSpore Serving部署分布式推理服务</a> 。</p>
<dl class="py function">
<dt class="sig sig-object py" id="mindspore_serving.server.distributed.start_servable">
<span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.distributed.</span></span><span class="sig-name descname"><span class="pre">start_servable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">servable_directory</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">servable_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_table_json_file</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">version_number</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distributed_address</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'0.0.0.0:6200'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wait_agents_time_in_seconds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/distributed/_distributed.html#start_servable"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.distributed.start_servable" title="Permalink to this definition"></a></dt>
<dd><p>启动在 <cite>servable_directory</cite> 中定义的名为 <cite>servable_name</cite> 的分布式服务。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>servable_directory</strong> (str) - 服务所在的目录。预期有一个名为 <cite>servable_name</cite> 的目录。详细信息可以查看 <a class="reference external" href="https://www.mindspore.cn/serving/docs/zh-CN/r1.8/serving_model.html">通过配置模型提供Servable</a> 。</p></li>
<li><p><strong>servable_name</strong> (str) - 服务名称。</p></li>
<li><p><strong>version_number</strong> (int, optional) - 要加载的服务版本号。版本号应为正整数，从1开始。默认值：1。</p></li>
<li><p><strong>rank_table_json_file</strong> (str) - rank table json文件名。</p></li>
<li><p><strong>distributed_address</strong> (str, optional) - Worker代理（Agent）连接的分布式Worker服务器地址。默认值： <cite>“0.0.0.0:6200”</cite> 。</p></li>
<li><p><strong>wait_agents_time_in_seconds</strong> (int, optional) - 等待所有Worker代理就绪的最长时间（以秒为单位），0表示无限时间。默认值：0。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 启动分布式服务失败。</p></li>
</ul>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">os</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">distributed</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">servable_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">distributed</span><span class="o">.</span><span class="n">start_servable</span><span class="p">(</span><span class="n">servable_dir</span><span class="p">,</span> <span class="s2">&quot;matmul&quot;</span><span class="p">,</span> <span class="n">startup_worker_agents</span><span class="o">=</span><span class="s2">&quot;hccl_8p.json&quot;</span><span class="p">,</span> \
<span class="gp">... </span>                           <span class="n">distributed_address</span><span class="o">=</span><span class="s2">&quot;127.0.0.1:6200&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore_serving.server.distributed.startup_agents">
<span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.distributed.</span></span><span class="sig-name descname"><span class="pre">startup_agents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">distributed_address</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_files</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group_config_files</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">agent_start_port</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">7000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">agent_ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dec_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dec_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'AES-GCM'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/worker/distributed/agent_startup.html#startup_agents"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.distributed.startup_agents" title="Permalink to this definition"></a></dt>
<dd><p>在当前计算机上启动所有所需的Worker代理（Agent），这组Worker代理进程将负责本机器设备上的推理任务，详细可参考
<a class="reference external" href="https://www.mindspore.cn/serving/docs/zh-CN/r1.8/serving_distributed_example.html">基于MindSpore Serving部署分布式推理服务</a> 。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>distributed_address</strong> (str) - Worker代理连接分布式Worker服务器地址。</p></li>
<li><p><strong>model_files</strong> (Union[list[str], tuple[str]]) - 当前计算机中需要的所有模型文件，为绝对路径或相对于此启动Python脚本的路径。</p></li>
<li><p><strong>group_config_files</strong> (Union[list[str], tuple[str]], optional) - 当前计算机中需要的所有组配置文件，相对于此启动Python脚本的绝对路径或相对路径，为None时表示没有配置文件。默认值：None。</p></li>
<li><p><strong>agent_start_port</strong> (int, optional) - Worker代理连接Worker服务器的起始端口号。默认值：7000。</p></li>
<li><p><strong>agent_ip</strong> (str, optional) - 本地Worker代理ip，如果为无，则代理ip将从rank table文件中获取。参数 <cite>agent_ip</cite> 和参数 <cite>rank_start</cite> 必须同时有值，或者同时是None。默认值：None。</p></li>
<li><p><strong>rank_start</strong> (int, optional) - 此计算机的起始rank id，如果为None，则将从rank table文件中获取rank id。参数 <cite>agent_ip</cite> 和参数 <cite>rank_start</cite> 必须同时有值，或者同时是None。默认值：None。</p></li>
<li><p><strong>dec_key</strong> (bytes, optional) - 用于解密的密钥，类型为字节。有效长度为16、24或32。默认值：None。</p></li>
<li><p><strong>dec_mode</strong> (str, optional) - 指定解密模式，在设置了 <cite>dec_key</cite> 时生效。值可为： <cite>‘AES-GCM’</cite> 或 <cite>‘AES-CBC’</cite> 。默认值： <cite>‘AES-GCM’</cite> 。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 启动Worker代理失败。</p></li>
</ul>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">os</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">distributed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model_files</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">model_files</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;models/device</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/matmul.mindir&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">distributed</span><span class="o">.</span><span class="n">startup_agents</span><span class="p">(</span><span class="n">distributed_address</span><span class="o">=</span><span class="s2">&quot;127.0.0.1:6200&quot;</span><span class="p">,</span> <span class="n">model_files</span><span class="o">=</span><span class="n">model_files</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore_serving.server.distributed.declare_servable">
<span class="sig-prename descclassname"><span class="pre">mindspore_serving.server.distributed.</span></span><span class="sig-name descname"><span class="pre">declare_servable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rank_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stage_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_batch_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">without_batch_dim_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_pipeline_infer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_serving/server/worker/distributed/register.html#declare_servable"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_serving.server.distributed.declare_servable" title="Permalink to this definition"></a></dt>
<dd><p>用于在servable_config.py中声明分布式服务，详细可参考
<a class="reference external" href="https://www.mindspore.cn/serving/docs/zh-CN/r1.8/serving_distributed_example.html">基于MindSpore Serving部署分布式推理服务</a> 。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>rank_size</strong> (int) - 分布式模型的rank大小。</p></li>
<li><p><strong>stage_size</strong> (int) - 分布式模型的stage大小。</p></li>
<li><p><strong>with_batch_dim</strong> (bool, optional) - 模型输入和输出shape的第一个维度是否是batch维度。默认值：True。</p></li>
<li><p><strong>without_batch_dim_inputs</strong> (Union[int, tuple[int], list[int]], optional) - 当 <cite>with_batch_dim</cite> 为True时，用于指定shape不包括batch维度的模型输入的索引，比如模型输入0的shape不包括batch维度，则 <cite>without_batch_dim_inputs=(0,)</cite> 。默认值：None。</p></li>
<li><p><strong>enable_pipeline_infer</strong> (bool, optional) - 是否开启流水线并行推理，流水线并行可有效提升推理性能，详情可参考 <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r1.8/parallel/pipeline_parallel.html">流水线并行</a> 。默认值：False。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p><cite>Model</cite> ，此模型的标识，可以用来调用 <cite>Model.call</cite> 或作为 <cite>add_stage</cite> 的输入。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - 参数的类型或值无效。</p></li>
</ul>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">distributed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">distributed</span><span class="o">.</span><span class="n">declare_servable</span><span class="p">(</span><span class="n">rank_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stage_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>


           </div>
           
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="serving_multi_subgraphs.html" class="btn btn-neutral float-left" title="实现多子图和有状态模型的服务部署" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="client.html" class="btn btn-neutral float-right" title="mindspore_serving.client" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>