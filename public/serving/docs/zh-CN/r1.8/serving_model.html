<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>通过配置模型提供Servable &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="实现多子图和有状态模型的服务部署" href="serving_multi_subgraphs.html" />
    <link rel="prev" title="基于RESTful接口访问MindSpore Serving服务" href="serving_restful.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="serving_install.html">安装MindSpore Serving</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">使用指南</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="serving_example.html">基于MindSpore Serving部署推理服务</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_distributed_example.html">基于MindSpore Serving部署分布式推理服务</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_grpc.html">基于gRPC接口访问MindSpore Serving服务</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_restful.html">基于RESTful接口访问MindSpore Serving服务</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">通过配置模型提供Servable</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#概述">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#相关概念">相关概念</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#方法">方法</a></li>
<li class="toctree-l3"><a class="reference internal" href="#实例">实例</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#单模型服务">单模型服务</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#预处理和后处理定义">预处理和后处理定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="#模型声明">模型声明</a></li>
<li class="toctree-l3"><a class="reference internal" href="#方法定义">方法定义</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#多模型组合">多模型组合</a></li>
<li class="toctree-l2"><a class="reference internal" href="#多进程并发">多进程并发</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="serving_multi_subgraphs.html">实现多子图和有状态模型的服务部署</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="server.html">mindspore_serving.server</a></li>
<li class="toctree-l1"><a class="reference internal" href="client.html">mindspore_serving.client</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>通过配置模型提供Servable</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/serving_model.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="通过配置模型提供servable">
<h1>通过配置模型提供Servable<a class="headerlink" href="#通过配置模型提供servable" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.8/docs/serving/docs/source_zh_cn/serving_model.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_source.png"></a></p>
<section id="概述">
<h2>概述<a class="headerlink" href="#概述" title="Permalink to this headline"></a></h2>
<p>运行示例前，需确保已经正确安装了MindSpore Serving，并配置了环境变量。MindSpore Serving安装和配置可以参考<a class="reference external" href="https://www.mindspore.cn/serving/docs/zh-CN/r1.8/serving_install.html">MindSpore Serving安装页面</a>。</p>
<p>MindSpore Serving的Servable提供推理服务，包含两种类型，一种是推理服务来源于单模型，一种是推理服务来源于多模型组合，它们使用相同的接口进行定义。模型需要进行配置以提供Serving推理服务。</p>
<p>本文将说明如何对模型进行配置以提供Servable，单个模型以ResNet-50作为样例，样例代码可参考<a class="reference external" href="https://gitee.com/mindspore/serving/tree/r1.8/example/resnet/">ResNet-50样例</a> 。Serving客户端简称客户端。</p>
</section>
<section id="相关概念">
<h2>相关概念<a class="headerlink" href="#相关概念" title="Permalink to this headline"></a></h2>
<section id="方法">
<h3>方法<a class="headerlink" href="#方法" title="Permalink to this headline"></a></h3>
<p>以ResNet-50推理模型为例，客户端发来的数据为jpg、png等格式的图片，预期返回图片的分类。ResNet-50模型输入为经过图片<code class="docutils literal notranslate"><span class="pre">Decode</span></code>、<code class="docutils literal notranslate"><span class="pre">Resize</span></code>、<code class="docutils literal notranslate"><span class="pre">Normalize</span></code>等操作产生的Tensor，输出为每个类别的得分Tensor。需要通过预处理将图片转化为满足模型输入的Tensor，通过后处理返回<strong>得分最大的类别名称</strong>或者<strong>前5类别名称及其得分</strong>。</p>
<p>以下图是<code class="docutils literal notranslate"><span class="pre">resnet50</span></code> Servable数据流程图，描述了图像数据从Serving客户端通过网络传输到Serving，Serving进行预处理、推理和后处理，最后向Serving客户端返回结果：</p>
<p><img alt="image" src="_images/resnet_example.png" /></p>
<p>在不同的场景下，如果来自客户端的数据输入组成、结构或类型不同，可以提供不同的预处理。如果对模型的输出也有不同的要求，可以提供不同的后处理。比如上述<code class="docutils literal notranslate"><span class="pre">resnet50</span></code> Servable，针对返回<strong>得分最大的类别名称</strong>还是<strong>前5类别名称及其得分</strong>这两种场景提供了两个后处理。</p>
<p>不同的服务处理流程可以通过不同的方法来体现，一个Servable可提供一个或多个方法，Servable的名称和方法的名称标记了Serving提供的一个服务，每个方法对客户端提供的数据进行一系列Python处理或者模型推理等操作，最后将需要的结果返回给客户端。上述的<code class="docutils literal notranslate"><span class="pre">resnet50</span></code> Servable提供了<code class="docutils literal notranslate"><span class="pre">classify_top5</span></code>和<code class="docutils literal notranslate"><span class="pre">classify_top1</span></code>两个方法（<code class="docutils literal notranslate"><span class="pre">Method</span></code>）。</p>
<p>Servable的方法包含如下内容：</p>
<ul class="simple">
<li><p>指定方法名，使客户端可以通过方法名指定使用的方法。</p></li>
<li><p>指定方法的输入和输出名称，使客户端可以通过名称来指定输入、获取输出。</p></li>
<li><p>指定方法一个或多个处理阶段（<code class="docutils literal notranslate"><span class="pre">Stage</span></code>），每个<code class="docutils literal notranslate"><span class="pre">Stage</span></code>可以是一个Python函数或者一个模型。一个方法中，Python函数和模型的数量不限制、顺序不限制，并且可在多个<code class="docutils literal notranslate"><span class="pre">Stage</span></code>中被重复使用，一个方法中可以使用多个不同模型。</p></li>
<li><p>定义方法输入、各个<code class="docutils literal notranslate"><span class="pre">Stage</span></code>、方法输出之间的数据流，前者作为后者的输入。</p></li>
</ul>
</section>
<section id="实例">
<h3>实例<a class="headerlink" href="#实例" title="Permalink to this headline"></a></h3>
<p>每次请求可包括一个或多个实例，每个实例之间相互独立，结果互不影响。比如一张图片返回一个分类类别，三张独立的图片独立返回三个分类类别。</p>
</section>
</section>
<section id="单模型服务">
<h2>单模型服务<a class="headerlink" href="#单模型服务" title="Permalink to this headline"></a></h2>
<p>以ResNet-50模型为例，模型配置文件目录结果如下图所示：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>resnet50
├── 1
│   └── resnet50_1b_cifar10.mindir
├── 2
│   └── resnet50_1b_cifar10.mindir
└── servable_config.py
</pre></div>
</div>
<ul class="simple">
<li><p>目录<code class="docutils literal notranslate"><span class="pre">resnet50</span></code>指示Servable的名称。</p></li>
<li><p>通过<code class="docutils literal notranslate"><span class="pre">servable_config.py</span></code>配置Servable，其中包括预处理和后处理定义、模型声明、方法定义。</p></li>
<li><p>目录<code class="docutils literal notranslate"><span class="pre">1</span></code>和<code class="docutils literal notranslate"><span class="pre">2</span></code>表示版本<code class="docutils literal notranslate"><span class="pre">1</span></code>和版本<code class="docutils literal notranslate"><span class="pre">2</span></code>的模型，模型版本为正整数，从<code class="docutils literal notranslate"><span class="pre">1</span></code>开始，数字越大表示版本越新。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">resnet50_1b_cifar10.mindir</span></code>为模型文件，Servable启动会加载对应版本的模型文件。</p></li>
</ul>
<section id="预处理和后处理定义">
<h3>预处理和后处理定义<a class="headerlink" href="#预处理和后处理定义" title="Permalink to this headline"></a></h3>
<p>预处理和后处理定义方式例子如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision</span> <span class="k">as</span> <span class="nn">vision</span>

<span class="c1"># cifar 10</span>
<span class="n">idx_2_label</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;airplane&#39;</span><span class="p">,</span> <span class="s1">&#39;automobile&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;deer&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;frog&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">,</span> <span class="s1">&#39;ship&#39;</span><span class="p">,</span> <span class="s1">&#39;truck&#39;</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">preprocess_eager</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Define preprocess, input is image numpy, return preprocess result.</span>
<span class="sd">    Return type can be numpy, str, bytes, int, float, or bool.</span>
<span class="sd">    Use MindData Eager, this image processing can also use other image processing library,</span>
<span class="sd">    likes numpy, PIL or cv2 etc.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">image_size</span> <span class="o">=</span> <span class="mi">224</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.4914</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.4822</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.4465</span> <span class="o">*</span> <span class="mi">255</span><span class="p">]</span>
    <span class="n">std</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2023</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.1994</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.2010</span> <span class="o">*</span> <span class="mi">255</span><span class="p">]</span>

    <span class="n">decode</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">()</span>
    <span class="n">resize</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">Resize</span><span class="p">([</span><span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">])</span>
    <span class="n">normalize</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">)</span>
    <span class="n">hwc2chw</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>

    <span class="n">image</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">hwc2chw</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">image</span>


<span class="k">def</span> <span class="nf">postprocess_top1</span><span class="p">(</span><span class="n">score</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Define postprocess. This example has one input and one output.</span>
<span class="sd">    The input is the numpy tensor of the score, and the output is the label str of top one.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">idx_2_label</span><span class="p">[</span><span class="n">max_idx</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">postprocess_top5</span><span class="p">(</span><span class="n">score</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Define postprocess. This example has one input and two outputs.</span>
<span class="sd">    The input is the numpy tensor of the score. The first output is the str joined by labels of top five,</span>
<span class="sd">    and the second output is the score tensor of the top five.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">score</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="mi">5</span><span class="p">]</span>  <span class="c1"># top 5</span>
    <span class="n">ret_label</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx_2_label</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">]</span>
    <span class="n">ret_score</span> <span class="o">=</span> <span class="n">score</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="k">return</span> <span class="s2">&quot;;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ret_label</span><span class="p">),</span> <span class="n">ret_score</span>
</pre></div>
</div>
<p>预处理和后处理定义格式相同，入参为每个实例的输入数据。输入数据为文本时，入参为str对象；输入数据为其他数据类型，包括Tensor、Scalar number、Bool、Bytes时，入参为<strong>numpy对象</strong>。通过<code class="docutils literal notranslate"><span class="pre">return</span></code>返回实例的处理结果，<code class="docutils literal notranslate"><span class="pre">return</span></code>返回的每项数据可为<strong>numpy、Python的bool、int、float、str、或bytes</strong>数据对象。</p>
</section>
<section id="模型声明">
<h3>模型声明<a class="headerlink" href="#模型声明" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">resnet50</span></code> Servabale模型声明示例代码如下所示：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">register</span>
<span class="n">resnet_model</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">declare_model</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s2">&quot;resnet50_1b_cifar10.mindir&quot;</span><span class="p">,</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR&quot;</span><span class="p">,</span> <span class="n">with_batch_dim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>其中：</p>
<ol class="arabic">
<li><p><code class="docutils literal notranslate"><span class="pre">declare_model</span></code>入参<code class="docutils literal notranslate"><span class="pre">model_file</span></code>指示模型的文件名称。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model_format</span></code>指示模型的模型格式。</p></li>
<li><p>如果模型输入和输出第1维度不是<code class="docutils literal notranslate"><span class="pre">batch</span></code>维度，需要设置参数<code class="docutils literal notranslate"><span class="pre">with_batch_dim=False</span></code>，<code class="docutils literal notranslate"><span class="pre">with_batch_dim</span></code>默认为<code class="docutils literal notranslate"><span class="pre">True</span></code>。</p>
<p>设置<code class="docutils literal notranslate"><span class="pre">with_batch_dim</span></code>为<code class="docutils literal notranslate"><span class="pre">True</span></code>，主要针对处理图片、文本等包含<code class="docutils literal notranslate"><span class="pre">batch</span></code>维度的模型。假设<code class="docutils literal notranslate"><span class="pre">batch_size=2</span></code>，当前请求有3个实例，共3张图片，会拆分为2次模型推理，第1次处理2张图片返回2个结果，第2次对剩余的1张图片进行拷贝做一次推理并返回1个结果，最终返回3个结果。</p>
<p><img alt="image" src="_images/resnet_with_batch.png" /></p>
<p>设置<code class="docutils literal notranslate"><span class="pre">with_batch_dim</span></code>为<code class="docutils literal notranslate"><span class="pre">False</span></code>，主要针对不涉及或不考虑<code class="docutils literal notranslate"><span class="pre">batch</span></code>维度的模型。比如输入输出为二维Tensor的矩阵乘模型。请求的每个实例将单独作一次推理任务。</p>
<p><img alt="image" src="_images/matmul_without_batch.png" /></p>
</li>
<li><p>另外，对于一个模型，假设其中一个输入是数据输入，包括<code class="docutils literal notranslate"><span class="pre">batch</span></code>维度信息，另一个输入为模型配置信息，没有包括<code class="docutils literal notranslate"><span class="pre">batch</span></code>维度信息，此时在设置<code class="docutils literal notranslate"><span class="pre">with_batch_dim</span></code>为<code class="docutils literal notranslate"><span class="pre">True</span></code>基础上，设置额外参数<code class="docutils literal notranslate"><span class="pre">without_batch_dim_inputs</span></code>指定没有包括<code class="docutils literal notranslate"><span class="pre">batch</span></code>维度信息的输入信息。例如：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">register</span>
<span class="c1"># Input1 indicates the input shape information of the model, without the batch dimension information.</span>
<span class="c1"># input0: [N,3,416,416], input1: [2]</span>
<span class="n">yolov_model</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">declare_model</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s2">&quot;yolov3_darknet53.mindir&quot;</span><span class="p">,</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR&quot;</span><span class="p">,</span>
                                     <span class="n">with_batch_dim</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">without_batch_dim_inputs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>如果想要配置模型运行时的参数以及设备信息，可以使用<code class="docutils literal notranslate"><span class="pre">declare_model</span></code>的<code class="docutils literal notranslate"><span class="pre">context</span></code>和<code class="docutils literal notranslate"><span class="pre">config_file</span></code>入参。具体可以参考相关<a class="reference external" href="https://www.mindspore.cn/serving/docs/zh-CN/r1.8/server.html#mindspore_serving.server.register.declare_model">API文档</a>。</p></li>
</ol>
<p>对于分布式模型，与非分布式单模型配置相比仅声明方法不同，需要使用<code class="docutils literal notranslate"><span class="pre">mindspore_serving.server.distributed.declare_servable</span></code>，其中入参<code class="docutils literal notranslate"><span class="pre">rank_size</span></code>表示模型推理使用的device个数，<code class="docutils literal notranslate"><span class="pre">stage_size</span></code>表示流水线的段数，可以参考<a class="reference external" href="https://www.mindspore.cn/serving/docs/zh-CN/r1.8/serving_distributed_example.html">部署分布式推理服务</a>。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">distributed</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">distributed</span><span class="o">.</span><span class="n">declare_servable</span><span class="p">(</span><span class="n">rank_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stage_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">with_batch_dim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="方法定义">
<h3>方法定义<a class="headerlink" href="#方法定义" title="Permalink to this headline"></a></h3>
<p>方法定义的例子如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">register</span>

<span class="nd">@register</span><span class="o">.</span><span class="n">register_method</span><span class="p">(</span><span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">classify_top1</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>  <span class="c1"># pipeline: preprocess_eager/postprocess_top1, model</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Define method `classify_top1` for servable `resnet50`.</span>
<span class="sd">     The input is `image` and the output is `label`.&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">preprocess_eager</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">postprocess_top1</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="nd">@register</span><span class="o">.</span><span class="n">register_method</span><span class="p">(</span><span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="s2">&quot;score&quot;</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">classify_top5</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Define method `classify_top5` for servable `resnet50`.</span>
<span class="sd">     The input is `image` and the output is `label` and `score`. &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">preprocess_eager</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">label</span><span class="p">,</span> <span class="n">score</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">postprocess_top5</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">label</span><span class="p">,</span> <span class="n">score</span>
</pre></div>
</div>
<p>上述代码在Servable <code class="docutils literal notranslate"><span class="pre">resnet50</span></code>定义了<code class="docutils literal notranslate"><span class="pre">classify_top1</span></code>和<code class="docutils literal notranslate"><span class="pre">classify_top5</span></code>方法，其中方法<code class="docutils literal notranslate"><span class="pre">classify_top1</span></code>入参为<code class="docutils literal notranslate"><span class="pre">image</span></code>，出参为<code class="docutils literal notranslate"><span class="pre">label</span></code>，方法<code class="docutils literal notranslate"><span class="pre">classify_top5</span></code>入参为<code class="docutils literal notranslate"><span class="pre">image</span></code>，出参为<code class="docutils literal notranslate"><span class="pre">label</span></code>和<code class="docutils literal notranslate"><span class="pre">score</span></code>。即，Servable方法的入参由Python函数的入参指定，Servable方法的出参由<code class="docutils literal notranslate"><span class="pre">register_method</span></code>的参数<code class="docutils literal notranslate"><span class="pre">output_names</span></code>指定。</p>
<p>另外方法定义中：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">add_stage</span></code>定义一个<code class="docutils literal notranslate"><span class="pre">Stage</span></code>，指示使用的预处理、模型和后处理，以及它们的输入。<code class="docutils literal notranslate"><span class="pre">Stage</span></code>的输入可以是方法的输入或者前序<code class="docutils literal notranslate"><span class="pre">Stage</span></code>的输出。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">return</span></code>指示了方法的返回数据，可以是方法的输入或者<code class="docutils literal notranslate"><span class="pre">add_stage</span></code>的输出，和<code class="docutils literal notranslate"><span class="pre">register_method</span></code>的<code class="docutils literal notranslate"><span class="pre">output_names</span></code>参数对应。</p></li>
</ul>
<p>用户在客户端使用Servable某个方法提供的服务时，需要通过入参名称指定对应输入的值，通过出参名称获取各个输出的值。比如客户端访问方法<code class="docutils literal notranslate"><span class="pre">classify_top5</span></code>：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">mindspore_serving.client</span> <span class="kn">import</span> <span class="n">Client</span>

<span class="k">def</span> <span class="nf">read_images</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Read images for directory test_image&quot;&quot;&quot;</span>
    <span class="n">image_files</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">images_buffer</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">path</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">file_list</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="s2">&quot;./test_image/&quot;</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">file_list</span><span class="p">:</span>
            <span class="n">image_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
            <span class="n">image_files</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image_file</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">image_file</span> <span class="ow">in</span> <span class="n">image_files</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">image_file</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">images_buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fp</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">image_files</span><span class="p">,</span> <span class="n">images_buffer</span>

<span class="k">def</span> <span class="nf">run_classify_top5</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Client for servable resnet50 and method classify_top5&quot;&quot;&quot;</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s2">&quot;localhost:5500&quot;</span><span class="p">,</span> <span class="s2">&quot;resnet50&quot;</span><span class="p">,</span> <span class="s2">&quot;classify_top5&quot;</span><span class="p">)</span>
    <span class="n">instances</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">image_files</span><span class="p">,</span> <span class="n">images_buffer</span> <span class="o">=</span> <span class="n">read_images</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images_buffer</span><span class="p">:</span>
        <span class="n">instances</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;image&quot;</span><span class="p">:</span> <span class="n">image</span><span class="p">})</span>  <span class="c1"># input `image`</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">instances</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">file</span><span class="p">,</span> <span class="n">result_item</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">image_files</span><span class="p">,</span> <span class="n">result</span><span class="p">):</span>  <span class="c1"># result for every image</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">result_item</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span>  <span class="c1"># result `label`</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">result_item</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span>  <span class="c1"># result `score`</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;file:&quot;</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;label result:&quot;</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;score result:&quot;</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">run_classify_top5</span><span class="p">()</span>
</pre></div>
</div>
<p>另外，一次请求可包括多个实例，且多个排队处理的请求也将有多个实例，如果需要在自定义的预处理或后处理中通过多线程等并发方式处理多个实例，比如在预处理中使用MindData并发能力处理多个输入图片，MindSpore Serving在接口<code class="docutils literal notranslate"><span class="pre">add_stage</span></code>中提供了入参<code class="docutils literal notranslate"><span class="pre">batch_size</span></code>用于注册此类预处理和后处理。详情可参考<a class="reference external" href="https://gitee.com/mindspore/serving/blob/r1.8/example/resnet/resnet50/servable_config.py">ResNet-50样例的模型配置</a> 。</p>
</section>
</section>
<section id="多模型组合">
<h2>多模型组合<a class="headerlink" href="#多模型组合" title="Permalink to this headline"></a></h2>
<p>以一个简单OCR服务为例，涉及Deeptext和CRNN两个模型，客户端发来一张图片，Deeptext模型识别图片中的文本框，CRNN对文本框的内容进行识别，最终向客户端返回文本内容。</p>
<p><img alt="image" src="_images/ocr_example.png" /></p>
<p>一个方法中的<code class="docutils literal notranslate"><span class="pre">Stage</span></code>数量不限制，每个<code class="docutils literal notranslate"><span class="pre">Stage</span></code>可以是模型或者是Python函数，我们可多次使用<code class="docutils literal notranslate"><span class="pre">add_stage</span></code>定义多模型组合的服务。</p>
<p>需要注意的是，由于Python GIL的存在，并非Python任务的<code class="docutils literal notranslate"><span class="pre">Stage</span></code>越多性能越好，在MindSpore Serving服务器中，所有的Python任务在一个Python线程中被调度执行。如果需要提升Python任务的吞吐量，可以参考下文<span class="xref myst">多进程并发</span>。</p>
<p>首先需要在各个模型版本目录中同时存在这两个模型文件，只有一个版本1时，模型配置文件目录结果如下图所示：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ocr
├── 1
│   │── deeptext_bs1.mindir
│   └── crnn_bs1.mindir
└── servable_config.py
</pre></div>
</div>
<p>使用<code class="docutils literal notranslate"><span class="pre">declare_model</span></code>声明Deeptext和CRNN两个模型，使用多个<code class="docutils literal notranslate"><span class="pre">add_stage</span></code>串接两个模型。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">register</span>

<span class="n">deeptext_model</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">declare_model</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s2">&quot;deeptext_bs1.mindir&quot;</span><span class="p">,</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR&quot;</span><span class="p">)</span>

<span class="n">crnn_model</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">declare_model</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s2">&quot;crnn_bs1.mindir&quot;</span><span class="p">,</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">deeptext_prerpocess</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="c1"># decode, resize, normalize, HWC2CHW</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">decode_image</span><span class="p">,</span> <span class="n">scale</span>

<span class="k">def</span> <span class="nf">deeptext_postprocess</span><span class="p">(</span><span class="n">bboxs</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
    <span class="c1"># Get the bbox with the highest score</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">bbox</span>

<span class="k">def</span> <span class="nf">crnn_preprocess</span><span class="p">(</span><span class="n">decode_image</span><span class="p">,</span> <span class="n">bbox</span><span class="p">):</span>
    <span class="c1"># crop, padding, normalize, HWC2CHW</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">cropped_image</span>

<span class="k">def</span> <span class="nf">crnn_postprocess</span><span class="p">(</span><span class="n">text_tensor</span><span class="p">):</span>
    <span class="c1"># Convert text tensor to text</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">text_str</span>

<span class="nd">@register</span><span class="o">.</span><span class="n">register_method</span><span class="p">(</span><span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Define method `classify_top1` for servable `resnet50`.</span>
<span class="sd">     The input is `image` and the output is `label`.&quot;&quot;&quot;</span>
    <span class="n">image</span><span class="p">,</span> <span class="n">decode_image</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">deeptext_prerpocess</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">bboxs</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">deeptext_model</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">bbox</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">deeptext_postprocess</span><span class="p">,</span> <span class="n">bboxs</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">cropped_image</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">crnn_preprocess</span><span class="p">,</span> <span class="n">decode_image</span><span class="p">,</span> <span class="n">bbox</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">text_tensor</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">crnn_model</span><span class="p">,</span> <span class="n">cropped_image</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">text_str</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">crnn_postprocess</span><span class="p">,</span> <span class="n">text_tensor</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text_str</span>
</pre></div>
</div>
</section>
<section id="多进程并发">
<h2>多进程并发<a class="headerlink" href="#多进程并发" title="Permalink to this headline"></a></h2>
<p>影响一个Serving服务器内的一个Servable的吞吐能力主要有两个方面，一是模型推理吞吐能力，其次是预处理、后处理等Python任务的处理时间。模型推理和Python任务并发执行。</p>
<p>如果当增加模型batch size，平均每个batch的处理时间变小，则可权衡吞吐量和时延，适当增加模型的batch size。</p>
<p>另一种方式是增加Worker进程的个数，可通过参数<code class="docutils literal notranslate"><span class="pre">device_ids</span></code>部署到多卡。由于Python GIL的存在，进程内所有的Python任务在一个Python线程中被调度执行，如果Python函数处理时间大于模型推理时间，可通过参数<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>配置额外的进程。</p>
<p>下面示例中的Servable，配置了2个Worker分别占用设备0和1（<code class="docutils literal notranslate"><span class="pre">device_ids</span></code>），可以处理模型推理和Python任务，配置了1个额外Worker，仅处理Python任务，共3（<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>）个Worker。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">mindspore_serving</span> <span class="kn">import</span> <span class="n">server</span>


<span class="k">def</span> <span class="nf">start</span><span class="p">():</span>
    <span class="n">servable_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">realpath</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="c1"># Total 3 worker, two worker occupy device 0 and device 1, the model inference tasks</span>
    <span class="c1"># of other workers are forwarded to the worker that occupies the device.</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">server</span><span class="o">.</span><span class="n">ServableStartConfig</span><span class="p">(</span><span class="n">servable_directory</span><span class="o">=</span><span class="n">servable_dir</span><span class="p">,</span>
                                        <span class="n">servable_name</span><span class="o">=</span><span class="s2">&quot;resnet50&quot;</span><span class="p">,</span>
                                        <span class="n">device_ids</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span>
                                        <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">server</span><span class="o">.</span><span class="n">start_servables</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="n">server</span><span class="o">.</span><span class="n">start_grpc_server</span><span class="p">(</span><span class="s2">&quot;127.0.0.1:5500&quot;</span><span class="p">)</span>
    <span class="n">server</span><span class="o">.</span><span class="n">start_restful_server</span><span class="p">(</span><span class="s2">&quot;127.0.0.1:1500&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">start</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="image" src="_images/parallel.png" /></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="serving_restful.html" class="btn btn-neutral float-left" title="基于RESTful接口访问MindSpore Serving服务" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="serving_multi_subgraphs.html" class="btn btn-neutral float-right" title="实现多子图和有状态模型的服务部署" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>