<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Customized Debugging Information &mdash; MindSpore 0.2.0-alpha documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="On-Device Inference" href="on_device_inference.html" />
    <link rel="prev" title="Natural Language Processing (NLP) Application" href="nlp_application.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation/data_preparation.html">Data Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/saving_and_loading_model_parameters.html">Saving and Loading Model Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/debugging_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Use</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="visualization_tutorials.html">Training Process Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed_precision.html">Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="computer_vision_application.html">Computer Vision Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_application.html">Natural Language Processing (NLP) Application</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Customized Debugging Information</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#introduction-to-callback">Introduction to Callback</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#callback-capabilities-of-mindspore">Callback Capabilities of MindSpore</a></li>
<li class="toctree-l3"><a class="reference internal" href="#custom-callback">Custom Callback</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#mindspore-metrics">MindSpore Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mindspore-print-operator">MindSpore Print Operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#log-related-environment-variables-and-configurations">Log-related Environment Variables and Configurations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="on_device_inference.html">On-Device Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_security.html">Model Security</a></li>
<li class="toctree-l1"><a class="reference internal" href="community.html">Community</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Customized Debugging Information</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/advanced_use/customized_debugging_information.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="customized-debugging-information">
<h1>Customized Debugging Information<a class="headerlink" href="#customized-debugging-information" title="Permalink to this headline"></a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>This section describes how to use the customized capabilities provided by MindSpore, such as callback, metrics, and log printing, to help you quickly debug the training network.</p>
</section>
<section id="introduction-to-callback">
<h2>Introduction to Callback<a class="headerlink" href="#introduction-to-callback" title="Permalink to this headline"></a></h2>
<p>Callback here is not a function but a class. You can use callback to observe the internal status and related information of the network during training or perform specific actions in a specific period.
For example, you can monitor the loss, save model parameters, dynamically adjust parameters, and terminate training tasks in advance.</p>
<section id="callback-capabilities-of-mindspore">
<h3>Callback Capabilities of MindSpore<a class="headerlink" href="#callback-capabilities-of-mindspore" title="Permalink to this headline"></a></h3>
<p>MindSpore provides the callback capabilities to allow users to insert customized operations in a specific phase of training or inference, including:</p>
<ul class="simple">
<li><p>Callback functions such as ModelCheckpoint, LossMonitor, and SummaryStep provided by the MindSpore framework</p></li>
<li><p>Custom callback functions</p></li>
</ul>
<p>Usage: Transfer the callback object in the model.train method. The callback object can be a list, for example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ckpt_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">()</span>
<span class="n">loss_cb</span> <span class="o">=</span> <span class="n">LossMonitor</span><span class="p">()</span>
<span class="n">summary_cb</span> <span class="o">=</span> <span class="n">SummaryStep</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ckpt_cb</span><span class="p">,</span> <span class="n">loss_cb</span><span class="p">,</span> <span class="n">summary_cb</span><span class="p">])</span>
</pre></div>
</div>
<p>ModelCheckpoint can save model parameters for retraining or inference.
LossMonitor can output loss information in logs for users to view. In addition, LossMonitor monitors the loss value change during training. When the loss value is <code class="docutils literal notranslate"><span class="pre">Nan</span></code> or <code class="docutils literal notranslate"><span class="pre">Inf</span></code>, the training terminates.
SummaryStep can save the training information to a file for later use.</p>
</section>
<section id="custom-callback">
<h3>Custom Callback<a class="headerlink" href="#custom-callback" title="Permalink to this headline"></a></h3>
<p>You can customize callback based on the callback base class as required.</p>
<p>The callback base class is defined as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Callback</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Callback base class&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called once before the network executing.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called before each epoch beginning.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called after each epoch finished.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called before each epoch beginning.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called after each step finished.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called once after network training.&quot;&quot;&quot;</span>
        <span class="k">pass</span>
</pre></div>
</div>
<p>The callback can record important information during training and transfer the information to the callback object through a dictionary variable <code class="docutils literal notranslate"><span class="pre">cb_params</span></code>,
You can obtain related attributes from each custom callback and perform customized operations. You can also customize other variables and transfer them to the <code class="docutils literal notranslate"><span class="pre">cb_params</span></code> object.</p>
<p>The main attributes of <code class="docutils literal notranslate"><span class="pre">cb_params</span></code> are as follows:</p>
<ul class="simple">
<li><p>loss_fn: Loss function</p></li>
<li><p>optimizer: Optimizer</p></li>
<li><p>train_dataset: Training dataset</p></li>
<li><p>cur_epoch_num: Number of current epochs</p></li>
<li><p>cur_step_num: Number of current steps</p></li>
<li><p>batch_num: Number of steps in an epoch</p></li>
<li><p>…</p></li>
</ul>
<p>You can inherit the callback base class to customize a callback object.</p>
<p>The following example describes how to use a custom callback function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">StopAtTime</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_time</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StopAtTime</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">run_time</span> <span class="o">=</span> <span class="n">run_time</span><span class="o">*</span><span class="mi">60</span>

    <span class="k">def</span> <span class="nf">begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">cb_params</span><span class="o">.</span><span class="n">init_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">epoch_num</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span>
        <span class="n">step_num</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cb_params</span>
        <span class="n">cur_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">cur_time</span> <span class="o">-</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">init_time</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_time</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;epoch: &quot;</span><span class="p">,</span> <span class="n">epoch_num</span><span class="p">,</span> <span class="s2">&quot; step: &quot;</span><span class="p">,</span> <span class="n">step_num</span><span class="p">,</span> <span class="s2">&quot; loss: &quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
            <span class="n">run_context</span><span class="o">.</span><span class="n">request_stop</span><span class="p">()</span>

<span class="n">stop_cb</span> <span class="o">=</span> <span class="n">StopAtTime</span><span class="p">(</span><span class="n">run_time</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">stop_cb</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 20 step: 32 loss: 2.298344373703003
</pre></div>
</div>
<p>This callback function is used to terminate the training within a specified period. You can use the <code class="docutils literal notranslate"><span class="pre">run_context.original_args()</span></code> method to obtain the <code class="docutils literal notranslate"><span class="pre">cb_params</span></code> dictionary, which contains the main attribute information described above.
In addition, you can modify and add values in the dictionary. In the preceding example, an <code class="docutils literal notranslate"><span class="pre">init_time</span></code> object is defined in <code class="docutils literal notranslate"><span class="pre">begin()</span></code> and transferred to the <code class="docutils literal notranslate"><span class="pre">cb_params</span></code> dictionary.
A decision is made at each <code class="docutils literal notranslate"><span class="pre">step_end</span></code>. When the training time is greater than the configured time threshold, a training termination signal will be sent to the <code class="docutils literal notranslate"><span class="pre">run_context</span></code> to terminate the training in advance and the current values of epoch, step, and loss will be printed.</p>
</section>
</section>
<section id="mindspore-metrics">
<h2>MindSpore Metrics<a class="headerlink" href="#mindspore-metrics" title="Permalink to this headline"></a></h2>
<p>After the training is complete, you can use metrics to evaluate the training result.</p>
<p>MindSpore provides multiple metrics, such as <code class="docutils literal notranslate"><span class="pre">accuracy</span></code>, <code class="docutils literal notranslate"><span class="pre">loss</span></code>, <code class="docutils literal notranslate"><span class="pre">tolerance</span></code>, <code class="docutils literal notranslate"><span class="pre">recall</span></code>, and <code class="docutils literal notranslate"><span class="pre">F1</span></code>.</p>
<p>You can define a metrics dictionary object that contains multiple metrics and transfer them to the <code class="docutils literal notranslate"><span class="pre">model.eval</span></code> interface to verify the training precision.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(),</span>
    <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Loss</span><span class="p">(),</span>
    <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Precision</span><span class="p">(),</span>
    <span class="s1">&#39;recall&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Recall</span><span class="p">(),</span>
    <span class="s1">&#39;f1_score&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">F1</span><span class="p">()</span>
<span class="p">}</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">ResNet</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>
<span class="n">ds_eval</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">ds_eval</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code> method returns a dictionary that contains the metrics and results transferred to the metrics.</p>
<p>You can also define your own metrics class by inheriting the <code class="docutils literal notranslate"><span class="pre">Metric</span></code> base class and rewriting the <code class="docutils literal notranslate"><span class="pre">clear</span></code>, <code class="docutils literal notranslate"><span class="pre">update</span></code>, and <code class="docutils literal notranslate"><span class="pre">eval</span></code> methods.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> operator is used as an example to describe the internal implementation principle.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> inherits the <code class="docutils literal notranslate"><span class="pre">EvaluationBase</span></code> base class and rewrites the preceding three methods.
The <code class="docutils literal notranslate"><span class="pre">clear()</span></code> method initializes related calculation parameters in the class.
The <code class="docutils literal notranslate"><span class="pre">update()</span></code> method accepts the predicted value and tag value and updates the internal variables of accuracy.
The <code class="docutils literal notranslate"><span class="pre">eval()</span></code> method calculates related indicators and returns the calculation result.
By invoking the <code class="docutils literal notranslate"><span class="pre">eval</span></code> method of <code class="docutils literal notranslate"><span class="pre">accuracy</span></code>, you will obtain the calculation result.</p>
<p>You can understand how <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> runs by using the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]]))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">Accuracy</span><span class="p">()</span>
<span class="n">metric</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
<span class="n">metric</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy is &#39;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Accuracy is 0.6667
</pre></div>
</div>
</section>
<section id="mindspore-print-operator">
<h2>MindSpore Print Operator<a class="headerlink" href="#mindspore-print-operator" title="Permalink to this headline"></a></h2>
<p>MindSpore-developed print operator is used to print the tensors or character strings input by users. Multiple strings, multiple tensors, and a combination of tensors and strings are supported, which are separated by comma (,).
The use method of MindSpore print operator is the same that of other operators. You need to assert MindSpore print operator in <code class="docutils literal notranslate"><span class="pre">__init__</span></code>() and invoke using <code class="docutils literal notranslate"><span class="pre">construct()</span></code>. The following is an example.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">PrintDemo</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PrintDemo</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">print</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Print</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="s1">&#39;print Tensor x and Tensor y:&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">PrintDemo</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>print Tensor x and Tensor y:
Tensor shape:[[const vector][2, 1]]Int32
val:[[1]
[1]]
Tensor shape:[[const vector][2, 2]]Int32
val:[[1 1]
[1 1]]
</pre></div>
</div>
</section>
<section id="log-related-environment-variables-and-configurations">
<h2>Log-related Environment Variables and Configurations<a class="headerlink" href="#log-related-environment-variables-and-configurations" title="Permalink to this headline"></a></h2>
<p>MindSpore uses glog to output logs. The following environment variables are commonly used:</p>
<ol class="arabic simple">
<li><p>GLOG_v specifies the log level. The default value is 2, indicating the WARNING level. The values are as follows: 0: DEBUG; 1: INFO; 2: WARNING; 3: ERROR.</p></li>
<li><p>When GLOG_logtostderr is set to 1, logs are output to the screen. If the value is set to 0, logs are output to a file. Default value: 1</p></li>
<li><p>GLOG_log_dir=YourPath specifies the log output path. If GLOG_logtostderr is set to 0, value of this variable must be specified. If GLOG_log_dir is specified and the value of GLOG_logtostderr is 1, logs are output to the screen but not to a file. Logs of C++ and Python will be output to different files. The file name of C++ log complies with the naming rule of GLOG log file. Here, the name is <code class="docutils literal notranslate"><span class="pre">mindspore.MachineName.UserName.log.LogLevel.Timestamp</span></code>. The file name of Python log is <code class="docutils literal notranslate"><span class="pre">mindspore.log</span></code>.</p></li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="nlp_application.html" class="btn btn-neutral float-left" title="Natural Language Processing (NLP) Application" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="on_device_inference.html" class="btn btn-neutral float-right" title="On-Device Inference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>