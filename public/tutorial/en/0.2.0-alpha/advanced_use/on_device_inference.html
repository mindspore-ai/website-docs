<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>On-Device Inference &mdash; MindSpore 0.2.0-alpha documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Model Security" href="model_security.html" />
    <link rel="prev" title="Customized Debugging Information" href="customized_debugging_information.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation/data_preparation.html">Data Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/saving_and_loading_model_parameters.html">Saving and Loading Model Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/debugging_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Use</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="visualization_tutorials.html">Training Process Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed_precision.html">Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="computer_vision_application.html">Computer Vision Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_application.html">Natural Language Processing (NLP) Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="customized_debugging_information.html">Customized Debugging Information</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">On-Device Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#compilation-method">Compilation Method</a></li>
<li class="toctree-l2"><a class="reference internal" href="#use-of-on-device-inference">Use of On-Device Inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#generating-an-on-device-model-file">Generating an On-Device Model File</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implementing-on-device-inference">Implementing On-Device Inference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_security.html">Model Security</a></li>
<li class="toctree-l1"><a class="reference internal" href="community.html">Community</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>On-Device Inference</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/advanced_use/on_device_inference.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="on-device-inference">
<h1>On-Device Inference<a class="headerlink" href="#on-device-inference" title="Permalink to this headline"></a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>MindSpore Predict is a lightweight deep neural network inference engine that provides the inference function for models trained by MindSpore on the device side. This tutorial describes how to use and compile MindSpore Predict.</p>
</section>
<section id="compilation-method">
<h2>Compilation Method<a class="headerlink" href="#compilation-method" title="Permalink to this headline"></a></h2>
<p>You need to compile the MindSpore Predict by yourself. This section describes how to perform cross compilation in the Ubuntu environment.</p>
<p>The environment requirements are as follows:</p>
<ul>
<li><p>Hardware requirements</p>
<ul class="simple">
<li><p>Memory: 1 GB or above</p></li>
<li><p>Hard disk space: 10 GB or above</p></li>
</ul>
</li>
<li><p>System requirements</p>
<ul class="simple">
<li><p>System: Ubuntu = 16.04.02LTS (availability is checked)</p></li>
<li><p>Kernel: 4.4.0-62-generic (availability is checked)</p></li>
</ul>
</li>
<li><p>Software dependencies</p>
<ul class="simple">
<li><p><a class="reference external" href="https://cmake.org/download/">cmake</a> &gt;= 3.14.1</p></li>
<li><p><a class="reference external" href="https://gcc.gnu.org/releases.html">GCC</a> &gt;= 5.4</p></li>
<li><p><a class="reference external" href="http://ftp.gnu.org/gnu/autoconf/">autoconf</a> 2.69</p></li>
<li><p><a class="reference external" href="http://releases.llvm.org/8.0.0/clang+llvm-8.0.0-x86_64-linux-gnu-ubuntu-16.04.tar.xz">LLVM 8.0.0</a></p></li>
<li><p><a class="reference external" href="https://dl.google.com/android/repository/android-ndk-r16b-linux-x86_64.zip">Android_NDK r16b</a></p></li>
<li><p>numpy &gt;= 1.16</p></li>
<li><p>decorator</p></li>
<li><p>scipy</p></li>
</ul>
<blockquote>
<div><p>numpy, decorator and scipy can be installed through pip.  The reference command is as following.</p>
</div></blockquote>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip3<span class="w"> </span>install<span class="w"> </span><span class="nv">numpy</span><span class="o">==</span><span class="m">1</span>.16<span class="w"> </span>decorator<span class="w"> </span>scipy
</pre></div>
</div>
</li>
</ul>
<p>The compilation procedure is as follows:</p>
<ol class="arabic">
<li><p>Configure environment variables.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">LLVM_PATH</span><span class="o">={</span><span class="nv">$LLVM_PATH</span><span class="o">}</span>/clang+llvm-8.0.0-x86_64-linux-gnu-ubuntu-16.04/bin/llvm-config<span class="w"> </span><span class="c1">#Set the LLVM path.</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">ANDROID_NDK</span><span class="o">={</span><span class="nv">$NDK_PATH</span><span class="o">}</span>/android-ndk-r16b<span class="w"> </span><span class="c1">#Set the NDK path.</span>
</pre></div>
</div>
</li>
<li><p>Download source code from the code repository.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://gitee.com/mindspore/mindspore.git<span class="w"> </span>-b<span class="w"> </span>r0.2
</pre></div>
</div>
</li>
<li><p>Run the following command in the root directory of the source code to compile MindSpore Predict: -I indicates options for compiling MindSpore Predict and the parameter is the target platform architecture. Currently, only the Android arm64 platform is supported.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sh<span class="w"> </span>build.sh<span class="w"> </span>-I<span class="w"> </span>arm64
</pre></div>
</div>
</li>
<li><p>Obtain the compilation result.</p>
<p>Go to the predict/output directory of the source code to view the generated package. The package name is MSPredict-{Version number}-{Host platform}_{Device platform}.tar.gz, for example, MSPredict-0.1.0-linux_aarch64.tar.gz. The package contains the following directories:</p>
<ul class="simple">
<li><p>include: MindSpore Predict header file.</p></li>
<li><p>lib: MindSpore Predict dynamic library.</p></li>
</ul>
</li>
</ol>
</section>
<section id="use-of-on-device-inference">
<h2>Use of On-Device Inference<a class="headerlink" href="#use-of-on-device-inference" title="Permalink to this headline"></a></h2>
<p>When MindSpore is used to perform model inference in the APK project of an app, preprocessing input is required before model inference. For example, before an image is converted into the tensor format required by MindSpore inference, the image needs to be resized. After MindSpore completes model inference, postprocess the model inference result and sends the processed output to the app.</p>
<p>This section describes how to use MindSpore to perform model inference. The setup of an APK project and pre- and post-processing of model inference are not described here.</p>
<p>To perform on-device model inference using MindSpore, perform the following steps.</p>
<section id="generating-an-on-device-model-file">
<h3>Generating an On-Device Model File<a class="headerlink" href="#generating-an-on-device-model-file" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>After training is complete, load the generated checkpoint file to the defined network.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">ckpoint_file_name</span><span class="o">=</span><span class="n">ckpt_file_path</span><span class="p">)</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Call the <code class="docutils literal notranslate"><span class="pre">export</span></code> API to export the .ms model file on the device.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">export</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">input_data</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">&quot;./lenet.ms&quot;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;LITE&#39;</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
<p>Take the LeNet network as an example. The generated on-device model file is <code class="docutils literal notranslate"><span class="pre">lenet.ms</span></code>. The complete sample code lenet.py is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>
<span class="kn">from</span> <span class="nn">mindspore.common.tensor</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">export</span><span class="p">,</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>

<span class="k">class</span> <span class="nc">LeNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Reshape</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_x</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">origin_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">255</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">origin_data</span><span class="o">.</span><span class="n">tofile</span><span class="p">(</span><span class="s2">&quot;lenet.bin&quot;</span><span class="p">)</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">origin_data</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span>
    <span class="n">ckpt_file_path</span> <span class="o">=</span> <span class="s2">&quot;path_to/lenet.ckpt&quot;</span>

    <span class="n">is_ckpt_exist</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">ckpt_file_path</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">is_ckpt_exist</span><span class="p">:</span>
        <span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">ckpoint_file_name</span><span class="o">=</span><span class="n">ckpt_file_path</span><span class="p">)</span>
        <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
        <span class="n">export</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">input_data</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">&quot;./lenet.ms&quot;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;LITE&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;export model success.&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;checkpoint file does not exist.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="implementing-on-device-inference">
<h3>Implementing On-Device Inference<a class="headerlink" href="#implementing-on-device-inference" title="Permalink to this headline"></a></h3>
<p>Use the .ms model file and image data as input to create a session and implement inference on the device.</p>
<p><img alt="" src="../_images/side_infer_process.png" /></p>
<p>Figure 1 On-device inference sequence diagram</p>
<ol class="arabic">
<li><p>Load the .ms model file to the memory buffer. The ReadFile function needs to be implemented by users, according to the <a class="reference external" href="http://www.cplusplus.com/doc/tutorial/files/">C++ tutorial</a>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// read model file</span>
<span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">modelPath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;./models/lenet/lenet.ms&quot;</span><span class="p">;</span>
<span class="kt">size_t</span><span class="w"> </span><span class="n">graphSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="cm">/* ReadFile() here is a dummy function */</span>
<span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">graphBuf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ReadFile</span><span class="p">(</span><span class="n">modelPath</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span><span class="w"> </span><span class="n">graphSize</span><span class="p">);</span>
</pre></div>
</div>
</li>
<li><p>Call the CreateSession API to create a session. After the session is created, the model file in the memory buffer can be released.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// create session</span>
<span class="n">Context</span><span class="w"> </span><span class="n">ctx</span><span class="p">;</span>
<span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">Session</span><span class="o">&gt;</span><span class="w"> </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CreateSession</span><span class="p">(</span><span class="n">graphBuf</span><span class="p">,</span><span class="w"> </span><span class="n">graphSize</span><span class="p">,</span><span class="w"> </span><span class="n">ctx</span><span class="p">);</span>
<span class="n">free</span><span class="p">(</span><span class="n">graphBuf</span><span class="p">);</span>
</pre></div>
</div>
</li>
<li><p>Read the input data for inference from the memory buffer and call the SetData() API to set the input data to input tensor.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// load input buffer</span>
<span class="kt">size_t</span><span class="w"> </span><span class="n">inputSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">imagePath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;./data/input/lenet.bin&quot;</span><span class="p">;</span>
<span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">inputBuf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ReadFile</span><span class="p">(</span><span class="n">imagePath</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span><span class="w"> </span><span class="n">inputSize</span><span class="p">);</span>

<span class="c1">//get input tensors</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">GetInput</span><span class="p">();</span>
<span class="c1">//set input buffer</span>
<span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-&gt;</span><span class="n">SetData</span><span class="p">(</span><span class="n">inputBuf</span><span class="p">);</span>
</pre></div>
</div>
</li>
<li><p>Call the Run() API in the session to perform inference.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// session run</span>
<span class="kt">int</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">Run</span><span class="p">(</span><span class="n">inputs</span><span class="p">);</span>
</pre></div>
</div>
</li>
<li><p>Call the GetAllOutput() API to obtain the output.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// get output</span>
<span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="w"> </span><span class="o">*&gt;&gt;</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">GetAllOutput</span><span class="p">();</span>
</pre></div>
</div>
</li>
<li><p>Call the Getdata() API to get the output data.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// get output data</span>
<span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">outputs</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">second</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">tensors</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)(</span><span class="n">tensor</span><span class="o">-&gt;</span><span class="n">GetData</span><span class="p">());</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>Release input and output tensors after the inference is complete.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// free inputs and outputs</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">input</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">inputs</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">delete</span><span class="w"> </span><span class="n">input</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">output</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">outputs</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputTensor</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">second</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">delete</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
<span class="n">outputs</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
</pre></div>
</div>
</li>
</ol>
<p>Select the LeNet network and set the inference input to lenet.bin. The complete sample code lenet.cpp is as follows:</p>
<blockquote>
<div><p>MindSpore Predict uses FlatBuffers to define models. The FlatBuffers header file is required for parsing models. Therefore, you need to configure the FlatBuffers header file.</p>
<p>Method: Copy the flatbuffers folder in MindSpore root directory/third_party/flatbuffers/include to the directory at the same level as session.h.</p>
</div></blockquote>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;string&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;context.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;session.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;tensor.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;errorcode.h&quot;</span>

<span class="k">using</span><span class="w"> </span><span class="k">namespace</span><span class="w"> </span><span class="nn">mindspore</span><span class="o">::</span><span class="nn">predict</span><span class="p">;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">modelPath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;./models/lenet/lenet.ms&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">imagePath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;./data/input/lenet.bin&quot;</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// read model file</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">graphSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* ReadFile() here is a dummy function */</span>
<span class="w">  </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">graphBuf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ReadFile</span><span class="p">(</span><span class="n">modelPath</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span><span class="w"> </span><span class="n">graphSize</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">graphBuf</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// create session</span>
<span class="w">  </span><span class="n">Context</span><span class="w"> </span><span class="n">ctx</span><span class="p">;</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CreateSession</span><span class="p">(</span><span class="n">graphBuf</span><span class="p">,</span><span class="w"> </span><span class="n">graphSize</span><span class="p">,</span><span class="w"> </span><span class="n">ctx</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">session</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">graphBuf</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">free</span><span class="p">(</span><span class="n">graphBuf</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// load input buf</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">inputSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">  </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">inputBuf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ReadFile</span><span class="p">(</span><span class="n">imagePath</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span><span class="w"> </span><span class="n">inputSize</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">inputBuf</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">GetInput</span><span class="p">();</span>
<span class="w">  </span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-&gt;</span><span class="n">SetData</span><span class="p">(</span><span class="n">inputBuf</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// session run</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">Run</span><span class="p">(</span><span class="n">inputs</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">RET_OK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;run failed, error: %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ret</span><span class="p">);</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">input</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">inputs</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">delete</span><span class="w"> </span><span class="n">input</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// get output</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">GetAllOutput</span><span class="p">();</span>

<span class="w">  </span><span class="c1">// get output data</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">outputs</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">second</span><span class="p">;</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">tensors</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)(</span><span class="n">tensor</span><span class="o">-&gt;</span><span class="n">GetData</span><span class="p">());</span>
<span class="w">      </span><span class="c1">//print the contents of the data</span>
<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">tensor</span><span class="o">-&gt;</span><span class="n">GetElementSize</span><span class="p">();</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot; %f &quot;</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">      </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// free inputs and outputs</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">input</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">inputs</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">delete</span><span class="w"> </span><span class="n">input</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">inputs</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">output</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">outputs</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputTensor</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">second</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">delete</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">outputs</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="customized_debugging_information.html" class="btn btn-neutral float-left" title="Customized Debugging Information" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="model_security.html" class="btn btn-neutral float-right" title="Model Security" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>