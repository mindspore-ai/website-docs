<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Training Process Visualization &mdash; MindSpore 0.2.0-alpha documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Mixed Precision" href="mixed_precision.html" />
    <link rel="prev" title="Debugging in PyNative Mode" href="../use/debugging_in_pynative_mode.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation/data_preparation.html">Data Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/saving_and_loading_model_parameters.html">Saving and Loading Model Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/debugging_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Use</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Training Process Visualization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#operation-process">Operation Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="#preparing-the-training-script">Preparing the Training Script</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mindinsight-commands">MindInsight Commands</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#view-the-command-help-information">View the command help information</a></li>
<li class="toctree-l3"><a class="reference internal" href="#view-the-version-information">View the version information</a></li>
<li class="toctree-l3"><a class="reference internal" href="#start-the-service">Start the service</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stop-the-service">Stop the service</a></li>
<li class="toctree-l3"><a class="reference internal" href="#view-the-service-process-information">View the service process information</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#visualization-components">Visualization Components</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#computational-graph-visualization">Computational Graph Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scalar-visualization">Scalar Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#image-visualization">Image Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-lineage-visualization">Model Lineage Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dataset-graph-visualization">Dataset Graph Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dataset-lineage-visualization">Dataset Lineage Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parameter-distribution">Parameter Distribution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mixed_precision.html">Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="computer_vision_application.html">Computer Vision Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_application.html">Natural Language Processing (NLP) Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="customized_debugging_information.html">Customized Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="on_device_inference.html">On-Device Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_security.html">Model Security</a></li>
<li class="toctree-l1"><a class="reference internal" href="community.html">Community</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Training Process Visualization</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/advanced_use/visualization_tutorials.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="training-process-visualization">
<h1>Training Process Visualization<a class="headerlink" href="#training-process-visualization" title="Permalink to this headline"></a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>Scalars, images, computational graphs, and model hyperparameters during training are recorded in files and can be viewed on the web page.</p>
</section>
<section id="operation-process">
<h2>Operation Process<a class="headerlink" href="#operation-process" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>Prepare a training script, specify scalars, images, computational graphs, and model hyperparameters in the training script, record them in the summary log file, and run the training script.</p></li>
<li><p>Start MindInsight and specify the summary log file directory using startup parameters. After MindInsight is started, access the visualization page based on the IP address and port number. The default access IP address is <code class="docutils literal notranslate"><span class="pre">http://127.0.0.1:8080</span></code>.</p></li>
<li><p>During the training, when data is written into the summary log file, you can view the data on the web page.</p></li>
</ul>
</section>
<section id="preparing-the-training-script">
<h2>Preparing the Training Script<a class="headerlink" href="#preparing-the-training-script" title="Permalink to this headline"></a></h2>
<p>Currently, MindSpore uses the <code class="docutils literal notranslate"><span class="pre">Callback</span></code> mechanism to save scalars, images, computational graphs, and model hyperparameters to summary log files and display them on the web page.</p>
<p>Scalar and image data is recorded by using the <code class="docutils literal notranslate"><span class="pre">Summary</span></code> operator. A computational graph is saved to the summary log file by using <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code> after network compilation is complete.
Model parameters are saved to the summary log file by using <code class="docutils literal notranslate"><span class="pre">TrainLineage</span></code> or <code class="docutils literal notranslate"><span class="pre">EvalLineage</span></code>.</p>
<p>Step 1: Call the <code class="docutils literal notranslate"><span class="pre">Summary</span></code> operator in the <code class="docutils literal notranslate"><span class="pre">construct</span></code> function of the derived class that inherits <code class="docutils literal notranslate"><span class="pre">nn.Cell</span></code> to collect image or scalar data.</p>
<p>For example, when a network is defined, image data is recorded in <code class="docutils literal notranslate"><span class="pre">construct</span></code> of the network. When the loss function is defined, the loss value is recorded in <code class="docutils literal notranslate"><span class="pre">construct</span></code> of the loss function.</p>
<p>Record the dynamic learning rate in <code class="docutils literal notranslate"><span class="pre">construct</span></code> of the optimizer when defining the optimizer.</p>
<p>The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Optimizer</span>


<span class="k">class</span> <span class="nc">CrossEntropyLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Loss function definition.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CrossEntropyLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cross_entropy</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">OneHot</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># Init ScalarSummary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sm_scalar</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ScalarSummary</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">logits</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">label</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>

        <span class="c1"># Record loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sm_scalar</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>


<span class="k">class</span> <span class="nc">MyOptimizer</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimizer definition.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="o">......</span><span class="p">):</span>
        <span class="o">......</span>
        <span class="c1"># Initialize ScalarSummary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sm_scalar</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ScalarSummary</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">HistogramSummary</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="o">......</span>
        <span class="c1"># Record learning rate here</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sm_scalar</span><span class="p">(</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>

        <span class="c1"># Record weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">paramters</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1"># Record gradient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;.gradient&quot;</span><span class="p">,</span> <span class="n">grads</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="o">......</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Net definition.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="o">......</span>

        <span class="c1"># Init ImageSummary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sm_image</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ImageSummary</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="c1"># Record image by Summary operator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sm_image</span><span class="p">(</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        <span class="o">......</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
<p>Step 2: Use the <code class="docutils literal notranslate"><span class="pre">Callback</span></code> mechanism to add the required callback instance to specify the data to be recorded during training.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">SummaryStep</span></code> specifies the step interval for recording summary data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TrainLineage</span></code> records parameters related to model training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">EvalLineage</span></code> records parameters related to the model test.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">network</span></code> parameter needs to be specified when <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code> is called to record the computational graph. By default, the computational graph is not recorded.</p>
<p>The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindinsight.lineagemgr</span> <span class="kn">import</span> <span class="n">TrainLineage</span><span class="p">,</span> <span class="n">EvalLineage</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">SummaryStep</span>
<span class="kn">from</span> <span class="nn">mindspore.train.summary.summary_record</span> <span class="kn">import</span> <span class="n">SummaryRecord</span>


<span class="k">def</span> <span class="nf">test_summary</span><span class="p">():</span>
    <span class="c1"># Init context env</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">)</span>
    <span class="c1"># Init hyperparameter</span>
    <span class="n">epoch</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="c1"># Init network and Model</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optim</span> <span class="o">=</span> <span class="n">MyOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="c1"># Init SummaryRecord and specify a folder for storing summary log files</span>
    <span class="c1"># and specify the graph that needs to be recorded</span>
    <span class="n">summary_writer</span> <span class="o">=</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s1">&#39;./summary&#39;</span><span class="p">,</span> <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
    <span class="n">summary_callback</span> <span class="o">=</span> <span class="n">SummaryStep</span><span class="p">(</span><span class="n">summary_writer</span><span class="p">,</span> <span class="n">flush_step</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="c1"># Init TrainLineage to record the training information</span>
    <span class="n">train_callback</span> <span class="o">=</span> <span class="n">TrainLineage</span><span class="p">(</span><span class="n">summary_writer</span><span class="p">)</span>

    <span class="c1"># Prepare mindrecord_dataset for training</span>
    <span class="n">train_ds</span> <span class="o">=</span> <span class="n">create_mindrecord_dataset_for_training</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">train_ds</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_callback</span><span class="p">,</span> <span class="n">train_callback</span><span class="p">])</span>

    <span class="c1"># Init EvalLineage to record the evaluation information</span>
    <span class="n">eval_callback</span> <span class="o">=</span> <span class="n">EvalLineage</span><span class="p">(</span><span class="n">summary_writer</span><span class="p">)</span>

    <span class="c1"># Prepare mindrecord_dataset for testing</span>
    <span class="n">eval_ds</span> <span class="o">=</span> <span class="n">create_mindrecord_dataset_for_testing</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">eval_ds</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">eval_callback</span><span class="p">])</span>

    <span class="c1"># Close summary</span>
    <span class="n">summary_writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>Use the <code class="docutils literal notranslate"><span class="pre">save_graphs</span></code> option of <code class="docutils literal notranslate"><span class="pre">context</span></code> to record the computational graph after operator fusion.
<code class="docutils literal notranslate"><span class="pre">ms_output_after_hwopt.pb</span></code> is the computational graph after operator fusion.</p>
<blockquote>
<div><p>Currently MindSpore supports recording computational graph after operator fusion for Ascend 910 AI processor only.</p>
</div></blockquote>
<blockquote>
<div><p>It’s recommended that you reduce calls to <code class="docutils literal notranslate"><span class="pre">HistogramSummary</span></code> under 10 times per batch. The more you call <code class="docutils literal notranslate"><span class="pre">HistogramSummary</span></code>, the more performance overhead.</p>
</div></blockquote>
</section>
<section id="mindinsight-commands">
<h2>MindInsight Commands<a class="headerlink" href="#mindinsight-commands" title="Permalink to this headline"></a></h2>
<section id="view-the-command-help-information">
<h3>View the command help information<a class="headerlink" href="#view-the-command-help-information" title="Permalink to this headline"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mindinsight<span class="w"> </span>--help
</pre></div>
</div>
</section>
<section id="view-the-version-information">
<h3>View the version information<a class="headerlink" href="#view-the-version-information" title="Permalink to this headline"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mindinsight<span class="w"> </span>--version
</pre></div>
</div>
</section>
<section id="start-the-service">
<h3>Start the service<a class="headerlink" href="#start-the-service" title="Permalink to this headline"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mindinsight<span class="w"> </span>start<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span><span class="o">[</span>--config<span class="w"> </span>&lt;CONFIG&gt;<span class="o">]</span><span class="w"> </span><span class="o">[</span>--workspace<span class="w"> </span>&lt;WORKSPACE&gt;<span class="o">]</span>
<span class="w">                  </span><span class="o">[</span>--port<span class="w"> </span>&lt;PORT&gt;<span class="o">]</span><span class="w"> </span><span class="o">[</span>--reload-interval<span class="w"> </span>&lt;RELOAD_INTERVAL&gt;<span class="o">]</span>
<span class="w">                  </span><span class="o">[</span>--summary-base-dir<span class="w"> </span>&lt;SUMMARY_BASE_DIR&gt;<span class="o">]</span>
</pre></div>
</div>
<p>Optional parameters as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-h,</span> <span class="pre">--help</span></code> : Displays the help information about the startup command.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--config</span> <span class="pre">&lt;CONFIG&gt;</span></code> : Specifies the configuration file or module. CONFIG indicates the physical file path (file:/path/to/config.py), or a module path (python:path.to.config.module) that can be identified by Python.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--workspace</span> <span class="pre">&lt;WORKSPACE&gt;</span></code> : Specifies the working directory. The default value of WORKSPACE is $HOME/mindinsight.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--port</span> <span class="pre">&lt;PORT&gt;</span></code> : Specifies the port number of the web visualization service. The value ranges from 1 to 65535. The default value of PORT is 8080.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--reload-interval</span> <span class="pre">&lt;RELOAD_INTERVAL&gt;</span></code> : Specifies the interval (unit: second) for loading data. The value 0 indicates that data is loaded only once. The default value of RELOAD_INTERVAL is 3 seconds.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--summary-base-dir</span> <span class="pre">&lt;SUMMARY_BASE_DIR&gt;</span></code> : Specifies the root directory for loading training log data. MindInsight traverses the direct subdirectories in this directory and searches for log files whose names comply with the regular expression ‘summary.\d+’ or ‘.pb$’. If a direct subdirectory contains log files, it is identified as the log file directory. If a root directory contains log files, it is identified as the log file directory. SUMMARY_BASE_DIR is the current directory path by default.</p></li>
</ul>
<blockquote>
<div><p>When the service is started, the parameter values of the command line are saved as the environment variables of the process and start with <code class="docutils literal notranslate"><span class="pre">MINDINSIGHT_</span></code>, for example, <code class="docutils literal notranslate"><span class="pre">MINDINSIGHT_CONFIG</span></code>, <code class="docutils literal notranslate"><span class="pre">MINDINSIGHT_WORKSPACE</span></code>, and <code class="docutils literal notranslate"><span class="pre">MINDINSIGHT_PORT</span></code>.</p>
</div></blockquote>
</section>
<section id="stop-the-service">
<h3>Stop the service<a class="headerlink" href="#stop-the-service" title="Permalink to this headline"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mindinsight<span class="w"> </span>stop<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span><span class="o">[</span>--port<span class="w"> </span>PORT<span class="o">]</span>
</pre></div>
</div>
<p>Optional parameters as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-h,</span> <span class="pre">--help</span></code> : Displays the help information about the stop command.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--port</span> <span class="pre">&lt;PORT&gt;</span></code> : Specifies the port number of the web visualization service. The value ranges from 1 to 65535. The default value of PORT is 8080.</p></li>
</ul>
</section>
<section id="view-the-service-process-information">
<h3>View the service process information<a class="headerlink" href="#view-the-service-process-information" title="Permalink to this headline"></a></h3>
<p>MindInsight provides user with web services. Run the following command to view the running web service process:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ps<span class="w"> </span>-ef<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>mindinsight
</pre></div>
</div>
<p>Run the following command to access the working directory WORKSPACE corresponding to the service process based on the service process ID:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>lsof<span class="w"> </span>-p<span class="w"> </span>&lt;PID&gt;<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>access
</pre></div>
</div>
<p>Output with the working directory WORKSPACE as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>gunicorn<span class="w">  </span>&lt;PID&gt;<span class="w">  </span>&lt;USER&gt;<span class="w">  </span>&lt;FD&gt;<span class="w">  </span>&lt;TYPE&gt;<span class="w">  </span>&lt;DEVICE&gt;<span class="w">  </span>&lt;SIZE/OFF&gt;<span class="w">  </span>&lt;NODE&gt;<span class="w">  </span>&lt;WORKSPACE&gt;/log/gunicorn/access.log
</pre></div>
</div>
</section>
</section>
<section id="visualization-components">
<h2>Visualization Components<a class="headerlink" href="#visualization-components" title="Permalink to this headline"></a></h2>
<section id="computational-graph-visualization">
<h3>Computational Graph Visualization<a class="headerlink" href="#computational-graph-visualization" title="Permalink to this headline"></a></h3>
<p>Computational graph visualization is used to display the graph structure, data flow direction, and control flow direction of a computational graph. It supports visualization of summary log files and pb files generated by <code class="docutils literal notranslate"><span class="pre">save_graphs</span></code> configuration in <code class="docutils literal notranslate"><span class="pre">context</span></code>.</p>
<p><img alt="graph.png" src="../_images/graph.png" /></p>
<p>Figure 1: Computational graph display area</p>
<p>Figure 1 shows the network structure of a computational graph. As shown in the figure, select an operator in the right area of the display area. The operator has two inputs and three outputs (the solid line indicates the data flow direction of the operator).</p>
<p><img alt="graph_sidebar.png" src="../_images/graph_sidebar.png" /></p>
<p>Figure 2 Computational graph function area</p>
<p>Figure 2 shows the function area of the computational graph, including:</p>
<ul class="simple">
<li><p>File selection box: View the computational graphs of different files.</p></li>
<li><p>Search box: Enter a node name and press Enter to view the node.</p></li>
<li><p>Thumbnail: Display the thumbnail of the entire network structure. When viewing an extra large image structure, you can view the currently browsed area.</p></li>
<li><p>Node information: Display the basic information of the selected node, including the node name, properties, input node, and output node.</p></li>
<li><p>Legend: Display the meaning of each icon in the computational graph.</p></li>
</ul>
</section>
<section id="scalar-visualization">
<h3>Scalar Visualization<a class="headerlink" href="#scalar-visualization" title="Permalink to this headline"></a></h3>
<p>Scalar visualization is used to display the change trend of scalars during training.</p>
<p><img alt="scalar.png" src="../_images/scalar.png" /></p>
<p>Figure 3: Scalar trend chart</p>
<p>Figure 3 shows a change process of loss values during the neural network training. The horizontal coordinate indicates the training step, and the vertical coordinate indicates the loss value.</p>
<p>Buttons from left to right in the upper right corner of the figure are used to display the chart in full screen, switch the Y-axis scale, enable or disable the rectangle selection, roll back the chart step by step, and restore the chart.</p>
<ul class="simple">
<li><p>Full-screen Display: Display the scalar curve in full screen. Click the button again to restore it.</p></li>
<li><p>Switch Y-axis Scale: Perform logarithmic conversion on the Y-axis coordinate.</p></li>
<li><p>Enable/Disable Rectangle Selection: Draw a rectangle to select and zoom in a part of the chart. You can perform rectangle selection again on the zoomed-in chart.</p></li>
<li><p>Step-by-step Rollback: Cancel operations step by step after continuously drawing rectangles to select and zooming in the same area.</p></li>
<li><p>Restore Chart: Restore a chart to the original state.</p></li>
</ul>
<p><img alt="scalar_select.png" src="../_images/scalar_select.png" /></p>
<p>Figure 4: Scalar visualization function area</p>
<p>Figure 4 shows the scalar visualization function area, which allows you to view scalar information by selecting different tags, different dimensions of the horizontal axis, and smoothness.</p>
<ul class="simple">
<li><p>Tag: Select the required tags to view the corresponding scalar information.</p></li>
<li><p>Horizontal Axis: Select any of Step, Relative Time, and Absolute Time as the horizontal axis of the scalar curve.</p></li>
<li><p>Smoothness: Adjust the smoothness to smooth the scalar curve.</p></li>
<li><p>Scalar Synthesis: Synthesize two scalar curves and display them in a chart to facilitate comparison between the two curves or view the synthesized chart.</p></li>
</ul>
<p><img alt="scalar_compound.png" src="../_images/scalar_compound.png" /></p>
<p>Figure 5: Scalar synthesis of Accuracy and Loss curves</p>
<p>Figure 5 shows the scalar synthesis of the Accuracy and Loss curves. The function area of scalar synthesis is similar to that of scalar visualization. Different from the scalar visualization function area, the scalar synthesis function allows you to select a maximum of two tags at a time to synthesize and display their curves.</p>
</section>
<section id="image-visualization">
<h3>Image Visualization<a class="headerlink" href="#image-visualization" title="Permalink to this headline"></a></h3>
<p>Image visualization is used to display images specified by users.</p>
<p><img alt="image.png" src="../_images/image_vi.png" /></p>
<p>Figure 6: Image visualization</p>
<p>Figure 6 shows how to view images of different steps by sliding the Step slider.</p>
<p><img alt="image_function.png" src="../_images/image_function.png" /></p>
<p>Figure 7: Image visualization function area</p>
<p>Figure 7 shows the function area of image visualization. You can view image information by selecting different tags, brightness, and contrast.</p>
<ul class="simple">
<li><p>Tag: Select the required tags to view the corresponding image information.</p></li>
<li><p>Brightness Adjustment: Adjust the brightness of all displayed images.</p></li>
<li><p>Contrast Adjustment: Adjust the contrast of all displayed images.</p></li>
</ul>
</section>
<section id="model-lineage-visualization">
<h3>Model Lineage Visualization<a class="headerlink" href="#model-lineage-visualization" title="Permalink to this headline"></a></h3>
<p>Model lineage visualization is used to display the parameter information of all training models.</p>
<p><img alt="image.png" src="../_images/lineage_label.png" /></p>
<p>Figure 8: Model parameter selection area</p>
<p>Figure 8 shows the model parameter selection area, which lists the model parameter tags that can be viewed. You can select required tags to view the corresponding model parameters.</p>
<p><img alt="image.png" src="../_images/lineage_model_chart.png" /></p>
<p>Figure 9: Model lineage function area</p>
<p>Figure 9 shows the model lineage function area, which visualizes the model parameter information. You can select a specific area in the column to display the model information within the area.</p>
<p><img alt="image.png" src="../_images/lineage_model_table.png" /></p>
<p>Figure 10: Model list</p>
<p>Figure 10 shows all model information. You can sort the model information in ascending or descending order by specified column.</p>
</section>
<section id="dataset-graph-visualization">
<h3>Dataset Graph Visualization<a class="headerlink" href="#dataset-graph-visualization" title="Permalink to this headline"></a></h3>
<p>Dataset graph visualization is used to display data processing and augmentation information of a single model training.</p>
<p><img alt="data_function.png" src="../_images/data_function.png" /></p>
<p>Figure 11: Dataset graph function area</p>
<p>Figure 11 shows the dataset graph function area which includes the following content:</p>
<ul class="simple">
<li><p>Legend: Display the meaning of each icon in the data lineage graph.</p></li>
<li><p>Data Processing Pipeline: Display the data processing pipeline used for training. Select a single node in the graph to view details.</p></li>
<li><p>Node Information: Display basic information about the selected node, including names and parameters of the data processing and augmentation operators.</p></li>
</ul>
</section>
<section id="dataset-lineage-visualization">
<h3>Dataset Lineage Visualization<a class="headerlink" href="#dataset-lineage-visualization" title="Permalink to this headline"></a></h3>
<p>Dataset lineage visualization is used to display data processing and augmentation information of all model trainings.</p>
<p><img alt="data_label.png" src="../_images/data_label.png" /></p>
<p>Figure 12: Data processing and augmentation operator selection area</p>
<p>Figure 12 shows the data processing and augmentation operator selection area, which lists names of data processing and augmentation operators that can be viewed. You can select required tags to view related parameters.</p>
<p><img alt="data_chart.png" src="../_images/data_chart.png" /></p>
<p>Figure 13: Dataset lineage function area</p>
<p>Figure 13 shows the dataset lineage function area, which visualizes the parameter information used for data processing and augmentation. You can select a specific area in the column to display the parameter information within the area.</p>
<p><img alt="data_table.png" src="../_images/data_table.png" /></p>
<p>Figure 14: Dataset lineage list</p>
<p>Figure 14 shows the data processing and augmentation information of all model trainings.</p>
</section>
<section id="parameter-distribution">
<h3>Parameter Distribution<a class="headerlink" href="#parameter-distribution" title="Permalink to this headline"></a></h3>
<p>The parameter distribution in a form of a histogram displays tensors specified by a user.</p>
<p><img alt="histogram.png" src="../_images/histogram.png" /></p>
<p>Figure 15: Histogram</p>
<p>Figure 15 shows tensors recorded by a user in a form of a histogram. Click the upper right corner to zoom in the histogram.</p>
<p><img alt="histogram_func.png" src="../_images/histogram_func.png" /></p>
<p>Figure 16: Function area of the parameter distribution histogram</p>
<p>Figure 16 shows the function area of the parameter distribution histogram, including:</p>
<ul class="simple">
<li><p>Tag selection: Select the required tags to view the corresponding histogram.</p></li>
<li><p>Vertical axis: Select any of <code class="docutils literal notranslate"><span class="pre">Step</span></code>, <code class="docutils literal notranslate"><span class="pre">Relative</span> <span class="pre">time</span></code>, and <code class="docutils literal notranslate"><span class="pre">Absolute</span> <span class="pre">time</span></code> as the data displayed on the vertical axis of the histogram.</p></li>
<li><p>Angle of view: Select either <code class="docutils literal notranslate"><span class="pre">Front</span></code> or <code class="docutils literal notranslate"><span class="pre">Top</span></code>. <code class="docutils literal notranslate"><span class="pre">Front</span></code> view refers to viewing the histogram from the front view. In this case, data between different steps is overlapped. <code class="docutils literal notranslate"><span class="pre">Top</span></code> view refers to viewing the histogram at an angle of 45 degrees. In this case, data between different steps can be presented.</p></li>
</ul>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../use/debugging_in_pynative_mode.html" class="btn btn-neutral float-left" title="Debugging in PyNative Mode" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mixed_precision.html" class="btn btn-neutral float-right" title="Mixed Precision" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>