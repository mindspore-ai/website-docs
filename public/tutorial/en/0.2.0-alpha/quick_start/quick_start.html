<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Implementing an Image Classification Application &mdash; MindSpore 0.2.0-alpha documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Data Preparation" href="../use/data_preparation/data_preparation.html" />
    <link rel="prev" title="MindSpore Tutorials" href="../index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Implementing an Image Classification Application</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#preparations">Preparations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#downloading-the-dataset">Downloading the Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#importing-python-libraries-and-modules">Importing Python Libraries and Modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configuring-the-running-information">Configuring the Running Information</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#processing-data">Processing Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-dataset-and-data-operations">Defining the Dataset and Data Operations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#defining-the-network">Defining the Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="#defining-the-loss-function-and-optimizer">Defining the Loss Function and Optimizer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#basic-concepts">Basic Concepts</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-loss-function">Defining the Loss Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-optimizer">Defining the Optimizer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#training-the-network">Training the Network</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#saving-the-configured-model">Saving the Configured Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configuring-the-network-training">Configuring the Network Training</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#running-and-viewing-the-result">Running and Viewing the Result</a></li>
<li class="toctree-l2"><a class="reference internal" href="#validating-the-model">Validating the Model</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation/data_preparation.html">Data Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/saving_and_loading_model_parameters.html">Saving and Loading Model Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/debugging_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/visualization_tutorials.html">Training Process Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/mixed_precision.html">Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/distributed_training.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/computer_vision_application.html">Computer Vision Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/nlp_application.html">Natural Language Processing (NLP) Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/customized_debugging_information.html">Customized Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/on_device_inference.html">On-Device Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/model_security.html">Model Security</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/community.html">Community</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Implementing an Image Classification Application</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/quick_start/quick_start.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="implementing-an-image-classification-application">
<h1>Implementing an Image Classification Application<a class="headerlink" href="#implementing-an-image-classification-application" title="Permalink to this headline"></a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>This document uses a practice example to demonstrate the basic functions of MindSpore. For common users, it takes 20 to 30 minutes to complete the practice.</p>
<p>During the practice, a simple image classification function is implemented. The overall process is as follows:</p>
<ol class="arabic simple">
<li><p>Process the required dataset. The MNIST dataset is used in this example.</p></li>
<li><p>Define a network. The LeNet network is used in this example.</p></li>
<li><p>Define the loss function and optimizer.</p></li>
<li><p>Load dataset, perform training. After the training is complete, check the result and save the model file.</p></li>
<li><p>Load the saved model for inference.</p></li>
<li><p>Validate the model, load the test dataset and trained model, and validate the result accuracy.</p></li>
</ol>
<blockquote>
<div><p>You can find the complete executable sample code at <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r0.2/tutorials/tutorial_code/lenet.py">https://gitee.com/mindspore/docs/blob/r0.2/tutorials/tutorial_code/lenet.py</a>.</p>
</div></blockquote>
<p>This is a simple and basic application process. For other advanced and complex applications, extend this basic process as needed.</p>
</section>
<section id="preparations">
<h2>Preparations<a class="headerlink" href="#preparations" title="Permalink to this headline"></a></h2>
<p>Before you start, check whether MindSpore has been correctly installed. If no, install MindSpore on your computer by visiting <a class="reference external" href="https://www.mindspore.cn/install">MindSpore installation page</a>.</p>
<p>In addition, you shall have basic mathematical knowledge such as Python coding basics, probability, and matrix.</p>
<p>Start your MindSpore experience now.</p>
<section id="downloading-the-dataset">
<h3>Downloading the Dataset<a class="headerlink" href="#downloading-the-dataset" title="Permalink to this headline"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">MNIST</span></code> dataset used in this example consists of 10 classes of 28 x 28 pixels grayscale images. It has a training set of 60,000 examples, and a test set of 10,000 examples.</p>
<blockquote>
<div><p>Download the MNIST dataset at <a class="reference external" href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>. This page provides four download links of dataset files. The first two links are required for data training, and the last two links are required for data test.</p>
</div></blockquote>
<p>Download the files, decompress them, and store them in the workspace directories <code class="docutils literal notranslate"><span class="pre">./MNIST_Data/train</span></code> and <code class="docutils literal notranslate"><span class="pre">./MNIST_Data/test</span></code>.</p>
<p>The directory structure is as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>└─MNIST_Data
    ├─test
    │      t10k-images.idx3-ubyte
    │      t10k-labels.idx1-ubyte
    │
    └─train
            train-images.idx3-ubyte
            train-labels.idx1-ubyte
</pre></div>
</div>
<blockquote>
<div><p>For ease of use, we added the function of automatically downloading datasets in the sample script.</p>
</div></blockquote>
</section>
<section id="importing-python-libraries-and-modules">
<h3>Importing Python Libraries and Modules<a class="headerlink" href="#importing-python-libraries-and-modules" title="Permalink to this headline"></a></h3>
<p>Before start, you need to import Python libraries.</p>
<p>Currently, the <code class="docutils literal notranslate"><span class="pre">os</span></code> libraries are required. For ease of understanding, other required libraries will not be described here.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
</pre></div>
</div>
<p>For details about MindSpore modules, search on the <a class="reference external" href="https://www.mindspore.cn/api/en/0.2.0-alpha/index.html">MindSpore API Page</a>.</p>
</section>
<section id="configuring-the-running-information">
<h3>Configuring the Running Information<a class="headerlink" href="#configuring-the-running-information" title="Permalink to this headline"></a></h3>
<p>Before compiling code, you need to learn basic information about the hardware and backend required for MindSpore running.</p>
<p>You can use <code class="docutils literal notranslate"><span class="pre">context.set_context()</span></code> to configure the information required for running, such as the running mode, backend information, and hardware information.</p>
<p>Import the <code class="docutils literal notranslate"><span class="pre">context</span></code> module and configure the required information.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;MindSpore LeNet Example&#39;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--device_target&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">,</span> <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Ascend&#39;</span><span class="p">,</span> <span class="s1">&#39;GPU&#39;</span><span class="p">,</span> <span class="s1">&#39;CPU&#39;</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;device where the code will be implemented (default: CPU)&#39;</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device_target</span><span class="p">,</span>
                        <span class="n">enable_mem_reuse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>This example runs in graph mode. You can configure hardware information based on site requirements. For example, if the code runs on the Ascend AI processor, set <code class="docutils literal notranslate"><span class="pre">--device_target</span></code> to <code class="docutils literal notranslate"><span class="pre">Ascend</span></code>. This rule also applies to the code running on the CPU and GPU. For details about parameters, see the API description for <code class="docutils literal notranslate"><span class="pre">context.set_context()</span></code>.</p>
</section>
</section>
<section id="processing-data">
<h2>Processing Data<a class="headerlink" href="#processing-data" title="Permalink to this headline"></a></h2>
<p>Datasets are important for training. A good dataset can effectively improve training accuracy and efficiency. Generally, before loading a dataset, you need to perform some operations on the dataset.</p>
<section id="defining-the-dataset-and-data-operations">
<h3>Defining the Dataset and Data Operations<a class="headerlink" href="#defining-the-dataset-and-data-operations" title="Permalink to this headline"></a></h3>
<p>Define the <code class="docutils literal notranslate"><span class="pre">create_dataset()</span></code> function to create a dataset. In this function, define the data augmentation and processing operations to be performed.</p>
<ol class="arabic simple">
<li><p>Define the dataset.</p></li>
<li><p>Define parameters required for data augmentation and processing.</p></li>
<li><p>Generate corresponding data augmentation operations according to the parameters.</p></li>
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">map()</span></code> mapping function to apply data operations to the dataset.</p></li>
<li><p>Process the generated dataset.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.transforms.c_transforms</span> <span class="k">as</span> <span class="nn">C</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.transforms.vision.c_transforms</span> <span class="k">as</span> <span class="nn">CV</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset.transforms.vision</span> <span class="kn">import</span> <span class="n">Inter</span>
<span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>

<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                   <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; create dataset for train or test</span>
<span class="sd">    Args:</span>
<span class="sd">        data_path: Data path</span>
<span class="sd">        batch_size: The number of data records in each group</span>
<span class="sd">        repeat_size: The number of replicated data records</span>
<span class="sd">        num_parallel_workers: The number of parallel workers</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># define dataset</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MnistDataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>

    <span class="c1"># define operation parameters</span>
    <span class="n">resize_height</span><span class="p">,</span> <span class="n">resize_width</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span>
    <span class="n">rescale</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">255.0</span>
    <span class="n">shift</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">rescale_nml</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mf">0.3081</span>
    <span class="n">shift_nml</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="mf">0.1307</span> <span class="o">/</span> <span class="mf">0.3081</span>

    <span class="c1"># define map operations</span>
    <span class="n">resize_op</span> <span class="o">=</span> <span class="n">CV</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="n">resize_height</span><span class="p">,</span> <span class="n">resize_width</span><span class="p">),</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">)</span>  <span class="c1"># resize images to (32, 32)</span>
    <span class="n">rescale_nml_op</span> <span class="o">=</span> <span class="n">CV</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="n">rescale_nml</span><span class="p">,</span> <span class="n">shift_nml</span><span class="p">)</span>  <span class="c1"># normalize images</span>
    <span class="n">rescale_op</span> <span class="o">=</span> <span class="n">CV</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="n">rescale</span><span class="p">,</span> <span class="n">shift</span><span class="p">)</span>  <span class="c1"># rescale images</span>
    <span class="n">hwc2chw_op</span> <span class="o">=</span> <span class="n">CV</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>  <span class="c1"># change shape from (height, width, channel) to (channel, height, width) to fit network.</span>
    <span class="n">type_cast_op</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>  <span class="c1"># change data type of label to int32 to fit network</span>

    <span class="c1"># apply map operations on images</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="n">operations</span><span class="o">=</span><span class="n">type_cast_op</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">operations</span><span class="o">=</span><span class="n">resize_op</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">operations</span><span class="o">=</span><span class="n">rescale_op</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">operations</span><span class="o">=</span><span class="n">rescale_nml_op</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">operations</span><span class="o">=</span><span class="n">hwc2chw_op</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>

    <span class="c1"># apply DatasetOps</span>
    <span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">10000</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">buffer_size</span><span class="p">)</span>  <span class="c1"># 10000 as in LeNet train script</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat_size</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mnist_ds</span>

</pre></div>
</div>
<p>In the preceding information:<br />
<code class="docutils literal notranslate"><span class="pre">batch_size</span></code>: number of data records in each group. Currently, each group contains 32 data records.<br />
<code class="docutils literal notranslate"><span class="pre">repeat_size</span></code>: number of replicated data records.</p>
<p>Perform the shuffle and batch operations, and then perform the repeat operation to ensure that data during an epoch is unique.</p>
<blockquote>
<div><p>MindSpore supports multiple data processing and augmentation operations, which are usually combined. For details, see section “Data Processing and Augmentation” in the MindSpore Tutorials (<a class="reference external" href="https://www.mindspore.cn/tutorial/en/0.2.0-alpha/use/data_preparation/data_processing_and_augmentation.html">https://www.mindspore.cn/tutorial/en/0.2.0-alpha/use/data_preparation/data_processing_and_augmentation.html</a>).</p>
</div></blockquote>
</section>
</section>
<section id="defining-the-network">
<h2>Defining the Network<a class="headerlink" href="#defining-the-network" title="Permalink to this headline"></a></h2>
<p>The LeNet network is relatively simple. In addition to the input layer, the LeNet network has seven layers, including two convolutional layers, two down-sample layers (pooling layers), and three full connection layers. Each layer contains different numbers of training parameters, as shown in the following figure:</p>
<p><img alt="LeNet-5" src="../_images/LeNet_5.jpg" /></p>
<blockquote>
<div><p>For details about the LeNet network, visit <a class="reference external" href="http://yann.lecun.com/exdb/lenet/">http://yann.lecun.com/exdb/lenet/</a>.</p>
</div></blockquote>
<p>You need to initialize the full connection layers and convolutional layers.</p>
<p><code class="docutils literal notranslate"><span class="pre">TruncatedNormal</span></code>: parameter initialization method. MindSpore supports multiple parameter initialization methods, such as <code class="docutils literal notranslate"><span class="pre">TruncatedNormal</span></code>, <code class="docutils literal notranslate"><span class="pre">Normal</span></code>, and <code class="docutils literal notranslate"><span class="pre">Uniform</span></code>. For details, see the description of the <code class="docutils literal notranslate"><span class="pre">mindspore.common.initializer</span></code> module of the MindSpore API.</p>
<p>The following is the sample code for initialization:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">TruncatedNormal</span>

<span class="k">def</span> <span class="nf">weight_variable</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    weight initial</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">TruncatedNormal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    conv layer weight initial</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span>
                     <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                     <span class="n">weight_init</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fc_with_initialize</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    fc layer weight initial</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
</pre></div>
</div>
<p>To use MindSpore for neural network definition, inherit <code class="docutils literal notranslate"><span class="pre">mindspore.nn.cell.Cell</span></code>. <code class="docutils literal notranslate"><span class="pre">Cell</span></code> is the base class of all neural networks (such as <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code>).</p>
<p>Define each layer of a neural network in the <code class="docutils literal notranslate"><span class="pre">__init__()</span></code> method in advance, and then define the <code class="docutils literal notranslate"><span class="pre">construct()</span></code> method to complete the forward construction of the neural network. According to the structure of the LeNet network, define the network layers as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>

<span class="k">class</span> <span class="nc">LeNet5</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Lenet network structure</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">#define the operator required</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet5</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Reshape</span><span class="p">()</span>

    <span class="c1">#use the preceding operators to construct networks</span>
    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</section>
<section id="defining-the-loss-function-and-optimizer">
<h2>Defining the Loss Function and Optimizer<a class="headerlink" href="#defining-the-loss-function-and-optimizer" title="Permalink to this headline"></a></h2>
<section id="basic-concepts">
<h3>Basic Concepts<a class="headerlink" href="#basic-concepts" title="Permalink to this headline"></a></h3>
<p>Before definition, this section briefly describes concepts of loss function and optimizer.</p>
<ul class="simple">
<li><p>Loss function: It is also called objective function and is used to measure the difference between a predicted value and an actual value. Deep learning reduces the value of the loss function by continuous iteration. Defining a good loss function can effectively improve the model performance.</p></li>
<li><p>Optimizer: It is used to minimize the loss function, improving the model during training.</p></li>
</ul>
<p>After the loss function is defined, the weight-related gradient of the loss function can be obtained. The gradient is used to indicate the weight optimization direction for the optimizer, improving model performance.</p>
</section>
<section id="defining-the-loss-function">
<h3>Defining the Loss Function<a class="headerlink" href="#defining-the-loss-function" title="Permalink to this headline"></a></h3>
<p>Loss functions supported by MindSpore include <code class="docutils literal notranslate"><span class="pre">SoftmaxCrossEntropyWithLogits</span></code>, <code class="docutils literal notranslate"><span class="pre">L1Loss</span></code>, <code class="docutils literal notranslate"><span class="pre">MSELoss</span></code>. The loss function <code class="docutils literal notranslate"><span class="pre">SoftmaxCrossEntropyWithLogits</span></code> is used in this example.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.nn.loss</span> <span class="kn">import</span> <span class="n">SoftmaxCrossEntropyWithLogits</span>
</pre></div>
</div>
<p>Call the defined loss function in the <code class="docutils literal notranslate"><span class="pre">__main__</span></code> function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="c1">#define the loss function</span>
    <span class="n">net_loss</span> <span class="o">=</span> <span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">is_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
    <span class="o">...</span>
</pre></div>
</div>
</section>
<section id="defining-the-optimizer">
<h3>Defining the Optimizer<a class="headerlink" href="#defining-the-optimizer" title="Permalink to this headline"></a></h3>
<p>Optimizers supported by MindSpore include <code class="docutils literal notranslate"><span class="pre">Adam</span></code>, <code class="docutils literal notranslate"><span class="pre">AdamWeightDecay</span></code> and <code class="docutils literal notranslate"><span class="pre">Momentum</span></code>.</p>
<p>The popular Momentum optimizer is used in this example.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="c1">#learning rate setting</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span>
    <span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>
    <span class="c1">#create the network</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
    <span class="c1">#define the optimizer</span>
    <span class="n">net_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="p">)</span>
    <span class="o">...</span>
</pre></div>
</div>
</section>
</section>
<section id="training-the-network">
<h2>Training the Network<a class="headerlink" href="#training-the-network" title="Permalink to this headline"></a></h2>
<section id="saving-the-configured-model">
<h3>Saving the Configured Model<a class="headerlink" href="#saving-the-configured-model" title="Permalink to this headline"></a></h3>
<p>MindSpore provides the callback mechanism to execute customized logic during training. <code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> and <code class="docutils literal notranslate"><span class="pre">LossMonitor</span></code> provided by the framework are used in this example.
<code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> can save network models and parameters for subsequent fine-tuning. <code class="docutils literal notranslate"><span class="pre">LossMonitor</span></code> can monitor the changes of the <code class="docutils literal notranslate"><span class="pre">loss</span></code> value during training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">CheckpointConfig</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="c1"># set parameters of check point</span>
    <span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="mi">1875</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="c1"># apply parameters of check point</span>
    <span class="n">ckpoint_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;checkpoint_lenet&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
    <span class="o">...</span>
</pre></div>
</div>
</section>
<section id="configuring-the-network-training">
<h3>Configuring the Network Training<a class="headerlink" href="#configuring-the-network-training" title="Permalink to this headline"></a></h3>
<p>Use the <code class="docutils literal notranslate"><span class="pre">model.train</span></code> API provided by MindSpore to easily train the network.
In this example, set <code class="docutils literal notranslate"><span class="pre">epoch_size</span></code> to 1 to train the dataset for five iterations.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.nn.metrics</span> <span class="kn">import</span> <span class="n">Accuracy</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">LossMonitor</span>
<span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="o">...</span>
<span class="k">def</span> <span class="nf">train_net</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">epoch_size</span><span class="p">,</span> <span class="n">mnist_path</span><span class="p">,</span> <span class="n">repeat_size</span><span class="p">,</span> <span class="n">ckpoint_cb</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;define the training method&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;============== Starting Training ==============&quot;</span><span class="p">)</span>
    <span class="c1">#load training dataset</span>
    <span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">mnist_path</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">),</span> <span class="mi">32</span><span class="p">,</span> <span class="n">repeat_size</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch_size</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ckpoint_cb</span><span class="p">,</span> <span class="n">LossMonitor</span><span class="p">()],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># train</span>
<span class="o">...</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="o">...</span>

    <span class="n">epoch_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">mnist_path</span> <span class="o">=</span> <span class="s2">&quot;./MNIST_Data&quot;</span>
    <span class="n">repeat_size</span> <span class="o">=</span> <span class="n">epoch_size</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">,</span> <span class="n">net_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">Accuracy</span><span class="p">()})</span>
    <span class="n">train_net</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">epoch_size</span><span class="p">,</span> <span class="n">mnist_path</span><span class="p">,</span> <span class="n">repeat_size</span><span class="p">,</span> <span class="n">ckpoint_cb</span><span class="p">)</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>In the preceding information:<br />
In the <code class="docutils literal notranslate"><span class="pre">train_net</span></code> method, we loaded the training dataset, <code class="docutils literal notranslate"><span class="pre">MNIST</span> <span class="pre">path</span></code> is MNIST dataset path.</p>
</section>
</section>
<section id="running-and-viewing-the-result">
<h2>Running and Viewing the Result<a class="headerlink" href="#running-and-viewing-the-result" title="Permalink to this headline"></a></h2>
<p>Run the script using the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">lenet</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">device_target</span><span class="o">=</span><span class="n">CPU</span>
</pre></div>
</div>
<p>In the preceding information:<br />
<code class="docutils literal notranslate"><span class="pre">lenet.py</span></code>: the script file you wrote.<br />
<code class="docutils literal notranslate"><span class="pre">--device_target</span> <span class="pre">CPU</span></code>: Specify the hardware platform.The   parameters are ‘CPU’, ‘GPU’ or ‘Ascend’.</p>
<p>Loss values are output during training, as shown in the following figure. Although loss values may fluctuate, they gradually decrease and the accuracy gradually increases in general. Loss values displayed each time may be different because of their randomicity.</p>
<p>The following is an example of loss values output during training:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>...
epoch:<span class="w"> </span><span class="m">1</span><span class="w"> </span>step:<span class="w"> </span><span class="m">262</span>,<span class="w"> </span>loss<span class="w"> </span>is<span class="w"> </span><span class="m">1</span>.9212162
epoch:<span class="w"> </span><span class="m">1</span><span class="w"> </span>step:<span class="w"> </span><span class="m">263</span>,<span class="w"> </span>loss<span class="w"> </span>is<span class="w"> </span><span class="m">1</span>.8498616
epoch:<span class="w"> </span><span class="m">1</span><span class="w"> </span>step:<span class="w"> </span><span class="m">264</span>,<span class="w"> </span>loss<span class="w"> </span>is<span class="w"> </span><span class="m">1</span>.7990671
epoch:<span class="w"> </span><span class="m">1</span><span class="w"> </span>step:<span class="w"> </span><span class="m">265</span>,<span class="w"> </span>loss<span class="w"> </span>is<span class="w"> </span><span class="m">1</span>.9492403
epoch:<span class="w"> </span><span class="m">1</span><span class="w"> </span>step:<span class="w"> </span><span class="m">266</span>,<span class="w"> </span>loss<span class="w"> </span>is<span class="w"> </span><span class="m">2</span>.0305142
epoch:<span class="w"> </span><span class="m">1</span><span class="w"> </span>step:<span class="w"> </span><span class="m">267</span>,<span class="w"> </span>loss<span class="w"> </span>is<span class="w"> </span><span class="m">2</span>.0657792
epoch:<span class="w"> </span><span class="m">1</span><span class="w"> </span>step:<span class="w"> </span><span class="m">268</span>,<span class="w"> </span>loss<span class="w"> </span>is<span class="w"> </span><span class="m">1</span>.9582214
epoch:<span class="w"> </span><span class="m">1</span><span class="w"> </span>step:<span class="w"> </span><span class="m">269</span>,<span class="w"> </span>loss<span class="w"> </span>is<span class="w"> </span><span class="m">0</span>.9459006
epoch:<span class="w"> </span><span class="m">1</span><span class="w"> </span>step:<span class="w"> </span><span class="m">270</span>,<span class="w"> </span>loss<span class="w"> </span>is<span class="w"> </span><span class="m">0</span>.8167224
epoch:<span class="w"> </span><span class="m">1</span><span class="w"> </span>step:<span class="w"> </span><span class="m">271</span>,<span class="w"> </span>loss<span class="w"> </span>is<span class="w"> </span><span class="m">0</span>.7432692
...
</pre></div>
</div>
<p>The following is an example of model files saved after training:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>checkpoint_lenet-1_1875.ckpt
</pre></div>
</div>
<p>In the preceding information:<br />
<code class="docutils literal notranslate"><span class="pre">checkpoint_lenet-1_1875.ckpt</span></code>: saved model parameter file. The following refers to saved files as well. The file name format is checkpoint_{network name}-{epoch No.}_{step No.}.ckpt.</p>
</section>
<section id="validating-the-model">
<h2>Validating the Model<a class="headerlink" href="#validating-the-model" title="Permalink to this headline"></a></h2>
<p>After get the model file, we verify the generalization ability of the model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>

<span class="k">def</span> <span class="nf">test_net</span><span class="p">(</span><span class="n">args</span><span class="p">,</span><span class="n">network</span><span class="p">,</span><span class="n">model</span><span class="p">,</span><span class="n">mnist_path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;define the evaluation method&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;============== Starting Testing ==============&quot;</span><span class="p">)</span>
    <span class="c1">#load the saved model for evaluation</span>
    <span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;checkpoint_lenet-1_1875.ckpt&quot;</span><span class="p">)</span>
    <span class="c1">#load parameter to the network</span>
    <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
    <span class="c1">#load testing dataset</span>
    <span class="n">ds_eval</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">mnist_path</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">))</span> <span class="c1"># test</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">ds_eval</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;============== Accuracy:</span><span class="si">{}</span><span class="s2"> ==============&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="n">test_net</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">mnist_path</span><span class="p">)</span>
</pre></div>
</div>
<p>In the preceding information:<br />
<code class="docutils literal notranslate"><span class="pre">load_checkpoint()</span></code>: This API is used to load the CheckPoint model parameter file and return a parameter dictionary.<br />
<code class="docutils literal notranslate"><span class="pre">checkpoint_lenet-3_1404.ckpt</span></code>: name of the saved CheckPoint model file.
<code class="docutils literal notranslate"><span class="pre">load_param_into_net</span></code>: This API is used to load parameters to the network.</p>
<p>Run the script using the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">lenet</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">device_target</span><span class="o">=</span><span class="n">CPU</span>
</pre></div>
</div>
<p>In the preceding information:
<code class="docutils literal notranslate"><span class="pre">Lenet.</span> <span class="pre">Py</span></code>: the script file you wrote.
<code class="docutils literal notranslate"><span class="pre">--device_target</span> <span class="pre">CPU</span></code>: Specify the hardware platform.The parameters are ‘CPU’, ‘GPU’ or ‘Ascend’.</p>
<p>Command output similar to the following is displayed:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">==============</span> <span class="n">Starting</span> <span class="n">Testing</span> <span class="o">==============</span>
<span class="o">==============</span> <span class="n">Accuracy</span><span class="p">:{</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="mf">0.9742588141025641</span><span class="p">}</span> <span class="o">==============</span>
</pre></div>
</div>
<p>The model accuracy data is displayed in the output content. In the example, the accuracy reaches 97.4%, indicating a good model quality.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="MindSpore Tutorials" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../use/data_preparation/data_preparation.html" class="btn btn-neutral float-right" title="Data Preparation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>