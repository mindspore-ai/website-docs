<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Saving and Loading Model Parameters in the Hybrid Parallel Scenario &mdash; MindSpore r0.5 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Mixed Precision" href="mixed_precision.html" />
    <link rel="prev" title="Getting Started with Parallel Distributed Training" href="distributed_training.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation/data_preparation.html">Data Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">Defining the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/saving_and_loading_model_parameters.html">Saving and Loading Model Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/multi_platform_inference.html">Multi-platform Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="computer_vision_application.html">Computer Vision Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_application.html">Natural Language Processing (NLP) Application</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debugging_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="customized_debugging_information.html">Customized Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization_tutorials.html">Training Process Visualization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="distributed_training_tutorials.html">Distributed training</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="distributed_training.html">Getting Started with Parallel Distributed Training</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Saving and Loading Model Parameters in the Hybrid Parallel Scenario</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#background">Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="#application-scenario">Application Scenario</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#integrating-the-saved-checkpoint-files">Integrating the Saved Checkpoint Files</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#overall-process">Overall Process</a></li>
<li class="toctree-l4"><a class="reference internal" href="#preparations">Preparations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#integrate-the-model-parallel-parameters">Integrate the Model Parallel Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#saving-the-data-and-generating-a-new-checkpoint-file">Saving the Data and Generating a New Checkpoint File</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#loading-the-integrated-and-saved-checkpoint-file">Loading the Integrated and Saved Checkpoint File</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">Overall Process</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-1-loading-the-checkpoint-file">Step 1: Loading the Checkpoint File</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-2-dividing-a-model-parallel-parameter">Step 2: Dividing a Model Parallel Parameter</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-3-loading-the-modified-parameter-data-to-the-network">Step 3: Loading the Modified Parameter Data to the Network</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#example">Example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#scenario-description">Scenario Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example-code">Example Code</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mixed_precision.html">Mixed Precision</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Usage on Device</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="on_device_inference.html">On-Device Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Network Migration</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="network_migration.html">Network Migration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_security.html">Model Security</a></li>
<li class="toctree-l1"><a class="reference internal" href="differential_privacy.html">Differential Privacy in Machine Learning</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="distributed_training_tutorials.html">Distributed training</a> &raquo;</li>
      <li>Saving and Loading Model Parameters in the Hybrid Parallel Scenario</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/advanced_use/checkpoint_for_hybrid_parallel.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="saving-and-loading-model-parameters-in-the-hybrid-parallel-scenario">
<h1>Saving and Loading Model Parameters in the Hybrid Parallel Scenario<a class="headerlink" href="#saving-and-loading-model-parameters-in-the-hybrid-parallel-scenario" title="Permalink to this headline"></a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<section id="background">
<h3>Background<a class="headerlink" href="#background" title="Permalink to this headline"></a></h3>
<p>In the MindSpore model parallel scenario, each instance process stores only the parameter data on the current node. The parameter data of a model parallel Cell on each node is a slice of the complete parameter data. For example, the complete parameter data shape is [8, 8], and the parameter data on each node is a part of the data, for example, shape [2, 8].</p>
<p>In the auto parallel scenario, MindSpore automatically generates the dividing strategy. The MindSpore checkpoint module supports automatic integrating, saving, and loading.</p>
<p>In the hybrid parallel scenario, the dividing strategy is implemented by users. MindSpore saves only the data corresponding to each node. Users need to integrate, save, and load the checkpoint files by themselves. This tutorial describes how to integrate, save, and load checkpoint files in the hybrid parallel scenario.</p>
</section>
<section id="application-scenario">
<h3>Application Scenario<a class="headerlink" href="#application-scenario" title="Permalink to this headline"></a></h3>
<p>If you encounter the following scenarios, refer to this tutorial to integrate, save, and load checkpoint files:</p>
<p>Scenario 1: multi-device training and single-device inference</p>
<p>The following describes the overall process of training on 64 devices and inference on a single device:</p>
<ol class="arabic">
<li><p>Execute the training to automatically generate the checkpoint files.</p></li>
<li><p>Integrate the saved checkpoint files.</p>
<p>Integrate the divided model parameters based on the specific dividing strategy to generate a new checkpoint file.</p>
</li>
<li><p>Load the new checkpoint file in the single-GPU environment and call the export API to export the model for inference as required.</p></li>
</ol>
<p>If the number of GPUs in a cluster in the checkpoint saving environment is the same as that in the loading environment, for example, if the checkpoint files are saved and loaded in the same training environment or training and inference is performed on a single device, you do not need to perform integration, saving and loading.</p>
<p>Scenario 2: The training is divided into multiple stages, and the cluster size in each stage is different.</p>
<p>For example, in the training stage 1, the training environment with 64 devices is used, and in the training stage 2, the training environment with 56 devices is used. The overall operation process is as follows:</p>
<ol class="arabic">
<li><p>Execute the training in stage 1 to automatically generate the checkpoint files.</p></li>
<li><p>Integrate the saved checkpoint files.</p>
<p>Integrate the divided model parameters based on the specific dividing strategy to generate a new checkpoint file.</p>
</li>
<li><p>Load the checkpoint file that is integrated and saved in the stage 2 cluster.</p>
<p>During the loading, you need to redivide the parameter data in the checkpoint file based on the new training environment configuration.</p>
</li>
<li><p>Perform stage 2 training.</p></li>
</ol>
</section>
</section>
<section id="integrating-the-saved-checkpoint-files">
<h2>Integrating the Saved Checkpoint Files<a class="headerlink" href="#integrating-the-saved-checkpoint-files" title="Permalink to this headline"></a></h2>
<section id="overall-process">
<h3>Overall Process<a class="headerlink" href="#overall-process" title="Permalink to this headline"></a></h3>
<p>Import the checkpoint files to be integrated to the network and obtain the list of all parameters through the API provided by MindSpore. See steps 1 and 2 in the following figure.</p>
<p>Then, update the parameter list and integrate the model parallel parameters. See step 3 in the following figure.</p>
<p>Finally, save the updated parameter list to a file through the API provided by MindSpore to generate a new checkpoint file. See step 4 in the following figure.</p>
<p><img alt="img" src="../_images/checkpoint_integration_process.jpg" /></p>
</section>
<section id="preparations">
<h3>Preparations<a class="headerlink" href="#preparations" title="Permalink to this headline"></a></h3>
<section id="importing-the-checkpoint-files-to-the-network">
<h4>Importing the Checkpoint Files to the Network<a class="headerlink" href="#importing-the-checkpoint-files-to-the-network" title="Permalink to this headline"></a></h4>
<p>Define the network, call the <code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code> and <code class="docutils literal notranslate"><span class="pre">load_param_into_net</span></code> APIs, and import the checkpoint files to the network.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="o">./</span><span class="n">CKP_1</span><span class="o">-</span><span class="mf">4_32.</span><span class="n">ckpt</span><span class="p">)</span>  <span class="c1"># checkpoint file name</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span> 
<span class="n">opt</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">())</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
</pre></div>
</div>
<p>In the preceding information:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code>: loads the checkpoint model parameter file and returns a parameter dictionary.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">load_param_into_net</span></code>: loads model parameter data to the network.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CKP_1-4_32.ckpt</span></code>: name of the saved checkpoint model parameter file.</p></li>
</ul>
<blockquote>
<div><p>If a new checkpoint file is directly saved in the training environment based on the current training data and the parameter values already exist on the network, skip this step and you do not need to import the checkpoint files.</p>
</div></blockquote>
</section>
<section id="obtaining-a-list-of-all-parameters-on-the-network">
<h4>Obtaining a List of All Parameters on the Network<a class="headerlink" href="#obtaining-a-list-of-all-parameters-on-the-network" title="Permalink to this headline"></a></h4>
<p>Call the <code class="docutils literal notranslate"><span class="pre">parameters_and_names</span></code> API to obtain all parameter data on the network.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">param_dict</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters_and_names</span><span class="p">():</span>
    <span class="n">param_dict</span><span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span> 
</pre></div>
</div>
</section>
</section>
<section id="integrate-the-model-parallel-parameters">
<h3>Integrate the Model Parallel Parameters<a class="headerlink" href="#integrate-the-model-parallel-parameters" title="Permalink to this headline"></a></h3>
<p>The following uses a model parameter as an example to describe a specific integration process.</p>
<p>The parameter name is model_parallel_weight and the data is Tensor [[1, 2, 3, 4], [5, 6, 7, 8]].</p>
<p>The dividing strategy is to perform dividing in a 4-device scenario based on [2, 2]. That is, the data is first divided into two slices in the row dimension, then the two slices are respectively divided into two smaller slices in the column dimension, and finally four slices are obtained. Data distribution after dividing is as follows:</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Device0</p></th>
<th class="head"><p>Device1</p></th>
<th class="head"><p>Device2</p></th>
<th class="head"><p>Device3</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Value [1, 2]</p></td>
<td><p>Value [3, 4]</p></td>
<td><p>Value [5, 6]</p></td>
<td><p>Value [7, 8]</p></td>
</tr>
</tbody>
</table>
<ol class="arabic">
<li><p>Obtain the data value on the current node for model parallel parameters.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>param_data = param_dict[“model_parallel_weight”]
param_data_moments = param_dict[“moments.model_parallel_weight”]
</pre></div>
</div>
<blockquote>
<div><p>To ensure that the parameter update speed remains unchanged, you need to integrate the parameters saved in the optimizer, for example, moments.model_parallel_weight.</p>
</div></blockquote>
</li>
<li><p>Define, instantiate, and execute the <code class="docutils literal notranslate"><span class="pre">AllGather</span></code> Cell, and obtain data on all devices.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.nn.cell</span> <span class="kn">import</span> <span class="n">Cell</span>
<span class="kn">from</span> <span class="nn">mindspore.ops.operations.comm_ops</span> <span class="kn">import</span> <span class="n">AllGather</span>

<span class="k">class</span> <span class="nc">AllGatherCell</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Allgather cell, used in model parallel scenario.</span>
<span class="sd">    To allgather the selected parameter slice from each device.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AllGatherCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allgather</span> <span class="o">=</span> <span class="n">AllGather</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">allgather</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">allgather_net</span> <span class="o">=</span> <span class="n">AllGatherCell</span><span class="p">()</span>
<span class="n">param_data</span> <span class="o">=</span> <span class="n">allgather_net</span><span class="p">(</span><span class="n">param_data</span><span class="p">)</span> 
<span class="n">param_data_moments</span> <span class="o">=</span> <span class="n">allgather_net</span><span class="p">(</span><span class="n">param_data_moments</span><span class="p">)</span> 
</pre></div>
</div>
<p>The value of <code class="docutils literal notranslate"><span class="pre">param_data</span></code> is the integration of data on each device in dimension 0. The data value is [[1, 2], [3, 4], [5, 6], [7, 8]], and the shape is [4, 2]. The raw data value of <code class="docutils literal notranslate"><span class="pre">param_data</span></code> is [[1, 2, 3, 4], [5, 6, 7, 8]], and the shape is [2, 4]. The data needs to be redivided and integrated.</p>
</li>
<li><p>Divide the data obtained from <code class="docutils literal notranslate"><span class="pre">AllGather</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">slice_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">param_data</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>   <span class="c1"># 4：group_size, number of nodes in cluster</span>
<span class="n">slice_lis_moments</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">param_data_moments</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 4: group_size, number of nodes in cluster</span>
</pre></div>
</div>
<p>The result of <code class="docutils literal notranslate"><span class="pre">param_data</span></code> is as follows:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> slice_list[0]  --- [1,  2]     Slice data on device0    
 slice_list[1]  --- [3,  4]     Slice data on device1    
 slice_list[2]  --- [5,  6]     Slice data on device2    
 slice_list[3]  --- [7,  8]     Slice data on device3    
</pre></div>
</div>
</li>
<li><p>Reassemble data based on the site requirements.</p>
<p>In the following code, slice 1 and slice 2, slice 3 and slice 4 are first spliced by column, and then the obtained data is spliced by row.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">slice_line1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">slice_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">slice_list</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>   <span class="c1"># result [1,2,3,4]</span>
<span class="n">slice_line2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">slice_list</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">slice_list</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>   <span class="c1"># result [5,6,7,8]</span>
<span class="n">whole_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">slice_line1</span><span class="p">,</span> <span class="n">slice_line2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>        <span class="c1"># result [[1, 2, 3, 4], [5, 6, 7, 8]]</span>

<span class="n">slice_moments_line1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">slice_lis_moments</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">slice_lis_moments</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">slice_moments_line2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">slice_lis_moments</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">slice_lis_moments</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">whole_moments_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">slice_moments_line1</span><span class="p">,</span> <span class="n">slice_moments_line2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Assign values to model parameters.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">param_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">whole_data</span><span class="p">)</span> 
<span class="n">param_data_moments</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">whole_moments_data</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
<blockquote>
<div><ol class="arabic simple">
<li><p>If there are multiple model parallel parameters, repeat steps 1 to 5 to process them one by one.</p></li>
<li><p>If the data obtained in step 2 is the final data, skip the following steps. That is, the dividing strategy is to perform dividing only on shape0 and each device loads different slice data.</p></li>
</ol>
</div></blockquote>
</section>
<section id="saving-the-data-and-generating-a-new-checkpoint-file">
<h3>Saving the Data and Generating a New Checkpoint File<a class="headerlink" href="#saving-the-data-and-generating-a-new-checkpoint-file" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>Convert <code class="docutils literal notranslate"><span class="pre">param_dict</span></code> to <code class="docutils literal notranslate"><span class="pre">param_list</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>param_list = []
for (key, value) in param_dict.items():
    each_param = {}
    each_param[&quot;name&quot;] = key
    if isinstance(value.data, Tensor):
        param_data = value.data                                         
    else:
        param_data = Tensor(value.data)                                                       
    each_param[&quot;data&quot;] = param_data
    param_list.append(each_param）
</pre></div>
</div>
</li>
<li><p>Call the <code class="docutils literal notranslate"><span class="pre">save_checkpoint</span></code> API to write the parameter data to a file and generate a new checkpoint file.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>save_checkpoint(param_list, “./CKP-Integrated_1-4_32.ckpt”)
</pre></div>
</div>
<p>In the preceding information:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">save_checkpoint</span></code>: saves network model parameters to a file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CKP-Integrated_1-4_32.ckpt</span></code>: name of the generated checkpoint model parameter file.</p></li>
</ul>
</li>
</ol>
</section>
</section>
<section id="loading-the-integrated-and-saved-checkpoint-file">
<h2>Loading the Integrated and Saved Checkpoint File<a class="headerlink" href="#loading-the-integrated-and-saved-checkpoint-file" title="Permalink to this headline"></a></h2>
<section id="id1">
<h3>Overall Process<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<p>If you need to load the integrated and saved checkpoint file to multi-device training or inference, divide the parallel parameter data based on the new strategy before loading the model parameters to the network. The following steps are implemented in the pre-training script. Steps 1 and 3 are the same as the strategy of checkpoint loading in a single-node system. Step 2 is added to divide model parallel parameters. In the single-device training/inference scenario, data dividing is not involved. In this case, step 2 can be skipped.</p>
</section>
<section id="step-1-loading-the-checkpoint-file">
<h3>Step 1: Loading the Checkpoint File<a class="headerlink" href="#step-1-loading-the-checkpoint-file" title="Permalink to this headline"></a></h3>
<p>Call the <code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code> API to load model parameter data from the checkpoint file.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;./CKP-Integrated_1-4_32.ckpt&quot;</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code>: loads the checkpoint model parameter file and returns a parameter dictionary.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CKP-Integrated_1-4_32.ckpt</span></code>: name of the checkpoint model parameter file to be loaded.</p></li>
</ul>
</section>
<section id="step-2-dividing-a-model-parallel-parameter">
<h3>Step 2: Dividing a Model Parallel Parameter<a class="headerlink" href="#step-2-dividing-a-model-parallel-parameter" title="Permalink to this headline"></a></h3>
<p>The following uses a specific model parameter as an example. The parameter name is model_parallel_weight, the data value is Tensor [[1, 2, 3, 4], [5, 6, 7, 8]], and the dividing strategy is to perform dividing in the two-device scenario based on [2, 1]. Data distribution after dividing is as follows:</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Device0</p></th>
<th class="head"><p>Device1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Value [1, 2, 3, 4]</p></td>
<td><p>Value [5, 6, 7, 8]</p></td>
</tr>
</tbody>
</table>
<ol class="arabic">
<li><p>Divide the model parameter data.</p>
<p>In the following code example, data is divided into two slices in dimension 0.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>new_param = parameter_dict[“model_parallel_weight”]
slice_list = np.split(new_param.data.asnumpy(), 2, axis=0)
new_param_moments = parameter_dict[“moments.model_parallel_weight”]
slice_moments_list = np.split(new_param_moments.data.asnumpy(), 2, axis=0)
</pre></div>
</div>
<p>Data after dividing:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> slice_list[0]  --- [1, 2, 3, 4]    Corresponding to device0   
 slice_list[1]  --- [5, 6, 7, 8]    Corresponding to device1     
</pre></div>
</div>
<p>Similar to slice_list, slice_moments_list is divided into two tensors with the shape of [1, 4].</p>
</li>
<li><p>Load the corresponding data slice on each node.</p>
<p>Obtain rank_id of the current node and load data based on rank_id.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rank</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
<span class="n">tensor_slice</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">slice_list</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span>
<span class="n">tensor_slice_moments</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">slice_moments_list</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">get_rank</span></code>: obtains the ID of the current device in the cluster.</p></li>
</ul>
</li>
<li><p>Modify values of model parameters.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">new_param</span><span class="o">.</span><span class="n">set_parameter_data</span><span class="p">(</span><span class="n">tensor_slice</span><span class="p">)</span> 
<span class="n">new_param_moments</span><span class="o">.</span><span class="n">set_parameter_data</span><span class="p">(</span><span class="n">tensor_slice_moments</span><span class="p">)</span> 
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">set_parameter_data</span></code>: sets the value of a model parameter. The API parameter type is Tensor or number.</p></li>
</ul>
</li>
</ol>
</section>
<section id="step-3-loading-the-modified-parameter-data-to-the-network">
<h3>Step 3: Loading the Modified Parameter Data to the Network<a class="headerlink" href="#step-3-loading-the-modified-parameter-data-to-the-network" title="Permalink to this headline"></a></h3>
<p>Call the <code class="docutils literal notranslate"><span class="pre">load_param_into_net</span></code> API to load the model parameter data to the network.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span> 
<span class="n">opt</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">parallel_net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">())</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="example">
<h2>Example<a class="headerlink" href="#example" title="Permalink to this headline"></a></h2>
<section id="scenario-description">
<h3>Scenario Description<a class="headerlink" href="#scenario-description" title="Permalink to this headline"></a></h3>
<p>Overall scenario: The training is divided into two stages. The cluster scales in the two stages are different. The MatMul operator at the FC layer is simulated to run in parallel.</p>
<p>User process:</p>
<ol class="arabic simple">
<li><p>Execute stage 1 training. There are four devices in stage 1 training environment. The weight shape of the MatMul operator on each device is [2, 8]. Checkpoint files are automatically exported during the training.</p></li>
<li><p>Execute the script to integrate checkpoint files. Based on the specific dividing strategy, integrate the divided model parameters to generate the integrated checkpoint file.</p></li>
<li><p>Execute stage 2 training: There are two devices in stage 2 training environment. The weight shape of the MatMul operator on each device is [4, 8]. Load the initialized model parameter data from the integrated checkpoint file and then perform training.</p></li>
</ol>
<blockquote>
<div><p>For details about the distributed environment configuration and training code, see <a class="reference external" href="https://www.mindspore.cn/tutorial/en/r0.5/advanced_use/distributed_training.html">Distributed Training</a>.</p>
<p>This document provides the example code for integrating checkpoint files and loading checkpoint files before distributed training. The code is for reference only.</p>
</div></blockquote>
</section>
<section id="example-code">
<h3>Example Code<a class="headerlink" href="#example-code" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>Run the following script to integrate the checkpoint files:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span>  <span class="o">./</span><span class="n">integrate_checkpoint</span><span class="o">.</span><span class="n">py</span> <span class="s2">&quot;Path and name of the checkpoint file to be integrated&quot;</span> <span class="s2">&quot;Path and name of the checkpoint file generated after integration&quot;</span>
</pre></div>
</div>
<p>integrate_checkpoint.py:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Parameter</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="kn">from</span> <span class="nn">mindspore.ops.operations.comm_ops</span> <span class="kn">import</span> <span class="n">AllGather</span>
<span class="kn">from</span> <span class="nn">mindspore.communication.management</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">save_checkpoint</span><span class="p">,</span> <span class="n">load_checkpoint</span>
<span class="n">devid</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;DEVICE_ID&#39;</span><span class="p">))</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">,</span> <span class="n">save_graphs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device_id</span><span class="o">=</span><span class="n">devid</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">weight_init</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">weight_init</span><span class="p">),</span>  <span class="s2">&quot;model_parallel_weight&quot;</span><span class="p">,</span> <span class="n">layerwise_parallel</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">AllGatherNet</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Allgather cell, used in model parallel scenario.</span>
<span class="sd">    To allgather the selected parameter slice from each device.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allgather</span> <span class="o">=</span> <span class="n">AllGather</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">allgather</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">integrate_ckpt_file</span><span class="p">(</span><span class="n">old_ckpt_file</span><span class="p">,</span> <span class="n">new_ckpt_file</span><span class="p">):</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">())</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>

    <span class="c1"># load CheckPoint into net</span>
    <span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">old_ckpt_file</span><span class="p">)</span>
    <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
    <span class="n">param_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters_and_names</span><span class="p">():</span>
       <span class="n">param_dict</span><span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span>

    <span class="k">for</span> <span class="n">paramname</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;model_parallel_weight&quot;</span><span class="p">,</span> <span class="s2">&quot;moments.model_parallel_weight&quot;</span><span class="p">]:</span>
        <span class="c1"># get layer wise model parallel parameter</span>
        <span class="n">layerwise_param</span> <span class="o">=</span> <span class="n">param_dict</span><span class="p">[</span><span class="n">paramname</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layerwise_param</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
                <span class="n">param_data</span> <span class="o">=</span> <span class="n">layerwise_param</span><span class="o">.</span><span class="n">data</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">param_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">layerwise_param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="c1"># merge the parallel parameters of the model</span>
        <span class="n">allgather_net</span> <span class="o">=</span> <span class="n">get_allgather_cell</span><span class="p">()</span>
        <span class="n">param_data</span> <span class="o">=</span> <span class="n">allgather_net</span><span class="p">(</span><span class="n">param_data</span><span class="p">)</span>
        <span class="n">layerwise_param</span><span class="o">.</span><span class="n">set_parameter_data</span><span class="p">(</span><span class="n">param_data</span><span class="p">)</span>

    <span class="c1"># convert param_dict to list type data</span>
    <span class="n">param_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">param_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">each_param</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">each_param</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">key</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
            <span class="n">param_data</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">param_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">each_param</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">param_data</span> 
        <span class="n">param_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">each_param</span><span class="p">)</span> 

    <span class="c1"># call the API to generate a new CheckPoint file</span>
    <span class="n">save_checkpoint</span><span class="p">(</span><span class="n">param_list</span><span class="p">,</span> <span class="n">new_ckpt_file</span><span class="p">)</span>

    <span class="k">return</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">old_ckpt_file</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">new_ckpt_file</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">integrate</span><span class="p">(</span><span class="n">old_ckpt_file</span><span class="p">,</span> <span class="n">new_ckpt_file</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fail to integrate checkpoint file)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>In the preceding information:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mode=context.GRAPH_MODE</span></code>: sets the running mode to graph mode for distributed training. (The PyNative mode does not support parallel running.)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">device_id</span></code>: physical sequence number of a device, that is, the actual sequence number of the device on a computer where the device is located.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">init</span></code>: completes the distributed training initialization.</p></li>
</ul>
<p>The command output is as follows.</p>
<p>Before the script is executed, the parameter values in the checkpoint files are as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>device0：
name is model_parallel_weight
value is 
[[0.87537426 1.0448935 0.86736983 0.8836905 0.77354026 0.69588304 0.9183654 0.7792076]
 [0.87224025 0.8726848 0.771446 0.81967723 0.88974726 0.7988162 0.72919345 0.7677011]]
name is learning_rate
value is [0.01]
name is momentum
value is [0.9]
name is moments.model_weight
value is
[[0.2567724 -0.07485991 0.282002 0.2456022 0.454939 0.619168 0.18964815 0.45714882]
 [0.25946522 0.24344791 0.45677605 0.3611395 0.23378398 0.41439137 0.5312468 0.4696194]]

device1：
name is model_parallel_weight
value is 
[[0.9210751 0.9050457 0.9827775 0.920396 0.9240526 0.9750359 1.0275179 1.0819869]
 [0.73605865 0.84631145 0.9746683 0.9386582 0.82902765 0.83565056 0.9702136 1.0514659]]
name is learning_rate
value is [0.01]
name is momentum
value is [0.9]
name is moments.model_weight
value is
[[0.2417504 0.28193963 0.06713893 0.21510397 0.23380603 0.11424308 0.0218009 -0.11969765]
 [0.45955992 0.22664294 0.01990281 0.0731914 0.27125207 0.27298513 -0.01716102 -0.15327111]] 

device2：
name is model_parallel_weight
value is 
[[1.0108461 0.8689414  0.91719437 0.8805056 0.7994629 0.8999671 0.7585804 1.0287056 ]
 [0.90653455 0.60146594 0.7206475 0.8306303 0.8364681 0.89625114 0.7354735 0.8447268]]
name is learning_rate
value is [0.01]
name is momentum
value is [0.9]
name is moments.model_weight
value is 
[[0.03440702 0.41419312 0.24817684 0.30765256 0.48516113 0.24904746 0.57791173 0.00955463]
 [0.13458519 0.6690533 0.49259356 0.28319967 0.25951773 0.16777472 0.45696738 0.24933104]]

device3：
name is model_parallel_weight
value is
[[0.7147005 0.9168278 0.80178416 0.6258351 0.8413766 0.5909515 0.696347 0.71359116]
 [0.20506378 0.03691584 0.2454556 0.12978578 0.19065076 0.23904312 0.27509746 0.34614682]]
name is learning_rate
value is [0.01]
name is momentum
value is [0.9]
name is moments.model_parallel_weight
value is 
[[0.14152306 0.5040985 0.24455397 0.10907605 0.11319532 0.19538902 0.01208619 0.40430856]
[-0.7773164 -0.47611716 -0.6041424 -0.6144473 -0.2651842 -0.31909415 -0.4510405 -0.12860501]]
</pre></div>
</div>
<p>After the script is executed, the parameter values in the checkpoint files are as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">name</span> <span class="ow">is</span> <span class="n">model_parallel_weight</span>
<span class="n">value</span> <span class="ow">is</span> 
<span class="p">[[</span><span class="mf">1.1138763</span> <span class="mf">1.0962057</span> <span class="mf">1.3516843</span> <span class="mf">1.0812817</span> <span class="mf">1.1579804</span> <span class="mf">1.1078343</span> <span class="mf">1.0906502</span> <span class="mf">1.3207073</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.916671</span> <span class="mf">1.0781671</span> <span class="mf">1.0368758</span> <span class="mf">0.9680898</span> <span class="mf">1.1735439</span> <span class="mf">1.0628364</span> <span class="mf">0.9960786</span> <span class="mf">1.0135143</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.8828271</span> <span class="mf">0.7963984</span> <span class="mf">0.90675324</span> <span class="mf">0.9830291</span> <span class="mf">0.89010954</span> <span class="mf">0.897052</span> <span class="mf">0.7890109</span> <span class="mf">0.89784735</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">1.0011744</span> <span class="mf">1.0840297</span> <span class="mf">1.0201758</span> <span class="mf">1.0882459</span> <span class="mf">0.94232416</span> <span class="mf">1.0775206</span> <span class="mf">1.0195118</span> <span class="mf">1.0528734</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">1.0053468</span> <span class="mf">0.98402303</span> <span class="mf">0.99762845</span> <span class="mf">0.97587246</span> <span class="mf">1.0259694</span> <span class="mf">1.0055295</span> <span class="mf">0.99420834</span> <span class="mf">0.9496847</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">1.0851002</span> <span class="mf">1.0295962</span> <span class="mf">1.0999886</span> <span class="mf">1.0958165</span> <span class="mf">0.9765328</span> <span class="mf">1.146529</span> <span class="mf">1.0970603</span> <span class="mf">1.1388365</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.7147005</span> <span class="mf">0.9168278</span> <span class="mf">0.80178416</span> <span class="mf">0.6258351</span> <span class="mf">0.8413766</span> <span class="mf">0.5909515</span> <span class="mf">0.696347</span> <span class="mf">0.71359116</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.20506378</span> <span class="mf">0.03691584</span> <span class="mf">0.2454556</span> <span class="mf">0.12978578</span> <span class="mf">0.19065076</span> <span class="mf">0.23904312</span> <span class="mf">0.27509746</span> <span class="mf">0.34614682</span><span class="p">]]</span>
<span class="n">name</span> <span class="ow">is</span> <span class="n">learning_rate</span>
<span class="n">value</span> <span class="ow">is</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">]</span>
<span class="n">name</span> <span class="ow">is</span> <span class="n">momentum</span>
<span class="n">value</span> <span class="ow">is</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">]</span>
<span class="n">name</span> <span class="ow">is</span> <span class="n">moments</span><span class="o">.</span><span class="n">model_parallel_weight</span>
<span class="n">value</span> <span class="ow">is</span> 
<span class="p">[[</span><span class="mf">0.2567724</span> <span class="o">-</span><span class="mf">0.07485991</span> <span class="mf">0.282002</span> <span class="mf">0.2456022</span> <span class="mf">0.454939</span> <span class="mf">0.619168</span> <span class="mf">0.18964815</span> <span class="mf">0.45714882</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.25946522</span> <span class="mf">0.24344791</span> <span class="mf">0.45677605</span> <span class="mf">0.3611395</span> <span class="mf">0.23378398</span> <span class="mf">0.41439137</span> <span class="mf">0.5312468</span> <span class="mf">0.4696194</span> <span class="p">]</span>
 <span class="p">[</span><span class="mf">0.2417504</span> <span class="mf">0.28193963</span> <span class="mf">0.06713893</span> <span class="mf">0.21510397</span> <span class="mf">0.23380603</span> <span class="mf">0.11424308</span> <span class="mf">0.0218009</span> <span class="o">-</span><span class="mf">0.11969765</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.45955992</span> <span class="mf">0.22664294</span> <span class="mf">0.01990281</span> <span class="mf">0.0731914</span> <span class="mf">0.27125207</span> <span class="mf">0.27298513</span> <span class="o">-</span><span class="mf">0.01716102</span> <span class="o">-</span><span class="mf">0.15327111</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.03440702</span> <span class="mf">0.41419312</span> <span class="mf">0.24817684</span> <span class="mf">0.30765256</span> <span class="mf">0.48516113</span> <span class="mf">0.24904746</span> <span class="mf">0.57791173</span> <span class="mf">0.00955463</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.13458519</span> <span class="mf">0.6690533</span> <span class="mf">0.49259356</span> <span class="mf">0.28319967</span> <span class="mf">0.25951773</span> <span class="mf">0.16777472</span> <span class="mf">0.45696738</span>  <span class="mf">0.24933104</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.14152306</span> <span class="mf">0.5040985</span> <span class="mf">0.24455397</span> <span class="mf">0.10907605</span> <span class="mf">0.11319532</span> <span class="mf">0.19538902</span> <span class="mf">0.01208619</span>  <span class="mf">0.40430856</span><span class="p">]</span>
 <span class="p">[</span><span class="o">-</span><span class="mf">0.7773164</span> <span class="o">-</span><span class="mf">0.47611716</span> <span class="o">-</span><span class="mf">0.6041424</span> <span class="o">-</span><span class="mf">0.6144473</span> <span class="o">-</span><span class="mf">0.2651842</span> <span class="o">-</span><span class="mf">0.31909415</span> <span class="o">-</span><span class="mf">0.4510405</span>
  <span class="o">-</span><span class="mf">0.12860501</span><span class="p">]]</span>
</pre></div>
</div>
</li>
<li><p>Execute stage 2 training and load the checkpoint file before training. The training code needs to be supplemented based on the site requirements.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Parameter</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>

<span class="kn">from</span> <span class="nn">mindspore.communication.management</span> <span class="kn">import</span> <span class="n">init</span>
<span class="n">devid</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;DEVICE_ID&#39;</span><span class="p">))</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span><span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">,</span><span class="n">save_graphs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device_id</span><span class="o">=</span><span class="n">devid</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">weight_init</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">weight_init</span><span class="p">),</span> <span class="s2">&quot;model_parallel_weight&quot;</span><span class="p">,</span> <span class="n">layerwise_parallel</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
<span class="k">def</span> <span class="nf">train_mindspore_impl_fc</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">ckpt_file</span><span class="p">):</span>
    <span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">ckpt_file</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">paramname</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;model_parallel_weight&quot;</span><span class="p">,</span> <span class="s2">&quot;moments.model_parallel_weight&quot;</span><span class="p">]:</span>
        <span class="c1"># get layer wise model parallel parameter</span>
        <span class="n">new_param</span> <span class="o">=</span> <span class="n">parameter_dict</span><span class="p">[</span><span class="n">paramname</span><span class="p">]</span>
        <span class="c1"># split the model parameter data</span>
        <span class="n">slice_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">new_param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># Load the corresponding data slice</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
        <span class="n">tensor_slice</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">slice_list</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span>
        <span class="c1"># modify model parameter data values</span>
        <span class="n">new_param</span><span class="o">.</span><span class="n">set_parameter_data</span><span class="p">(</span><span class="n">tensor_slice</span><span class="p">)</span>

        <span class="c1"># load the modified parameter data into the network</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">parallel_net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">())</span>
        <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
        <span class="c1"># train code </span>
        <span class="o">...</span>

    <span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mean = &quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">train_mindspore_impl_fc</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">weight1</span><span class="p">)</span>
</pre></div>
</div>
<p>Parameter values after loading:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>device0：
name is model_parallel_weight
value is 
[[0.87537426 1.0448935 0.86736983 0.8836905 0.77354026 0.69588304 0.9183654 0.7792076]
[0.87224025 0.8726848 0.771446 0.81967723 0.88974726 0.7988162 0.72919345 0.7677011]
[0.8828271 0.7963984 0.90675324 0.9830291 0.89010954 0.897052 0.7890109 0.89784735]
[1.0011744 1.0840297 1.0201758 1.0882459 0.94232416 1.0775206 1.0195118 1.0528734]]
name is learning_rate
value is [0.01]
name is momentum
value is [0.9]
name is moments.model_weight
value is
[[0.2567724 -0.07485991 0.282002 0.2456022 0.454939 0.619168 0.18964815 0.45714882]
[0.25946522 0.24344791 0.45677605 0.3611395 0.23378398 0.41439137 0.5312468 0.4696194]
[0.2417504 0.28193963 0.06713893 0.21510397 0.23380603 0.11424308 0.0218009 -0.11969765]
[0.45955992 0.22664294 0.01990281 0.0731914 0.27125207 0.27298513 -0.01716102  -0.15327111]]

device1：
name is model_parallel_weight
value is 
[[1.0053468 0.98402303 0.99762845 0.97587246 1.0259694 1.0055295 0.99420834 0.9496847]
[1.0851002 1.0295962 1.0999886 1.0958165 0.9765328 1.146529 1.0970603 1.1388365]
[0.7147005 0.9168278 0.80178416 0.6258351 0.8413766 0.5909515 0.696347 0.71359116]
[0.20506378 0.03691584 0.2454556 0.12978578 0.19065076 0.23904312 0.27509746 0.34614682]]
name is learning_rate
value is [0.01]
name is momentum
value is [0.9]
name is moments.model_weight
value is
[[0.03440702 0.41419312 0.24817684 0.30765256 0.48516113 0.24904746 0.57791173 0.00955463]
[0.13458519 0.6690533 0.49259356 0.28319967 0.25951773 0.16777472 0.45696738  0.24933104]
[0.14152306 0.5040985 0.24455397 0.10907605 0.11319532 0.19538902 0.01208619  0.40430856]
[-0.7773164 -0.47611716 -0.6041424 -0.6144473 -0.2651842 -0.31909415 -0.4510405 -0.12860501]] 
</pre></div>
</div>
</li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="distributed_training.html" class="btn btn-neutral float-left" title="Getting Started with Parallel Distributed Training" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mixed_precision.html" class="btn btn-neutral float-right" title="Mixed Precision" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>