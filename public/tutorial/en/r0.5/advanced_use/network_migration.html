<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Network Migration &mdash; MindSpore r0.5 documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Model Security" href="model_security.html" />
    <link rel="prev" title="On-Device Inference" href="on_device_inference.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation/data_preparation.html">Data Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">Defining the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/saving_and_loading_model_parameters.html">Saving and Loading Model Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/multi_platform_inference.html">Multi-platform Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="computer_vision_application.html">Computer Vision Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_application.html">Natural Language Processing (NLP) Application</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debugging_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="customized_debugging_information.html">Customized Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization_tutorials.html">Training Process Visualization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_tutorials.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed_precision.html">Mixed Precision</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Usage on Device</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="on_device_inference.html">On-Device Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Network Migration</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Network Migration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#preparations">Preparations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#operator-assessment">Operator Assessment</a></li>
<li class="toctree-l3"><a class="reference internal" href="#software-and-hardware-environments">Software and Hardware Environments</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#e2e-network-migration">E2E Network Migration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#training-phase">Training Phase</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#script-migration">Script Migration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#accuracy-debugging">Accuracy Debugging</a></li>
<li class="toctree-l4"><a class="reference internal" href="#on-cloud-integration">On-Cloud Integration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#inference-phase">Inference Phase</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#examples">Examples</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_security.html">Model Security</a></li>
<li class="toctree-l1"><a class="reference internal" href="differential_privacy.html">Differential Privacy in Machine Learning</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Network Migration</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/advanced_use/network_migration.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="network-migration">
<h1>Network Migration<a class="headerlink" href="#network-migration" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/tree/r0.5/tutorials/source_en/advanced_use/network_migration.md"><img alt="View Source On Gitee" src="../_images/logo_source.png" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>You’ve probably written scripts for frameworks such as TensorFlow and PyTorch. This tutorial describes how to migrate existing TensorFlow and PyTorch networks to MindSpore, including key steps and operation recommendations which help you quickly migrate your network.</p>
</section>
<section id="preparations">
<h2>Preparations<a class="headerlink" href="#preparations" title="Permalink to this headline"></a></h2>
<p>Before you start working on your scripts, prepare your operator assessment and hardware and software environments to make sure that MindSpore can support the network you want to migrate.</p>
<section id="operator-assessment">
<h3>Operator Assessment<a class="headerlink" href="#operator-assessment" title="Permalink to this headline"></a></h3>
<p>Analyze the operators contained in the network to be migrated and figure out how does MindSpore support these operators based on the <a class="reference external" href="https://www.mindspore.cn/docs/en/r0.5/operator_list.html">Operator List</a>.</p>
<p>Take ResNet-50 as an example. The two major operators <a class="reference external" href="https://www.mindspore.cn/api/en/r0.5/api/python/mindspore/mindspore.nn.html#mindspore.nn.Conv2d">Conv</a> and <a class="reference external" href="https://www.mindspore.cn/api/en/r0.5/api/python/mindspore/mindspore.nn.html#mindspore.nn.BatchNorm2d">BatchNorm</a> exist in the MindSpore Operator List.</p>
<p>If any operator does not exist, you are advised to perform the following operations:</p>
<ul class="simple">
<li><p>Operator replacement: Analyze the operator implementation formula and check whether a combination of existing operators of MindSpore can be used to achieve the expected objective.</p></li>
<li><p>Substitution solution: For example, if a loss operator is not supported, check whether it can be replaced with a loss operator of the same type supported by MindSpore; alternatively, check whether the current network structure can be replaced by another mainstream network of the same type.</p></li>
</ul>
<p>If the operators used for replacement are not able to fulfill complete function, you are advised to perform the following operations:</p>
<ul class="simple">
<li><p>Delete unnecessary functions.</p></li>
<li><p>Find a substitution solution for necessary functions.</p></li>
</ul>
<p>If the preceding requirements cannot be met, you can raise requirements in the <a class="reference external" href="https://gitee.com/mindspore/mindspore">MindSpore community</a>.</p>
</section>
<section id="software-and-hardware-environments">
<h3>Software and Hardware Environments<a class="headerlink" href="#software-and-hardware-environments" title="Permalink to this headline"></a></h3>
<p>Prepare the hardware environment, find a platform corresponding to your environment by referring to the <a class="reference external" href="https://www.mindspore.cn/install/en">installation guide</a>, and install MindSpore.</p>
</section>
</section>
<section id="e2e-network-migration">
<h2>E2E Network Migration<a class="headerlink" href="#e2e-network-migration" title="Permalink to this headline"></a></h2>
<section id="training-phase">
<h3>Training Phase<a class="headerlink" href="#training-phase" title="Permalink to this headline"></a></h3>
<section id="script-migration">
<h4>Script Migration<a class="headerlink" href="#script-migration" title="Permalink to this headline"></a></h4>
<p>MindSpore differs from TensorFlow and PyTorch in the network structure. Before migration, you need to clearly understand the original script and information of each layer, such as shape.</p>
<blockquote>
<div><p>You can also use <a class="reference external" href="https://gitee.com/mindspore/mindinsight/tree/r0.5/mindinsight/mindconverter">MindConverter Tool</a> to automatically convert the PyTorch network definition script to MindSpore network definition script.</p>
</div></blockquote>
<p>The ResNet-50 network migration and training on the Ascend 910 is used as an example.</p>
<ol class="arabic">
<li><p>Import MindSpore modules.</p>
<p>Import the corresponding MindSpore modules based on the required APIs. For details about the module list, see <a class="reference external" href="https://www.mindspore.cn/api/en/r0.5/index.html">https://www.mindspore.cn/api/en/r0.5/index.html</a>.</p>
</li>
<li><p>Load and preprocess a dataset.</p>
<p>Use MindSpore to build the required dataset. Currently, MindSpore supports common datasets. You can call APIs in the original format, <code class="docutils literal notranslate"><span class="pre">MindRecord</span></code>, and <code class="docutils literal notranslate"><span class="pre">TFRecord</span></code>. In addition, MindSpore supports data processing and data augmentation. For details, see the <a class="reference external" href="https://www.mindspore.cn/tutorial/en/r0.5/use/data_preparation/data_preparation.html">Data Preparation</a>.</p>
<p>In this example, the CIFAR-10 dataset is loaded, which supports both single-GPU and multi-GPU scenarios.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">device_num</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">de</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">de</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                           <span class="n">num_shards</span><span class="o">=</span><span class="n">device_num</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="n">rank_id</span><span class="p">)</span>
</pre></div>
</div>
<p>Then, perform data augmentation, data cleaning, and batch processing. For details about the code, see <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r0.5/model_zoo/resnet/src/dataset.py">https://gitee.com/mindspore/mindspore/blob/r0.5/model_zoo/resnet/src/dataset.py</a>.</p>
</li>
<li><p>Build a network.</p>
<p>The biggest difference between MindSpore and TensorFlow in convolution is the data format. <code class="docutils literal notranslate"><span class="pre">NCHW</span></code> is used in MindSpore by default, while <code class="docutils literal notranslate"><span class="pre">NHWC</span></code> is used in TensorFlow.</p>
<p>The following uses the first convolutional layer on the ResNet-50 network whose batch_size is set to 32 as an example:</p>
<ul>
<li><p>In TensorFlow, the format of the input feature is [32, 224, 224, 3], and the size of the convolution kernel is [7, 7, 3, 64].</p></li>
<li><p>In MindSpore, the format of the input feature is [32, 3, 224, 224], and the size of the convolution kernel is [64, 3, 7, 7].</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_conv7x7</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">weight_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">_weight_variable</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span>
                    <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">weight</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_bn</span><span class="p">(</span><span class="n">channel</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                        <span class="n">gamma_init</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">beta_init</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">moving_mean_init</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">moving_var_init</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Build a subnet.</p>
<p>In MindSpore, <code class="docutils literal notranslate"><span class="pre">nn.Cell</span></code> is used to build a subnet structure. The network structure must be defined before being used in a subnet. Define each operator to be used in the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> function of the Cell, connect the defined operators in the <code class="docutils literal notranslate"><span class="pre">construct</span></code> function, and then return the output of the subnet through <code class="docutils literal notranslate"><span class="pre">return</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ResidualBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ResNet V1 residual block definition.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_channel (int): Input channel.</span>
<span class="sd">        out_channel (int): Output channel.</span>
<span class="sd">        stride (int): Stride size for the first convolutional layer. Default: 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, output tensor.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; ResidualBlock(3, 256, stride=2)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">expansion</span> <span class="o">=</span> <span class="mi">4</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">in_channel</span><span class="p">,</span>
                <span class="n">out_channel</span><span class="p">,</span>
                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ResidualBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">channel</span> <span class="o">=</span> <span class="n">out_channel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">_conv1x1</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">_bn</span><span class="p">(</span><span class="n">channel</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">_conv3x3</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="n">channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">_bn</span><span class="p">(</span><span class="n">channel</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">_conv1x1</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">_bn_last</span><span class="p">(</span><span class="n">out_channel</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">stride</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">in_channel</span> <span class="o">!=</span> <span class="n">out_channel</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span><span class="n">_conv1x1</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
                                                        <span class="n">_bn</span><span class="p">(</span><span class="n">out_channel</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">TensorAdd</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">identity</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span><span class="p">:</span>
            <span class="n">identity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span><span class="p">(</span><span class="n">identity</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">identity</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</li>
<li><p>Define a concatenated structure.</p>
<p>The ResNet-50 network has a large number of repeated structures. In TensorFlow, you can use the for loop function to reduce repeated code. In MindSpore, each defined Cell object is independent. Especially for subnets with weight parameters, the defined Cell cannot be used repeatedly. If a large number of repeated concatenated structures exist, you can construct multiple Cell instances using the for loop function and concatenate them by using <code class="docutils literal notranslate"><span class="pre">SequentialCell</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_make_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="n">layer_num</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Make stage network of ResNet.</span>

<span class="sd">    Args:</span>
<span class="sd">        block (Cell): Resnet block.</span>
<span class="sd">        layer_num (int): Layer number.</span>
<span class="sd">        in_channel (int): Input channel.</span>
<span class="sd">        out_channel (int): Output channel.</span>
<span class="sd">        stride (int): Stride size for the first convolutional layer.</span>

<span class="sd">    Returns:</span>
<span class="sd">        SequentialCell, the output layer.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; _make_layer(ResidualBlock, 3, 128, 256, 2)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">resnet_block</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">resnet_block</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">layer_num</span><span class="p">):</span>
        <span class="n">resnet_block</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">resnet_block</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Build the entire network.</p>
<p>The <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r0.5/model_zoo/resnet/src/resnet.py">ResNet-50</a> network structure is formed by connecting multiple defined subnets. Follow the rule of defining subnets before using them and define all the subnets used in the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> and connect subnets in the <code class="docutils literal notranslate"><span class="pre">construct</span></code>.</p>
</li>
<li><p>Define a loss function and an optimizer.</p>
<p>After the network is defined, the loss function and optimizer need to be defined accordingly.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()),</span> <span class="n">lr</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Build a model.</p>
<p>Similar to the <code class="docutils literal notranslate"><span class="pre">Estimator</span></code> API of TensorFlow, the defined network prototype, loss function, and optimizer are transferred to the <code class="docutils literal notranslate"><span class="pre">Model</span></code> API of MindSpore and automatically combined into a network that can be used for training.</p>
<p>To use loss scale in training, define a <code class="docutils literal notranslate"><span class="pre">loss_scale_manager</span></code> and transfer it to the <code class="docutils literal notranslate"><span class="pre">Model</span></code> API.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">loss_scale</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">drop_overflow_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>You can use a built-in assessment method of <code class="docutils literal notranslate"><span class="pre">Model</span></code> by setting the <a class="reference external" href="https://www.mindspore.cn/tutorial/en/r0.5/advanced_use/customized_debugging_information.html#mindspore-metrics">metrics</a> attribute.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">})</span>
</pre></div>
</div>
<p>Similar to <code class="docutils literal notranslate"><span class="pre">estimator.train</span></code> of TensorFlow, you can call the <code class="docutils literal notranslate"><span class="pre">model.train</span></code> API to perform training. Functions such as CheckPoint and intermediate result printing can be defined on the <code class="docutils literal notranslate"><span class="pre">model.train</span></code> API in Callback mode.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">time_cb</span> <span class="o">=</span> <span class="n">TimeMonitor</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="n">step_size</span><span class="p">)</span>
<span class="n">loss_cb</span> <span class="o">=</span> <span class="n">LossMonitor</span><span class="p">()</span>
<span class="n">cb</span> <span class="o">=</span> <span class="p">[</span><span class="n">time_cb</span><span class="p">,</span> <span class="n">loss_cb</span><span class="p">]</span>
<span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">:</span>
    <span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">save_checkpoint_steps</span><span class="p">,</span>
                                    <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">keep_checkpoint_max</span><span class="p">)</span>
    <span class="n">ckpt_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;resnet&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">save_checkpoint_path</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
    <span class="n">cb</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ckpt_cb</span><span class="p">]</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch_size</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">cb</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="accuracy-debugging">
<h4>Accuracy Debugging<a class="headerlink" href="#accuracy-debugging" title="Permalink to this headline"></a></h4>
<p>The accuracy optimization process is as follows:</p>
<ol class="arabic simple">
<li><p>When validating the single-GPU accuracy, you are advised to use a small dataset for training. After the validation is successful, use the full dataset for multi-GPU accuracy validation. This helps improve the debugging efficiency.</p></li>
<li><p>Delete unnecessary skills (such as augmentation configuration and dynamic loss scale in an optimizer) from the script. After the validation is successful, add functions one by one. After a new function is confirmed to be normal, add the next function. In this way, you can quickly locate the fault.</p></li>
</ol>
</section>
<section id="on-cloud-integration">
<h4>On-Cloud Integration<a class="headerlink" href="#on-cloud-integration" title="Permalink to this headline"></a></h4>
<p>Run your scripts on ModelArts. For details, see <a class="reference external" href="https://www.mindspore.cn/tutorial/zh-CN/r0.5/advanced_use/use_on_the_cloud.html">Using MindSpore on Cloud</a>.</p>
</section>
</section>
<section id="inference-phase">
<h3>Inference Phase<a class="headerlink" href="#inference-phase" title="Permalink to this headline"></a></h3>
<p>Models trained on the Ascend 910 AI processor can be used for inference on different hardware platforms. Refer to the <a class="reference external" href="https://www.mindspore.cn/tutorial/en/r0.5/use/multi_platform_inference.html">Multi-platform Inference Tutorial</a> for detailed steps.</p>
</section>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this headline"></a></h2>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://www.mindspore.cn/tutorial/en/r0.5/use/data_preparation/loading_the_datasets.html">Common dataset examples</a></p></li>
<li><p><a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r0.5/model_zoo">Model Zoo</a></p></li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="on_device_inference.html" class="btn btn-neutral float-left" title="On-Device Inference" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="model_security.html" class="btn btn-neutral float-right" title="Model Security" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>