

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Custom Operators &mdash; MindSpore r0.5 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Saving and Loading Model Parameters" href="saving_and_loading_model_parameters.html" />
    <link rel="prev" title="Defining the Network" href="defining_the_network.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
</ul>
<p class="caption"><span class="caption-text">Use</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="data_preparation/data_preparation.html">Data Preparation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="defining_the_network.html">Defining the Network</a><ul class="current">
<li class="toctree-l2"><a class="reference external" href="https://www.mindspore.cn/docs/en/r0.5/network_list.html">Network List</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Custom Operators</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#registering-the-operator-primitive">Registering the Operator Primitive</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implementing-a-tbe-operator-and-registering-the-operator-information">Implementing a TBE Operator and Registering the Operator Information</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#implementing-a-tbe-operator">Implementing a TBE Operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="#registering-the-operator-information">Registering the Operator Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example">Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#using-custom-operators">Using Custom Operators</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-bprop-function-for-an-operator">Defining the bprop Function for an Operator</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="saving_and_loading_model_parameters.html">Saving and Loading Model Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Multi-platform Inference</a></li>
</ul>
<p class="caption"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/computer_vision_application.html">Computer Vision Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/nlp_application.html">Natural Language Processing (NLP) Application</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/debugging_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/customized_debugging_information.html">Customized Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/visualization_tutorials.html">Training Process Visualization</a></li>
</ul>
<p class="caption"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/distributed_training_tutorials.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/mixed_precision.html">Mixed Precision</a></li>
</ul>
<p class="caption"><span class="caption-text">Usage on Device</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/on_device_inference.html">On-Device Inference</a></li>
</ul>
<p class="caption"><span class="caption-text">Network Migration</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/network_migration.html">Network Migration</a></li>
</ul>
<p class="caption"><span class="caption-text">AI Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/model_security.html">Model Security</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/differential_privacy.html">Differential Privacy in Machine Learning</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="defining_the_network.html">Defining the Network</a> &raquo;</li>
        
      <li>Custom Operators</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/use/custom_operator.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="custom-operators">
<h1>Custom Operators<a class="headerlink" href="#custom-operators" title="Permalink to this headline">¶</a></h1>
<!-- TOC --><ul class="simple">
<li><p><a class="reference external" href="#custom-operators">Custom Operators</a></p>
<ul>
<li><p><a class="reference external" href="#overview">Overview</a></p></li>
<li><p><a class="reference external" href="#registering-the-operator-primitive">Registering the Operator Primitive</a></p></li>
<li><p><a class="reference external" href="#implementing-a-tbe-operator-and-registering-the-operator-information">Implementing a TBE Operator and Registering the Operator Information</a></p>
<ul>
<li><p><a class="reference external" href="#implementing-a-tbe-operator">Implementing a TBE Operator</a></p></li>
<li><p><a class="reference external" href="#registering-the-operator-information">Registering the Operator Information</a></p></li>
<li><p><a class="reference external" href="#example">Example</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#using-custom-operators">Using Custom Operators</a></p></li>
<li><p><a class="reference external" href="#defining-the-bprop-function-for-an-operator">Defining the bprop Function for an Operator</a></p></li>
</ul>
</li>
</ul>
<!-- /TOC --><p><a href="https://gitee.com/mindspore/docs/blob/r0.5/tutorials/source_en/use/custom_operator.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>When built-in operators cannot meet requirements during network development, you can call the Python API of MindSpore to quickly extend custom operators of the Ascend AI processor.</p>
<p>To add a custom operator, you need to register the operator primitive, implement the operator, and register the operator information.</p>
<p>The related concepts are as follows:</p>
<ul class="simple">
<li><p>Operator primitive: defines the frontend API prototype of an operator on the network. It is the basic unit for forming a network model and includes the operator name, attribute (optional), input and output names, output shape inference method, and output dtype inference method.</p></li>
<li><p>Operator implementation: describes the implementation of the internal computation logic for an operator through the DSL API provided by the Tensor Boost Engine (TBE). The TBE supports the development of custom operators based on the Ascend AI chip. You can apply for Open Beta Tests (OBTs) by visiting <a class="reference external" href="https://www.huaweicloud.com/ascend/tbe">https://www.huaweicloud.com/ascend/tbe</a>.</p></li>
<li><p>Operator information: describes basic information about a TBE operator, such as the operator name and supported input and output types. It is the basis for the backend to select and map operators.</p></li>
</ul>
<p>This section takes a Square operator as an example to describe how to customize an operator. For details, see cases in <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r0.5/tests/st/ops/custom_ops_tbe">tests/st/ops/custom_ops_tbe</a> in the MindSpore source code.</p>
</div>
<div class="section" id="registering-the-operator-primitive">
<h2>Registering the Operator Primitive<a class="headerlink" href="#registering-the-operator-primitive" title="Permalink to this headline">¶</a></h2>
<p>The primitive of an operator is a subclass inherited from <code class="docutils literal notranslate"><span class="pre">PrimitiveWithInfer</span></code>. The type name of the subclass is the operator name.</p>
<p>The definition of the custom operator primitive is the same as that of the built-in operator primitive.</p>
<ul class="simple">
<li><p>The attribute is defined by the input parameter of the constructor function <code class="docutils literal notranslate"><span class="pre">__init__</span></code>. The operator in this test case has no attribute. Therefore, <code class="docutils literal notranslate"><span class="pre">__init__</span></code> has only one input parameter. For details about test cases in which operators have attributes, see <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r0.5/tests/st/ops/custom_ops_tbe/cus_add3.py">custom add3</a> in the MindSpore source code.</p></li>
<li><p>The input and output names are defined by the <code class="docutils literal notranslate"><span class="pre">init_prim_io_names</span></code> function.</p></li>
<li><p>The shape inference method of the output tensor is defined in the <code class="docutils literal notranslate"><span class="pre">infer_shape</span></code> function, and the dtype inference method of the output tensor is defined in the <code class="docutils literal notranslate"><span class="pre">infer_dtype</span></code> function.</p></li>
</ul>
<p>The only difference between a custom operator and a built-in operator is that the operator implementation function (<code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">square_impl</span> <span class="pre">import</span> <span class="pre">CusSquareImpl</span></code>) needs to be imported to the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> function to register the operator implementation with the backend for the custom operator. In this test case, the operator implementation and information are defined in <code class="docutils literal notranslate"><span class="pre">square_impl.py</span></code>, and the definition will be described in the following parts.</p>
<p>The following code takes the Square operator primitive <code class="docutils literal notranslate"><span class="pre">cus_square.py</span></code> as an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">prim_attr_register</span><span class="p">,</span> <span class="n">PrimitiveWithInfer</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="c1"># y = x^2</span>
<span class="k">class</span> <span class="nc">CusSquare</span><span class="p">(</span><span class="n">PrimitiveWithInfer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The definition of the CusSquare primitive.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@prim_attr_register</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_prim_io_names</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">])</span>
        <span class="kn">from</span> <span class="nn">square_impl</span> <span class="kn">import</span> <span class="n">CusSquareImpl</span> <span class="c1"># Import the entry function of the kernel implementation from relative path or PYTHONPATH.</span>

    <span class="k">def</span> <span class="nf">infer_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">data_shape</span>

    <span class="k">def</span> <span class="nf">infer_dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_dtype</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">data_dtype</span>
</pre></div>
</div>
</div>
<div class="section" id="implementing-a-tbe-operator-and-registering-the-operator-information">
<h2>Implementing a TBE Operator and Registering the Operator Information<a class="headerlink" href="#implementing-a-tbe-operator-and-registering-the-operator-information" title="Permalink to this headline">¶</a></h2>
<div class="section" id="implementing-a-tbe-operator">
<h3>Implementing a TBE Operator<a class="headerlink" href="#implementing-a-tbe-operator" title="Permalink to this headline">¶</a></h3>
<p>To compile an operator implementation, you need to compile a computable function and an entry function first.</p>
<p>The computable function of an operator is mainly used to encapsulate the computation logic of the operator for the main function to call. The computation logic is implemented by calling the combined API of the TBE.</p>
<p>The entry function of an operator describes the internal process of compiling the operator. The process is as follows:</p>
<ol class="simple">
<li><p>Prepare placeholders to be input. A placeholder will return a tensor object that represents a group of input data.</p></li>
<li><p>Call the computable function. The computable function uses the API provided by the TBE to describe the computation logic of the operator.</p></li>
<li><p>Call the scheduling module. The model tiles the operator data based on the scheduling description and specifies the data transfer process to ensure optimal hardware execution. By default, the automatic scheduling module (<code class="docutils literal notranslate"><span class="pre">auto_schedule</span></code>) can be used.</p></li>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">cce_build_code</span></code> to compile and generate an operator binary file.</p></li>
</ol>
<blockquote>
<div><p>The input parameters of the entry function require the input information of each operator, output information of each operator, operator attributes (optional), and <code class="docutils literal notranslate"><span class="pre">kernel_name</span></code> (name of the generated operator binary file). The input and output information is encapsulated in dictionaries, including the input and output shape and dtype when the operator is called on the network.</p>
</div></blockquote>
<p>For details about TBE operator development, visit the <a class="reference external" href="https://www.huaweicloud.com/ascend/tbe">TBE website</a>. For details about how to debug and optimize the TBE operator, visit the <a class="reference external" href="https://www.huaweicloud.com/intl/en-us/ascend/mindstudio">Mind Studio website</a>.</p>
</div>
<div class="section" id="registering-the-operator-information">
<h3>Registering the Operator Information<a class="headerlink" href="#registering-the-operator-information" title="Permalink to this headline">¶</a></h3>
<p>The operator information is key for the backend to select the operator implementation and guides the backend to insert appropriate type and format conversion operators. It uses the <code class="docutils literal notranslate"><span class="pre">TBERegOp</span></code> API for definition and uses the <code class="docutils literal notranslate"><span class="pre">op_info_register</span></code> decorator to bind the operator information to the entry function of the operator implementation. When the .py operator implementation file is imported, the <code class="docutils literal notranslate"><span class="pre">op_info_register</span></code> decorator registers the operator information to the operator information library at the backend. For details about how to use the operator information, see comments for the member method of <code class="docutils literal notranslate"><span class="pre">TBERegOp</span></code>.</p>
<blockquote>
<div><p>The numbers and sequences of the input and output information defined in the operator information must be the same as those in the parameters of the entry function of the operator implementation and those listed in the operator primitive.</p>
</div></blockquote>
<blockquote>
<div><p>If an operator has attributes, use <code class="docutils literal notranslate"><span class="pre">attr</span></code> to describe the attribute information in the operator information. The attribute names must be the same as those in the operator primitive definition.</p>
</div></blockquote>
</div>
<div class="section" id="example">
<h3>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h3>
<p>The following takes the TBE implementation <code class="docutils literal notranslate"><span class="pre">square_impl.py</span></code> of the <code class="docutils literal notranslate"><span class="pre">Square</span></code> operator as an example. <code class="docutils literal notranslate"><span class="pre">square_compute</span></code> is a computable function of the operator implementation. It describes the computation logic of <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">*</span> <span class="pre">x</span></code> by calling the API provided by <code class="docutils literal notranslate"><span class="pre">te.lang.cce</span></code>. <code class="docutils literal notranslate"><span class="pre">cus_square_op_info</span> </code> is the operator information, which is defined by <code class="docutils literal notranslate"><span class="pre">TBERegOp</span></code>.</p>
<p>Note the following parameters when setting <code class="docutils literal notranslate"><span class="pre">TBERegOp</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">OPAQUE</span></code> in <code class="docutils literal notranslate"><span class="pre">fusion_type(&quot;OPAQUE&quot;)</span></code> indicates that the custom operator uses the non-fusion strategy.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CusSquareImpl</span></code> in <code class="docutils literal notranslate"><span class="pre">kernel_name(&quot;CusSquareImpl&quot;)</span></code> must be the same as the name of the operator entry function.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dtype_format</span></code> is used to describe data types supported by the operator. In the following example, two types are registered, indicating that the operator supports two data types. Each type describes the supported format in order of input and output. The first <code class="docutils literal notranslate"><span class="pre">dtype_format</span></code> indicates that the data type input0 is in F32_Default format and the data type output0 is in F32_Default format. The second <code class="docutils literal notranslate"><span class="pre">dtype_format</span></code> indicates that the data type input0 is in F16_Default format and the data type output0 is in F16_Default format.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">te</span> <span class="kn">import</span> <span class="n">tvm</span>
<span class="kn">from</span> <span class="nn">topi</span> <span class="kn">import</span> <span class="n">generic</span>
<span class="kn">import</span> <span class="nn">te.lang.cce</span>
<span class="kn">from</span> <span class="nn">topi.cce</span> <span class="kn">import</span> <span class="n">util</span>
<span class="kn">from</span> <span class="nn">mindspore.ops.op_info_register</span> <span class="kn">import</span> <span class="n">op_info_register</span><span class="p">,</span> <span class="n">TBERegOp</span><span class="p">,</span> <span class="n">DataType</span>

<span class="k">def</span> <span class="nf">square_compute</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">output_y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The compute function of the CusSquare implementation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">cce</span><span class="o">.</span><span class="n">vmul</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>

<span class="c1"># Define the kernel info of CusSquare.</span>
<span class="n">cus_square_op_info</span> <span class="o">=</span> <span class="n">TBERegOp</span><span class="p">(</span><span class="s2">&quot;CusSquare&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">fusion_type</span><span class="p">(</span><span class="s2">&quot;OPAQUE&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">partial_flag</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">async_flag</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">binfile_name</span><span class="p">(</span><span class="s2">&quot;square.so&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">compute_cost</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">kernel_name</span><span class="p">(</span><span class="s2">&quot;CusSquareImpl&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;required&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;required&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">dtype_format</span><span class="p">(</span><span class="n">DataType</span><span class="o">.</span><span class="n">F32_Default</span><span class="p">,</span> <span class="n">DataType</span><span class="o">.</span><span class="n">F32_Default</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">dtype_format</span><span class="p">(</span><span class="n">DataType</span><span class="o">.</span><span class="n">F16_Default</span><span class="p">,</span> <span class="n">DataType</span><span class="o">.</span><span class="n">F16_Default</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">get_op_info</span><span class="p">()</span> 

<span class="c1"># Binding kernel info with the kernel implementation.</span>
<span class="nd">@op_info_register</span><span class="p">(</span><span class="n">cus_square_op_info</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">CusSquareImpl</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">output_y</span><span class="p">,</span> <span class="n">kernel_name</span><span class="o">=</span><span class="s2">&quot;CusSquareImpl&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The entry function of the CusSquare implementation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">shape_refine</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>

    <span class="k">with</span> <span class="n">tvm</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">cce</span><span class="p">():</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">square_compute</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">output_y</span><span class="p">)</span>
        <span class="n">sch</span> <span class="o">=</span> <span class="n">generic</span><span class="o">.</span><span class="n">auto_schedule</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>

    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;print_ir&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
              <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">kernel_name</span><span class="p">,</span>
              <span class="s2">&quot;tensor_list&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">res</span><span class="p">]}</span>

    <span class="n">te</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">cce</span><span class="o">.</span><span class="n">cce_build_code</span><span class="p">(</span><span class="n">sch</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="using-custom-operators">
<h2>Using Custom Operators<a class="headerlink" href="#using-custom-operators" title="Permalink to this headline">¶</a></h2>
<p>The usage of custom operators is the same as that of built-in operators on the network. The operators can be directly used by importing primitives. The following takes the single-operator network test of <code class="docutils literal notranslate"><span class="pre">CusSquare</span></code> as an example.</p>
<p>Define the network in the <code class="docutils literal notranslate"><span class="pre">test_square.py</span></code> file.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="c1"># Import the definition of the CusSquare primitive.</span>
<span class="kn">from</span> <span class="nn">cus_square</span> <span class="kn">import</span> <span class="n">CusSquare</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">square</span> <span class="o">=</span> <span class="n">CusSquare</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">test_net</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">square</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">square</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x: &quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output: &quot;</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>Execute the test case.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pytest</span> <span class="o">-</span><span class="n">s</span> <span class="n">tests</span><span class="o">/</span><span class="n">st</span><span class="o">/</span><span class="n">ops</span><span class="o">/</span><span class="n">custom_ops_tbe</span><span class="o">/</span><span class="n">test_square</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_net</span>
</pre></div>
</div>
<p>The execution result is as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.</span> <span class="mf">4.</span> <span class="mf">9.</span><span class="p">]</span>
<span class="n">output</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.</span> <span class="mf">16.</span> <span class="mf">81.</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="defining-the-bprop-function-for-an-operator">
<h2>Defining the bprop Function for an Operator<a class="headerlink" href="#defining-the-bprop-function-for-an-operator" title="Permalink to this headline">¶</a></h2>
<p>If an operator needs to support automatic differentiation, the bprop function needs to be defined in the primitive of the operator. In the bprop function, you need to describe the backward computation logic that uses the forward input, forward output, and output gradients to obtain the input gradients. The backward computation logic can be composed of built-in operators or custom backward operators.</p>
<p>Note the following points when defining the bprop function:</p>
<ul class="simple">
<li><p>The input parameter sequence of the bprop function is the forward input, forward output, and output gradients. For a multi-output operator, the forward output and output gradients are provided in the form of tuples.</p></li>
<li><p>The return value of the bprop function is tuples consisting of input gradients. The sequence of elements in a tuple is the same as that of the forward input parameters. Even if there is only one input gradient, the return value must be a tuple.</p></li>
</ul>
<p>For example, the <code class="docutils literal notranslate"><span class="pre">CusSquare</span></code> primitive after the bprop function is added is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CusSquare</span><span class="p">(</span><span class="n">PrimitiveWithInfer</span><span class="p">):</span>
    <span class="nd">@prim_attr_register</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;init CusSquare&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_prim_io_names</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">])</span>
        <span class="kn">from</span> <span class="nn">square_impl</span> <span class="kn">import</span> <span class="n">CusSquareImpl</span>

    <span class="k">def</span> <span class="nf">infer_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">data_shape</span>

    <span class="k">def</span> <span class="nf">infer_dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_dtype</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">data_dtype</span>

    <span class="k">def</span> <span class="nf">get_bprop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">bprop</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
            <span class="n">twos_like</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">OnesLike</span><span class="p">()(</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="mf">2.0</span>
            <span class="n">gradient</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Mul</span><span class="p">()(</span><span class="n">data</span><span class="p">,</span> <span class="n">twos_like</span><span class="p">)</span>
            <span class="n">dx</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Mul</span><span class="p">()(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">dx</span><span class="p">,)</span>
        <span class="k">return</span> <span class="n">bprop</span>
</pre></div>
</div>
<p>Define backward cases in the <code class="docutils literal notranslate"><span class="pre">test_square.py</span></code> file.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">composite</span> <span class="k">as</span> <span class="n">C</span>
<span class="k">def</span> <span class="nf">test_grad_net</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">sens</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">square</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">GradOperation</span><span class="p">(</span><span class="s1">&#39;grad_with_sens&#39;</span><span class="p">,</span> <span class="n">sens_param</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">square</span><span class="p">)(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">sens</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x: &quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dx: &quot;</span><span class="p">,</span> <span class="n">dx</span><span class="p">)</span>
</pre></div>
</div>
<p>Execute the test case.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pytest</span> <span class="o">-</span><span class="n">s</span> <span class="n">tests</span><span class="o">/</span><span class="n">st</span><span class="o">/</span><span class="n">ops</span><span class="o">/</span><span class="n">custom_ops_tbe</span><span class="o">/</span><span class="n">test_square</span><span class="o">.</span><span class="n">py</span><span class="p">::</span><span class="n">test_grad_net</span>
</pre></div>
</div>
<p>The execution result is as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.</span> <span class="mf">4.</span> <span class="mf">9.</span><span class="p">]</span>
<span class="n">dx</span><span class="p">:</span> <span class="p">[</span><span class="mf">2.</span> <span class="mf">8.</span> <span class="mf">18.</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="saving_and_loading_model_parameters.html" class="btn btn-neutral float-right" title="Saving and Loading Model Parameters" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="defining_the_network.html" class="btn btn-neutral float-left" title="Defining the Network" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, MindSpore

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>