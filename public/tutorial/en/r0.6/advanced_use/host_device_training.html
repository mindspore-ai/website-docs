<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Host+Device Hybrid Training &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Saving and Loading Model Parameters in the Hybrid Parallel Scenario" href="checkpoint_for_hybrid_parallel.html" />
    <link rel="prev" title="Parallel Distributed Training (Ascend)" href="distributed_training_ascend.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation/data_preparation.html">Data Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">Defining the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/saving_and_loading_model_parameters.html">Saving and Loading Model Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/multi_platform_inference.html">Multi-Platform Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="computer_vision_application.html">Computer Vision Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_application.html">Natural Language Processing (NLP) Application</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debugging_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="customized_debugging_information.html">Customized Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization_tutorials.html">Training Process Visualization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="distributed_training_tutorials.html">Distributed training</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="distributed_training_ascend.html">Parallel Distributed Training (Ascend)</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Host+Device Hybrid Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#preliminaries">Preliminaries</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configuring-for-hybrid-training">Configuring for Hybrid Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training-the-model">Training the Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="checkpoint_for_hybrid_parallel.html">Saving and Loading Model Parameters in the Hybrid Parallel Scenario</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mixed_precision.html">Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_kernel_fusion.html">Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization_aware.html">Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Network Migration</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="network_migration.html">Network Migration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_security.html">Model Security</a></li>
<li class="toctree-l1"><a class="reference internal" href="differential_privacy.html">Differential Privacy in Machine Learning</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="distributed_training_tutorials.html">Distributed training</a> &raquo;</li>
      <li>Host+Device Hybrid Training</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/advanced_use/host_device_training.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="host-device-hybrid-training">
<h1>Host+Device Hybrid Training<a class="headerlink" href="#host-device-hybrid-training" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r0.6/tutorials/source_en/advanced_use/host_device_training.md"><img alt="View Source On Gitee" src="../_images/logo_source.png" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>In deep learning, one usually has to deal with the huge model problem, in which the total size of parameters in the model is beyond the device memory capacity. To efficiently train a huge model, one solution is to employ homogenous accelerators (<em>e.g.</em>, Ascend 910 AI Accelerator and GPU) for <a class="reference external" href="https://www.mindspore.cn/tutorial/en/r0.6/advanced_use/distributed_training.html">distributed training</a>. When the size of a model is hundreds of GBs or several TBs,
the number of required accelerators is too overwhelming for people to access, resulting in this solution inapplicable.  One alternative is Host+Device hybrid training. This solution simultaneously leveraging the huge memory in hosts and fast computation in accelerators, is a promisingly
efficient method for addressing huge model problem.</p>
<p>In MindSpore, users can easily implement hybrid training by configuring trainable parameters and necessary operators to run on hosts, and other operators to run on accelerators.
This tutorial introduces how to train <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r0.6/model_zoo/official/recommend/wide_and_deep">Wide&amp;Deep</a> in the Host+Ascend 910 AI Accelerator mode.</p>
</section>
<section id="preliminaries">
<h2>Preliminaries<a class="headerlink" href="#preliminaries" title="Permalink to this headline"></a></h2>
<ol class="arabic">
<li><p>Prepare the model. The Wide&amp;Deep code can be found at: <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r0.6/model_zoo/official/recommend/wide_and_deep">https://gitee.com/mindspore/mindspore/tree/r0.6/model_zoo/official/recommend/wide_and_deep</a>, in which <code class="docutils literal notranslate"><span class="pre">train_and_eval_auto_parallel.py</span></code> is the main function for training,
<code class="docutils literal notranslate"><span class="pre">src/</span></code> directory contains the model definition, data processing and configuration files, <code class="docutils literal notranslate"><span class="pre">script/</span></code> directory contains the launch scripts in different modes.</p></li>
<li><p>Prepare the dataset. The dataset can be found at: <a class="reference external" href="https://s3-eu-west-1.amazonaws.com/kaggle-display-advertising-challenge-dataset/dac.tar.gz">https://s3-eu-west-1.amazonaws.com/kaggle-display-advertising-challenge-dataset/dac.tar.gz</a>. Use the script <code class="docutils literal notranslate"><span class="pre">src/preprocess_data.py</span></code> to transform dataset into MindRecord format.</p></li>
<li><p>Configure the device information. When performing training in the bare-metal environment, the network information file needs to be configured. This example only employs one accelerator, thus <code class="docutils literal notranslate"><span class="pre">rank_table_1p_0.json</span></code> containing #0 accelerator is configured as follows (you need to check the server’s IP first):</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">     </span><span class="nt">&quot;version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1.0&quot;</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;server_count&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;server_list&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">         </span><span class="p">{</span>
<span class="w">             </span><span class="nt">&quot;server_id&quot;</span><span class="p">:</span><span class="s2">&quot;10.*.*.*&quot;</span><span class="p">,</span>
<span class="w">             </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                      </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="s2">&quot;0&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="s2">&quot;192.1.113.246&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="s2">&quot;0&quot;</span><span class="p">}],</span>
<span class="w">             </span><span class="nt">&quot;host_nic_ip&quot;</span><span class="p">:</span><span class="s2">&quot;reserve&quot;</span>
<span class="w">         </span><span class="p">}</span>
<span class="w">     </span><span class="p">],</span>
<span class="w">     </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;completed&quot;</span>
<span class="w"> </span><span class="p">}</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="configuring-for-hybrid-training">
<h2>Configuring for Hybrid Training<a class="headerlink" href="#configuring-for-hybrid-training" title="Permalink to this headline"></a></h2>
<ol class="arabic">
<li><p>Configure the flag of hybrid training. In the function <code class="docutils literal notranslate"><span class="pre">argparse_init</span></code> of file <code class="docutils literal notranslate"><span class="pre">src/config.py</span></code>, change the default value of <code class="docutils literal notranslate"><span class="pre">host_device_mix</span></code> to be <code class="docutils literal notranslate"><span class="pre">1</span></code>; change <code class="docutils literal notranslate"><span class="pre">self.host_device_mix</span></code> in function <code class="docutils literal notranslate"><span class="pre">__init__</span></code> of <code class="docutils literal notranslate"><span class="pre">class</span> <span class="pre">WideDeepConfig</span></code> to be <code class="docutils literal notranslate"><span class="pre">1</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">host_device_mix</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</li>
<li><p>Check placement of necessary operators and optimizers. In class <code class="docutils literal notranslate"><span class="pre">WideDeepModel</span></code> of file <code class="docutils literal notranslate"><span class="pre">src/wide_and_deep.py</span></code>, check the placement of <code class="docutils literal notranslate"><span class="pre">EmbeddingLookup</span></code> is at host:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">deep_embeddinglookup</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">EmbeddingLookup</span><span class="p">()</span>
<span class="bp">self</span><span class="o">.</span><span class="n">wide_embeddinglookup</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">EmbeddingLookup</span><span class="p">()</span>
</pre></div>
</div>
<p>In <code class="docutils literal notranslate"><span class="pre">class</span> <span class="pre">TrainStepWrap(nn.Cell)</span></code> of file <code class="docutils literal notranslate"><span class="pre">src/wide_and_deep.py</span></code>, check two optimizer are also at host:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_w</span><span class="o">.</span><span class="n">sparse_opt</span><span class="o">.</span><span class="n">add_prim_attr</span><span class="p">(</span><span class="s2">&quot;primitive_target&quot;</span><span class="p">,</span> <span class="s2">&quot;CPU&quot;</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">optimizer_d</span><span class="o">.</span><span class="n">sparse_opt</span><span class="o">.</span><span class="n">add_prim_attr</span><span class="p">(</span><span class="s2">&quot;primitive_target&quot;</span><span class="p">,</span> <span class="s2">&quot;CPU&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="training-the-model">
<h2>Training the Model<a class="headerlink" href="#training-the-model" title="Permalink to this headline"></a></h2>
<p>Use the script <code class="docutils literal notranslate"><span class="pre">script/run_auto_parallel_train.sh</span></code>. Run the command <code class="docutils literal notranslate"><span class="pre">bash</span> <span class="pre">run_auto_parallel_train.sh</span> <span class="pre">1</span> <span class="pre">1</span> <span class="pre">DATASET</span> <span class="pre">RANK_TABLE_FILE</span></code>,
where the first <code class="docutils literal notranslate"><span class="pre">1</span></code> is the number of accelerators, the second <code class="docutils literal notranslate"><span class="pre">1</span></code> is the number of epochs, <code class="docutils literal notranslate"><span class="pre">DATASET</span></code> is the path of dataset,
and <code class="docutils literal notranslate"><span class="pre">RANK_TABLE_FILE</span></code> is the path of the above <code class="docutils literal notranslate"><span class="pre">rank_table_1p_0.json</span></code> file.</p>
<p>The running log is in the directory of <code class="docutils literal notranslate"><span class="pre">device_0</span></code>, where <code class="docutils literal notranslate"><span class="pre">loss.log</span></code> contains every loss value of every step in the epoch. Here is an example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">epoch</span><span class="p">:</span> <span class="mi">1</span> <span class="n">step</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">wide_loss</span> <span class="ow">is</span> <span class="mf">0.6873926</span><span class="p">,</span> <span class="n">deep_loss</span> <span class="ow">is</span> <span class="mf">0.8878349</span>
<span class="n">epoch</span><span class="p">:</span> <span class="mi">1</span> <span class="n">step</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">wide_loss</span> <span class="ow">is</span> <span class="mf">0.6442529</span><span class="p">,</span> <span class="n">deep_loss</span> <span class="ow">is</span> <span class="mf">0.8342661</span>
<span class="n">epoch</span><span class="p">:</span> <span class="mi">1</span> <span class="n">step</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">wide_loss</span> <span class="ow">is</span> <span class="mf">0.6227323</span><span class="p">,</span> <span class="n">deep_loss</span> <span class="ow">is</span> <span class="mf">0.80273706</span>
<span class="n">epoch</span><span class="p">:</span> <span class="mi">1</span> <span class="n">step</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">wide_loss</span> <span class="ow">is</span> <span class="mf">0.6107221</span><span class="p">,</span> <span class="n">deep_loss</span> <span class="ow">is</span> <span class="mf">0.7813441</span>
<span class="n">epoch</span><span class="p">:</span> <span class="mi">1</span> <span class="n">step</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">wide_loss</span> <span class="ow">is</span> <span class="mf">0.5937832</span><span class="p">,</span> <span class="n">deep_loss</span> <span class="ow">is</span> <span class="mf">0.75526017</span>
<span class="n">epoch</span><span class="p">:</span> <span class="mi">1</span> <span class="n">step</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">wide_loss</span> <span class="ow">is</span> <span class="mf">0.5875453</span><span class="p">,</span> <span class="n">deep_loss</span> <span class="ow">is</span> <span class="mf">0.74038756</span>
<span class="n">epoch</span><span class="p">:</span> <span class="mi">1</span> <span class="n">step</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="n">wide_loss</span> <span class="ow">is</span> <span class="mf">0.5798845</span><span class="p">,</span> <span class="n">deep_loss</span> <span class="ow">is</span> <span class="mf">0.7245408</span>
<span class="n">epoch</span><span class="p">:</span> <span class="mi">1</span> <span class="n">step</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="n">wide_loss</span> <span class="ow">is</span> <span class="mf">0.57553077</span><span class="p">,</span> <span class="n">deep_loss</span> <span class="ow">is</span> <span class="mf">0.7123517</span>
<span class="n">epoch</span><span class="p">:</span> <span class="mi">1</span> <span class="n">step</span><span class="p">:</span> <span class="mi">9</span><span class="p">,</span> <span class="n">wide_loss</span> <span class="ow">is</span> <span class="mf">0.5733629</span><span class="p">,</span> <span class="n">deep_loss</span> <span class="ow">is</span> <span class="mf">0.70278376</span>
<span class="n">epoch</span><span class="p">:</span> <span class="mi">1</span> <span class="n">step</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="n">wide_loss</span> <span class="ow">is</span> <span class="mf">0.566089</span><span class="p">,</span> <span class="n">deep_loss</span> <span class="ow">is</span> <span class="mf">0.6884129</span>
<span class="o">...</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">test_deep0.log</span></code> contains the runtime log (This needs to adjust the log level to INFO, and add the <code class="docutils literal notranslate"><span class="pre">-p</span> <span class="pre">on</span></code> option when compiling MindSpore).
Search <code class="docutils literal notranslate"><span class="pre">EmbeddingLookup</span></code> in <code class="docutils literal notranslate"><span class="pre">test_deep0.log</span></code>, the following can be found:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">DEVICE</span><span class="p">(</span><span class="mi">109904</span><span class="p">,</span><span class="n">python3</span><span class="mf">.7</span><span class="p">):</span><span class="mi">2020</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">27</span><span class="o">-</span><span class="mi">12</span><span class="p">:</span><span class="mi">42</span><span class="p">:</span><span class="mf">34.928.275</span> <span class="p">[</span><span class="n">mindspore</span><span class="o">/</span><span class="n">ccsrc</span><span class="o">/</span><span class="n">device</span><span class="o">/</span><span class="n">cpu</span><span class="o">/</span><span class="n">cpu_kernel_runtime</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">324</span><span class="p">]</span> <span class="n">Run</span><span class="p">]</span> <span class="n">cpu</span> <span class="n">kernel</span><span class="p">:</span> <span class="n">Default</span><span class="o">/</span><span class="n">network</span><span class="o">-</span><span class="n">VirtualDatasetCellTriple</span><span class="o">/</span><span class="n">_backbone</span><span class="o">-</span><span class="n">NetWithLossClass</span><span class="o">/</span><span class="n">network</span><span class="o">-</span><span class="n">WideDeepModel</span><span class="o">/</span><span class="n">EmbeddingLookup</span><span class="o">-</span><span class="n">op297</span> <span class="n">costs</span> <span class="mi">3066</span> <span class="n">us</span><span class="o">.</span>
<span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">DEVICE</span><span class="p">(</span><span class="mi">109904</span><span class="p">,</span><span class="n">python3</span><span class="mf">.7</span><span class="p">):</span><span class="mi">2020</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">27</span><span class="o">-</span><span class="mi">12</span><span class="p">:</span><span class="mi">42</span><span class="p">:</span><span class="mf">34.943.896</span> <span class="p">[</span><span class="n">mindspore</span><span class="o">/</span><span class="n">ccsrc</span><span class="o">/</span><span class="n">device</span><span class="o">/</span><span class="n">cpu</span><span class="o">/</span><span class="n">cpu_kernel_runtime</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">324</span><span class="p">]</span> <span class="n">Run</span><span class="p">]</span> <span class="n">cpu</span> <span class="n">kernel</span><span class="p">:</span> <span class="n">Default</span><span class="o">/</span><span class="n">network</span><span class="o">-</span><span class="n">VirtualDatasetCellTriple</span><span class="o">/</span><span class="n">_backbone</span><span class="o">-</span><span class="n">NetWithLossClass</span><span class="o">/</span><span class="n">network</span><span class="o">-</span><span class="n">WideDeepModel</span><span class="o">/</span><span class="n">EmbeddingLookup</span><span class="o">-</span><span class="n">op298</span> <span class="n">costs</span> <span class="mi">15521</span> <span class="n">us</span><span class="o">.</span>
</pre></div>
</div>
<p>showing the running time of <code class="docutils literal notranslate"><span class="pre">EmbeddingLookup</span></code> on the host.</p>
<p>Search <code class="docutils literal notranslate"><span class="pre">FusedSparseFtrl</span></code> and <code class="docutils literal notranslate"><span class="pre">FusedSparseLazyAdam</span></code> in <code class="docutils literal notranslate"><span class="pre">test_deep0.log</span></code>, the following can be found:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">DEVICE</span><span class="p">(</span><span class="mi">109904</span><span class="p">,</span><span class="n">python3</span><span class="mf">.7</span><span class="p">):</span><span class="mi">2020</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">27</span><span class="o">-</span><span class="mi">12</span><span class="p">:</span><span class="mi">42</span><span class="p">:</span><span class="mf">35.422.963</span> <span class="p">[</span><span class="n">mindspore</span><span class="o">/</span><span class="n">ccsrc</span><span class="o">/</span><span class="n">device</span><span class="o">/</span><span class="n">cpu</span><span class="o">/</span><span class="n">cpu_kernel_runtime</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">324</span><span class="p">]</span> <span class="n">Run</span><span class="p">]</span> <span class="n">cpu</span> <span class="n">kernel</span><span class="p">:</span> <span class="n">Default</span><span class="o">/</span><span class="n">optimizer_w</span><span class="o">-</span><span class="n">FTRL</span><span class="o">/</span><span class="n">FusedSparseFtrl</span><span class="o">-</span><span class="n">op299</span> <span class="n">costs</span> <span class="mi">54492</span> <span class="n">us</span><span class="o">.</span>
<span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">DEVICE</span><span class="p">(</span><span class="mi">109904</span><span class="p">,</span><span class="n">python3</span><span class="mf">.7</span><span class="p">):</span><span class="mi">2020</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">27</span><span class="o">-</span><span class="mi">12</span><span class="p">:</span><span class="mi">42</span><span class="p">:</span><span class="mf">35.565.953</span> <span class="p">[</span><span class="n">mindspore</span><span class="o">/</span><span class="n">ccsrc</span><span class="o">/</span><span class="n">device</span><span class="o">/</span><span class="n">cpu</span><span class="o">/</span><span class="n">cpu_kernel_runtime</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">324</span><span class="p">]</span> <span class="n">Run</span><span class="p">]</span> <span class="n">cpu</span> <span class="n">kernel</span><span class="p">:</span> <span class="n">Default</span><span class="o">/</span><span class="n">optimizer_d</span><span class="o">-</span><span class="n">LazyAdam</span><span class="o">/</span><span class="n">FusedSparseLazyAdam</span><span class="o">-</span><span class="n">op300</span> <span class="n">costs</span> <span class="mi">142865</span> <span class="n">us</span><span class="o">.</span>
</pre></div>
</div>
<p>showing the running time of two optimizers on the host.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="distributed_training_ascend.html" class="btn btn-neutral float-left" title="Parallel Distributed Training (Ascend)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="checkpoint_for_hybrid_parallel.html" class="btn btn-neutral float-right" title="Saving and Loading Model Parameters in the Hybrid Parallel Scenario" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>