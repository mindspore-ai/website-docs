<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Inference on the Ascend 310 AI processor &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Inference on a GPU" href="multi_platform_inference_gpu.html" />
    <link rel="prev" title="Inference on the Ascend 910 AI processor" href="multi_platform_inference_ascend_910.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Inference Model</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Multi-Platform Inference Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_ascend_910.html">Inference on the Ascend 910 AI processor</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Inference on the Ascend 310 AI processor</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#inference-using-an-onnx-or-air-file">Inference Using an ONNX or AIR File</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_gpu.html">Inference on a GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_cpu.html">Inference on a CPU</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/en">On-Device Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference Service</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="serving.html">MindSpore-based Inference Service Deployment</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Inference on the Ascend 310 AI processor</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/multi_platform_inference_ascend_310.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="inference-on-the-ascend-310-ai-processor">
<h1>Inference on the Ascend 310 AI processor<a class="headerlink" href="#inference-on-the-ascend-310-ai-processor" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">Inference</span> <span class="pre">Application</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.0/tutorials/inference/source_en/multi_platform_inference_ascend_310.md" target="_blank"><img src="./_static/logo_source.png"></a></p>
<section id="inference-using-an-onnx-or-air-file">
<h2>Inference Using an ONNX or AIR File<a class="headerlink" href="#inference-using-an-onnx-or-air-file" title="Permalink to this headline"></a></h2>
<p>The Ascend 310 AI processor is equipped with the ACL framework and supports the OM format which needs to be converted from the model in ONNX or AIR format. For inference on the Ascend 310 AI processor, perform the following steps:</p>
<ol class="arabic simple">
<li><p>Generate a model in ONNX or AIR format on the training platform. For details, see <a class="reference external" href="https://www.mindspore.cn/tutorial/training/en/r1.0/use/save_model.html#export-air-model">Export AIR Model</a> and <a class="reference external" href="https://www.mindspore.cn/tutorial/training/en/r1.0/use/save_model.html#export-onnx-model">Export ONNX Model</a>.</p></li>
<li><p>Convert the ONNX or AIR model file into an OM model file and perform inference.</p>
<ul class="simple">
<li><p>For performing inference in the cloud environment (ModelArt), see the <a class="reference external" href="https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_0026.html">Ascend 910 training and Ascend 310 inference samples</a>.</p></li>
<li><p>For details about the local bare-metal environment where the Ascend 310 AI processor is deployed in local (compared with the cloud environment), see the document of the Ascend 310 AI processor software package.</p></li>
</ul>
</li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="multi_platform_inference_ascend_910.html" class="btn btn-neutral float-left" title="Inference on the Ascend 910 AI processor" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="multi_platform_inference_gpu.html" class="btn btn-neutral float-right" title="Inference on a GPU" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>