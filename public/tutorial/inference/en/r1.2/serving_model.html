<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Servable Provided Through Model Configuration &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Multi-hop Knowledge Reasoning Question-answering Model TPRR" href="nlp_tprr.html" />
    <link rel="prev" title="RESTful-based MindSpore Serving Access" href="serving_restful.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Inference Model</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_ascend_910.html">Inference on the Ascend 910 AI processor</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_ascend_310.html">Inference on Ascend 310</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_gpu.html">Inference on a GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_cpu.html">Inference on a CPU</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/docs/en?master">On-Device Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference Service</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="serving_example.html">MindSpore Serving-based Inference Service Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_distributed_example.html">MindSpore Serving-based Distributed Inference Service Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_grpc.html">gRPC-based MindSpore Serving Access</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_restful.html">RESTful-based MindSpore Serving Access</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Servable Provided Through Model Configuration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#concepts">Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#preprocessing-and-post-processing">Preprocessing and Post-processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#methods">Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="#instances">Instances</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#model-configuration">Model Configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#preprocessing-and-post-processing-definition">Preprocessing and Post-processing Definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-declaration">Model Declaration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#method-definition">Method Definition</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application Practice</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="nlp_tprr.html">Multi-hop Knowledge Reasoning Question-answering Model TPRR</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Servable Provided Through Model Configuration</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/serving_model.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="servable-provided-through-model-configuration">
<h1>Servable Provided Through Model Configuration<a class="headerlink" href="#servable-provided-through-model-configuration" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">Serving</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/inference/source_en/serving_model.md"><img alt="View Source On Gitee" src="_images/logo_source.png" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>MindSpore Serving supports only the Ascend 310 and Ascend 910 environments.</p>
<p>MindSpore Serving Servable provides the inference services of the following types: One inference service comes from a single model, and the other one comes from a combination of multiple models (this is being developed). Models need to be configured to provide the Serving inference service.</p>
<p>The following describes how to configure a single model to provide Servable. All Servable configurations are for single-model Servables and the Serving client is referred to as the client.</p>
<p>ResNet-50 is used as an example to describe how to configure a model to provide Servable. For details about the sample code, see the <a class="reference external" href="https://gitee.com/mindspore/serving/tree/r1.2/example/resnet/">ResNet-50 Example</a>.</p>
</section>
<section id="concepts">
<h2>Concepts<a class="headerlink" href="#concepts" title="Permalink to this headline"></a></h2>
<section id="preprocessing-and-post-processing">
<h3>Preprocessing and Post-processing<a class="headerlink" href="#preprocessing-and-post-processing" title="Permalink to this headline"></a></h3>
<p>A model provides the inference capability. Its input and output have fixed data type, data length, and shape.</p>
<p>If data sent from the client cannot directly meet model input requirements, the data needs to be preprocessed and converted into the qualified data.
If the model output cannot be not directly provided for the client, post-processing is required to convert the output into the required output data.</p>
<p>The following shows the <code class="docutils literal notranslate"><span class="pre">resnet50</span></code> Servable data flowchart. The image data is transmitted from the client to the Serving through a network. The Serving performs preprocessing, inference, and post-processing, and returns the result to the client.</p>
<p><img alt="image" src="_images/resnet_example.png" /></p>
<p>For a ResNet-50 inference model, the data sent by the client is images in JPG or PNG format, and the image classification is expected to be returned. The input of a ResNet model is the tensor generated by operations such as image <code class="docutils literal notranslate"><span class="pre">Decode</span></code>, <code class="docutils literal notranslate"><span class="pre">Resize</span></code>, and <code class="docutils literal notranslate"><span class="pre">Normalize</span></code>. The output is the score tensor of each category. The image needs to be converted into a tensor that meets the model input requirements during preprocessing. <strong>Name of the top 1 category</strong> or <strong>Names of the top 5 categories and their scores</strong> are returned after post-processing.</p>
<p>The provided preprocessing may vary according to the composition, structure, or type of data input from the client in different scenarios. The provided post-processing may also vary according to the model output requirements. For example, in the preceding <code class="docutils literal notranslate"><span class="pre">resnet50</span></code> Servable, two post-processing methods are provided for the following two scenarios: <strong>Name of the top 1 category</strong> and <strong>Names of the top 5 categories and their scores</strong>.</p>
</section>
<section id="methods">
<h3>Methods<a class="headerlink" href="#methods" title="Permalink to this headline"></a></h3>
<p>The preceding <code class="docutils literal notranslate"><span class="pre">resnet</span></code> Servable provides the <code class="docutils literal notranslate"><span class="pre">classify_top5</span></code> and <code class="docutils literal notranslate"><span class="pre">classify_top1</span></code> methods. The input of <code class="docutils literal notranslate"><span class="pre">classify_top5</span></code> is <code class="docutils literal notranslate"><span class="pre">image</span></code>, and the output is <code class="docutils literal notranslate"><span class="pre">label</span></code> and <code class="docutils literal notranslate"><span class="pre">score</span></code>. The top 5 category names and scores are returned. The preprocessing of <code class="docutils literal notranslate"><span class="pre">classify_top1</span></code> is the same as that of <code class="docutils literal notranslate"><span class="pre">classify_top5</span></code>, but the post-processing is different. The input is <code class="docutils literal notranslate"><span class="pre">image</span></code>, and the output is <code class="docutils literal notranslate"><span class="pre">label</span></code>. The top 1 category name is returned.</p>
<p>One Servable can provide one or more methods. The Servable name and the method name are marked with a service provided by the Serving. Each method preprocesses the data provided by the client, performs model inference and optional post-processing on the model inference result, and returns the required result to the client.</p>
<p>A Servable is used to:</p>
<ul class="simple">
<li><p>Specify optional preprocessing and post-processing.</p></li>
<li><p>Define a data flow between method input, preprocessing, model, post-processing, and method output. The former data value can be used as the latter data input. For example, the value of method output may come from the method input, preprocessing, model, or post-processing.</p></li>
<li><p>Specify a method name for the client to specify a method to be used.</p></li>
<li><p>Specify the input and output names of a method for the client to specify the input and obtain the output.</p></li>
</ul>
</section>
<section id="instances">
<h3>Instances<a class="headerlink" href="#instances" title="Permalink to this headline"></a></h3>
<p>Each request includes one or more independent instances which do not affect each other’s result. For example, a category is returned for an image, and three categories are returned for three independent images.</p>
</section>
</section>
<section id="model-configuration">
<h2>Model Configuration<a class="headerlink" href="#model-configuration" title="Permalink to this headline"></a></h2>
<p>Take the ResNet-50 model as an example. The model configuration file directory is as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>resnet50
├──<span class="w"> </span><span class="m">1</span>
│<span class="w">   </span>└──<span class="w"> </span>resnet_classify.mindir
├──<span class="w"> </span><span class="m">2</span>
│<span class="w">   </span>└──<span class="w"> </span>resnet_classify.mindir
└──<span class="w"> </span>servable_config.py
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">resnet50</span></code>: a directory, which is named after the Servable name.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">servable_config.py</span></code>: configures Servable, including preprocessing and post-processing definitions, model declaration, and method definition.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">1</span></code> and <code class="docutils literal notranslate"><span class="pre">2</span></code>: directories, which indicate models of the <code class="docutils literal notranslate"><span class="pre">1</span></code> and <code class="docutils literal notranslate"><span class="pre">2</span></code> versions. The model version is a positive integer starting from <code class="docutils literal notranslate"><span class="pre">1</span></code>. A larger number indicates a later version.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">resnet_classify.mindir</span></code>: a model file. When the Servable is started, the model file of the corresponding version is loaded.</p></li>
</ul>
<section id="preprocessing-and-post-processing-definition">
<h3>Preprocessing and Post-processing Definition<a class="headerlink" href="#preprocessing-and-post-processing-definition" title="Permalink to this headline"></a></h3>
<p>The following is an example to define preprocessing and post-processing:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.transforms.c_transforms</span> <span class="k">as</span> <span class="nn">TC</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision.c_transforms</span> <span class="k">as</span> <span class="nn">VC</span>

<span class="k">def</span> <span class="nf">preprocess_eager</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Define preprocess, input is image numpy, return preprocess result.</span>
<span class="sd">    Return type can be numpy, str, bytes, int, float, or bool.</span>
<span class="sd">    Use MindData Eager, this image processing can also use other image processing library, likes numpy, PIL or cv2 etc.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">image_size</span> <span class="o">=</span> <span class="mi">224</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.485</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.456</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.406</span> <span class="o">*</span> <span class="mi">255</span><span class="p">]</span>
    <span class="n">std</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.229</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.224</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.225</span> <span class="o">*</span> <span class="mi">255</span><span class="p">]</span>

    <span class="n">decode</span> <span class="o">=</span> <span class="n">VC</span><span class="o">.</span><span class="n">Decode</span><span class="p">()</span>
    <span class="n">resize</span> <span class="o">=</span> <span class="n">VC</span><span class="o">.</span><span class="n">Resize</span><span class="p">([</span><span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">])</span>
    <span class="n">normalize</span> <span class="o">=</span> <span class="n">VC</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">)</span>
    <span class="n">hwc2chw</span> <span class="o">=</span> <span class="n">VC</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>

    <span class="n">image</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">hwc2chw</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">image</span>

<span class="k">def</span> <span class="nf">postprocess_top1</span><span class="p">(</span><span class="n">score</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Define postprocess. This example has one input and one output.</span>
<span class="sd">    The input is the numpy tensor of the score, and the output is the label str of top one.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">idx_2_label</span><span class="p">[</span><span class="n">max_idx</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">postprocess_top5</span><span class="p">(</span><span class="n">score</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Define postprocess. This example has one input and two outputs.</span>
<span class="sd">    The input is the numpy tensor of the score. The first output is the str joined by labels of top five, and the second output is the score tensor of the top five.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">score</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="mi">5</span><span class="p">]</span>  <span class="c1"># top 5</span>
    <span class="n">ret_label</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx_2_label</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">]</span>
    <span class="n">ret_score</span> <span class="o">=</span> <span class="n">score</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="k">return</span> <span class="s2">&quot;;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ret_label</span><span class="p">),</span> <span class="n">ret_score</span>
</pre></div>
</div>
<p>The preprocessing and post-processing are defined in the same format. The input parameters are the input data of each instance. If the input data is a text, the input parameter is a str object. If the input data is of other types, such as Tensor, Scalar number, Boolean, and Bytes, the input parameter is a <strong>numpy object</strong>. The instance processing result is returned through <code class="docutils literal notranslate"><span class="pre">return</span></code>, which can be <strong>numpy</strong>, or a single data object or a tuple consisting of <strong>bool, int, float, str, or bytes of Python</strong>.</p>
<p>The input sources and output usage of preprocessing and post-processing are determined by the <a class="reference external" href="https://www.mindspore.cn/tutorial/inference/en/r1.2/serving_model.html#id9">Method Definition</a>.</p>
</section>
<section id="model-declaration">
<h3>Model Declaration<a class="headerlink" href="#model-declaration" title="Permalink to this headline"></a></h3>
<p>The sample code for declaring the <code class="docutils literal notranslate"><span class="pre">resnet50</span></code> Servable model is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_serving.worker</span> <span class="kn">import</span> <span class="n">register</span>
<span class="n">register</span><span class="o">.</span><span class="n">declare_servable</span><span class="p">(</span><span class="n">servable_file</span><span class="o">=</span><span class="s2">&quot;resnet50_1b_imagenet.mindir&quot;</span><span class="p">,</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR&quot;</span><span class="p">,</span> <span class="n">with_batch_dim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>The input parameter <code class="docutils literal notranslate"><span class="pre">servable_file</span></code> of <code class="docutils literal notranslate"><span class="pre">declare_servable</span></code> indicates the model file name. <code class="docutils literal notranslate"><span class="pre">model_format</span></code> indicates the model type. Currently, the Ascend 310 environment supports both <code class="docutils literal notranslate"><span class="pre">OM</span></code> and <code class="docutils literal notranslate"><span class="pre">MindIR</span></code> model types. The Ascend 910 environment supports only the <code class="docutils literal notranslate"><span class="pre">MindIR</span></code> model type.</p>
<p>If the 1D model input and output is not the <code class="docutils literal notranslate"><span class="pre">batch</span></code> dimension, you need to change the value of <code class="docutils literal notranslate"><span class="pre">with_batch_dim</span></code> from the default value <code class="docutils literal notranslate"><span class="pre">True</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<p>Set <code class="docutils literal notranslate"><span class="pre">with_batch_dim</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code> if models contain the <code class="docutils literal notranslate"><span class="pre">batch</span></code> dimension, such as image and text processing models. Assume that <code class="docutils literal notranslate"><span class="pre">batch_size=2</span></code> and the current request has three instances of images which will be split into two batches for model inference. For the first batch, two images are inferred to return two results. For the second batch, the remaining image is copied and inferred to return one result. Finally, three results are returned.</p>
<p><img alt="image" src="_images/resnet_with_batch.png" /></p>
<p>Set <code class="docutils literal notranslate"><span class="pre">with_batch_dim</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code> if models do not involve or consider the <code class="docutils literal notranslate"><span class="pre">batch</span></code> dimension. For example, the input and output are matrix multiplication models of 2D tensors. Each instance of the request performs an independent inference task.</p>
<p><img alt="image" src="_images/matmul_without_batch.png" /></p>
<p>If a model has one data input with <code class="docutils literal notranslate"><span class="pre">batch</span></code> dimension information and one model configuration information input without <code class="docutils literal notranslate"><span class="pre">batch</span></code> dimension information, you need to set <code class="docutils literal notranslate"><span class="pre">with_batch_dim</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code> and set an extra parameter <code class="docutils literal notranslate"><span class="pre">without_batch_dim_inputs</span></code> to specify the input information that does not contain the <code class="docutils literal notranslate"><span class="pre">batch</span></code> dimension information.
For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_serving.worker</span> <span class="kn">import</span> <span class="n">register</span>
<span class="c1"># Input1 indicates the input shape information of the model, without the batch dimension information.</span>
<span class="c1"># input0: [N,3,416,416], input1: [2]</span>
<span class="n">register</span><span class="o">.</span><span class="n">declare_servable</span><span class="p">(</span><span class="n">servable_file</span><span class="o">=</span><span class="s2">&quot;yolov3_darknet53.mindir&quot;</span><span class="p">,</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR&quot;</span><span class="p">,</span>
                          <span class="n">with_batch_dim</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">without_batch_dim_inputs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>For distributed model, the only difference compared with non-distributed single model configuration is declaration, you need to use <code class="docutils literal notranslate"><span class="pre">declare_distributed_servable</span></code> method, <code class="docutils literal notranslate"><span class="pre">rank_size</span></code> is the number of devices used in the model, <code class="docutils literal notranslate"><span class="pre">stage_size</span></code> is the number of stages in the pipeline.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_serving.worker</span> <span class="kn">import</span> <span class="n">distributed</span>
<span class="kn">from</span> <span class="nn">mindspore_serving.worker</span> <span class="kn">import</span> <span class="n">register</span>

<span class="n">distributed</span><span class="o">.</span><span class="n">declare_distributed_servable</span><span class="p">(</span><span class="n">rank_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stage_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">with_batch_dim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="method-definition">
<h3>Method Definition<a class="headerlink" href="#method-definition" title="Permalink to this headline"></a></h3>
<p>An example of the method definition is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_serving.worker</span> <span class="kn">import</span> <span class="n">register</span>

<span class="nd">@register</span><span class="o">.</span><span class="n">register_method</span><span class="p">(</span><span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">classify_top1</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Define method `classify_top1` for servable `resnet50`.</span>
<span class="sd">     The input is `image` and the output is `label`.&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">call_preprocess</span><span class="p">(</span><span class="n">preprocess_eager</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">call_servable</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">call_postprocess</span><span class="p">(</span><span class="n">postprocess_top1</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="nd">@register</span><span class="o">.</span><span class="n">register_method</span><span class="p">(</span><span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="s2">&quot;score&quot;</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">classify_top5</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Define method `classify_top5` for servable `resnet50`.</span>
<span class="sd">     The input is `image` and the output is `label` and `score`. &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">call_preprocess</span><span class="p">(</span><span class="n">preprocess_eager</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">call_servable</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">label</span><span class="p">,</span> <span class="n">score</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">call_postprocess</span><span class="p">(</span><span class="n">postprocess_top5</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">label</span><span class="p">,</span> <span class="n">score</span>
</pre></div>
</div>
<p>The preceding code defines the <code class="docutils literal notranslate"><span class="pre">classify_top1</span></code> and <code class="docutils literal notranslate"><span class="pre">classify_top5</span></code> methods in Servable <code class="docutils literal notranslate"><span class="pre">resnet50</span></code>. The input parameter of the <code class="docutils literal notranslate"><span class="pre">classify_top1</span></code> method is <code class="docutils literal notranslate"><span class="pre">image</span></code> and the output parameter is <code class="docutils literal notranslate"><span class="pre">label</span></code>. The input parameter of the <code class="docutils literal notranslate"><span class="pre">classify_top5</span></code> method is <code class="docutils literal notranslate"><span class="pre">image</span></code> and the output parameters are <code class="docutils literal notranslate"><span class="pre">label</span></code> and <code class="docutils literal notranslate"><span class="pre">score</span></code>. That is, the input parameters of the Servable method are specified by the input parameters of the Python method, and the output parameters of the Servable method are specified by <code class="docutils literal notranslate"><span class="pre">output_names</span></code> of <code class="docutils literal notranslate"><span class="pre">register_method</span></code>.</p>
<p>In the preceding method definition:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">call_preprocess</span></code> specifies the preprocessing used and its input.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">call_servable</span></code> specifies the input of model inference.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">call_postprocess</span></code> specifies the post-processing and its input used.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">return</span></code> specifies the data returned by the method and corresponds to the <code class="docutils literal notranslate"><span class="pre">output_names</span></code> parameter of <code class="docutils literal notranslate"><span class="pre">register_method</span></code>.</p></li>
</ul>
<p>The method definition cannot contain branch structures such as if, for, and while. Preprocessing and post-processing are optional and cannot be repeated. Model inference is mandatory, and the sequence cannot be disordered.</p>
<p>When a user uses a service provided by a Servable method on the client, the user needs to specify the input value based on the input parameter name and identify the output value based on the output parameter name. For example, the method <code class="docutils literal notranslate"><span class="pre">classify_top5</span></code> accessed by the client is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_serving.client</span> <span class="kn">import</span> <span class="n">Client</span>

<span class="k">def</span> <span class="nf">read_images</span><span class="p">():</span>
    <span class="c1"># read image file and return</span>

<span class="k">def</span> <span class="nf">run_classify_top5</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Client for servable resnet50 and method classify_top5&quot;&quot;&quot;</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s2">&quot;localhost&quot;</span><span class="p">,</span> <span class="mi">5500</span><span class="p">,</span> <span class="s2">&quot;resnet50&quot;</span><span class="p">,</span> <span class="s2">&quot;classify_top5&quot;</span><span class="p">)</span>
    <span class="n">instances</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">read_images</span><span class="p">():</span>  <span class="c1"># read multi image</span>
        <span class="n">instances</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;image&quot;</span><span class="p">:</span> <span class="n">image</span><span class="p">})</span>  <span class="c1"># input `image`</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">instances</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">result_item</span> <span class="ow">in</span> <span class="n">result</span><span class="p">:</span>  <span class="c1"># result for every image</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">result_item</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span>  <span class="c1"># result `label`</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">result_item</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span>  <span class="c1"># result `score`</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;label result&quot;</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;score result&quot;</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">run_classify_top5</span><span class="p">()</span>
</pre></div>
</div>
<p>In addition, one request may include multiple instances, and multiple requests in queue for processing also have multiple instances. If multiple instances need to be processed concurrently by using, for example, multiple threads in customized preprocessing or post-processing (for example, the MindData concurrency is used to process multiple input images during preprocessing), MindSpore Serving provides <code class="docutils literal notranslate"><span class="pre">call_preprocess_pipeline</span></code> and <code class="docutils literal notranslate"><span class="pre">call_postprocess_pipeline</span></code> for registering such preprocessing and post-processing. For details, see <a class="reference external" href="https://gitee.com/mindspore/serving/blob/r1.2/example/resnet/resnet50/servable_config.py">ResNet-50 sample model configuration</a>.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="serving_restful.html" class="btn btn-neutral float-left" title="RESTful-based MindSpore Serving Access" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="nlp_tprr.html" class="btn btn-neutral float-right" title="Multi-hop Knowledge Reasoning Question-answering Model TPRR" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>