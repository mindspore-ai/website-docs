<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Implementing an Image Classification Application &mdash; MindSpore Lite master documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Building MindSpore Lite" href="../use/build.html" />
    <link rel="prev" title="Using MindSpore on Mobile and IoT" href="../index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Implementing an Image Classification Application</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#selecting-a-model">Selecting a Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#converting-a-model">Converting a Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#deploying-an-application">Deploying an Application</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#running-dependencies">Running Dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="#building-and-running">Building and Running</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#detailed-description-of-the-sample-program">Detailed Description of the Sample Program</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sample-program-structure">Sample Program Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configuring-mindspore-lite-dependencies">Configuring MindSpore Lite Dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloading-and-deploying-a-model-file">Downloading and Deploying a Model File</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compiling-on-device-inference-code">Compiling On-Device Inference Code</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/build.html">Building MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/convert_model.html">Converting Into The MindSpore Lite Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/evaluating_the_model.html">Evaluating MindSpore Lite Model (optional)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preprocessing.html">Data Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/runtime.html">Using Runtime for Model Inference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Implementing an Image Classification Application</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/quick_start/quick_start.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="implementing-an-image-classification-application">
<h1>Implementing an Image Classification Application<a class="headerlink" href="#implementing-an-image-classification-application" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.0/tutorials/lite/source_en/quick_start/quick_start.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>It is recommended that you start from the image classification demo on the Android device to understand how to build the MindSpore Lite application project, configure dependencies, and use related APIs.</p>
<p>This tutorial demonstrates the on-device deployment process based on the image classification sample program on the Android device provided by the MindSpore team.</p>
<ol class="arabic simple">
<li><p>Select an image classification model.</p></li>
<li><p>Convert the model into a MindSpore Lite model.</p></li>
<li><p>Use the MindSpore Lite inference model on the device. The following describes how to use the MindSpore Lite C++ APIs (Android JNIs) and MindSpore Lite image classification models to perform on-device inference, classify the content captured by a device camera, and display the most possible classification result on the application’s image preview screen.</p></li>
</ol>
<blockquote>
<div><p>Click to find <a class="reference external" href="https://download.mindspore.cn/model_zoo/official/lite/mobilenetv2_openimage_lite">Android image classification models</a> and <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.0/model_zoo/official/lite/image_classification">sample code</a>.</p>
</div></blockquote>
</section>
<section id="selecting-a-model">
<h2>Selecting a Model<a class="headerlink" href="#selecting-a-model" title="Permalink to this headline"></a></h2>
<p>The MindSpore team provides a series of preset device models that you can use in your application.<br />
Click <a class="reference external" href="https://download.mindspore.cn/model_zoo/official/lite/mobilenetv2_openimage_lite/mobilenetv2.ms">here</a> to download image classification models in MindSpore ModelZoo.
In addition, you can use the preset model to perform migration learning to implement your image classification tasks.</p>
</section>
<section id="converting-a-model">
<h2>Converting a Model<a class="headerlink" href="#converting-a-model" title="Permalink to this headline"></a></h2>
<p>After you retrain a model provided by MindSpore, export the model in the <a class="reference external" href="https://www.mindspore.cn/tutorial/training/en/r1.0/use/save_model.html#export-mindir-model">.mindir format</a>. Use the MindSpore Lite <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.0/use/converter_tool.html">model conversion tool</a> to convert the .mindir model to a .ms model.</p>
<p>Take the mobilenetv2 model as an example. Execute the following script to convert a model into a MindSpore Lite model for on-device inference.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite<span class="w"> </span>--fmk<span class="o">=</span>MINDIR<span class="w"> </span>--modelFile<span class="o">=</span>mobilenetv2.mindir<span class="w"> </span>--outputFile<span class="o">=</span>mobilenetv2.ms
</pre></div>
</div>
</section>
<section id="deploying-an-application">
<h2>Deploying an Application<a class="headerlink" href="#deploying-an-application" title="Permalink to this headline"></a></h2>
<p>The following section describes how to build and execute an on-device image classification task on MindSpore Lite.</p>
<section id="running-dependencies">
<h3>Running Dependencies<a class="headerlink" href="#running-dependencies" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Android Studio 3.2 or later (Android 4.0 or later is recommended.)</p></li>
<li><p>Native development kit (NDK) 21.3</p></li>
<li><p><a class="reference external" href="https://cmake.org/download">CMake</a> 3.10.2</p></li>
<li><p>Android software development kit (SDK) 26 or later</p></li>
<li><p>JDK 1.8 or later</p></li>
</ul>
</section>
<section id="building-and-running">
<h3>Building and Running<a class="headerlink" href="#building-and-running" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>Load the sample source code to Android Studio and install the corresponding SDK. (After the SDK version is specified, Android Studio automatically installs the SDK.)</p>
<p><img alt="start_home" src="../_images/lite_quick_start_home.png" /></p>
<p>Start Android Studio, click <code class="docutils literal notranslate"><span class="pre">File</span> <span class="pre">&gt;</span> <span class="pre">Settings</span> <span class="pre">&gt;</span> <span class="pre">System</span> <span class="pre">Settings</span> <span class="pre">&gt;</span> <span class="pre">Android</span> <span class="pre">SDK</span></code>, and select the corresponding SDK. As shown in the following figure, select an SDK and click <code class="docutils literal notranslate"><span class="pre">OK</span></code>. Android Studio automatically installs the SDK.</p>
<p><img alt="start_sdk" src="../_images/lite_quick_start_sdk.png" /></p>
<p>(Optional) If an NDK version issue occurs during the installation, manually download the corresponding <a class="reference external" href="https://developer.android.com/ndk/downloads">NDK version</a> (the version used in the sample code is 21.3). Specify the NDK location in <code class="docutils literal notranslate"><span class="pre">Android</span> <span class="pre">NDK</span> <span class="pre">location</span></code> of <code class="docutils literal notranslate"><span class="pre">Project</span> <span class="pre">Structure</span></code>.</p>
<p><img alt="project_structure" src="../_images/lite_quick_start_project_structure.png" /></p>
</li>
<li><p>Connect to an Android device and runs the image classification application.</p>
<p>Connect to the Android device through a USB cable for debugging. Click <code class="docutils literal notranslate"><span class="pre">Run</span> <span class="pre">'app'</span></code> to run the sample project on your device.</p>
<p><img alt="run_app" src="../_images/lite_quick_start_run_app.PNG" /></p>
<p>For details about how to connect the Android Studio to a device for debugging, see <a class="reference external" href="https://developer.android.com/studio/run/device">https://developer.android.com/studio/run/device</a>.</p>
<p>The mobile phone needs to turn on “USB debugging mode” for Android Studio to recognize the phone. In general, Huawei mobile phones turn on “USB debugging mode” in Settings -&gt; System and Update -&gt; Developer Options -&gt; USB Debugging.</p>
</li>
<li><p>Continue the installation on the Android device. After the installation is complete, you can view the content captured by a camera and the inference result.</p>
<p><img alt="result" src="../_images/lite_quick_start_app_result.png" /></p>
</li>
</ol>
</section>
</section>
<section id="detailed-description-of-the-sample-program">
<h2>Detailed Description of the Sample Program<a class="headerlink" href="#detailed-description-of-the-sample-program" title="Permalink to this headline"></a></h2>
<p>This image classification sample program on the Android device includes a Java layer and a JNI layer. At the Java layer, the Android Camera 2 API is used to enable a camera to obtain image frames and process images. At the JNI layer, the model inference process is completed in <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.0/use/runtime.html">Runtime</a>.</p>
<blockquote>
<div><p>This following describes the JNI layer implementation of the sample program. At the Java layer, the Android Camera 2 API is used to enable a device camera and process image frames. Readers are expected to have the basic Android development knowledge.</p>
</div></blockquote>
<section id="sample-program-structure">
<h3>Sample Program Structure<a class="headerlink" href="#sample-program-structure" title="Permalink to this headline"></a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>app
│
├── src/main
│   ├── assets # resource files
|   |   └── mobilenetv2.ms # model file
│   |
│   ├── cpp # main logic encapsulation classes for model loading and prediction
|   |   |── ...
|   |   ├── mindspore_lite_1.0.0-minddata-arm64-cpu` #MindSpore Lite version
|   |   ├── MindSporeNetnative.cpp # JNI methods related to MindSpore calling
│   |   └── MindSporeNetnative.h # header file
│   |
│   ├── java # application code at the Java layer
│   │   └── com.mindspore.himindsporedemo 
│   │       ├── gallery.classify # implementation related to image processing and MindSpore JNI calling
│   │       │   └── ...
│   │       └── widget # implementation related to camera enabling and drawing
│   │           └── ...
│   │   
│   ├── res # resource files related to Android
│   └── AndroidManifest.xml # Android configuration file
│
├── CMakeList.txt # CMake compilation entry file
│
├── build.gradle # Other Android configuration file
├── download.gradle # MindSpore version download
└── ...
</pre></div>
</div>
</section>
<section id="configuring-mindspore-lite-dependencies">
<h3>Configuring MindSpore Lite Dependencies<a class="headerlink" href="#configuring-mindspore-lite-dependencies" title="Permalink to this headline"></a></h3>
<p>When MindSpore C++ APIs are called at the Android JNI layer, related library files are required. You can use MindSpore Lite <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.0/use/build.html">source code compilation</a> to generate the MindSpore Lite version. In this case, you need to use the compile command of generate with image preprocessing module.</p>
<p>In this example, the build process automatically downloads the <code class="docutils literal notranslate"><span class="pre">mindspore-lite-1.0.0-minddata-arm64-cpu</span></code> by the <code class="docutils literal notranslate"><span class="pre">app/download.gradle</span></code> file and saves in the <code class="docutils literal notranslate"><span class="pre">app/src/main/cpp</span></code> directory.</p>
<p>Note: if the automatic download fails, please manually download the relevant library files and put them in the corresponding location.</p>
<p>mindspore-lite-1.0.0-minddata-arm64-cpu.tar.gz <a class="reference external" href="https://ms-release.obs.cn-north-4.myhuaweicloud.com/1.0.0/lite/android_aarch64/mindspore-lite-1.0.0-minddata-arm64-cpu.tar.gz">Download link</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">android</span><span class="p">{</span>
    <span class="n">defaultConfig</span><span class="p">{</span>
        <span class="n">externalNativeBuild</span><span class="p">{</span>
            <span class="n">cmake</span><span class="p">{</span>
                <span class="n">arguments</span> <span class="s2">&quot;-DANDROID_STL=c++_shared&quot;</span>
            <span class="p">}</span>
        <span class="p">}</span>

        <span class="n">ndk</span><span class="p">{</span> 
            <span class="n">abiFilters</span><span class="s1">&#39;armeabi-v7a&#39;</span><span class="p">,</span> <span class="s1">&#39;arm64-v8a&#39;</span>  
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Create a link to the <code class="docutils literal notranslate"><span class="pre">.so</span></code> library file in the <code class="docutils literal notranslate"><span class="pre">app/CMakeLists.txt</span></code> file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># ============== Set MindSpore Dependencies. =============
include_directories(${CMAKE_SOURCE_DIR}/src/main/cpp)
include_directories(${CMAKE_SOURCE_DIR}/src/main/cpp/${MINDSPORELITE_VERSION}/third_party/flatbuffers/include)
include_directories(${CMAKE_SOURCE_DIR}/src/main/cpp/${MINDSPORELITE_VERSION})
include_directories(${CMAKE_SOURCE_DIR}/src/main/cpp/${MINDSPORELITE_VERSION}/include)
include_directories(${CMAKE_SOURCE_DIR}/src/main/cpp/${MINDSPORELITE_VERSION}/include/ir/dtype)
include_directories(${CMAKE_SOURCE_DIR}/src/main/cpp/${MINDSPORELITE_VERSION}/include/schema)

add_library(mindspore-lite SHARED IMPORTED )
add_library(minddata-lite SHARED IMPORTED )

set_target_properties(mindspore-lite PROPERTIES IMPORTED_LOCATION
        ${CMAKE_SOURCE_DIR}/src/main/cpp/${MINDSPORELITE_VERSION}/lib/libmindspore-lite.so)
set_target_properties(minddata-lite PROPERTIES IMPORTED_LOCATION
        ${CMAKE_SOURCE_DIR}/src/main/cpp/${MINDSPORELITE_VERSION}/lib/libminddata-lite.so)
# --------------- MindSpore Lite set End. --------------------

# Link target library.       
target_link_libraries(
    ...
     # --- mindspore ---
        minddata-lite
        mindspore-lite
    ...
)
</pre></div>
</div>
</section>
<section id="downloading-and-deploying-a-model-file">
<h3>Downloading and Deploying a Model File<a class="headerlink" href="#downloading-and-deploying-a-model-file" title="Permalink to this headline"></a></h3>
<p>In this example, the build process automatically downloads the <code class="docutils literal notranslate"><span class="pre">mobilenetv2.ms</span></code> by the <code class="docutils literal notranslate"><span class="pre">app/download.gradle</span></code> file and saves in the <code class="docutils literal notranslate"><span class="pre">app/src/main/assets</span></code> directory.</p>
<p>Note: if the automatic download fails, please manually download the relevant library files and put them in the corresponding location.</p>
<p>mobilenetv2.ms <a class="reference external" href="https://download.mindspore.cn/model_zoo/official/lite/mobilenetv2_openimage_lite/mobilenetv2.ms">mobilenetv2.ms</a></p>
</section>
<section id="compiling-on-device-inference-code">
<h3>Compiling On-Device Inference Code<a class="headerlink" href="#compiling-on-device-inference-code" title="Permalink to this headline"></a></h3>
<p>Call MindSpore Lite C++ APIs at the JNI layer to implement on-device inference.</p>
<p>The inference code process is as follows. For details about the complete code, see <code class="docutils literal notranslate"><span class="pre">src/cpp/MindSporeNetnative.cpp</span></code>.</p>
<ol class="arabic">
<li><p>Load the MindSpore Lite model file and build the context, session, and computational graph for inference.</p>
<ul>
<li><p>Load a model file. Create and configure the context for model inference.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Buffer is the model data passed in by the Java layer</span>
<span class="n">jlong</span><span class="w"> </span><span class="n">bufferLen</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">env</span><span class="o">-&gt;</span><span class="n">GetDirectBufferCapacity</span><span class="p">(</span><span class="n">buffer</span><span class="p">);</span>
<span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">modelBuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CreateLocalModelBuffer</span><span class="p">(</span><span class="n">env</span><span class="p">,</span><span class="w"> </span><span class="n">buffer</span><span class="p">);</span><span class="w">  </span>
</pre></div>
</div>
</li>
<li><p>Create a session.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="n">labelEnv</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">;</span>
<span class="n">MSNetWork</span><span class="w"> </span><span class="o">*</span><span class="n">labelNet</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">MSNetWork</span><span class="p">;</span>
<span class="o">*</span><span class="n">labelEnv</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labelNet</span><span class="p">;</span>

<span class="c1">// Create context.</span>
<span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="o">*</span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">Context</span><span class="p">;</span>
<span class="n">context</span><span class="o">-&gt;</span><span class="n">thread_num_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_thread</span><span class="p">;</span>

<span class="c1">// Create the mindspore session.</span>
<span class="n">labelNet</span><span class="o">-&gt;</span><span class="n">CreateSessionMS</span><span class="p">(</span><span class="n">modelBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">bufferLen</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;device label&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">context</span><span class="p">);</span>
<span class="k">delete</span><span class="p">(</span><span class="n">context</span><span class="p">);</span>
</pre></div>
</div>
</li>
<li><p>Load the model file and build a computational graph for inference.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">MSNetWork::CreateSessionMS</span><span class="p">(</span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">modelBuffer</span><span class="p">,</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">bufferLen</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">Context</span><span class="o">*</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="n">CreateSession</span><span class="p">(</span><span class="n">modelBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">bufferLen</span><span class="p">,</span><span class="w"> </span><span class="n">ctx</span><span class="p">);</span><span class="w">  </span>
<span class="w">    </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">session</span><span class="o">::</span><span class="n">LiteSession</span><span class="o">::</span><span class="n">CreateSession</span><span class="p">(</span><span class="n">ctx</span><span class="p">);</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">Model</span><span class="o">::</span><span class="n">Import</span><span class="p">(</span><span class="n">modelBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">bufferLen</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">CompileGraph</span><span class="p">(</span><span class="n">model</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Convert the input image into the Tensor format of the MindSpore model.</p>
<p>Convert the image data to be detected into the Tensor format of the MindSpore model.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Convert the Bitmap image passed in from the JAVA layer to Mat for OpenCV processing</span>
<span class="w"> </span><span class="n">BitmapToMat</span><span class="p">(</span><span class="n">env</span><span class="p">,</span><span class="w"> </span><span class="n">srcBitmap</span><span class="p">,</span><span class="w"> </span><span class="n">matImageSrc</span><span class="p">);</span>
<span class="c1">// Processing such as zooming the picture size.</span>
<span class="n">matImgPreprocessed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">PreProcessImageData</span><span class="p">(</span><span class="n">matImageSrc</span><span class="p">);</span><span class="w">  </span>

<span class="n">ImgDims</span><span class="w"> </span><span class="n">inputDims</span><span class="p">;</span><span class="w"> </span>
<span class="n">inputDims</span><span class="p">.</span><span class="n">channel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">matImgPreprocessed</span><span class="p">.</span><span class="n">channels</span><span class="p">();</span>
<span class="n">inputDims</span><span class="p">.</span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">matImgPreprocessed</span><span class="p">.</span><span class="n">cols</span><span class="p">;</span>
<span class="n">inputDims</span><span class="p">.</span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">matImgPreprocessed</span><span class="p">.</span><span class="n">rows</span><span class="p">;</span>
<span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">dataHWC</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="kt">float</span><span class="p">[</span><span class="n">inputDims</span><span class="p">.</span><span class="n">channel</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">inputDims</span><span class="p">.</span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">inputDims</span><span class="p">.</span><span class="n">height</span><span class="p">]</span>

<span class="c1">// Copy the image data to be detected to the dataHWC array.</span>
<span class="c1">// The dataHWC[image_size] array here is the intermediate variable of the input MindSpore model tensor.</span>
<span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">ptrTmp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">matImgPreprocessed</span><span class="p">.</span><span class="n">data</span><span class="p">);</span>
<span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">inputDims</span><span class="p">.</span><span class="n">channel</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">inputDims</span><span class="p">.</span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">inputDims</span><span class="p">.</span><span class="n">height</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">){</span>
<span class="w">   </span><span class="n">dataHWC</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ptrTmp</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>

<span class="c1">// Assign dataHWC[image_size] to the input tensor variable.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">msInputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mSession</span><span class="o">-&gt;</span><span class="n">GetInputs</span><span class="p">();</span>
<span class="k">auto</span><span class="w"> </span><span class="n">inTensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">msInputs</span><span class="p">.</span><span class="n">front</span><span class="p">();</span>
<span class="n">memcpy</span><span class="p">(</span><span class="n">inTensor</span><span class="o">-&gt;</span><span class="n">MutableData</span><span class="p">(),</span><span class="w"> </span><span class="n">dataHWC</span><span class="p">,</span>
<span class="w">    </span><span class="n">inputDims</span><span class="p">.</span><span class="n">channel</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">inputDims</span><span class="p">.</span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">inputDims</span><span class="p">.</span><span class="n">height</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="k">delete</span><span class="p">[]</span><span class="w"> </span><span class="p">(</span><span class="n">dataHWC</span><span class="p">);</span>
</pre></div>
</div>
</li>
<li><p>Preprocessing the input data.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">bool</span><span class="w"> </span><span class="nf">PreProcessImageData</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">LiteMat</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lite_mat_bgr</span><span class="p">,</span><span class="w"> </span><span class="n">LiteMat</span><span class="w"> </span><span class="o">*</span><span class="n">lite_norm_mat_ptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">  </span><span class="n">LiteMat</span><span class="w"> </span><span class="n">lite_mat_resize</span><span class="p">;</span>
<span class="w">  </span><span class="n">LiteMat</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lite_norm_mat_cut</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">lite_norm_mat_ptr</span><span class="p">;</span>
<span class="w">  </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ResizeBilinear</span><span class="p">(</span><span class="n">lite_mat_bgr</span><span class="p">,</span><span class="w"> </span><span class="n">lite_mat_resize</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">ret</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;ResizeBilinear error&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">LiteMat</span><span class="w"> </span><span class="n">lite_mat_convert_float</span><span class="p">;</span>
<span class="w">  </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ConvertTo</span><span class="p">(</span><span class="n">lite_mat_resize</span><span class="p">,</span><span class="w"> </span><span class="n">lite_mat_convert_float</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">255.0</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">ret</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;ConvertTo error&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">LiteMat</span><span class="w"> </span><span class="n">lite_mat_cut</span><span class="p">;</span>
<span class="w">  </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Crop</span><span class="p">(</span><span class="n">lite_mat_convert_float</span><span class="p">,</span><span class="w"> </span><span class="n">lite_mat_cut</span><span class="p">,</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span><span class="w"> </span><span class="mi">224</span><span class="p">,</span><span class="w"> </span><span class="mi">224</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">ret</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;Crop error&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">means</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mf">0.485</span><span class="p">,</span><span class="w"> </span><span class="mf">0.456</span><span class="p">,</span><span class="w"> </span><span class="mf">0.406</span><span class="p">};</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">vars</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mf">1.0</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">0.229</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">0.224</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">0.225</span><span class="p">};</span>
<span class="w">  </span><span class="n">SubStractMeanNormalize</span><span class="p">(</span><span class="n">lite_mat_cut</span><span class="p">,</span><span class="w"> </span><span class="n">lite_norm_mat_cut</span><span class="p">,</span><span class="w"> </span><span class="n">means</span><span class="p">,</span><span class="w"> </span><span class="n">vars</span><span class="p">);</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>Perform inference on the input tensor based on the model, obtain the output tensor, and perform post-processing.</p>
<ul>
<li><p>Perform graph execution and on-device inference.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// After the model and image tensor data is loaded, run inference.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mSession</span><span class="o">-&gt;</span><span class="n">RunGraph</span><span class="p">();</span>
</pre></div>
</div>
</li>
<li><p>Obtain the output data.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mSession</span><span class="o">-&gt;</span><span class="n">GetOutputTensorNames</span><span class="p">();</span>
<span class="n">std</span><span class="o">::</span><span class="n">unordered_map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span><span class="n">mindspore</span><span class="o">::</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">msOutputs</span><span class="p">;</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">name</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">names</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">temp_dat</span><span class="w"> </span><span class="o">=</span><span class="n">mSession</span><span class="o">-&gt;</span><span class="n">GetOutputByTensorName</span><span class="p">(</span><span class="n">name</span><span class="p">);</span>
<span class="w">    </span><span class="n">msOutputs</span><span class="p">.</span><span class="n">insert</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="p">{</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">temp_dat</span><span class="p">});</span>
<span class="w">  </span><span class="p">}</span>
<span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">retStr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ProcessRunnetResult</span><span class="p">(</span><span class="n">msOutputs</span><span class="p">,</span><span class="w"> </span><span class="n">ret</span><span class="p">);</span>
</pre></div>
</div>
</li>
<li><p>Perform post-processing of the output data.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="nf">ProcessRunnetResult</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">unordered_map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span>
<span class="w">        </span><span class="n">mindspore</span><span class="o">::</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">msOutputs</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">runnetRet</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">unordered_map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;::</span><span class="n">iterator</span><span class="w"> </span><span class="n">iter</span><span class="p">;</span>
<span class="w">  </span><span class="n">iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">msOutputs</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span>

<span class="w">  </span><span class="c1">// The mobilenetv2.ms model output just one branch.</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">outputTensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iter</span><span class="o">-&gt;</span><span class="n">second</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">tensorNum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outputTensor</span><span class="o">-&gt;</span><span class="n">ElementsNum</span><span class="p">();</span>

<span class="w">  </span><span class="c1">// Get a pointer to the first score.</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">temp_scores</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="o">&gt;</span><span class="p">(</span><span class="n">outputTensor</span><span class="o">-&gt;</span><span class="n">MutableData</span><span class="p">());</span>

<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">scores</span><span class="p">[</span><span class="n">RET_CATEGORY_SUM</span><span class="p">];</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">RET_CATEGORY_SUM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">temp_scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.5</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;MindSpore scores[%d] : [%f]&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">temp_scores</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">temp_scores</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Score for each category.</span>
<span class="w">  </span><span class="c1">// Converted to text information that needs to be displayed in the APP.</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">categoryScore</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">RET_CATEGORY_SUM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">categoryScore</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">labels_name_map</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="n">categoryScore</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s">&quot;:&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">score_str</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">to_string</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="n">categoryScore</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">score_str</span><span class="p">;</span>
<span class="w">    </span><span class="n">categoryScore</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s">&quot;;&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">categoryScore</span><span class="p">;</span>
<span class="p">}</span><span class="w">      </span>
</pre></div>
</div>
</li>
</ul>
</li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="Using MindSpore on Mobile and IoT" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../use/build.html" class="btn btn-neutral float-right" title="Building MindSpore Lite" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore Lite.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>