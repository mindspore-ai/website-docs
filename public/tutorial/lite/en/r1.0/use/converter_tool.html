<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Converting into the MindSpore Lite Model &mdash; MindSpore Lite master documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Converting to the MindSpore Lite Model (Post Training Quantization)" href="post_training_quantization.html" />
    <link rel="prev" title="Converting Into The MindSpore Lite Model" href="convert_model.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Use</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="build.html">Building MindSpore Lite</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="convert_model.html">Converting Into The MindSpore Lite Model</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Converting into the MindSpore Lite Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#linux-environment-instructions">Linux Environment Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#environment-preparation">Environment Preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example">Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="#parameter-description">Parameter Description</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#windows-environment-instructions">Windows Environment Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">Environment Preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id2">Parameter Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id3">Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="post_training_quantization.html">Converting to the MindSpore Lite Model (Post Training Quantization)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="evaluating_the_model.html">Evaluating MindSpore Lite Model (optional)</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_preprocessing.html">Data Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">Using Runtime for Model Inference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="convert_model.html">Converting Into The MindSpore Lite Model</a> &raquo;</li>
      <li>Converting into the MindSpore Lite Model</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/use/converter_tool.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="converting-into-the-mindspore-lite-model">
<h1>Converting into the MindSpore Lite Model<a class="headerlink" href="#converting-into-the-mindspore-lite-model" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.0/tutorials/lite/source_en/use/converter_tool.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>MindSpore Lite provides a tool for offline model conversion. It supports conversion of multiple types of models. The converted models can be used for inference. The command line parameters contain multiple personalized options, providing a convenient conversion method for users.</p>
<p>Currently, the following input formats are supported: MindSpore, TensorFlow Lite, Caffe, and ONNX.</p>
</section>
<section id="linux-environment-instructions">
<h2>Linux Environment Instructions<a class="headerlink" href="#linux-environment-instructions" title="Permalink to this headline"></a></h2>
<section id="environment-preparation">
<h3>Environment Preparation<a class="headerlink" href="#environment-preparation" title="Permalink to this headline"></a></h3>
<p>To use the MindSpore Lite model conversion tool, you need to prepare the environment as follows:</p>
<ul class="simple">
<li><p>Compilation: Install basic and additional build dependencies and perform build. The build version is x86_64. The code of the model conversion tool is stored in the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/tools/converter</span></code> directory of the MindSpore source code. For details about the build operations, see the <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.0/use/build.html#environment-requirements">Environment Requirements</a> and <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.0/use/build.html#compilation-example">Compilation Example</a> in the build document.</p></li>
<li><p>Run: Obtain the <code class="docutils literal notranslate"><span class="pre">converter</span></code> tool and configure environment variables by referring to <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.0/use/build.html#output-description">Output Description</a> in the build document.</p></li>
</ul>
</section>
<section id="example">
<h3>Example<a class="headerlink" href="#example" title="Permalink to this headline"></a></h3>
<p>First, in the root directory of the source code, run the following command to perform compilation. For details, see <code class="docutils literal notranslate"><span class="pre">compile.md</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>build.sh<span class="w"> </span>-I<span class="w"> </span>x86_64
</pre></div>
</div>
<blockquote>
<div><p>Currently, the model conversion tool supports only the x86_64 architecture.</p>
</div></blockquote>
<p>The following describes how to use the conversion command by using several common examples.</p>
<ul>
<li><p>Take the Caffe model LeNet as an example. Run the following conversion command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite<span class="w"> </span>--fmk<span class="o">=</span>CAFFE<span class="w"> </span>--modelFile<span class="o">=</span>lenet.prototxt<span class="w"> </span>--weightFile<span class="o">=</span>lenet.caffemodel<span class="w"> </span>--outputFile<span class="o">=</span>lenet
</pre></div>
</div>
<p>In this example, the Caffe model is used. Therefore, the model structure and model weight files are required. Two more parameters <code class="docutils literal notranslate"><span class="pre">fmk</span></code> and <code class="docutils literal notranslate"><span class="pre">outputFile</span></code> are also required.</p>
<p>The output is as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">CONVERTER</span> <span class="n">RESULT</span> <span class="n">SUCCESS</span><span class="p">:</span><span class="mi">0</span>
</pre></div>
</div>
<p>This indicates that the Caffe model is successfully converted into the MindSpore Lite model and the new file <code class="docutils literal notranslate"><span class="pre">lenet.ms</span></code> is generated.</p>
</li>
<li><p>The following uses the MindSpore, TensorFlow Lite, ONNX and perception quantization models as examples to describe how to run the conversion command.</p>
<ul>
<li><p>MindSpore model <code class="docutils literal notranslate"><span class="pre">model.mindir</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite<span class="w"> </span>--fmk<span class="o">=</span>MINDIR<span class="w"> </span>--modelFile<span class="o">=</span>model.mindir<span class="w"> </span>--outputFile<span class="o">=</span>model
</pre></div>
</div>
</li>
<li><p>TensorFlow Lite model <code class="docutils literal notranslate"><span class="pre">model.tflite</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite<span class="w"> </span>--fmk<span class="o">=</span>TFLITE<span class="w"> </span>--modelFile<span class="o">=</span>model.tflite<span class="w"> </span>--outputFile<span class="o">=</span>model
</pre></div>
</div>
</li>
<li><p>ONNX model <code class="docutils literal notranslate"><span class="pre">model.onnx</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite<span class="w"> </span>--fmk<span class="o">=</span>ONNX<span class="w"> </span>--modelFile<span class="o">=</span>model.onnx<span class="w"> </span>--outputFile<span class="o">=</span>model
</pre></div>
</div>
</li>
<li><p>TensorFlow Lite aware quantization model <code class="docutils literal notranslate"><span class="pre">model_quant.tflite</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite<span class="w"> </span>--fmk<span class="o">=</span>TFLITE<span class="w"> </span>--modelFile<span class="o">=</span>model.tflite<span class="w"> </span>--outputFile<span class="o">=</span>model<span class="w"> </span>--quantType<span class="o">=</span>AwareTraining
</pre></div>
</div>
</li>
<li><p>TensorFlow Lite aware quantization model <code class="docutils literal notranslate"><span class="pre">model_quant.tflite</span></code> set the input and output data type to be float</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite<span class="w"> </span>--fmk<span class="o">=</span>TFLITE<span class="w"> </span>--modelFile<span class="o">=</span>model.tflite<span class="w"> </span>--outputFile<span class="o">=</span>model<span class="w"> </span>--quantType<span class="o">=</span>AwareTraining<span class="w">  </span>--inferenceType<span class="o">=</span>FLOAT
</pre></div>
</div>
</li>
</ul>
<p>In the preceding scenarios, the following information is displayed, indicating that the conversion is successful. In addition, the target file <code class="docutils literal notranslate"><span class="pre">model.ms</span></code> is obtained.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">CONVERTER</span> <span class="n">RESULT</span> <span class="n">SUCCESS</span><span class="p">:</span><span class="mi">0</span>
</pre></div>
</div>
</li>
<li><p>If fail to run the conversion command, an <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.0/errorcode_and_metatype.html">errorcode</a> will be output.</p></li>
</ul>
</section>
<section id="parameter-description">
<h3>Parameter Description<a class="headerlink" href="#parameter-description" title="Permalink to this headline"></a></h3>
<p>MindSpore Lite model conversion tool provides multiple parameters.
You can enter <code class="docutils literal notranslate"><span class="pre">./converter_lite</span> <span class="pre">--help</span></code> to obtain help information in real time.</p>
<p>The following describes the parameters in detail.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Mandatory or Not</p></th>
<th class="head"><p>Parameter Description</p></th>
<th class="head"><p>Value Range</p></th>
<th class="head"><p>Default Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--help</span></code></p></td>
<td><p>No</p></td>
<td><p>Prints all help information.</p></td>
<td><p>-</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--fmk=&lt;FMK&gt;</span></code></p></td>
<td><p>Yes</p></td>
<td><p>Original format of the input model.</p></td>
<td><p>MINDIR, CAFFE, TFLITE, or ONNX</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--modelFile=&lt;MODELFILE&gt;</span></code></p></td>
<td><p>Yes</p></td>
<td><p>Path of the input model.</p></td>
<td><p>-</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--outputFile=&lt;OUTPUTFILE&gt;</span></code></p></td>
<td><p>Yes</p></td>
<td><p>Path of the output model. (If the path does not exist, a directory will be automatically created.) The suffix <code class="docutils literal notranslate"><span class="pre">.ms</span></code> can be automatically generated.</p></td>
<td><p>-</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--weightFile=&lt;WEIGHTFILE&gt;</span></code></p></td>
<td><p>Yes (for Caffe models only)</p></td>
<td><p>Path of the weight file of the input model.</p></td>
<td><p>-</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--quantType=&lt;QUANTTYPE&gt;</span></code></p></td>
<td><p>No</p></td>
<td><p>Sets the quant type of the model.</p></td>
<td><p>PostTraining: quantization after training <br>AwareTraining: perceptual quantization</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--inferenceType=&lt;INFERENCETYPE&gt;</span> </code></p></td>
<td><p>No(supported by aware quant models only)</p></td>
<td><p>Sets the input and output data type of the converted model. If the types are different from the origin model, the convert tool will insert data type convert op in the inputs and outputs of the model to make sure the data types are same as origin model.</p></td>
<td><p>UINT8, FLOAT or INT8</p></td>
<td><p>FLOAT</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--stdDev=&lt;STDDEV&gt;</span></code></p></td>
<td><p>No(supported by aware quant models only)</p></td>
<td><p>Sets the standard deviation of the input data.</p></td>
<td><p>（0，+∞）</p></td>
<td><p>128</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--mean=&lt;MEAN&gt;</span></code></p></td>
<td><p>No(supported by aware quant models only)</p></td>
<td><p>Sets the mean value of the input data.</p></td>
<td><p>[-128, 127]</p></td>
<td><p>-0.5</p></td>
</tr>
</tbody>
</table>
<blockquote>
<div><ul class="simple">
<li><p>The parameter name and parameter value are separated by an equal sign (=) and no space is allowed between them.</p></li>
<li><p>The Caffe model is divided into two files: model structure <code class="docutils literal notranslate"><span class="pre">*.prototxt</span></code>, corresponding to the <code class="docutils literal notranslate"><span class="pre">--modelFile</span></code> parameter; model weight <code class="docutils literal notranslate"><span class="pre">*.caffemodel</span></code>, corresponding to the <code class="docutils literal notranslate"><span class="pre">--weightFile</span></code> parameter</p></li>
</ul>
</div></blockquote>
</section>
</section>
<section id="windows-environment-instructions">
<h2>Windows Environment Instructions<a class="headerlink" href="#windows-environment-instructions" title="Permalink to this headline"></a></h2>
<section id="id1">
<h3>Environment Preparation<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<p>To use the MindSpore Lite model conversion tool, the following environment preparations are required.</p>
<ul class="simple">
<li><p>Get the toolkit: To obtain the ‘Converter’ tool, download the <a class="reference external" href="https://www.mindspore.cn/versions/en">zip package</a> of windows conversion tool and unzip it to the local directory.</p></li>
</ul>
</section>
<section id="id2">
<h3>Parameter Description<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<p>Reference description Linux environment model conversion tool <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.0/use/converter_tool.html#parameter-description">parameter description</a>.</p>
</section>
<section id="id3">
<h3>Example<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h3>
<p>Set the log printing level to INFO.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">set</span><span class="w"> </span><span class="nv">MSLOG</span><span class="o">=</span>INFO
</pre></div>
</div>
<p>Several common examples are selected below to illustrate the use of conversion commands.</p>
<ul>
<li><p>Take Caffe model LeNet as an example to execute the conversion command.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>call<span class="w"> </span>converter_lite<span class="w"> </span>--fmk<span class="o">=</span>CAFFE<span class="w"> </span>--modelFile<span class="o">=</span>lenet.prototxt<span class="w"> </span>--weightFile<span class="o">=</span>lenet.caffemodel<span class="w"> </span>--outputFile<span class="o">=</span>lenet
</pre></div>
</div>
<p>In this example, because the Caffe model is used, two input files of model structure and model weight are required. Then plus fmk type and output path two parameters which are required, you can successfully execute.</p>
<p>The result is shown as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">CONVERTER</span> <span class="n">RESULT</span> <span class="n">SUCCESS</span><span class="p">:</span><span class="mi">0</span>
</pre></div>
</div>
<p>This means that the Caffe model has been successfully converted to the MindSpore Lite model and the new file <code class="docutils literal notranslate"><span class="pre">lenet.ms</span></code> has been obtained.</p>
</li>
<li><p>Take MindSpore, TensorFlow Lite, ONNX model format and perceptual quantization model as examples to execute conversion commands.</p>
<ul>
<li><p>MindSpore model <code class="docutils literal notranslate"><span class="pre">model.mindir</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>call<span class="w"> </span>converter_lite<span class="w"> </span>--fmk<span class="o">=</span>MINDIR<span class="w"> </span>--modelFile<span class="o">=</span>model.mindir<span class="w"> </span>--outputFile<span class="o">=</span>model
</pre></div>
</div>
</li>
<li><p>TensorFlow Lite model<code class="docutils literal notranslate"><span class="pre">model.tflite</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>call<span class="w"> </span>converter_lite<span class="w"> </span>--fmk<span class="o">=</span>TFLITE<span class="w"> </span>--modelFile<span class="o">=</span>model.tflite<span class="w"> </span>--outputFile<span class="o">=</span>model
</pre></div>
</div>
</li>
<li><p>ONNX model<code class="docutils literal notranslate"><span class="pre">model.onnx</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>call<span class="w"> </span>converter_lite<span class="w"> </span>--fmk<span class="o">=</span>ONNX<span class="w"> </span>--modelFile<span class="o">=</span>model.onnx<span class="w"> </span>--outputFile<span class="o">=</span>model
</pre></div>
</div>
</li>
<li><p>TensorFlow Lite awaring quant model <code class="docutils literal notranslate"><span class="pre">model_quant.tflite</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>call<span class="w"> </span>converter_lite<span class="w"> </span>--fmk<span class="o">=</span>TFLITE<span class="w"> </span>--modelFile<span class="o">=</span>model_quant.tflite<span class="w"> </span>--outputFile<span class="o">=</span>model<span class="w"> </span>--quantType<span class="o">=</span>AwareTraining
</pre></div>
</div>
</li>
</ul>
<p>In the above cases, the following conversion success prompt is displayed, and the <code class="docutils literal notranslate"><span class="pre">model.ms</span></code> target file is obtained at the same time.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">CONVERTER</span> <span class="n">RESULT</span> <span class="n">SUCCESS</span><span class="p">:</span><span class="mi">0</span>
</pre></div>
</div>
</li>
<li><p>If fail to run the conversion command, an <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.0/errorcode_and_metatype.html">errorcode</a> will be output.</p></li>
</ul>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="convert_model.html" class="btn btn-neutral float-left" title="Converting Into The MindSpore Lite Model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="post_training_quantization.html" class="btn btn-neutral float-right" title="Converting to the MindSpore Lite Model (Post Training Quantization)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore Lite.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>