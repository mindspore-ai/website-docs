<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Using Runtime for Model Inference &mdash; MindSpore Lite master documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Preprocessing Image Data" href="image_processing.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Use</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="build.html">Building MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="convert_model.html">Converting Into The MindSpore Lite Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluating_the_model.html">Evaluating MindSpore Lite Model (optional)</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_preprocessing.html">Data Preprocessing</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Using Runtime for Model Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#reading-models">Reading Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#session-creation">Session Creation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#creating-contexts">Creating Contexts</a></li>
<li class="toctree-l3"><a class="reference internal" href="#creating-sessions">Creating Sessions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#graph-compilation">Graph Compilation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#variable-dimension">Variable Dimension</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id1">Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compiling-graphs">Compiling Graphs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#data-input">Data Input</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#obtaining-input-tensors">Obtaining Input Tensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="#copying-data">Copying Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#graph-execution">Graph Execution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#executing-sessions">Executing Sessions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#core-binding">Core Binding</a></li>
<li class="toctree-l3"><a class="reference internal" href="#callback-running">Callback Running</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#obtaining-outputs">Obtaining Outputs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#obtaining-output-tensors">Obtaining Output Tensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#obtaining-version-string">Obtaining Version String</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id6">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#session-parallel-launch">Session parallel launch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#single-session-parallel-launch">Single Session parallel launch</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multiple-session-parallel-launch">Multiple Session parallel launch</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">Example</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Using Runtime for Model Inference</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/use/runtime.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="using-runtime-for-model-inference">
<h1>Using Runtime for Model Inference<a class="headerlink" href="#using-runtime-for-model-inference" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.0/tutorials/lite/source_en/use/runtime.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>After model conversion using MindSpore Lite, the model inference process needs to be completed in Runtime.</p>
<p>The procedure for using Runtime is shown in the following figure:</p>
<p><img alt="img" src="../_images/side_infer_process.png" /></p>
<p>Its components and their functions are described as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Model</span></code>: model used by MindSpore Lite, which instantiates the list of operator prototypes through image composition or direct network loading.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Lite</span> <span class="pre">Session</span></code>: provides the graph compilation function and calls the graph executor for inference.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Scheduler</span></code>: operator heterogeneous scheduler. It can select a proper kernel for each operator based on the heterogeneous scheduling policy, construct a kernel list, and split a graph into subgraphs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Executor</span></code>: graph executor, which executes the kernel list to dynamically allocate and release tensors.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Operator</span></code>: operator prototype, including operator attributes and methods for inferring the shape, data type, and format.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Kernel</span></code>: operator, which provides specific operator implementation and the operator forwarding function.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Tensor</span></code>: tensor used by MindSpore Lite, which provides functions and APIs for tensor memory operations.</p></li>
</ul>
</section>
<section id="reading-models">
<h2>Reading Models<a class="headerlink" href="#reading-models" title="Permalink to this headline"></a></h2>
<p>In MindSpore Lite, a model file is an <code class="docutils literal notranslate"><span class="pre">.ms</span></code> file converted using the model conversion tool. During model inference, the model needs to be loaded from the file system and parsed. Related operations are mainly implemented in the Model component. The Model component holds model data such as weight data and operator attributes.</p>
<p>A model is created based on memory data using the static <code class="docutils literal notranslate"><span class="pre">Import</span></code> method of the Model class. The <code class="docutils literal notranslate"><span class="pre">Model</span></code> instance returned by the function is a pointer, which is created by using <code class="docutils literal notranslate"><span class="pre">new</span></code>. If the pointer is not required, you need to release it by using <code class="docutils literal notranslate"><span class="pre">delete</span></code>.</p>
<p>If there is a large limitation on the runtime memory, you can use the <code class="docutils literal notranslate"><span class="pre">Free</span></code> interface to reduce the memory usage after the <code class="docutils literal notranslate"><span class="pre">Model</span></code> is compiled. But once the <code class="docutils literal notranslate"><span class="pre">Free</span></code> interface of a certain <code class="docutils literal notranslate"><span class="pre">Model</span></code> is called, the <code class="docutils literal notranslate"><span class="pre">Model</span></code> can no longer perform graph compilation.</p>
</section>
<section id="session-creation">
<h2>Session Creation<a class="headerlink" href="#session-creation" title="Permalink to this headline"></a></h2>
<p>When MindSpore Lite is used for inference, sessions are the main entrance of inference. You can compile and execute graphs through sessions.</p>
<section id="creating-contexts">
<h3>Creating Contexts<a class="headerlink" href="#creating-contexts" title="Permalink to this headline"></a></h3>
<p>Contexts save some basic configuration parameters required by sessions to guide graph compilation and execution. The definition of context is as follows:</p>
<p>MindSpore Lite supports heterogeneous inference. The preferred backend for inference is specified by <code class="docutils literal notranslate"><span class="pre">device_ctx_</span></code> in <code class="docutils literal notranslate"><span class="pre">Context</span></code> and is CPU by default. During graph compilation, operator selection and scheduling are performed based on the preferred backend.</p>
<p>MindSpore Lite has a built-in thread pool shared by processes. During inference, <code class="docutils literal notranslate"><span class="pre">thread_num_</span></code> is used to specify the maximum number of threads in the thread pool. The default maximum number is 2. It is recommended that the maximum number be no more than 4. Otherwise, the performance may be affected.</p>
<p>MindSpore Lite supports dynamic memory allocation and release. If <code class="docutils literal notranslate"><span class="pre">allocator</span></code> is not specified, a default <code class="docutils literal notranslate"><span class="pre">allocator</span></code> is generated during inference. You can also use the <code class="docutils literal notranslate"><span class="pre">Context</span></code> method to allow multiple <code class="docutils literal notranslate"><span class="pre">Context</span></code> to share the memory allocator.</p>
<p>If users create the <code class="docutils literal notranslate"><span class="pre">Context</span></code> by using <code class="docutils literal notranslate"><span class="pre">new</span></code>,  it should be released by using <code class="docutils literal notranslate"><span class="pre">delete</span></code> once it’s not required. Usually the <code class="docutils literal notranslate"><span class="pre">Context</span></code> is released after finishing the session creation.</p>
</section>
<section id="creating-sessions">
<h3>Creating Sessions<a class="headerlink" href="#creating-sessions" title="Permalink to this headline"></a></h3>
<p>Use the <code class="docutils literal notranslate"><span class="pre">Context</span></code> created in the previous step to call the static <code class="docutils literal notranslate"><span class="pre">CreateSession</span></code> method of LiteSession to create <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code>. The <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> instance returned by the function is a pointer, which is created by using <code class="docutils literal notranslate"><span class="pre">new</span></code>. If the pointer is not required, you need to release it by using <code class="docutils literal notranslate"><span class="pre">delete</span></code>.</p>
</section>
<section id="example">
<h3>Example<a class="headerlink" href="#example" title="Permalink to this headline"></a></h3>
<p>The following sample code demonstrates how to create a <code class="docutils literal notranslate"><span class="pre">Context</span></code> and how to allow two <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> to share a memory pool.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">nothrow</span><span class="p">)</span><span class="w"> </span><span class="n">lite</span><span class="o">::</span><span class="n">Context</span><span class="p">;</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">context</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New context failed while running %s&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">modelName</span><span class="p">.</span><span class="n">c_str</span><span class="p">();</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="p">}</span>
<span class="c1">// The preferred backend is GPU, which means, if there is a GPU operator, it will run on the GPU first, otherwise it will run on the CPU.</span>
<span class="n">context</span><span class="o">-&gt;</span><span class="n">device_type_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lite</span><span class="o">::</span><span class="n">DT_GPU</span><span class="p">;</span>
<span class="c1">// The medium core takes priority in thread and core binding methods. This parameter will work in the BindThread interface. For specific binding effect, see the &quot;Run Graph&quot; section.</span>
<span class="n">context</span><span class="o">-&gt;</span><span class="n">cpu_bind_mode_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MID_CPU</span><span class="p">;</span>
<span class="c1">// Configure the number of worker threads in the thread pool to 2, including the main thread.</span>
<span class="n">context</span><span class="o">-&gt;</span><span class="n">thread_num_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="c1">// Allocators can be shared across multiple Contexts.</span>
<span class="k">auto</span><span class="w"> </span><span class="o">*</span><span class="n">context2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">Context</span><span class="p">();</span>
<span class="n">context2</span><span class="o">-&gt;</span><span class="n">thread_num_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">context</span><span class="o">-&gt;</span><span class="n">thread_num_</span><span class="p">;</span>
<span class="n">context2</span><span class="o">-&gt;</span><span class="n">allocator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">context</span><span class="o">-&gt;</span><span class="n">allocator</span><span class="p">;</span>
<span class="n">context2</span><span class="o">-&gt;</span><span class="n">device_type_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">context</span><span class="o">-&gt;</span><span class="n">device_type_</span><span class="p">;</span>
<span class="n">context2</span><span class="o">-&gt;</span><span class="n">cpu_bind_mode_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">context</span><span class="o">-&gt;</span><span class="n">cpu_bind_mode_</span><span class="p">;</span>
<span class="c1">// Use Context to create Session.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">session1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">::</span><span class="n">LiteSession</span><span class="o">::</span><span class="n">CreateSession</span><span class="p">(</span><span class="n">context</span><span class="p">);</span>
<span class="c1">// After the LiteSession is created, the Context can be released.</span>
<span class="k">delete</span><span class="w"> </span><span class="p">(</span><span class="n">context</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">session1</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;CreateSession failed while running %s&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">modelName</span><span class="p">.</span><span class="n">c_str</span><span class="p">();</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="p">}</span>
<span class="c1">// session1 and session2 can share one memory pool.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">session2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">::</span><span class="n">LiteSession</span><span class="o">::</span><span class="n">CreateSession</span><span class="p">(</span><span class="n">context2</span><span class="p">);</span>
<span class="k">delete</span><span class="w"> </span><span class="p">(</span><span class="n">context2</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">session2</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;CreateSession failed while running %s&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">modelName</span><span class="p">.</span><span class="n">c_str</span><span class="p">();</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="graph-compilation">
<h2>Graph Compilation<a class="headerlink" href="#graph-compilation" title="Permalink to this headline"></a></h2>
<section id="variable-dimension">
<h3>Variable Dimension<a class="headerlink" href="#variable-dimension" title="Permalink to this headline"></a></h3>
<p>When using MindSpore Lite for inference, after the session creation and graph compilation have been completed, if you need to resize the input shape, you can reset the shape of the input tensor, and then call the session’s Resize() interface.</p>
<blockquote>
<div><p>Not all models support variable dimensions. For example, when there is a MatMul operator in the model whose input Tensor is a weight tensor and an input tensor, calling the variable dimension interface will cause the shape of the input tensor and the weight tensor being unmatched.</p>
</div></blockquote>
</section>
<section id="id1">
<h3>Example<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<p>The following code demonstrates how to resize the input of MindSpore Lite:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Assume we have created a LiteSession instance named session.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">GetInputs</span><span class="p">();</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">resize_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">};</span>
<span class="c1">// Assume the model has only one input,resize input shape to [1, 128, 128, 3]</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">new_shapes</span><span class="p">;</span>
<span class="n">new_shapes</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">resize_shape</span><span class="p">);</span>
<span class="n">session</span><span class="o">-&gt;</span><span class="n">Resize</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">new_shapes</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="compiling-graphs">
<h3>Compiling Graphs<a class="headerlink" href="#compiling-graphs" title="Permalink to this headline"></a></h3>
<p>Before graph execution, call the <code class="docutils literal notranslate"><span class="pre">CompileGraph</span></code> API of the <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> to compile graphs and further parse the Model instance loaded from the file, mainly for subgraph split and operator selection and scheduling. This process takes a long time. Therefore, it is recommended that <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> achieve multiple executions with one creation and one compilation.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">/// \brief  Compile MindSpore Lite model.</span>
<span class="c1">///</span>
<span class="c1">/// \note  CompileGraph should be called before RunGraph.</span>
<span class="c1">///</span>
<span class="c1">/// \param[in] model  Define the model to be compiled.</span>
<span class="c1">///</span>
<span class="c1">/// \return  STATUS as an error code of compiling graph, STATUS is defined in errorcode.h.</span>
<span class="k">virtual</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">CompileGraph</span><span class="p">(</span><span class="n">lite</span><span class="o">::</span><span class="n">Model</span><span class="w"> </span><span class="o">*</span><span class="n">model</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</pre></div>
</div>
</section>
<section id="id2">
<h3>Example<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<p>The following code demonstrates how to compile graph of MindSpore Lite:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Assume we have created a LiteSession instance named session and a Model instance named model before.</span>
<span class="c1">// The methods of creating model and session can refer to &quot;Import Model&quot; and &quot;Create Session&quot; two sections.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">CompileGraph</span><span class="p">(</span><span class="n">model</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">RET_OK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;CompileGraph failed&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="c1">// session and model need to be released by users manually.</span>
<span class="w">    </span><span class="k">delete</span><span class="w"> </span><span class="p">(</span><span class="n">session</span><span class="p">);</span>
<span class="w">    </span><span class="k">delete</span><span class="w"> </span><span class="p">(</span><span class="n">model</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">ret</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">model</span><span class="o">-&gt;</span><span class="n">Free</span><span class="p">();</span>
</pre></div>
</div>
</section>
</section>
<section id="data-input">
<h2>Data Input<a class="headerlink" href="#data-input" title="Permalink to this headline"></a></h2>
<section id="obtaining-input-tensors">
<h3>Obtaining Input Tensors<a class="headerlink" href="#obtaining-input-tensors" title="Permalink to this headline"></a></h3>
<p>Before graph execution, you need to copy the input data to model input tensors.</p>
<p>MindSpore Lite provides the following methods to obtain model input tensors.</p>
<ol class="arabic">
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">GetInputsByName</span></code> method to obtain vectors of the model input tensors that are connected to the model input node based on the node name.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">/// \brief  Get input MindSpore Lite MSTensors of model by node name.</span>
<span class="c1">///</span>
<span class="c1">/// \param[in] node_name  Define node name.</span>
<span class="c1">///</span>
<span class="c1">/// \return  The vector of MindSpore Lite MSTensor.</span>
<span class="k">virtual</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">GetInputsByName</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="o">&amp;</span><span class="n">node_name</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</pre></div>
</div>
</li>
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">GetInputs</span></code> method to directly obtain the vectors of all model input tensors.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">/// \brief  Get input MindSpore Lite MSTensors of model.</span>
<span class="c1">///</span>
<span class="c1">/// \return  The vector of MindSpore Lite MSTensor.</span>
<span class="k">virtual</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">GetInputs</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="copying-data">
<h3>Copying Data<a class="headerlink" href="#copying-data" title="Permalink to this headline"></a></h3>
<p>After model input tensors are obtained, you need to enter data into the tensors. Use the <code class="docutils literal notranslate"><span class="pre">Size</span></code> method of <code class="docutils literal notranslate"><span class="pre">MSTensor</span></code> to obtain the size of the data to be entered into tensors, use the <code class="docutils literal notranslate"><span class="pre">data_type</span></code> method to obtain the data type of tensors, and use the <code class="docutils literal notranslate"><span class="pre">MutableData</span></code> method of <code class="docutils literal notranslate"><span class="pre">MSTensor</span></code> to obtain the writable pointer.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">/// \brief  Get byte size of data in MSTensor.</span>
<span class="c1">///</span>
<span class="c1">/// \return  Byte size of data in MSTensor.</span>
<span class="k">virtual</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="nf">Size</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="c1">/// \brief  Get the pointer of data in MSTensor.</span>
<span class="c1">///</span>
<span class="c1">/// \note  The data pointer can be used to both write and read data in MSTensor.</span>
<span class="c1">///</span>
<span class="c1">/// \return  The pointer points to data in MSTensor.</span>
<span class="k">virtual</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="nf">MutableData</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</pre></div>
</div>
</section>
<section id="id3">
<h3>Example<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h3>
<p>The following sample code shows how to obtain the entire graph input <code class="docutils literal notranslate"><span class="pre">MSTensor</span></code> from <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> and enter the model input data to <code class="docutils literal notranslate"><span class="pre">MSTensor</span></code>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Assume we have created a LiteSession instance named session.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">GetInputs</span><span class="p">();</span>
<span class="c1">// Assume that the model has only one input tensor.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">in_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputs</span><span class="p">.</span><span class="n">front</span><span class="p">();</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">in_tensor</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Input tensor is nullptr&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="p">}</span>
<span class="c1">// It is omitted that users have read the model input file and generated a section of memory buffer: input_buf, as well as the byte size of input_buf: data_size.</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">in_tensor</span><span class="o">-&gt;</span><span class="n">Size</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">data_size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Input data size is not suit for model input&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">auto</span><span class="w"> </span><span class="o">*</span><span class="n">in_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in_tensor</span><span class="o">-&gt;</span><span class="n">MutableData</span><span class="p">();</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">in_data</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Data of in_tensor is nullptr&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">memcpy</span><span class="p">(</span><span class="n">in_data</span><span class="p">,</span><span class="w"> </span><span class="n">input_buf</span><span class="p">,</span><span class="w"> </span><span class="n">data_size</span><span class="p">);</span>
<span class="c1">// Users need to free input_buf.</span>
<span class="c1">// The elements in the inputs are managed by MindSpore Lite so that users do not need to free inputs.</span>
</pre></div>
</div>
<p>Note:</p>
<ul class="simple">
<li><p>The data layout in the model input tensors of MindSpore Lite must be NHWC.</p></li>
<li><p>The model input <code class="docutils literal notranslate"><span class="pre">input_buf</span></code> is read from disks. After it is copied to model input tensors, you need to release <code class="docutils literal notranslate"><span class="pre">input_buf</span></code>.</p></li>
<li><p>Vectors returned by using the <code class="docutils literal notranslate"><span class="pre">GetInputs</span></code> and <code class="docutils literal notranslate"><span class="pre">GetInputsByName</span></code> methods do not need to be released by users.</p></li>
</ul>
</section>
</section>
<section id="graph-execution">
<h2>Graph Execution<a class="headerlink" href="#graph-execution" title="Permalink to this headline"></a></h2>
<section id="executing-sessions">
<h3>Executing Sessions<a class="headerlink" href="#executing-sessions" title="Permalink to this headline"></a></h3>
<p>After a MindSpore Lite session performs graph compilation, you can use <code class="docutils literal notranslate"><span class="pre">RunGraph</span></code> of <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> for model inference.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">virtual</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">RunGraph</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">KernelCallBack</span><span class="w"> </span><span class="o">&amp;</span><span class="n">before</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">KernelCallBack</span><span class="w"> </span><span class="o">&amp;</span><span class="n">after</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</pre></div>
</div>
</section>
<section id="core-binding">
<h3>Core Binding<a class="headerlink" href="#core-binding" title="Permalink to this headline"></a></h3>
<p>The built-in thread pool of MindSpore Lite supports core binding and unbinding. By calling the <code class="docutils literal notranslate"><span class="pre">BindThread</span></code> API, you can bind working threads in the thread pool to specified CPU cores for performance analysis. The core binding operation is related to the context specified when <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> is created. The core binding operation sets the affinity between a thread and CPU based on the core binding policy in the context.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">/// \brief  Attempt to bind or unbind threads in the thread pool to or from the specified cpu core.</span>
<span class="c1">///</span>
<span class="c1">/// \param[in] if_bind  Define whether to bind or unbind threads.</span>
<span class="k">virtual</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">BindThread</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">if_bind</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</pre></div>
</div>
<p>Note that core binding is an affinity operation, which is affected by system scheduling. Therefore, successful binding to the specified CPU core cannot be ensured. After executing the code of core binding, you need to perform the unbinding operation. The following is an example:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Assume we have created a LiteSession instance named session.</span>
<span class="n">session</span><span class="o">-&gt;</span><span class="n">BindThread</span><span class="p">(</span><span class="nb">true</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">RunGraph</span><span class="p">();</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">RET_OK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;RunGraph failed&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">delete</span><span class="w"> </span><span class="n">session</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">session</span><span class="o">-&gt;</span><span class="n">BindThread</span><span class="p">(</span><span class="nb">false</span><span class="p">);</span>
</pre></div>
</div>
<blockquote>
<div><p>Core binding parameters can be used to bind big cores first or middle cores first.<br />
The rule for determining big core or middle core is based on the CPU core frequency instead of CPU architecture. For the CPU architecture where big, middle, and little cores are not distinguished, this rule can be used.<br />
Big core first indicates that threads in the thread pool are bound to cores according to core frequency. The first thread is bound to the core with the highest frequency, and the second thread is bound to the core with the second highest frequency. This rule also applies to other threads.<br />
Middle cores are defined based on experience. By default, middle cores are cores with the third and fourth highest frequency. Middle core first indicates that threads are bound to middle cores preferentially. When there are no available middle cores, threads are bound to little cores.</p>
</div></blockquote>
</section>
<section id="callback-running">
<h3>Callback Running<a class="headerlink" href="#callback-running" title="Permalink to this headline"></a></h3>
<p>MindSpore Lite can transfer two <code class="docutils literal notranslate"><span class="pre">KernelCallBack</span></code> function pointers to call back the inference model when calling <code class="docutils literal notranslate"><span class="pre">RunGraph</span></code>. Compared with common graph execution, callback running can obtain extra information during the running process to help developers analyze performance and fix bugs. The extra information includes:</p>
<ul class="simple">
<li><p>Name of the running node</p></li>
<li><p>Input and output tensors before inference of the current node</p></li>
<li><p>Input and output tensors after inference of the current node</p></li>
</ul>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">/// \brief  CallBackParam defines input arguments for callback function.</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">CallBackParam</span><span class="w"> </span><span class="p">{</span>
<span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">name_callback_param</span><span class="p">;</span><span class="w"> </span><span class="cm">/**&lt; node name argument */</span>
<span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">type_callback_param</span><span class="p">;</span><span class="w"> </span><span class="cm">/**&lt; node type argument */</span>
<span class="p">};</span>

<span class="c1">/// \brief  KernelCallBack defines the function pointer for callback.</span>
<span class="k">using</span><span class="w"> </span><span class="n">KernelCallBack</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">function</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">CallBackParam</span><span class="w"> </span><span class="o">&amp;</span><span class="n">opInfo</span><span class="p">)</span><span class="o">&gt;</span><span class="p">;</span>
</pre></div>
</div>
</section>
<section id="id4">
<h3>Example<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<p>The following sample code demonstrates how to use <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> to compile a graph, defines two callback functions as the before-callback pointer and after-callback pointer, transfers them to the <code class="docutils literal notranslate"><span class="pre">RunGraph</span></code> API for callback inference, and demonstrates the scenario of multiple graph executions with one graph compilation.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Assume we have created a LiteSession instance named session and a Model instance named model before.</span>
<span class="c1">// The methods of creating model and session can refer to &quot;Import Model&quot; and &quot;Create Session&quot; two sections.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">CompileGraph</span><span class="p">(</span><span class="n">model</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">RET_OK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;CompileGraph failed&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="c1">// session and model need to be released by users manually.</span>
<span class="w">    </span><span class="k">delete</span><span class="w"> </span><span class="p">(</span><span class="n">session</span><span class="p">);</span>
<span class="w">    </span><span class="k">delete</span><span class="w"> </span><span class="p">(</span><span class="n">model</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">ret</span><span class="p">;</span>
<span class="p">}</span>
<span class="c1">// Copy input data into the input tensor. Users can refer to the &quot;Input Data&quot; section. We uses random data here.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">GetInputs</span><span class="p">();</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">in_tensor</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">inputs</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">in_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputs</span><span class="p">.</span><span class="n">front</span><span class="p">();</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">in_tensor</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Input tensor is nullptr&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="c1">// When calling the MutableData method, if the data in MSTensor is not allocated, it will be malloced. After allocation, the data in MSTensor can be considered as random data.</span>
<span class="w">    </span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="n">in_tensor</span><span class="o">-&gt;</span><span class="n">MutableData</span><span class="p">();</span>
<span class="p">}</span>
<span class="c1">// Definition of callback function before forwarding operator.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">before_call_back_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="o">&amp;</span><span class="p">](</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">before_inputs</span><span class="p">,</span>
<span class="w">                             </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">before_outputs</span><span class="p">,</span>
<span class="w">                             </span><span class="k">const</span><span class="w"> </span><span class="n">session</span><span class="o">::</span><span class="n">CallBackParam</span><span class="w"> </span><span class="o">&amp;</span><span class="n">call_param</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Before forwarding &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">call_param</span><span class="p">.</span><span class="n">name_callback_param</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="p">};</span>
<span class="c1">// Definition of callback function after forwarding operator.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">after_call_back_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="o">&amp;</span><span class="p">](</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">after_inputs</span><span class="p">,</span>
<span class="w">                            </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">after_outputs</span><span class="p">,</span>
<span class="w">                            </span><span class="k">const</span><span class="w"> </span><span class="n">session</span><span class="o">::</span><span class="n">CallBackParam</span><span class="w"> </span><span class="o">&amp;</span><span class="n">call_param</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;After forwarding &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">call_param</span><span class="p">.</span><span class="n">name_callback_param</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="p">};</span>
<span class="c1">// Call the callback function when performing the model inference process.</span>
<span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session_</span><span class="o">-&gt;</span><span class="n">RunGraph</span><span class="p">(</span><span class="n">before_call_back_</span><span class="p">,</span><span class="w"> </span><span class="n">after_call_back_</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">RET_OK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Run graph failed.&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="p">}</span>
<span class="c1">// CompileGraph would cost much time, a better solution is calling CompileGraph only once and RunGraph much more times.</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session_</span><span class="o">-&gt;</span><span class="n">RunGraph</span><span class="p">();</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">RET_OK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">MS_LOG</span><span class="p">(</span><span class="n">ERROR</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Run graph failed.&quot;</span><span class="p">;</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">RET_ERROR</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
<span class="c1">// session and model needs to be released by users manually.</span>
<span class="k">delete</span><span class="w"> </span><span class="p">(</span><span class="n">session</span><span class="p">);</span>
<span class="k">delete</span><span class="w"> </span><span class="p">(</span><span class="n">model</span><span class="p">);</span>
</pre></div>
</div>
</section>
</section>
<section id="obtaining-outputs">
<h2>Obtaining Outputs<a class="headerlink" href="#obtaining-outputs" title="Permalink to this headline"></a></h2>
<section id="obtaining-output-tensors">
<h3>Obtaining Output Tensors<a class="headerlink" href="#obtaining-output-tensors" title="Permalink to this headline"></a></h3>
<p>After performing inference, MindSpore Lite can obtain the model inference result.</p>
<p>MindSpore Lite provides the following methods to obtain the model output <code class="docutils literal notranslate"><span class="pre">MSTensor</span></code>.</p>
<ol class="arabic">
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">GetOutputsByNodeName</span></code> method to obtain vectors of the model output <code class="docutils literal notranslate"><span class="pre">MSTensor</span></code> that is connected to the model output node based on the node name.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">/// \brief  Get output MindSpore Lite MSTensors of model by node name.</span>
<span class="c1">///</span>
<span class="c1">/// \param[in] node_name Define node name.</span>
<span class="c1">///</span>
<span class="c1">/// \return  The vector of MindSpore Lite MSTensor.</span>
<span class="k">virtual</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">GetOutputsByNodeName</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="o">&amp;</span><span class="n">node_name</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</pre></div>
</div>
</li>
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">GetOutputByTensorName</span></code> method to obtain the model output <code class="docutils literal notranslate"><span class="pre">MSTensor</span></code> based on the tensor name.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">/// \brief  Get output MindSpore Lite MSTensors of model by tensor name.</span>
<span class="c1">///</span>
<span class="c1">/// \param[in] tensor_name  Define tensor name.</span>
<span class="c1">///</span>
<span class="c1">/// \return  Pointer of MindSpore Lite MSTensor.</span>
<span class="k">virtual</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*</span><span class="nf">GetOutputByTensorName</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="o">&amp;</span><span class="n">tensor_name</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</pre></div>
</div>
</li>
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">GetOutputs</span></code> method to directly obtain the mapping between the names of all model output tensors and the model output <code class="docutils literal notranslate"><span class="pre">MSTensor</span></code>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">/// \brief  Get output MindSpore Lite MSTensors of model mapped by tensor name.</span>
<span class="c1">///</span>
<span class="c1">/// \return  The map of output tensor name and MindSpore Lite MSTensor.</span>
<span class="k">virtual</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">unordered_map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">GetOutputs</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</pre></div>
</div>
</li>
</ol>
<p>After model output tensors are obtained, you need to enter data into the tensors. Use the <code class="docutils literal notranslate"><span class="pre">Size</span></code> method of <code class="docutils literal notranslate"><span class="pre">MSTensor</span></code> to obtain the size of the data to be entered into tensors, use the <code class="docutils literal notranslate"><span class="pre">data_type</span></code> method to obtain the data type of <code class="docutils literal notranslate"><span class="pre">MSTensor</span></code>, and use the <code class="docutils literal notranslate"><span class="pre">MutableData</span></code> method of <code class="docutils literal notranslate"><span class="pre">MSTensor</span></code> to obtain the writable pointer.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">/// \brief  Get byte size of data in MSTensor.</span>
<span class="c1">///</span>
<span class="c1">/// \return  Byte size of data in MSTensor.</span>
<span class="k">virtual</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="nf">Size</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="c1">/// \brief  Get data type of the MindSpore Lite MSTensor.</span>
<span class="c1">///</span>
<span class="c1">/// \note  TypeId is defined in mindspore/mindspore/core/ir/dtype/type_id.h. Only number types in TypeId enum are</span>
<span class="c1">/// suitable for MSTensor.</span>
<span class="c1">///</span>
<span class="c1">/// \return  MindSpore Lite TypeId of the MindSpore Lite MSTensor.</span>
<span class="k">virtual</span><span class="w"> </span><span class="n">TypeId</span><span class="w"> </span><span class="nf">data_type</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="c1">/// \brief  Get the pointer of data in MSTensor.</span>
<span class="c1">///</span>
<span class="c1">/// \note The data pointer can be used to both write and read data in MSTensor.</span>
<span class="c1">///</span>
<span class="c1">/// \return  The pointer points to data in MSTensor.</span>
<span class="k">virtual</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="nf">MutableData</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</pre></div>
</div>
</section>
<section id="id5">
<h3>Example<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h3>
<p>The following sample code shows how to obtain the output <code class="docutils literal notranslate"><span class="pre">MSTensor</span></code> from <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> using the <code class="docutils literal notranslate"><span class="pre">GetOutputs</span></code> method and print the first ten data or all data records of each output <code class="docutils literal notranslate"><span class="pre">MSTensor</span></code>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Assume we have created a LiteSession instance named session before.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">output_map</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">GetOutputs</span><span class="p">();</span>
<span class="c1">// Assume that the model has only one output node.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">out_node_iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">output_map</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span>
<span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">out_node_iter</span><span class="o">-&gt;</span><span class="n">first</span><span class="p">;</span>
<span class="c1">// Assume that the unique output node has only one output tensor.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">out_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">out_node_iter</span><span class="o">-&gt;</span><span class="n">second</span><span class="p">;</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">out_tensor</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Output tensor is nullptr&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="p">}</span>
<span class="c1">// Assume that the data format of output data is float 32.</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">out_tensor</span><span class="o">-&gt;</span><span class="n">data_type</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">TypeId</span><span class="o">::</span><span class="n">kNumberTypeFloat32</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Output of lenet should in float32&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">auto</span><span class="w"> </span><span class="o">*</span><span class="n">out_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">out_tensor</span><span class="o">-&gt;</span><span class="n">MutableData</span><span class="p">());</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">out_data</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Data of out_tensor is nullptr&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="p">}</span>
<span class="c1">// Print the first 10 float data or all output data of the output tensor.</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Output data: &quot;</span><span class="p">;</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">10</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">out_tensor</span><span class="o">-&gt;</span><span class="n">ElementsNum</span><span class="p">();</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">out_data</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="c1">// The elements in outputs do not need to be free by users, because outputs are managed by the MindSpore Lite.</span>
</pre></div>
</div>
<p>Note that the vectors or map returned by the <code class="docutils literal notranslate"><span class="pre">GetOutputsByNodeName</span></code>, <code class="docutils literal notranslate"><span class="pre">GetOutputByTensorName</span></code> and <code class="docutils literal notranslate"><span class="pre">GetOutputs</span></code> methods do not need to be released by users.</p>
<p>The following sample code shows how to obtain the output <code class="docutils literal notranslate"><span class="pre">MSTensor</span></code> from <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> using the <code class="docutils literal notranslate"><span class="pre">GetOutputsByNodeName</span></code> method.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Assume we have created a LiteSession instance named session before.</span>
<span class="c1">// Assume that model has a output node named output_node_name_0.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">output_vec</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">GetOutputsByNodeName</span><span class="p">(</span><span class="s">&quot;output_node_name_0&quot;</span><span class="p">);</span>
<span class="c1">// Assume that output node named output_node_name_0 has only one output tensor.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">out_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">output_vec</span><span class="p">.</span><span class="n">front</span><span class="p">();</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">out_tensor</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Output tensor is nullptr&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The following sample code shows how to obtain the output <code class="docutils literal notranslate"><span class="pre">MSTensor</span></code> from <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> using the <code class="docutils literal notranslate"><span class="pre">GetOutputByTensorName</span></code> method.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Assume we have created a LiteSession instance named session.</span>
<span class="c1">// We can use GetOutputTensorNames method to get all name of output tensor of model which is in order.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tensor_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">GetOutputTensorNames</span><span class="p">();</span>
<span class="c1">// Assume we have created a LiteSession instance named session before.</span>
<span class="c1">// Use output tensor name returned by GetOutputTensorNames as key</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">tensor_name</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">tensor_names</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">out_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">GetOutputByTensorName</span><span class="p">(</span><span class="n">tensor_name</span><span class="p">);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">out_tensor</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Output tensor is nullptr&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="obtaining-version-string">
<h2>Obtaining Version String<a class="headerlink" href="#obtaining-version-string" title="Permalink to this headline"></a></h2>
<section id="id6">
<h3>Example<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<p>The following sample code shows how to obtain version string using <code class="docutils literal notranslate"><span class="pre">Version</span></code> method.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;include/version.h&quot;</span>
<span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">version</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">Version</span><span class="p">();</span>
</pre></div>
</div>
</section>
</section>
<section id="session-parallel-launch">
<h2>Session parallel launch<a class="headerlink" href="#session-parallel-launch" title="Permalink to this headline"></a></h2>
<p>MindSpore Lite supports multiple <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> parallel inferences, but does not support multiple threads calling the <code class="docutils literal notranslate"><span class="pre">RunGraph</span></code> interface of a single <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> at the same time.</p>
<section id="single-session-parallel-launch">
<h3>Single Session parallel launch<a class="headerlink" href="#single-session-parallel-launch" title="Permalink to this headline"></a></h3>
<p>MindSpore Lite does not support multi-threaded parallel calling of the inference interface of a single <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code>, otherwise we will get the following error message:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">ERROR</span><span class="w"> </span><span class="p">[</span><span class="n">mindspore</span><span class="o">/</span><span class="n">lite</span><span class="o">/</span><span class="n">src</span><span class="o">/</span><span class="n">lite_session</span><span class="p">.</span><span class="n">cc</span><span class="o">:</span><span class="mi">297</span><span class="p">]</span><span class="w"> </span><span class="n">RunGraph</span><span class="p">]</span><span class="w"> </span><span class="mi">10</span><span class="w"> </span><span class="n">Not</span><span class="w"> </span><span class="n">support</span><span class="w"> </span><span class="n">multi</span><span class="o">-</span><span class="n">threading</span>
</pre></div>
</div>
</section>
<section id="multiple-session-parallel-launch">
<h3>Multiple Session parallel launch<a class="headerlink" href="#multiple-session-parallel-launch" title="Permalink to this headline"></a></h3>
<p>MindSpore Lite supports multiple <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> in doing inference in parallel. The thread pool and memory pool of each <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> are independent.</p>
</section>
<section id="id7">
<h3>Example<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h3>
<p>The following code shows how to create multiple <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> and do inference in parallel:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;thread&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;src/common/file_utils.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;include/model.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;include/version.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;include/context.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;include/lite_session.h&quot;</span>

<span class="n">mindspore</span><span class="o">::</span><span class="n">session</span><span class="o">::</span><span class="n">LiteSession</span><span class="w"> </span><span class="o">*</span><span class="nf">GenerateSession</span><span class="p">(</span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">Model</span><span class="w"> </span><span class="o">*</span><span class="n">model</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">model</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Read model file failed while running&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">nothrow</span><span class="p">)</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">Context</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">context</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New context failed while running&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">session</span><span class="o">::</span><span class="n">LiteSession</span><span class="o">::</span><span class="n">CreateSession</span><span class="p">(</span><span class="n">context</span><span class="p">);</span>
<span class="w">  </span><span class="k">delete</span><span class="w"> </span><span class="p">(</span><span class="n">context</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">session</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;CreateSession failed while running&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">CompileGraph</span><span class="p">(</span><span class="n">model</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">RET_OK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;CompileGraph failed while running&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">delete</span><span class="w"> </span><span class="p">(</span><span class="n">session</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">msInputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">GetInputs</span><span class="p">();</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">msInput</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">msInputs</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">msInput</span><span class="o">-&gt;</span><span class="n">MutableData</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">session</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">argv</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">  </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">graphBuf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">ReadFile</span><span class="p">(</span><span class="s">&quot;test.ms&quot;</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">size</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">graphBuf</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Read model file failed while running&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">Model</span><span class="o">::</span><span class="n">Import</span><span class="p">(</span><span class="n">graphBuf</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">model</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Import model file failed while running&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">delete</span><span class="p">[](</span><span class="n">graphBuf</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">delete</span><span class="p">[](</span><span class="n">graphBuf</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">session1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GenerateSession</span><span class="p">(</span><span class="n">model</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">session1</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Generate session 1 failed&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">delete</span><span class="p">(</span><span class="n">model</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">session2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GenerateSession</span><span class="p">(</span><span class="n">model</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">session2</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Generate session 2 failed&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">delete</span><span class="p">(</span><span class="n">model</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">Free</span><span class="p">();</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="kr">thread</span><span class="w"> </span><span class="n">thread1</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](){</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session1</span><span class="o">-&gt;</span><span class="n">RunGraph</span><span class="p">();</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">status</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Inference error &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">status</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">      </span><span class="k">return</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Session1 inference success&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="p">});</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="kr">thread</span><span class="w"> </span><span class="n">thread2</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](){</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session2</span><span class="o">-&gt;</span><span class="n">RunGraph</span><span class="p">();</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">status</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Inference error &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">status</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">      </span><span class="k">return</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Session2 inference success&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="p">});</span>

<span class="w">  </span><span class="n">thread1</span><span class="p">.</span><span class="n">join</span><span class="p">();</span>
<span class="w">  </span><span class="n">thread2</span><span class="p">.</span><span class="n">join</span><span class="p">();</span>
<span class="w">  </span><span class="k">delete</span><span class="w"> </span><span class="p">(</span><span class="n">session1</span><span class="p">);</span>
<span class="w">  </span><span class="k">delete</span><span class="w"> </span><span class="p">(</span><span class="n">session2</span><span class="p">);</span>
<span class="w">  </span><span class="k">delete</span><span class="w"> </span><span class="p">(</span><span class="n">model</span><span class="p">);</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="image_processing.html" class="btn btn-neutral float-left" title="Preprocessing Image Data" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore Lite.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>