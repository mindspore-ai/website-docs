<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Simplified MindSpore Lite C++ Demo &mdash; MindSpore Lite master documentation</title>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/lite.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/lite.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Simplified MindSpore Lite Java Demo" href="quick_start_java.html" />
    <link rel="prev" title="Building MindSpore Lite" href="../use/build.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Obtain MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/downloads.html">Downloading MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/build.html">Building MindSpore Lite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Simplified MindSpore Lite C++ Demo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#building-and-running">Building and Running</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#linux-x86">Linux x86</a></li>
<li class="toctree-l3"><a class="reference internal" href="#windows">Windows</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#configure-cmake">Configure CMake</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-loading">Model Loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-build">Model Build</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-inference">Model Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="#memory-release">Memory Release</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_java.html">Simplified MindSpore Lite Java Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">Implementing an Image Classification Application (C++)</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_segmentation.html">Android Application Development Based on Java Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_codegen.html">Compile a MNIST Classification Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="train_lenet.html">Training a LeNet Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference on Devices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/converter_tool.html">Converting Models for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/code_generator.html">Code Generator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/post_training_quantization.html">Optimizing the Model (Quantization After Training)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preprocessing.html">Data Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/runtime.html">Executing Model Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/asic.html">Application Specific Integrated Circuit Integration Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/tools.html">Other Tools</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training on Devices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/converter_train.html">Creating MindSpore Lite Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/runtime_train.html">Executing Model Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/tools_train.html">Other Tools</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_lite.html">Lite Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_codegen.html">Codegen Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_lite.html">Model List</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Simplified MindSpore Lite C++ Demo</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/quick_start/quick_start_cpp.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="simplified-mindspore-lite-c-demo">
<h1>Simplified MindSpore Lite C++ Demo<a class="headerlink" href="#simplified-mindspore-lite-c-demo" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Windows</span></code> <code class="docutils literal notranslate"><span class="pre">x86</span></code> <code class="docutils literal notranslate"><span class="pre">C++</span></code> <code class="docutils literal notranslate"><span class="pre">Whole</span> <span class="pre">Process``Inference</span> <span class="pre">Application</span></code> <code class="docutils literal notranslate"><span class="pre">Data</span> <span class="pre">Preparation</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/lite/source_en/quick_start/quick_start_cpp.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>This tutorial provides a MindSpore Lite inference demo. It demonstrates the basic on-device inference process using C++ by inputting random data, executing inference, and printing the inference result. You can quickly understand how to use inference-related APIs on MindSpore Lite. In this tutorial, the randomly generated data is used as the input data to perform the inference on the MobileNetV2 model and print the output data. The code is stored in the <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.2/mindspore/lite/examples/quick_start_cpp">mindspore/lite/examples/quick_start_cpp</a> directory.</p>
<p>The MindSpore Lite inference steps are as follows:</p>
<ol class="arabic simple">
<li><p>Load the model: Read the <code class="docutils literal notranslate"><span class="pre">.ms</span></code> model converted by the <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.2/use/converter_tool.html">model conversion tool</a> from the file system, import the model by using <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.2/lite.html#import">mindspore::lite::Model::Import</a>, parse the model, and create the <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">*</span></code>.</p></li>
<li><p>Create and configure context: Create and configure <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.2/lite.html#context">context</a> to save some basic configuration parameters required by a session to guide graph build and execution.</p></li>
<li><p>Create a session: Create <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.2/session.html#litesession">LiteSession</a> and configure the <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.2/lite.html#context">context</a> obtained in the previous step to the session.</p></li>
<li><p>Build a graph: Before performing inference, call the <code class="docutils literal notranslate"><span class="pre">CompileGraph</span></code> API of <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.2/session.html#litesession">LiteSession</a> to build a graph. In the graph build phase, subgraph partition and operator selection and scheduling are performed, which takes a long time. Therefore, it is recommended that with one <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.2/session.html#litesession">LiteSession</a> created, one graph be built. In this case, the inference will be performed for multiple times.</p></li>
<li><p>Input data: Before the graph is executed, data needs to be filled in the <code class="docutils literal notranslate"><span class="pre">Input</span> <span class="pre">Tensor</span></code>.</p></li>
<li><p>Perform inference: Use <code class="docutils literal notranslate"><span class="pre">RunGraph</span></code> of the <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.2/session.html#litesession">LiteSession</a> to perform model inference.</p></li>
<li><p>Obtain the output: After the graph execution is complete, you can obtain the inference result by <code class="docutils literal notranslate"><span class="pre">outputting</span> <span class="pre">the</span> <span class="pre">tensor</span></code>.</p></li>
<li><p>Release the memory: If the MindSpore Lite inference framework is not required, release the created <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.2/session.html#litesession">LiteSession</a> and <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.2/lite.html#model">Model</a>.</p></li>
</ol>
<p><img alt="img" src="../_images/lite_runtime.png" /></p>
<blockquote>
<div><p>To view the advanced usage of MindSpore Lite, see <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.2/use/runtime_cpp.html">Using Runtime to Perform Inference (C++)</a>].</p>
</div></blockquote>
</section>
<section id="building-and-running">
<h2>Building and Running<a class="headerlink" href="#building-and-running" title="Permalink to this headline"></a></h2>
<section id="linux-x86">
<h3>Linux x86<a class="headerlink" href="#linux-x86" title="Permalink to this headline"></a></h3>
<ul>
<li><p>Environment requirements</p>
<ul class="simple">
<li><p>System environment: Linux x86_64 (Ubuntu 18.04.02LTS is recommended.)</p></li>
<li><p>Build dependency:</p>
<ul>
<li><p><a class="reference external" href="https://cmake.org/download/">CMake</a> &gt;= 3.14</p></li>
<li><p><a class="reference external" href="https://gcc.gnu.org/releases.html">GCC</a> &gt;= 7.3.0</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Build</p>
<p>Run the <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/quick_start_cpp/build.sh">build script</a> in the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_cpp</span></code> directory to automatically download the MindSpore Lite inference framework library and model files and build the demo.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>build.sh
</pre></div>
</div>
<blockquote>
<div><p>If the MindSpore Lite inference framework fails to be downloaded by using this build script, manually download the MindSpore Lite model inference framework <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.2/use/downloads.html">mindspore-lite-{version}-linux-x64.tar.gz</a> whose hardware platform is CPU and operating system is Ubuntu-x64, and copy the <code class="docutils literal notranslate"><span class="pre">libmindspore-lite.a</span></code> file in the decompressed lib directory to the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_cpp/lib</span></code> directory. Also copy the files from <code class="docutils literal notranslate"><span class="pre">inference/include</span></code> to the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_cpp/include</span></code> directory.</p>
<p>If the MobileNetV2 model fails to be downloaded, manually download the model file <a class="reference external" href="https://download.mindspore.cn/model_zoo/official/lite/mobilenetv2_imagenet/mobilenetv2.ms">mobilenetv2.ms</a> and copy it to the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_cpp/model</span></code> directory.</p>
<p>After manually downloading and placing the file in the specified location, you need to execute the build.sh script again to complete the compilation.</p>
</div></blockquote>
</li>
<li><p>Inference</p>
<p>After the build, go to the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_cpp/build</span></code> directory and run the following command to experience MindSpore Lite inference on the MobileNetV2 model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./mindspore_quick_start_cpp<span class="w"> </span>../model/mobilenetv2.ms
</pre></div>
</div>
<p>After the execution, the following information is displayed, including the tensor name, tensor size, number of output tensors, and the first 50 pieces of data.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>tensor<span class="w"> </span>name<span class="w"> </span>is:Default/head-MobileNetV2Head/Softmax-op204<span class="w"> </span>tensor<span class="w"> </span>size<span class="w"> </span>is:4000<span class="w"> </span>tensor<span class="w"> </span>elements<span class="w"> </span>num<span class="w"> </span>is:1000
output<span class="w"> </span>data<span class="w"> </span>is:5.26823e-05<span class="w"> </span><span class="m">0</span>.00049752<span class="w"> </span><span class="m">0</span>.000296722<span class="w"> </span><span class="m">0</span>.000377607<span class="w"> </span><span class="m">0</span>.000177048<span class="w"> </span><span class="m">8</span>.02107e-05<span class="w"> </span><span class="m">0</span>.000212864<span class="w"> </span><span class="m">0</span>.000422286<span class="w"> </span><span class="m">0</span>.000273189<span class="w"> </span><span class="m">0</span>.000234105<span class="w"> </span><span class="m">0</span>.00099807<span class="w"> </span><span class="m">0</span>.0042331<span class="w"> </span><span class="m">0</span>.00204993<span class="w"> </span><span class="m">0</span>.00124968<span class="w"> </span><span class="m">0</span>.00294458<span class="w"> </span><span class="m">0</span>.00139795<span class="w"> </span><span class="m">0</span>.00111545<span class="w"> </span><span class="m">0</span>.000656357<span class="w"> </span><span class="m">0</span>.000809457<span class="w"> </span><span class="m">0</span>.00153731<span class="w"> </span><span class="m">0</span>.000621049<span class="w"> </span><span class="m">0</span>.00224637<span class="w"> </span><span class="m">0</span>.00127045<span class="w"> </span><span class="m">0</span>.00187557<span class="w"> </span><span class="m">0</span>.000420144<span class="w"> </span><span class="m">0</span>.000150638<span class="w"> </span><span class="m">0</span>.000266477<span class="w"> </span><span class="m">0</span>.000438628<span class="w"> </span><span class="m">0</span>.000187773<span class="w"> </span><span class="m">0</span>.00054668<span class="w"> </span><span class="m">0</span>.000212853<span class="w"> </span><span class="m">0</span>.000921661<span class="w"> </span><span class="m">0</span>.000127179<span class="w"> </span><span class="m">0</span>.000565873<span class="w"> </span><span class="m">0</span>.00100394<span class="w"> </span><span class="m">0</span>.000300159<span class="w"> </span><span class="m">0</span>.000282677<span class="w"> </span><span class="m">0</span>.000358067<span class="w"> </span><span class="m">0</span>.00215288<span class="w"> </span><span class="m">0</span>.000477845<span class="w"> </span><span class="m">0</span>.00107596<span class="w"> </span><span class="m">0</span>.00065134<span class="w"> </span><span class="m">0</span>.000722132<span class="w"> </span><span class="m">0</span>.000807501<span class="w"> </span><span class="m">0</span>.000631415<span class="w"> </span><span class="m">0</span>.00043247<span class="w"> </span><span class="m">0</span>.00125898<span class="w"> </span><span class="m">0</span>.000255094<span class="w"> </span><span class="m">8</span>.2606e-05<span class="w"> </span><span class="m">9</span>.91917e-05<span class="w"> </span><span class="m">0</span>.000794512
</pre></div>
</div>
</li>
</ul>
</section>
<section id="windows">
<h3>Windows<a class="headerlink" href="#windows" title="Permalink to this headline"></a></h3>
<ul>
<li><p>Environment requirements</p>
<ul class="simple">
<li><p>System environment: 64-bit Windows 7 or 64-bit Windows 10</p></li>
<li><p>Build dependency:</p>
<ul>
<li><p><a class="reference external" href="https://cmake.org/download/">CMake</a> &gt;= 3.14</p></li>
<li><p><a class="reference external" href="https://sourceforge.net/projects/mingw-w64/files/ToolchainstargettingWin64/PersonalBuilds/mingw-builds/7.3.0/threads-posix/seh/x86_64-7.3.0-release-posix-seh-rt_v5-rev0.7z/download">MinGW GCC</a> = 7.3.0</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Build</p>
<ul class="simple">
<li><p>Download the library: Manually download the MindSpore Lite model inference framework <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.2/use/downloads.html">mindspore-lite-{version}-win-x64.zip</a> whose hardware platform is CPU and operating system is Windows-x64. Copy the <code class="docutils literal notranslate"><span class="pre">libmindspore-lite.a</span></code> file in the decompressed <code class="docutils literal notranslate"><span class="pre">inference/lib</span></code> directory to the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_cpp/lib</span></code> project directory, and change the include directory to the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_cpp/include</span></code> project directory. (Note: The <code class="docutils literal notranslate"><span class="pre">lib</span></code> and <code class="docutils literal notranslate"><span class="pre">include</span></code> directories under the project need to be created manually)</p></li>
<li><p>Download the model: Manually download the model file <a class="reference external" href="https://download.mindspore.cn/model_zoo/official/lite/mobilenetv2_imagenet/mobilenetv2.ms">mobilenetv2.ms</a> and copy it to the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_cpp/model</span></code> directory.</p></li>
<li><p>Build the demo: Run the <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/quick_start_cpp/build.bat">build script</a> in the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_cpp</span></code> directory to automatically download related files and build the Demo.</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>call<span class="w"> </span>build.bat
</pre></div>
</div>
</li>
<li><p>Inference</p>
<p>After the build, go to the <code class="docutils literal notranslate"><span class="pre">mindspore/lite/examples/quick_start_cpp/build</span></code> directory and run the following command to experience MindSpore Lite inference on the MobileNetV2 model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>call<span class="w"> </span>mindspore_quick_start_cpp.exe<span class="w"> </span>../model/mobilenetv2.ms
</pre></div>
</div>
<p>After the execution, the following information is displayed, including the tensor name, tensor size, number of output tensors, and the first 50 pieces of data.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>tensor<span class="w"> </span>name<span class="w"> </span>is:Default/head-MobileNetV2Head/Softmax-op204<span class="w"> </span>tensor<span class="w"> </span>size<span class="w"> </span>is:4000<span class="w"> </span>tensor<span class="w"> </span>elements<span class="w"> </span>num<span class="w"> </span>is:1000
output<span class="w"> </span>data<span class="w"> </span>is:5.26823e-05<span class="w"> </span><span class="m">0</span>.00049752<span class="w"> </span><span class="m">0</span>.000296722<span class="w"> </span><span class="m">0</span>.000377607<span class="w"> </span><span class="m">0</span>.000177048<span class="w"> </span><span class="m">8</span>.02107e-05<span class="w"> </span><span class="m">0</span>.000212864<span class="w"> </span><span class="m">0</span>.000422286<span class="w"> </span><span class="m">0</span>.000273189<span class="w"> </span><span class="m">0</span>.000234105<span class="w"> </span><span class="m">0</span>.00099807<span class="w"> </span><span class="m">0</span>.0042331<span class="w"> </span><span class="m">0</span>.00204993<span class="w"> </span><span class="m">0</span>.00124968<span class="w"> </span><span class="m">0</span>.00294458<span class="w"> </span><span class="m">0</span>.00139795<span class="w"> </span><span class="m">0</span>.00111545<span class="w"> </span><span class="m">0</span>.000656357<span class="w"> </span><span class="m">0</span>.000809457<span class="w"> </span><span class="m">0</span>.00153731<span class="w"> </span><span class="m">0</span>.000621049<span class="w"> </span><span class="m">0</span>.00224637<span class="w"> </span><span class="m">0</span>.00127045<span class="w"> </span><span class="m">0</span>.00187557<span class="w"> </span><span class="m">0</span>.000420144<span class="w"> </span><span class="m">0</span>.000150638<span class="w"> </span><span class="m">0</span>.000266477<span class="w"> </span><span class="m">0</span>.000438628<span class="w"> </span><span class="m">0</span>.000187773<span class="w"> </span><span class="m">0</span>.00054668<span class="w"> </span><span class="m">0</span>.000212853<span class="w"> </span><span class="m">0</span>.000921661<span class="w"> </span><span class="m">0</span>.000127179<span class="w"> </span><span class="m">0</span>.000565873<span class="w"> </span><span class="m">0</span>.00100394<span class="w"> </span><span class="m">0</span>.000300159<span class="w"> </span><span class="m">0</span>.000282677<span class="w"> </span><span class="m">0</span>.000358067<span class="w"> </span><span class="m">0</span>.00215288<span class="w"> </span><span class="m">0</span>.000477845<span class="w"> </span><span class="m">0</span>.00107596<span class="w"> </span><span class="m">0</span>.00065134<span class="w"> </span><span class="m">0</span>.000722132<span class="w"> </span><span class="m">0</span>.000807501<span class="w"> </span><span class="m">0</span>.000631415<span class="w"> </span><span class="m">0</span>.00043247<span class="w"> </span><span class="m">0</span>.00125898<span class="w"> </span><span class="m">0</span>.000255094<span class="w"> </span><span class="m">8</span>.2606e-05<span class="w"> </span><span class="m">9</span>.91917e-05<span class="w"> </span><span class="m">0</span>.000794512
</pre></div>
</div>
</li>
</ul>
</section>
</section>
<section id="configure-cmake">
<h2>Configure CMake<a class="headerlink" href="#configure-cmake" title="Permalink to this headline"></a></h2>
<p>The following is the sample code when integrating <code class="docutils literal notranslate"><span class="pre">libmindspore-lite.a</span></code> static library through CMake.</p>
<blockquote>
<div><p>When CMake integrates the <code class="docutils literal notranslate"><span class="pre">libmindspore-lite.a</span></code> static library, the <code class="docutils literal notranslate"><span class="pre">-Wl,--whole-archive</span></code> option needs to be passed to the linker.</p>
<p>In addition, the build option for stack protection <code class="docutils literal notranslate"><span class="pre">-fstack-protector-strong</span></code> is added during the build of MindSpore Lite. Therefore, the <code class="docutils literal notranslate"><span class="pre">ssp</span></code> library in MinGW needs to be linked on the Windows platform.</p>
</div></blockquote>
<div class="highlight-cmake notranslate"><div class="highlight"><pre><span></span><span class="nb">cmake_minimum_required</span><span class="p">(</span><span class="s">VERSION</span><span class="w"> </span><span class="s">3.14</span><span class="p">)</span>
<span class="nb">project</span><span class="p">(</span><span class="s">QuickStartCpp</span><span class="p">)</span>

<span class="nb">if</span><span class="p">(</span><span class="s">CMAKE_CXX_COMPILER_ID</span><span class="w"> </span><span class="s">STREQUAL</span><span class="w"> </span><span class="s2">&quot;GNU&quot;</span><span class="w"> </span><span class="s">AND</span><span class="w"> </span><span class="s">CMAKE_CXX_COMPILER_VERSION</span><span class="w"> </span><span class="s">VERSION_LESS</span><span class="w"> </span><span class="s">7.3.0</span><span class="p">)</span>
<span class="w">    </span><span class="nb">message</span><span class="p">(</span><span class="s">FATAL_ERROR</span><span class="w"> </span><span class="s2">&quot;GCC version ${CMAKE_CXX_COMPILER_VERSION} must not be less than 7.3.0&quot;</span><span class="p">)</span>
<span class="nb">endif</span><span class="p">()</span>

<span class="c"># Add the directory to include search path</span>
<span class="nb">include_directories</span><span class="p">(</span><span class="o">${</span><span class="nv">CMAKE_CURRENT_SOURCE_DIR</span><span class="o">}</span><span class="p">)</span>

<span class="c"># Add the directory to link search path</span>
<span class="nb">link_directories</span><span class="p">(</span><span class="o">${</span><span class="nv">CMAKE_CURRENT_SOURCE_DIR</span><span class="o">}</span><span class="s">/lib</span><span class="p">)</span>

<span class="nb">file</span><span class="p">(</span><span class="s">GLOB_RECURSE</span><span class="w"> </span><span class="s">QUICK_START_CXX</span><span class="w"> </span><span class="o">${</span><span class="nv">CMAKE_CURRENT_SOURCE_DIR</span><span class="o">}</span><span class="s">/*.cc</span><span class="p">)</span>
<span class="nb">add_executable</span><span class="p">(</span><span class="s">mindspore_quick_start_cpp</span><span class="w"> </span><span class="o">${</span><span class="nv">QUICK_START_CXX</span><span class="o">}</span><span class="p">)</span>

<span class="nb">target_link_libraries</span><span class="p">(</span>
<span class="w">        </span><span class="s">mindspore_quick_start_cpp</span>
<span class="w">        </span><span class="s">-Wl,--whole-archive</span><span class="w"> </span><span class="s">mindspore-lite</span><span class="w"> </span><span class="s">-Wl,--no-whole-archive</span>
<span class="w">        </span><span class="s">pthread</span>
<span class="p">)</span>

<span class="c"># Due to the increased compilation options for stack protection,</span>
<span class="c"># it is necessary to target link ssp library when Use the static library in Windows.</span>
<span class="nb">if</span><span class="p">(</span><span class="s">WIN32</span><span class="p">)</span>
<span class="w">    </span><span class="nb">target_link_libraries</span><span class="p">(</span>
<span class="w">            </span><span class="s">mindspore_quick_start_cpp</span>
<span class="w">            </span><span class="s">ssp</span>
<span class="w">    </span><span class="p">)</span>
<span class="nb">endif</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="model-loading">
<h2>Model Loading<a class="headerlink" href="#model-loading" title="Permalink to this headline"></a></h2>
<p>Read the MindSpore Lite model from the file system and use the <code class="docutils literal notranslate"><span class="pre">mindspore::lite::Model::Import</span></code> function to import the model for parsing.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Read model file.</span>
<span class="kt">size_t</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">model_buf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ReadFile</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">size</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">model_buf</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Read model file failed.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="p">}</span>
<span class="c1">// Load the .ms model.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">Model</span><span class="o">::</span><span class="n">Import</span><span class="p">(</span><span class="n">model_buf</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="k">delete</span><span class="p">[](</span><span class="n">model_buf</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">model</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Import model file failed.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="model-build">
<h2>Model Build<a class="headerlink" href="#model-build" title="Permalink to this headline"></a></h2>
<p>Model build includes context configuration creation, session creation, and graph build.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">mindspore</span><span class="o">::</span><span class="n">session</span><span class="o">::</span><span class="n">LiteSession</span><span class="w"> </span><span class="o">*</span><span class="nf">Compile</span><span class="p">(</span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">Model</span><span class="w"> </span><span class="o">*</span><span class="n">model</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Create and init context.</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">Context</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">context</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;New context failed while.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Create the session.</span>
<span class="w">  </span><span class="n">mindspore</span><span class="o">::</span><span class="n">session</span><span class="o">::</span><span class="n">LiteSession</span><span class="w"> </span><span class="o">*</span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">session</span><span class="o">::</span><span class="n">LiteSession</span><span class="o">::</span><span class="n">CreateSession</span><span class="p">(</span><span class="n">context</span><span class="p">.</span><span class="n">get</span><span class="p">());</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">session</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;CreateSession failed while running.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Build a graph.</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">CompileGraph</span><span class="p">(</span><span class="n">model</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">RET_OK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">delete</span><span class="w"> </span><span class="n">session</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Compile failed while running.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Note: when use model-&gt;Free(), the model can not be compiled again.</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">model</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">Free</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">session</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="model-inference">
<h2>Model Inference<a class="headerlink" href="#model-inference" title="Permalink to this headline"></a></h2>
<p>Model inference includes data input, inference execution, and output obtaining. In this example, the input data is randomly generated, and the output result is printed after inference.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">Run</span><span class="p">(</span><span class="n">mindspore</span><span class="o">::</span><span class="n">session</span><span class="o">::</span><span class="n">LiteSession</span><span class="w"> </span><span class="o">*</span><span class="n">session</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">GetInputs</span><span class="p">();</span>

<span class="w">  </span><span class="c1">// Generate random data as input data.</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GenerateInputDataWithRandom</span><span class="p">(</span><span class="n">inputs</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">RET_OK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Generate Random Input Data failed.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">ret</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Run Inference.</span>
<span class="w">  </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">RunGraph</span><span class="p">();</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">RET_OK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Inference error &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">ret</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Get Output Tensor Data.</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">out_tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="o">-&gt;</span><span class="n">GetOutputs</span><span class="p">();</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">out_tensors</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;tensor name is:&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">first</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; tensor size is:&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">second</span><span class="o">-&gt;</span><span class="n">Size</span><span class="p">()</span>
<span class="w">              </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; tensor elements num is:&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">second</span><span class="o">-&gt;</span><span class="n">ElementsNum</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">out_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="n">second</span><span class="o">-&gt;</span><span class="n">MutableData</span><span class="p">());</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;output data is:&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">second</span><span class="o">-&gt;</span><span class="n">ElementsNum</span><span class="p">()</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">50</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">out_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">RET_OK</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="memory-release">
<h2>Memory Release<a class="headerlink" href="#memory-release" title="Permalink to this headline"></a></h2>
<p>If the MindSpore Lite inference framework is not required, release the created <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code> and <code class="docutils literal notranslate"><span class="pre">Model</span></code>.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Delete model buffer.</span>
<span class="k">delete</span><span class="w"> </span><span class="n">model</span><span class="p">;</span>
<span class="c1">// Delete session buffer.</span>
<span class="k">delete</span><span class="w"> </span><span class="n">session</span><span class="p">;</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../use/build.html" class="btn btn-neutral float-left" title="Building MindSpore Lite" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="quick_start_java.html" class="btn btn-neutral float-right" title="Simplified MindSpore Lite Java Demo" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore Lite.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>