

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Converting Models for Inference &mdash; MindSpore Lite master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/lite.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/js/lite.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Code Generator" href="code_generator.html" />
    <link rel="prev" title="Training a LeNet Model" href="../quick_start/train_lenet.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore Lite
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Obtain MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="downloads.html">Downloading MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="build.html">Building MindSpore Lite</a></li>
</ul>
<p class="caption"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_cpp.html">Simplified MindSpore Lite C++ Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_java.html">Simplified MindSpore Lite Java Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application (C++)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/image_segmentation.html">Android Application Development Based on Java Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_codegen.html">Compile a MNIST Classification Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/train_lenet.html">Training a LeNet Model</a></li>
</ul>
<p class="caption"><span class="caption-text">Inference on Devices</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Converting Models for Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#linux-environment-instructions">Linux Environment Instructions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#environment-preparation">Environment Preparation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parameter-description">Parameter Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#windows-environment-instructions">Windows Environment Instructions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Environment Preparation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">Parameter Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="code_generator.html">Code Generator</a></li>
<li class="toctree-l1"><a class="reference internal" href="post_training_quantization.html">Optimizing the Model (Quantization After Training)</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_preprocessing.html">Data Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">Executing Model Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="asic.html">Application Specific Integrated Circuit Integration Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">Other Tools</a></li>
</ul>
<p class="caption"><span class="caption-text">Training on Devices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="converter_train.html">Creating MindSpore Lite Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime_train.html">Executing Model Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools_train.html">Other Tools</a></li>
</ul>
<p class="caption"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_lite.html">Lite Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_codegen.html">Codegen Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_lite.html">Model List</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Converting Models for Inference</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/use/converter_tool.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="converting-models-for-inference">
<h1>Converting Models for Inference<a class="headerlink" href="#converting-models-for-inference" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Windows</span></code> <code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Converting</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<!-- TOC -->
<ul class="simple">
<li><p><a class="reference external" href="#converting-models-for-inference">Converting Models for Inference</a></p>
<ul>
<li><p><a class="reference external" href="#overview">Overview</a></p></li>
<li><p><a class="reference external" href="#linux-environment-instructions">Linux Environment Instructions</a></p>
<ul>
<li><p><a class="reference external" href="#environment-preparation">Environment Preparation</a></p></li>
<li><p><a class="reference external" href="#parameter-description">Parameter Description</a></p></li>
<li><p><a class="reference external" href="#example">Example</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#windows-environment-instructions">Windows Environment Instructions</a></p>
<ul>
<li><p><a class="reference external" href="#environment-preparation-1">Environment Preparation</a></p></li>
<li><p><a class="reference external" href="#parameter-description-1">Parameter Description</a></p></li>
<li><p><a class="reference external" href="#example-1">Example</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- /TOC -->
<p><a href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/lite/source_en/use/converter_tool.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>MindSpore Lite provides a tool for offline model conversion. It supports conversion of multiple types of models. The converted models can be used for inference. The command line parameters contain multiple personalized options, providing a convenient conversion method for users.</p>
<p>Currently, the following input formats are supported: MindSpore, TensorFlow Lite, Caffe, TensorFlow and ONNX.</p>
<p>The ms model converted by the conversion tool supports the conversion tool and the higher version of the Runtime framework to perform inference.</p>
</div>
<div class="section" id="linux-environment-instructions">
<h2>Linux Environment Instructions<a class="headerlink" href="#linux-environment-instructions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="environment-preparation">
<h3>Environment Preparation<a class="headerlink" href="#environment-preparation" title="Permalink to this headline">¶</a></h3>
<p>To use the MindSpore Lite model conversion tool, you need to prepare the environment as follows:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.2/use/build.html">Compile</a> or <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.2/use/downloads.html">download</a> model transfer tool.</p></li>
<li><p>Configure environment variables, refer to <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.2/use/build.html">Configure converter</a>.</p></li>
</ul>
</div>
<div class="section" id="parameter-description">
<h3>Parameter Description<a class="headerlink" href="#parameter-description" title="Permalink to this headline">¶</a></h3>
<p>MindSpore Lite model conversion tool provides multiple parameters.
You can enter <code class="docutils literal notranslate"><span class="pre">./converter_lite</span> <span class="pre">--help</span></code> to obtain the help information in real time.</p>
<p>The following describes the parameters in detail.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Parameter</th>
<th>Mandatory or Not</th>
<th>Parameter Description</th>
<th>Value Range</th>
<th>Default Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--help</code></td>
<td>No</td>
<td>Prints all the help information.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td><code>--fmk=&lt;FMK&gt;</code></td>
<td>Yes</td>
<td>Original format of the input model.</td>
<td>MINDIR, CAFFE, TFLITE, TF, or ONNX</td>
<td>-</td>
</tr>
<tr>
<td><code>--modelFile=&lt;MODELFILE&gt;</code></td>
<td>Yes</td>
<td>Path of the input model.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td><code>--outputFile=&lt;OUTPUTFILE&gt;</code></td>
<td>Yes</td>
<td>Path of the output model. The suffix <code>.ms</code> can be automatically generated.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td><code>--weightFile=&lt;WEIGHTFILE&gt;</code></td>
<td>Yes (for Caffe models only)</td>
<td>Path of the weight file of the input model.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td><code>--quantType=&lt;QUANTTYPE&gt;</code></td>
<td>No</td>
<td>Sets the quantization type of the model.</td>
<td>PostTraining: quantization after training <br>WeightQuant: only do weight quantization after training</td>
<td>-</td>
</tr>
<tr>
<td><code>--bitNum=&lt;BITNUM&gt;</code></td>
<td>No</td>
<td>Sets the quantization bitNum when quantType is set as WeightQuant, now supports 1 bit to 16 bit quantization.</td>
<td>[1, 16]</td>
<td>8</td>
</tr>
<tr>
<td><code>--quantWeightSize=&lt;QUANTWEIGHTSIZE&gt;</code></td>
<td>No</td>
<td>Sets a size threshold of convolution filter when quantType is set as WeightQuant. If the size is bigger than this value, it will trigger weight quantization.</td>
<td>[0, +∞)</td>
<td>0</td>
</tr>
<tr>
<td><code>--quantWeightChannel=&lt;QUANTWEIGHTCHANNEL&gt;</code></td>
<td>No</td>
<td>Sets a channel number threshold of convolution filter when quantType is set as WeightQuant. If the number is bigger than this, it will trigger weight quantization.</td>
<td>[0, +∞)</td>
<td>16</td>
</tr>
<tr>
<td><code>--configFile=&lt;CONFIGFILE&gt;</code></td>
<td>No</td>
<td>Profile path of calibration dataset when quantType is set as PostTraining.</td>
<td>-</td>
<td>-</td>
</tr>
</tbody>
</table>
<blockquote>
<div><ul class="simple">
<li><p>The parameter name and parameter value are separated by an equal sign (=) and no space is allowed between them.</p></li>
<li><p>The Caffe model is divided into two files: model structure <code class="docutils literal notranslate"><span class="pre">*.prototxt</span></code>, corresponding to the <code class="docutils literal notranslate"><span class="pre">--modelFile</span></code> parameter; model weight <code class="docutils literal notranslate"><span class="pre">*.caffemodel</span></code>, corresponding to the <code class="docutils literal notranslate"><span class="pre">--weightFile</span></code> parameter.</p></li>
<li><p>In order to ensure the accuracy of weight quantization, the “–bitNum” parameter should better be set to a range from 8bit to 16bit.</p></li>
<li><p>PostTraining method currently only supports activation quantization and weight quantization in 8 bit.</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="example">
<h3>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h3>
<p>First, in the root directory of the source code, run the following command to perform compilation.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash build.sh -I x86_64
</pre></div>
</div>
<blockquote>
<div><p>Currently, the model conversion tool supports only the x86_64 architecture.</p>
</div></blockquote>
<p>The following describes how to use the conversion command by using several common examples.</p>
<ul>
<li><p>Take the Caffe model LeNet as an example. Run the following conversion command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite --fmk<span class="o">=</span>CAFFE --modelFile<span class="o">=</span>lenet.prototxt --weightFile<span class="o">=</span>lenet.caffemodel --outputFile<span class="o">=</span>lenet
</pre></div>
</div>
<p>In this example, the Caffe model is used. Therefore, the model structure and model weight files are required. Two more parameters <code class="docutils literal notranslate"><span class="pre">fmk</span></code> and <code class="docutils literal notranslate"><span class="pre">outputFile</span></code> are also required.</p>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>CONVERTER RESULT SUCCESS:0
</pre></div>
</div>
<p>This indicates that the Caffe model is successfully converted into the MindSpore Lite model and the new file <code class="docutils literal notranslate"><span class="pre">lenet.ms</span></code> is generated.</p>
</li>
<li><p>The following uses the MindSpore, TensorFlow Lite, ONNX models as examples to describe how to run the conversion command.</p>
<ul>
<li><p>MindSpore model <code class="docutils literal notranslate"><span class="pre">model.mindir</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite --fmk<span class="o">=</span>MINDIR --modelFile<span class="o">=</span>model.mindir --outputFile<span class="o">=</span>model
</pre></div>
</div>
</li>
</ul>
<blockquote>
<div><p>The <code class="docutils literal notranslate"><span class="pre">MindIR</span></code> model exported by MindSpore v1.1.1 or earlier is recommended to be converted to the <code class="docutils literal notranslate"><span class="pre">ms</span></code> model using the converter tool of the corresponding version. MindSpore v1.1.1 and later versions, the converter tool will be forward compatible.</p>
</div></blockquote>
<ul>
<li><p>TensorFlow Lite model <code class="docutils literal notranslate"><span class="pre">model.tflite</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite --fmk<span class="o">=</span>TFLITE --modelFile<span class="o">=</span>model.tflite --outputFile<span class="o">=</span>model
</pre></div>
</div>
</li>
<li><p>TensorFlow model <code class="docutils literal notranslate"><span class="pre">model.pb</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite --fmk<span class="o">=</span>TF --modelFile<span class="o">=</span>model.pb --outputFile<span class="o">=</span>model
</pre></div>
</div>
</li>
<li><p>ONNX model <code class="docutils literal notranslate"><span class="pre">model.onnx</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite --fmk<span class="o">=</span>ONNX --modelFile<span class="o">=</span>model.onnx --outputFile<span class="o">=</span>model
</pre></div>
</div>
</li>
</ul>
<p>In the preceding scenarios, the following information is displayed, indicating that the conversion is successful. In addition, the target file <code class="docutils literal notranslate"><span class="pre">model.ms</span></code> is obtained.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>CONVERTER RESULT SUCCESS:0
</pre></div>
</div>
</li>
<li><p>If running the conversion command is failed, an <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.2/errorcode_and_metatype.html">errorcode</a> will be output.</p></li>
</ul>
</div>
</div>
<div class="section" id="windows-environment-instructions">
<h2>Windows Environment Instructions<a class="headerlink" href="#windows-environment-instructions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id1">
<h3>Environment Preparation<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>To use the MindSpore Lite model conversion tool, the following environment preparations are required.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.2/use/build.html">Compile</a> or <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.2/use/downloads.html">download</a> model transfer tool.</p></li>
<li><p>Configure environment variables, refer to <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.2/use/build.html">Configure converter</a>.</p></li>
</ul>
</div>
<div class="section" id="id2">
<h3>Parameter Description<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>Refer to the Linux environment model conversion tool <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.2/use/converter_tool.html#parameter-description">parameter description</a>.</p>
</div>
<div class="section" id="id3">
<h3>Example<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>Set the log printing level to INFO.</p>
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span><span class="k">set</span> <span class="nv">GLOG_v</span><span class="p">=</span>1
</pre></div>
</div>
<blockquote>
<div><p>Log level: 0 is DEBUG, 1 is INFO, 2 is WARNING, 3 is ERROR.</p>
</div></blockquote>
<p>Several common examples are selected below to illustrate the use of conversion commands.</p>
<ul>
<li><p>Take the Caffe model LeNet as an example to execute the conversion command.</p>
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span><span class="k">call</span> converter_lite --fmk=CAFFE --modelFile=lenet.prototxt --weightFile=lenet.caffemodel --outputFile=lenet
</pre></div>
</div>
<p>In this example, because the Caffe model is used, two input files of model structure and model weight are required. Then with the fmk type and output path two parameters which are required, you can successfully execute.</p>
<p>The result is shown as:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>CONVERTER RESULT SUCCESS:0
</pre></div>
</div>
<p>This means that the Caffe model has been successfully converted to the MindSpore Lite model and the new file <code class="docutils literal notranslate"><span class="pre">lenet.ms</span></code> has been obtained.</p>
</li>
<li><p>Take MindSpore, TensorFlow Lite, ONNX model format and perceptual quantization model as examples to execute conversion commands.</p>
<ul>
<li><p>MindSpore model <code class="docutils literal notranslate"><span class="pre">model.mindir</span></code></p>
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span><span class="k">call</span> converter_lite --fmk=MINDIR --modelFile=model.mindir --outputFile=model
</pre></div>
</div>
</li>
</ul>
<blockquote>
<div><p>The <code class="docutils literal notranslate"><span class="pre">MindIR</span></code> model exported by MindSpore v1.1.1 or earlier is recommended to be converted to the <code class="docutils literal notranslate"><span class="pre">ms</span></code> model using the converter tool of the corresponding version. MindSpore v1.1.1 and later versions, the converter tool will be forward compatible.</p>
</div></blockquote>
<ul>
<li><p>TensorFlow Lite model<code class="docutils literal notranslate"><span class="pre">model.tflite</span></code></p>
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span><span class="k">call</span> converter_lite --fmk=TFLITE --modelFile=model.tflite --outputFile=model
</pre></div>
</div>
</li>
<li><p>TensorFlow model <code class="docutils literal notranslate"><span class="pre">model.pb</span></code></p>
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span><span class="k">call</span> converter_lite --fmk=TF --modelFile=model.pb --outputFile=model
</pre></div>
</div>
</li>
<li><p>ONNX model<code class="docutils literal notranslate"><span class="pre">model.onnx</span></code></p>
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span><span class="k">call</span> converter_lite --fmk=ONNX --modelFile=model.onnx --outputFile=model
</pre></div>
</div>
</li>
</ul>
<p>In the above cases, the following conversion success prompt is displayed, and the <code class="docutils literal notranslate"><span class="pre">model.ms</span></code> target file is obtained at the same time.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>CONVERTER RESULT SUCCESS:0
</pre></div>
</div>
</li>
<li><p>If running the conversion command is failed, an <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.2/errorcode_and_metatype.html">errorcode</a> will be output.</p></li>
</ul>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="code_generator.html" class="btn btn-neutral float-right" title="Code Generator" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="../quick_start/train_lenet.html" class="btn btn-neutral float-left" title="Training a LeNet Model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, MindSpore Lite.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>