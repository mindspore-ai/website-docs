<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Using Runtime to Perform Inference (Java) &mdash; MindSpore Lite master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script src="../_static/js/lite.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Application Specific Integrated Circuit Integration Instructions" href="asic.html" />
    <link rel="prev" title="Using Runtime to Perform Inference (C++)" href="runtime_cpp.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Obtain MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="downloads.html">Downloading MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="build.html">Building MindSpore Lite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_cpp.html">Simplified MindSpore Lite C++ Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_java.html">Simplified MindSpore Lite Java Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application (C++)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/image_segmentation.html">Android Application Development Based on Java Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start_codegen.html">Compile a MNIST Classification Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/train_lenet.html">Training a LeNet Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference on Devices</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="converter_tool.html">Converting Models for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="code_generator.html">Code Generator</a></li>
<li class="toctree-l1"><a class="reference internal" href="post_training_quantization.html">Optimizing the Model (Quantization After Training)</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_preprocessing.html">Data Preprocessing</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="runtime.html">Executing Model Inference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="runtime_cpp.html">Using Runtime to Perform Inference (C++)</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Using Runtime to Perform Inference (Java)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#referencing-the-mindspore-lite-java-library">Referencing the MindSpore Lite Java Library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#linux-x86-project-referencing-the-jar-library">Linux X86 Project Referencing the JAR Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="#android-projects-referencing-the-aar-library">Android Projects Referencing the AAR Library</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#loading-a-model">Loading a Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#creating-a-configuration-context">Creating a Configuration Context</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#configuring-the-cpu-backend">Configuring the CPU Backend</a></li>
<li class="toctree-l4"><a class="reference internal" href="#configuring-the-gpu-backend">Configuring the GPU Backend</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#creating-a-session">Creating a Session</a></li>
<li class="toctree-l3"><a class="reference internal" href="#building-a-graph">Building a Graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="#inputting-data">Inputting Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#executing-inference">Executing Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="#obtaining-the-output">Obtaining the Output</a></li>
<li class="toctree-l3"><a class="reference internal" href="#releasing-the-memory">Releasing the Memory</a></li>
<li class="toctree-l3"><a class="reference internal" href="#advanced-usage">Advanced Usage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#optimizing-the-memory-size">Optimizing the Memory Size</a></li>
<li class="toctree-l4"><a class="reference internal" href="#core-binding-operations">Core Binding Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#resizing-the-input-dimension">Resizing the Input Dimension</a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-sessions">Parallel Sessions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#viewing-logs">Viewing Logs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#obtaining-the-version-number">Obtaining the Version Number</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="asic.html">Application Specific Integrated Circuit Integration Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">Other Tools</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training on Devices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="converter_train.html">Creating MindSpore Lite Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime_train.html">Executing Model Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools_train.html">Other Tools</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_lite.html">Lite Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_codegen.html">Codegen Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_lite.html">Model List</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="runtime.html">Executing Model Inference</a> &raquo;</li>
      <li>Using Runtime to Perform Inference (Java)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/use/runtime_java.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="using-runtime-to-perform-inference-java">
<h1>Using Runtime to Perform Inference (Java)<a class="headerlink" href="#using-runtime-to-perform-inference-java" title="Permalink to this headline">ÔÉÅ</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Android</span></code> <code class="docutils literal notranslate"><span class="pre">Java</span></code> <code class="docutils literal notranslate"><span class="pre">Inference</span> <span class="pre">Application</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Loading</span></code> <code class="docutils literal notranslate"><span class="pre">Data</span> <span class="pre">Preparation</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/lite/source_en/use/runtime_java.md"><img alt="View Source On Gitee" src="https://gitee.com/mindspore/docs/raw/r1.2/resource/_static/logo_source.png" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>After the model is converted into a <code class="docutils literal notranslate"><span class="pre">.ms</span></code> model by using the MindSpore Lite model conversion tool, the inference process can be performed in Runtime. For details, see <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.2/use/converter_tool.html">Converting Models for Inference</a>. This tutorial describes how to use the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/index.html">Java API</a> to perform inference.</p>
<p>If MindSpore Lite is used in an Android project, you can use <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.2/index.html">C++ API</a> or <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/index.html">Java API</a> to run the inference framework. Compared with C++ APIs, Java APIs can be directly called in the Java class. Users do not need to implement the code at the JNI layer, which is more convenient. To run the MindSpore Lite inference framework, perform the following steps:</p>
<ol class="arabic simple">
<li><p>Load the model: Read the <code class="docutils literal notranslate"><span class="pre">.ms</span></code> model converted by the model conversion tool introduced in <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.2/use/converter_tool.html">Converting Models for Inference</a> from the file system and import the model using the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/model.html#loadmodel">loadModel</a>.</p></li>
<li><p>Create a configuration context: Create a configuration context <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/msconfig.html#msconfig">MSConfig</a> to save some basic configuration parameters required by a session to guide graph build and execution, including <code class="docutils literal notranslate"><span class="pre">deviceType</span></code> (device type), <code class="docutils literal notranslate"><span class="pre">threadNum</span></code> (number of threads), <code class="docutils literal notranslate"><span class="pre">cpuBindMode</span></code> (CPU core binding mode), and <code class="docutils literal notranslate"><span class="pre">enable_float16</span></code> (whether to preferentially use the float16 operator).</p></li>
<li><p>Create a session: Create <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#litesession">LiteSession</a> and call the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#init">init</a> method to configure the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/msconfig.html#msconfig">MSConfig</a> obtained in the previous step in the session.</p></li>
<li><p>Build a graph: Before building a graph, the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#compilegraph">compileGraph</a> API of <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#litesession">LiteSession</a> needs to be called to build the graph, including graph partition and operator selection and scheduling. This takes a long time. Therefore, it is recommended that with <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.2/session.html#litesession">LiteSession</a> created each time, one graph be built. In this case, the inference will be performed for multiple times.</p></li>
<li><p>Input data: Before the graph is performed, data needs to be filled in to the <code class="docutils literal notranslate"><span class="pre">Input</span> <span class="pre">Tensor</span></code>.</p></li>
<li><p>Perform inference: Use the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#rungraph">runGraph</a> of the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#litesession">LiteSession</a> to perform model inference.</p></li>
<li><p>Obtain the output: After the graph execution is complete, you can obtain the inference result by <code class="docutils literal notranslate"><span class="pre">outputting</span> <span class="pre">the</span> <span class="pre">tensor</span></code>.</p></li>
<li><p>Release the memory: If the MindSpore Lite inference framework is not required, release the created <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#litesession">LiteSession</a> and <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/model.html#model">Model</a>.</p></li>
</ol>
<p><img alt="img" src="../_images/lite_runtime.png" /></p>
<blockquote>
<div><p>For details about the calling process of MindSpore Lite inference, see <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.2/quick_start/quick_start_cpp.html">Simplified MindSpore Lite Java Demo</a>.</p>
</div></blockquote>
</section>
<section id="referencing-the-mindspore-lite-java-library">
<h2>Referencing the MindSpore Lite Java Library<a class="headerlink" href="#referencing-the-mindspore-lite-java-library" title="Permalink to this headline">ÔÉÅ</a></h2>
<section id="linux-x86-project-referencing-the-jar-library">
<h3>Linux X86 Project Referencing the JAR Library<a class="headerlink" href="#linux-x86-project-referencing-the-jar-library" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>When using <code class="docutils literal notranslate"><span class="pre">Maven</span></code> as the build tool, you can copy <code class="docutils literal notranslate"><span class="pre">mindspore-lite-java.jar</span></code> to the <code class="docutils literal notranslate"><span class="pre">lib</span></code> directory in the root directory and add the dependency of the JAR package to <code class="docutils literal notranslate"><span class="pre">pom.xml</span></code>.</p>
<div class="highlight-xml notranslate"><div class="highlight"><pre><span></span><span class="nt">&lt;dependencies&gt;</span>
<span class="w">    </span><span class="nt">&lt;dependency&gt;</span>
<span class="w">        </span><span class="nt">&lt;groupId&gt;</span>com.mindspore.lite<span class="nt">&lt;/groupId&gt;</span>
<span class="w">        </span><span class="nt">&lt;artifactId&gt;</span>mindspore-lite-java<span class="nt">&lt;/artifactId&gt;</span>
<span class="w">        </span><span class="nt">&lt;version&gt;</span>1.0<span class="nt">&lt;/version&gt;</span>
<span class="w">        </span><span class="nt">&lt;scope&gt;</span>system<span class="nt">&lt;/scope&gt;</span>
<span class="w">        </span><span class="nt">&lt;systemPath&gt;</span>${project.basedir}/lib/mindspore-lite-java.jar<span class="nt">&lt;/systemPath&gt;</span>
<span class="w">    </span><span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;/dependencies&gt;</span>
</pre></div>
</div>
<blockquote>
<div><p>Add the paths of <code class="docutils literal notranslate"><span class="pre">libmindspore-lite.so</span></code> and <code class="docutils literal notranslate"><span class="pre">libminspore-lite-jni.so</span></code> to <code class="docutils literal notranslate"><span class="pre">java.library.path</span></code>.</p>
</div></blockquote>
</section>
<section id="android-projects-referencing-the-aar-library">
<h3>Android Projects Referencing the AAR Library<a class="headerlink" href="#android-projects-referencing-the-aar-library" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>When <code class="docutils literal notranslate"><span class="pre">Gradle</span></code> is used as the build tool, move the <code class="docutils literal notranslate"><span class="pre">mindspore-lite-{version}.aar</span></code> file to the <code class="docutils literal notranslate"><span class="pre">libs</span></code> directory of the target module, and then add the local reference directory to <code class="docutils literal notranslate"><span class="pre">repositories</span></code> of <code class="docutils literal notranslate"><span class="pre">build.gradle</span></code> of the target module, add the AAR dependency to <code class="docutils literal notranslate"><span class="pre">dependencies</span></code> as follows:</p>
<blockquote>
<div><p>Note that mindspore-lite-{version} is the AAR file name. Replace {version} with the corresponding version information.</p>
</div></blockquote>
<div class="highlight-groovy notranslate"><div class="highlight"><pre><span></span><span class="n">repositories</span><span class="w"> </span><span class="o">{</span>
<span class="w">    </span><span class="n">flatDir</span><span class="w"> </span><span class="o">{</span>
<span class="w">        </span><span class="n">dirs</span><span class="w"> </span><span class="s1">&#39;libs&#39;</span>
<span class="w">    </span><span class="o">}</span>
<span class="o">}</span>

<span class="n">dependencies</span><span class="w"> </span><span class="o">{</span>
<span class="w">    </span><span class="n">implementation</span><span class="w"> </span><span class="n">fileTree</span><span class="o">(</span><span class="nl">dir:</span><span class="w"> </span><span class="s2">&quot;libs&quot;</span><span class="o">,</span><span class="w"> </span><span class="nl">include:</span><span class="w"> </span><span class="o">[</span><span class="s1">&#39;*.aar&#39;</span><span class="o">])</span>
<span class="o">}</span>
</pre></div>
</div>
</section>
</section>
<section id="loading-a-model">
<h2>Loading a Model<a class="headerlink" href="#loading-a-model" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>Before performing model inference, MindSpore Lite needs to load the <code class="docutils literal notranslate"><span class="pre">.ms</span></code> model converted by the model conversion tool from the file system and parse the model. The <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/model.html#model">Model</a> class of Java provides two <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/model.html#loadmodel">loadModel</a> APIs to load models from <code class="docutils literal notranslate"><span class="pre">Assets</span></code> or other file paths.</p>
<p>The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L217">MainActivity.java</a> reads the <code class="docutils literal notranslate"><span class="pre">mobilenetv2.ms</span></code> model file from <code class="docutils literal notranslate"><span class="pre">Assets</span></code> to load the model.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="c1">// Load the .ms model.</span>
<span class="n">Model</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">Model</span><span class="p">();</span>
<span class="n">String</span><span class="w"> </span><span class="n">modelPath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;mobilenetv2.ms&quot;</span><span class="p">;</span>
<span class="kt">boolean</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="na">loadModel</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="na">getApplicationContext</span><span class="p">(),</span><span class="w"> </span><span class="n">modelPath</span><span class="p">);</span>
</pre></div>
</div>
<blockquote>
<div><p>Only the <code class="docutils literal notranslate"><span class="pre">AAR</span></code> library supports the API for loading model files from <code class="docutils literal notranslate"><span class="pre">Assert</span></code>.</p>
</div></blockquote>
<p>The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/quick_start_java/src/main/java/com/mindspore/lite/demo/Main.java#L128">MainActivity.java</a> reads the model file from the <code class="docutils literal notranslate"><span class="pre">modelPath</span></code> path to load the model.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="n">Model</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">Model</span><span class="p">();</span>
<span class="kt">boolean</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="na">loadModel</span><span class="p">(</span><span class="n">modelPath</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="creating-a-configuration-context">
<h2>Creating a Configuration Context<a class="headerlink" href="#creating-a-configuration-context" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>Create the configuration context <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/msconfig.html#msconfig">MSConfig</a> to save some basic configuration parameters required by the session to guide graph build and execution.</p>
<p>MindSpore Lite supports heterogeneous inference. The preferred backend for inference is specified by <code class="docutils literal notranslate"><span class="pre">deviceType</span></code> of <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/msconfig.html#msconfig">MSConfig</a>. Currently, CPU and GPU are supported. During graph build, operator selection and scheduling are performed based on the preferred backend.</p>
<p>MindSpore Lite has a built-in thread pool shared by processes. During inference, <code class="docutils literal notranslate"><span class="pre">threadNum</span></code> is used to specify the maximum number of threads in the thread pool. The default value is 2.</p>
<p>MindSpore Lite supports inference in float16 operator mode. After <code class="docutils literal notranslate"><span class="pre">enable_float16</span></code> is set to <code class="docutils literal notranslate"><span class="pre">true</span></code>, the float16 operator is preferentially used.</p>
<section id="configuring-the-cpu-backend">
<h3>Configuring the CPU Backend<a class="headerlink" href="#configuring-the-cpu-backend" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>If the backend to be performed is a CPU, you need to configure <code class="docutils literal notranslate"><span class="pre">DeviceType.DT_CPU</span></code> in <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/msconfig.html#init">init</a> after <code class="docutils literal notranslate"><span class="pre">MSConfig</span></code> is created. In addition, the CPU supports the setting of the core binding mode and whether to preferentially use the float16 operator.</p>
<p>The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L59">MainActivity.java</a> demonstrates how to create a CPU backend, set the CPU core binding mode to large-core priority, and enable float16 inference:</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="n">MSConfig</span><span class="w"> </span><span class="n">msConfig</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">MSConfig</span><span class="p">();</span>
<span class="kt">boolean</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">msConfig</span><span class="p">.</span><span class="na">init</span><span class="p">(</span><span class="n">DeviceType</span><span class="p">.</span><span class="na">DT_CPU</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">CpuBindMode</span><span class="p">.</span><span class="na">HIGHER_CPU</span><span class="p">,</span><span class="w"> </span><span class="kc">true</span><span class="p">);</span>
</pre></div>
</div>
<blockquote>
<div><p>Float16 takes effect only when the CPU is of the ARM v8.2 architecture. Other models and x86 platforms that are not supported are automatically rolled back to float32.</p>
</div></blockquote>
</section>
<section id="configuring-the-gpu-backend">
<h3>Configuring the GPU Backend<a class="headerlink" href="#configuring-the-gpu-backend" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>If the backend to be performed is heterogeneous inference based on CPU and GPU, you need to configure <code class="docutils literal notranslate"><span class="pre">DeviceType.DT_GPU</span></code> in <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/msconfig.html#init">init</a> after <code class="docutils literal notranslate"><span class="pre">MSConfig</span></code> is created. After the configuration, GPU-based inference is preferentially used. In addition, if enable_float16 is set to true, both the GPU and CPU preferentially use the float16 operator.</p>
<p>The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L69">MainActivity.java</a> demonstrates how to create the CPU and GPU heterogeneous inference backend and how to enable float16 inference for the GPU.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="n">MSConfig</span><span class="w"> </span><span class="n">msConfig</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">MSConfig</span><span class="p">();</span>
<span class="kt">boolean</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">msConfig</span><span class="p">.</span><span class="na">init</span><span class="p">(</span><span class="n">DeviceType</span><span class="p">.</span><span class="na">DT_GPU</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">CpuBindMode</span><span class="p">.</span><span class="na">MID_CPU</span><span class="p">,</span><span class="w"> </span><span class="kc">true</span><span class="p">);</span>
</pre></div>
</div>
<blockquote>
<div><p>Currently, the GPU can run only on Android mobile devices. Therefore, only the <code class="docutils literal notranslate"><span class="pre">AAR</span></code> library can be run.</p>
</div></blockquote>
</section>
</section>
<section id="creating-a-session">
<h2>Creating a Session<a class="headerlink" href="#creating-a-session" title="Permalink to this headline">ÔÉÅ</a></h2>
<p><a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#litesession">LiteSession</a> is the main entry for inference. You can use <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#litesession">LiteSession</a> to build and perform graphs. Create <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#litesession">LiteSession</a> and call the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#init">init</a> method to configure the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/msconfig.html#msconfig">MSConfig</a> obtained in the previous step in the session. After the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#litesession">LiteSession</a> is initialized, the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/msconfig.html#msconfig">MSConfig</a> can perform the release operation.</p>
<p>The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L86">MainActivity.java</a> demonstrates how to create a <code class="docutils literal notranslate"><span class="pre">LiteSession</span></code>:</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="n">LiteSession</span><span class="w"> </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">LiteSession</span><span class="p">();</span>
<span class="kt">boolean</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="p">.</span><span class="na">init</span><span class="p">(</span><span class="n">msConfig</span><span class="p">);</span>
<span class="n">msConfig</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
</pre></div>
</div>
</section>
<section id="building-a-graph">
<h2>Building a Graph<a class="headerlink" href="#building-a-graph" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>Before building a graph, the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#compilegraph">compileGraph</a> API of <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#litesession">LiteSession</a> needs to be called to build the graph, including graph partition and operator selection and scheduling. This takes a long time. Therefore, it is recommended that with the <a class="reference external" href="https://www.mindspore.cn/doc/api_cpp/en/r1.2/session.html#litesession">LiteSession</a> created each time, one graph be built. In this case, the inference will be performed for multiple times.</p>
<p>The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L87">MainActivity.java</a> demonstrates how to call <code class="docutils literal notranslate"><span class="pre">CompileGraph</span></code> to build a graph.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="kt">boolean</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="p">.</span><span class="na">compileGraph</span><span class="p">(</span><span class="n">model</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="inputting-data">
<h2>Inputting Data<a class="headerlink" href="#inputting-data" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>MindSpore Lite Java APIs provide the <code class="docutils literal notranslate"><span class="pre">getInputsByTensorName</span></code> and <code class="docutils literal notranslate"><span class="pre">getInputs</span></code> methods to obtain the input tensor. Both the <code class="docutils literal notranslate"><span class="pre">byte[]</span></code> and <code class="docutils literal notranslate"><span class="pre">ByteBuffer</span></code> data types are supported. You can set the data of the input tensor by calling <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/mstensor.html#setdata">setData</a>.</p>
<ol class="arabic">
<li><p>Use the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#getinputsbytensorname">getInputsByTensorName</a> method to obtain the tensor connected to the input node from the model input tensor based on the name of the model input tensor. The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L151">MainActivity.java</a> demonstrates how to call the <code class="docutils literal notranslate"><span class="pre">getInputsByTensorName</span></code> function to obtain the input tensor and fill in data.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="n">MSTensor</span><span class="w"> </span><span class="n">inputTensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="p">.</span><span class="na">getInputsByTensorName</span><span class="p">(</span><span class="s">&quot;2031_2030_1_construct_wrapper:x&quot;</span><span class="p">);</span>
<span class="c1">// Set Input Data.</span>
<span class="n">inputTensor</span><span class="p">.</span><span class="na">setData</span><span class="p">(</span><span class="n">inputData</span><span class="p">);</span>
</pre></div>
</div>
</li>
<li><p>Use the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#getinputs">getInputs</a> method to directly obtain the vectors of all model input tensors. The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L113">MainActivity.java</a> demonstrates how to call <code class="docutils literal notranslate"><span class="pre">getInputs</span></code> to obtain the input tensors and fill in the data.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="n">List</span><span class="o">&lt;</span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="p">.</span><span class="na">getInputs</span><span class="p">();</span>
<span class="n">MSTensor</span><span class="w"> </span><span class="n">inputTensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputs</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="c1">// Set Input Data.</span>
<span class="n">inputTensor</span><span class="p">.</span><span class="na">setData</span><span class="p">(</span><span class="n">inputData</span><span class="p">);</span>
</pre></div>
</div>
</li>
</ol>
<blockquote>
<div><p>The data layout in the input tensor of the MindSpore Lite model must be <code class="docutils literal notranslate"><span class="pre">NHWC</span></code>. For more information about data pre-processing, see <a class="reference external" href="https://www.mindspore.cn/tutorial/lite/en/r1.2/quick_start/image_segmentation.html#id10">Implementing an Image Segmentation Application</a>.</p>
</div></blockquote>
</section>
<section id="executing-inference">
<h2>Executing Inference<a class="headerlink" href="#executing-inference" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>After a MindSpore Lite session builds a graph, it can call the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#rungraph">runGraph</a> function of <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#litesession">LiteSession</a> to perform model inference.</p>
<p>The following sample code demonstrates how to call <code class="docutils literal notranslate"><span class="pre">runGraph</span></code> to perform inference.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="c1">// Run graph to infer results.</span>
<span class="kt">boolean</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="p">.</span><span class="na">runGraph</span><span class="p">();</span>
</pre></div>
</div>
</section>
<section id="obtaining-the-output">
<h2>Obtaining the Output<a class="headerlink" href="#obtaining-the-output" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>After performing inference, MindSpore Lite can output a tensor to obtain the inference result. MindSpore Lite provides three methods to obtain the output <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/mstensor.html">MSTensor</a> of a model and supports the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/mstensor.html#getbytedata">getByteData</a>, <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/mstensor.html#getfloatdata">getFloatData</a>, <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/mstensor.html#getintdata">getIntData</a> and <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/mstensor.html#getlongdata">getLongData</a> methods to obtain the output data.</p>
<ol class="arabic">
<li><p>Use the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#getoutputmapbytensor">getOutputMapByTensor</a> method to directly obtain the names of all model output <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/mstensor.html#mstensor">MSTensor</a> and a map of the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/mstensor.html#mstensor">MSTensor</a> pointer. The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L191">MainActivity.java</a> demonstrates how to call <code class="docutils literal notranslate"><span class="pre">getOutputMapByTensor</span></code> to obtain the output tensor.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">outTensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="p">.</span><span class="na">getOutputMapByTensor</span><span class="p">();</span>

<span class="n">Iterator</span><span class="o">&lt;</span><span class="n">Map</span><span class="p">.</span><span class="na">Entry</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">MSTensor</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">entries</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outTensors</span><span class="p">.</span><span class="na">entrySet</span><span class="p">().</span><span class="na">iterator</span><span class="p">();</span>
<span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="n">entries</span><span class="p">.</span><span class="na">hasNext</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">Map</span><span class="p">.</span><span class="na">Entry</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">entry</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">entries</span><span class="p">.</span><span class="na">next</span><span class="p">();</span>
<span class="w">    </span><span class="c1">// Apply infer results.</span>
<span class="w">    </span><span class="p">...</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>Use the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#getoutputsbynodename">getOutputByNodeName</a> method to obtain the vector of the tensor connected to the model output <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/mstensor.html#mstensor">MSTensor</a> based on the name of the model output node. The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L175">MainActivity.java</a> demonstrates how to call <code class="docutils literal notranslate"><span class="pre">getOutputByTensorName</span></code> to obtain the output tensor.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="n">MSTensor</span><span class="w"> </span><span class="n">outTensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="p">.</span><span class="na">getOutputsByNodeName</span><span class="p">(</span><span class="s">&quot;Default/head-MobileNetV2Head/Softmax-op204&quot;</span><span class="p">);</span>
<span class="c1">// Apply infer results.</span>
<span class="p">...</span>
</pre></div>
</div>
</li>
<li><p>Use the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#getoutputbytensorname">getOutputByTensorName</a> method to obtain the model output <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/mstensor.html#mstensor">MSTensor</a> based on the name of the model output tensor. The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L182">MainActivity.java</a> demonstrates how to call <code class="docutils literal notranslate"><span class="pre">getOutputByTensorName</span></code> to obtain the output tensor.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="n">MSTensor</span><span class="w"> </span><span class="n">outTensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="p">.</span><span class="na">getOutputByTensorName</span><span class="p">(</span><span class="s">&quot;Default/head-MobileNetV2Head/Softmax-op204&quot;</span><span class="p">);</span>
<span class="c1">// Apply infer results.</span>
<span class="p">...</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="releasing-the-memory">
<h2>Releasing the Memory<a class="headerlink" href="#releasing-the-memory" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>If the MindSpore Lite inference framework is not required, you need to release the created LiteSession and Model. The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L204">MainActivity.java</a> demonstrates how to release the memory before the program ends.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="n">session</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
<span class="n">model</span><span class="p">.</span><span class="na">free</span><span class="p">();</span>
</pre></div>
</div>
</section>
<section id="advanced-usage">
<h2>Advanced Usage<a class="headerlink" href="#advanced-usage" title="Permalink to this headline">ÔÉÅ</a></h2>
<section id="optimizing-the-memory-size">
<h3>Optimizing the Memory Size<a class="headerlink" href="#optimizing-the-memory-size" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>If there is a large limit on the running memory, call the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/model.html#freebuffer">freeBuffer</a> function of <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/model.html#model">Model</a> after the graph build is complete to release the MetaGraph in the MindSpore Lite Model to reduce the running memory. Once the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/model.html#freebuffer">freeBuffer</a> of a <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/model.html#model">Model</a> is called, the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/model.html#model">Model</a> cannot be built again.</p>
<p>The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L241">MainActivity.java</a> demonstrates how to call the <code class="docutils literal notranslate"><span class="pre">freeBuffer</span></code> interface of <code class="docutils literal notranslate"><span class="pre">Model</span></code> to release <code class="docutils literal notranslate"><span class="pre">MetaGraph</span></code> to reduce the memory size during running.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="c1">// Compile graph.</span>
<span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="p">.</span><span class="na">compileGraph</span><span class="p">(</span><span class="n">model</span><span class="p">);</span>
<span class="p">...</span>
<span class="c1">// Note: when use model.freeBuffer(), the model can not be compiled.</span>
<span class="n">model</span><span class="p">.</span><span class="na">freeBuffer</span><span class="p">();</span>
</pre></div>
</div>
</section>
<section id="core-binding-operations">
<h3>Core Binding Operations<a class="headerlink" href="#core-binding-operations" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>The built-in thread pool of MindSpore Lite supports core binding and unbinding. By calling the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#bindthread">BindThread</a> API, you can bind working threads in the thread pool to specified CPU cores for performance analysis. The core binding operation is related to the context specified by the user when the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html">LiteSession</a> is created. The core binding operation sets the affinity between the thread and the CPU based on the core binding policy in the context.</p>
<p>Note that core binding is an affinity operation and may not be bound to a specified CPU core. It may be affected by system scheduling. In addition, after the core binding, you need to perform the unbinding operation after the code is performed.</p>
<p>The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L164">MainActivity.java</a> demonstrates how to bind to cores with the highest frequency first when performing inference.</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="kt">boolean</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">msConfig</span><span class="p">.</span><span class="na">init</span><span class="p">(</span><span class="n">DeviceType</span><span class="p">.</span><span class="na">DT_CPU</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">CpuBindMode</span><span class="p">.</span><span class="na">HIGHER_CPU</span><span class="p">,</span><span class="w"> </span><span class="kc">true</span><span class="p">);</span>
<span class="p">...</span>
<span class="n">session</span><span class="p">.</span><span class="na">bindThread</span><span class="p">(</span><span class="kc">true</span><span class="p">);</span>
<span class="c1">// Run Inference.</span>
<span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="p">.</span><span class="na">runGraph</span><span class="p">();</span>
<span class="n">session</span><span class="p">.</span><span class="na">bindThread</span><span class="p">(</span><span class="kc">false</span><span class="p">);</span>
</pre></div>
</div>
<blockquote>
<div><p>There are three options for core binding: HIGHER_CPU, MID_CPU, and NO_BIND.</p>
<p>The rule for determining the core binding mode is based on the frequency of CPU cores instead of the CPU architecture.</p>
<p>HIGHER_CPU: indicates that threads in the thread pool are preferentially bound to the core with the highest frequency. The first thread is bound to the core with the highest frequency, the second thread is bound to the core with the second highest frequency, and so on.</p>
<p>Mediumcores are defined based on experience. By default, mediumcores are with the third and fourth highest frequency. Mediumcore first indicates that threads are bound to mediumcores preferentially. When there are no available mediumcores, threads are bound to small cores.</p>
</div></blockquote>
</section>
<section id="resizing-the-input-dimension">
<h3>Resizing the Input Dimension<a class="headerlink" href="#resizing-the-input-dimension" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>When using MindSpore Lite for inference, if you need to resize the input shape, you can call the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#resize">resize</a> API of <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html">LiteSession</a> to reset the shape of the input tensor after creating a session and building a graph.</p>
<blockquote>
<div><p>Some networks do not support variable dimensions. As a result, an error message is displayed and the model exits unexpectedly. For example, the model contains the MatMul operator, one input tensor of the MatMul operator is the weight, and the other input tensor is the input. If a variable dimension API is called, the input tensor does not match the shape of the weight tensor. As a result, the inference fails.</p>
</div></blockquote>
<p>The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L164">MainActivity.java</a> demonstrates how to perform <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#resize">resize</a> on the input tensor of MindSpore Lite:</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="n">List</span><span class="o">&lt;</span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="p">.</span><span class="na">getInputs</span><span class="p">();</span>
<span class="kt">int</span><span class="o">[][]</span><span class="w"> </span><span class="n">dims</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">300</span><span class="p">,</span><span class="w"> </span><span class="mi">300</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">}};</span>
<span class="n">bool</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="p">.</span><span class="na">resize</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">dims</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="parallel-sessions">
<h3>Parallel Sessions<a class="headerlink" href="#parallel-sessions" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>MindSpore Lite supports parallel inference of multiple <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html">LiteSession</a>. The thread pool and memory pool of each <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#litesession">LiteSession</a> are independent. However, multiple threads cannot call the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#rungraph">runGraph</a> API of a single <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html#litesession">LiteSession</a> at the same time.</p>
<p>The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L220">MainActivity.java</a> demonstrates how to infer multiple <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html">LiteSession</a> in parallel:</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="n">session1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">createLiteSession</span><span class="p">(</span><span class="kc">false</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">session1</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="kc">null</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">session1Compile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">true</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">Toast</span><span class="p">.</span><span class="na">makeText</span><span class="p">(</span><span class="n">getApplicationContext</span><span class="p">(),</span><span class="w"> </span><span class="s">&quot;session1 Compile Failed.&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="n">Toast</span><span class="p">.</span><span class="na">LENGTH_SHORT</span><span class="p">).</span><span class="na">show</span><span class="p">();</span>
<span class="p">}</span>
<span class="n">session2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">createLiteSession</span><span class="p">(</span><span class="kc">true</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">session2</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="kc">null</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">session2Compile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">true</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">Toast</span><span class="p">.</span><span class="na">makeText</span><span class="p">(</span><span class="n">getApplicationContext</span><span class="p">(),</span><span class="w"> </span><span class="s">&quot;session2 Compile Failed.&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="n">Toast</span><span class="p">.</span><span class="na">LENGTH_SHORT</span><span class="p">).</span><span class="na">show</span><span class="p">();</span>
<span class="p">}</span>
<span class="p">...</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">session1Finish</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">session1Compile</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">new</span><span class="w"> </span><span class="n">Thread</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">Runnable</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nd">@Override</span>
<span class="w">        </span><span class="kd">public</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">run</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">session1Finish</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">false</span><span class="p">;</span>
<span class="w">            </span><span class="n">runInference</span><span class="p">(</span><span class="n">session1</span><span class="p">);</span>
<span class="w">            </span><span class="n">session1Finish</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">true</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}).</span><span class="na">start</span><span class="p">();</span>
<span class="p">}</span>

<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">session2Finish</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">session2Compile</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">new</span><span class="w"> </span><span class="n">Thread</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">Runnable</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nd">@Override</span>
<span class="w">        </span><span class="kd">public</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">run</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">session2Finish</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">false</span><span class="p">;</span>
<span class="w">            </span><span class="n">runInference</span><span class="p">(</span><span class="n">session2</span><span class="p">);</span>
<span class="w">            </span><span class="n">session2Finish</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">true</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}).</span><span class="na">start</span><span class="p">();</span>
<span class="p">}</span>
</pre></div>
</div>
<p>MindSpore Lite does not support multi-thread parallel execution of inference for a single <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html">LiteSession</a>. Otherwise, the following error information is displayed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ERROR<span class="w"> </span><span class="o">[</span>mindspore/lite/src/lite_session.cc:297<span class="o">]</span><span class="w"> </span>RunGraph<span class="o">]</span><span class="w"> </span><span class="m">10</span><span class="w"> </span>Not<span class="w"> </span>support<span class="w"> </span>multi-threading
</pre></div>
</div>
</section>
<section id="viewing-logs">
<h3>Viewing Logs<a class="headerlink" href="#viewing-logs" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>If an exception occurs during inference, you can view logs to locate the fault. For the Android platform, use the <code class="docutils literal notranslate"><span class="pre">Logcat</span></code> command line to view the MindSpore Lite inference log information and use <code class="docutils literal notranslate"><span class="pre">MS_LITE</span></code> to filter the log information.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>logcat<span class="w"> </span>-s<span class="w"> </span><span class="s2">&quot;MS_LITE&quot;</span>
</pre></div>
</div>
</section>
<section id="obtaining-the-version-number">
<h3>Obtaining the Version Number<a class="headerlink" href="#obtaining-the-version-number" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>MindSpore Lite provides the <a class="reference external" href="https://www.mindspore.cn/doc/api_java/en/r1.2/lite_session.html">Version</a> method to obtain the version number, which is included in the <code class="docutils literal notranslate"><span class="pre">com.mindspore.lite.Version</span></code> header file. You can call this method to obtain the version number of MindSpore Lite.</p>
<p>The following sample code from <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/mindspore/lite/examples/runtime_java/app/src/main/java/com/mindspore/lite/demo/MainActivity.java#L215">MainActivity.java</a> demonstrates how to obtain the version number of MindSpore Lite:</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">com.mindspore.lite.Version</span><span class="p">;</span>
<span class="n">String</span><span class="w"> </span><span class="n">version</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Version</span><span class="p">.</span><span class="na">version</span><span class="p">();</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="runtime_cpp.html" class="btn btn-neutral float-left" title="Using Runtime to Perform Inference (C++)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="asic.html" class="btn btn-neutral float-right" title="Application Specific Integrated Circuit Integration Instructions" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>