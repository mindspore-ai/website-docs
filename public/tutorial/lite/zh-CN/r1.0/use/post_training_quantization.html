

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>转换为MindSpore Lite量化模型(训练后量化) &mdash; MindSpore Lite master documentation</title>
  

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="评估MindSpore Lite模型（可选）" href="evaluating_the_model.html" />
    <link rel="prev" title="转换为MindSpore Lite模型" href="converter_tool.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore Lite
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">实现一个图像分类应用</a></li>
</ul>
<p class="caption"><span class="caption-text">基础使用</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="build.html">编译MindSpore Lite</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="convert_model.html">转换为MindSpore Lite模型</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="converter_tool.html">转换为MindSpore Lite模型</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">转换为MindSpore Lite量化模型(训练后量化)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">权重量化</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">参数说明</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id4">使用步骤</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id5">部分模型精度结果</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id6">全量化</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id7">参数说明</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8">使用步骤</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id9">部分模型精度结果</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="evaluating_the_model.html">评估MindSpore Lite模型（可选）</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_preprocessing.html">预处理数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">使用Runtime执行推理</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="convert_model.html">转换为MindSpore Lite模型</a> &raquo;</li>
        
      <li>转换为MindSpore Lite量化模型(训练后量化)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/use/post_training_quantization.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="mindspore-lite">
<h1>转换为MindSpore Lite量化模型(训练后量化)<a class="headerlink" href="#mindspore-lite" title="Permalink to this headline">¶</a></h1>
<!-- TOC --><ul class="simple">
<li><p><a class="reference external" href="#%E8%BD%AC%E6%8D%A2%E4%B8%BAmindspore-lite%E9%87%8F%E5%8C%96%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%90%8E%E9%87%8F%E5%8C%96">转换为MindSpore Lite量化模型(训练后量化)</a></p>
<ul>
<li><p><a class="reference external" href="#%E6%A6%82%E8%BF%B0">概述</a></p></li>
<li><p><a class="reference external" href="#%E6%9D%83%E9%87%8D%E9%87%8F%E5%8C%96">权重量化</a></p>
<ul>
<li><p><a class="reference external" href="#%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E">参数说明</a></p></li>
<li><p><a class="reference external" href="#%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4">使用步骤</a></p></li>
<li><p><a class="reference external" href="#%E9%83%A8%E5%88%86%E6%A8%A1%E5%9E%8B%E7%B2%BE%E5%BA%A6%E7%BB%93%E6%9E%9C">部分模型精度结果</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#%E5%85%A8%E9%87%8F%E5%8C%96">全量化</a></p>
<ul>
<li><p><a class="reference external" href="#%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E-1">参数说明</a></p></li>
<li><p><a class="reference external" href="#%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4-1">使用步骤</a></p></li>
<li><p><a class="reference external" href="#%E9%83%A8%E5%88%86%E6%A8%A1%E5%9E%8B%E7%B2%BE%E5%BA%A6%E7%BB%93%E6%9E%9C-1">部分模型精度结果</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- /TOC --><p><a href="https://gitee.com/mindspore/docs/blob/r1.0/tutorials/lite/source_zh_cn/use/post_training_quantization.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<div class="section" id="id1">
<h2>概述<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>对于已经训练好的<code class="docutils literal notranslate"><span class="pre">float32</span></code>模型，通过训练后量化将其转为<code class="docutils literal notranslate"><span class="pre">int8</span></code>，不仅能减小模型大小，而且能显著提高推理性能。在MindSpore Lite中，这部分功能集成在模型转换工具<code class="docutils literal notranslate"><span class="pre">conveter_lite</span></code>内，通过增加命令行参数，便能够转换得到量化后模型。
目前训练后量化属于alpha阶段（支持部分网络，不支持多输入模型），正在持续完善中。</p>
<p>MindSpore Lite训练后量化分为两类：</p>
<ol class="simple">
<li><p>权重量化：单独对模型的权值进行量化；</p></li>
<li><p>全量化：对模型的权值、激活值、bias值统一进行量化。</p></li>
</ol>
<p>训练后量化在两种情况下所需的数据类型和参数设定不同，但均可通过转换工具设定。有关转换工具<code class="docutils literal notranslate"><span class="pre">converter_lite</span></code>的使用方法可参考<a class="reference external" href="https://www.mindspore.cn/tutorial/lite/zh-CN/r1.0/use/converter_tool.html">转换为MindSpore Lite模型</a>。在此基础之上进行配置，启用训练后量化。</p>
</div>
<div class="section" id="id2">
<h2>权重量化<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>下面对权重量化的使用方式和效果进行阐述。</p>
<div class="section" id="id3">
<h3>参数说明<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>权重量化转换命令的一般形式为：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">converter_lite</span> <span class="o">--</span><span class="n">fmk</span><span class="o">=</span><span class="n">ModelType</span> <span class="o">--</span><span class="n">modelFile</span><span class="o">=</span><span class="n">ModelFilePath</span> <span class="o">--</span><span class="n">outputFile</span><span class="o">=</span><span class="n">ConvertedModelPath</span> <span class="o">--</span><span class="n">quantType</span><span class="o">=</span><span class="n">WeightQuant</span> <span class="o">--</span><span class="n">bitNum</span><span class="o">=</span><span class="n">BitNumValue</span> <span class="o">--</span><span class="n">quantSize</span><span class="o">=</span><span class="n">QuantizationSizeThresholdValue</span> <span class="o">--</span><span class="n">convWeightQuantChannelThreshold</span><span class="o">=</span><span class="n">ConvWeightQuantChannelThresholdValue</span>
</pre></div>
</div>
<p>下面对此命令的量化相关参数进行说明：</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>参数</th>
<th>属性</th>
<th>功能描述</th>
<th>参数类型</th>
<th>默认值</th>
<th>取值范围</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--quantType=&lt;QUANTTYPE&gt;</code></td>
<td>必选</td>
<td>设置为WeightQuant，启用权重量化</td>
<td>String</td>
<td>-</td>
<td>必须设置为WeightQuant</td>
</tr>
<tr>
<td><code>--bitNum=&lt;BITNUM&gt;</code></td>
<td>可选</td>
<td>设定权重量化的比特数，目前仅支持8bit量化</td>
<td>Integer</td>
<td>8</td>
<td>8</td>
</tr>
<tr>
<td><code>--quantSize=&lt;QUANTSIZE&gt;</code></td>
<td>可选</td>
<td>设定参与权重量化的卷积核尺寸阈值，若卷积核尺寸大于该值，则对此权重进行量化；建议设置为500</td>
<td>Integer</td>
<td>0</td>
<td>（0，+∞）</td>
</tr>
<tr>
<td><code>--convWeightQuantChannelThreshold=&lt;CONVWEIGHTQUANTCHANNELTHRESHOLD&gt;</code></td>
<td>可选</td>
<td>设定参与权重量化的卷积通道数阈值，若卷积通道数大于该值，则对此权重进行量化；建议设置为16</td>
<td>Integer</td>
<td>16</td>
<td>（0，+∞）</td>
</tr>
</tbody>
</table><p>用户可根据模型及自身需要对权重量化的参数作出调整。</p>
</div>
<div class="section" id="id4">
<h3>使用步骤<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<ol>
<li><p>正确编译出<code class="docutils literal notranslate"><span class="pre">converter_lite</span></code>可执行文件。该部分可参考构建文档<a class="reference external" href="https://www.mindspore.cn/tutorial/lite/zh-CN/r1.0/use/build.html">编译MindSpore Lite</a>，获得<code class="docutils literal notranslate"><span class="pre">converter_lite</span></code>工具，并配置环境变量。</p></li>
<li><p>以TensorFlow Lite模型为例，执行权重量化模型转换命令:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">converter_lite</span> <span class="o">--</span><span class="n">fmk</span><span class="o">=</span><span class="n">TFLITE</span> <span class="o">--</span><span class="n">modelFile</span><span class="o">=</span><span class="n">Inception_v3</span><span class="o">.</span><span class="n">tflite</span> <span class="o">--</span><span class="n">outputFile</span><span class="o">=</span><span class="n">Inception_v3</span><span class="o">.</span><span class="n">tflite</span> <span class="o">--</span><span class="n">quantType</span><span class="o">=</span><span class="n">WeightQuant</span> <span class="o">--</span><span class="n">bitNum</span><span class="o">=</span><span class="mi">8</span> <span class="o">--</span><span class="n">quantSize</span><span class="o">=</span><span class="mi">0</span> <span class="o">--</span><span class="n">convWeightQuantChannelThreshold</span><span class="o">=</span><span class="mi">0</span>
</pre></div>
</div>
</li>
<li><p>上述命令执行成功后，便可得到量化后的模型<code class="docutils literal notranslate"><span class="pre">Inception_v3.tflite.ms</span></code>，量化后的模型大小通常会下降到FP32模型的1/4。</p></li>
</ol>
</div>
<div class="section" id="id5">
<h3>部分模型精度结果<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th>模型</th>
<th>测试数据集</th>
<th>FP32模型精度</th>
<th>权重量化精度</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/model_zoo/upload_20180427/inception_v3_2018_04_27.tgz">Inception_V3</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>77.92%</td>
<td>77.84%</td>
</tr>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz">Mobilenet_V1_1.0_224</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>70.96%</td>
<td>70.56%</td>
</tr>
</tbody>
</table><blockquote>
<div><p>以上所有结果均在x86环境上测得。</p>
</div></blockquote>
</div>
</div>
<div class="section" id="id6">
<h2>全量化<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p>下面对全量化的使用方式和效果进行阐述。</p>
<div class="section" id="id7">
<h3>参数说明<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>全量化转换命令的一般形式为：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">converter_lite</span> <span class="o">--</span><span class="n">fmk</span><span class="o">=</span><span class="n">ModelType</span> <span class="o">--</span><span class="n">modelFile</span><span class="o">=</span><span class="n">ModelFilePath</span> <span class="o">--</span><span class="n">outputFile</span><span class="o">=</span><span class="n">ConvertedModelPath</span> <span class="o">--</span><span class="n">quantType</span><span class="o">=</span><span class="n">PostTraining</span> <span class="o">--</span><span class="n">config_file</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">cfg</span>
</pre></div>
</div>
<p>下面对此命令的量化相关参数进行说明：</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>参数</th>
<th>属性</th>
<th>功能描述</th>
<th>参数类型</th>
<th>默认值</th>
<th>取值范围</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--quantType=&lt;QUANTTYPE&gt;</code></td>
<td>必选</td>
<td>设置为PostTraining，启用全量化</td>
<td>String</td>
<td>-</td>
<td>必须设置为PostTraining</td>
</tr>
<tr>
<td><code>--config_file=&lt;CONFIGFILE&gt;</code></td>
<td>必选</td>
<td>校准数据集配置文件路径</td>
<td>String</td>
<td>-</td>
<td>-</td>
</tr>
</tbody>
</table><p>为了计算激活值的量化参数，用户需要提供校准数据集。校准数据集最好来自真实推理场景，能表征模型的实际输入情况，数量在100个左右。
校准数据集配置文件采用<code class="docutils literal notranslate"><span class="pre">key=value</span></code>的方式定义相关参数，需要配置的<code class="docutils literal notranslate"><span class="pre">key</span></code>如下:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>参数名</th>
<th>属性</th>
<th>功能描述</th>
<th>参数类型</th>
<th>默认值</th>
<th>取值范围</th>
</tr>
</thead>
<tbody>
<tr>
<td>image_path</td>
<td>必选</td>
<td>存放校准数据集的目录</td>
<td>String</td>
<td>-</td>
<td>该目录存放可直接用于执行推理的输入数据。由于目前框架还不支持数据预处理，所有数据必须事先完成所需的转换，使得它们满足推理的输入要求。</td>
</tr>
<tr>
<td>batch_count</td>
<td>可选</td>
<td>使用的输入数目</td>
<td>Integer</td>
<td>100</td>
<td>（0，+∞）</td>
</tr>
<tr>
<td>method_x</td>
<td>可选</td>
<td>网络层输入输出数据量化算法</td>
<td>String</td>
<td>KL</td>
<td>KL，MAX_MIN。 KL: 基于<a href="http://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf">KL散度</a>对数据范围作量化校准； MAX_MIN：基于最大值、最小值计算数据的量化参数。 在模型以及数据集比较较简单的情况下，推荐使用MAX_MIN</td>
</tr>
<tr>
<td>thread_num</td>
<td>可选</td>
<td>使用校准数据集执行推理流程时的线程数</td>
<td>Integer</td>
<td>1</td>
<td>（0，+∞）</td>
</tr>
</tbody>
</table></div>
<div class="section" id="id8">
<h3>使用步骤<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<ol>
<li><p>正确编译出<code class="docutils literal notranslate"><span class="pre">converter_lite</span></code>可执行文件。</p></li>
<li><p>准备校准数据集，假设存放在<code class="docutils literal notranslate"><span class="pre">/dir/images</span></code>目录，编写配置文件<code class="docutils literal notranslate"><span class="pre">config.cfg</span></code>，内容如下：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">image_path</span><span class="o">=/</span><span class="nb">dir</span><span class="o">/</span><span class="n">images</span>
<span class="n">batch_count</span><span class="o">=</span><span class="mi">100</span>
<span class="n">method_x</span><span class="o">=</span><span class="n">MAX_MIN</span>
<span class="n">thread_num</span><span class="o">=</span><span class="mi">1</span>
</pre></div>
</div>
<p>校准数据集可以选择测试数据集的子集，要求<code class="docutils literal notranslate"><span class="pre">/dir/images</span></code>目录下存放的每个文件均是预处理好的输入数据，每个文件都可以直接用于推理的输入。</p>
</li>
<li><p>以MindSpore模型为例，执行全量化的模型转换命令:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">converter_lite</span> <span class="o">--</span><span class="n">fmk</span><span class="o">=</span><span class="n">MINDIR</span> <span class="o">--</span><span class="n">modelFile</span><span class="o">=</span><span class="n">lenet</span><span class="o">.</span><span class="n">mindir</span> <span class="o">--</span><span class="n">outputFile</span><span class="o">=</span><span class="n">lenet_quant</span> <span class="o">--</span><span class="n">quantType</span><span class="o">=</span><span class="n">PostTraining</span> <span class="o">--</span><span class="n">config_file</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">cfg</span>
</pre></div>
</div>
</li>
<li><p>上述命令执行成功后，便可得到量化后的模型<code class="docutils literal notranslate"><span class="pre">lenet_quant.ms</span></code>，通常量化后的模型大小会下降到FP32模型的1/4。</p></li>
</ol>
</div>
<div class="section" id="id9">
<h3>部分模型精度结果<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th>模型</th>
<th>测试数据集</th>
<th>method_x</th>
<th>FP32模型精度</th>
<th>全量化精度</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/model_zoo/upload_20180427/inception_v3_2018_04_27.tgz">Inception_V3</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>KL</td>
<td>77.92%</td>
<td>77.95%</td>
<td>校准数据集随机选择ImageNet Validation数据集中的100张</td>
</tr>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz">Mobilenet_V1_1.0_224</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>KL</td>
<td>70.96%</td>
<td>70.69%</td>
<td>校准数据集随机选择ImageNet Validation数据集中的100张</td>
</tr>
</tbody>
</table><blockquote>
<div><p>以上所有结果均在x86环境上测得。</p>
</div></blockquote>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="evaluating_the_model.html" class="btn btn-neutral float-right" title="评估MindSpore Lite模型（可选）" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="converter_tool.html" class="btn btn-neutral float-left" title="转换为MindSpore Lite模型" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, MindSpore Lite

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>