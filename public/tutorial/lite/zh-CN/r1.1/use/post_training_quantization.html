

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>优化模型(训练后量化) &mdash; MindSpore Lite r1.1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/lite.css" type="text/css" />

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/js/lite.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="预处理数据" href="data_preprocessing.html" />
    <link rel="prev" title="推理模型转换" href="converter_tool.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore Lite
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">实现一个图像分类应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/train_lenet.html">训练一个LeNet模型</a></li>
</ul>
<p class="caption"><span class="caption-text">获取MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="downloads.html">下载MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="build.html">编译MindSpore Lite</a></li>
</ul>
<p class="caption"><span class="caption-text">端侧推理</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="converter_tool.html">推理模型转换</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">优化模型(训练后量化)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id2">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">权重量化</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id4">参数说明</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">使用步骤</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">部分模型精度结果</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id7">全量化</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id8">参数说明</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id9">使用步骤</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">部分模型精度结果</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="data_preprocessing.html">预处理数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">执行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">其他工具</a></li>
</ul>
<p class="caption"><span class="caption-text">端侧训练</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="converter_train.html">训练模型转换</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime_train.html">执行训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools_train.html">其他工具</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>优化模型(训练后量化)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/use/post_training_quantization.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1>优化模型(训练后量化)<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Windows</span></code> <code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">模型转换</span></code> <code class="docutils literal notranslate"><span class="pre">模型调优</span></code> <code class="docutils literal notranslate"><span class="pre">中级</span></code> <code class="docutils literal notranslate"><span class="pre">高级</span></code></p>
<!-- TOC --><ul class="simple">
<li><p><a class="reference external" href="#%E4%BC%98%E5%8C%96%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%90%8E%E9%87%8F%E5%8C%96">优化模型(训练后量化)</a></p>
<ul>
<li><p><a class="reference external" href="#%E6%A6%82%E8%BF%B0">概述</a></p></li>
<li><p><a class="reference external" href="#%E6%9D%83%E9%87%8D%E9%87%8F%E5%8C%96">权重量化</a></p>
<ul>
<li><p><a class="reference external" href="#%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E">参数说明</a></p></li>
<li><p><a class="reference external" href="#%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4">使用步骤</a></p></li>
<li><p><a class="reference external" href="#%E9%83%A8%E5%88%86%E6%A8%A1%E5%9E%8B%E7%B2%BE%E5%BA%A6%E7%BB%93%E6%9E%9C">部分模型精度结果</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#%E5%85%A8%E9%87%8F%E5%8C%96">全量化</a></p>
<ul>
<li><p><a class="reference external" href="#%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E-1">参数说明</a></p></li>
<li><p><a class="reference external" href="#%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4-1">使用步骤</a></p></li>
<li><p><a class="reference external" href="#%E9%83%A8%E5%88%86%E6%A8%A1%E5%9E%8B%E7%B2%BE%E5%BA%A6%E7%BB%93%E6%9E%9C-1">部分模型精度结果</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- /TOC --><p><a href="https://gitee.com/mindspore/docs/blob/r1.1/tutorials/lite/source_zh_cn/use/post_training_quantization.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<div class="section" id="id2">
<h2>概述<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>对于已经训练好的<code class="docutils literal notranslate"><span class="pre">float32</span></code>模型，通过训练后量化将其转为<code class="docutils literal notranslate"><span class="pre">int8</span></code>，不仅能减小模型大小，而且能显著提高推理性能。在MindSpore Lite中，这部分功能集成在模型转换工具<code class="docutils literal notranslate"><span class="pre">conveter_lite</span></code>内，通过增加命令行参数，便能够转换得到量化后模型。</p>
<p>MindSpore Lite训练后量化分为两类：</p>
<ol class="simple">
<li><p>权重量化：对模型的权值进行量化，仅压缩模型大小，推理时仍然执行<code class="docutils literal notranslate"><span class="pre">float32</span></code>推理；</p></li>
<li><p>全量化：对模型的权值、激活值等统一进行量化，推理时执行<code class="docutils literal notranslate"><span class="pre">int</span></code>运算，能提升模型推理速度、降低功耗。</p></li>
</ol>
<p>训练后量化在两种情况下所需的数据类型和参数设定不同，但均可通过转换工具设定。有关转换工具<code class="docutils literal notranslate"><span class="pre">converter_lite</span></code>的使用方法可参考<a class="reference external" href="https://www.mindspore.cn/tutorial/lite/zh-CN/r1.1/use/converter_tool.html">转换为MindSpore Lite模型</a>。在此基础之上进行配置，启用训练后量化。</p>
</div>
<div class="section" id="id3">
<h2>权重量化<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>支持1~16之间的任意比特量化，量化比特数越低，模型压缩率越大，但是精度损失通常也比较大。可以结合使用<a class="reference external" href="https://www.mindspore.cn/tutorial/lite/zh-CN/r1.1/use/benchmark_tool.html">Benchmark工具</a>进行精度评估，确定合适的量化比特数；通常平均相对误差(accuracyThreshold)满足4%以内，精度误差是比较小的。下面对权重量化的使用方式和效果进行阐述。</p>
<div class="section" id="id4">
<h3>参数说明<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>权重量化转换命令的一般形式为：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite --fmk<span class="o">=</span>ModelType --modelFile<span class="o">=</span>ModelFilePath --outputFile<span class="o">=</span>ConvertedModelPath --quantType<span class="o">=</span>WeightQuant --bitNum<span class="o">=</span>BitNumValue --quantWeightSize<span class="o">=</span>ConvWeightQuantSizeThresholdValue --quantWeightChannel<span class="o">=</span>ConvWeightQuantChannelThresholdValue
</pre></div>
</div>
<p>下面对此命令的量化相关参数进行说明：</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>参数</th>
<th>属性</th>
<th>功能描述</th>
<th>参数类型</th>
<th>默认值</th>
<th>取值范围</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--quantType=&lt;QUANTTYPE&gt;</code></td>
<td>必选</td>
<td>设置为WeightQuant，启用权重量化</td>
<td>String</td>
<td>-</td>
<td>必须设置为WeightQuant</td>
</tr>
<tr>
<td><code>--bitNum=&lt;BITNUM&gt;</code></td>
<td>可选</td>
<td>设定权重量化的比特数，目前支持1bit～16bit量化</td>
<td>Integer</td>
<td>8</td>
<td>[1，16]</td>
</tr>
<tr>
<td><code>--quantWeightSize=&lt;QUANTWEIGHTSIZE&gt;</code></td>
<td>可选</td>
<td>设定参与权重量化的卷积核尺寸阈值，若卷积核尺寸大于该值，则对此权重进行量化；建议设置为500</td>
<td>Integer</td>
<td>0</td>
<td>[0，+∞）</td>
</tr>
<tr>
<td><code>--quantWeightChannel=&lt;QUANTWEIGHTCHANNEL&gt;</code></td>
<td>可选</td>
<td>设定参与权重量化的卷积通道数阈值，若卷积通道数大于该值，则对此权重进行量化；建议设置为16</td>
<td>Integer</td>
<td>16</td>
<td>[0，+∞）</td>
</tr>
</tbody>
</table><p>用户可根据模型及自身需要对权重量化的参数作出调整。</p>
<blockquote>
<div><p>为保证权重量化的精度，建议<code class="docutils literal notranslate"><span class="pre">--bitNum</span></code>参数设定范围为8bit～16bit。</p>
</div></blockquote>
</div>
<div class="section" id="id5">
<h3>使用步骤<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<ol>
<li><p>正确编译出<code class="docutils literal notranslate"><span class="pre">converter_lite</span></code>可执行文件。该部分可参考构建文档<a class="reference external" href="https://www.mindspore.cn/tutorial/lite/zh-CN/r1.1/use/build.html">编译MindSpore Lite</a>，获得<code class="docutils literal notranslate"><span class="pre">converter_lite</span></code>工具，并配置环境变量。</p></li>
<li><p>以TensorFlow Lite模型为例，执行权重量化模型转换命令:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite --fmk<span class="o">=</span>TFLITE --modelFile<span class="o">=</span>Inception_v3.tflite --outputFile<span class="o">=</span>Inception_v3.tflite --quantType<span class="o">=</span>WeightQuant --bitNum<span class="o">=</span><span class="m">8</span> --quantWeightSize<span class="o">=</span><span class="m">0</span> --quantWeightChannel<span class="o">=</span><span class="m">0</span>
</pre></div>
</div>
</li>
<li><p>上述命令执行成功后，便可得到量化后的模型<code class="docutils literal notranslate"><span class="pre">Inception_v3.tflite.ms</span></code>，量化后的模型大小通常会下降到FP32模型的1/4。</p></li>
</ol>
</div>
<div class="section" id="id6">
<h3>部分模型精度结果<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th>模型</th>
<th>测试数据集</th>
<th>FP32模型精度</th>
<th>权重量化精度（8bit）</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/model_zoo/upload_20180427/inception_v3_2018_04_27.tgz">Inception_V3</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>77.60%</td>
<td>77.53%</td>
</tr>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz">Mobilenet_V1_1.0_224</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>70.96%</td>
<td>70.56%</td>
</tr>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224.tgz">Mobilenet_V2_1.0_224</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>71.56%</td>
<td>71.53%</td>
</tr>
</tbody>
</table><blockquote>
<div><p>以上所有结果均在x86环境上测得。</p>
</div></blockquote>
</div>
</div>
<div class="section" id="id7">
<h2>全量化<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<p>针对需要提升模型运行速度、降低模型运行功耗的场景，可以使用训练后全量化功能。下面对全量化的使用方式和效果进行阐述。</p>
<div class="section" id="id8">
<h3>参数说明<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>全量化转换命令的一般形式为：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite --fmk<span class="o">=</span>ModelType --modelFile<span class="o">=</span>ModelFilePath --outputFile<span class="o">=</span>ConvertedModelPath --quantType<span class="o">=</span>PostTraining --bitNum<span class="o">=</span><span class="m">8</span> --configFile<span class="o">=</span>config.cfg
</pre></div>
</div>
<p>下面对此命令的量化相关参数进行说明：</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>参数</th>
<th>属性</th>
<th>功能描述</th>
<th>参数类型</th>
<th>默认值</th>
<th>取值范围</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--quantType=&lt;QUANTTYPE&gt;</code></td>
<td>必选</td>
<td>设置为PostTraining，启用全量化</td>
<td>String</td>
<td>-</td>
<td>必须设置为PostTraining</td>
</tr>
<tr>
<td><code>--configFile=&lt;CONFIGFILE&gt;</code></td>
<td>必选</td>
<td>校准数据集配置文件路径</td>
<td>String</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td><code>--bitNum=&lt;BITNUM&gt;</code></td>
<td>可选</td>
<td>设定全量化的比特数，目前支持1bit～8bit量化</td>
<td>Integer</td>
<td>8</td>
<td>[1，8]</td>
</tr>
</tbody>
</table><p>为了计算激活值的量化参数，用户需要提供校准数据集。校准数据集最好来自真实推理场景，能表征模型的实际输入情况，数量在100个左右。
校准数据集配置文件采用<code class="docutils literal notranslate"><span class="pre">key=value</span></code>的方式定义相关参数，需要配置的<code class="docutils literal notranslate"><span class="pre">key</span></code>如下:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>参数名</th>
<th>属性</th>
<th>功能描述</th>
<th>参数类型</th>
<th>默认值</th>
<th>取值范围</th>
</tr>
</thead>
<tbody>
<tr>
<td>image_path</td>
<td>必选</td>
<td>存放校准数据集的目录；如果模型有多个输入，请依次填写对应的数据所在目录，目录路径间请用<code>,</code>隔开</td>
<td>String</td>
<td>-</td>
<td>该目录存放可直接用于执行推理的输入数据。由于目前框架还不支持数据预处理，所有数据必须事先完成所需的转换，使得它们满足推理的输入要求</td>
</tr>
<tr>
<td>batch_count</td>
<td>可选</td>
<td>使用的输入数目</td>
<td>Integer</td>
<td>100</td>
<td>（0，+∞）</td>
</tr>
<tr>
<td>method_x</td>
<td>可选</td>
<td>网络层输入输出数据量化算法</td>
<td>String</td>
<td>KL</td>
<td>KL、MAX_MIN、RemovalOutlier。 <br> KL：基于<a href="http://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf">KL散度</a>对数据范围作量化校准。 <br> MAX_MIN：基于最大值、最小值计算数据的量化参数。 <br> RemovalOutlier：按照一定比例剔除数据的极大极小值，再计算量化参数。 <br> 在校准数据集与实际推理时的输入数据相吻合的情况下，推荐使用MAX_MIN；而在校准数据集噪声比较大的情况下，推荐使用KL或者RemovalOutlier</td>
</tr>
<tr>
<td>thread_num</td>
<td>可选</td>
<td>使用校准数据集执行推理流程时的线程数</td>
<td>Integer</td>
<td>1</td>
<td>（0，+∞）</td>
</tr>
<tr>
<td>bias_correction</td>
<td>可选</td>
<td>是否对量化误差进行校正</td>
<td>Boolean</td>
<td>false</td>
<td>true、flase。使能后，能提升转换后的模型精度，建议设置为true</td>
</tr>
</tbody>
</table><blockquote>
<div><p>对于多输入模型，要求不同输入数据分别存放在各自不同的目录，同时各自目录中的所有文件的文件名按照字典序递增排序后，能够一一对应。例如：模型有两个输入input0、input1，校准数据集共2组（batch_count=2）；input0的对应数据存放在/dir/input0/目录，输入数据文件名为：data_1.bin、data_2.bin；input1的对应数据存放在/dir/input1/目录，输入数据文件名为：data_a.bin、data_b.bin，则认为(data_1.bin, data_a.bin)构成一组输入，（data_2.bin, data_b.bin）构成另一组输入。</p>
</div></blockquote>
</div>
<div class="section" id="id9">
<h3>使用步骤<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<ol>
<li><p>正确编译出<code class="docutils literal notranslate"><span class="pre">converter_lite</span></code>可执行文件。</p></li>
<li><p>准备校准数据集，假设存放在<code class="docutils literal notranslate"><span class="pre">/dir/images</span></code>目录，编写配置文件<code class="docutils literal notranslate"><span class="pre">config.cfg</span></code>，内容如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">image_path</span><span class="o">=/</span><span class="nb">dir</span><span class="o">/</span><span class="n">images</span>
<span class="n">batch_count</span><span class="o">=</span><span class="mi">100</span>
<span class="n">method_x</span><span class="o">=</span><span class="n">MAX_MIN</span>
<span class="n">thread_num</span><span class="o">=</span><span class="mi">1</span>
<span class="n">bias_correction</span><span class="o">=</span><span class="n">true</span>
</pre></div>
</div>
<p>校准数据集可以选择测试数据集的子集，要求<code class="docutils literal notranslate"><span class="pre">/dir/images</span></code>目录下存放的每个文件均是预处理好的输入数据，每个文件都可以直接用于推理的输入。</p>
</li>
<li><p>以MindSpore模型为例，执行全量化的模型转换命令:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./converter_lite --fmk<span class="o">=</span>MINDIR --modelFile<span class="o">=</span>lenet.mindir --outputFile<span class="o">=</span>lenet_quant --quantType<span class="o">=</span>PostTraining --configFile<span class="o">=</span>config.cfg
</pre></div>
</div>
</li>
<li><p>上述命令执行成功后，便可得到量化后的模型<code class="docutils literal notranslate"><span class="pre">lenet_quant.ms</span></code>，通常量化后的模型大小会下降到FP32模型的1/4。</p></li>
</ol>
</div>
<div class="section" id="id10">
<h3>部分模型精度结果<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th>模型</th>
<th>测试数据集</th>
<th>method_x</th>
<th>FP32模型精度</th>
<th>全量化精度（8bit）</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/model_zoo/upload_20180427/inception_v3_2018_04_27.tgz">Inception_V3</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>KL</td>
<td>77.60%</td>
<td>77.40%</td>
<td>校准数据集随机选择ImageNet Validation数据集中的100张</td>
</tr>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz">Mobilenet_V1_1.0_224</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>KL</td>
<td>70.96%</td>
<td>70.31%</td>
<td>校准数据集随机选择ImageNet Validation数据集中的100张</td>
</tr>
<tr>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224.tgz">Mobilenet_V2_1.0_224</a></td>
<td><a href="http://image-net.org/">ImageNet</a></td>
<td>MAX_MIN</td>
<td>71.56%</td>
<td>71.16%</td>
<td>校准数据集随机选择ImageNet Validation数据集中的100张</td>
</tr>
</tbody>
</table><blockquote>
<div><p>以上所有结果均在x86环境上测得，均设置<code class="docutils literal notranslate"><span class="pre">bias_correction=true</span></code>。</p>
</div></blockquote>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="data_preprocessing.html" class="btn btn-neutral float-right" title="预处理数据" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="converter_tool.html" class="btn btn-neutral float-left" title="推理模型转换" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, MindSpore Lite

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>