<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>实现一个图像分类应用（C++） &mdash; MindSpore Lite master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/lite.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script src="../_static/js/lite.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="实现一个图像分割应用（Java）" href="image_segmentation.html" />
    <link rel="prev" title="体验MindSpore Lite Java极简Demo" href="quick_start_java.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore Lite
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">获取MindSpore Lite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/downloads.html">下载MindSpore Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/build.html">编译MindSpore Lite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">快速入门</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="quick_start_cpp.html">体验MindSpore Lite C++极简Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_java.html">体验MindSpore Lite Java极简Demo</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">实现一个图像分类应用（C++）</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">选择模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">转换模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id4">部署应用</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id5">运行依赖</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">构建与运行</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id7">示例程序详细说明</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id8">示例程序结构</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mindspore-lite">配置MindSpore Lite依赖项</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id9">下载及部署模型文件</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">编写端侧推理代码</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="image_segmentation.html">实现一个图像分割应用（Java）</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_codegen.html">使用CodeGen编译一个MNIST分类模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="train_lenet.html">训练一个LeNet模型</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">端侧推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/converter_tool.html">推理模型转换</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/code_generator.html">代码生成工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/post_training_quantization.html">优化模型(训练后量化)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preprocessing.html">预处理数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/runtime.html">执行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/asic.html">专用芯片集成说明</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/tools.html">其他工具</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">端侧训练</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/converter_train.html">训练模型转换</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/runtime_train.html">执行训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/tools_train.html">其他工具</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_lite.html">Lite算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operator_list_codegen.html">Codegen算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_lite.html">模型支持</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore Lite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>实现一个图像分类应用（C++）</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/quick_start/quick_start.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="c">
<h1>实现一个图像分类应用（C++）<a class="headerlink" href="#c" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Android</span></code> <code class="docutils literal notranslate"><span class="pre">C++</span></code> <code class="docutils literal notranslate"><span class="pre">全流程</span></code> <code class="docutils literal notranslate"><span class="pre">模型转换</span></code> <code class="docutils literal notranslate"><span class="pre">模型加载</span></code> <code class="docutils literal notranslate"><span class="pre">推理应用</span></code> <code class="docutils literal notranslate"><span class="pre">数据准备</span></code> <code class="docutils literal notranslate"><span class="pre">初级</span></code> <code class="docutils literal notranslate"><span class="pre">中级</span></code> <code class="docutils literal notranslate"><span class="pre">高级</span></code></p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/lite/source_zh_cn/quick_start/quick_start.md"><img alt="查看源文件" src="../_images/logo_source.png" /></a></p>
<section id="id1">
<h2>概述<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<p>我们推荐你从端侧Android图像分类demo入手，了解MindSpore Lite应用工程的构建、依赖项配置以及相关API的使用。</p>
<p>本教程基于MindSpore团队提供的Android“端侧图像分类”示例程序，演示了端侧部署的流程。</p>
<ol class="arabic simple">
<li><p>选择图像分类模型。</p></li>
<li><p>将模型转换成MindSpore Lite模型格式。</p></li>
<li><p>在端侧使用MindSpore Lite推理模型。详细说明如何在端侧利用MindSpore Lite C++ API（Android JNI）和MindSpore Lite图像分类模型完成端侧推理，实现对设备摄像头捕获的内容进行分类，并在APP图像预览界面中，显示出最可能的分类结果。</p></li>
</ol>
<blockquote>
<div><p>你可以在这里找到<a class="reference external" href="https://download.mindspore.cn/model_zoo/official/lite/mobilenetv2_openimage_lite">Android图像分类模型</a>和<a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.2/model_zoo/official/lite/image_classification">图像分类示例代码</a>。</p>
<p>本示例中讲述了C++ API的应用方法，此外MindSpore Lite还支持Java API。关于Java API的使用请参考<a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.2/model_zoo/official/lite/image_segmentation">图像分割demo</a>。</p>
</div></blockquote>
<p>我们提供了本示例对应的APK文件，你可扫描下方的二维码或直接下载<a class="reference external" href="https://download.mindspore.cn/model_zoo/official/lite/apk/label/Classification.apk">APK文件</a>，并部署到Android设备后使用。</p>
<p><img alt="apk" src="../_images/classification_apk.png" /></p>
</section>
<section id="id2">
<h2>选择模型<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<p>MindSpore团队提供了一系列预置终端模型，你可以在应用程序中使用这些预置的终端模型。<br />
可下载<a class="reference external" href="https://download.mindspore.cn/model_zoo/official/lite/mobilenetv2_openimage_lite/mobilenetv2.ms">MindSpore Model Zoo中图像分类模型</a>。
同时，你也可以使用预置模型做迁移学习，以实现自己的图像分类任务。</p>
</section>
<section id="id3">
<h2>转换模型<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h2>
<p>如果预置模型已经满足你要求，请跳过本章节。 如果你需要对MindSpore提供的模型进行重训，重训完成后，需要将模型导出为<a class="reference external" href="https://www.mindspore.cn/tutorial/training/zh-CN/r1.2/use/save_model.html#mindir">.mindir格式</a>。然后使用MindSpore Lite<a class="reference external" href="https://www.mindspore.cn/tutorial/lite/zh-CN/r1.2/use/converter_tool.html">模型转换工具</a>将.mindir格式转换成.ms格式。</p>
<p>以mobilenetv2模型为例，如下脚本将其转换为MindSpore Lite模型用于端侧推理。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>call<span class="w"> </span>converter_lite<span class="w"> </span>--fmk<span class="o">=</span>MINDIR<span class="w"> </span>--modelFile<span class="o">=</span>mobilenetv2.mindir<span class="w"> </span>--outputFile<span class="o">=</span>mobilenetv2
</pre></div>
</div>
</section>
<section id="id4">
<h2>部署应用<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h2>
<p>接下来介绍如何构建和执行mindspore Lite端侧图像分类任务。</p>
<section id="id5">
<h3>运行依赖<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Android Studio &gt;= 3.2 (推荐4.0以上版本)</p></li>
<li><p>NDK 21.3</p></li>
<li><p><a class="reference external" href="https://cmake.org/download">CMake</a> 3.10.2</p></li>
<li><p>Android SDK &gt;= 26</p></li>
<li><p>JDK &gt;= 1.8</p></li>
</ul>
</section>
<section id="id6">
<h3>构建与运行<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>在Android Studio中加载本示例源码，并安装相应的SDK（指定SDK版本后，由Android Studio自动安装）。</p>
<p><img alt="start_home" src="../_images/lite_quick_start_home.png" /></p>
<p>启动Android Studio后，点击<code class="docutils literal notranslate"><span class="pre">File-&gt;Settings-&gt;System</span> <span class="pre">Settings-&gt;Android</span> <span class="pre">SDK</span></code>，勾选相应的SDK。如下图所示，勾选后，点击<code class="docutils literal notranslate"><span class="pre">OK</span></code>，Android Studio即可自动安装SDK。</p>
<p><img alt="start_sdk" src="../_images/lite_quick_start_sdk.png" /></p>
<p>（可选）若安装时出现NDK版本问题，可手动下载相应的<a class="reference external" href="https://developer.android.com/ndk/downloads?hl=zh-cn">NDK版本</a>（本示例代码使用的NDK版本为21.3），并在<code class="docutils literal notranslate"><span class="pre">Project</span> <span class="pre">Structure</span></code>的<code class="docutils literal notranslate"><span class="pre">Android</span> <span class="pre">NDK</span> <span class="pre">location</span></code>设置中指定NDK的位置。</p>
<p><img alt="project_structure" src="../_images/lite_quick_start_project_structure.png" /></p>
</li>
<li><p>连接Android设备，运行图像分类应用程序。</p>
<p>通过USB连接Android设备调试，点击<code class="docutils literal notranslate"><span class="pre">Run</span> <span class="pre">'app'</span></code>即可在你的设备上运行本示例项目。</p>
<p><img alt="run_app" src="../_images/lite_quick_start_run_app.PNG" /></p>
<p>Android Studio连接设备调试操作，可参考<a class="reference external" href="https://developer.android.com/studio/run/device?hl=zh-cn">https://developer.android.com/studio/run/device?hl=zh-cn</a>。</p>
<p>手机需开启“USB调试模式”，Android Studio才能识别到手机。 华为手机一般在<code class="docutils literal notranslate"><span class="pre">设置-&gt;系统和更新-&gt;开发人员选项-&gt;USB调试</span></code>中打开“USB调试模式”。</p>
</li>
<li><p>在Android设备上，点击“继续安装”，安装完即可查看到设备摄像头捕获的内容和推理结果。</p>
<p><img alt="install" src="../_images/lite_quick_start_install.png" /></p>
<p>识别结果如下图所示。</p>
<p><img alt="result" src="../_images/lite_quick_start_app_result.png" /></p>
</li>
</ol>
</section>
</section>
<section id="id7">
<h2>示例程序详细说明<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h2>
<p>本端侧图像分类Android示例程序分为JAVA层和JNI层，其中，JAVA层主要通过Android Camera 2 API实现摄像头获取图像帧，以及相应的图像处理等功能；JNI层在<a class="reference external" href="https://www.mindspore.cn/tutorial/lite/zh-CN/r1.2/use/runtime.html">Runtime</a>中完成模型推理的过程。</p>
<blockquote>
<div><p>此处详细说明示例程序的JNI层实现，JAVA层运用Android Camera 2 API实现开启设备摄像头以及图像帧处理等功能，需读者具备一定的Android开发基础知识。</p>
</div></blockquote>
<section id="id8">
<h3>示例程序结构<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h3>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>app
├── src/main
│   ├── assets # 资源文件
|   |   └── model # 模型文件
|   |       └── mobilenetv2.ms # 存放的模型文件
│   |
│   ├── cpp # 模型加载和预测主要逻辑封装类
|   |   ├── ..
|   |   ├── mindspore-lite-{version}-android-{arch} # MindSpore Lite版本
|   |   ├── MindSporeNetnative.cpp # MindSpore调用相关的JNI方法
│   |   └── MindSporeNetnative.h # 头文件
|   |   └── MsNetWork.cpp # MindSpore接口封装
│   |
│   ├── java # java层应用代码
│   │   └── com.mindspore.classification
│   │       ├── gallery.classify # 图像处理及MindSpore JNI调用相关实现
│   │       │   └── ...
│   │       └── widget # 开启摄像头及绘制相关实现
│   │           └── ...
│   │
│   ├── res # 存放Android相关的资源文件
│   └── AndroidManifest.xml # Android配置文件
│
├── CMakeList.txt # cmake编译入口文件
│
├── build.gradle # 其他Android配置文件
├── download.gradle # 工程依赖文件下载
└── ...
</pre></div>
</div>
</section>
<section id="mindspore-lite">
<h3>配置MindSpore Lite依赖项<a class="headerlink" href="#mindspore-lite" title="Permalink to this headline"></a></h3>
<p>Android JNI层调用MindSpore C++ API时，需要相关库文件支持。可通过MindSpore Lite<a class="reference external" href="https://www.mindspore.cn/tutorial/lite/zh-CN/r1.2/use/build.html">源码编译</a>生成<code class="docutils literal notranslate"><span class="pre">mindspore-lite-{version}-android-{arch}.tar.gz</span></code>库文件包并解压缩（包含<code class="docutils literal notranslate"><span class="pre">libmindspore-lite.so</span></code>库文件和相关头文件），在本例中需使用生成带图像预处理模块的编译命令。</p>
<blockquote>
<div><p>version：输出件版本号，与所编译的分支代码对应的版本一致。</p>
<p>arch：操作系统，arm64或arm32。</p>
</div></blockquote>
<p>本示例中，build过程由<code class="docutils literal notranslate"><span class="pre">app/download.gradle</span></code>文件自动下载MindSpore Lite版本文件，并放置在<code class="docutils literal notranslate"><span class="pre">app/src/main/cpp/</span></code>目录下。</p>
<p>注： 若自动下载失败，请手动下载操作系统为Android-aarch64/Android-aarch32的MindSpore Lite 模型推理框架相关库文件<a class="reference external" href="https://www.mindspore.cn/tutorial/lite/zh-CN/r1.2/use/downloads.html">mindspore-lite-{version}-android-{arch}.tar.gz</a>，解压后将<code class="docutils literal notranslate"><span class="pre">mindspore-lite-{version}-android-{arch}</span></code>的文件夹拷贝到<code class="docutils literal notranslate"><span class="pre">src/main/cpp</span></code>目录下。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>android{
    defaultConfig{
        externalNativeBuild{
            cmake{
                arguments &quot;-DANDROID_STL=c++_shared&quot;
            }
        }

        ndk{
            abiFilters&#39;armeabi-v7a&#39;, &#39;arm64-v8a&#39;  
        }
    }
}
</pre></div>
</div>
<p>在<code class="docutils literal notranslate"><span class="pre">app/CMakeLists.txt</span></code>文件中建立<code class="docutils literal notranslate"><span class="pre">.so</span></code>库文件链接，如下所示。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># ============== Set MindSpore Dependencies. =============
include_directories(${CMAKE_SOURCE_DIR}/src/main/cpp)
include_directories(${CMAKE_SOURCE_DIR}/src/main/cpp/${MINDSPORELITE_VERSION}/inference)
include_directories(${CMAKE_SOURCE_DIR}/src/main/cpp/${MINDSPORELITE_VERSION}/inference/include)
include_directories(${CMAKE_SOURCE_DIR}/src/main/cpp/${MINDSPORELITE_VERSION}/inference/minddata/include)

add_library(mindspore-lite SHARED IMPORTED)
add_library(minddata-lite SHARED IMPORTED)

set_target_properties(mindspore-lite PROPERTIES IMPORTED_LOCATION
        ${CMAKE_SOURCE_DIR}/src/main/cpp/${MINDSPORELITE_VERSION}/inference/lib/libmindspore-lite.so)
set_target_properties(minddata-lite PROPERTIES IMPORTED_LOCATION
        ${CMAKE_SOURCE_DIR}/src/main/cpp/${MINDSPORELITE_VERSION}/inference/minddata/lib/libminddata-lite.so)
# --------------- MindSpore Lite set End. --------------------

# Link target library.
target_link_libraries( # Specifies the target library.
        mlkit-label-MS

        # --- mindspore ---
        minddata-lite
        mindspore-lite

        # --- other dependencies.---
        -ljnigraphics
        android

        # Links the target library to the log library
        ${log-lib}
        )
</pre></div>
</div>
</section>
<section id="id9">
<h3>下载及部署模型文件<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h3>
<p>从MindSpore Model Hub中下载模型文件，本示例程序中使用的终端图像分类模型文件为<code class="docutils literal notranslate"><span class="pre">mobilenetv2.ms</span></code>，同样通过<code class="docutils literal notranslate"><span class="pre">app/download.gradle</span></code>脚本在APP构建时自动下载，并放置在<code class="docutils literal notranslate"><span class="pre">app/src/main/assets/model</span></code>工程目录下。</p>
<p>注：若下载失败请手工下载模型文件<a class="reference external" href="https://download.mindspore.cn/model_zoo/official/lite/mobilenetv2_openimage_lite/mobilenetv2.ms">mobilenetv2.ms</a>。</p>
</section>
<section id="id10">
<h3>编写端侧推理代码<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h3>
<p>在JNI层调用MindSpore Lite C++ API实现端侧推理。</p>
<p>推理代码流程如下，完整代码请参见<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/model_zoo/official/lite/image_classification/app/src/main/cpp/MindSporeNetnative.cpp">MindSporeNetnative.cpp</a>。</p>
<ol class="arabic">
<li><p>加载MindSpore Lite模型文件，构建上下文、会话以及用于推理的计算图。</p>
<ul>
<li><p>加载模型文件：</p>
<p>在Android的Java层读取模型文件，转换成ByteBuffer类型文件<code class="docutils literal notranslate"><span class="pre">model_buffer</span></code>，通过JNI调用传输到C++层。最终将<code class="docutils literal notranslate"><span class="pre">model_buffer</span></code>转换成char类型文件<code class="docutils literal notranslate"><span class="pre">modelBuffer</span></code>。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Buffer is the model data passed in by the Java layer</span>
<span class="n">jlong</span><span class="w"> </span><span class="n">bufferLen</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">env</span><span class="o">-&gt;</span><span class="n">GetDirectBufferCapacity</span><span class="p">(</span><span class="n">model_buffer</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="mi">0</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">bufferLen</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;error, bufferLen is 0!&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">jlong</span><span class="p">)</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">modelBuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CreateLocalModelBuffer</span><span class="p">(</span><span class="n">env</span><span class="p">,</span><span class="w"> </span><span class="n">model_buffer</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">modelBuffer</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;modelBuffer create failed!&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">jlong</span><span class="p">)</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>构建上下文、会话以及用于推理的计算图：</p>
<p>构建上下文，设置会话参数。通过上下文和模型数据创建会话。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// To create a MindSpore network inference environment.</span>
<span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="n">labelEnv</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">;</span>
<span class="n">MSNetWork</span><span class="w"> </span><span class="o">*</span><span class="n">labelNet</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">MSNetWork</span><span class="p">;</span>
<span class="o">*</span><span class="n">labelEnv</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labelNet</span><span class="p">;</span>

<span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="o">*</span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">Context</span><span class="p">;</span>
<span class="n">context</span><span class="o">-&gt;</span><span class="n">thread_num_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_thread</span><span class="p">;</span>
<span class="n">context</span><span class="o">-&gt;</span><span class="n">device_list_</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">device_info_</span><span class="p">.</span><span class="n">cpu_device_info_</span><span class="p">.</span><span class="n">cpu_bind_mode_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">NO_BIND</span><span class="p">;</span>
<span class="n">context</span><span class="o">-&gt;</span><span class="n">device_list_</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">device_info_</span><span class="p">.</span><span class="n">cpu_device_info_</span><span class="p">.</span><span class="n">enable_float16_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="n">context</span><span class="o">-&gt;</span><span class="n">device_list_</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">device_type_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">DT_CPU</span><span class="p">;</span>

<span class="n">labelNet</span><span class="o">-&gt;</span><span class="n">CreateSessionMS</span><span class="p">(</span><span class="n">modelBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">bufferLen</span><span class="p">,</span><span class="w"> </span><span class="n">context</span><span class="p">);</span>
<span class="k">delete</span><span class="w"> </span><span class="n">context</span><span class="p">;</span>
</pre></div>
</div>
<p>基于模型文件<code class="docutils literal notranslate"><span class="pre">modelBuffer</span></code>构建用于推理的计算图。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">MSNetWork::CreateSessionMS</span><span class="p">(</span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">modelBuffer</span><span class="p">,</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">bufferLen</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="o">*</span><span class="n">ctx</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">session_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">session</span><span class="o">::</span><span class="n">LiteSession</span><span class="o">::</span><span class="n">CreateSession</span><span class="p">(</span><span class="n">ctx</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">session_</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;Create Session failed.&quot;</span><span class="p">);</span>
<span class="w">      </span><span class="k">return</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Compile model.</span>
<span class="w">  </span><span class="n">model_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">Model</span><span class="o">::</span><span class="n">Import</span><span class="p">(</span><span class="n">modelBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">bufferLen</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">model_</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">ReleaseNets</span><span class="p">();</span>
<span class="w">      </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;Import model failed.&quot;</span><span class="p">);</span>
<span class="w">      </span><span class="k">return</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session_</span><span class="o">-&gt;</span><span class="n">CompileGraph</span><span class="p">(</span><span class="n">model_</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ret</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">lite</span><span class="o">::</span><span class="n">RET_OK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="n">ReleaseNets</span><span class="p">();</span>
<span class="w">       </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;CompileGraph failed.&quot;</span><span class="p">);</span>
<span class="w">       </span><span class="k">return</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>将输入图片转换为传入MindSpore模型的Tensor格式。</p>
<ul>
<li><p>将待检测图片<code class="docutils literal notranslate"><span class="pre">srcBitmap</span></code>进行尺寸裁剪并转换为LiteMat格式<code class="docutils literal notranslate"><span class="pre">lite_norm_mat_cut</span></code>。对其宽高以及通道数信息转换成float格式数据<code class="docutils literal notranslate"><span class="pre">dataHWC</span></code>。最终把<code class="docutils literal notranslate"><span class="pre">dataHWC</span></code>拷贝到MindSpore模型的Tensor输入<code class="docutils literal notranslate"><span class="pre">inTensor</span></code>中。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">BitmapToLiteMat</span><span class="p">(</span><span class="n">env</span><span class="p">,</span><span class="w"> </span><span class="n">srcBitmap</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lite_mat_bgr</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;BitmapToLiteMat error&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span>
<span class="w"> </span><span class="p">}</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">PreProcessImageData</span><span class="p">(</span><span class="n">lite_mat_bgr</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lite_norm_mat_cut</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;PreProcessImageData error&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span>
<span class="w"> </span><span class="p">}</span>

<span class="n">ImgDims</span><span class="w"> </span><span class="n">inputDims</span><span class="p">;</span>
<span class="n">inputDims</span><span class="p">.</span><span class="n">channel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lite_norm_mat_cut</span><span class="p">.</span><span class="n">channel_</span><span class="p">;</span>
<span class="n">inputDims</span><span class="p">.</span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lite_norm_mat_cut</span><span class="p">.</span><span class="n">width_</span><span class="p">;</span>
<span class="n">inputDims</span><span class="p">.</span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lite_norm_mat_cut</span><span class="p">.</span><span class="n">height_</span><span class="p">;</span>

<span class="c1">// Get the MindSpore inference environment which created in loadModel().</span>
<span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="n">labelEnv</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">void</span><span class="w"> </span><span class="o">**&gt;</span><span class="p">(</span><span class="n">netEnv</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">labelEnv</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;MindSpore error, labelEnv is a nullptr.&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span>
<span class="w"> </span><span class="p">}</span>
<span class="n">MSNetWork</span><span class="w"> </span><span class="o">*</span><span class="n">labelNet</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="n">MSNetWork</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="o">*</span><span class="n">labelEnv</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">mSession</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labelNet</span><span class="o">-&gt;</span><span class="n">session</span><span class="p">();</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">mSession</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">nullptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;MindSpore error, Session is a nullptr.&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w"> </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;MindSpore get session.&quot;</span><span class="p">);</span>

<span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">msInputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mSession</span><span class="o">-&gt;</span><span class="n">GetInputs</span><span class="p">();</span>
<span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">msInputs</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;MindSpore error, msInputs.size() equals 0.&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">inTensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">msInputs</span><span class="p">.</span><span class="n">front</span><span class="p">();</span>

<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">dataHWC</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">lite_norm_mat_cut</span><span class="p">.</span><span class="n">data_ptr_</span><span class="p">);</span>
<span class="w">  </span><span class="c1">// Copy dataHWC to the model input tensor.</span>
<span class="w">  </span><span class="n">memcpy</span><span class="p">(</span><span class="n">inTensor</span><span class="o">-&gt;</span><span class="n">MutableData</span><span class="p">(),</span><span class="w"> </span><span class="n">dataHWC</span><span class="p">,</span>
<span class="w">     </span><span class="n">inputDims</span><span class="p">.</span><span class="n">channel</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">inputDims</span><span class="p">.</span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">inputDims</span><span class="p">.</span><span class="n">height</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
</pre></div>
</div>
<p>调整输入图片的尺寸，以及数据处理详细算法。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">bool</span><span class="w"> </span><span class="nf">PreProcessImageData</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">LiteMat</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lite_mat_bgr</span><span class="p">,</span><span class="w"> </span><span class="n">LiteMat</span><span class="w"> </span><span class="o">*</span><span class="n">lite_norm_mat_ptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">  </span><span class="n">LiteMat</span><span class="w"> </span><span class="n">lite_mat_resize</span><span class="p">;</span>
<span class="w">  </span><span class="n">LiteMat</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lite_norm_mat_cut</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">lite_norm_mat_ptr</span><span class="p">;</span>
<span class="w">  </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ResizeBilinear</span><span class="p">(</span><span class="n">lite_mat_bgr</span><span class="p">,</span><span class="w"> </span><span class="n">lite_mat_resize</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">ret</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;ResizeBilinear error&quot;</span><span class="p">);</span>
<span class="w">     </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">LiteMat</span><span class="w"> </span><span class="n">lite_mat_convert_float</span><span class="p">;</span>
<span class="w">  </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ConvertTo</span><span class="p">(</span><span class="n">lite_mat_resize</span><span class="p">,</span><span class="w"> </span><span class="n">lite_mat_convert_float</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">255.0</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">ret</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;ConvertTo error&quot;</span><span class="p">);</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">LiteMat</span><span class="w"> </span><span class="n">lite_mat_cut</span><span class="p">;</span>
<span class="w">  </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Crop</span><span class="p">(</span><span class="n">lite_mat_convert_float</span><span class="p">,</span><span class="w"> </span><span class="n">lite_mat_cut</span><span class="p">,</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span><span class="w"> </span><span class="mi">224</span><span class="p">,</span><span class="w"> </span><span class="mi">224</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">ret</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;Crop error&quot;</span><span class="p">);</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">means</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mf">0.485</span><span class="p">,</span><span class="w"> </span><span class="mf">0.456</span><span class="p">,</span><span class="w"> </span><span class="mf">0.406</span><span class="p">};</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">stds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mf">0.229</span><span class="p">,</span><span class="w"> </span><span class="mf">0.224</span><span class="p">,</span><span class="w"> </span><span class="mf">0.225</span><span class="p">};</span>
<span class="w">  </span><span class="n">SubStractMeanNormalize</span><span class="p">(</span><span class="n">lite_mat_cut</span><span class="p">,</span><span class="w"> </span><span class="n">lite_norm_mat_cut</span><span class="p">,</span><span class="w"> </span><span class="n">means</span><span class="p">,</span><span class="w"> </span><span class="n">stds</span><span class="p">);</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w"> </span><span class="p">}</span>
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>对输入Tensor按照模型进行推理，获取输出Tensor，并进行后处理。</p>
<ul>
<li><p>图和模型加载完成，执行端侧推理。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// After the model and image tensor data is loaded, run inference.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mSession</span><span class="o">-&gt;</span><span class="n">RunGraph</span><span class="p">();</span>
</pre></div>
</div>
</li>
<li><p>获取对MindSpore模型的Tensor输出<code class="docutils literal notranslate"><span class="pre">msOutputs</span></code>。通过<code class="docutils literal notranslate"><span class="pre">msOutputs</span></code>以及分类数组信息，计算得到在APP中显示的文本信息<code class="docutils literal notranslate"><span class="pre">resultCharData</span></code>。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mSession</span><span class="o">-&gt;</span><span class="n">GetOutputTensorNames</span><span class="p">();</span>
<span class="n">std</span><span class="o">::</span><span class="n">unordered_map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">msOutputs</span><span class="p">;</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">name</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">names</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">temp_dat</span><span class="w"> </span><span class="o">=</span><span class="n">mSession</span><span class="o">-&gt;</span><span class="n">GetOutputByTensorName</span><span class="p">(</span><span class="n">name</span><span class="p">);</span>
<span class="w">    </span><span class="n">msOutputs</span><span class="p">.</span><span class="n">insert</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="p">{</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">temp_dat</span><span class="p">});</span>
<span class="w">  </span><span class="p">}</span>
<span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">resultStr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ProcessRunnetResult</span><span class="p">(</span><span class="o">::</span><span class="n">RET_CATEGORY_SUM</span><span class="p">,</span><span class="o">::</span><span class="n">labels_name_map</span><span class="p">,</span><span class="w"> </span><span class="n">msOutputs</span><span class="p">);</span>

<span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">resultCharData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">resultStr</span><span class="p">.</span><span class="n">c_str</span><span class="p">();</span>
<span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">env</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">NewStringUTF</span><span class="p">(</span><span class="n">resultCharData</span><span class="p">);</span>
</pre></div>
</div>
<p>输出数据的后续处理。通过<code class="docutils literal notranslate"><span class="pre">msOutputs</span></code>获取输出对象<code class="docutils literal notranslate"><span class="pre">outputTensor</span></code>，并和事物类别数组<code class="docutils literal notranslate"><span class="pre">labels_name_map</span></code>解析得到每个元素的训练的得分数组<code class="docutils literal notranslate"><span class="pre">scores[]</span></code>。 设置可信度阀值为<code class="docutils literal notranslate"><span class="pre">unifiedThre</span></code>，根据训练数据统计可信度阀值。高于阀值，归属于这个类型。反之，则不是。最终返回一个对应事物类别名称和对应得分的数据<code class="docutils literal notranslate"><span class="pre">categoryScore</span></code>。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="nf">ProcessRunnetResult</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">RET_CATEGORY_SUM</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="k">const</span><span class="w"> </span><span class="n">labels_name_map</span><span class="p">[],</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">unordered_map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">msOutputs</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="c1">// Get the branch of the model output.</span>
<span class="c1">// Use iterators to get map elements.</span>
<span class="n">std</span><span class="o">::</span><span class="n">unordered_map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">tensor</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="o">*&gt;::</span><span class="n">iterator</span><span class="w"> </span><span class="n">iter</span><span class="p">;</span>
<span class="n">iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">msOutputs</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span>

<span class="c1">// The mobilenetv2.ms model output just one branch.</span>
<span class="k">auto</span><span class="w"> </span><span class="n">outputTensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iter</span><span class="o">-&gt;</span><span class="n">second</span><span class="p">;</span>

<span class="kt">int</span><span class="w"> </span><span class="n">tensorNum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outputTensor</span><span class="o">-&gt;</span><span class="n">ElementsNum</span><span class="p">();</span>
<span class="n">MS_PRINT</span><span class="p">(</span><span class="s">&quot;Number of tensor elements:%d&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">tensorNum</span><span class="p">);</span>

<span class="c1">// Get a pointer to the first score.</span>
<span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">temp_scores</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">outputTensor</span><span class="o">-&gt;</span><span class="n">MutableData</span><span class="p">());</span>
<span class="kt">float</span><span class="w"> </span><span class="n">scores</span><span class="p">[</span><span class="n">RET_CATEGORY_SUM</span><span class="p">];</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">RET_CATEGORY_SUM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">temp_scores</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>

<span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">unifiedThre</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.5</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">probMax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">RET_CATEGORY_SUM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="kt">float</span><span class="w"> </span><span class="n">threshold</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">g_thres_map</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">     </span><span class="kt">float</span><span class="w"> </span><span class="n">tmpProb</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tmpProb</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">threshold</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">tmpProb</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmpProb</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">threshold</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">unifiedThre</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">tmpProb</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">tmpProb</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">threshold</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">probMax</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">threshold</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">unifiedThre</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">unifiedThre</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmpProb</span><span class="p">;</span>
<span class="p">}</span>

<span class="w"> </span><span class="c1">// Score for each category.</span>
<span class="w"> </span><span class="c1">// Converted to text information that needs to be displayed in the APP.</span>
<span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">categoryScore</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;&quot;</span><span class="p">;</span>
<span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">RET_CATEGORY_SUM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="n">categoryScore</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">labels_name_map</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">     </span><span class="n">categoryScore</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s">&quot;:&quot;</span><span class="p">;</span>
<span class="w">     </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">score_str</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">to_string</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">     </span><span class="n">categoryScore</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">score_str</span><span class="p">;</span>
<span class="w">     </span><span class="n">categoryScore</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s">&quot;;&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">categoryScore</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="quick_start_java.html" class="btn btn-neutral float-left" title="体验MindSpore Lite Java极简Demo" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="image_segmentation.html" class="btn btn-neutral float-right" title="实现一个图像分割应用（Java）" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore Lite.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>