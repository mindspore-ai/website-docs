

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Migrating From Third Party Frameworks With Tools &mdash; MindSpore master documentation</title>
  

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Migrating Training Scripts from Third Party Frameworks" href="migrate_3rd_scripts.html" />
    <link rel="prev" title="Migrating Training Scripts from Third Party Frameworks" href="migrate_script.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/linear_regression.html">Implementing Simple Linear Function Fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">Defining the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/save_model.html">Saving Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/load_model_for_inference_and_transfer.html">Loading a Model for Inference and Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/publish_model.html">Publishing Models using MindSpore Hub</a></li>
</ul>
<p class="caption"><span class="caption-text">Process Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="convert_dataset.html">Converting Dataset to MindRecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimize_data_processing.html">Optimizing Data Processing</a></li>
</ul>
<p class="caption"><span class="caption-text">Build Networks</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="custom_operator.html">Custom Operator</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="migrate_script.html">Migrating Training Scripts from Third Party Frameworks</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Migrating From Third Party Frameworks With Tools</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#installation">Installation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#usage">Usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scenario">Scenario</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example">Example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#ast-based-conversion">AST-Based Conversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="#graph-based-conversion">Graph-Based Conversion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#caution">Caution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="migrate_3rd_scripts.html">Migrating Training Scripts from Third Party Frameworks</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization_tutorials.html">Training Process Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_augmentation.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluate_the_model_during_training.html">Evaluating the Model during Training</a></li>
</ul>
<p class="caption"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_tutorials.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying Gradient Accumulation Algorithm</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Compression</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
</ul>
<p class="caption"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="migrate_script.html">Migrating Training Scripts from Third Party Frameworks</a> &raquo;</li>
        
      <li>Migrating From Third Party Frameworks With Tools</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/advanced_use/migrate_3rd_scripts_mindconverter.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="migrating-from-third-party-frameworks-with-tools">
<h1>Migrating From Third Party Frameworks With Tools<a class="headerlink" href="#migrating-from-third-party-frameworks-with-tools" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Development</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code></p>
<!-- TOC --><ul class="simple">
<li><p><a class="reference external" href="#migrating-from-third-party-frameworks-with-tools">Migrating From Third Party Frameworks With Tools</a></p>
<ul>
<li><p><a class="reference external" href="#overview">Overview</a></p></li>
<li><p><a class="reference external" href="#installation">Installation</a></p></li>
<li><p><a class="reference external" href="#usage">Usage</a></p></li>
<li><p><a class="reference external" href="#scenario">Scenario</a></p></li>
<li><p><a class="reference external" href="#example">Example</a></p>
<ul>
<li><p><a class="reference external" href="#ast-based-conversion">AST-Based Conversion</a></p></li>
<li><p><a class="reference external" href="#graph-based-conversion">Graph-Based Conversion</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#caution">Caution</a></p></li>
</ul>
</li>
</ul>
<!-- /TOC --><p><a href="https://gitee.com/mindspore/docs/blob/r1.0/tutorials/training/source_en/advanced_use/migrate_3rd_scripts_mindconverter.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>MindConverter is a migration tool to transform the model scripts from PyTorch to Mindspore. Users can migrate their PyTorch models to Mindspore rapidly with minor changes according to the conversion report.</p>
</div>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>Mindconverter is a submodule in MindInsight. Please follow the <a class="reference external" href="https://www.mindspore.cn/install/en">Guide</a> here to install MindInsight.</p>
</div>
<div class="section" id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h2>
<p>MindConverter currently only provides command-line interface. Here is the manual page.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>usage: mindconverter <span class="o">[</span>-h<span class="o">]</span> <span class="o">[</span>--version<span class="o">]</span> <span class="o">[</span>--in_file IN_FILE<span class="o">]</span>
                     <span class="o">[</span>--model_file MODEL_FILE<span class="o">]</span> <span class="o">[</span>--shape SHAPE<span class="o">]</span>
                     <span class="o">[</span>--output OUTPUT<span class="o">]</span> <span class="o">[</span>--report REPORT<span class="o">]</span>
                     <span class="o">[</span>--project_path PROJECT_PATH<span class="o">]</span>

optional arguments:
  -h, --help            show this <span class="nb">help</span> message and <span class="nb">exit</span>
  --version             show program version number and <span class="nb">exit</span>
  --in_file IN_FILE     Specify path <span class="k">for</span> script file to use AST schema to <span class="k">do</span>
                        script conversation.
  --model_file MODEL_FILE
                        PyTorch .pth model file path to use graph based schema
                        to <span class="k">do</span> script generation. When <span class="sb">`</span>--in_file<span class="sb">`</span> and
                        <span class="sb">`</span>--model_file<span class="sb">`</span> are both provided, use AST schema as
                        default.
  --shape SHAPE         Optional, expected input tensor shape of
                        <span class="sb">`</span>--model_file<span class="sb">`</span>. It is required when use graph based
                        schema. Usage: --shape <span class="m">3</span>,244,244
  --output OUTPUT       Optional, specify path <span class="k">for</span> converted script file
                        directory. Default output directory is <span class="sb">`</span>output<span class="sb">`</span> folder
                        in the current working directory.
  --report REPORT       Optional, specify report directory. Default is
                        converted script directory.
  --project_path PROJECT_PATH
                        Optional, PyTorch scripts project path. If PyTorch
                        project is not in PYTHONPATH, please assign
                        <span class="sb">`</span>--project_path<span class="sb">`</span> when use graph based schema. Usage:
                        --project_path ~/script_file/
</pre></div>
</div>
<p><strong>MindConverter provides two modes：</strong></p>
<ol class="simple">
<li><p><strong>Abstract Syntax Tree (AST) based conversion</strong>：Use the argument <code class="docutils literal notranslate"><span class="pre">--in_file</span></code> will enable the AST mode.</p></li>
<li><p><strong>Computational Graph basedconversion</strong>：Use <code class="docutils literal notranslate"><span class="pre">--model_file</span></code> and <code class="docutils literal notranslate"><span class="pre">--shape</span></code> arguments will enable the Graph mode.</p></li>
</ol>
<blockquote>
<div><p>The AST mode will be enabled, if both <code class="docutils literal notranslate"><span class="pre">--in_file</span></code> and <code class="docutils literal notranslate"><span class="pre">--model_file</span></code> are specified.</p>
</div></blockquote>
<p>For the Graph mode, <code class="docutils literal notranslate"><span class="pre">--shape</span></code> is mandatory.</p>
<p>For the AST mode, <code class="docutils literal notranslate"><span class="pre">--shape</span></code> is ignored.</p>
<p><code class="docutils literal notranslate"><span class="pre">--output</span></code> and <code class="docutils literal notranslate"><span class="pre">--report</span></code> is optional. MindConverter creates an <code class="docutils literal notranslate"><span class="pre">output</span></code> folder under the current working directory, and outputs generated scripts and conversion reports to it.</p>
<p>Please note that your original PyTorch project is included in the module search path (PYTHONPATH). Use the python interpreter and test your module can be successfully loaded by <code class="docutils literal notranslate"><span class="pre">import</span></code> command. Use <code class="docutils literal notranslate"><span class="pre">--project_path</span></code> instead if your project is not in the PYTHONPATH to ensure MindConverter can load it.</p>
<blockquote>
<div><p>Assume the project is located at <code class="docutils literal notranslate"><span class="pre">/home/user/project/model_training</span></code>, users can use this command to add the project to <code class="docutils literal notranslate"><span class="pre">PYTHONPATH</span></code> : <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">PYTHONPATH=/home/user/project/model_training:$PYTHONPATH</span></code></p>
</div></blockquote>
<blockquote>
<div><p>MindConverter needs the original PyTorch scripts because of the reverse serialization.</p>
</div></blockquote>
</div>
<div class="section" id="scenario">
<h2>Scenario<a class="headerlink" href="#scenario" title="Permalink to this headline">¶</a></h2>
<p>MindConverter provides two modes for different migration demands.</p>
<ol class="simple">
<li><p>Keep original scripts’ structures, including variables, functions, and libraries.</p></li>
<li><p>Keep extra modifications as few as possible, or no modifications are required after conversion.</p></li>
</ol>
<p>The AST mode is recommended for the first demand. It parses and analyzes PyTorch scripts, then replace them with the MindSpore AST to generate codes. Theoretically, The AST mode supports any model script. However, the conversion may differ due to the coding style of original scripts.</p>
<p>For the second demand, the Graph mode is recommended. As the computational graph is a standard descriptive language, it is not affected by user’s coding style. This mode may have more operators converted as long as these operators are supported by MindConverter.</p>
<p>Some typical image classification networks such as ResNet and VGG have been tested for the Graph mode. Note that:</p>
<blockquote>
<div><ol class="simple">
<li><p>Currently, the Graph mode does not support models with multiple inputs. Only models with a single input and single output are supported.</p></li>
<li><p>The Dropout operator will be lost after conversion because the inference mode is used to load the PyTorch model. Manually re-implement is necessary.</p></li>
<li><p>The Graph-based mode will be continuously developed and optimized with further updates.</p></li>
</ol>
</div></blockquote>
</div>
<div class="section" id="example">
<h2>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h2>
<div class="section" id="ast-based-conversion">
<h3>AST-Based Conversion<a class="headerlink" href="#ast-based-conversion" title="Permalink to this headline">¶</a></h3>
<p>Assume the PyTorch script is located at <code class="docutils literal notranslate"><span class="pre">/home/user/model.py</span></code>, and outputs the transformed MindSpore script to <code class="docutils literal notranslate"><span class="pre">/home/user/output</span></code>, with the conversion report to <code class="docutils literal notranslate"><span class="pre">/home/user/output/report</span></code>. Use the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mindconverter --in_file /home/user/model.py <span class="se">\</span>
              --output /home/user/output <span class="se">\</span>
              --report /home/user/output/report
</pre></div>
</div>
<p>In the conversion report, non-transformed code is listed as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>line &lt;row&gt;:&lt;col&gt; [UnConvert] &#39;operator&#39; didn&#39;t convert. ...
</pre></div>
</div>
<p>For non-transformed operators, the original code keeps. Please manually migrate them. <a class="reference external" href="https://www.mindspore.cn/doc/note/en/r1.0/index.html#operator_api">Click here</a> for more information about operator mapping.</p>
<p>Here is an example of the conversion report:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span> [Start Convert]
 [Insert] &#39;import mindspore.ops.operations as P&#39; is inserted to the converted file.
 line 1:0: [Convert] &#39;import torch&#39; is converted to &#39;import mindspore&#39;.
 ...
 line 157:23: [UnConvert] &#39;nn.AdaptiveAvgPool2d&#39; didn&#39;t convert. Maybe could convert to mindspore.ops.operations.ReduceMean.
 ...
 [Convert Over]
</pre></div>
</div>
<p>For non-transformed operators, suggestions are provided in the report. For instance, MindConverter suggests that replace <code class="docutils literal notranslate"><span class="pre">torch.nn.AdaptiveAvgPool2d</span></code> with <code class="docutils literal notranslate"><span class="pre">mindspore.ops.operations.ReduceMean</span></code>.</p>
</div>
<div class="section" id="graph-based-conversion">
<h3>Graph-Based Conversion<a class="headerlink" href="#graph-based-conversion" title="Permalink to this headline">¶</a></h3>
<p>Assume the PyTorch model (.pth file) is located at <code class="docutils literal notranslate"><span class="pre">/home/user/model.pth</span></code>, with input shape (3, 224, 224) and the original PyTorch script is at <code class="docutils literal notranslate"><span class="pre">/home/user/project/model_training</span></code>. Output the transformed MindSpore script to <code class="docutils literal notranslate"><span class="pre">/home/user/output</span></code>, with the conversion report to <code class="docutils literal notranslate"><span class="pre">/home/user/output/report</span></code>. Use the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mindconverter --model_file /home/user/model.pth --shape <span class="m">3</span>,224,224 <span class="se">\</span>
              --output /home/user/output <span class="se">\</span>
              --report /home/user/output/report <span class="se">\</span>
              --project_path /home/user/project/model_training
</pre></div>
</div>
<p>The Graph mode has the same conversion report as the AST mode. However, the line number and column number refer to the transformed scripts since no original scripts are used in the process.</p>
<p>In addition, input and output Tensor shape of unconverted operators shows explicitly (<code class="docutils literal notranslate"><span class="pre">input_shape</span></code> and <code class="docutils literal notranslate"><span class="pre">output_shape</span></code>) as comments in converted scripts to help further manual modifications. Here is an example of the <code class="docutils literal notranslate"><span class="pre">Reshape</span></code> operator (Not supported in current version):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                                    <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="c1"># Suppose input of `reshape` is x.</span>
        <span class="n">reshape_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>It is convenient to replace the operators according to the <code class="docutils literal notranslate"><span class="pre">input_shape</span></code> and <code class="docutils literal notranslate"><span class="pre">output_shape</span></code> parameters. The replacement is like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="o">...</span>

<span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                                 <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="c1"># Suppose input of `reshape` is x.</span>
        <span class="n">reshape_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>
        <span class="o">...</span>
</pre></div>
</div>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">--output</span></code> and <code class="docutils literal notranslate"><span class="pre">--report</span></code> are optional. MindConverter creates an <code class="docutils literal notranslate"><span class="pre">output</span></code> folder under the current working directory, and outputs generated scripts and conversion reports to it.</p>
</div></blockquote>
</div>
</div>
<div class="section" id="caution">
<h2>Caution<a class="headerlink" href="#caution" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>PyTorch is not an explicitly stated dependency library in MindInsight. The Graph conversion requires the consistent PyTorch version as the model is trained. (MindConverter recommends PyTorch 1.4.0 or 1.6.0)</p></li>
<li><p>This script conversion tool relies on operators which supported by MindConverter and MindSpore. Unsupported operators may not successfully mapped to MindSpore operators. You can manually edit, or implement the mapping based on MindConverter, and contribute to our MindInsight repository. We appreciate your support for the MindSpore community.</p></li>
</ol>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="migrate_3rd_scripts.html" class="btn btn-neutral float-right" title="Migrating Training Scripts from Third Party Frameworks" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="migrate_script.html" class="btn btn-neutral float-left" title="Migrating Training Scripts from Third Party Frameworks" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, MindSpore

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>