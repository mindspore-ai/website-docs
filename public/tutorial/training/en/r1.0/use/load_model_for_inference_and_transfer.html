<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Loading a Model for Inference and Transfer Learning &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Publishing Models using MindSpore Hub" href="publish_model.html" />
    <link rel="prev" title="Saving Models" href="save_model.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/linear_regression.html">Implementing Simple Linear Function Fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Use</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="data_preparation.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="defining_the_network.html">Defining the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_model.html">Saving Models</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Loading a Model for Inference and Transfer Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#loading-the-local-model">Loading the local Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#for-inference-validation">For Inference Validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#for-transfer-training">For Transfer Training</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#loading-the-model-from-hub">Loading the Model from Hub</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">For Inference Validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">For Transfer Training</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="publish_model.html">Publishing Models using MindSpore Hub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Process Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/convert_dataset.html">Converting Dataset to MindRecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/optimize_data_processing.html">Optimizing Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build Networks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/custom_operator.html">Custom Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/migrate_script.html">Migrating Training Scripts from Third Party Frameworks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/visualization_tutorials.html">Training Process Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/enable_auto_augmentation.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/evaluate_the_model_during_training.html">Evaluating the Model during Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/distributed_training_tutorials.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/apply_gradient_accumulation.html">Applying Gradient Accumulation Algorithm</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Compression</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/nlp.html">Natural Language Processing</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Loading a Model for Inference and Transfer Learning</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/use/load_model_for_inference_and_transfer.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="loading-a-model-for-inference-and-transfer-learning">
<h1>Loading a Model for Inference and Transfer Learning<a class="headerlink" href="#loading-a-model-for-inference-and-transfer-learning" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Loading</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.0/tutorials/training/source_en/use/load_model_for_inference_and_transfer.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>CheckPoints which are saved locally during model training, or download from <a class="reference external" href="https://www.mindspore.cn/resources/hub/">MindSpore Hub</a> are used for inference and transfer training.</p>
<p>The following uses examples to describe how to load models from local and MindSpore Hub.</p>
</section>
<section id="loading-the-local-model">
<h2>Loading the local Model<a class="headerlink" href="#loading-the-local-model" title="Permalink to this headline"></a></h2>
<p>After saving CheckPoint files, you can load parameters.</p>
<section id="for-inference-validation">
<h3>For Inference Validation<a class="headerlink" href="#for-inference-validation" title="Permalink to this headline"></a></h3>
<p>In inference-only scenarios, use <code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code> to directly load parameters to the network for subsequent inference validation.</p>
<p>The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">resnet</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">()</span>
<span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50-2_32.ckpt&quot;</span><span class="p">,</span> <span class="n">net</span><span class="o">=</span><span class="n">resnet</span><span class="p">)</span>
<span class="n">dateset_eval</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">mnist_path</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">),</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># define the test dataset</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;accuracy&quot;</span><span class="p">})</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset_eval</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code> method loads network parameters in the parameter file to the model. After the loading, parameters in the network are those saved in CheckPoints.
The <code class="docutils literal notranslate"><span class="pre">eval</span></code> method validates the accuracy of the trained model.</p>
</section>
<section id="for-transfer-training">
<h3>For Transfer Training<a class="headerlink" href="#for-transfer-training" title="Permalink to this headline"></a></h3>
<p>In the retraining and fine-tuning scenarios for task interruption, you can load network parameters and optimizer parameters to the model.</p>
<p>The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># return a parameter dict for model</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50-2_32.ckpt&quot;</span><span class="p">)</span>
<span class="n">resnet</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">()</span>
<span class="c1"># load the parameter into net</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="c1"># load the parameter into optimizer</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code> method returns a parameter dictionary and then the <code class="docutils literal notranslate"><span class="pre">load_param_into_net</span></code> method loads parameters in the parameter dictionary to the network or optimizer.</p>
</section>
</section>
<section id="loading-the-model-from-hub">
<h2>Loading the Model from Hub<a class="headerlink" href="#loading-the-model-from-hub" title="Permalink to this headline"></a></h2>
<section id="id1">
<h3>For Inference Validation<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">mindspore_hub.load</span></code> API is used to load the pre-trained model in a single line of code. The main process of model loading is as follows:</p>
<ol class="arabic">
<li><p>Search the model of interest on <a class="reference external" href="https://www.mindspore.cn/resources/hub">MindSpore Hub Website</a>.</p>
<p>For example, if you aim to perform image classification on CIFAR-10 dataset using GoogleNet, please search on <a class="reference external" href="https://www.mindspore.cn/resources/hub">MindSpore Hub Website</a> with the keyword <code class="docutils literal notranslate"><span class="pre">GoogleNet</span></code>. Then all related models will be returned.  Once you enter into the related model page, you can get the website <code class="docutils literal notranslate"><span class="pre">url</span></code>.</p>
</li>
<li><p>Complete the task of loading model using <code class="docutils literal notranslate"><span class="pre">url</span></code> , as shown in the example below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="kn">import</span> <span class="nn">mindspore_hub</span> <span class="k">as</span> <span class="nn">mshub</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.train.model</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision.py_transforms</span> <span class="k">as</span> <span class="nn">py_transforms</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span>
                     <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">,</span>
                     <span class="n">device_id</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="s2">&quot;mindspore/ascend/0.7/googlenet_v1_cifar10&quot;</span>

<span class="c1"># Initialize the number of classes based on the pre-trained model.</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">mshub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">network</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># ...</span>

</pre></div>
</div>
</li>
<li><p>After loading the model, you can use MindSpore to do inference. You can refer to <a class="reference external" href="https://www.mindspore.cn/tutorial/inference/en/r1.0/multi_platform_inference.html">here</a>.</p></li>
</ol>
</section>
<section id="id2">
<h3>For Transfer Training<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<p>When loading a model with <code class="docutils literal notranslate"><span class="pre">mindspore_hub.load</span></code> API, we can add an extra argument to load the feature extraction part of the model only. So we can easily add new layers to perform transfer learning. This feature can be found in the related model page when an extra argument (e.g., include_top) has been integrated into the model construction by the model developer. The value of <code class="docutils literal notranslate"><span class="pre">include_top</span></code> is True or False, indicating whether to keep the top layer in the fully-connected network.</p>
<p>We use GoogleNet as example to illustrate how to load a model trained on ImageNet dataset and then perform transfer learning (re-training) on specific sub-task dataset. The main steps are listed below:</p>
<ol class="arabic">
<li><p>Search the model of interest on <a class="reference external" href="https://www.mindspore.cn/resources/hub/">MindSpore Hub Website</a> and get the related <code class="docutils literal notranslate"><span class="pre">url</span></code>.</p></li>
<li><p>Load the model from MindSpore Hub using the <code class="docutils literal notranslate"><span class="pre">url</span></code>. Note that the parameter <code class="docutils literal notranslate"><span class="pre">include_top</span></code> is provided by the model developer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">save_checkpoint</span>
<span class="kn">from</span> <span class="nn">mindspore.nn.loss</span> <span class="kn">import</span> <span class="n">SoftmaxCrossEntropyWithLogits</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Momentum</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">mindspore_hub</span> <span class="k">as</span> <span class="nn">mshub</span>
<span class="kn">from</span> <span class="nn">src.dataset</span> <span class="kn">import</span> <span class="n">create_dataset</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">,</span>
                     <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model_url</span> <span class="o">=</span> <span class="s2">&quot;mindspore/ascend/0.7/googlenet_v1_cifar10&quot;</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">mshub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_url</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">network</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Add a new classification layer into current model architecture.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ReduceMeanFlatten</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
      <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
         <span class="nb">super</span><span class="p">(</span><span class="n">ReduceMeanFlatten</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">(</span><span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>

      <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
         <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
         <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
         <span class="k">return</span> <span class="n">x</span>

<span class="c1"># Check MindSpore Hub website to conclude that the last output shape is 1024.</span>
<span class="n">last_channel</span> <span class="o">=</span> <span class="mi">1024</span>

<span class="c1"># The number of classes in target task is 26.</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">26</span>

<span class="n">reducemean_flatten</span> <span class="o">=</span> <span class="n">ReduceMeanFlatten</span><span class="p">()</span>

<span class="n">classification_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">last_channel</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="n">classification_layer</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">train_network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span><span class="n">network</span><span class="p">,</span> <span class="n">reducemean_flatten</span><span class="p">,</span> <span class="n">classification_layer</span><span class="p">])</span>
</pre></div>
</div>
</li>
<li><p>Define <code class="docutils literal notranslate"><span class="pre">loss</span></code> and <code class="docutils literal notranslate"><span class="pre">optimizer</span></code> for training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">epoch_size</span> <span class="o">=</span> <span class="mi">60</span>

<span class="c1"># Wrap the backbone network with loss.</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="n">loss_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">WithLossCell</span><span class="p">(</span><span class="n">train_network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">get_lr</span><span class="p">(</span><span class="n">global_step</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">lr_init</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">lr_max</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
            <span class="n">lr_end</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
            <span class="n">warmup_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">total_epochs</span><span class="o">=</span><span class="n">epoch_size</span><span class="p">)</span>

<span class="c1"># Create an optimizer.</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">loss_net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()),</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">lr</span><span class="p">),</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">4e-5</span><span class="p">)</span>
<span class="n">train_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">loss_net</span><span class="p">,</span> <span class="n">optim</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Create dataset and start fine-tuning. As is shown below, the new dataset used for fine-tuning is the garbage classification data located at <code class="docutils literal notranslate"><span class="pre">/ssd/data/garbage/train</span></code> folder.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s2">&quot;/ssd/data/garbage/train&quot;</span><span class="p">,</span>
                           <span class="n">do_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                           <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                           <span class="n">platform</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">,</span>
                           <span class="n">repeat_num</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_size</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">items</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
         <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">items</span>
         <span class="n">data</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
         <span class="n">label</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

         <span class="n">loss</span> <span class="o">=</span> <span class="n">train_net</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
         <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epoch_size</span><span class="si">}</span><span class="s2">, loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
      <span class="c1"># Save the ckpt file for each epoch.</span>
      <span class="n">ckpt_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;./ckpt/garbage_finetune_epoch</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">.ckpt&quot;</span>
      <span class="n">save_checkpoint</span><span class="p">(</span><span class="n">train_network</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Eval on test set.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">mshub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;mindspore/ascend/0.7/googlenet_v1_cifar10&#39;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                     <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="n">reducemean_flatten</span> <span class="o">=</span> <span class="n">ReduceMeanFlatten</span><span class="p">()</span>

<span class="n">classification_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">last_channel</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="n">classification_layer</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span><span class="n">network</span><span class="p">,</span> <span class="n">reducemean_flatten</span><span class="p">,</span>
                              <span class="n">classification_layer</span><span class="p">,</span> <span class="n">softmax</span><span class="p">])</span>

<span class="c1"># Load a pre-trained ckpt file.</span>
<span class="n">ckpt_path</span> <span class="o">=</span> <span class="s2">&quot;./ckpt/garbage_finetune_epoch59.ckpt&quot;</span>
<span class="n">trained_ckpt</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">)</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">trained_ckpt</span><span class="p">)</span>

<span class="c1"># Define loss and create model.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">},</span> <span class="n">eval_network</span><span class="o">=</span><span class="n">network</span><span class="p">)</span>

<span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s2">&quot;/ssd/data/garbage/test&quot;</span><span class="p">,</span>
                           <span class="n">do_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                           <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                           <span class="n">platform</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">,</span>
                           <span class="n">repeat_num</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;result:&quot;</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="s2">&quot;ckpt=&quot;</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="save_model.html" class="btn btn-neutral float-left" title="Saving Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="publish_model.html" class="btn btn-neutral float-right" title="Publishing Models using MindSpore Hub" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>