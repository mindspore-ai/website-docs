<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Enabling Mixed Precision &mdash; MindSpore r1.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/training.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/training.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Enabling Graph Kernel Fusion" href="enable_graph_kernel_fusion.html" />
    <link rel="prev" title="Saving and Loading Models in Hybrid Parallel Mode" href="save_load_model_hybrid_parallel.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/linear_regression.html">Implementing Simple Linear Function Fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">Defining the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/save_model.html">Saving Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/load_model_for_inference_and_transfer.html">Loading a Model for Inference and Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/publish_model.html">Publishing Models using MindSpore Hub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Process Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="convert_dataset.html">Converting Dataset to MindRecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimize_data_processing.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build Networks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="custom_operator.html">Custom Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrate_script.html">Migrating Training Scripts from Third Party Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_deep_probability_programming.html">Deep Probabilistic Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="achieve_high_order_differentiation.html">Achieve High Order Differentiation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization_tutorials.html">Training Process Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_augmentation.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluate_the_model_during_training.html">Evaluating the Model during Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="distributed_training_tutorials.html">Distributed Training</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Enabling Mixed Precision</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#computation-process">Computation Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="#automatic-mixed-precision">Automatic Mixed Precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="#manual-mixed-precision">Manual Mixed Precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="#constraints">Constraints</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_cache.html">Application of Single-Node Tensor Cache</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Compression</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">Using Membership Inference to Test Model Security</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Use MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Enabling Mixed Precision</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/advanced_use/enable_mixed_precision.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="enabling-mixed-precision">
<h1>Enabling Mixed Precision<a class="headerlink" href="#enabling-mixed-precision" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Training</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.1/tutorials/training/source_en/advanced_use/enable_mixed_precision.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>The mixed precision training method accelerates the deep learning neural network training process by using both the single-precision and half-precision data formats, and maintains the network precision achieved by the single-precision training at the same time.
Mixed precision training can accelerate the computation process, reduce memory usage, and enable a larger model or batch size to be trained on specific hardware.</p>
<p>For FP16 operators, if the input data type is FP32, the backend of MindSpore will automatically handle it with reduced precision. Users could check the reduced-precision operators by enabling INFO log and then searching ‘Reduce precision’.</p>
</section>
<section id="computation-process">
<h2>Computation Process<a class="headerlink" href="#computation-process" title="Permalink to this headline"></a></h2>
<p>The following figure shows the typical computation process of mixed precision in MindSpore.</p>
<p><img alt="mix precision" src="../_images/mix_precision.PNG" /></p>
<ol class="arabic simple">
<li><p>Parameters are stored in FP32 format.</p></li>
<li><p>During the forward computation, if an FP16 operator is involved, the operator input and parameters need to be cast from FP32 to FP16.</p></li>
<li><p>The loss layer is set to FP32.</p></li>
<li><p>During backward computation, the value is multiplied by Loss Scale to avoid underflow due to a small gradient.</p></li>
<li><p>The FP16 parameter is used for gradient computation, and the result is cast back to FP32.</p></li>
<li><p>Then, the value is divided by Loss scale to restore the multiplied gradient.</p></li>
<li><p>The optimizer checks whether the gradient overflows. If yes, the optimizer skips the update. If no, the optimizer uses FP32 to update the original parameters.</p></li>
</ol>
<p>This document describes the computation process by using examples of automatic and manual mixed precision.</p>
</section>
<section id="automatic-mixed-precision">
<h2>Automatic Mixed Precision<a class="headerlink" href="#automatic-mixed-precision" title="Permalink to this headline"></a></h2>
<p>To use the automatic mixed precision, you need to invoke the corresponding API, which takes the network to be trained and the optimizer as the input. This API converts the operators of the entire network into FP16 operators (except the <code class="docutils literal notranslate"><span class="pre">BatchNorm</span></code> and Loss operators). You can use automatic mixed precision through API <code class="docutils literal notranslate"><span class="pre">amp</span></code> or API <code class="docutils literal notranslate"><span class="pre">Model</span></code>.</p>
<p>The procedure of using automatic mixed precision by API <code class="docutils literal notranslate"><span class="pre">amp</span></code> is as follows:</p>
<ol class="arabic simple">
<li><p>Introduce the MindSpore mixed precision API <code class="docutils literal notranslate"><span class="pre">amp</span></code>.</p></li>
<li><p>Define the network. This step is the same as the common network definition. (You do not need to manually configure the precision of any specific operator.)</p></li>
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">amp.build_train_network</span></code> API to encapsulate the network model and optimizer. You can learn how to set parameter <code class="docutils literal notranslate"><span class="pre">level</span></code> through <a class="reference external" href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/mindspore.html#mindspore.build_train_network">https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/mindspore.html#mindspore.build_train_network</a>. In this step, MindSpore automatically converts the operators to the required format.</p></li>
</ol>
<p>A code example is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">context</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Momentum</span>
<span class="c1"># The interface of Auto_mixed precision</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">amp</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>

<span class="c1"># Define network</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="c1"># Initialize network</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>

<span class="c1"># Define training data, label</span>
<span class="n">predict</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">64</span><span class="p">,</span> <span class="mi">512</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="c1"># Define Loss and Optimizer</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">train_network</span> <span class="o">=</span> <span class="n">amp</span><span class="o">.</span><span class="n">build_train_network</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="s2">&quot;O3&quot;</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># Run training</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">train_network</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
<p>The procedure of using automatic mixed precision by API <code class="docutils literal notranslate"><span class="pre">Model</span></code> is as follows:</p>
<ol class="arabic simple">
<li><p>Introduce the MindSpore model API <code class="docutils literal notranslate"><span class="pre">Model</span></code>.</p></li>
<li><p>Define the network. This step is the same as the common network definition. (You do not need to manually configure the precision of any specific operator.)</p></li>
<li><p>Create dataset.You can learn detail step at <a class="reference external" href="https://www.mindspore.cn/tutorial/training/en/r1.1/use/data_preparation.html">https://www.mindspore.cn/tutorial/training/en/r1.1/use/data_preparation.html</a>.</p></li>
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">Model</span></code> API to encapsulate the network model and optimizer. You can learn how to set parameter <code class="docutils literal notranslate"><span class="pre">amp_level</span></code> through <a class="reference external" href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/mindspore.html#mindspore.Mode">https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/mindspore.html#mindspore.Mode</a>. In this step, MindSpore automatically converts the operators to the required format.</p></li>
</ol>
<p>A code example is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>import numpy as np
import mindspore.nn as nn
from mindspore.nn.metrics import Accuracy
from mindspore import context, Model
from mindspore.common.initializer import Normal
from src.dataset import create_dataset

context.set_context(mode=context.GRAPH_MODE)
context.set_context(device_target=&quot;Ascend&quot;)

# Define network
class LeNet5(nn.Cell):
    &quot;&quot;&quot;
    Lenet network

    Args:
        num_class (int): Number of classes. Default: 10.
        num_channel (int): Number of channels. Default: 1.

    Returns:
        Tensor, output tensor
    Examples:
        &gt;&gt;&gt; LeNet(num_class=10)

    &quot;&quot;&quot;
    def __init__(self, num_class=10, num_channel=1):
        super(LeNet5, self).__init__()
        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode=&#39;valid&#39;)
        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode=&#39;valid&#39;)
        self.fc1 = nn.Dense(16 * 5 * 5, 120, weight_init=Normal(0.02))
        self.fc2 = nn.Dense(120, 84, weight_init=Normal(0.02))
        self.fc3 = nn.Dense(84, num_class, weight_init=Normal(0.02))
        self.relu = nn.ReLU()
        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)
        self.flatten = nn.Flatten()

    def construct(self, x):
        x = self.max_pool2d(self.relu(self.conv1(x)))
        x = self.max_pool2d(self.relu(self.conv2(x)))
        x = self.flatten(x)
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# create dataset
ds_train = create_dataset(&quot;/dataset/MNIST/train&quot;, 32)

# Initialize network
network = LeNet5(10)

# Define Loss and Optimizer
net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=&quot;mean&quot;)
net_opt = nn.Momentum(network.trainable_params(),learning_rate=0.01, momentum=0.9)
model = Model(network, net_loss, net_opt, metrics={&quot;Accuracy&quot;: Accuracy()}，amp_level=&quot;O3&quot;)

# Run training
model.train(epoch=10, train_dataset=ds_train)
</pre></div>
</div>
</section>
<section id="manual-mixed-precision">
<h2>Manual Mixed Precision<a class="headerlink" href="#manual-mixed-precision" title="Permalink to this headline"></a></h2>
<p>MindSpore also supports manual mixed precision. It is assumed that only one dense layer in the network needs to be calculated by using FP32, and other layers are calculated by using FP16. The mixed precision is configured in the granularity of cell. The default format of a cell is FP32.</p>
<p>The following is the procedure for implementing manual mixed precision:</p>
<ol class="arabic simple">
<li><p>Define the network. This step is similar to step 2 in the automatic mixed precision.</p></li>
<li><p>Configure the mixed precision. Use <code class="docutils literal notranslate"><span class="pre">net.to_float(mstype.float16)</span></code> to set all operators of the cell and its sub-cells to FP16. Then, configure the dense to FP32.</p></li>
<li><p>Use TrainOneStepCell to encapsulate the network model and optimizer.</p></li>
</ol>
<p>A code example is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">context</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">WithLossCell</span><span class="p">,</span> <span class="n">TrainOneStepCell</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Momentum</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>

<span class="c1"># Define network</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># Initialize network</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="c1"># Set mixing precision</span>
<span class="n">net</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">dense</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Define training data, label</span>
<span class="n">predict</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">64</span><span class="p">,</span> <span class="mi">512</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="c1"># Define Loss and Optimizer</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">WithLossCell</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
<span class="n">train_network</span> <span class="o">=</span> <span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
<span class="n">train_network</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>

<span class="c1"># Run training</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">train_network</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="constraints">
<h2>Constraints<a class="headerlink" href="#constraints" title="Permalink to this headline"></a></h2>
<p>When mixed precision is enabled, backprop network only can be generated by ‘AutoDiff’ block but cannot be defined by users. If user defines the backprorp network, a data type dismatching exepcetion may be thrown out by MindSpore.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="save_load_model_hybrid_parallel.html" class="btn btn-neutral float-left" title="Saving and Loading Models in Hybrid Parallel Mode" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="enable_graph_kernel_fusion.html" class="btn btn-neutral float-right" title="Enabling Graph Kernel Fusion" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>