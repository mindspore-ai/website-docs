<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Explain Models &mdash; MindSpore r1.1 documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="MindInsight Commands" href="mindinsight_commands.html" />
    <link rel="prev" title="Using Debugger" href="debugger.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/linear_regression.html">Implementing Simple Linear Function Fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">Defining the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/save_model.html">Saving Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/load_model_for_inference_and_transfer.html">Loading a Model for Inference and Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/publish_model.html">Publishing Models using MindSpore Hub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Process Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="convert_dataset.html">Converting Dataset to MindRecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimize_data_processing.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build Networks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="custom_operator.html">Custom Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrate_script.html">Migrating Training Scripts from Third Party Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_deep_probability_programming.html">Deep Probabilistic Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="achieve_high_order_differentiation.html">Achieve High Order Differentiation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="visualization_tutorials.html">Training Process Visualization</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="summary_record.html">Collecting Summary Record</a></li>
<li class="toctree-l2"><a class="reference internal" href="dashboard.html">Viewing Dashboard</a></li>
<li class="toctree-l2"><a class="reference internal" href="lineage_and_scalars_comparision.html">Viewing Lineage and Scalars Comparision</a></li>
<li class="toctree-l2"><a class="reference internal" href="hyper_parameters_auto_tuning.html">Use Mindoptimizer to Tune Hyperparameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_profiling.html">Performance Profiling(Ascend)</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_profiling_gpu.html">Performance Profiling（GPU）</a></li>
<li class="toctree-l2"><a class="reference internal" href="debugger.html">Using Debugger</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Explain Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#operation-process">Operation Process</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#preparing-the-script">Preparing the Script</a></li>
<li class="toctree-l4"><a class="reference internal" href="#restrictions">Restrictions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#enabling-mindinsight">Enabling MindInsight</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pages-and-functions">Pages and Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#saliency-map-visualization">Saliency Map Visualization</a></li>
<li class="toctree-l4"><a class="reference internal" href="#explanation-method-assessment">Explanation Method Assessment</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mindinsight_commands.html">MindInsight Commands</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_augmentation.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluate_the_model_during_training.html">Evaluating the Model during Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_tutorials.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_cache.html">Application of Single-Node Tensor Cache</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Compression</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">Using Membership Inference to Test Model Security</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Use MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="visualization_tutorials.html">Training Process Visualization</a> &raquo;</li>
      <li>Explain Models</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/advanced_use/model_explaination.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="explain-models">
<h1>Explain Models<a class="headerlink" href="#explain-models" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Optimization</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.1/tutorials/training/source_en/advanced_use/model_explaination.md"><img alt="View Source On Gitee" src="../_images/logo_source.png" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>Currently, most deep learning models are black-box models with good performance but poor explainability. The model explanation module aims to provide users with explanation of the model decision basis, help users better understand the model, trust the model, and improve the model when an error occurs in the model.</p>
<p>In some critical application scenarios, such as automatic driving, financial decision-making, etc., AI model cannot be truly applied if it is not interpretable for legal and policy supervision reasons. Therefore, the interpretability of the model is becoming more and more important. As a consequence, model explanation is an important part of improving MindSpore’s applicability and user-friendliness.</p>
<p>To be specific, in the task of image classification, a widely-used group of explanation methods will highlight the most critical area that affects the classification decision of the model. We call it “saliency map”. If the highlighted parts are indeed the key features of the targeted label, then the features learned by the model are usually correct, thus the users can trust the effect and decision of the model. If the model focuses on irrelevant parts, even if the prediction label is correct, it does not mean that the model is reliable, the model developers still need to optimize and improve the model. This may be due to the correlation of some irrelevant features in the training data. Model developers can consider further data augmentation to correct the bias learned by the model correspondingly.</p>
<p>Besides a variety of explanation methods, we also provide a set of evaluation methods to evaluate the explanation methods from various dimensions. It helps users compare and select the explanation methods that are most suitable for a particular scenario.</p>
</section>
<section id="operation-process">
<h2>Operation Process<a class="headerlink" href="#operation-process" title="Permalink to this headline"></a></h2>
<section id="preparing-the-script">
<h3>Preparing the Script<a class="headerlink" href="#preparing-the-script" title="Permalink to this headline"></a></h3>
<p>Currently, MindSpore provides the explanation methods and explanation evaluation Python API. You can use the provided explanation methods by  <code class="docutils literal notranslate"><span class="pre">mindspore.explainer.explanation</span></code> and the provided explanation evaluation by <code class="docutils literal notranslate"><span class="pre">mindspore.explainer.benchmark</span></code>. You need to prepare the black-box model and data to be explained, instantiate explanation methods or explanation evaluation according to your need and call the explanation API in your script to collect the explanation result and explanation evaluation result.</p>
<p>MindSpore also provides <code class="docutils literal notranslate"><span class="pre">mindspore.explainer.ImageClassificationRunner</span></code> to run all explanation methods and explanation evaluation methods automatically. You just need to register the instantiated object and then all explanation methods and explanation evaluation methods will be executed. Explanation logs containing explanation results and explanation evaluation results will be automatically generated and stored.</p>
<p>The following uses ResNet-50 and multi-label dataset with 20 classes as an example. Initializing the explanation methods in <code class="docutils literal notranslate"><span class="pre">explanation</span></code> and the evaluation methods in <code class="docutils literal notranslate"><span class="pre">benchmark</span></code>, the users can then use <code class="docutils literal notranslate"><span class="pre">ImageClassificationRunner</span></code> to execute and explanation and evaluation for the black-box model. The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>

<span class="kn">from</span> <span class="nn">mindspore.explainer.explanation</span> <span class="kn">import</span> <span class="n">GradCAM</span><span class="p">,</span> <span class="n">GuidedBackprop</span>
<span class="kn">from</span> <span class="nn">mindspore.explainer.benchmark</span> <span class="kn">import</span> <span class="n">Faithfulness</span><span class="p">,</span> <span class="n">Localization</span>
<span class="kn">from</span> <span class="nn">mindspore.explainer</span> <span class="kn">import</span> <span class="n">ImageClassificationRunner</span>

<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1"># please refer to model_zoo for the model architecture of resnet50</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50.ckpt&quot;</span><span class="p">)</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>


<span class="c1"># initialize explainers with the loaded black-box model</span>
<span class="n">gradcam</span> <span class="o">=</span> <span class="n">GradCAM</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="s1">&#39;layer4&#39;</span><span class="p">)</span>
<span class="n">guidedbackprop</span> <span class="o">=</span> <span class="n">GuidedBackprop</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

<span class="c1"># initialize benchmarkers to evaluate the chosen explainers</span>
<span class="c1"># for Faithfulness, the initialization needs a activation function that transforms the output of the network to a probability is also needed.</span>
<span class="n">activation_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>  <span class="c1"># for multi-label classification</span>
<span class="n">faithfulness</span> <span class="o">=</span> <span class="n">Faithfulness</span><span class="p">(</span><span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;InsertionAUC&#39;</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">activation_fn</span><span class="p">)</span>
<span class="n">localization</span> <span class="o">=</span> <span class="n">Localization</span><span class="p">(</span><span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;PointingGame&#39;</span><span class="p">)</span>

<span class="c1"># returns the dataset to be explained, when localization is chosen, the dataset is required to provide bounding box</span>
<span class="c1"># the columns of the dataset should be in [image], [image, labels], or [image, labels, bbox] (order matters).</span>
<span class="c1"># You may refer to &#39;mindspore.dataset.project&#39; for columns managements.</span>
<span class="n">dataset_path</span> <span class="o">=</span> <span class="s2">&quot;dataset_dir&quot;</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">)</span>

<span class="c1"># specify the class names of the dataset</span>
<span class="n">classes</span> <span class="o">=</span> <span class="p">[</span>
 <span class="s1">&#39;aeroplane&#39;</span><span class="p">,</span> <span class="s1">&#39;bicycle&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;boat&#39;</span><span class="p">,</span> <span class="s1">&#39;bottle&#39;</span><span class="p">,</span> <span class="s1">&#39;bus&#39;</span><span class="p">,</span> <span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span>
 <span class="s1">&#39;chair&#39;</span><span class="p">,</span> <span class="s1">&#39;cow&#39;</span><span class="p">,</span> <span class="s1">&#39;diningtable&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">,</span> <span class="s1">&#39;motorbike&#39;</span><span class="p">,</span> <span class="s1">&#39;person&#39;</span><span class="p">,</span>
 <span class="s1">&#39;pottedplant&#39;</span><span class="p">,</span> <span class="s1">&#39;sheep&#39;</span><span class="p">,</span> <span class="s1">&#39;sofa&#39;</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;tvmonitor&#39;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
<span class="n">explainers</span> <span class="o">=</span> <span class="p">[</span><span class="n">gradcam</span><span class="p">,</span> <span class="n">guidedbackprop</span><span class="p">]</span>
<span class="n">benchmarkers</span> <span class="o">=</span> <span class="p">[</span><span class="n">faithfulness</span><span class="p">,</span> <span class="n">localization</span><span class="p">]</span>

<span class="c1"># initialize runner with specified summary_dir</span>
<span class="n">runner</span> <span class="o">=</span> <span class="n">ImageClassificationRunner</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">,</span> <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">activation_fn</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<span class="n">runner</span><span class="o">.</span><span class="n">register_saliency</span><span class="p">(</span><span class="n">explainers</span><span class="p">,</span> <span class="n">benchmarkers</span><span class="p">)</span>

<span class="c1"># execute runner.run to generate explanation and evaluation results to save it to summary_dir</span>
<span class="n">runner</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="restrictions">
<h3>Restrictions<a class="headerlink" href="#restrictions" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Only support CNN of image classification models, such as Lenet, Resnet, Alexnet.</p></li>
<li><p>Only support PyNative mode.</p></li>
<li><p>All instances of explanation and evaluation methods cannot be reused across runners. Explanation and evaluation methods have to be instantiated exclusively for each runner. Otherwise, errors may occur. A correct example is shown below.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gradcam</span> <span class="o">=</span> <span class="n">GradCAM</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="s1">&#39;layer4&#39;</span><span class="p">)</span>
<span class="n">guidedbackprop</span> <span class="o">=</span> <span class="n">GuidedBackprop</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

<span class="n">runner</span> <span class="o">=</span> <span class="n">ImageClassificationRunner</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir_1&#39;</span><span class="p">,</span> <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">activation_fn</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<span class="n">runner</span><span class="o">.</span><span class="n">register_saliency</span><span class="p">(</span><span class="n">expaliners</span><span class="o">=</span><span class="p">[</span><span class="n">gradcam</span><span class="p">,</span> <span class="n">guidedbackprop</span><span class="p">])</span>
<span class="n">runner</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

<span class="c1"># generate another summary with GradCAM only</span>
<span class="n">runner2</span> <span class="o">=</span> <span class="n">ImageClassificationRunner</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir_2&#39;</span><span class="p">,</span> <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">activation_fn</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># reusing explainer instance in other runner, errors may occur</span>
<span class="c1"># runner2.register_saliency(explainers=[gradcam])</span>

<span class="c1"># instantiating a new GradCAM is the correct way</span>
<span class="n">gradcam2</span> <span class="o">=</span> <span class="n">GradCAM</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="s1">&#39;layer4&#39;</span><span class="p">)</span>
<span class="n">runner2</span><span class="o">.</span><span class="n">register_saliency</span><span class="p">(</span><span class="n">explainers</span><span class="o">=</span><span class="p">[</span><span class="n">gradcam2</span><span class="p">])</span>

<span class="n">runner2</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="enabling-mindinsight">
<h3>Enabling MindInsight<a class="headerlink" href="#enabling-mindinsight" title="Permalink to this headline"></a></h3>
<p>Enable MindInsight and click <strong>Model Explanation</strong> on the top of the page. All explanation log paths are displayed. When a log path meets the conditions, the <strong>Saliency Map Visualization</strong> buttons are displayed in the <strong>Operation</strong> column.</p>
<p><img alt="xai_index" src="../_images/xai_index.png" /></p>
</section>
</section>
<section id="pages-and-functions">
<h2>Pages and Functions<a class="headerlink" href="#pages-and-functions" title="Permalink to this headline"></a></h2>
<section id="saliency-map-visualization">
<h3>Saliency Map Visualization<a class="headerlink" href="#saliency-map-visualization" title="Permalink to this headline"></a></h3>
<p>Saliency map visualization is used to display the image area that has the most significant impact on the model decision-making result. Generally, the highlighted regions can be considered as key features of the objective classification.</p>
<p><img alt="xai_saliency_map" src="../_images/xai_saliency_map.png" /></p>
<p>The following information is displayed on the <strong>Saliency Map Visualization</strong> page:</p>
<ul class="simple">
<li><p>Objective dataset set by a user through the Python API of the dataset.</p></li>
<li><p>Ground truth tags, prediction tags, and the prediction probabilities of the model for the corresponding tags. The system adds the TP, TN, FP and FN flags(meanings are provided in the page’s information) in the upper left corner of the corresponding tag based on the actual requirements.</p></li>
<li><p>A saliency map given by the selected explanation method.</p></li>
</ul>
<p>Operations:</p>
<ol class="arabic simple">
<li><p>Select the required explanation methods. Currently, we support four explanation methods. More explanation methods will be provided in the future.</p></li>
<li><p>Click <strong>Overlay on Original Image</strong> in the upper right corner of the page to overlay the saliency map on the original image.</p></li>
<li><p>Click different tags to display the saliency map analysis results of the model for different tags. For different classification results, the focus of the model is usually different.</p></li>
<li><p>Use the tag filtering function on the upper part of the page to filter out images with specified tags.</p></li>
<li><p>Select an image display sequence from <strong>Sort Images By</strong> in the upper right corner of the page.</p></li>
<li><p>Click <strong>View Score</strong> on the right of an explanation method. The page for assessing all explanation methods is displayed.</p></li>
<li><p>Click image you will see the higher resolution image.</p></li>
</ol>
<p><img alt="xai_saliency_map_detail" src="../_images/xai_saliency_map_detail.png" /></p>
</section>
<section id="explanation-method-assessment">
<h3>Explanation Method Assessment<a class="headerlink" href="#explanation-method-assessment" title="Permalink to this headline"></a></h3>
<section id="comprehensive-assessment">
<h4>Comprehensive Assessment<a class="headerlink" href="#comprehensive-assessment" title="Permalink to this headline"></a></h4>
<p>The provided explanation methods are scored from different dimensions. We provide various dimensions scores to help users compare the performance and select the most suitable one. You can configure weights for metrics in a specific scenario to obtain the comprehensive score.</p>
<p><img alt="xai_metrix_comprehensive" src="../_images/xai_metrix_comprehensive.png" /></p>
</section>
<section id="classification-assessment">
<h4>Classification Assessment<a class="headerlink" href="#classification-assessment" title="Permalink to this headline"></a></h4>
<p>The classification assessment page provides two types of comparison. One is to compare scores of different evaluation dimensions of the same explanation method in each tag. The other is to compare scores of different explanation methods of the same evaluation dimension in each tag.</p>
<p><img alt="xai_metrix_class" src="../_images/xai_metrix_class.png" /></p>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="debugger.html" class="btn btn-neutral float-left" title="Using Debugger" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindinsight_commands.html" class="btn btn-neutral float-right" title="MindInsight Commands" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>