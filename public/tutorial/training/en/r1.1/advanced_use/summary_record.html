

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Collecting Summary Record &mdash; MindSpore r1.1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/training.css" type="text/css" />

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/js/training.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Viewing Dashboard" href="dashboard.html" />
    <link rel="prev" title="Training Process Visualization" href="visualization_tutorials.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/linear_regression.html">Implementing Simple Linear Function Fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">Defining the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/save_model.html">Saving Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/load_model_for_inference_and_transfer.html">Loading a Model for Inference and Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/publish_model.html">Publishing Models using MindSpore Hub</a></li>
</ul>
<p class="caption"><span class="caption-text">Process Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="convert_dataset.html">Converting Dataset to MindRecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimize_data_processing.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption"><span class="caption-text">Build Networks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="custom_operator.html">Custom Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrate_script.html">Migrating Training Scripts from Third Party Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_deep_probability_programming.html">Deep Probabilistic Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="achieve_high_order_differentiation.html">Achieve High Order Differentiation</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Optimization</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="visualization_tutorials.html">Training Process Visualization</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Collecting Summary Record</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#operation-process">Operation Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="#preparing-the-training-script">Preparing The Training Script</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#method-one-automatically-collected-through-summarycollector">Method one: Automatically collected through SummaryCollector</a></li>
<li class="toctree-l4"><a class="reference internal" href="#method-two-custom-collection-of-network-data-with-summary-operators-and-summarycollector">Method two: Custom collection of network data with summary operators and SummaryCollector</a></li>
<li class="toctree-l4"><a class="reference internal" href="#method-three-custom-callback-recording-data">Method three: Custom callback recording data</a></li>
<li class="toctree-l4"><a class="reference internal" href="#method-four-advanced-usage-custom-training-cycle">Method four: Advanced usage, custom training cycle</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tip-recording-gradients">Tip: Recording gradients</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#run-mindinsight">Run MindInsight</a></li>
<li class="toctree-l3"><a class="reference internal" href="#notices">Notices</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dashboard.html">Viewing Dashboard</a></li>
<li class="toctree-l2"><a class="reference internal" href="lineage_and_scalars_comparision.html">Viewing Lineage and Scalars Comparision</a></li>
<li class="toctree-l2"><a class="reference internal" href="hyper_parameters_auto_tuning.html">Use Mindoptimizer to Tune Hyperparameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_profiling.html">Performance Profiling(Ascend)</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_profiling_gpu.html">Performance Profiling（GPU）</a></li>
<li class="toctree-l2"><a class="reference internal" href="debugger.html">Using Debugger</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_explaination.html">Explain Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindinsight_commands.html">MindInsight Commands</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_augmentation.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluate_the_model_during_training.html">Evaluating the Model during Training</a></li>
</ul>
<p class="caption"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_tutorials.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_cache.html">Application of Single-Node Tensor Cache</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Compression</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">Using Membership Inference to Test Model Security</a></li>
</ul>
<p class="caption"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Use MindSpore on the Cloud</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="visualization_tutorials.html">Training Process Visualization</a> &raquo;</li>
        
      <li>Collecting Summary Record</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/advanced_use/summary_record.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="collecting-summary-record">
<h1>Collecting Summary Record<a class="headerlink" href="#collecting-summary-record" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Optimization</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<!-- TOC --><ul class="simple">
<li><p><a class="reference external" href="#collecting-summary-record">Collecting Summary Record</a></p>
<ul>
<li><p><a class="reference external" href="#overview">Overview</a></p></li>
<li><p><a class="reference external" href="#operation-process">Operation Process</a></p></li>
<li><p><a class="reference external" href="#preparing-the-training-script">Preparing The Training Script</a></p>
<ul>
<li><p><a class="reference external" href="#method-one-automatically-collected-through-summarycollector">Method one: Automatically collected through SummaryCollector</a></p></li>
<li><p><a class="reference external" href="#method-two-custom-collection-of-network-data-with-summary-operators-and-summarycollector">Method two: Custom collection of network data with summary operators and SummaryCollector</a></p></li>
<li><p><a class="reference external" href="#method-three-custom-callback-recording-data">Method three: Custom callback recording data</a></p></li>
<li><p><a class="reference external" href="#method-four-advanced-usage-custom-training-cycle">Method four: Advanced usage, custom training cycle</a></p></li>
<li><p><a class="reference external" href="#tip-recording-gradients">Tip: Recording gradients</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#run-mindinsight">Run MindInsight</a></p></li>
<li><p><a class="reference external" href="#notices">Notices</a></p></li>
</ul>
</li>
</ul>
<!-- /TOC --><p><a href="https://gitee.com/mindspore/docs/blob/r1.1/tutorials/training/source_en/advanced_use/summary_record.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>Scalars, images, computational graphs, and model hyperparameters during training are recorded in files and can be viewed on the web page.</p>
</div>
<div class="section" id="operation-process">
<h2>Operation Process<a class="headerlink" href="#operation-process" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Prepare a training script, specify scalars, images, computational graphs, and model hyperparameters in the training script, record them in the summary log file, and run the training script.</p></li>
<li><p>Start MindInsight and specify the summary log file directory using startup parameters. After MindInsight is started, access the visualization page based on the IP address and port number. The default access IP address is <code class="docutils literal notranslate"><span class="pre">http://127.0.0.1:8080</span></code>.</p></li>
<li><p>During the training, when data is written into the summary log file, you can view the data on the web page.</p></li>
</ul>
</div>
<div class="section" id="preparing-the-training-script">
<h2>Preparing The Training Script<a class="headerlink" href="#preparing-the-training-script" title="Permalink to this headline">¶</a></h2>
<p>Currently, MindSpore supports to save scalars, images, computational graph, and model hyperparameters to summary log file and display them on the web page.</p>
<p>MindSpore currently supports multiple ways to record data into summary log files.</p>
<div class="section" id="method-one-automatically-collected-through-summarycollector">
<h3>Method one: Automatically collected through SummaryCollector<a class="headerlink" href="#method-one-automatically-collected-through-summarycollector" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">Callback</span></code> mechanism in MindSpore provides a quick and easy way to collect common information, including the calculational graph, loss value, learning rate, parameter weights, etc. It is named ‘SummaryCollector’.</p>
<p>When you write a training script, you just instantiate the <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> and apply it to either <code class="docutils literal notranslate"><span class="pre">model.train</span></code> or <code class="docutils literal notranslate"><span class="pre">model.eval</span></code>. You can automatically collect some common summary data. The detailed usage of <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> can refer to the <code class="docutils literal notranslate"><span class="pre">API</span></code> document <code class="docutils literal notranslate"><span class="pre">mindspore.train.callback.SummaryCollector</span></code>.</p>
<p>The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore.nn.metrics</span> <span class="kn">import</span> <span class="n">Accuracy</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">SummaryCollector</span>


<span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                     <span class="n">has_bias</span><span class="o">=</span><span class="n">has_bias</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="n">pad_mode</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">fc_with_initialize</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="n">has_bias</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">AlexNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;AlexNet&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">phase</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlexNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv5</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">include_top</span> <span class="o">=</span> <span class="n">include_top</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">include_top</span><span class="p">:</span>
            <span class="n">dropout_ratio</span> <span class="o">=</span> <span class="mf">0.65</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span>
                <span class="n">dropout_ratio</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">*</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_ratio</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;define network&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv5</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">include_top</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">AlexNet</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">Accuracy</span><span class="p">()})</span>

<span class="c1"># How to create a valid dataset instance,</span>
<span class="c1"># for detail, see the https://www.mindspore.cn/tutorial/training/en/r1.1/quick_start/quick_start.html document.</span>
<span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;./dataset_path&#39;</span><span class="p">)</span>

<span class="c1"># Init a SummaryCollector callback instance, and use it in model.train or model.eval</span>
<span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">,</span> <span class="n">collect_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Note: dataset_sink_mode should be set to False, else you should modify collect freq in SummaryCollector</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">ds_eval</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;./dataset_path&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">ds_eval</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">])</span>
</pre></div>
</div>
<blockquote>
<div><p>When using summary, it is recommended that you set <code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code> argument of <code class="docutils literal notranslate"><span class="pre">model.train()</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>. Please see notices for more information.</p>
</div></blockquote>
</div>
<div class="section" id="method-two-custom-collection-of-network-data-with-summary-operators-and-summarycollector">
<h3>Method two: Custom collection of network data with summary operators and SummaryCollector<a class="headerlink" href="#method-two-custom-collection-of-network-data-with-summary-operators-and-summarycollector" title="Permalink to this headline">¶</a></h3>
<p>In addition to providing the <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> that automatically collects some summary data, MindSpore provides summary operators that enable customized collection of other data on the network, such as the input of each convolutional layer, or the loss value in the loss function, etc.</p>
<p>The following summary operators are currently supported:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.ScalarSummary.html">ScalarSummary</a>: Record a scalar data.</p></li>
<li><p><a class="reference external" href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.TensorSummary.html">TensorSummary</a>: Record a tensor data.</p></li>
<li><p><a class="reference external" href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.ImageSummary.html">ImageSummary</a>: Record a image data.</p></li>
<li><p><a class="reference external" href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.HistogramSummary.html">HistogramSummary</a>: Convert tensor data into histogram data records.</p></li>
</ul>
<p>The recording method is shown in the following steps.</p>
<p>Step 1: Call the summary operator in the <code class="docutils literal notranslate"><span class="pre">construct</span></code> function of the derived class that inherits <code class="docutils literal notranslate"><span class="pre">nn.Cell</span></code> to collect image or scalar data.</p>
<p>For example, when a network is defined, image data is recorded in <code class="docutils literal notranslate"><span class="pre">construct</span></code> of the network. When the loss function is defined, the loss value is recorded in <code class="docutils literal notranslate"><span class="pre">construct</span></code> of the loss function.</p>
<p>Record the dynamic learning rate in <code class="docutils literal notranslate"><span class="pre">construct</span></code> of the optimizer when defining the optimizer.</p>
<p>The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Optimizer</span>


<span class="k">class</span> <span class="nc">CrossEntropyLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Loss function definition.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CrossEntropyLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cross_entropy</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">OneHot</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># Init ScalarSummary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scalar_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ScalarSummary</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">logits</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">label</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>

        <span class="c1"># Record loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scalar_summary</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>


<span class="k">class</span> <span class="nc">MyOptimizer</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Optimizer definition.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="o">...</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="c1"># Initialize ScalarSummary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scalar_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ScalarSummary</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">HistogramSummary</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="c1"># Record learning rate here</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scalar_summary</span><span class="p">(</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>

        <span class="c1"># Record weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1"># Record gradient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;.gradient&quot;</span><span class="p">,</span> <span class="n">grads</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="o">...</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Net definition.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="o">...</span>

        <span class="c1"># Init ImageSummary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ImageSummary</span><span class="p">()</span>
        <span class="c1"># Init TensorSummary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensor_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">TensorSummary</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="c1"># Record image by Summary operator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_summary</span><span class="p">(</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        <span class="c1"># Record tensor by Summary operator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensor_summary</span><span class="p">(</span><span class="s2">&quot;tensor&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        <span class="o">...</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
<blockquote>
<div><p>In the same Summary operator, the name given to the data must not be repeated, otherwise the data collection and presentation will have unexpected behavior.
For example, if two <code class="docutils literal notranslate"><span class="pre">ScalarSummary</span></code> operators are used to collect scalar data, two scalars cannot be given the same name.</p>
</div></blockquote>
<p>Step 2: In the training script, instantiate the <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> and apply it to <code class="docutils literal notranslate"><span class="pre">model.train</span></code>.</p>
<p>The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">SummaryCollector</span>
<span class="o">...</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">MyOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">Accuracy</span><span class="p">()})</span>

<span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;./dataset_path&#39;</span><span class="p">)</span>

<span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">,</span> <span class="n">collect_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="method-three-custom-callback-recording-data">
<h3>Method three: Custom callback recording data<a class="headerlink" href="#method-three-custom-callback-recording-data" title="Permalink to this headline">¶</a></h3>
<p>MindSpore supports customized callback and supports to record data into summary log file
in custom callback, and display the data by the web page.</p>
<p>The following pseudocode is shown in the CNN network, where developers can use the network output with the original tag and the prediction tag to generate the image of the confusion matrix.
It is then recorded into the summary log file through the <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code> module.
The detailed usage of <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code> can refer to the <code class="docutils literal notranslate"><span class="pre">API</span></code> document <code class="docutils literal notranslate"><span class="pre">mindspore.train.summary.SummaryRecord</span></code>.</p>
<p>The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">Callback</span>
<span class="kn">from</span> <span class="nn">mindspore.train.summary</span> <span class="kn">import</span> <span class="n">SummaryRecord</span>

<span class="k">class</span> <span class="nc">ConfusionMatrixCallback</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">summary_dir</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_summary_dir</span> <span class="o">=</span> <span class="n">summary_dir</span>

    <span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># init you summary record in here, when the train script run, it will be inited before training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span> <span class="o">=</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_summary_dir</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">exc_args</span><span class="p">):</span>
        <span class="c1"># Note: you must close the summary record, it will release the process pool resource</span>
        <span class="c1"># else your training script will not exit from training.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>

        <span class="c1"># create a confusion matric image, and record it to summary file</span>
        <span class="n">confusion_matrix</span> <span class="o">=</span> <span class="n">create_confusion_matrix</span><span class="p">(</span><span class="n">cb_params</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s1">&#39;image&#39;</span><span class="p">,</span> <span class="s1">&#39;confusion_matrix&#39;</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step</span><span class="p">)</span>

<span class="c1"># init you train script</span>
<span class="o">...</span>

<span class="n">confusion_matrix</span> <span class="o">=</span> <span class="n">ConfusionMatrixCallback</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">confusion_matrix</span><span class="p">])</span>
</pre></div>
</div>
<p>The above three ways support the record computational graph, loss value and other data. In addition, MindSpore also supports the saving of computational graph for other phases of training, through
the <code class="docutils literal notranslate"><span class="pre">save_graphs</span></code> option of <code class="docutils literal notranslate"><span class="pre">context.set_context</span></code> in the training script is set to <code class="docutils literal notranslate"><span class="pre">True</span></code> to record computational graphs of other phases, including the computational graph after operator fusion.</p>
<p>In the saved files, <code class="docutils literal notranslate"><span class="pre">ms_output_after_hwopt.pb</span></code> is the computational graph after operator fusion, which can be viewed on the web page.</p>
</div>
<div class="section" id="method-four-advanced-usage-custom-training-cycle">
<h3>Method four: Advanced usage, custom training cycle<a class="headerlink" href="#method-four-advanced-usage-custom-training-cycle" title="Permalink to this headline">¶</a></h3>
<p>If you are not using the <code class="docutils literal notranslate"><span class="pre">Model</span></code> interface provided by MindSpore, you can implement a method by imitating <code class="docutils literal notranslate"><span class="pre">train</span></code> method of <code class="docutils literal notranslate"><span class="pre">Model</span></code> interface to control the number of iterations. You can imitate the <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> and record the summary operator data in the following manner. For a detailed custom training cycle tutorial, please <a class="reference external" href="https://www.mindspore.cn/doc/programming_guide/en/r1.1/train.html#customizing-a-training-cycle">refer to the tutorial on the official website</a>.</p>
<p>The following example demonstrates how to record data in a custom training cycle using the summary operator and the <code class="docutils literal notranslate"><span class="pre">add_value</span></code> interface of <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code>. For more tutorials about <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code>, <a class="reference external" href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/mindspore.train.html?highlight=summaryrecord#mindspore.train.summary.SummaryRecord">refer to the Python API documentation</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.train.summary</span> <span class="kn">import</span> <span class="n">SummaryRecord</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="k">class</span> <span class="nc">LeNet5</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_class</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet5</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_class</span> <span class="o">=</span> <span class="n">num_class</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="o">...</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">image_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ImageSummary</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensor_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">TensorSummary</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_summary</span><span class="p">(</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensor_summary</span><span class="p">(</span><span class="s1">&#39;after_conv1&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="o">...</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="o">...</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">summary_record</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">for</span> <span class="n">inputs</span> <span class="ow">in</span> <span class="n">dataset_helper</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>
                <span class="n">current_step</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset_helper</span><span class="p">)</span> <span class="o">+</span> <span class="n">step</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;step: </span><span class="si">{0}</span><span class="s2">, losses: </span><span class="si">{1}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">current_step</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()))</span>

                <span class="c1"># Note1: The output should be a scalar, and use &#39;add_value&#39; method to record loss.</span>
                <span class="c1"># Note2: You must use the &#39;record(step)&#39; method to record the data of this step.</span>
                <span class="n">summary_record</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s1">&#39;scalar&#39;</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
                <span class="n">summary_record</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">current_step</span><span class="p">)</span>

                <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="tip-recording-gradients">
<h3>Tip: Recording gradients<a class="headerlink" href="#tip-recording-gradients" title="Permalink to this headline">¶</a></h3>
<p>There is a tip for recording gradients with summary in addition to the above methods. Please note that the tip should be used with one of the above methods.</p>
<p>Recording gradients is possible by inheriting your original optimizer and inserting calls to summary operator. An example of code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="o">...</span>

<span class="c1"># Define a new optimizer class by inheriting your original optimizer.</span>
<span class="k">class</span> <span class="nc">MyOptimizer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_original_construct</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">construct</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">HistogramSummary</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;.gradient&quot;</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="c1"># Record gradient.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gradient_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">grads</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_original_construct</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>

<span class="o">...</span>

<span class="c1"># Initialize your model with the newly defined optimizer.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">MyOptimizer</span><span class="p">(</span><span class="n">arg1</span><span class="o">=</span><span class="n">arg1value</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="run-mindinsight">
<h2>Run MindInsight<a class="headerlink" href="#run-mindinsight" title="Permalink to this headline">¶</a></h2>
<p>After completing the data collection in the tutorial above, you can start MindInsight to visualize the collected data. When start MindInsight, you need to specify the summary log file directory with the <code class="docutils literal notranslate"><span class="pre">--summary-base-dir</span></code> parameter.</p>
<p>The specified summary log file directory can be the output directory of a training or the parent directory of the output directory of multiple training.</p>
<p>The output directory structure for a training is as follows</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─summary_dir
    events.out.events.summary.1596869898.hostname_MS
    events.out.events.summary.1596869898.hostname_lineage
</pre></div>
</div>
<p>Execute command:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>mindinsight start --summary-base-dir ./summary_dir
</pre></div>
</div>
<p>The output directory structure of multiple training is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─summary
    ├─summary_dir1
    │      events.out.events.summary.1596869898.hostname_MS
    │      events.out.events.summary.1596869898.hostname_lineage
    │
    └─summary_dir2
            events.out.events.summary.1596869998.hostname_MS
            events.out.events.summary.1596869998.hostname_lineage
</pre></div>
</div>
<p>Execute command:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>mindinsight start --summary-base-dir ./summary
</pre></div>
</div>
<p>After successful startup, the visual page can be viewed by visiting the <code class="docutils literal notranslate"><span class="pre">http://127.0.0.1:8080</span></code> address through the browser.</p>
<p>Stop MindInsight command:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>mindinsight stop
</pre></div>
</div>
<p>For more parameter Settings, see the <a class="reference external" href="https://www.mindspore.cn/tutorial/training/en/r1.1/advanced_use/mindinsight_commands.html">MindInsight related commands</a> page.</p>
</div>
<div class="section" id="notices">
<h2>Notices<a class="headerlink" href="#notices" title="Permalink to this headline">¶</a></h2>
<ol>
<li><p>To limit time of listing summaries, MindInsight lists at most 999 summary items.</p></li>
<li><p>Multiple <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code> instances can not be used at the same time. (<code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code> is used in <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code>)</p>
<p>If you use two or more instances of <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> in the callback list of ‘model.train’ or ‘model.eval’, it is seen as using multiple <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code> instances at the same time, and it may cause recoding data failure.</p>
<p>If the customized callback uses <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code>, it can not be used with <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> at the same time.</p>
<p>Correct code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">])</span>
<span class="o">...</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">])</span>
</pre></div>
</div>
<p>Wrong code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="n">summary_collector1</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="s1">&#39;./summary_dir1&#39;</span><span class="p">)</span>
<span class="n">summary_collector2</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="s1">&#39;./summary_dir2&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector1</span><span class="p">,</span> <span class="n">summary_collector2</span><span class="p">])</span>
</pre></div>
</div>
<p>Wrong code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="c1"># Note: the &#39;ConfusionMatrixCallback&#39; is user-defined, and it uses SummaryRecord to record data.</span>
<span class="n">confusion_callback</span> <span class="o">=</span> <span class="n">ConfusionMatrixCallback</span><span class="p">(</span><span class="s1">&#39;./summary_dir1&#39;</span><span class="p">)</span>
<span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="s1">&#39;./summary_dir2&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">confusion_callback</span><span class="p">,</span> <span class="n">summary_collector</span><span class="p">])</span>
</pre></div>
</div>
</li>
<li><p>In each Summary log file directory, only one training data should be placed. If a summary log directory contains summary data from multiple training, MindInsight will overlay the summary data from these training when visualizing the data, which may not be consistent with the expected visualizations.</p></li>
<li><p>Currently, <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> and <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code> do not support scenarios with GPU multi-card running.</p></li>
<li><p>When using summary, it is recommended that you set <code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code> argument of <code class="docutils literal notranslate"><span class="pre">model.train()</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>, so that the unit of <code class="docutils literal notranslate"><span class="pre">collect_freq</span></code> is <code class="docutils literal notranslate"><span class="pre">step</span></code>. When <code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code> was <code class="docutils literal notranslate"><span class="pre">True</span></code>, the unit of <code class="docutils literal notranslate"><span class="pre">collect_freq</span></code> would be <code class="docutils literal notranslate"><span class="pre">epoch</span></code> and it is recommend you set <code class="docutils literal notranslate"><span class="pre">collect_freq</span></code> manually.</p></li>
<li><p>The maximum amount of data saved per step is 2147483647Bytes. If this limit is exceeded, data for the step cannot be recorded and an error occurs.</p></li>
<li><p>In PyNative mode, the <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> can be used properly, but the computational graph can not be recorded and the summary operator can not be used.</p></li>
</ol>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="dashboard.html" class="btn btn-neutral float-right" title="Viewing Dashboard" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="visualization_tutorials.html" class="btn btn-neutral float-left" title="Training Process Visualization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, MindSpore

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>