<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Implementing Simple Linear Function Fitting &mdash; MindSpore r1.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/training.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/training.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Hands-on Installation and Experience" href="quick_video.html" />
    <link rel="prev" title="Implementing an Image Classification Application" href="quick_start.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Implementing Simple Linear Function Fitting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#environment-preparation">Environment Preparation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#generating-datasets">Generating Datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-dataset-generation-function">Defining the Dataset Generation Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-data-argumentation-function">Defining the Data Argumentation Function</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#defining-the-training-network">Defining the Training Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="#defining-and-associating-the-forward-and-backward-propagation-networks">Defining and Associating the Forward and Backward Propagation Networks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-forward-propagation-network">Defining the Forward Propagation Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-backward-propagation-network">Defining the Backward Propagation Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="#associating-the-forward-and-backward-propagation-networks">Associating the Forward and Backward Propagation Networks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#preparation-for-fitting-process-visualization">Preparation for Fitting Process Visualization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-visualization-function">Defining the Visualization Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-callback-function">Defining the Callback Function</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#performing-training">Performing Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">Defining the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/save_model.html">Saving Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/load_model_for_inference_and_transfer.html">Loading a Model for Inference and Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/publish_model.html">Publishing Models using MindSpore Hub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Process Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/convert_dataset.html">Converting Dataset to MindRecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/optimize_data_processing.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build Networks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/custom_operator.html">Custom Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/migrate_script.html">Migrating Training Scripts from Third Party Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/apply_deep_probability_programming.html">Deep Probabilistic Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/achieve_high_order_differentiation.html">Achieve High Order Differentiation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/visualization_tutorials.html">Training Process Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/enable_auto_augmentation.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/evaluate_the_model_during_training.html">Evaluating the Model during Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/distributed_training_tutorials.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/apply_gradient_accumulation.html">Applying Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/enable_cache.html">Application of Single-Node Tensor Cache</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Compression</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/test_model_security_membership_inference.html">Using Membership Inference to Test Model Security</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/use_on_the_cloud.html">Use MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Implementing Simple Linear Function Fitting</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/quick_start/linear_regression.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="implementing-simple-linear-function-fitting">
<h1>Implementing Simple Linear Function Fitting<a class="headerlink" href="#implementing-simple-linear-function-fitting" title="Permalink to this headline"></a></h1>
<p>Author: <a class="reference external" href="https://github.com/helloyesterday">Yi Yang</a>    Editor: <a class="reference external" href="https://gitee.com/lvmingfu">Mingfu Lv</a></p>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Windows</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Whole</span> <span class="pre">Process</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.1/tutorials/training/source_en/quick_start/linear_regression.md" target="_blank"><img src="../_static/logo_source.png"></a>
  
<a href="https://gitee.com/mindspore/docs/blob/r1.1/tutorials/notebook/mindspore_linear_regression.ipynb" target="_blank"><img src="../_static/logo_notebook.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>Regression algorithms usually use a series of properties to predict a value, and the predicted values are consecutive. For example, the price of a house is predicted based on some given feature data of the house, such as area and the number of bedrooms; or future temperature conditions are predicted by using the temperature change data and satellite cloud images in the last week. If the actual price of the house is CNY5 million, and the value predicted through regression analysis is CNY4.99 million, the regression analysis is considered accurate. For machine learning problems, common regression analysis includes linear regression, polynomial regression, and logistic regression. This example describes the linear regression algorithms and how to use MindSpore to perform linear regression AI training.</p>
<p>The whole process is as follows:</p>
<ol class="arabic simple">
<li><p>Generate datasets.</p></li>
<li><p>Define a training network.</p></li>
<li><p>Define and associate the forward and backward propagation networks.</p></li>
<li><p>Prepare for fitting process visualization.</p></li>
<li><p>Perform training.</p></li>
</ol>
<p>Source code address of this example: <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.1/tutorials/tutorial_code/linear_regression.py">https://gitee.com/mindspore/docs/blob/r1.1/tutorials/tutorial_code/linear_regression.py</a>.</p>
</section>
<section id="environment-preparation">
<h2>Environment Preparation<a class="headerlink" href="#environment-preparation" title="Permalink to this headline"></a></h2>
<p>Complete MindSpore running configuration.</p>
<p>Third-party support package: <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code>. If this package is not installed, run the <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">matplotlib</span></code> command to install it first.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">GRAPH_MODE</span></code>: graph mode.</p>
<p><code class="docutils literal notranslate"><span class="pre">device_target</span></code>: sets the MindSpore training hardware to CPU.</p>
</section>
<section id="generating-datasets">
<h2>Generating Datasets<a class="headerlink" href="#generating-datasets" title="Permalink to this headline"></a></h2>
<section id="defining-the-dataset-generation-function">
<h3>Defining the Dataset Generation Function<a class="headerlink" href="#defining-the-dataset-generation-function" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">get_data</span></code> is used to generate training and test datasets. Since linear data is fitted, the required training datasets should be randomly distributed around the objective function. Assume that the objective function to be fitted is $f(x)=2x+3$. $f(x)=2x+3+noise$ is used to generate training datasets, and <code class="docutils literal notranslate"><span class="pre">noise</span></code> is a random value that complies with standard normal distribution rules.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">3.0</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">noise</span>
        <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p>Use <code class="docutils literal notranslate"><span class="pre">get_data</span></code> to generate 50 groups of test data and visualize them.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">eval_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">get_data</span><span class="p">(</span><span class="mi">50</span><span class="p">))</span>
<span class="n">x_target_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
<span class="n">y_target_label</span> <span class="o">=</span> <span class="n">x_target_label</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">3</span>
<span class="n">x_eval_label</span><span class="p">,</span><span class="n">y_eval_label</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">eval_data</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_eval_label</span><span class="p">,</span> <span class="n">y_eval_label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_target_label</span><span class="p">,</span> <span class="n">y_target_label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Eval data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<p><img alt="png" src="../_images/linear_regression_eval_datasets.png" /></p>
<p>In the preceding figure, the green line indicates the objective function, and the red points indicate the verification data <code class="docutils literal notranslate"><span class="pre">eval_data</span></code>.</p>
</section>
<section id="defining-the-data-argumentation-function">
<h3>Defining the Data Argumentation Function<a class="headerlink" href="#defining-the-data-argumentation-function" title="Permalink to this headline"></a></h3>
<p>Use the MindSpore data conversion function <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> to convert the data type to that suitable for MindSpore training, and then use <code class="docutils literal notranslate"><span class="pre">batch</span></code> and <code class="docutils literal notranslate"><span class="pre">repeat</span></code> to perform data argumentation. The operation is described as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ds.GeneratorDataset</span></code>: converts the generated data into a MindSpore dataset and saves the x and y values of the generated data to arrays of <code class="docutils literal notranslate"><span class="pre">data</span></code> and <code class="docutils literal notranslate"><span class="pre">label</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batch</span></code>: combines <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> pieces of data into a batch.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">repeat</span></code>: multiplies the number of datasets.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dataset</span> <span class="k">as</span> <span class="n">ds</span>

<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">get_data</span><span class="p">(</span><span class="n">num_data</span><span class="p">)),</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_data</span>
</pre></div>
</div>
<p>Use the dataset argumentation function to generate training data and view the training data format.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data_number</span> <span class="o">=</span> <span class="mi">1600</span>
<span class="n">batch_number</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">repeat_number</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">data_number</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_number</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="n">repeat_number</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The dataset size of ds_train:&quot;</span><span class="p">,</span> <span class="n">ds_train</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">())</span>
<span class="n">dict_datasets</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">ds_train</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="n">dict_datasets</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The x label value shape:&quot;</span><span class="p">,</span> <span class="n">dict_datasets</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The y label value shape:&quot;</span><span class="p">,</span> <span class="n">dict_datasets</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>The dataset size of ds_train: 100
dict_keys([&#39;data&#39;, &#39;label&#39;])
The x label value shape: (16, 1)
The y label value shape: (16, 1)
</pre></div>
</div>
<p>Use the defined <code class="docutils literal notranslate"><span class="pre">create_dataset</span></code> to perform argumentation on the generated 1600 data records and set them into 100 datasets with the shape of 16 x 1.</p>
</section>
</section>
<section id="defining-the-training-network">
<h2>Defining the Training Network<a class="headerlink" href="#defining-the-training-network" title="Permalink to this headline"></a></h2>
<p>In MindSpore, use <code class="docutils literal notranslate"><span class="pre">nn.Dense</span></code> to generate a linear function model of single data input and single data output.</p>
<p>$$f(x)=wx+b\tag{1}$$</p>
<p>Use the Normal operator to randomly initialize the weights $w$ and $b$.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">Normal</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">LinearNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">),</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<p>Call the network to view the initialized model parameters.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">LinearNet</span><span class="p">()</span>
<span class="n">model_params</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model_params</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Parameter (name=fc.weight) [[-0.02289871]]
Parameter (name=fc.bias) [0.01492652]
</pre></div>
</div>
<p>After initializing the network model, visualize the initialized network function and training dataset to understand the model function before fitting.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="n">x_model_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
<span class="n">y_model_label</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_model_label</span> <span class="o">*</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">model_params</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span>
                 <span class="n">Tensor</span><span class="p">(</span><span class="n">model_params</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_eval_label</span><span class="p">,</span> <span class="n">y_eval_label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_model_label</span><span class="p">,</span> <span class="n">y_model_label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_target_label</span><span class="p">,</span> <span class="n">y_target_label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<p><img alt="png" src="../_images/model_net_and_eval_datasets.png" /></p>
<p>As shown in the preceding figure, the initialized model function in blue differs greatly from the objective function in green.</p>
</section>
<section id="defining-and-associating-the-forward-and-backward-propagation-networks">
<h2>Defining and Associating the Forward and Backward Propagation Networks<a class="headerlink" href="#defining-and-associating-the-forward-and-backward-propagation-networks" title="Permalink to this headline"></a></h2>
<p>Define the loss function of the model. The mean squared error (MSE) method is used to determine the fitting effect. The smaller the MSE value difference, the better the fitting effect. The loss function formula is as follows:</p>
<p>$$J(w)=\frac{1}{2m}\sum_{i=1}^m(h(x_i)-y^{(i)})^2\tag{2}$$</p>
<p>Assuming that the $i$th data record in the training data is $(x_i,y^{(i)})$, parameters in formula 2 are described as follows:</p>
<ul class="simple">
<li><p>$J(w)$ specifies the loss value.</p></li>
<li><p>$m$ specifies the amount of sample data. In this example, the value of $m$ is <code class="docutils literal notranslate"><span class="pre">batch_number</span></code>.</p></li>
<li><p>$h(x_i)$ is a predicted value obtained after the $x_i$ value of the $i$th data record is substituted into the model network (formula 1).</p></li>
<li><p>$y^{(i)}$ is the $y^{(i)}$ value (label value) of the $i$th data record.</p></li>
</ul>
<section id="defining-the-forward-propagation-network">
<h3>Defining the Forward Propagation Network<a class="headerlink" href="#defining-the-forward-propagation-network" title="Permalink to this headline"></a></h3>
<p>A forward propagation network consists of two parts:</p>
<ol class="arabic simple">
<li><p>Bring parameters into the model network to obtain the predicted value.</p></li>
<li><p>Use the predicted value and training data to compute the loss value.</p></li>
</ol>
<p>The following method is used in MindSpore:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">LinearNet</span><span class="p">()</span>
<span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="defining-the-backward-propagation-network">
<h3>Defining the Backward Propagation Network<a class="headerlink" href="#defining-the-backward-propagation-network" title="Permalink to this headline"></a></h3>
<p>The objective of the backward propagation network is to continuously change the weight value to obtain the minimum loss value. Generally, the weight update formula is used in the linear network:</p>
<p>$$w_{t}=w_{t-1}-\alpha\frac{\partial{J(w_{t-1})}}{\partial{w}}\tag{3}$$</p>
<p>Parameters in formula 3 are described as follows:</p>
<ul class="simple">
<li><p>$w_{t}$ indicates the weight after training steps.</p></li>
<li><p>$w_{t-1}$ indicates the weight before training steps.</p></li>
<li><p>$\alpha$ indicates the learning rate.</p></li>
<li><p>$\frac{\partial{J(w_{t-1}\ )}}{\partial{w}}$ is the differentiation of the loss function to the weight $w_{t-1}$.</p></li>
</ul>
<p>After all weight values in the function are updated, transfer the values to the model function. This process is the backward propagation. To implement this process, the optimizer function in MindSpore is required.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="associating-the-forward-and-backward-propagation-networks">
<h3>Associating the Forward and Backward Propagation Networks<a class="headerlink" href="#associating-the-forward-and-backward-propagation-networks" title="Permalink to this headline"></a></h3>
<p>After forward propagation and backward propagation are defined, call the <code class="docutils literal notranslate"><span class="pre">Model</span></code> function in MindSpore to associate the previously defined networks, loss functions, and optimizer function to form a complete computing network.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="preparation-for-fitting-process-visualization">
<h2>Preparation for Fitting Process Visualization<a class="headerlink" href="#preparation-for-fitting-process-visualization" title="Permalink to this headline"></a></h2>
<section id="defining-the-visualization-function">
<h3>Defining the Visualization Function<a class="headerlink" href="#defining-the-visualization-function" title="Permalink to this headline"></a></h3>
<p>To make the entire training process easier to understand, the test data, objective function, and model network of the training process need to be visualized. The following defines a visualization function which is called after each training step to display a fitting process of the model network.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="k">def</span> <span class="nf">plot_model_and_datasets</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">eval_data</span><span class="p">):</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">bias</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">eval_data</span><span class="p">)</span>
    <span class="n">x_target</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">y_target</span> <span class="o">=</span> <span class="n">x_target</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">3</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="o">-</span><span class="mi">11</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="mi">25</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_target</span><span class="p">,</span> <span class="n">y_target</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.02</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="defining-the-callback-function">
<h3>Defining the Callback Function<a class="headerlink" href="#defining-the-callback-function" title="Permalink to this headline"></a></h3>
<p>MindSpore provides tools to customize the model training process. The following calls the visualization function in <code class="docutils literal notranslate"><span class="pre">step_end</span></code> to display the fitting process. For more information, see <a class="reference external" href="https://www.mindspore.cn/tutorial/training/en/r1.1/advanced_use/custom_debugging_info.html#callback">Customized Debugging Information</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">Callback</span>

<span class="k">class</span> <span class="nc">ImageShowCallback</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">eval_data</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_data</span> <span class="o">=</span> <span class="n">eval_data</span>

    <span class="k">def</span> <span class="nf">step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">plot_model_and_datasets</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_data</span><span class="p">)</span>
        <span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="performing-training">
<h2>Performing Training<a class="headerlink" href="#performing-training" title="Permalink to this headline"></a></h2>
<p>After the preceding process is complete, use the training parameter <code class="docutils literal notranslate"><span class="pre">ds_train</span></code> to train the model. In this example, <code class="docutils literal notranslate"><span class="pre">model.train</span></code> is called. The parameters are described as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">epoch</span></code>: Number of times that the entire dataset is trained.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ds_train</span></code>: Training dataset.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">callbacks</span></code>: Required callback function during training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code>: Dataset offload mode, which supports the Ascend and GPU computing platforms. In this example, this parameter is set to False for the CPU computing platform.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">LossMonitor</span>

<span class="n">epoch</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">imageshow_cb</span> <span class="o">=</span> <span class="n">ImageShowCallback</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">eval_data</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">imageshow_cb</span><span class="p">],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">plot_model_and_datasets</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">eval_data</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<p><img alt="gif" src="../_images/linear_regression.gif" /></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Parameter (name=fc.weight) [[2.0064354]]
Parameter (name=fc.bias) [2.9529438]
</pre></div>
</div>
<p>After the training is complete, the weight parameters of the final model are printed. The value of weight is close to 2.0 and the value of bias is close to 3.0. As a result, the model training meets the expectation.</p>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline"></a></h2>
<p>We have learned the principles of the linear fitting algorithm, defined the corresponding algorithms in the MindSpore framework, understood the training process of such linear fitting models in MindSpore, and finally fitted a model function close to the objective function. In addition, you can adjust the dataset generation interval from (-10,10) to (-100,100) to check whether the weight values are closer to those of the objective function; adjust the learning rate to check whether the fitting efficiency changes; or explore how to use MindSpore to fit quadratic functions, such as $f(x)=ax^2+bx+c$, or higher-order functions.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="quick_start.html" class="btn btn-neutral float-left" title="Implementing an Image Classification Application" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="quick_video.html" class="btn btn-neutral float-right" title="Hands-on Installation and Experience" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>