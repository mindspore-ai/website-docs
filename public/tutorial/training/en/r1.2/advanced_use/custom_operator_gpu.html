<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Custom Operators (GPU) &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/training.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Custom Operators (CPU)" href="custom_operator_cpu.html" />
    <link rel="prev" title="Custom Operators (Ascend)" href="custom_operator_ascend.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/linear_regression.html">Implementing Simple Linear Function Fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">Defining the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/save_model.html">Saving Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/load_model_for_inference_and_transfer.html">Loading a Model for Inference and Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/publish_model.html">Publishing Models using MindSpore Hub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Process Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="convert_dataset.html">Converting Dataset to MindRecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimize_data_processing.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build Networks</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="custom_loss_function.html">Customizing and Using Loss Function</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="custom_operator.html">Custom Operator</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="custom_operator_ascend.html">Custom Operators (Ascend)</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Custom Operators (GPU)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#registering-the-operator-primitive">Registering the Operator Primitive</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-bprop-function-for-an-operator">Defining the bprop Function for an Operator</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implementing-a-gpu-operator">Implementing a GPU operator</a></li>
<li class="toctree-l3"><a class="reference internal" href="#registering-the-operator-information">Registering the Operator Information</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compiling-mindspore">Compiling Mindspore</a></li>
<li class="toctree-l3"><a class="reference internal" href="#operator-verification">Operator verification</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="custom_operator_cpu.html">Custom Operators (CPU)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="migrate_script.html">Migrating Training Scripts from Third Party Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_deep_probability_programming.html">Deep Probabilistic Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_high_order_differentiation.html">Implementing High-order Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantum_neural_network.html">Quantum Neural Network</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization_tutorials.html">Training Process Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_augmentation.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluate_the_model_during_training.html">Evaluating the Model during Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_tutorials.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying a Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_cache.html">Application of Single-Node Tensor Cache</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Compression</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_post_training_quantization.html">Applying Post Training Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_suppress_privacy.html">Protecting User Privacy with Suppress Privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">Using Membership Inference to Test Model Security</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="custom_operator.html">Custom Operator</a> &raquo;</li>
      <li>Custom Operators (GPU)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/advanced_use/custom_operator_gpu.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="custom-operators-gpu">
<h1>Custom Operators (GPU)<a class="headerlink" href="#custom-operators-gpu" title="Permalink to this headline"></a></h1>
<p>Translator: <a class="reference external" href="https://gitee.com/Leon_02">Leon_02</a></p>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Development</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/training/source_en/advanced_use/custom_operator_gpu.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>Operator is the basic element of constructing neural network. When built-in operators cannot meet requirements during network development, you can utilize MindSpore to quickly extend custom operators of the Graphics Processing Unit.</p>
<ul class="simple">
<li><p>Primitive registration: the register operator primitive is the basic unit of constructing network model. Users can directly or indirectly call the operator primitive to build a neural network model.</p></li>
<li><p>GPU Kernel implementation: GPU kernel is used to call GPU to accelerate computing.</p></li>
<li><p>GPU Kernel registration: operator registration is used to register the GPU kernel and necessary information to the framework, and the framework completes the call to the GPU kernel.</p></li>
</ul>
<p>In this tutorial, we will develop a TensorAddV2 operator using C++ and CUDA in the mindspore framework. TensorAddV2 is used to add two tensors of the same dimension element by element.</p>
</section>
<section id="registering-the-operator-primitive">
<h2>Registering the Operator Primitive<a class="headerlink" href="#registering-the-operator-primitive" title="Permalink to this headline"></a></h2>
<p>Operator primitives usually include:</p>
<ul class="simple">
<li><p>Aperator names: operator names are used to uniquely identify operators.</p></li>
<li><p>Annotations: describe the algorithm and usage constraints of operators. The annotations will be exported as Mindspore API interface documentation for developers to refer to.</p></li>
<li><p>Input: the tensor(s) for operator input.</p></li>
<li><p>Attributes: for example, the <code class="docutils literal notranslate"><span class="pre">data_format</span></code> attribute in Conv2d describes that the input data is in <code class="docutils literal notranslate"><span class="pre">NCHW</span></code> or <code class="docutils literal notranslate"><span class="pre">NHWC</span></code> format.</p></li>
<li><p>Validation of input data: verify the validity of input data and attributes, which is convenient for developers to find the problems of network model as soon as possible.</p></li>
<li><p>Output data type and dimension derivation: used to derive the data type and dimension of output.</p></li>
</ul>
<p>The following code defines an operator called TensorAddV2:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">TensorAddV2</span></code> is a subclass inherited from <code class="docutils literal notranslate"><span class="pre">PrimitiveWithInfer</span></code>.</p></li>
<li><p>The constructor <code class="docutils literal notranslate"><span class="pre">__init__</span></code> is used to initialize the operator, since TensorAddV2 doesn’t have any attributes, there is none additional input for <code class="docutils literal notranslate"><span class="pre">__init__</span></code>.</p></li>
<li><p>The function <code class="docutils literal notranslate"><span class="pre">infer_shape</span></code> constraints two input dimensions must be the same and the output dimension will be same as the dimension of x1.</p></li>
<li><p>The function <code class="docutils literal notranslate"><span class="pre">infer_dtype</span></code> constrains that two input data must be of type float32 and the output data type is the same as the input data type.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mindspore/ops/operations/math_ops.py</span>
<span class="k">class</span> <span class="nc">TensorAddV2</span><span class="p">(</span><span class="n">PrimitiveWithInfer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adds two input tensors element-wise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@prim_attr_register</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_prim_io_names</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">infer_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1_shape</span><span class="p">,</span> <span class="n">x2_shape</span><span class="p">):</span>
        <span class="n">validator</span><span class="o">.</span><span class="n">check_integer</span><span class="p">(</span><span class="s1">&#39;input dims&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x1_shape</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">x2_shape</span><span class="p">),</span> <span class="n">Rel</span><span class="o">.</span><span class="n">EQ</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x1_shape</span><span class="p">)):</span>
            <span class="n">validator</span><span class="o">.</span><span class="n">check_integer</span><span class="p">(</span><span class="s1">&#39;input_shape&#39;</span><span class="p">,</span> <span class="n">x1_shape</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x2_shape</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">Rel</span><span class="o">.</span><span class="n">EQ</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x1_shape</span>

    <span class="k">def</span> <span class="nf">infer_dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1_dtype</span><span class="p">,</span> <span class="n">x2_type</span><span class="p">):</span>
        <span class="n">validator</span><span class="o">.</span><span class="n">check_tensor_type_same</span><span class="p">({</span><span class="s1">&#39;x1_dtype&#39;</span><span class="p">:</span> <span class="n">x1_dtype</span><span class="p">},</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="n">validator</span><span class="o">.</span><span class="n">check_tensor_type_same</span><span class="p">({</span><span class="s1">&#39;x2_dtype&#39;</span><span class="p">:</span> <span class="n">x2_dtype</span><span class="p">},</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x1_dtype</span>
</pre></div>
</div>
<p>Next we’ll export TensorAddV2 type in ‘<strong>init</strong>.py’, which convenient for users to import and use in the network.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mindspore/ops/operations/__init__.py</span>
<span class="kn">from</span> <span class="nn">.math_ops</span> <span class="kn">import</span> <span class="p">(</span><span class="n">Abs</span><span class="p">,</span> <span class="n">ACos</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">TensorAddV2</span><span class="p">)</span>
<span class="o">...</span>
<span class="o">...</span>
<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
  <span class="s1">&#39;ReverseSequence&#39;</span><span class="p">,</span>
  <span class="s1">&#39;CropAndResize&#39;</span><span class="p">,</span>
  <span class="o">...</span><span class="p">,</span>
  <span class="s1">&#39;TensorAddV2&#39;</span>
<span class="p">]</span>
</pre></div>
</div>
</section>
<section id="defining-the-bprop-function-for-an-operator">
<h2>Defining the bprop Function for an Operator<a class="headerlink" href="#defining-the-bprop-function-for-an-operator" title="Permalink to this headline"></a></h2>
<p>If an operator wants to support automatic differentiation, its back-propagation function (bprop) needs to be defined in its primitive. You need to describe the forward input, forward output and output gradient in bprop to get the reverse computing logic of input gradient. Reverse computation logic can be composed of built-in operators or custom reverse operators.</p>
<p>The following points should be paid attention to when defining the bprop Function for an operator:</p>
<ul class="simple">
<li><p>The input order of a bprop function is defined as forward input, forward output and output gradient. If the operator is a multi output operator, the forward output and output gradient will be provided in the form of tuples.</p></li>
<li><p>The return value of a bprop function is conventionally a tuple of input gradients, the order of elements in tuples is consistent with the order of forward input parameters. Even if there is only one input gradient, the return value must be in the form of tuples.</p></li>
</ul>
<p>For example, the reverse primitive for <code class="docutils literal notranslate"><span class="pre">TensorAddV2</span></code> can be:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="nd">@bprop_getters</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">TensorAddV2</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_bprop_tensoraddv2</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate bprop for TensorAddV2&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">bprop</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">dout</span><span class="p">,</span> <span class="n">dout</span>

    <span class="k">return</span> <span class="n">bprop</span>
</pre></div>
</div>
</section>
<section id="implementing-a-gpu-operator">
<h2>Implementing a GPU operator<a class="headerlink" href="#implementing-a-gpu-operator" title="Permalink to this headline"></a></h2>
<p>Custom GPU operators inherit from <code class="docutils literal notranslate"><span class="pre">GPUKernel</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Init()</span></code>: it is used to initialize the GPU kernel, usually includes recording the input / output dimension of the operator, and completing the preparation before launch.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GetInputSizeList()</span></code>: feedback to the frame the number of bytes of video memory to input tensor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GetOutputSizeList()</span></code>: feedback to the frame the number of bytes of video memory to output tensor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GetWorkspaceSizeList()</span></code>: feedback to the frame the number of bytes for <code class="docutils literal notranslate"><span class="pre">Workspace</span></code>, where <code class="docutils literal notranslate"><span class="pre">Workspace</span></code> is the space used to store temporary data during calculation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Launch()</span></code>: generally, CUDA kernel (CUDA kernel is a kernel function developed by Nvidia GPU’s parallel computing architecture) or cudnn interface are called to complete the operator acceleration on GPU.</p></li>
</ul>
<p>The following code shows the implementation of TensorAddV2:
In order to support generalization of data types, we use class template to define <code class="docutils literal notranslate"><span class="pre">TensorAddV2GpuKernel</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Init()</span></code> records the number of tensor elements.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GetInputSizeList()</span></code> returns the number of bytes the input tensor needs to occupy. TensorAddV2 has two Input and the number of bytes per input equals to element_num * sizeof(T).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GetOutputSizeList()</span></code> returns the number of bytes the output tensor needs to occupy. TensorAddV2 has one output and the output occupies element_num * sizeof(T) bytes.</p></li>
<li><p>Since TensorAddV2 doesn’t need <code class="docutils literal notranslate"><span class="pre">Workspace</span></code>, the <code class="docutils literal notranslate"><span class="pre">GetWorkspaceSizeList()</span></code> returns a null <code class="docutils literal notranslate"><span class="pre">std::vector&lt;size_t&gt;</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Launch()</span></code> receives the addresses of input and output in video memory, and then calls <code class="docutils literal notranslate"><span class="pre">TensorAddV2</span></code> to complete acceleration.</p></li>
</ul>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// mindspore/ccsrc/backend/kernel_compiler/gpu/math/tensor_add_v2_gpu_kernel.h</span>

<span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<span class="k">class</span><span class="w"> </span><span class="nc">TensorAddV2GpuKernel</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">GpuKernel</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="n">TensorAddV2GpuKernel</span><span class="p">()</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">element_num_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{}</span>
<span class="w">  </span><span class="o">~</span><span class="n">TensorAddV2GpuKernel</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span>

<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">Init</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">CNodePtr</span><span class="w"> </span><span class="o">&amp;</span><span class="n">kernel_node</span><span class="p">)</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">AnfAlgo</span><span class="o">::</span><span class="n">GetPrevNodeOutputInferShape</span><span class="p">(</span><span class="n">kernel_node</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">shape</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">element_num_</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">InitSizeLists</span><span class="p">();</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">GetInputSizeList</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">input_size_list_</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">GetOutputSizeList</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">output_size_list_</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">GetWorkspaceSizeList</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">workspace_size_list_</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>

<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">Launch</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">AddressPtr</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">AddressPtr</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="p">,</span>
<span class="w">              </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">AddressPtr</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">stream_ptr</span><span class="p">)</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">T</span><span class="w"> </span><span class="o">*</span><span class="n">x1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetDeviceAddress</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="n">T</span><span class="w"> </span><span class="o">*</span><span class="n">x2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetDeviceAddress</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">    </span><span class="n">T</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetDeviceAddress</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">    </span><span class="n">TensorAddV2</span><span class="p">(</span><span class="n">element_num_</span><span class="p">,</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">x2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="n">cudaStream_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">stream_ptr</span><span class="p">));</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w"> </span><span class="k">protected</span><span class="o">:</span>
<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">InitSizeLists</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">input_size_list_</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">element_num_</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">T</span><span class="p">));</span>
<span class="w">    </span><span class="n">input_size_list_</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">element_num_</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">T</span><span class="p">));</span>
<span class="w">    </span><span class="n">output_size_list_</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">element_num_</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">T</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>

<span class="w"> </span><span class="k">private</span><span class="o">:</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">element_num_</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">input_size_list_</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">output_size_list_</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">workspace_size_list_</span><span class="p">;</span>
<span class="p">};</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">TensorAddV2</span></code> calls CUDA kernel<code class="docutils literal notranslate"><span class="pre">TensorAddV2Kernel</span></code> to implement the parallel addition of <code class="docutils literal notranslate"><span class="pre">element_num</span></code> elements:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// mindspore/ccsrc/backend/kernel_compiler/gpu/math/tensor_add_v2_gpu_kernel.h</span>

<span class="w"> </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<span class="w"> </span><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">TensorAddV2Kernel</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">element_num</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">x2</span><span class="p">,</span><span class="w"> </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">element_num</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x2</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="w"> </span><span class="p">}</span>

<span class="w"> </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">TensorAddV2</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="o">&amp;</span><span class="n">element_num</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">x2</span><span class="p">,</span><span class="w"> </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">stream</span><span class="p">){</span>
<span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="n">thread_per_block</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">256</span><span class="p">;</span>
<span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="n">block_per_grid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">element_num</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">thread_per_block</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">thread_per_block</span><span class="p">;</span>
<span class="w">    </span><span class="n">TensorAddV2Kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">block_per_grid</span><span class="p">,</span><span class="w"> </span><span class="n">thread_per_block</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">element_num</span><span class="p">,</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">x2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">);</span>
<span class="w">   </span><span class="k">return</span><span class="p">;</span>
<span class="w"> </span><span class="p">}</span>

<span class="w"> </span><span class="k">template</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">TensorAddV2</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="o">&amp;</span><span class="n">element_num</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">x2</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="registering-the-operator-information">
<h2>Registering the Operator Information<a class="headerlink" href="#registering-the-operator-information" title="Permalink to this headline"></a></h2>
<p>Operator information includes:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Primive</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Input</span> <span class="pre">dtype,</span> <span class="pre">output</span> <span class="pre">dtype</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GPU</span> <span class="pre">Kernel</span> <span class="pre">class</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CUDA</span> <span class="pre">built-in</span> <span class="pre">dtype</span></code></p></li>
</ul>
<p>Framework calls <code class="docutils literal notranslate"><span class="pre">CUDA</span> <span class="pre">built-in</span> <span class="pre">dtype</span></code> to instantiate <code class="docutils literal notranslate"><span class="pre">GPU</span> <span class="pre">Kernel</span> <span class="pre">class</span></code> template class based on <code class="docutils literal notranslate"><span class="pre">Primive</span></code> and <code class="docutils literal notranslate"><span class="pre">Input</span> <span class="pre">dtype,</span> <span class="pre">output</span> <span class="pre">dtype</span></code>.</p>
<p>The TensorAddV2 operators supporting float and int are registered in the code below:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// mindspore/ccsrc/backend/kernel_compiler/gpu/math/tensor_add_v2_gpu_kernel.cc</span>

<span class="n">MS_REG_GPU_KERNEL_ONE</span><span class="p">(</span><span class="n">TensorAddV2</span><span class="p">,</span><span class="w"> </span><span class="n">KernelAttr</span><span class="p">()</span>
<span class="w">                                    </span><span class="p">.</span><span class="n">AddInputAttr</span><span class="p">(</span><span class="n">kNumberTypeFloat32</span><span class="p">)</span>
<span class="w">                                    </span><span class="p">.</span><span class="n">AddInputAttr</span><span class="p">(</span><span class="n">kNumberTypeFloat32</span><span class="p">)</span>
<span class="w">                                    </span><span class="p">.</span><span class="n">AddOutputAttr</span><span class="p">(</span><span class="n">kNumberTypeFloat32</span><span class="p">),</span>
<span class="w">                      </span><span class="n">TensorAddV2GpuKernel</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="p">)</span>

<span class="n">MS_REG_GPU_KERNEL_ONE</span><span class="p">(</span><span class="n">TensorAddV2</span><span class="p">,</span><span class="w"> </span><span class="n">KernelAttr</span><span class="p">()</span>
<span class="w">                                    </span><span class="p">.</span><span class="n">AddInputAttr</span><span class="p">(</span><span class="n">kNumberTypeInt32</span><span class="p">)</span>
<span class="w">                                    </span><span class="p">.</span><span class="n">AddInputAttr</span><span class="p">(</span><span class="n">kNumberTypeInt32</span><span class="p">)</span>
<span class="w">                                    </span><span class="p">.</span><span class="n">AddOutputAttr</span><span class="p">(</span><span class="n">kNumberTypeInt32</span><span class="p">),</span>
<span class="w">                      </span><span class="n">TensorAddV2GpuKernel</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="compiling-mindspore">
<h2>Compiling Mindspore<a class="headerlink" href="#compiling-mindspore" title="Permalink to this headline"></a></h2>
<p>After writing the custom GPU operator, you need to recompile and install MindSpore, see <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.2/install/mindspore_gpu_install_source_en.md#">Installation Documentation</a>.</p>
</section>
<section id="operator-verification">
<h2>Operator verification<a class="headerlink" href="#operator-verification" title="Permalink to this headline"></a></h2>
<p>At the end of the tutorial, we construct a single operator network to validate the TensorAddV2 operator we just developed：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># tests/st/ops/gpu/test_tensoraddv2_op.py</span>

<span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">level0</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">platform_x86_gpu_training</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">env_onecard</span>
<span class="k">def</span> <span class="nf">test_TensroAdd</span><span class="p">():</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">TensorAddV2</span><span class="p">()(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;result: &#39;</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>When the command <code class="docutils literal notranslate"><span class="pre">pytest</span> <span class="pre">-s</span> <span class="pre">tests/st/ops/gpu/test_tensoraddv2_op.py</span></code> executes, you can see the results meeting expectations：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>result: [[2. 2. 2. 2.]
  [2. 2. 2. 2.]
  [2. 2. 2. 2.]]
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="custom_operator_ascend.html" class="btn btn-neutral float-left" title="Custom Operators (Ascend)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="custom_operator_cpu.html" class="btn btn-neutral float-right" title="Custom Operators (CPU)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>