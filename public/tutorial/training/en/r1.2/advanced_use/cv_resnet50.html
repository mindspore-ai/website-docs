<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Image Classification Using ResNet-50 Network &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script src="../_static/js/training.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ResNet-50 Second-Order Optimization Practice" href="cv_resnet50_second_order_optimizer.html" />
    <link rel="prev" title="Computer Vision" href="cv.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/linear_regression.html">Implementing Simple Linear Function Fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">Defining the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/save_model.html">Saving Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/load_model_for_inference_and_transfer.html">Loading a Model for Inference and Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/publish_model.html">Publishing Models using MindSpore Hub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Process Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="convert_dataset.html">Converting Dataset to MindRecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimize_data_processing.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build Networks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="custom_loss_function.html">Customizing and Using Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_operator.html">Custom Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrate_script.html">Migrating Training Scripts from Third Party Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_deep_probability_programming.html">Deep Probabilistic Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_high_order_differentiation.html">Implementing High-order Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantum_neural_network.html">Quantum Neural Network</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization_tutorials.html">Training Process Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_augmentation.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluate_the_model_during_training.html">Evaluating the Model during Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_tutorials.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying a Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_cache.html">Application of Single-Node Tensor Cache</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Compression</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_post_training_quantization.html">Applying Post Training Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_suppress_privacy.html">Protecting User Privacy with Suppress Privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">Using Membership Inference to Test Model Security</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="cv.html">Computer Vision</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Image Classification Using ResNet-50 Network</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#image-classification">Image Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="#task-description-and-preparation">Task Description and Preparation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#downloading-the-cifar-10-dataset">Downloading the CIFAR-10 Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-preloading-and-preprocessing">Data Preloading and Preprocessing</a></li>
<li class="toctree-l4"><a class="reference internal" href="#defining-the-cnn">Defining the CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="#defining-the-loss-function-and-optimizer">Defining the Loss Function and Optimizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="#calling-the-high-level-model-api-to-train-and-save-the-model-file">Calling the High-level <code class="docutils literal notranslate"><span class="pre">Model</span></code> API To Train and Save the Model File</a></li>
<li class="toctree-l4"><a class="reference internal" href="#loading-and-validating-the-saved-model">Loading and Validating the Saved Model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cv_resnet50_second_order_optimizer.html">ResNet-50 Second-Order Optimization Practice</a></li>
<li class="toctree-l2"><a class="reference internal" href="cv_mobilenetv2_fine_tune.html">Using MobileNetV2 to Implement Fine-Tuning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="cv.html">Computer Vision</a> &raquo;</li>
      <li>Image Classification Using ResNet-50 Network</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/advanced_use/cv_resnet50.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="image-classification-using-resnet-50-network">
<h1>Image Classification Using ResNet-50 Network<a class="headerlink" href="#image-classification-using-resnet-50-network" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">Whole</span> <span class="pre">Process</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/training/source_en/advanced_use/cv_resnet50.md"><img alt="View Source On Gitee" src="../_images/logo_source.png" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>Computer vision is one of the most widely researched and mature technology fields of deep learning, and is widely applied to scenarios such as mobile phone photographing, intelligent security protection, and automated driving. Since AlexNet won the ImageNet competition in 2012, deep learning has greatly promoted the development of the computer vision field. Almost all the most advanced computer vision algorithms are related to deep learning. Deep neural network can extract image features layer by layer and retain local invariance. It is widely used in visual tasks such as classification, detection, segmentation, retrieval, recognition, promotion, and reconstruction.</p>
<p>This chapter describes how to apply MindSpore to computer vision scenarios based on image classification tasks.</p>
</section>
<section id="image-classification">
<h2>Image Classification<a class="headerlink" href="#image-classification" title="Permalink to this headline"></a></h2>
<p>Image classification is one of the most basic computer vision applications and belongs to the supervised learning category. For example, determine the class of a digital image, such as cat, dog, airplane, or car. The function is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
   <span class="n">label</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
   <span class="k">return</span> <span class="n">label</span>
</pre></div>
</div>
<p>The key point is to select a proper model. The model generally refers to a deep convolutional neural network (CNN), such as AlexNet, VGG, GoogleNet, and ResNet.</p>
<p>MindSpore presets a typical CNN, developer can visit <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.2/model_zoo/official">model_zoo</a> to get more details.</p>
<p>MindSpore supports the following image classification networks: LeNet, AlexNet, and ResNet.</p>
</section>
<section id="task-description-and-preparation">
<h2>Task Description and Preparation<a class="headerlink" href="#task-description-and-preparation" title="Permalink to this headline"></a></h2>
<p><img alt="cifar10" src="../_images/cifar10.jpg" /></p>
<p>Figure 1: CIFAR-10 dataset [1]</p>
<p>The CIFAR-10 dataset contains 10 classes of 60,000 images. Each class contains 6000 images. 50,000 images are for training and 10,000 images are for testing. The size of each image is 32 x 32 pixels.</p>
<p>Generally, a training indicator of image classification is accuracy, that is, a ratio of the quantity of accurately predicted examples to the total quantity of predicted examples.</p>
<p>Next, let’s use MindSpore to solve the image classification task. The overall process is as follows:</p>
<ol class="arabic simple">
<li><p>Download the CIFAR-10 dataset.</p></li>
<li><p>Load and preprocess data.</p></li>
<li><p>Define a convolutional neural network. In this example, the ResNet-50 network is used.</p></li>
<li><p>Define the loss function and optimizer.</p></li>
<li><p>Call the high-level <code class="docutils literal notranslate"><span class="pre">Model</span></code> API to train and save the model file.</p></li>
<li><p>Load the saved model for inference.</p></li>
</ol>
<blockquote>
<div><p>This example uses the hardware platform of the Ascend 910 AI processor. You can find the complete executable sample code at <a class="reference external" href="https://gitee.com/mindspore/docs/tree/r1.2/tutorials/tutorial_code/resnet">https://gitee.com/mindspore/docs/tree/r1.2/tutorials/tutorial_code/resnet</a>.</p>
</div></blockquote>
<p>The key parts of the task process code are explained below.</p>
<section id="downloading-the-cifar-10-dataset">
<h3>Downloading the CIFAR-10 Dataset<a class="headerlink" href="#downloading-the-cifar-10-dataset" title="Permalink to this headline"></a></h3>
<p>CIFAR-10 dataset download address: <a class="reference external" href="https://www.cs.toronto.edu/~kriz/cifar.html">the website of Cifar-10 Dataset</a>. In this example, the data is in binary format. In the Linux environment, run the following command to download the dataset:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz
</pre></div>
</div>
<p>Run the following command to decompress the dataset:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>tar<span class="w"> </span>-zvxf<span class="w"> </span>cifar-10-binary.tar.gz
</pre></div>
</div>
</section>
<section id="data-preloading-and-preprocessing">
<h3>Data Preloading and Preprocessing<a class="headerlink" href="#data-preloading-and-preprocessing" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>Load the dataset.</p>
<p>Data can be loaded through the built-in dataset format <code class="docutils literal notranslate"><span class="pre">Cifar10Dataset</span></code> API.</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">Cifar10Dataset</span></code>: The read type is random read. The built-in CIFAR-10 dataset contains images and labels. The default image format is uint8, and the default label data format is uint32. For details, see the description of the <code class="docutils literal notranslate"><span class="pre">Cifar10Dataset</span></code> API.</p>
</div></blockquote>
<p>The data loading code is as follows, where <code class="docutils literal notranslate"><span class="pre">data_home</span></code> indicates the data storage location:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cifar_ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">data_home</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Enhance the data.</p>
<p>Data augmentation is to normalize data and enrich the number of data samples. Common data augmentation modes include cropping, flipping, and color change. MindSpore calls the <code class="docutils literal notranslate"><span class="pre">map</span></code> method to perform augmentation operations on images.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">resize_height</span> <span class="o">=</span> <span class="mi">224</span>
<span class="n">resize_width</span> <span class="o">=</span> <span class="mi">224</span>
<span class="n">rescale</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">shift</span> <span class="o">=</span> <span class="mf">0.0</span>

<span class="c1"># define map operations</span>
<span class="n">random_crop_op</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span> <span class="c1"># padding_mode default CONSTANT</span>
<span class="n">random_horizontal_op</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">()</span>
<span class="n">resize_op</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="n">resize_height</span><span class="p">,</span> <span class="n">resize_width</span><span class="p">))</span> <span class="c1"># interpolation default BILINEAR</span>
<span class="n">rescale_op</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="n">rescale</span><span class="p">,</span> <span class="n">shift</span><span class="p">)</span>
<span class="n">normalize_op</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.4914</span><span class="p">,</span> <span class="mf">0.4822</span><span class="p">,</span> <span class="mf">0.4465</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.2023</span><span class="p">,</span> <span class="mf">0.1994</span><span class="p">,</span> <span class="mf">0.2010</span><span class="p">))</span>
<span class="n">changeswap_op</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
<span class="n">type_cast_op</span> <span class="o">=</span> <span class="n">C2</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

<span class="n">c_trans</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">if</span> <span class="n">training</span><span class="p">:</span>
    <span class="n">c_trans</span> <span class="o">=</span> <span class="p">[</span><span class="n">random_crop_op</span><span class="p">,</span> <span class="n">random_horizontal_op</span><span class="p">]</span>
<span class="n">c_trans</span> <span class="o">+=</span> <span class="p">[</span><span class="n">resize_op</span><span class="p">,</span> <span class="n">rescale_op</span><span class="p">,</span> <span class="n">normalize_op</span><span class="p">,</span> <span class="n">changeswap_op</span><span class="p">]</span>

<span class="c1"># apply map operations on images</span>
<span class="n">cifar_ds</span> <span class="o">=</span> <span class="n">cifar_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">type_cast_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">)</span>
<span class="n">cifar_ds</span> <span class="o">=</span> <span class="n">cifar_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">c_trans</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Shuffle and batch process the data.</p>
<p>Shuffle data randomly to disorder the data sequence and read data in batches for model training:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># apply shuffle operations</span>
<span class="n">cifar_ds</span> <span class="o">=</span> <span class="n">cifar_ds</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># apply batch operations</span>
<span class="n">cifar_ds</span> <span class="o">=</span> <span class="n">cifar_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">args_opt</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># apply repeat operations</span>
<span class="n">cifar_ds</span> <span class="o">=</span> <span class="n">cifar_ds</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat_num</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="defining-the-cnn">
<h3>Defining the CNN<a class="headerlink" href="#defining-the-cnn" title="Permalink to this headline"></a></h3>
<p>CNN is a standard algorithm for image classification tasks. CNN uses a layered structure to perform feature extraction on an image, and is formed by stacking a series of network layers, such as a convolutional layer, a pooling layer, and an activation layer.</p>
<p>ResNet is recommended. First, it is deep enough with 34 layers, 50 layers, or 101 layers. The deeper the hierarchy, the stronger the representation capability, and the higher the classification accuracy. Second, it is learnable. The residual structure is used. The lower layer is directly connected to the upper layer through the shortcut connection, which solves the problem of gradient disappearance caused by the network depth during the reverse propagation. In addition, the ResNet network has good performance, including the recognition accuracy, model size, and parameter quantity.</p>
<p>MindSpore Model Zoo has a ResNet <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/model_zoo/official/cv/resnet/src/resnet.py">model</a>. The calling method is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">network</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>For more information about ResNet, see <a class="reference external" href="https://arxiv.org/abs/1512.03385">ResNet Paper</a>.</p>
</section>
<section id="defining-the-loss-function-and-optimizer">
<h3>Defining the Loss Function and Optimizer<a class="headerlink" href="#defining-the-loss-function-and-optimizer" title="Permalink to this headline"></a></h3>
<p>A loss function and an optimizer need to be defined. The loss function is a training objective of the deep learning, and is also referred to an objective function. The loss function indicates the distance between a logit of a neural network and a label, and is scalar data.</p>
<p>Common loss functions include mean square error, L2 loss, Hinge loss, and cross entropy. Cross entropy is usually used for image classification.</p>
<p>The optimizer is used for neural network solution (training). Because of the large scale of neural network parameters, the stochastic gradient descent (SGD) algorithm and its improved algorithm are used in deep learning to solve the problem. MindSpore encapsulates common optimizers, such as <code class="docutils literal notranslate"><span class="pre">SGD</span></code>, <code class="docutils literal notranslate"><span class="pre">ADAM</span></code>, and <code class="docutils literal notranslate"><span class="pre">Momemtum</span></code>. In this example, the <code class="docutils literal notranslate"><span class="pre">Momentum</span></code> optimizer is used. Generally, two parameters need to be set: <code class="docutils literal notranslate"><span class="pre">moment</span></code> and <code class="docutils literal notranslate"><span class="pre">weight</span> <span class="pre">decay</span></code>.</p>
<p>An example of the code for defining the loss function and optimizer in MindSpore is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># loss function definition</span>
<span class="n">ls</span> <span class="o">=</span> <span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>

<span class="c1"># optimization definition</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()),</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="calling-the-high-level-model-api-to-train-and-save-the-model-file">
<h3>Calling the High-level <code class="docutils literal notranslate"><span class="pre">Model</span></code> API To Train and Save the Model File<a class="headerlink" href="#calling-the-high-level-model-api-to-train-and-save-the-model-file" title="Permalink to this headline"></a></h3>
<p>After data preprocessing, network definition, and loss function and optimizer definition are complete, model training can be performed. Model training involves two iterations: multi-round iteration (<code class="docutils literal notranslate"><span class="pre">epoch</span></code>) of datasets and single-step iteration based on the batch size of datasets. The single-step iteration refers to extracting data from a dataset by <code class="docutils literal notranslate"><span class="pre">batch</span></code>, inputting the data to a network to calculate a loss function, and then calculating and updating a gradient of training parameters by using an optimizer.</p>
<p>To simplify the training process, MindSpore encapsulates the high-level <code class="docutils literal notranslate"><span class="pre">Model</span></code> API. You can enter the network, loss function, and optimizer to complete the <code class="docutils literal notranslate"><span class="pre">Model</span></code> initialization, and then call the <code class="docutils literal notranslate"><span class="pre">train</span></code> API for training. The <code class="docutils literal notranslate"><span class="pre">train</span></code> API parameters include the number of iterations (<code class="docutils literal notranslate"><span class="pre">epoch</span></code>) and dataset (<code class="docutils literal notranslate"><span class="pre">dataset</span></code>).</p>
<p>Model saving is a process of persisting training parameters. In the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class, the model is saved using the <code class="docutils literal notranslate"><span class="pre">callback</span></code> function, as shown in the following code: You can set the parameters of the <code class="docutils literal notranslate"><span class="pre">callback</span></code> function by using <code class="docutils literal notranslate"><span class="pre">CheckpointConfig</span></code>. <code class="docutils literal notranslate"><span class="pre">save_checkpoint_steps</span></code> indicates that the model is saved once every fixed number of single-step iterations, and <code class="docutils literal notranslate"><span class="pre">keep_checkpoint_max</span></code> indicates the maximum number of saved models.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">network, loss, optimizer are defined before.</span>
<span class="sd">batch_num, epoch_size are training parameters.</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">})</span>

<span class="c1"># CheckPoint CallBack definition</span>
<span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">batch_num</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">35</span><span class="p">)</span>
<span class="n">ckpoint_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;train_resnet_cifar10&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;./&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>

<span class="c1"># LossMonitor is used to print loss value on screen</span>
<span class="n">loss_cb</span> <span class="o">=</span> <span class="n">LossMonitor</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch_size</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ckpoint_cb</span><span class="p">,</span> <span class="n">loss_cb</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="loading-and-validating-the-saved-model">
<h3>Loading and Validating the Saved Model<a class="headerlink" href="#loading-and-validating-the-saved-model" title="Permalink to this headline"></a></h3>
<p>The trained model file (such as <code class="docutils literal notranslate"><span class="pre">resnet.ckpt</span></code>) can be used to predict the class of a new image. Run the <code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code> command to load the model file. Then call the <code class="docutils literal notranslate"><span class="pre">eval</span></code> API of <code class="docutils literal notranslate"><span class="pre">Model</span></code> to predict the new image class.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">args_opt</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">)</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;result: &quot;</span><span class="p">,</span> <span class="n">res</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline"></a></h2>
<p>[1] <a class="reference external" href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="cv.html" class="btn btn-neutral float-left" title="Computer Vision" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="cv_resnet50_second_order_optimizer.html" class="btn btn-neutral float-right" title="ResNet-50 Second-Order Optimization Practice" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>