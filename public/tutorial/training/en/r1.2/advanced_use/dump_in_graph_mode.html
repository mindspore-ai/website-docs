<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Using Dump in the Graph Mode &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/training.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/training.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Custom Debugging Information" href="custom_debugging_info.html" />
    <link rel="prev" title="Debugging in PyNative Mode" href="debug_in_pynative_mode.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/linear_regression.html">Implementing Simple Linear Function Fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">Defining the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/save_model.html">Saving Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/load_model_for_inference_and_transfer.html">Loading a Model for Inference and Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/publish_model.html">Publishing Models using MindSpore Hub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Process Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="convert_dataset.html">Converting Dataset to MindRecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimize_data_processing.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build Networks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="custom_loss_function.html">Customizing and Using Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_operator.html">Custom Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrate_script.html">Migrating Training Scripts from Third Party Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_deep_probability_programming.html">Deep Probabilistic Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_high_order_differentiation.html">Implementing High-order Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantum_neural_network.html">Quantum Neural Network</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Using Dump in the Graph Mode</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#debugging-process">Debugging Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="#applicable-scene">Applicable Scene</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#dump-introduction">Dump Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#synchronous-dump">Synchronous Dump</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#synchronous-dump-step">Synchronous Dump Step</a></li>
<li class="toctree-l3"><a class="reference internal" href="#synchronous-dump-data-object-directory">Synchronous Dump Data Object Directory</a></li>
<li class="toctree-l3"><a class="reference internal" href="#introduction-to-synchronous-dump-data-file">Introduction to Synchronous Dump Data File</a></li>
<li class="toctree-l3"><a class="reference internal" href="#synchronous-dump-data-analysis-sample">Synchronous Dump Data Analysis Sample</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#asynchronous-dump">Asynchronous Dump</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#asynchronous-dump-step">Asynchronous Dump Step</a></li>
<li class="toctree-l3"><a class="reference internal" href="#asynchronous-dump-data-object-directory">Asynchronous Dump Data Object Directory</a></li>
<li class="toctree-l3"><a class="reference internal" href="#introduction-to-asynchronous-dump-data-file">Introduction to Asynchronous Dump Data File</a></li>
<li class="toctree-l3"><a class="reference internal" href="#asynchronous-dump-data-analysis-sample">Asynchronous Dump Data Analysis Sample</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization_tutorials.html">Training Process Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_augmentation.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluate_the_model_during_training.html">Evaluating the Model during Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_tutorials.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying a Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_cache.html">Application of Single-Node Tensor Cache</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Compression</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_post_training_quantization.html">Applying Post Training Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_suppress_privacy.html">Protecting User Privacy with Suppress Privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">Using Membership Inference to Test Model Security</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Using Dump in the Graph Mode</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/advanced_use/dump_in_graph_mode.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="using-dump-in-the-graph-mode">
<h1>Using Dump in the Graph Mode<a class="headerlink" href="#using-dump-in-the-graph-mode" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Optimization</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/training/source_en/advanced_use/dump_in_graph_mode.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.2/resource/_static/logo_source.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>The input and output of the operator can be saved for debugging through the data dump when the training result deviates from the expectation.</p>
<ul class="simple">
<li><p>For the dynamic graph mode, MindSpore provides native Python execution capabilities. Users can view and record the corresponding input and output during the running of the network script. For details, see <a class="reference external" href="https://www.mindspore.cn/tutorial/training/en/r1.2/advanced_use/debug_in_pynative_mode.html">Use PyNative Mode to Debug</a>.</p></li>
<li><p>For the static graph mode, MindSpore provides the Dump function to save the graph and the input and output data of the operator during model training to a disk file.</p></li>
</ul>
<p>Aiming at the static graph mode, this tutorial introduces how to analyze and compare network data based on the Dump function.</p>
<section id="debugging-process">
<h3>Debugging Process<a class="headerlink" href="#debugging-process" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>Find the corresponding operator from the script.</p>
<p>The Dump function needs to use the IR file of the final execution graph. The IR file can be viewed with the <code class="docutils literal notranslate"><span class="pre">vi</span></code> command. The IR file contains the full name of the operator, and the dependency of the operator on the input and output of the computational graph, and also contains the trace information from the operator to the corresponding script code. For the configuration of the Dump function, see <span class="xref myst">Synchronous Dump Step</span> and <span class="xref myst">Asynchronous Dump Step</span>. For the final implementation of the image IR file naming and directory structure, see <span class="xref myst">Synchronous Dump Data Object Directory</span> and <span class="xref myst">Asynchronous Dump Data Object Directory</span>. Then find the operator corresponding to the code in the script through the graph file, refer to <span class="xref myst">Synchronous Dump Data Analysis Sample</span> and <span class="xref myst">Asynchronous Dump Data Analysis Sample</span>.</p>
</li>
<li><p>From operator to dump data.</p>
<p>After understanding the mapping relationship between the script and the operator, you can determine the name of the operator you want to analyze and find the dump file corresponding to the operator. Please refer to <span class="xref myst">Synchronous Dump Data Object Directory</span> and <span class="xref myst">Asynchronous Dump Data Object Directory</span>.</p>
</li>
<li><p>Analyze Dump data.</p>
<p>By analyzing Dump data, it can be compared with other third-party frameworks. For the synchronous dump data format, please refer to <span class="xref myst">Introduction to Synchronous Dump Data File</span>. For the asynchronous Dump data format, please refer to <span class="xref myst">Introduction to Asynchronous Dump Data File</span>.</p>
</li>
</ol>
</section>
<section id="applicable-scene">
<h3>Applicable Scene<a class="headerlink" href="#applicable-scene" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>Analysis of static graph operator results.</p>
<p>Through the IR diagram obtained by the Dump function, you can understand the mapping relationship between the script code and the execution operator (for details, see <a class="reference external" href="https://www.mindspore.cn/doc/note/en/r1.2/design/mindspore/mindir.html#overview">MindSpore IR Introduction</a>). Combining the input and output data of the execution operator, it is possible to analyze possible overflow, gradient explosion and disappearance during the training process, and backtrack to the code that may have problems in the script.</p>
</li>
<li><p>Analysis of the feature map.</p>
<p>Analyze the information of the feature map by obtaining the output data of the layer.</p>
</li>
<li><p>Model migration.</p>
<p>In the scenario of migrating a model from a third-party framework (TensorFlow, PyTorch) to MindSpore, by comparing the output data of the same position operator, analyzing whether the training results of the third-party framework and MindSpore for the same model are close enough to locate the model Precision issues.</p>
</li>
</ol>
</section>
</section>
<section id="dump-introduction">
<h2>Dump Introduction<a class="headerlink" href="#dump-introduction" title="Permalink to this headline"></a></h2>
<p>MindSpore provides two modes: synchronous dump and asynchronous dump:</p>
<ul class="simple">
<li><p>The mechanism of synchronous dump is that after the execution of each step in the network training process, the host side initiates a dump action, copies the data in the operator address from the device to the host, and saves the file. Synchronous Dump will turn off memory reuse between operators by default to avoid reading dirty data.</p></li>
<li><p>Asynchronous Dump is a function developed specifically for the sinking of the entire Ascend image. It can dump data while executing the operator. The data will be dumped immediately after the execution of an operator. Therefore, the correct data can be generated by turning on the memory reuse, but the corresponding network training speed will be slower.</p></li>
</ul>
<p>The configuration files required for different modes and the data format of dump are different:</p>
<ul class="simple">
<li><p>Synchronous mode takes up more memory than asynchronous mode, but it is easier to use.</p></li>
<li><p>Generally, for small and medium-sized networks (such as ResNet), it is recommended to use the synchronous dump mode first. When the network does not occupy much memory, please use synchronous dump first.If an error of insufficient device memory occurs after enabling synchronous dump, please use asynchronous dump in the next section.</p></li>
<li><p>When Dump is enabled on Ascend, the operator to Dump will automatically close memory reuse.</p></li>
<li><p>Synchronous Dump supports the graphics mode both on Ascend, GPU and CPU, and currently does not support PyNative mode.</p></li>
<li><p>Asynchronous Dump only supports graph mode on Ascend, not PyNative mode. Memory reuse will not be turned off when asynchronous dump is enabled.</p></li>
</ul>
</section>
<section id="synchronous-dump">
<h2>Synchronous Dump<a class="headerlink" href="#synchronous-dump" title="Permalink to this headline"></a></h2>
<section id="synchronous-dump-step">
<h3>Synchronous Dump Step<a class="headerlink" href="#synchronous-dump-step" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>Create dump json file:<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>, the name and location of the JSON file can be customized.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;common_dump_settings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;dump_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;/absolute_path&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;net_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ResNet50&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;iteration&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;input_output&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;kernels&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;Default/Conv-op12&quot;</span><span class="p">],</span>
<span class="w">        </span><span class="nt">&quot;support_device&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">]</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;e2e_dump_settings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enable&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;trans_flag&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dump_mode</span></code>: 0: dump all kernels in graph, 1: dump kernels in kernels list.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>: The absolute path to save dump data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>: The net name eg:ResNet50.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration</span></code>: Specify the iterations to dump. Iteration should be set to 0 when dataset_sink_mode is False and data of every iteration will be dumped.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output</span></code>: 0: dump input and output of kernel, 1:dump input of kernel, 2:dump output of kernel. This parameter does not take effect on the GPU and only the output of operator will be dumped.  This configuration parameter only supports Ascend and CPU, and GPU can only dump the output of operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernels</span></code>: List of operator names. Turn on the IR save switch <code class="docutils literal notranslate"><span class="pre">context.set_context(save_graphs=True)</span></code> and execute the network to obtain the operator name from the generated <code class="docutils literal notranslate"><span class="pre">trace_code_graph_{graph_id}</span></code>IR file. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/doc/note/en/r1.2/design/mindspore/mindir.html#saving-ir">Saving IR</a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">support_device</span></code>: Supported devices, default setting is <code class="docutils literal notranslate"><span class="pre">[0,1,2,3,4,5,6,7]</span></code>. You can specify specific device ids to dump specific device data.  This configuration parameter is invalid on the CPU, because there is no concept of device on the CPU.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">enable</span></code>: Enable Asynchronous Dump. If synchronous dump and asynchronous dump are enabled at the same time, only synchronous dump will take effect.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trans_flag</span></code>: Enable trans flag. Transform the device data format into NCHW. If it is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the data will be saved in the 4D format (NCHW) format on the Host side; if it is <code class="docutils literal notranslate"><span class="pre">False</span></code>, the data format on the Device side will be retained.  This configuration parameter is invalid on the CPU, because there is no format conversion on the CPU.</p></li>
</ul>
</li>
<li><p>Specify the json configuration file of Dump.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_DUMP_CONFIG</span><span class="o">=</span><span class="si">${</span><span class="nv">xxx</span><span class="si">}</span>
</pre></div>
</div>
<p>“xxx” represents the absolute path of data_dump.json</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_DUMP_CONFIG</span><span class="o">=</span>/path/to/data_dump.json
</pre></div>
</div>
<ul class="simple">
<li><p>Set the environment variables before executing the training script. Setting environment variables during training will not take effect.</p></li>
<li><p>Dump environment variables need to be configured before calling <code class="docutils literal notranslate"><span class="pre">mindspore.communication.management.init</span></code>.</p></li>
</ul>
</li>
<li><p>Execute the training script to dump data.</p>
<p>After the training is started, if the <code class="docutils literal notranslate"><span class="pre">MINDSPORE_DUMP_CONFIG</span></code> environment variable is correctly configured, the content of the configuration file will be read and the operator data will be saved according to the data storage path specified in the Dump configuration.
In synchronous mode, if you want to dump data, you must use the non-data sink mode (set the <code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">model.train</span></code> or <code class="docutils literal notranslate"><span class="pre">DatasetHelper</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>) to ensure that you can get the dump data of each step.
If <code class="docutils literal notranslate"><span class="pre">model.train</span></code> or <code class="docutils literal notranslate"><span class="pre">DatasetHelper</span></code> is not called in the script, the default is non-data sinking mode. Using the Dump function will automatically generate the IR file of the final execution graph.</p>
<p>You can set <code class="docutils literal notranslate"><span class="pre">context.set_context(reserve_class_name_in_scope=False)</span></code> in your training script to avoid dump failure because of file name is too long.</p>
</li>
<li><p>Read and parse synchronous dump data through <code class="docutils literal notranslate"><span class="pre">numpy.fromfile</span></code>, refer to <span class="xref myst">Introduction to Synchronous Dump Data File</span>.</p></li>
</ol>
</section>
<section id="synchronous-dump-data-object-directory">
<h3>Synchronous Dump Data Object Directory<a class="headerlink" href="#synchronous-dump-data-object-directory" title="Permalink to this headline"></a></h3>
<p>After starting the training, the data objects saved by the synchronous Dump include the final execution graph (<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code> file) and the input and output data of the operators in the graph. The data directory structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{path}/
    |-- {net_name}/
        |-- device_{device_id}/
            |-- iteration_{iteration}/
                -- {op_name}_{input_output_index}_{shape}_{data_type}_{format}.bin
                …
            |-- graphs/
                ms_output_trace_code_graph_{graph_id}.pb
                ms_output_trace_code_graph_{graph_id}.ir
            |-- execution_order/
                ms_execution_order_graph_{graph_id}.csv

    |-- .metadata/
        data_dump.json
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>: the absolute path set in the <code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code> configuration file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>: the network name set in the <code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code> configuration file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">device_id</span></code>: the id of the training device.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">graph_id</span></code>: the id of the training graph.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration</span></code>: the iteration of the training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">operator_name</span></code>: the name of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output_index</span></code> : the index of input or output. For example, <code class="docutils literal notranslate"><span class="pre">output_0</span></code> means that the file is the data of the first output Tensor of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shape</span></code>: Tensor dimension information.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data_type</span></code>: the type of the data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">format</span></code>: the format of the data.</p></li>
</ul>
<p>When data dump is performed on the CPU, there is no directory level of <code class="docutils literal notranslate"><span class="pre">device_id</span></code>, because there is no concept of device on the CPU, and there are no <code class="docutils literal notranslate"><span class="pre">graphs</span></code>, <code class="docutils literal notranslate"><span class="pre">execution_order</span></code> and <code class="docutils literal notranslate"><span class="pre">.metadata</span></code> directories.</p>
</section>
<section id="introduction-to-synchronous-dump-data-file">
<h3>Introduction to Synchronous Dump Data File<a class="headerlink" href="#introduction-to-synchronous-dump-data-file" title="Permalink to this headline"></a></h3>
<p>The data file generated by the synchronous Dump is a binary file with the suffix <code class="docutils literal notranslate"><span class="pre">.bin</span></code>, and the file naming format is:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{operator_name}_{input_output_index}_{shape}_{data_type}_{format}.bin
</pre></div>
</div>
<p>According to the <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> information provided by the file name, you can use <code class="docutils literal notranslate"><span class="pre">numpy.fromfile</span></code> to read the data and restore the <code class="docutils literal notranslate"><span class="pre">data_type</span></code> and <code class="docutils literal notranslate"><span class="pre">shape</span></code> of the original data.</p>
<p>The suffixes of the final execution graph files generated by synchronous Dump are <code class="docutils literal notranslate"><span class="pre">.pb</span></code> and <code class="docutils literal notranslate"><span class="pre">.ir</span></code> respectively, and the file naming format is:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ms_output_trace_code_graph_{graph_id}.pb
ms_output_trace_code_graph_{graph_id}.ir
</pre></div>
</div>
<p>The files with the suffix <code class="docutils literal notranslate"><span class="pre">.ir</span></code> can be opened and viewed by the <code class="docutils literal notranslate"><span class="pre">vi</span></code> command.</p>
<p>The suffix of the node execution sequence file generated by the synchronous Dump is <code class="docutils literal notranslate"><span class="pre">.csv</span></code>, and the file naming format is:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ms_execution_order_graph_{graph_id}.csv
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">.metadata</span></code> records the original training information, and <code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code> saves the dump configuration set by the user.</p>
</section>
<section id="synchronous-dump-data-analysis-sample">
<h3>Synchronous Dump Data Analysis Sample<a class="headerlink" href="#synchronous-dump-data-analysis-sample" title="Permalink to this headline"></a></h3>
<p>For the Ascend scene, after the graph corresponding to the script is saved to the disk through the Dump function, the final execution graph file <code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code> will be generated. This file saves the stack information of each operator in the corresponding graph, and records the generation script corresponding to the operator.</p>
<p>Take <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/model_zoo/official/cv/alexnet/src/alexnet.py">AlexNet script</a> as an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>


<span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                     <span class="n">has_bias</span><span class="o">=</span><span class="n">has_bias</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="n">pad_mode</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">fc_with_initialize</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="n">has_bias</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">AlexNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Alexnet</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">phase</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlexNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv5</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">include_top</span> <span class="o">=</span> <span class="n">include_top</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">include_top</span><span class="p">:</span>
            <span class="n">dropout_ratio</span> <span class="o">=</span> <span class="mf">0.65</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span>
                <span class="n">dropout_ratio</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">*</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_ratio</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;define network&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv5</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">include_top</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<p>If the user wants to view the code at line 58 in the script:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>After executing the network training, you can find multiple operator information corresponding to the line of code from the final execution graph (<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code> file). The content of the file is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  %24(equivoutput) = Conv2D(%23, %21) {instance name: conv2d} primitive_attrs: {compile_info: , pri_format: NC1HWC0, stride: (1, 1, 1, 1), pad: (0, 0, 0, 0), pad_mod: same, out_channel:
192, mode: 1, dilation: (1, 1, 1, 1), output_names: [output], group: 1, format: NCHW, offset_a: 0, kernel_size: (3, 3), groups: 1, input_names: [x, w], pad_list: (1, 1, 1, 1),
IsFeatureMapOutput: true, IsFeatureMapInputList: (0)}
       : (&lt;Tensor[Float32]x[const vector][32, 128, 13, 13]&gt;, &lt;Tensor[Float16]x[const vector][192, 128, 3, 3]&gt;) -&gt; (&lt;Tensor[Float16]x[const vector][32, 192, 13, 13]&gt;)
       : (&lt;Float16xNC1HWC0[const vector][32, 8, 13, 13, 16]&gt;, &lt;Float16xFracZ[const vector][72, 12, 16, 16]&gt;) -&gt; (&lt;Float16xNC1HWC0[const vector][32, 12, 13, 13, 16]&gt;)
       : (Default/network-WithLossCell/_backbone-AlexNet/conv3-Conv2d/Conv2D-op107)
       ...
       # In file {Absolute path of model_zoo}/official/cv/alexnet/src/alexnet.py(58)/        x = self.conv3(x)/
       ...
  %25(equivoutput) = BiasAdd(%24, %22) {instance name: bias_add} primitive_attrs: {output_used_num: (1), input_names: [x, b], format: NCHW, compile_info: , output_names: [output],
IsFeatureMapOutput: true, IsFeatureMapInputList: (0), pri_format: NC1HWC0}
       : (&lt;Tensor[Float16]x[const vector][32, 192, 13, 13]&gt;) -&gt; (&lt;Tensor[Float16]x[const vector][192]&gt;) -&gt; (&lt;Tensor[Float16]x[const vector][32, 192, 13, 13]&gt;)
       : (&lt;Float16xNC1HWC0[const vector][32, 12, 13, 13, 16]&gt;) -&gt; (&lt;Float16xDefaultFormat[const vector][192]&gt;) -&gt; (&lt;Float16xNC1HWC0[const vector][32, 12, 13, 13, 16]&gt;)
       : (Default/network-WithLossCell/_backbone-AlexNet/conv3-Conv2d/BiasAdd-op105)
       ...
       # In file {Absolute path of model_zoo}/official/cv/alexnet/src/alexnet.py(58)/        x = self.conv3(x)/
       ...
</pre></div>
</div>
<p>The meanings of the lines in the file content shown above are as follows:</p>
<ul>
<li><p>The input and output of the operator on the Host side (the first line) and the Device side (the second line, some operators may not exist). It can be seen from the execution graph that the operator has two inputs (left side of the arrow) and one output (right side of the arrow).</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>: (&lt;Tensor[Float32]x[const vector][32, 128, 13, 13]&gt;, &lt;Tensor[Float16]x[const vector][192, 128, 3, 3]&gt;) -&gt; (&lt;Tensor[Float16]x[const vector][32, 192, 13, 13]&gt;)
: (&lt;Float16xNC1HWC0[const vector][32, 8, 13, 13, 16]&gt;, &lt;Float16xFracZ[const vector][72, 12, 16, 16]&gt;) -&gt; (&lt;Float16xNC1HWC0[const vector][32, 12, 13, 13, 16]&gt;)
</pre></div>
</div>
</li>
<li><p>Operator name. It can be seen from the execution graph that the full name of the operator in the final execution graph is <code class="docutils literal notranslate"><span class="pre">Default/network-WithLossCell/_backbone-AlexNet/conv3-Conv2d/Conv2D-op107</span></code>.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>: (Default/network-WithLossCell/_backbone-AlexNet/conv3-Conv2d/Conv2D-op107)
</pre></div>
</div>
</li>
<li><p>The training script code corresponding to the operator. By searching the training script code to be queried, multiple matching operators can be found.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># In file {Absolute path of model_zoo}/official/cv/alexnet/src/alexnet.py(58)/        x = self.conv3(x)/
</pre></div>
</div>
</li>
</ul>
<p>Through the operator name and input and output information, you can find the only corresponding Tensor data file. For example, if you want to view the dump file corresponding to the first output data of the Conv2D-op107 operator, you can obtain the following information:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">operator_name</span></code>: <code class="docutils literal notranslate"><span class="pre">Default--network-WithLossCell--_backbone-AlexNet--conv3-Conv2d--Conv2D-op107</span></code>. Based on the operator name declared in sequence number 2 in the graph, replace <code class="docutils literal notranslate"><span class="pre">/</span></code> with <code class="docutils literal notranslate"><span class="pre">--</span></code> to get it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output_index</span></code>: <code class="docutils literal notranslate"><span class="pre">output_0</span></code> indicates that the file is the data of the first output Tensor of the operator.</p></li>
</ul>
<p>Search for the corresponding file name in the data object file directory saved by Dump:
<code class="docutils literal notranslate"><span class="pre">Default--network-WithLossCell--_backbone-AlexNet--conv3-Conv2d--Conv2D-op107_output_0_shape_32_12_13_13_16_Float16_NC1HWC0.bin</span></code>.</p>
<p>The following information can be obtained from the file name:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">shape</span></code>: The tensor dimension is <code class="docutils literal notranslate"><span class="pre">32_12_13_13_16</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data_type</span></code>: The data type is <code class="docutils literal notranslate"><span class="pre">Float16</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">format</span></code>: The data format is <code class="docutils literal notranslate"><span class="pre">NC1HWC0</span></code> (the data format to be saved can be modified through the Dump configuration file).</p></li>
</ul>
<p>When restoring data, first execute:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">fromfile</span><span class="p">(</span><span class="s2">&quot;Default--network-WithLossCell--_backbone-AlexNet--conv3-Conv2d--Conv2D-op107_output_0_shape_32_12_13_13_16_Float16_NC1HWC0.bin&quot;</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
</pre></div>
</div>
<p>One-dimensional array data is generated, and then execute:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">16</span><span class="p">))</span>
</pre></div>
</div>
<p>Restore to the original shape data.</p>
</section>
</section>
<section id="asynchronous-dump">
<h2>Asynchronous Dump<a class="headerlink" href="#asynchronous-dump" title="Permalink to this headline"></a></h2>
<p>Large networks (such as Bert Large) will cause memory overflow when using synchronous dumps. MindSpore provides debugging capabilities for large networks through asynchronous dumps.</p>
<section id="asynchronous-dump-step">
<h3>Asynchronous Dump Step<a class="headerlink" href="#asynchronous-dump-step" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>Create dump json file:<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>.</p>
<p>The name and location of the JSON file can be customized.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;common_dump_settings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;dump_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;/absolute_path&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;net_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ResNet50&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;iteration&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;input_output&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;kernels&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;Default/Conv-op12&quot;</span><span class="p">],</span>
<span class="w">        </span><span class="nt">&quot;support_device&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">]</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;async_dump_settings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enable&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;op_debug_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dump_mode</span></code>: 0: dump all kernels in graph, 1: dump kernels in kernels list.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>: The absolute path to save dump data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>: The net name eg:ResNet50.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration</span></code>: Specify the iterations to dump. Iteration should be set to 0 when dataset_sink_mode is False and data of every iteration will be dumped.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output</span></code>: When set to 0, it means to Dump the operator’s input and output; setting it to 1 means to Dump the operator’s input; setting it to 2 means to Dump the output of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernels</span></code>: List of operator names. Turn on the IR save switch <code class="docutils literal notranslate"><span class="pre">context.set_context(save_graphs=True)</span></code> and execute the network to obtain the operator name from the generated <code class="docutils literal notranslate"><span class="pre">trace_code_graph_{graph_id}</span></code>IR file. <code class="docutils literal notranslate"><span class="pre">kernels</span></code> only supports TBE operator, AiCPU operator and communication operator. The data of communication operation input operator will be dumped if <code class="docutils literal notranslate"><span class="pre">kernels</span></code> is set to the name of communication operator. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/doc/note/en/r1.2/design/mindspore/mindir.html#saving-ir">Saving IR</a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">support_device</span></code>: Supported devices, default setting is <code class="docutils literal notranslate"><span class="pre">[0,1,2,3,4,5,6,7]</span></code>. You can specify specific device ids to dump specific device data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">enable</span></code>: Enable Asynchronous Dump. If synchronous dump and asynchronous dump are enabled at the same time, only synchronous dump will take effect.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_debug_mode</span></code>: 0: disable overflow check function; 1: enable AiCore overflow check; 2: enable Atomic overflow check; 3: enable all overflow check function. If it is not set to 0, only the data of the overflow operator will be dumped.</p></li>
</ul>
</li>
<li><p>Specify the json configuration file of Dump.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_DUMP_CONFIG</span><span class="o">={</span>Absolute<span class="w"> </span>path<span class="w"> </span>of<span class="w"> </span>data_dump.json<span class="o">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Set the environment variables before executing the training script. Setting environment variables during training will not take effect.</p></li>
<li><p>Dump environment variables need to be configured before calling <code class="docutils literal notranslate"><span class="pre">mindspore.communication.management.init</span></code>.</p></li>
</ul>
</li>
<li><p>Execute the training script to dump data.</p>
<p>You can set <code class="docutils literal notranslate"><span class="pre">context.set_context(reserve_class_name_in_scope=False)</span></code> in your training script to avoid dump failure because of file name is too long.</p>
</li>
<li><p>Refer to <span class="xref myst">Asynchronous Dump Data Analysis Sample</span> to analyze the Dump data file.</p></li>
</ol>
<ul class="simple">
<li><p>If you need to dump all or part of the operator, you can modify the <code class="docutils literal notranslate"><span class="pre">dump_mode</span></code> option in the json configuration file to 0 or 1.</p></li>
<li><p>If the data sink function is enabled (set the <code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">model.train</span></code> or <code class="docutils literal notranslate"><span class="pre">DatasetHelper</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code>), only the data of one step specified in the configuration file can be dumped (in this case, <code class="docutils literal notranslate"><span class="pre">iteration</span> <span class="pre">0</span></code> means The 0th step), and save it to the specified directory.</p></li>
<li><p>If the data sink function is not enabled (set the <code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">model.train</span></code> or <code class="docutils literal notranslate"><span class="pre">DatasetHelper</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>), <code class="docutils literal notranslate"><span class="pre">iteration</span></code> in the configuration file must be specified as 0, and all step data are stored in a directory In, cannot support multi-step data management. At this time, it is recommended to execute the step data dump only once (you can train only one step by modifying the script).</p></li>
<li><p>Using the Dump function will automatically generate the IR file of the final execution graph.</p></li>
</ul>
</section>
<section id="asynchronous-dump-data-object-directory">
<h3>Asynchronous Dump Data Object Directory<a class="headerlink" href="#asynchronous-dump-data-object-directory" title="Permalink to this headline"></a></h3>
<p>The data objects saved by asynchronous Dump include the final execution graph (<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code> file) and the input and output data of the operators in the graph. The directory structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{path}/
    |-- {device_id}/
        |-- {new_name}_graph_{graph_id}/
            |-- {graph_id}/
                |-- {iteration}/
                    |-- {op_type}.{op_name}.{task_id}.{timestamp}
                    …
        |-- graphs/
            ms_output_trace_code_graph_{graph_id}.pb
            ms_output_trace_code_graph_{graph_id}.ir
        |-- execution_order/
            ms_execution_order_graph_{graph_id}.csv

    |-- .metadata/
        data_dump.json
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>: the absolute path set in the <code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code> configuration file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>: the network name set in the <code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code> configuration file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">device_id</span></code>: the id of the training device.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">graph_id</span></code>: the id of the training graph.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration</span></code>: the iteration of the training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_type</span></code>: the type of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_name</span></code>: the name of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">taskid</span></code>: the id of the task.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">timestamp</span></code>: the time stamp.</p></li>
</ul>
</section>
<section id="introduction-to-asynchronous-dump-data-file">
<h3>Introduction to Asynchronous Dump Data File<a class="headerlink" href="#introduction-to-asynchronous-dump-data-file" title="Permalink to this headline"></a></h3>
<p>After the training is started, the original data file generated by asynchronous Dump is in protobuf format. It needs to be parsed using the data analysis tool that comes with the HiSilicon Run package. For details, please refer to <a class="reference external" href="https://support.huaweicloud.com/intl/en-us/usermanual-mindstudioc73/atlasmindstudioaccuracy_16_0022.html">How to view dump data files</a>.</p>
<p>The data format on the Device side may be different from the definition in the calculation diagram on the Host side. The data format of the asynchronous dump is the Device side format. If you want to convert to the Host side format, you can refer to <a class="reference external" href="https://support.huaweicloud.com/intl/en-us/usermanual-mindstudioc73/atlasmindstudioaccuracy_16_0021.html">How to convert dump data file format</a>.</p>
<p>The naming rules for data files generated by asynchronous Dump are as follows:</p>
<ul class="simple">
<li><p>The naming rule of the dump path is: <code class="docutils literal notranslate"><span class="pre">{path}/{device_id}/{net_name}_graph_{graph_id}/{graph_id}/{iteration}</span></code>.</p></li>
<li><p>The naming rule of Dump file is: <code class="docutils literal notranslate"><span class="pre">{op_type}.{op_name}.{task_id}.{timestamp}</span></code>.</p></li>
</ul>
<p>Take the Dump result of a simple network as an example: <code class="docutils literal notranslate"><span class="pre">Add.Default_Add-op1.2.161243956333802</span></code>, where <code class="docutils literal notranslate"><span class="pre">Add</span></code> is <code class="docutils literal notranslate"><span class="pre">{op_type}</span></code>, <code class="docutils literal notranslate"><span class="pre">Default_Add-op1</span></code> is <code class="docutils literal notranslate"><span class="pre">{op_name}</span></code>, and <code class="docutils literal notranslate"><span class="pre">2</span></code> is <code class="docutils literal notranslate"><span class="pre">{task_id'</span> <span class="pre">}</span></code>, <code class="docutils literal notranslate"><span class="pre">161243956333802</span></code> is <code class="docutils literal notranslate"><span class="pre">{timestamp}</span></code>.</p>
<p>If “.”, “/”, “”, and spaces appear in <code class="docutils literal notranslate"><span class="pre">op_type</span></code> and <code class="docutils literal notranslate"><span class="pre">op_name</span></code>, they will be converted to underscores.</p>
<p>The final execution graph file and node execution sequence file naming rules generated by asynchronous Dump are the same as that of synchronous Dump. You can refer to <span class="xref myst">Introduction to Synchronous Dump Data File</span>.</p>
</section>
<section id="asynchronous-dump-data-analysis-sample">
<h3>Asynchronous Dump Data Analysis Sample<a class="headerlink" href="#asynchronous-dump-data-analysis-sample" title="Permalink to this headline"></a></h3>
<p>Through the asynchronous Dump function, the data files generated by the operator asynchronous Dump can be obtained.</p>
<ol class="arabic">
<li><p>Parse the dumped file using <code class="docutils literal notranslate"><span class="pre">msaccucmp.py</span></code> provied in the run package, the path where the <code class="docutils literal notranslate"><span class="pre">msaccucmp.py</span></code> file is located may be different on different environments You can find it through the find command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>find<span class="w"> </span><span class="si">${</span><span class="nv">run_path</span><span class="si">}</span><span class="w"> </span>-name<span class="w"> </span><span class="s2">&quot;msaccucmp.py&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">run_path</span></code>: The installation path of the run package.</p></li>
</ul>
</li>
<li><p>Change directory to <code class="docutils literal notranslate"><span class="pre">/absolute_path</span></code> after training, execute the following commands to parse Dump data file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span><span class="si">${</span><span class="nv">The</span><span class="p">  absolute path of msaccucmp.py</span><span class="si">}</span><span class="w"> </span>convert<span class="w"> </span>-d<span class="w"> </span><span class="o">{</span>file<span class="w"> </span>path<span class="w"> </span>of<span class="w"> </span>dump<span class="o">}</span><span class="w"> </span>-out<span class="w"> </span><span class="o">{</span>file<span class="w"> </span>path<span class="w"> </span>of<span class="w"> </span>output<span class="o">}</span>
</pre></div>
</div>
<p>Or you can use <code class="docutils literal notranslate"><span class="pre">msaccucmp.py</span></code> to convert the format of dump file. Please see <a class="reference external" href="https://support.huawei.com/enterprise/zh/doc/EDOC1100191946/fa6aecce">https://support.huawei.com/enterprise/zh/doc/EDOC1100191946/fa6aecce</a>.</p>
<p>For example, the data file generated by Dump is:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491
</pre></div>
</div>
<p>Then execute:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3.7.5<span class="w"> </span>msaccucmp.py<span class="w"> </span>convert<span class="w"> </span>-d<span class="w"> </span>BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491<span class="w"> </span>-out<span class="w"> </span>./output<span class="w"> </span>-f<span class="w"> </span>NCHW<span class="w"> </span>-t<span class="w"> </span>npy
</pre></div>
</div>
<p>Then all input and output data of the operator can be generated under <code class="docutils literal notranslate"><span class="pre">./output</span></code>. Each data is saved as a file with the suffix of <code class="docutils literal notranslate"><span class="pre">.npy</span></code>, and the data format is <code class="docutils literal notranslate"><span class="pre">NCHW</span></code>.</p>
<p>The generated results are as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.0.30x1024x17x17.npy
BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.1.1x1024x1x1.npy
BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.2.1x1024x1x1.npy
BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.3.1x1024x1x1.npy
BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.4.1x1024x1x1.npy
BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.5.1x1024x1x1.npy
BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.6.1x1024x1x1.npy
BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.output.0.30x1024x17x17.npy
BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.output.1.1x1024x1x1.npy
BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.output.2.1x1024x1x1.npy
BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.output.3.1x1024x1x1.npy
BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.output.4.1x1024x1x1.npy
</pre></div>
</div>
<p>At the end of the file name, you can see which input or output the file is the operator, and the dimensional information of the data. For example, by the first <code class="docutils literal notranslate"><span class="pre">.npy</span></code> file name</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.0.30x1024x17x17.npy
</pre></div>
</div>
<p>It can be seen that the file is the 0th input of the operator, and the dimension information of the data is <code class="docutils literal notranslate"><span class="pre">30x1024x17x17</span></code>.</p>
</li>
<li><p>The corresponding data can be read through <code class="docutils literal notranslate"><span class="pre">numpy.load(&quot;file_name&quot;)</span></code>. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.0.30x1024x17x17.npy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="debug_in_pynative_mode.html" class="btn btn-neutral float-left" title="Debugging in PyNative Mode" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="custom_debugging_info.html" class="btn btn-neutral float-right" title="Custom Debugging Information" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>