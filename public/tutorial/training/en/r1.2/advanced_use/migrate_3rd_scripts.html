

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Migrating Training Scripts from Third Party Frameworks &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/js/training.js"></script>
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Deep Probabilistic Programming" href="apply_deep_probability_programming.html" />
    <link rel="prev" title="Migrating From Third Party Frameworks With Tools" href="migrate_3rd_scripts_mindconverter.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/linear_regression.html">Implementing Simple Linear Function Fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">Defining the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/save_model.html">Saving Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/load_model_for_inference_and_transfer.html">Loading a Model for Inference and Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/publish_model.html">Publishing Models using MindSpore Hub</a></li>
</ul>
<p class="caption"><span class="caption-text">Process Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="convert_dataset.html">Converting Dataset to MindRecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimize_data_processing.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption"><span class="caption-text">Build Networks</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="custom_loss_function.html">Customizing and Using Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_operator.html">Custom Operator</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="migrate_script.html">Migrating Training Scripts from Third Party Frameworks</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="migrate_3rd_scripts_mindconverter.html">Migrating From Third Party Frameworks With Tools</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Migrating Training Scripts from Third Party Frameworks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#preparations">Preparations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#operator-assessment">Operator Assessment</a></li>
<li class="toctree-l4"><a class="reference internal" href="#software-and-hardware-environments">Software and Hardware Environments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#e2e-network-migration">E2E Network Migration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#training-phase">Training Phase</a></li>
<li class="toctree-l4"><a class="reference internal" href="#inference-phase">Inference Phase</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#examples">Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="apply_deep_probability_programming.html">Deep Probabilistic Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_high_order_differentiation.html">Implementing High-order Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantum_neural_network.html">Quantum Neural Network</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization_tutorials.html">Training Process Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_augmentation.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluate_the_model_during_training.html">Evaluating the Model during Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_tutorials.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying a Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_cache.html">Application of Single-Node Tensor Cache</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Compression</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_post_training_quantization.html">Applying Post Training Quantization</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_suppress_privacy.html">Protecting User Privacy with Suppress Privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">Using Membership Inference to Test Model Security</a></li>
</ul>
<p class="caption"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="migrate_script.html">Migrating Training Scripts from Third Party Frameworks</a> &raquo;</li>
        
      <li>Migrating Training Scripts from Third Party Frameworks</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/advanced_use/migrate_3rd_scripts.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="migrating-training-scripts-from-third-party-frameworks">
<h1>Migrating Training Scripts from Third Party Frameworks<a class="headerlink" href="#migrating-training-scripts-from-third-party-frameworks" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Whole</span> <span class="pre">Process</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<!-- TOC -->
<ul class="simple">
<li><p><a class="reference external" href="#migrating-training-scripts-from-third-party-frameworks">Migrating Training Scripts from Third Party Frameworks</a></p>
<ul>
<li><p><a class="reference external" href="#overview">Overview</a></p></li>
<li><p><a class="reference external" href="#preparations">Preparations</a></p>
<ul>
<li><p><a class="reference external" href="#operator-assessment">Operator Assessment</a></p></li>
<li><p><a class="reference external" href="#software-and-hardware-environments">Software and Hardware Environments</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#e2e-network-migration">E2E Network Migration</a></p>
<ul>
<li><p><a class="reference external" href="#training-phase">Training Phase</a></p>
<ul>
<li><p><a class="reference external" href="#script-migration">Script Migration</a></p></li>
<li><p><a class="reference external" href="#accuracy-debugging">Accuracy Debugging</a></p></li>
<li><p><a class="reference external" href="#on-cloud-integration">On-Cloud Integration</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#inference-phase">Inference Phase</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#examples">Examples</a></p></li>
</ul>
</li>
</ul>
<!-- /TOC -->
<p><a href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/training/source_en/advanced_use/migrate_3rd_scripts.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>You’ve probably written scripts for frameworks such as TensorFlow and PyTorch. This tutorial describes how to migrate existing TensorFlow and PyTorch networks to MindSpore, including key steps and operation recommendations which help you quickly migrate your network.</p>
</div>
<div class="section" id="preparations">
<h2>Preparations<a class="headerlink" href="#preparations" title="Permalink to this headline">¶</a></h2>
<p>Before you start working on your scripts, prepare your operator assessment and hardware and software environments to make sure that MindSpore can support the network you want to migrate.</p>
<div class="section" id="operator-assessment">
<h3>Operator Assessment<a class="headerlink" href="#operator-assessment" title="Permalink to this headline">¶</a></h3>
<p>Analyze the operators contained in the network to be migrated and figure out how does MindSpore support these operators based on the <a class="reference external" href="https://www.mindspore.cn/doc/note/en/r1.2/operator_list.html">Operator List</a>.</p>
<p>Take ResNet-50 as an example. The two major operators <a class="reference external" href="https://www.mindspore.cn/doc/api_python/en/r1.2/mindspore/nn/mindspore.nn.Conv2d.html">Conv</a> and <a class="reference external" href="https://www.mindspore.cn/doc/api_python/en/r1.2/mindspore/nn/mindspore.nn.BatchNorm2d.html">BatchNorm</a> exist in the MindSpore Operator List.</p>
<p>If any operator does not exist, you are advised to perform the following operations:</p>
<ul class="simple">
<li><p>Operator replacement: Analyze the operator implementation formula and check whether a combination of existing operators of MindSpore can be used to achieve the expected objective.</p></li>
<li><p>Substitution solution: For example, if a loss operator is not supported, check whether it can be replaced with a loss operator of the same type supported by MindSpore; alternatively, check whether the current network structure can be replaced by another mainstream network of the same type.</p></li>
</ul>
<p>If the operators used for replacement are not able to fulfill complete function, you are advised to perform the following operations:</p>
<ul class="simple">
<li><p>Delete unnecessary functions.</p></li>
<li><p>Find a substitution solution for necessary functions.</p></li>
</ul>
<p>If the preceding requirements cannot be met, you can raise requirements in the <a class="reference external" href="https://gitee.com/mindspore/mindspore">MindSpore code repository</a>.</p>
</div>
<div class="section" id="software-and-hardware-environments">
<h3>Software and Hardware Environments<a class="headerlink" href="#software-and-hardware-environments" title="Permalink to this headline">¶</a></h3>
<p>Prepare the hardware environment, find a platform corresponding to your environment by referring to the <a class="reference external" href="https://www.mindspore.cn/install/en">installation guide</a>, and install MindSpore.</p>
</div>
</div>
<div class="section" id="e2e-network-migration">
<h2>E2E Network Migration<a class="headerlink" href="#e2e-network-migration" title="Permalink to this headline">¶</a></h2>
<div class="section" id="training-phase">
<h3>Training Phase<a class="headerlink" href="#training-phase" title="Permalink to this headline">¶</a></h3>
<div class="section" id="script-migration">
<h4>Script Migration<a class="headerlink" href="#script-migration" title="Permalink to this headline">¶</a></h4>
<p>MindSpore differs from TensorFlow and PyTorch in the network structure. Before migration, you need to clearly understand the original script and information of each layer, such as shape.</p>
<blockquote>
<div><p>You can also use <a class="reference external" href="https://gitee.com/mindspore/mindinsight/tree/r1.2/mindinsight/mindconverter">MindConverter Tool</a> to automatically convert the PyTorch network definition script to MindSpore network definition script.</p>
</div></blockquote>
<p>The ResNet-50 network migration and training on the Ascend 910 is used as an example.</p>
<ol>
<li><p>Import MindSpore modules.</p>
<p>Import the corresponding MindSpore modules based on the required APIs. For details about the module list, see <a class="reference external" href="https://www.mindspore.cn/doc/api_python/en/r1.2/index.html">https://www.mindspore.cn/doc/api_python/en/r1.2/index.html</a>.</p>
</li>
<li><p>Load and preprocess a dataset.</p>
<p>Use MindSpore to build the required dataset. Currently, MindSpore supports common datasets. You can call APIs in the original format, <code class="docutils literal notranslate"><span class="pre">MindRecord</span></code>, and <code class="docutils literal notranslate"><span class="pre">TFRecord</span></code>. In addition, MindSpore supports data processing and data augmentation. For details, see the <a class="reference external" href="https://www.mindspore.cn/tutorial/training/en/r1.2/use/data_preparation.html">Data Preparation</a>.</p>
<p>In this example, the CIFAR-10 dataset is loaded, which supports both single-GPU and multi-GPU scenarios.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">device_num</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">de</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">de</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                           <span class="n">num_shards</span><span class="o">=</span><span class="n">device_num</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="n">rank_id</span><span class="p">)</span>
</pre></div>
</div>
<p>Then, perform data augmentation, data cleaning, and batch processing. For details about the code, see <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/model_zoo/official/cv/resnet/src/dataset.py">https://gitee.com/mindspore/mindspore/blob/r1.2/model_zoo/official/cv/resnet/src/dataset.py</a>.</p>
</li>
<li><p>Build a network.</p>
<p>The biggest difference between MindSpore and TensorFlow in convolution is the data format. <code class="docutils literal notranslate"><span class="pre">NCHW</span></code> is used in MindSpore by default, while <code class="docutils literal notranslate"><span class="pre">NHWC</span></code> is used in TensorFlow.</p>
<p>The following uses the first convolutional layer on the ResNet-50 network whose batch_size is set to 32 as an example:</p>
<ul>
<li><p>In TensorFlow, the format of the input feature is [32, 224, 224, 3], and the size of the convolution kernel is [7, 7, 3, 64].</p></li>
<li><p>In MindSpore, the format of the input feature is [32, 3, 224, 224], and the size of the convolution kernel is [64, 3, 7, 7].</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_conv7x7</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">weight_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">_weight_variable</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span>
                    <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">weight</span><span class="p">)</span>


 <span class="k">def</span> <span class="nf">_bn</span><span class="p">(</span><span class="n">channel</span><span class="p">):</span>
     <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                         <span class="n">gamma_init</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">beta_init</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">moving_mean_init</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">moving_var_init</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Build a subnet.</p>
<p>In MindSpore, <code class="docutils literal notranslate"><span class="pre">nn.Cell</span></code> is used to build a subnet structure. The network structure must be defined before being used in a subnet. Define each operator to be used in the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> function of the Cell, connect the defined operators in the <code class="docutils literal notranslate"><span class="pre">construct</span></code> function, and then return the output of the subnet through <code class="docutils literal notranslate"><span class="pre">return</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ResidualBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ResNet V1 residual block definition.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_channel (int): Input channel.</span>
<span class="sd">        out_channel (int): Output channel.</span>
<span class="sd">        stride (int): Stride size for the first convolutional layer. Default: 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, output tensor.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; ResidualBlock(3, 256, stride=2)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">expansion</span> <span class="o">=</span> <span class="mi">4</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">in_channel</span><span class="p">,</span>
                <span class="n">out_channel</span><span class="p">,</span>
                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ResidualBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">channel</span> <span class="o">=</span> <span class="n">out_channel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">_conv1x1</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">_bn</span><span class="p">(</span><span class="n">channel</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">_conv3x3</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="n">channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">_bn</span><span class="p">(</span><span class="n">channel</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">_conv1x1</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">_bn_last</span><span class="p">(</span><span class="n">out_channel</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">stride</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">in_channel</span> <span class="o">!=</span> <span class="n">out_channel</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span><span class="n">_conv1x1</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
                                                        <span class="n">_bn</span><span class="p">(</span><span class="n">out_channel</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Add</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">identity</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span><span class="p">:</span>
            <span class="n">identity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span><span class="p">(</span><span class="n">identity</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">identity</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</li>
<li><p>Define a concatenated structure.</p>
<p>The ResNet-50 network has a large number of repeated structures. In TensorFlow, you can use the for loop function to reduce repeated code. In MindSpore, each defined Cell object is independent. Especially for subnets with weight parameters, the defined Cell cannot be used repeatedly. If a large number of repeated concatenated structures exist, you can construct multiple Cell instances using the for loop function and concatenate them by using <code class="docutils literal notranslate"><span class="pre">SequentialCell</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_make_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="n">layer_num</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Make stage network of ResNet.</span>

<span class="sd">    Args:</span>
<span class="sd">        block (Cell): Resnet block.</span>
<span class="sd">        layer_num (int): Layer number.</span>
<span class="sd">        in_channel (int): Input channel.</span>
<span class="sd">        out_channel (int): Output channel.</span>
<span class="sd">        stride (int): Stride size for the first convolutional layer.</span>

<span class="sd">    Returns:</span>
<span class="sd">        SequentialCell, the output layer.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; _make_layer(ResidualBlock, 3, 128, 256, 2)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">resnet_block</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">resnet_block</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">layer_num</span><span class="p">):</span>
        <span class="n">resnet_block</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">resnet_block</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Build the entire network.</p>
<p>The <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/model_zoo/official/cv/resnet/src/resnet.py">ResNet-50</a> network structure is formed by connecting multiple defined subnets. Follow the rule of defining subnets before using them and define all the subnets used in the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> and connect subnets in the <code class="docutils literal notranslate"><span class="pre">construct</span></code>.</p>
</li>
<li><p>Define a loss function and an optimizer.</p>
<p>After the network is defined, the loss function and optimizer need to be defined accordingly.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()),</span> <span class="n">lr</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Build a model.</p>
<p>Similar to the <code class="docutils literal notranslate"><span class="pre">Estimator</span></code> API of TensorFlow, the defined network prototype, loss function, and optimizer are transferred to the <code class="docutils literal notranslate"><span class="pre">Model</span></code> API of MindSpore and automatically combined into a network that can be used for training.</p>
<p>To use loss scale in training, define a <code class="docutils literal notranslate"><span class="pre">loss_scale_manager</span></code> and transfer it to the <code class="docutils literal notranslate"><span class="pre">Model</span></code> API.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">loss_scale</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">drop_overflow_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>You can use a built-in assessment method of <code class="docutils literal notranslate"><span class="pre">Model</span></code> by setting the <a class="reference external" href="https://www.mindspore.cn/tutorial/training/en/r1.2/advanced_use/custom_debugging_info.html#mindspore-metrics">metrics</a> attribute.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">})</span>
</pre></div>
</div>
<p>Similar to <code class="docutils literal notranslate"><span class="pre">estimator.train</span></code> of TensorFlow, you can call the <code class="docutils literal notranslate"><span class="pre">model.train</span></code> API to perform training. Functions such as CheckPoint and intermediate result printing can be defined on the <code class="docutils literal notranslate"><span class="pre">model.train</span></code> API in Callback mode.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">time_cb</span> <span class="o">=</span> <span class="n">TimeMonitor</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="n">step_size</span><span class="p">)</span>
<span class="n">loss_cb</span> <span class="o">=</span> <span class="n">LossMonitor</span><span class="p">()</span>
<span class="n">cb</span> <span class="o">=</span> <span class="p">[</span><span class="n">time_cb</span><span class="p">,</span> <span class="n">loss_cb</span><span class="p">]</span>
<span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">:</span>
    <span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">save_checkpoint_steps</span><span class="p">,</span>
                                    <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">keep_checkpoint_max</span><span class="p">)</span>
    <span class="n">ckpt_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;resnet&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">save_checkpoint_path</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
    <span class="n">cb</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ckpt_cb</span><span class="p">]</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch_size</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">cb</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="accuracy-debugging">
<h4>Accuracy Debugging<a class="headerlink" href="#accuracy-debugging" title="Permalink to this headline">¶</a></h4>
<p>The accuracy optimization process is as follows:</p>
<ol class="simple">
<li><p>When validating the single-GPU accuracy, you are advised to use a small dataset for training. After the validation is successful, use the full dataset for multi-GPU accuracy validation. This helps improve the debugging efficiency.</p></li>
<li><p>Delete unnecessary skills (such as augmentation configuration and dynamic loss scale in an optimizer) from the script. After the validation is successful, add functions one by one. After a new function is confirmed to be normal, add the next function. In this way, you can quickly locate the fault.</p></li>
</ol>
</div>
<div class="section" id="on-cloud-integration">
<h4>On-Cloud Integration<a class="headerlink" href="#on-cloud-integration" title="Permalink to this headline">¶</a></h4>
<p>Run your scripts on ModelArts. For details, see <a class="reference external" href="https://www.mindspore.cn/tutorial/training/zh-CN/r1.2/advanced_use/use_on_the_cloud.html">Using MindSpore on Cloud</a>.</p>
</div>
</div>
<div class="section" id="inference-phase">
<h3>Inference Phase<a class="headerlink" href="#inference-phase" title="Permalink to this headline">¶</a></h3>
<p>Models trained on the Ascend 910 AI processor can be used for inference on different hardware platforms. Refer to the <a class="reference external" href="https://www.mindspore.cn/tutorial/inference/en/r1.2/multi_platform_inference.html">Multi-platform Inference Tutorial</a> for detailed steps.</p>
</div>
</div>
<div class="section" id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.2/model_zoo">Model Zoo</a></p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="apply_deep_probability_programming.html" class="btn btn-neutral float-right" title="Deep Probabilistic Programming" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="migrate_3rd_scripts_mindconverter.html" class="btn btn-neutral float-left" title="Migrating From Third Party Frameworks With Tools" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>