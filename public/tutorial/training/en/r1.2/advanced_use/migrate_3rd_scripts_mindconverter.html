<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Migrating From Third Party Frameworks With Tools &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/training.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Migrating Training Scripts from Third Party Frameworks" href="migrate_3rd_scripts.html" />
    <link rel="prev" title="Migrating Training Scripts from Third Party Frameworks" href="migrate_script.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/linear_regression.html">Implementing Simple Linear Function Fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">Defining the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/save_model.html">Saving Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/load_model_for_inference_and_transfer.html">Loading a Model for Inference and Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/publish_model.html">Publishing Models using MindSpore Hub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Process Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="convert_dataset.html">Converting Dataset to MindRecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimize_data_processing.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build Networks</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="custom_loss_function.html">Customizing and Using Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_operator.html">Custom Operator</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="migrate_script.html">Migrating Training Scripts from Third Party Frameworks</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Migrating From Third Party Frameworks With Tools</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#installation">Installation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#usage">Usage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pytorch-model-scripts-migration">PyTorch Model Scripts Migration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tensorflow-model-scripts-migration">TensorFlow Model Scripts Migration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#onnx-model-file-migration">ONNX Model File Migration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#scenario">Scenario</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example">Example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#ast-based-conversion">AST-Based Conversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="#graph-based-conversion">Graph-Based Conversion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#mindconverter-error-code-definition">MindConverter Error Code Definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-list-supported-by-mindconverter">Model List Supported by MindConverter</a></li>
<li class="toctree-l3"><a class="reference internal" href="#caution">Caution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="migrate_3rd_scripts.html">Migrating Training Scripts from Third Party Frameworks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="apply_deep_probability_programming.html">Deep Probabilistic Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_high_order_differentiation.html">Implementing High-order Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantum_neural_network.html">Quantum Neural Network</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization_tutorials.html">Training Process Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_augmentation.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluate_the_model_during_training.html">Evaluating the Model during Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_tutorials.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying a Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_cache.html">Application of Single-Node Tensor Cache</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Compression</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_post_training_quantization.html">Applying Post Training Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_suppress_privacy.html">Protecting User Privacy with Suppress Privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">Using Membership Inference to Test Model Security</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="migrate_script.html">Migrating Training Scripts from Third Party Frameworks</a> &raquo;</li>
      <li>Migrating From Third Party Frameworks With Tools</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/advanced_use/migrate_3rd_scripts_mindconverter.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="migrating-from-third-party-frameworks-with-tools">
<h1>Migrating From Third Party Frameworks With Tools<a class="headerlink" href="#migrating-from-third-party-frameworks-with-tools" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Development</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/training/source_en/advanced_use/migrate_3rd_scripts_mindconverter.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>MindConverter is a migration tool to transform the model scripts and weights from PyTorch(ONNX) and TensorFlow(PB) to MindSpore. Users can migrate rapidly with minor changes according to the conversion report.</p>
</section>
<section id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline"></a></h2>
<p>Mindconverter is a submodule in MindInsight. Please follow the <a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.2/README.md#">Guide</a> here to install MindInsight.</p>
</section>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this headline"></a></h2>
<p>MindConverter currently only provides command-line interface. Here is the manual page.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>usage:<span class="w"> </span>mindconverter<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span><span class="o">[</span>--version<span class="o">]</span><span class="w"> </span><span class="o">[</span>--in_file<span class="w"> </span>IN_FILE<span class="o">]</span>
<span class="w">                     </span><span class="o">[</span>--model_file<span class="w"> </span>MODEL_FILE<span class="o">]</span><span class="w"> </span><span class="o">[</span>--shape<span class="w"> </span>SHAPE<span class="w"> </span><span class="o">[</span>SHAPE<span class="w"> </span>...<span class="o">]]</span>
<span class="w">                     </span><span class="o">[</span>--input_nodes<span class="w"> </span>INPUT_NODES<span class="w"> </span><span class="o">[</span>INPUT_NODES<span class="w"> </span>...<span class="o">]]</span>
<span class="w">                     </span><span class="o">[</span>--output_nodes<span class="w"> </span>OUTPUT_NODES<span class="w"> </span><span class="o">[</span>OUTPUT_NODES<span class="w"> </span>...<span class="o">]]</span>
<span class="w">                     </span><span class="o">[</span>--output<span class="w"> </span>OUTPUT<span class="o">]</span><span class="w"> </span><span class="o">[</span>--report<span class="w"> </span>REPORT<span class="o">]</span>

optional<span class="w"> </span>arguments:
<span class="w">  </span>-h,<span class="w"> </span>--help<span class="w">            </span>show<span class="w"> </span>this<span class="w"> </span><span class="nb">help</span><span class="w"> </span>message<span class="w"> </span>and<span class="w"> </span><span class="nb">exit</span>
<span class="w">  </span>--version<span class="w">             </span>show<span class="w"> </span>program<span class="w"> </span>version<span class="w"> </span>number<span class="w"> </span>and<span class="w"> </span><span class="nb">exit</span>
<span class="w">  </span>--in_file<span class="w"> </span>IN_FILE<span class="w">     </span>Specify<span class="w"> </span>path<span class="w"> </span><span class="k">for</span><span class="w"> </span>script<span class="w"> </span>file<span class="w"> </span>to<span class="w"> </span>use<span class="w"> </span>AST<span class="w"> </span>schema<span class="w"> </span>to<span class="w"> </span><span class="k">do</span>
<span class="w">                        </span>script<span class="w"> </span>conversation.
<span class="w">  </span>--model_file<span class="w"> </span>MODEL_FILE
<span class="w">                        </span>Tensorflow<span class="o">(</span>.pb<span class="o">)</span><span class="w"> </span>or<span class="w"> </span>ONNX<span class="o">(</span>.onnx<span class="o">)</span><span class="w"> </span>model<span class="w"> </span>file<span class="w"> </span>path<span class="w"> </span>is
<span class="w">                        </span>expected<span class="w"> </span>to<span class="w"> </span><span class="k">do</span><span class="w"> </span>script<span class="w"> </span>generation<span class="w"> </span>based<span class="w"> </span>on<span class="w"> </span>graph
<span class="w">                        </span>schema.<span class="w"> </span>When<span class="w"> </span><span class="sb">`</span>--in_file<span class="sb">`</span><span class="w"> </span>and<span class="w"> </span><span class="sb">`</span>--model_file<span class="sb">`</span><span class="w"> </span>are<span class="w"> </span>both
<span class="w">                        </span>provided,<span class="w"> </span>use<span class="w"> </span>AST<span class="w"> </span>schema<span class="w"> </span>as<span class="w"> </span>default.
<span class="w">  </span>--shape<span class="w"> </span>SHAPE<span class="w"> </span><span class="o">[</span>SHAPE<span class="w"> </span>...<span class="o">]</span>
<span class="w">                        </span>Optional,<span class="w"> </span>expected<span class="w"> </span>input<span class="w"> </span>tensor<span class="w"> </span>shape<span class="w"> </span>of
<span class="w">                        </span><span class="sb">`</span>--model_file<span class="sb">`</span>.<span class="w"> </span>It<span class="w"> </span>is<span class="w"> </span>required<span class="w"> </span>when<span class="w"> </span>use<span class="w"> </span>graph<span class="w"> </span>based
<span class="w">                        </span>schema.<span class="w"> </span>Both<span class="w"> </span>order<span class="w"> </span>and<span class="w"> </span>number<span class="w"> </span>should<span class="w"> </span>be<span class="w"> </span>consistent
<span class="w">                        </span>with<span class="w"> </span><span class="sb">`</span>--input_nodes<span class="sb">`</span>.<span class="w"> </span>Usage:<span class="w"> </span>--shape<span class="w"> </span><span class="m">1</span>,512<span class="w"> </span><span class="m">1</span>,512
<span class="w">  </span>--input_nodes<span class="w"> </span>INPUT_NODES<span class="w"> </span><span class="o">[</span>INPUT_NODES<span class="w"> </span>...<span class="o">]</span>
<span class="w">                        </span>Optional,<span class="w"> </span>input<span class="w"> </span>node<span class="o">(</span>s<span class="o">)</span><span class="w"> </span>name<span class="w"> </span>of<span class="w"> </span><span class="sb">`</span>--model_file<span class="sb">`</span>.<span class="w"> </span>It<span class="w"> </span>is
<span class="w">                        </span>required<span class="w"> </span>when<span class="w"> </span>use<span class="w"> </span>graph<span class="w"> </span>based<span class="w"> </span>schema.<span class="w"> </span>Both<span class="w"> </span>order<span class="w"> </span>and
<span class="w">                        </span>number<span class="w"> </span>should<span class="w"> </span>be<span class="w"> </span>consistent<span class="w"> </span>with<span class="w"> </span><span class="sb">`</span>--shape<span class="sb">`</span>.<span class="w"> </span>Usage:
<span class="w">                        </span>--input_nodes<span class="w"> </span>input_1:0<span class="w"> </span>input_2:0
<span class="w">  </span>--output_nodes<span class="w"> </span>OUTPUT_NODES<span class="w"> </span><span class="o">[</span>OUTPUT_NODES<span class="w"> </span>...<span class="o">]</span>
<span class="w">                        </span>Optional,<span class="w"> </span>output<span class="w"> </span>node<span class="o">(</span>s<span class="o">)</span><span class="w"> </span>name<span class="w"> </span>of<span class="w"> </span><span class="sb">`</span>--model_file<span class="sb">`</span>.<span class="w"> </span>It<span class="w"> </span>is
<span class="w">                        </span>required<span class="w"> </span>when<span class="w"> </span>use<span class="w"> </span>graph<span class="w"> </span>based<span class="w"> </span>schema.<span class="w"> </span>Usage:
<span class="w">                        </span>--output_nodes<span class="w"> </span>output_1:0<span class="w"> </span>output_2:0
<span class="w">  </span>--output<span class="w"> </span>OUTPUT<span class="w">       </span>Optional,<span class="w"> </span>specify<span class="w"> </span>path<span class="w"> </span><span class="k">for</span><span class="w"> </span>converted<span class="w"> </span>script<span class="w"> </span>file
<span class="w">                        </span>directory.<span class="w"> </span>Default<span class="w"> </span>output<span class="w"> </span>directory<span class="w"> </span>is<span class="w"> </span><span class="sb">`</span>output<span class="sb">`</span><span class="w"> </span>folder
<span class="w">                        </span><span class="k">in</span><span class="w"> </span>the<span class="w"> </span>current<span class="w"> </span>working<span class="w"> </span>directory.
<span class="w">  </span>--report<span class="w"> </span>REPORT<span class="w">       </span>Optional,<span class="w"> </span>specify<span class="w"> </span>report<span class="w"> </span>directory.<span class="w"> </span>Default<span class="w"> </span>is
<span class="w">                        </span>converted<span class="w"> </span>script<span class="w"> </span>directory.
</pre></div>
</div>
<section id="pytorch-model-scripts-migration">
<h3>PyTorch Model Scripts Migration<a class="headerlink" href="#pytorch-model-scripts-migration" title="Permalink to this headline"></a></h3>
<p><strong>MindConverter only provides Abstract Syntax Tree (AST) based conversion for PyTorch</strong>: Use the argument <code class="docutils literal notranslate"><span class="pre">--in_file</span></code> will enable the AST mode.</p>
<blockquote>
<div><p>The AST mode will be enabled, if both <code class="docutils literal notranslate"><span class="pre">--in_file</span></code> and <code class="docutils literal notranslate"><span class="pre">--model_file</span></code> are specified.</p>
</div></blockquote>
<p><code class="docutils literal notranslate"><span class="pre">--output</span></code> and <code class="docutils literal notranslate"><span class="pre">--report</span></code> is optional. MindConverter creates an <code class="docutils literal notranslate"><span class="pre">output</span></code> folder under the current working directory, and outputs generated scripts and conversion reports to it.</p>
<blockquote>
<div><p>If the user want to migrate PyTorch model script using graph based MindConverter, it is recommended to export PyTorch model to ONNX, and then use ONNX file to migrate model script. For details, see <a class="reference external" href="https://pytorch.org/docs/stable/onnx.html">PyTorch instructions</a>.</p>
</div></blockquote>
</section>
<section id="tensorflow-model-scripts-migration">
<h3>TensorFlow Model Scripts Migration<a class="headerlink" href="#tensorflow-model-scripts-migration" title="Permalink to this headline"></a></h3>
<p><strong>MindConverter provides computational graph based conversion for TensorFlow</strong>: Transformation will be done given <code class="docutils literal notranslate"><span class="pre">--model_file</span></code>, <code class="docutils literal notranslate"><span class="pre">--shape</span></code>, <code class="docutils literal notranslate"><span class="pre">--input_nodes</span></code> and <code class="docutils literal notranslate"><span class="pre">--output_nodes</span></code>.</p>
<blockquote>
<div><p>AST mode is not supported for TensorFlow, only computational graph based mode is available.</p>
</div></blockquote>
<p><code class="docutils literal notranslate"><span class="pre">--output</span></code> and <code class="docutils literal notranslate"><span class="pre">--report</span></code> is optional. MindConverter creates an <code class="docutils literal notranslate"><span class="pre">output</span></code> folder under the current working directory, and outputs generated scripts to it.</p>
</section>
<section id="onnx-model-file-migration">
<h3>ONNX Model File Migration<a class="headerlink" href="#onnx-model-file-migration" title="Permalink to this headline"></a></h3>
<p><strong>MindConverter provides computational graph based conversion for ONNX</strong>: Transformation will be done given <code class="docutils literal notranslate"><span class="pre">--model_file</span></code>, <code class="docutils literal notranslate"><span class="pre">--shape</span></code>, <code class="docutils literal notranslate"><span class="pre">--input_nodes</span></code> and <code class="docutils literal notranslate"><span class="pre">--output_nodes</span></code>.</p>
<blockquote>
<div><p>AST mode is not supported for ONNX, only computational graph based mode is available.</p>
</div></blockquote>
<p><code class="docutils literal notranslate"><span class="pre">--output</span></code> and <code class="docutils literal notranslate"><span class="pre">--report</span></code> is optional. MindConverter creates an <code class="docutils literal notranslate"><span class="pre">output</span></code> folder under the current working directory, and outputs generated scripts to it.</p>
</section>
</section>
<section id="scenario">
<h2>Scenario<a class="headerlink" href="#scenario" title="Permalink to this headline"></a></h2>
<p>MindConverter provides two modes for different migration demands.</p>
<ol class="arabic simple">
<li><p>Keep original scripts’ structures, including variables, functions, and libraries.</p></li>
<li><p>Keep extra modifications as few as possible, or no modifications are required after conversion.</p></li>
</ol>
<p>The AST mode is recommended for the first demand (AST mode is only supported for PyTorch). It parses and analyzes PyTorch scripts, then replace them with the MindSpore AST to generate codes. Theoretically, The AST mode supports any model script. However, the conversion may differ due to the coding style of original scripts.</p>
<p>For the second demand, the Graph mode is recommended. As the computational graph is a standard descriptive language, it is not affected by user’s coding style. This mode may have more operators converted as long as these operators are supported by MindConverter.</p>
<p>Some typical networks in computer vision field have been tested for the Graph mode. Note that:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>The Dropout operator will be lost after conversion because the inference mode is used to load the ONNX or TensorFlow model. Manually re-implement is necessary.</p></li>
<li><p>The Graph-based mode will be continuously developed and optimized with further updates.</p></li>
</ol>
</div></blockquote>
</section>
<section id="example">
<h2>Example<a class="headerlink" href="#example" title="Permalink to this headline"></a></h2>
<section id="ast-based-conversion">
<h3>AST-Based Conversion<a class="headerlink" href="#ast-based-conversion" title="Permalink to this headline"></a></h3>
<p>Assume the PyTorch script is located at <code class="docutils literal notranslate"><span class="pre">/home/user/model.py</span></code>, and outputs the transformed MindSpore script to <code class="docutils literal notranslate"><span class="pre">/home/user/output</span></code>, with the conversion report to <code class="docutils literal notranslate"><span class="pre">/home/user/output/report</span></code>. Use the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mindconverter<span class="w"> </span>--in_file<span class="w"> </span>/home/user/model.py<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--output<span class="w"> </span>/home/user/output<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--report<span class="w"> </span>/home/user/output/report
</pre></div>
</div>
<p>In the conversion report, non-transformed code is listed as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>line &lt;row&gt;:&lt;col&gt; [UnConvert] &#39;operator&#39; didn&#39;t convert. ...
</pre></div>
</div>
<p>For non-transformed operators, the original code keeps. Please manually migrate them. <a class="reference external" href="https://www.mindspore.cn/doc/note/en/r1.2/index.html#operator_api">Click here</a> for more information about operator mapping.</p>
<p>Here is an example of the conversion report:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span> [Start Convert]
 [Insert] &#39;import mindspore.ops as ops&#39; is inserted to the converted file.
 line 1:0: [Convert] &#39;import torch&#39; is converted to &#39;import mindspore&#39;.
 ...
 line 157:23: [UnConvert] &#39;nn.AdaptiveAvgPool2d&#39; didn&#39;t convert. Maybe could convert to mindspore.ops.operations.ReduceMean.
 ...
 [Convert Over]
</pre></div>
</div>
<p>For non-transformed operators, suggestions are provided in the report. For instance, MindConverter suggests that replace <code class="docutils literal notranslate"><span class="pre">torch.nn.AdaptiveAvgPool2d</span></code> with <code class="docutils literal notranslate"><span class="pre">mindspore.ops.operations.ReduceMean</span></code>.</p>
</section>
<section id="graph-based-conversion">
<h3>Graph-Based Conversion<a class="headerlink" href="#graph-based-conversion" title="Permalink to this headline"></a></h3>
<section id="tensorflow-model-scripts-conversion">
<h4>TensorFlow Model Scripts Conversion<a class="headerlink" href="#tensorflow-model-scripts-conversion" title="Permalink to this headline"></a></h4>
<p>To use TensorFlow model script migration, you need to export TensorFlow model to Pb format(frozen graph) first, and obtain the model input node and output node name. See <a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.2/mindinsight/mindconverter/docs/tensorflow_model_exporting.md#">Tutorial of exporting TensorFlow Pb model</a> for details.</p>
<p>Suppose the model is saved to <code class="docutils literal notranslate"><span class="pre">/home/user/xxx/frozen_model.pb</span></code>, corresponding input node name is <code class="docutils literal notranslate"><span class="pre">input_1:0</span></code>, output node name is <code class="docutils literal notranslate"><span class="pre">predictions/Softmax:0</span></code>, the input shape of model is <code class="docutils literal notranslate"><span class="pre">1,224,224,3</span></code>. Output the transformed MindSpore script to <code class="docutils literal notranslate"><span class="pre">/home/user/output</span></code>, with the conversion report to <code class="docutils literal notranslate"><span class="pre">/home/user/output/report</span></code>. Use the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mindconverter<span class="w"> </span>--model_file<span class="w"> </span>/home/user/xxx/frozen_model.pb<span class="w"> </span>--shape<span class="w"> </span><span class="m">1</span>,224,224,3<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--input_nodes<span class="w"> </span>input_1:0<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--output_nodes<span class="w"> </span>predictions/Softmax:0<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--output<span class="w"> </span>/home/user/output<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--report<span class="w"> </span>/home/user/output/report
</pre></div>
</div>
<p>After executing the command, MindSpore script, MindSpore weight file, weight map file, and report file can be found in corresponding directory.</p>
<p>The format of conversion report generated by script generation scheme based on graph structure is the same as that of AST scheme. However, since the graph based scheme is a generative method, the original tensorflow script is not referenced in the conversion process. Therefore, the code line and column numbers involved in the generated conversion report refer to the generated script.</p>
<p>In addition, input and output Tensor shape of unconverted operators shows explicitly (<code class="docutils literal notranslate"><span class="pre">input_shape</span></code> and <code class="docutils literal notranslate"><span class="pre">output_shape</span></code>) as comments in converted scripts to help further manual modifications. Here is an example of the <code class="docutils literal notranslate"><span class="pre">Reshape</span></code> operator (already supported after R1.0 version):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                                    <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="c1"># Suppose input of `reshape` is x.</span>
        <span class="n">reshape_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="o">...</span>

</pre></div>
</div>
<p>It is convenient to replace the operators according to the <code class="docutils literal notranslate"><span class="pre">input_shape</span></code> and <code class="docutils literal notranslate"><span class="pre">output_shape</span></code> parameters. The replacement is like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="o">...</span>

<span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                                 <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="c1"># Suppose input of `reshape` is x.</span>
        <span class="n">reshape_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>
        <span class="o">...</span>

</pre></div>
</div>
<p>Weight information in MindSpore (<code class="docutils literal notranslate"><span class="pre">converted_weight</span></code>) and that in source framework(<code class="docutils literal notranslate"><span class="pre">source_weight</span></code>) are saved in weight map separately.</p>
<p>Here is an example of the weight map:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;resnet50&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;converted_weight&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;conv2d_0.weight&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;shape&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                    </span><span class="mi">64</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">3</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">7</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">7</span>
<span class="w">                </span><span class="p">],</span>
<span class="w">                </span><span class="nt">&quot;data_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Float32&quot;</span>
<span class="w">            </span><span class="p">},</span>
<span class="w">            </span><span class="nt">&quot;source_weight&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;conv1.weight&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;shape&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                    </span><span class="mi">64</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">3</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">7</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">7</span>
<span class="w">                </span><span class="p">],</span>
<span class="w">                </span><span class="nt">&quot;data_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;float32&quot;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="onnx-model-file-conversion">
<h4>ONNX Model File Conversion<a class="headerlink" href="#onnx-model-file-conversion" title="Permalink to this headline"></a></h4>
<p>To use ONNX model File migration, you need to obtain the model input node and output node names. To get input node and output node names, <a class="reference external" href="https://github.com/lutzroeder/netron">Netron</a> is recommended.</p>
<p>Suppose the model is saved to <code class="docutils literal notranslate"><span class="pre">/home/user/xxx/model.onnx</span></code>, the corresponding input node name is <code class="docutils literal notranslate"><span class="pre">input_1:0</span></code>, the output node name is <code class="docutils literal notranslate"><span class="pre">predictions/Softmax:0</span></code>, the input shape of model is <code class="docutils literal notranslate"><span class="pre">1,3,224,224</span></code>, the following command can be used to generate the script:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mindconverter<span class="w"> </span>--model_file<span class="w"> </span>/home/user/xxx/model.onnx<span class="w"> </span>--shape<span class="w"> </span><span class="m">1</span>,3,224,224<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--input_nodes<span class="w"> </span>input_1:0<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--output_nodes<span class="w"> </span>predictions/Softmax:0<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--output<span class="w"> </span>/home/user/output<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--report<span class="w"> </span>/home/user/output/report
</pre></div>
</div>
<p>After executed, MindSpore script, MindSpore weight file, weight map file, and report file can be found in corresponding directory.</p>
<p>The format of conversion report generated by script generation scheme based on graph structure is the same as that of AST scheme. However, since the graph based scheme is a generative method, the original onnx file is not referenced in the conversion process. Therefore, the code line and column numbers involved in the generated conversion report refer to the generated script.</p>
<p>The example of weight map refers to that in <strong>TensorFlow Model Scripts Conversion</strong> section.</p>
</section>
</section>
</section>
<section id="mindconverter-error-code-definition">
<h2>MindConverter Error Code Definition<a class="headerlink" href="#mindconverter-error-code-definition" title="Permalink to this headline"></a></h2>
<p>Error code defined in MindConverter, please refer to <a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.2/mindinsight/mindconverter/docs/error_code_definition.md#">LINK</a>.</p>
</section>
<section id="model-list-supported-by-mindconverter">
<h2>Model List Supported by MindConverter<a class="headerlink" href="#model-list-supported-by-mindconverter" title="Permalink to this headline"></a></h2>
<p><a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.2/mindinsight/mindconverter/docs/supported_model_list.md#">List of supported models (Models in below table have been tested based on PyTorch 1.5.0 and TensorFlow 1.15.0, X86 Ubuntu released version)</a>.</p>
</section>
<section id="caution">
<h2>Caution<a class="headerlink" href="#caution" title="Permalink to this headline"></a></h2>
<ol class="arabic simple">
<li><p>TensorFlow is not a dependency library explicitly declared by MindInsight. If the user want to use graph based MindConverter, please install TensorFlow(MindConverter recommends TensorFlow 1.15.x).</p></li>
<li><p>ONNX(&gt;=1.8.0), ONNXRUNTIME(&gt;=1.5.2), ONNXOPTIMIZER(&gt;=0.1.2) are not explicitly stated dependency libraries in MindInsight, if the user want to use graph based MindConverter, above three-party libraries must be installed. If the user want to migrate TensorFlow model to MindSpore, TF2ONNX(&gt;=1.7.1) must be installed additionally.</p></li>
<li><p>This script conversion tool relies on operators which supported by MindConverter and MindSpore. Unsupported operators may not be successfully mapped to MindSpore operators. You can manually edit, or implement the mapping based on MindConverter, and contribute to our MindInsight repository. We appreciate your support for the MindSpore community.</p></li>
<li><p>MindConverter converts dynamic input shape to constant one based on <code class="docutils literal notranslate"><span class="pre">--shape</span></code> while using grpah based scheme, as a result, it is required that inputs’ shape used to retrain or inference in MindSpore are the same as that used to convert using MindConverter. If the input shape has changed, please re-running MindConverter with new <code class="docutils literal notranslate"><span class="pre">--shape</span></code> or fixing shape related parameters in the old script.</p></li>
<li><p>MindSpore script, MindSpore checkpoint file and weight map file are saved in the same file folder path.</p></li>
<li><p>The security and consistency of the model file should be guaranteed by the user.</p></li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="migrate_script.html" class="btn btn-neutral float-left" title="Migrating Training Scripts from Third Party Frameworks" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="migrate_3rd_scripts.html" class="btn btn-neutral float-right" title="Migrating Training Scripts from Third Party Frameworks" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>