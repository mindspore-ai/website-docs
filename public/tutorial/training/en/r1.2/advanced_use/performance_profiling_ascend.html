<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Performance Profiling (Ascend) &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script src="../_static/js/training.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Performance Profiling (GPU)" href="performance_profiling_gpu.html" />
    <link rel="prev" title="Performance Profiling" href="performance_profiling.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/linear_regression.html">Implementing Simple Linear Function Fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Use</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">Defining the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/save_model.html">Saving Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/load_model_for_inference_and_transfer.html">Loading a Model for Inference and Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/publish_model.html">Publishing Models using MindSpore Hub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Process Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="convert_dataset.html">Converting Dataset to MindRecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimize_data_processing.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build Networks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="custom_loss_function.html">Customizing and Using Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_operator.html">Custom Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrate_script.html">Migrating Training Scripts from Third Party Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_deep_probability_programming.html">Deep Probabilistic Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_high_order_differentiation.html">Implementing High-order Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantum_neural_network.html">Quantum Neural Network</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="visualization_tutorials.html">Training Process Visualization</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="summary_record.html">Collecting Summary Record</a></li>
<li class="toctree-l2"><a class="reference internal" href="dashboard.html">Viewing Dashboard</a></li>
<li class="toctree-l2"><a class="reference internal" href="lineage_and_scalars_comparison.html">Viewing Lineage and Scalars Comparison</a></li>
<li class="toctree-l2"><a class="reference internal" href="hyper_parameters_auto_tuning.html">Use Mindoptimizer to Tune Hyperparameters</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="performance_profiling.html">Performance Profiling</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Performance Profiling (Ascend)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="#operation-process">Operation Process</a></li>
<li class="toctree-l4"><a class="reference internal" href="#preparing-the-training-script">Preparing the Training Script</a></li>
<li class="toctree-l4"><a class="reference internal" href="#launch-mindinsight">Launch MindInsight</a></li>
<li class="toctree-l4"><a class="reference internal" href="#training-performance">Training Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="#resource-utilization">Resource Utilization</a></li>
<li class="toctree-l4"><a class="reference internal" href="#specifications">Specifications</a></li>
<li class="toctree-l4"><a class="reference internal" href="#notices">Notices</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="performance_profiling_gpu.html">Performance Profiling (GPU)</a></li>
<li class="toctree-l3"><a class="reference internal" href="performance_profiling_ascend_of_cluster.html">Cluster Performance Profiling (Ascend)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="debugger.html">Using Debugger</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_explanation.html">Explain Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindinsight_commands.html">MindInsight Commands</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_augmentation.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluate_the_model_during_training.html">Evaluating the Model during Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_tutorials.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying a Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_cache.html">Application of Single-Node Tensor Cache</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Compression</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_post_training_quantization.html">Applying Post Training Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Security and Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_suppress_privacy.html">Protecting User Privacy with Suppress Privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">Using Membership Inference to Test Model Security</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="visualization_tutorials.html">Training Process Visualization</a> &raquo;</li>
          <li><a href="performance_profiling.html">Performance Profiling</a> &raquo;</li>
      <li>Performance Profiling (Ascend)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/advanced_use/performance_profiling_ascend.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="performance-profiling-ascend">
<h1>Performance Profiling (Ascend)<a class="headerlink" href="#performance-profiling-ascend" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Optimization</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/training/source_en/advanced_use/performance_profiling_ascend.md"><img alt="View Source On Gitee" src="../_images/logo_source.png" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>This article describes how to use MindSpore Profiler for performance debugging on Ascend AI processors.</p>
</section>
<section id="operation-process">
<h2>Operation Process<a class="headerlink" href="#operation-process" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>Prepare a training script, add profiler APIs in the training script and run the training script.</p></li>
<li><p>Start MindInsight and specify the summary-base-dir using startup parameters, note that summary-base-dir is the parent directory of the directory created by Profiler. For example, the directory created by Profiler is <code class="docutils literal notranslate"><span class="pre">/home/user/code/data/</span></code>, the summary-base-dir should be <code class="docutils literal notranslate"><span class="pre">/home/user/code</span></code>. After MindInsight is started, access the visualization page based on the IP address and port number. The default access IP address is <code class="docutils literal notranslate"><span class="pre">http://127.0.0.1:8080</span></code>.</p></li>
<li><p>Find the training in the list, click the performance profiling link and view the data on the web page.</p></li>
</ul>
</section>
<section id="preparing-the-training-script">
<h2>Preparing the Training Script<a class="headerlink" href="#preparing-the-training-script" title="Permalink to this headline"></a></h2>
<p>To enable the performance profiling of neural networks, MindSpore Profiler APIs should be added into the script. At first, the MindSpore <code class="docutils literal notranslate"><span class="pre">Profiler</span></code> object need to be set after <code class="docutils literal notranslate"><span class="pre">set_context</span></code> is set and before the network and HCCL initialization. Then, at the end of the training, <code class="docutils literal notranslate"><span class="pre">Profiler.analyse()</span></code> should be called to finish profiling and generate the perforamnce analyse results.</p>
<blockquote>
<div><p>The parameters of Profiler are as follows:</p>
<p><a class="reference external" href="https://www.mindspore.cn/doc/api_python/en/r1.2/mindspore/mindspore.profiler.html">https://www.mindspore.cn/doc/api_python/en/r1.2/mindspore/mindspore.profiler.html</a></p>
</div></blockquote>
<p>The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.profiler</span> <span class="kn">import</span> <span class="n">Profiler</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">context</span>

<span class="c1"># Init context env</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">,</span> <span class="n">device_id</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;DEVICE_ID&quot;</span><span class="p">]))</span>

<span class="c1"># Init Profiler</span>
<span class="c1"># Note that &#39;data&#39; directory is created in current path by default. To visualize the profiling data by MindInsight,</span>
<span class="c1"># &#39;data&#39; directory should be placed under summary-base-dir.</span>
<span class="n">profiler</span> <span class="o">=</span> <span class="n">Profiler</span><span class="p">()</span>

<span class="c1"># Train Model</span>
<span class="n">Model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="c1"># Profiler end</span>
<span class="n">profiler</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="launch-mindinsight">
<h2>Launch MindInsight<a class="headerlink" href="#launch-mindinsight" title="Permalink to this headline"></a></h2>
<p>The MindInsight launch command can refer to <a class="reference external" href="https://www.mindspore.cn/tutorial/training/en/r1.2/advanced_use/mindinsight_commands.html">MindInsight Commands</a>.</p>
</section>
<section id="training-performance">
<h2>Training Performance<a class="headerlink" href="#training-performance" title="Permalink to this headline"></a></h2>
<p>Users can access the Training Performance by selecting a specific training from the training list, and click the performance profiling link.</p>
<p><img alt="performance_overall.png" src="../_images/performance_overall.png" /></p>
<p>Figure 1: Overall Performance</p>
<p>Figure 1 displays the overall performance of the training, including the overall data of Step Trace, Operator Performance, Data Preparation Performance and Timeline. The data shown in these components include:</p>
<ul class="simple">
<li><p>Step Trace: It will divide the training steps into several stages and collect execution time for each stage. The overall performance page will show the step trace graph.</p></li>
<li><p>Operator Performance: It will collect the execution time of operators and operator types. The overall performance page will show the pie graph for different operator types.</p></li>
<li><p>Data Preparation Performance: It will analyse the performance of the data input stages. The overall performance page will show the number of steps that may be the bottleneck for these stages.</p></li>
<li><p>Timeline: It will collect execution time for stream tasks on the devices. The tasks will be shown on the time axis. The overall performance page will show the statistics for streams and tasks.</p></li>
</ul>
<p>Users can click the detail link to see the details of each components. Besides, MindInsight Profiler will try to analyse the performance data, the assistant on the left will show performance tuning suggestions for this training.</p>
<section id="step-trace-analysis">
<h3>Step Trace Analysis<a class="headerlink" href="#step-trace-analysis" title="Permalink to this headline"></a></h3>
<p>The Step Trace Component is used to show the general performance of the stages in the training. Step Trace will divide the training into several stages:<br />
Step Gap (The time between the end of one step and the computation of next step), Forward/Backward Propagation, All Reduce and Parameter Update. It will show the execution time for each stage, and help to find the bottleneck stage quickly.</p>
<blockquote>
<div><p>Step Trace does not support heterogeneous training currently.</p>
</div></blockquote>
<p><img alt="step_trace.png" src="../_images/step_trace.png" /></p>
<p>Figure 2: Step Trace Analysis</p>
<p>Figure 2 displays the Step Trace page. The Step Trace detail will show the start/finish time for each stage. By default, it shows the average time for all the steps. Users can also choose a specific step to see its step trace statistics.</p>
<p>The graphs at the bottom of the page show the execution time of Step Interval, Forward/Backward Propagation and Step Tail (The time between the end of Backward Propagation and the end of Parameter Update) changes according to different steps, it will help to decide whether we can optimize the performance of some stages. Here are more details:</p>
<ul class="simple">
<li><p><strong>Step Interval</strong> is the duration for reading data from data queues. If this part takes long time, it is advised to check the data processing for further analysis.</p></li>
<li><p><strong>Forward and Backward Propagation</strong> is the duration for executing the forward and backward operations on the network, which handle the main calculation work of a step. If this part takes long time, it is advised to check the statistics of operators or timeline for further analysis.</p></li>
<li><p><strong>Step Tail</strong> is the duration for performing parameter aggregation and update operations in parallel training. If the operation takes long time, it is advised to check the statistics of communication operators and the status of parallelism.</p></li>
</ul>
<p>In order to divide the stages, the Step Trace Component need to figure out the forward propagation start operator and the backward propagation end operator. MindSpore will automatically figure out the two operators to reduce the profiler configuration work. The first operator after <code class="docutils literal notranslate"><span class="pre">get_next</span></code> will be selected as the forward start operator and the operator before the last all reduce will be selected as the backward end operator.
<strong>However, Profiler do not guarantee that the automatically selected operators will meet the user’s expectation in all cases.</strong> Users can set the two operators manually as follows:</p>
<ul class="simple">
<li><p>Set environment variable <code class="docutils literal notranslate"><span class="pre">PROFILING_FP_START</span></code> to configure the forward start operator, for example, <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">PROFILING_FP_START=fp32_vars/conv2d/BatchNorm</span></code>.</p></li>
<li><p>Set environment variable <code class="docutils literal notranslate"><span class="pre">PROFILING_BP_END</span></code> to configure the backward end operator, for example, <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">PROFILING_BP_END=loss_scale/gradients/AddN_70</span></code>.</p></li>
</ul>
</section>
<section id="operator-performance-analysis">
<h3>Operator Performance Analysis<a class="headerlink" href="#operator-performance-analysis" title="Permalink to this headline"></a></h3>
<p>The operator performance analysis component is used to display the execution time of the operators(AICORE/AICPU/HOSTCPU) during MindSpore run.</p>
<p><img alt="op_type_statistics.png" src="../_images/op_type_statistics.PNG" /></p>
<p>Figure 3: Statistics for Operator Types</p>
<p>Figure 3 displays the statistics for the operator types, including:</p>
<ul class="simple">
<li><p>Choose pie or bar graph to show the proportion time occupied by each operator type. The time of one operator type is calculated by accumulating the execution time of operators belonging to this type.</p></li>
<li><p>Display top 20 operator types with the longest execution time, show the proportion and execution time (ms) of each operator type.</p></li>
</ul>
<p><img alt="op_statistics.png" src="../_images/op_statistics.PNG" /></p>
<p>Figure 4: Statistics for Operators</p>
<p>Figure 4 displays the statistics table for the operators, including:</p>
<ul class="simple">
<li><p>Choose All: Display statistics for the operators, including operator name, type, execution time, full scope time, information, etc. The table will be sorted by execution time by default.</p></li>
<li><p>Choose Type: Display statistics for the operator types, including operator type name, execution time, execution frequency and proportion of total time. Users can click on each line, querying for all the operators belonging to this type.</p></li>
<li><p>Search: There is a search box on the right, which can support fuzzy search for operators/operator types.</p></li>
</ul>
</section>
<section id="data-preparation-performance-analysis">
<h3>Data Preparation Performance Analysis<a class="headerlink" href="#data-preparation-performance-analysis" title="Permalink to this headline"></a></h3>
<p>The Data preparation performance analysis component is used to analyse the execution of data input pipeline for the training. The data input pipeline can be divided into three stages:<br />
the data process pipeline, data transfer from host to device and data fetch on device. The component will analyse the performance of each stage in detail and display the results.</p>
<p><img alt="minddata_profile.png" src="../_images/minddata_profile.png" /></p>
<p>Figure 5: Data Preparation Performance Analysis</p>
<p>Figure 5 displays the page of data preparation performance analysis component. It consists of two tabs: the step gap and the data process.</p>
<p>The step gap page is used to analyse whether there is performance bottleneck in the three stages. We can get our conclusion from the data queue graphs:</p>
<ul class="simple">
<li><p>The data queue size stands for the queue length when the training fetches data from the queue on the device. If the data queue size is 0, the training will wait until there is data in the queue; If the data queue size is greater than 0, the training can get data very quickly, and it means data preparation stage is not the bottleneck for this training step.</p></li>
<li><p>The host queue size can be used to infer the speed of data process and data transfer. If the host queue size is 0, it means we need to speed up the data process stage.</p></li>
<li><p>If the size of the host queue is always large and the size of the data queue is continuously small, there may be a performance bottleneck in data transfer.</p></li>
</ul>
<p><img alt="data_op_profile.png" src="../_images/data_op_profile.png" /></p>
<p>Figure 6: Data Process Pipeline Analysis</p>
<p>Figure 6 displays the page of data process pipeline analysis. The data queues are used to exchange data between the data processing operators. The data size of the queues reflect the data consume speed of the operators, and can be used to infer the bottleneck operator. The queue usage percentage stands for the average value of data size in queue divide data queue maximum size, the higher the usage percentage, the more data that is accumulated in the queue. The graph at the bottom of the page shows the data processing pipeline operators with the data queues, the user can click one queue to see how the data size changes according to the time, and the operators connected to the queue. The data process pipeline can be analysed as follows:</p>
<ul class="simple">
<li><p>When the input queue usage percentage of one operator is high, and the output queue usage percentage is low, the operator may be the bottleneck.</p></li>
<li><p>For the leftmost operator, if the usage percentage of all the queues on the right are low, the operator may be the bottleneck.</p></li>
<li><p>For the rightmost operator, if the usage percentage of all the queues on the left are high, the operator may be the bottleneck.</p></li>
</ul>
<p>To optimize the performance of data processing operators, there are some suggestions:</p>
<ul class="simple">
<li><p>If the Dataset Operator is the bottleneck, try to increase the <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>.</p></li>
<li><p>If a GeneratorOp type operator is the bottleneck, try to increase the <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> and replace the operator to <code class="docutils literal notranslate"><span class="pre">MindRecordDataset</span></code>.</p></li>
<li><p>If a MapOp type operator is the bottleneck, try to increase the <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>. If it is a python operator, try to optimize the training script.</p></li>
<li><p>If a BatchOp type operator is the bottleneck, try to adjust the size of <code class="docutils literal notranslate"><span class="pre">prefetch_size</span></code>.</p></li>
</ul>
</section>
<section id="timeline-analysis">
<h3>Timeline Analysis<a class="headerlink" href="#timeline-analysis" title="Permalink to this headline"></a></h3>
<p>The Timeline component can display:</p>
<ul class="simple">
<li><p>The operators (AICORE/AICPU/HOSTCPU operators) are executed on which device.</p></li>
<li><p>The MindSpore stream split strategy for this neural network.</p></li>
<li><p>The execution sequence and execution time of the operator on the device.</p></li>
</ul>
<p>Users can get the most detailed information from the Timeline:</p>
<ul class="simple">
<li><p>From the High level, users can analyse whether the stream split strategy can be optimized and whether the step tail is too long.</p></li>
<li><p>From the Low level, users can analyse the execution time for all the operators, etc.</p></li>
</ul>
<p>Users can click the download button on the overall performance page to view Timeline details. The Timeline data file (json format) will be stored on local machine, and can be displayed by tools. We suggest to use <code class="docutils literal notranslate"><span class="pre">chrome://tracing</span></code> or <a class="reference external" href="https://ui.perfetto.dev/#!viewer">Perfetto</a> to visualize the Timeline.</p>
<ul class="simple">
<li><p>Chrome tracing: Click “load” on the upper left to load the file.</p></li>
<li><p>Perfetto: Click “Open trace file” on the left to load the file.</p></li>
</ul>
<p><img alt="timeline.png" src="../_images/timeline.png" /></p>
<p>Figure 10: Timeline Analysis</p>
<p>The Timeline consists of the following parts:</p>
<ul class="simple">
<li><p>Device and Stream List: It will show the stream list on each device. Each stream consists of a series of tasks. One rectangle stands for one task, and the area stands for the execution time of the task.</p></li>
<li><p>The Operator Information: When we click one task, the corresponding operator of this task will be shown at the bottom.</p></li>
</ul>
<p>W/A/S/D can be applied to zoom in and out of the Timeline graph.</p>
</section>
</section>
<section id="resource-utilization">
<h2>Resource Utilization<a class="headerlink" href="#resource-utilization" title="Permalink to this headline"></a></h2>
<p>Resource utilization includes cpu usage analysis and memory usage analysis.</p>
<p><img alt="resource_visibility.png" src="../_images/resource_visibility.png" /></p>
<p>Figure 11：Overview of resource utilization</p>
<p>Overview of resource utilization：Including CPU utilization analysis and memory usage analysis. You can view the details by clicking the View Details button in the upper right corner.</p>
<section id="cpu-utilization-analysis">
<h3>CPU Utilization Analysis<a class="headerlink" href="#cpu-utilization-analysis" title="Permalink to this headline"></a></h3>
<p>CPU utilization, which is mainly used to assist performance debugging. After the performance bottleneck is determined according to the queue size, the performance can be debugged according to the CPU utilization (if the user utilization is too low, increase the number of threads; if the system utilization is too high, decrease the number of threads).
CPU utilization includes CPU utilization of the whole machine, process and Data pipeline operator.</p>
<p><img alt="device_utilization.png" src="../_images/device_cpu_utilization.png" /></p>
<p>Figure 7: CPU utilization of the whole machine</p>
<p>CPU utilization of the whole machine: Show the overall CPU usage of the device in the training process, including user utilization, system utilization, idle utilization, IO utilization, current number of active processes, and context switching times. If the user utilization is low, you can try to increase the number of operator threads to increase the CPU utilization; if the system utilization is high, and the number of context switching and CPU waiting for processing is large, it indicates that the number of threads needs to be reduced accordingly.</p>
<p><img alt="process_cpu_utilization.png" src="../_images/process_cpu_utilizaton.png" /></p>
<p>Figure 8: Process utilization</p>
<p>Process utilization: Show the CPU usage of a single process. The combination of whole machine utilization and process utilization can determine whether other processes affect the training process.</p>
<p><img alt="data_op_utilization.png" src="../_images/data_op_utilization.png" /></p>
<p>Figure 9: Operator utilization</p>
<p>Operator utilization: Show the CPU utilization of Data pipeline single operator. We can adjust the number of threads of the corresponding operator according to the actual situation. If the number of threads is small and takes up a lot of CPU, you can consider whether you need to optimize the code.</p>
<p>Common scenarios of CPU utilization:</p>
<ul class="simple">
<li><p>According to the queue size, the network debugging personnel can judge that the performance of MindData has a bottleneck. They can adjust the number of threads by combining the utilization rate of the whole machine and the utilization rate of the operator.</p></li>
<li><p>Developers can check the utilization of operators. If an operator consumes CPU utilization, they can confirm whether the code needs to be optimized.</p></li>
</ul>
</section>
<section id="memory-analysis">
<h3>Memory Analysis<a class="headerlink" href="#memory-analysis" title="Permalink to this headline"></a></h3>
<p>This page is used to show the memory usage of the neural network model on the <strong>device</strong>, which is an <strong>ideal prediction</strong> based on the theoretical calculation results. The content of the page includes:</p>
<ul class="simple">
<li><p>An overview of the memory usage of the model, including the total available memory, peak memory and other information.</p></li>
<li><p>The memory occupied varies in the execution order while the model is running.</p></li>
<li><p>The memory usage of each operator is decomposed and displayed in the table of <code class="docutils literal notranslate"><span class="pre">Operator</span> <span class="pre">Memory</span> <span class="pre">Allocation</span></code>.</p></li>
</ul>
<blockquote>
<div><p>Memory Analysis does not support heterogeneous training currently.</p>
</div></blockquote>
<p><img alt="memory.png" src="../_images/memory.png" /></p>
<p>Figure 8：Memory Analysis</p>
<p>Users can obtain the summary of memory usage via the <code class="docutils literal notranslate"><span class="pre">Memory</span> <span class="pre">Allocation</span> <span class="pre">Overview</span></code>. In addition, they can obtain more detailed information from <code class="docutils literal notranslate"><span class="pre">Memory</span> <span class="pre">Usage</span></code>, including:</p>
<ul class="simple">
<li><p><strong>Line Chart</strong>: Changes in model memory usage, including static memory, total occupied memory and total available memory.</p></li>
<li><p><strong>Zooming</strong>: There is a zoom scroll bar under the line chart. Users can zoom in or out the line chart by adjusting its size to observe more details.</p></li>
<li><p><strong>FP/BP</strong>: The execution positions of the start of <code class="docutils literal notranslate"><span class="pre">Forward</span> <span class="pre">Propagation</span></code> and the end of <code class="docutils literal notranslate"><span class="pre">Backward</span> <span class="pre">Propagation</span></code> of the model on the line chart.</p></li>
<li><p><strong>Details of Nodes</strong>: Hovering over the line chart, the information of the corresponding execution operator is shown, including the execution order of the operator, the name of the operator, the memory occupied by the operator, the total memory occupied by the model in the current position, and the relative memory change compared with the previous execution position.</p></li>
<li><p><strong>Memory Decomposition</strong>: Left clicking a position on the line chart, the memory breakdowns of the execution position is shown in the table below the line chart, called <code class="docutils literal notranslate"><span class="pre">Operator</span> <span class="pre">Memory</span> <span class="pre">Allocation</span></code>. The table shows the memory decomposition of the corresponding execution position, i.e., the output tensor of which operators are allocated the occupied memory of the current execution position. The module provides users with abundant information, including tensor name, tensor size, tensor type, data type, shape, format, and the active lifetime of tensor memory.</p></li>
</ul>
<p><img alt="memory_graphics.png" src="../_images/memory_graphics.png" /></p>
<p>Figure 9：Memory Statistics</p>
</section>
</section>
<section id="specifications">
<h2>Specifications<a class="headerlink" href="#specifications" title="Permalink to this headline"></a></h2>
<ul>
<li><p>To limit the data size generated by the Profiler, MindInsight suggests that for large neural network, the profiled steps should be less than 10.</p>
<blockquote>
<div><p>The number of steps can be controlled by controlling the size of training data set. For example, the <code class="docutils literal notranslate"><span class="pre">num_samples</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">mindspore.dataset.MindDataset</span></code> can control the size of the data set. For details, please refer to:
<a class="reference external" href="https://www.mindspore.cn/doc/api_python/en/r1.2/mindspore/dataset/mindspore.dataset.MindDataset.html">https://www.mindspore.cn/doc/api_python/en/r1.2/mindspore/dataset/mindspore.dataset.MindDataset.html</a></p>
</div></blockquote>
</li>
<li><p>The parse of Timeline data is time consuming, and usually the data of a few steps is enough to analyze the results. In order to speed up the data parse and UI display, Profiler will show at most 20M data (Contain 10+ step information for large networks).</p></li>
</ul>
</section>
<section id="notices">
<h2>Notices<a class="headerlink" href="#notices" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>Currently running in PyNative mode is not supported.</p></li>
<li><p>Currently the training and inference process does not support performance debugging, only individual training or inference is supported.</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="performance_profiling.html" class="btn btn-neutral float-left" title="Performance Profiling" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="performance_profiling_gpu.html" class="btn btn-neutral float-right" title="Performance Profiling (GPU)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>