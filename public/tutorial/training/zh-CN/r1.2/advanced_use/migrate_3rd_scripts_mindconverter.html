<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>使用工具迁移第三方框架脚本 &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="迁移第三方框架训练脚本" href="migrate_3rd_scripts.html" />
    <link rel="prev" title="迁移第三方框架训练脚本" href="migrate_script.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">实现一个图片分类应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/linear_regression.html">实现简单线性函数拟合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">手把手安装和体验</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">基础使用</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation.html">加载数据集</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">定义网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/save_model.html">保存模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/load_model_for_inference_and_transfer.html">加载模型用于推理或迁移学习</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/publish_model.html">发布模型</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">处理数据</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="convert_dataset.html">转换数据集为MindRecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimize_data_processing.html">优化数据处理</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">构建网络</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="custom_loss_function.html">定义与使用损失函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_operator.html">自定义算子</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="migrate_script.html">迁移第三方框架训练脚本</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">使用工具迁移第三方框架脚本</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">安装</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">用法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pytorch">PyTorch模型脚本迁移</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tensorflow">TensorFlow模型脚本迁移</a></li>
<li class="toctree-l4"><a class="reference internal" href="#onnx">ONNX模型文件迁移</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id5">使用场景</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">使用示例</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#ast">基于AST的脚本转换示例</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id7">基于图结构的脚本生成示例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#mindconverter">MindConverter错误码速查表</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">MindConverter支持的模型列表</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id11">注意事项</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="migrate_3rd_scripts.html">迁移第三方框架训练脚本</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="apply_deep_probability_programming.html">深度概率编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_high_order_differentiation.html">实现高阶自动微分</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantum_neural_network.html">量子神经网络</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">调试网络</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">使用PyNative模式调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">使用Dump功能在Graph模式调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">自定义调试信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization_tutorials.html">使用可视化组件MindInsight</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_augmentation.html">应用自动数据增强</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluate_the_model_during_training.html">训练时验证模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">算子增量编译</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">优化训练性能</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_tutorials.html">分布式并行训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">使能自动混合精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">使能图算融合</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">应用梯度累积算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_cache.html">应用单节点数据缓存</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">压缩模型</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">应用感知量化训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_post_training_quantization.html">应用训练后量化</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型安全和隐私</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">使用NAD算法提升模型安全性</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">应用差分隐私机制保护用户隐私</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_suppress_privacy.html">应用抑制隐私机制保护用户隐私</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">使用fuzz testing模块测试模型安全性</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">使用成员推理测试模型安全性</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">应用实践</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">机器视觉</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">自然语言处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">高性能计算</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">在云上使用MindSpore</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="migrate_script.html">迁移第三方框架训练脚本</a> &raquo;</li>
      <li>使用工具迁移第三方框架脚本</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/advanced_use/migrate_3rd_scripts_mindconverter.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="id1">
<h1>使用工具迁移第三方框架脚本<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">模型开发</span></code> <code class="docutils literal notranslate"><span class="pre">初级</span></code></p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/training/source_zh_cn/advanced_use/migrate_3rd_scripts_mindconverter.md"><img alt="查看源文件" src="../_images/logo_source.png" /></a></p>
<section id="id2">
<h2>概述<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<p>MindConverter是一款用于将PyTorch（ONNX）、TensorFlow（PB）模型转换到MindSpore模型定义脚本以及权重文件的工具。结合转换报告的信息，用户只需对转换后的脚本进行微小的改动，即可实现快速迁移。</p>
</section>
<section id="id3">
<h2>安装<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h2>
<p>此工具为MindInsight的子模块，安装MindInsight后，即可使用MindConverter，MindInsight安装请参考该<a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.2/README_CN.md#">安装文档</a>。</p>
</section>
<section id="id4">
<h2>用法<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h2>
<p>MindConverter提供命令行（Command-line interface, CLI）的使用方式，命令如下。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>usage:<span class="w"> </span>mindconverter<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span><span class="o">[</span>--version<span class="o">]</span><span class="w"> </span><span class="o">[</span>--in_file<span class="w"> </span>IN_FILE<span class="o">]</span>
<span class="w">                     </span><span class="o">[</span>--model_file<span class="w"> </span>MODEL_FILE<span class="o">]</span><span class="w"> </span><span class="o">[</span>--shape<span class="w"> </span>SHAPE<span class="w"> </span><span class="o">[</span>SHAPE<span class="w"> </span>...<span class="o">]]</span>
<span class="w">                     </span><span class="o">[</span>--input_nodes<span class="w"> </span>INPUT_NODES<span class="w"> </span><span class="o">[</span>INPUT_NODES<span class="w"> </span>...<span class="o">]]</span>
<span class="w">                     </span><span class="o">[</span>--output_nodes<span class="w"> </span>OUTPUT_NODES<span class="w"> </span><span class="o">[</span>OUTPUT_NODES<span class="w"> </span>...<span class="o">]]</span>
<span class="w">                     </span><span class="o">[</span>--output<span class="w"> </span>OUTPUT<span class="o">]</span><span class="w"> </span><span class="o">[</span>--report<span class="w"> </span>REPORT<span class="o">]</span>

optional<span class="w"> </span>arguments:
<span class="w">  </span>-h,<span class="w"> </span>--help<span class="w">            </span>show<span class="w"> </span>this<span class="w"> </span><span class="nb">help</span><span class="w"> </span>message<span class="w"> </span>and<span class="w"> </span><span class="nb">exit</span>
<span class="w">  </span>--version<span class="w">             </span>show<span class="w"> </span>program<span class="w"> </span>version<span class="w"> </span>number<span class="w"> </span>and<span class="w"> </span><span class="nb">exit</span>
<span class="w">  </span>--in_file<span class="w"> </span>IN_FILE<span class="w">     </span>Specify<span class="w"> </span>path<span class="w"> </span><span class="k">for</span><span class="w"> </span>script<span class="w"> </span>file<span class="w"> </span>to<span class="w"> </span>use<span class="w"> </span>AST<span class="w"> </span>schema<span class="w"> </span>to<span class="w"> </span><span class="k">do</span>
<span class="w">                        </span>script<span class="w"> </span>conversation.
<span class="w">  </span>--model_file<span class="w"> </span>MODEL_FILE
<span class="w">                        </span>Tensorflow<span class="o">(</span>.pb<span class="o">)</span><span class="w"> </span>or<span class="w"> </span>ONNX<span class="o">(</span>.onnx<span class="o">)</span><span class="w"> </span>model<span class="w"> </span>file<span class="w"> </span>path<span class="w"> </span>is
<span class="w">                        </span>expected<span class="w"> </span>to<span class="w"> </span><span class="k">do</span><span class="w"> </span>script<span class="w"> </span>generation<span class="w"> </span>based<span class="w"> </span>on<span class="w"> </span>graph
<span class="w">                        </span>schema.<span class="w"> </span>When<span class="w"> </span><span class="sb">`</span>--in_file<span class="sb">`</span><span class="w"> </span>and<span class="w"> </span><span class="sb">`</span>--model_file<span class="sb">`</span><span class="w"> </span>are<span class="w"> </span>both
<span class="w">                        </span>provided,<span class="w"> </span>use<span class="w"> </span>AST<span class="w"> </span>schema<span class="w"> </span>as<span class="w"> </span>default.
<span class="w">  </span>--shape<span class="w"> </span>SHAPE<span class="w"> </span><span class="o">[</span>SHAPE<span class="w"> </span>...<span class="o">]</span>
<span class="w">                        </span>Optional,<span class="w"> </span>expected<span class="w"> </span>input<span class="w"> </span>tensor<span class="w"> </span>shape<span class="w"> </span>of
<span class="w">                        </span><span class="sb">`</span>--model_file<span class="sb">`</span>.<span class="w"> </span>It<span class="w"> </span>is<span class="w"> </span>required<span class="w"> </span>when<span class="w"> </span>use<span class="w"> </span>graph<span class="w"> </span>based
<span class="w">                        </span>schema.<span class="w"> </span>Both<span class="w"> </span>order<span class="w"> </span>and<span class="w"> </span>number<span class="w"> </span>should<span class="w"> </span>be<span class="w"> </span>consistent
<span class="w">                        </span>with<span class="w"> </span><span class="sb">`</span>--input_nodes<span class="sb">`</span>.<span class="w"> </span>Usage:<span class="w"> </span>--shape<span class="w"> </span><span class="m">1</span>,512<span class="w"> </span><span class="m">1</span>,512
<span class="w">  </span>--input_nodes<span class="w"> </span>INPUT_NODES<span class="w"> </span><span class="o">[</span>INPUT_NODES<span class="w"> </span>...<span class="o">]</span>
<span class="w">                        </span>Optional,<span class="w"> </span>input<span class="w"> </span>node<span class="o">(</span>s<span class="o">)</span><span class="w"> </span>name<span class="w"> </span>of<span class="w"> </span><span class="sb">`</span>--model_file<span class="sb">`</span>.<span class="w"> </span>It<span class="w"> </span>is
<span class="w">                        </span>required<span class="w"> </span>when<span class="w"> </span>use<span class="w"> </span>graph<span class="w"> </span>based<span class="w"> </span>schema.<span class="w"> </span>Both<span class="w"> </span>order<span class="w"> </span>and
<span class="w">                        </span>number<span class="w"> </span>should<span class="w"> </span>be<span class="w"> </span>consistent<span class="w"> </span>with<span class="w"> </span><span class="sb">`</span>--shape<span class="sb">`</span>.<span class="w"> </span>Usage:
<span class="w">                        </span>--input_nodes<span class="w"> </span>input_1:0<span class="w"> </span>input_2:0
<span class="w">  </span>--output_nodes<span class="w"> </span>OUTPUT_NODES<span class="w"> </span><span class="o">[</span>OUTPUT_NODES<span class="w"> </span>...<span class="o">]</span>
<span class="w">                        </span>Optional,<span class="w"> </span>output<span class="w"> </span>node<span class="o">(</span>s<span class="o">)</span><span class="w"> </span>name<span class="w"> </span>of<span class="w"> </span><span class="sb">`</span>--model_file<span class="sb">`</span>.<span class="w"> </span>It<span class="w"> </span>is
<span class="w">                        </span>required<span class="w"> </span>when<span class="w"> </span>use<span class="w"> </span>graph<span class="w"> </span>based<span class="w"> </span>schema.<span class="w"> </span>Usage:
<span class="w">                        </span>--output_nodes<span class="w"> </span>output_1:0<span class="w"> </span>output_2:0
<span class="w">  </span>--output<span class="w"> </span>OUTPUT<span class="w">       </span>Optional,<span class="w"> </span>specify<span class="w"> </span>path<span class="w"> </span><span class="k">for</span><span class="w"> </span>converted<span class="w"> </span>script<span class="w"> </span>file
<span class="w">                        </span>directory.<span class="w"> </span>Default<span class="w"> </span>output<span class="w"> </span>directory<span class="w"> </span>is<span class="w"> </span><span class="sb">`</span>output<span class="sb">`</span><span class="w"> </span>folder
<span class="w">                        </span><span class="k">in</span><span class="w"> </span>the<span class="w"> </span>current<span class="w"> </span>working<span class="w"> </span>directory.
<span class="w">  </span>--report<span class="w"> </span>REPORT<span class="w">       </span>Optional,<span class="w"> </span>specify<span class="w"> </span>report<span class="w"> </span>directory.<span class="w"> </span>Default<span class="w"> </span>is
<span class="w">                        </span>converted<span class="w"> </span>script<span class="w"> </span>directory.
</pre></div>
</div>
<section id="pytorch">
<h3>PyTorch模型脚本迁移<a class="headerlink" href="#pytorch" title="Permalink to this headline"></a></h3>
<p><strong>MindConverter仅提供基于抽象语法树（Abstract syntax tree, AST）的PyTorch脚本迁移</strong>：指定<code class="docutils literal notranslate"><span class="pre">--in_file</span></code>的值，将使用基于AST的脚本转换方案；</p>
<blockquote>
<div><p>若同时指定了<code class="docutils literal notranslate"><span class="pre">--in_file</span></code>，<code class="docutils literal notranslate"><span class="pre">--model_file</span></code>将默认使用AST方案进行脚本迁移。</p>
</div></blockquote>
<p>其中，<code class="docutils literal notranslate"><span class="pre">--output</span></code>与<code class="docutils literal notranslate"><span class="pre">--report</span></code>参数可省略。若省略，MindConverter将在当前工作目录（Working directory）下自动创建<code class="docutils literal notranslate"><span class="pre">output</span></code>目录，将生成的脚本、转换报告输出至该目录。</p>
<blockquote>
<div><p>若需要使用MindConverter计算图方案进行PyTorch模型脚本迁移，建议将PyTorch模型转换为ONNX，再使用ONNX文件进行模型脚本迁移，详情见<a class="reference external" href="https://pytorch.org/docs/stable/onnx.html">PyTorch使用说明</a>。</p>
</div></blockquote>
</section>
<section id="tensorflow">
<h3>TensorFlow模型脚本迁移<a class="headerlink" href="#tensorflow" title="Permalink to this headline"></a></h3>
<p><strong>MindConverter提供基于图结构的脚本生成方案</strong>：指定<code class="docutils literal notranslate"><span class="pre">--model_file</span></code>、<code class="docutils literal notranslate"><span class="pre">--shape</span></code>、<code class="docutils literal notranslate"><span class="pre">--input_nodes</span></code>、<code class="docutils literal notranslate"><span class="pre">--output_nodes</span></code>进行脚本迁移。</p>
<blockquote>
<div><p>AST方案不支持TensorFlow模型脚本迁移，TensorFlow脚本迁移仅支持基于图结构的方案。</p>
</div></blockquote>
<p>若省略<code class="docutils literal notranslate"><span class="pre">--output</span></code>与<code class="docutils literal notranslate"><span class="pre">--report</span></code>参数，MindConverter将在当前工作目录（Working directory）下自动创建<code class="docutils literal notranslate"><span class="pre">output</span></code>目录，将生成的脚本、转换报告、权重文件、权重映射表输出至该目录。</p>
</section>
<section id="onnx">
<h3>ONNX模型文件迁移<a class="headerlink" href="#onnx" title="Permalink to this headline"></a></h3>
<p><strong>MindConverter提供基于图结构的脚本生成方案</strong>：指定<code class="docutils literal notranslate"><span class="pre">--model_file</span></code>、<code class="docutils literal notranslate"><span class="pre">--shape</span></code>、<code class="docutils literal notranslate"><span class="pre">--input_nodes</span></code>、<code class="docutils literal notranslate"><span class="pre">--output_nodes</span></code>进行脚本迁移。</p>
<blockquote>
<div><p>AST方案不支持ONNX模型文件迁移，ONNX文件迁移仅支持基于图结构的方案。</p>
</div></blockquote>
<p>若省略<code class="docutils literal notranslate"><span class="pre">--output</span></code>与<code class="docutils literal notranslate"><span class="pre">--report</span></code>参数，MindConverter将在当前工作目录（Working directory）下自动创建<code class="docutils literal notranslate"><span class="pre">output</span></code>目录，将生成的脚本、转换报告、权重文件、权重映射表输出至该目录。</p>
</section>
</section>
<section id="id5">
<h2>使用场景<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h2>
<p>MindConverter提供两种技术方案，以应对不同脚本迁移场景：</p>
<ol class="arabic simple">
<li><p>用户希望迁移后脚本保持原脚本结构（包括变量、函数、类命名等与原脚本保持一致）；</p></li>
<li><p>用户希望迁移后脚本保持较高的转换率，尽量少的修改、甚至不需要修改，即可实现迁移后模型脚本的执行。</p></li>
</ol>
<p>对于上述第一种场景，推荐用户使用基于AST的方案进行转换（AST方案仅支持PyTorch脚本转换），AST方案通过对原PyTorch脚本的抽象语法树进行解析、编辑，将其替换为MindSpore的抽象语法树，再利用抽象语法树生成代码。理论上，AST方案支持任意模型脚本迁移，但语法树解析操作受原脚本用户编码风格影响，可能导致同一模型的不同脚本最终的转换率存在一定差异。</p>
<p>对于上述第二种场景，推荐用户使用基于图结构的脚本生成方案，计算图作为一种标准的模型描述语言，可以消除用户代码风格多样导致的脚本转换率不稳定的问题。在已支持算子的情况下，该方案可提供优于AST方案的转换率。</p>
<p>目前已基于计算机视觉领域典型模型对图结构的脚本转换方案进行测试。</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>基于图结构的脚本生成方案，由于要以推理模式加载ONNX、TensorFlow模型，会导致转换后网络中Dropout算子丢失，需要用户手动补齐。</p></li>
<li><p>基于图结构的脚本生成方案持续优化中。</p></li>
</ol>
</div></blockquote>
</section>
<section id="id6">
<h2>使用示例<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h2>
<section id="ast">
<h3>基于AST的脚本转换示例<a class="headerlink" href="#ast" title="Permalink to this headline"></a></h3>
<p>若用户希望使用基于AST的方案进行脚本迁移，假设原PyTorch脚本路径为<code class="docutils literal notranslate"><span class="pre">/home/user/model.py</span></code>，希望将脚本输出至<code class="docutils literal notranslate"><span class="pre">/home/user/output</span></code>，转换报告输出至<code class="docutils literal notranslate"><span class="pre">/home/user/output/report</span></code>，则脚本转换命令为：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mindconverter<span class="w"> </span>--in_file<span class="w"> </span>/home/user/model.py<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--output<span class="w"> </span>/home/user/output<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--report<span class="w"> </span>/home/user/output/report
</pre></div>
</div>
<p>转换报告中，对于未转换的代码行形式为如下，其中x, y指明的是原PyTorch脚本中代码的行、列号。对于未成功转换的算子，可参考<a class="reference external" href="https://www.mindspore.cn/doc/note/zh-CN/r1.2/index.html#operator_api">MindSporeAPI映射查询功能</a> 手动对代码进行迁移。对于工具无法迁移的算子，会保留原脚本中的代码。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>line x:y: [UnConvert] &#39;operator&#39; didn&#39;t convert. ...
</pre></div>
</div>
<p>转换报告示例如下所示：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span> [Start Convert]
 [Insert] &#39;import mindspore.ops as ops&#39; is inserted to the converted file.
 line 1:0: [Convert] &#39;import torch&#39; is converted to &#39;import mindspore&#39;.
 ...
 line 157:23: [UnConvert] &#39;nn.AdaptiveAvgPool2d&#39; didn&#39;t convert. Maybe could convert to mindspore.ops.operations.ReduceMean.
 ...
 [Convert Over]
</pre></div>
</div>
<p>对于部分未成功转换的算子，报告中会提供修改建议，如<code class="docutils literal notranslate"><span class="pre">line</span> <span class="pre">157:23</span></code>，MindConverter建议将<code class="docutils literal notranslate"><span class="pre">torch.nn.AdaptiveAvgPool2d</span></code>替换为<code class="docutils literal notranslate"><span class="pre">mindspore.ops.operations.ReduceMean</span></code>。</p>
</section>
<section id="id7">
<h3>基于图结构的脚本生成示例<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h3>
<section id="id8">
<h4>TensorFlow模型脚本生成示例<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h4>
<p>使用TensorFlow模型脚本迁移，需要先将TensorFlow模型导出为pb格式，并且获取模型输入节点、输出节点名称。TensorFlow pb模型导出可参考<a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.2/mindinsight/mindconverter/docs/tensorflow_model_exporting_cn.md#">TensorFlow Pb模型导出教程</a>。</p>
<p>假设输入节点名称为<code class="docutils literal notranslate"><span class="pre">input_1:0</span></code>，输出节点名称为<code class="docutils literal notranslate"><span class="pre">predictions/Softmax:0</span></code>，模型输入样本尺寸为<code class="docutils literal notranslate"><span class="pre">1,224,224,3</span></code>，模型绝对路径为<code class="docutils literal notranslate"><span class="pre">xxx/frozen_model.pb</span></code>，希望将脚本、权重文件、权重映射表输出至<code class="docutils literal notranslate"><span class="pre">/home/user/output</span></code>，转换报告输出至<code class="docutils literal notranslate"><span class="pre">/home/user/output/report</span></code>，则脚本生成命令为：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mindconverter<span class="w"> </span>--model_file<span class="w"> </span>/home/user/xxx/frozen_model.pb<span class="w"> </span>--shape<span class="w"> </span><span class="m">1</span>,224,224,3<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--input_nodes<span class="w"> </span>input_1:0<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--output_nodes<span class="w"> </span>predictions/Softmax:0<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--output<span class="w"> </span>/home/user/output<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--report<span class="w"> </span>/home/user/output/report
</pre></div>
</div>
<p>执行该命令，MindSpore代码文件、权重文件、权重映射表和转换报告生成至相应目录。</p>
<p>由于基于图结构方案属于生成式方法，转换过程中未参考原TensorFlow脚本，因此生成的转换报告中涉及的代码行、列号均指生成后脚本。</p>
<p>另外对于未成功转换的算子，在代码中会相应的标识该节点输入、输出Tensor的shape（以<code class="docutils literal notranslate"><span class="pre">input_shape</span></code>, <code class="docutils literal notranslate"><span class="pre">output_shape</span></code>标识），便于用户手动修改。以Reshape算子为例，将生成如下代码：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                                    <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="c1"># Suppose input of `reshape` is x.</span>
        <span class="n">reshape_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="o">...</span>

</pre></div>
</div>
<p>通过<code class="docutils literal notranslate"><span class="pre">input_shape</span></code>、<code class="docutils literal notranslate"><span class="pre">output_shape</span></code>参数，用户可以十分便捷地完成算子替换，替换结果如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="o">...</span>

<span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                                 <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="c1"># Suppose input of `reshape` is x.</span>
        <span class="n">reshape_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">))</span>
        <span class="o">...</span>

</pre></div>
</div>
<blockquote>
<div><p>其中<code class="docutils literal notranslate"><span class="pre">--output</span></code>与<code class="docutils literal notranslate"><span class="pre">--report</span></code>参数可省略，若省略，该命令将在当前工作目录（Working directory）下自动创建<code class="docutils literal notranslate"><span class="pre">output</span></code>目录，将生成的脚本、转换报告输出至该目录。</p>
</div></blockquote>
<p>映射表中分别保存算子在MindSpore中的权重信息（<code class="docutils literal notranslate"><span class="pre">converted_weight</span></code>）和在原始框架中的权重信息（<code class="docutils literal notranslate"><span class="pre">source_weight</span></code>）。</p>
<p>权重映射表示例如下所示：</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;resnet50&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;converted_weight&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;conv2d_0.weight&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;shape&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                    </span><span class="mi">64</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">3</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">7</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">7</span>
<span class="w">                </span><span class="p">],</span>
<span class="w">                </span><span class="nt">&quot;data_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Float32&quot;</span>
<span class="w">            </span><span class="p">},</span>
<span class="w">            </span><span class="nt">&quot;source_weight&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;conv1.weight&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;shape&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                    </span><span class="mi">64</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">3</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">7</span><span class="p">,</span>
<span class="w">                    </span><span class="mi">7</span>
<span class="w">                </span><span class="p">],</span>
<span class="w">                </span><span class="nt">&quot;data_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;float32&quot;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="id9">
<h4>ONNX模型文件生成示例<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h4>
<p>使用ONNX模型文件迁移，需要先从.onnx文件中获取模型输入节点、输出节点名称。获取ONNX模输入、输出节点名称，可使用 <a class="reference external" href="https://github.com/lutzroeder/netron">Netron</a> 工具查看。</p>
<p>假设输入节点名称为<code class="docutils literal notranslate"><span class="pre">input_1:0</span></code>、输出节点名称为<code class="docutils literal notranslate"><span class="pre">predictions/Softmax:0</span></code>，模型输入样本尺寸为<code class="docutils literal notranslate"><span class="pre">1,3,224,224</span></code>，则可使用如下命令进行脚本生成：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mindconverter<span class="w"> </span>--model_file<span class="w"> </span>/home/user/xxx/model.onnx<span class="w"> </span>--shape<span class="w"> </span><span class="m">1</span>,3,224,224<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--input_nodes<span class="w"> </span>input_1:0<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--output_nodes<span class="w"> </span>predictions/Softmax:0<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--output<span class="w"> </span>/home/user/output<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>--report<span class="w"> </span>/home/user/output/report
</pre></div>
</div>
<p>执行该命令，MindSpore代码文件、权重文件、权重映射表和转换报告生成至相应目录。</p>
<p>由于基于图结构方案属于生成式方法，转换过程中未参考ONNX文件，因此生成的转换报告中涉及的代码行、列号均指生成后脚本。</p>
<p>另外，对于未成功转换的算子，在代码中会相应的标识该节点输入、输出Tensor的shape（以<code class="docutils literal notranslate"><span class="pre">input_shape</span></code>、<code class="docutils literal notranslate"><span class="pre">output_shape</span></code>标识），便于用户手动修改，示例见<strong>TensorFlow模型脚本生成示例</strong>。</p>
</section>
</section>
</section>
<section id="mindconverter">
<h2>MindConverter错误码速查表<a class="headerlink" href="#mindconverter" title="Permalink to this headline"></a></h2>
<p>MindConverter错误码定义，请参考<a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.2/mindinsight/mindconverter/docs/error_code_definition_cn.md#">链接</a>。</p>
</section>
<section id="id10">
<h2>MindConverter支持的模型列表<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h2>
<p><a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/r1.2/mindinsight/mindconverter/docs/supported_model_list_cn.md#">支持的模型列表（如下模型已基于x86 Ubuntu发行版，PyTorch 1.5.0以及TensorFlow 1.15.0测试通过）</a>。</p>
</section>
<section id="id11">
<h2>注意事项<a class="headerlink" href="#id11" title="Permalink to this headline"></a></h2>
<ol class="arabic simple">
<li><p>TensorFlow不作为MindInsight明确声明的依赖库。若想使用基于图结构的脚本生成工具，需要用户手动安装TensorFlow（MindConverter推荐使用TensorFlow 1.15.x版本）。</p></li>
<li><p>ONNX（&gt;=1.8.0）、ONNXRUNTIME（&gt;=1.5.2）、ONNXOPTIMIZER（&gt;=0.1.2）不作为MindInsight明确声明的依赖库，若想使用基于图结构的脚本生成工具，必须安装上述三方库。若想使用TensorFlow（MindConverter推荐使用TensorFlow 1.15.x版本）模型脚本迁移需要额外安装TF2ONNX（&gt;=1.7.1）。</p></li>
<li><p>脚本转换工具本质上为算子驱动，对于MindConverter未维护的ONNX算子与MindSpore算子映射，将会出现相应的算子无法转换的问题，对于该类算子，用户可手动修改，或基于MindConverter实现映射关系，向MindInsight仓库贡献。</p></li>
<li><p>在使用基于计算图的迁移时，MindConverter会根据<code class="docutils literal notranslate"><span class="pre">--shape</span></code>参数将模型输入的批次大小（batch size）、句子长度（sequence length）、图片尺寸（image shape）等尺寸相关参数固定下来，用户需要保证基于MindSpore重训练、推理时输入shape与转换时一致；若需要调整输入尺寸，请重新指定<code class="docutils literal notranslate"><span class="pre">--shape</span></code>进行转换或修改转换后脚本中涉及张量尺寸变更操作相应的操作数。</p></li>
<li><p>脚本文件、权重文件和权重映射表输出于同一个目录下。</p></li>
<li><p>模型文件的安全性与一致性请用户自行保证。</p></li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="migrate_script.html" class="btn btn-neutral float-left" title="迁移第三方框架训练脚本" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="migrate_3rd_scripts.html" class="btn btn-neutral float-right" title="迁移第三方框架训练脚本" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>