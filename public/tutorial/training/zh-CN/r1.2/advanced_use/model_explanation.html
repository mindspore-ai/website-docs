

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>解释模型 &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/js/training.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="MindInsight相关命令" href="mindinsight_commands.html" />
    <link rel="prev" title="使用调试器" href="debugger.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">实现一个图片分类应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/linear_regression.html">实现简单线性函数拟合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">手把手安装和体验</a></li>
</ul>
<p class="caption"><span class="caption-text">基础使用</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation.html">加载数据集</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">定义网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/save_model.html">保存模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/load_model_for_inference_and_transfer.html">加载模型用于推理或迁移学习</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/publish_model.html">发布模型</a></li>
</ul>
<p class="caption"><span class="caption-text">处理数据</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="convert_dataset.html">转换数据集为MindRecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimize_data_processing.html">优化数据处理</a></li>
</ul>
<p class="caption"><span class="caption-text">构建网络</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="custom_loss_function.html">定义与使用损失函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_operator.html">自定义算子</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrate_script.html">迁移第三方框架训练脚本</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_deep_probability_programming.html">深度概率编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_high_order_differentiation.html">实现高阶自动微分</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantum_neural_network.html">量子神经网络</a></li>
</ul>
<p class="caption"><span class="caption-text">调试网络</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">使用PyNative模式调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">使用Dump功能在Graph模式调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">自定义调试信息</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="visualization_tutorials.html">使用可视化组件MindInsight</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="summary_record.html">收集Summary数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="dashboard.html">查看训练看板</a></li>
<li class="toctree-l2"><a class="reference internal" href="lineage_and_scalars_comparison.html">查看溯源和对比看板</a></li>
<li class="toctree-l2"><a class="reference internal" href="hyper_parameters_auto_tuning.html">使用mindoptimizer进行超参调优</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_profiling.html">性能调试</a></li>
<li class="toctree-l2"><a class="reference internal" href="debugger.html">使用调试器</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">解释模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">操作流程</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id4">准备脚本</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id5">使用限制</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mindinsight">启动MindInsight</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id6">页面及功能介绍</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id7">显著图可视化</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8">解释方法评估</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id11">不确定性</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id12">反事实</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id13">基于遮掩的反事实</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mindinsight_commands.html">MindInsight相关命令</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_augmentation.html">应用自动数据增强</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluate_the_model_during_training.html">训练时验证模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">算子增量编译</a></li>
</ul>
<p class="caption"><span class="caption-text">优化训练性能</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_tutorials.html">分布式并行训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">使能自动混合精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">使能图算融合</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">应用梯度累积算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_cache.html">应用单节点数据缓存</a></li>
</ul>
<p class="caption"><span class="caption-text">压缩模型</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">应用感知量化训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_post_training_quantization.html">应用训练后量化</a></li>
</ul>
<p class="caption"><span class="caption-text">模型安全和隐私</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">使用NAD算法提升模型安全性</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">应用差分隐私机制保护用户隐私</a></li>
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_suppress_privacy.html">应用抑制隐私机制保护用户隐私</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">使用fuzz testing模块测试模型安全性</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">使用成员推理测试模型安全性</a></li>
</ul>
<p class="caption"><span class="caption-text">应用实践</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">机器视觉</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">自然语言处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">高性能计算</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">在云上使用MindSpore</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="visualization_tutorials.html">使用可视化组件MindInsight</a> &raquo;</li>
        
      <li>解释模型</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/advanced_use/model_explanation.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="id1">
<h1>解释模型<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">模型调优</span></code> <code class="docutils literal notranslate"><span class="pre">初级</span></code> <code class="docutils literal notranslate"><span class="pre">中级</span></code> <code class="docutils literal notranslate"><span class="pre">高级</span></code></p>
<!-- TOC -->
<ul class="simple">
<li><p><a class="reference external" href="#%E8%A7%A3%E9%87%8A%E6%A8%A1%E5%9E%8B">解释模型</a></p>
<ul>
<li><p><a class="reference external" href="#%E6%A6%82%E8%BF%B0">概述</a></p></li>
<li><p><a class="reference external" href="#%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B">操作流程</a></p>
<ul>
<li><p><a class="reference external" href="#%E5%87%86%E5%A4%87%E8%84%9A%E6%9C%AC">准备脚本</a></p></li>
<li><p><a class="reference external" href="#%E4%BD%BF%E7%94%A8%E9%99%90%E5%88%B6">使用限制</a></p></li>
<li><p><a class="reference external" href="#%E5%90%AF%E5%8A%A8mindinsight">启动MindInsight</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#%E9%A1%B5%E9%9D%A2%E5%8F%8A%E5%8A%9F%E8%83%BD%E4%BB%8B%E7%BB%8D">页面及功能介绍</a></p>
<ul>
<li><p><a class="reference external" href="#%E6%98%BE%E8%91%97%E5%9B%BE%E5%8F%AF%E8%A7%86%E5%8C%96">显著图可视化</a></p></li>
<li><p><a class="reference external" href="#%E8%A7%A3%E9%87%8A%E6%96%B9%E6%B3%95%E8%AF%84%E4%BC%B0">解释方法评估</a></p>
<ul>
<li><p><a class="reference external" href="#%E7%BB%BC%E5%90%88%E8%AF%84%E4%BC%B0">综合评估</a></p></li>
<li><p><a class="reference external" href="#%E5%88%86%E7%B1%BB%E8%AF%84%E4%BC%B0">分类评估</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="#%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7">不确定性</a></p></li>
<li><p><a class="reference external" href="#%E5%8F%8D%E4%BA%8B%E5%AE%9E">反事实</a></p>
<ul>
<li><p><a class="reference external" href="#%E5%9F%BA%E4%BA%8E%E9%81%AE%E6%8E%A9%E7%9A%84%E5%8F%8D%E4%BA%8B%E5%AE%9E">基于遮掩的反事实</a></p>
<ul>
<li><p><a class="reference external" href="#%E5%9F%BA%E4%BA%8E%E9%81%AE%E6%8E%A9%E7%9A%84%E5%8F%8D%E4%BA%8B%E5%AE%9E%E4%BD%BF%E7%94%A8%E9%99%90%E5%88%B6">基于遮掩的反事实使用限制</a></p></li>
<li><p><a class="reference external" href="#%E5%9F%BA%E4%BA%8E%E9%81%AE%E6%8E%A9%E7%9A%84%E5%8F%8D%E4%BA%8B%E5%AE%9E%E9%A1%B5%E9%9D%A2%E5%8F%8A%E5%8A%9F%E8%83%BD%E4%BB%8B%E7%BB%8D">基于遮掩的反事实页面及功能介绍</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<!--/ TOC -->
<p><a href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/training/source_zh_cn/advanced_use/model_explanation.md" target="_blank"><img src="../_static/logo_source.png"></a></p>
<div class="section" id="id2">
<h2>概述<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>当前深度学习模型多为黑盒模型，性能表现好但可解释性较差。模型解释模块旨在为用户提供对模型决策依据的解释，帮助用户更好地理解模型、信任模型，以及当模型出现错误时有针对性地改进模型效果。</p>
<p>在一些影响至关重要的应用场景中，如自动驾驶、金融决策等，由于法律和政策监管的原因，AI模型如果不具备可解释性，是无法真正落地应用的。所以模型的可解释性的重要性越来越高，受到越来越多的关注。因此，模型解释是提升MindSpore生态应用性、用户友好性至关重要的一部分。</p>
<p>具体来说，在图片分类任务中，较为广泛使用的一类解释方法会将影响模型的分类决策最关键的区域高亮出来，我们称之为“显著图”，如果被高亮的部分恰好就是相应标签的关键特征，那么通常说明模型学习到的特征是正确的，用户可以更加信任模型的效果和决策。如果模型关注的是不相关的部分，即使预测标签是正确的，也不代表模型是可靠的，模型开发者还是需要优化改进模型。造成这种情况有可能是训练数据中存在某些特征的相关性，模型开发者可以考虑有针对性的做数据增强来修正模型学习到的偏见。</p>
<p>除了提供多种解释方法，我们还提供了一套对解释方法效果评分的度量方法，从多种维度评估解释方法的效果，从而帮助用户比较和选择最适合于特定场景的解释方法。</p>
</div>
<div class="section" id="id3">
<h2>操作流程<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id4">
<h3>准备脚本<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>当前MindSpore提供解释方法及给解释方法进行评估的度量Python API，已提供的解释方法可以通过<code class="docutils literal notranslate"><span class="pre">mindspore.explainer.explanation</span></code>包获取，度量方法可以通过<code class="docutils literal notranslate"><span class="pre">mindspore.explainer.benchmark</span></code>包获取。用户准备好待解释的黑盒模型和数据，在脚本中根据需要实例化解释方法及度量方法，调用API用于收集解释结果和解释度量结果。</p>
<p>MindSpore还提供<code class="docutils literal notranslate"><span class="pre">mindspore.explainer.ImageClassificationRunner</span></code>运行模块，支持自动化运行所有解释方法和度量方法。用户将实例化的解释方法及度量方法进行注册，即可自动运行解释方法及度量方法，并生成及保存包含解释结果及解释度量结果的解释日志。</p>
<p>下面以ResNet50及带有20类多标签数据为例，用户初始化<code class="docutils literal notranslate"><span class="pre">explanation</span></code>中解释方法及<code class="docutils literal notranslate"><span class="pre">benchmark</span></code>中度量方法，调用<code class="docutils literal notranslate"><span class="pre">ImageClassificationRunner</span></code>进行解释和度量。其样例代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>

<span class="kn">from</span> <span class="nn">mindspore.explainer.explanation</span> <span class="kn">import</span> <span class="n">GradCAM</span><span class="p">,</span> <span class="n">GuidedBackprop</span>
<span class="kn">from</span> <span class="nn">mindspore.explainer.benchmark</span> <span class="kn">import</span> <span class="n">Faithfulness</span><span class="p">,</span> <span class="n">Localization</span>
<span class="kn">from</span> <span class="nn">mindspore.explainer</span> <span class="kn">import</span> <span class="n">ImageClassificationRunner</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="c1"># please refer to model_zoo.cv.official.resnet.src.resnet50.py for the model architecture of resnet50</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>
    <span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50.ckpt&quot;</span><span class="p">)</span>
    <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>


    <span class="c1"># initialize explainers with the loaded black-box model</span>
    <span class="n">gradcam</span> <span class="o">=</span> <span class="n">GradCAM</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="s1">&#39;layer4&#39;</span><span class="p">)</span>
    <span class="n">guidedbackprop</span> <span class="o">=</span> <span class="n">GuidedBackprop</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

    <span class="c1"># initialize benchmarkers to evaluate the chosen explainers</span>
    <span class="c1"># for Faithfulness, the initialization needs an activation function that transforms the output of the network to a probability is also needed</span>
    <span class="n">activation_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>  <span class="c1"># for multi-label classification</span>
    <span class="n">faithfulness</span> <span class="o">=</span> <span class="n">Faithfulness</span><span class="p">(</span><span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;InsertionAUC&#39;</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">activation_fn</span><span class="p">)</span>
    <span class="n">localization</span> <span class="o">=</span> <span class="n">Localization</span><span class="p">(</span><span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;PointingGame&#39;</span><span class="p">)</span>

    <span class="c1"># returns the dataset to be explained, when localization is chosen, the dataset is required to provide bounding box</span>
    <span class="c1"># the columns of the dataset should be in [image], [image, labels], or [image, labels, bbox] (order matters)</span>
    <span class="c1"># You may refer to &#39;mindspore.dataset.project&#39; for columns managements</span>
    <span class="n">dataset_path</span> <span class="o">=</span> <span class="s2">&quot;dataset_dir&quot;</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">)</span>

    <span class="c1"># specify the class names of the dataset</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="p">[</span>
     <span class="s1">&#39;aeroplane&#39;</span><span class="p">,</span> <span class="s1">&#39;bicycle&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;boat&#39;</span><span class="p">,</span> <span class="s1">&#39;bottle&#39;</span><span class="p">,</span> <span class="s1">&#39;bus&#39;</span><span class="p">,</span> <span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span>
     <span class="s1">&#39;chair&#39;</span><span class="p">,</span> <span class="s1">&#39;cow&#39;</span><span class="p">,</span> <span class="s1">&#39;diningtable&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">,</span> <span class="s1">&#39;motorbike&#39;</span><span class="p">,</span> <span class="s1">&#39;person&#39;</span><span class="p">,</span>
     <span class="s1">&#39;pottedplant&#39;</span><span class="p">,</span> <span class="s1">&#39;sheep&#39;</span><span class="p">,</span> <span class="s1">&#39;sofa&#39;</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;tvmonitor&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
    <span class="n">explainers</span> <span class="o">=</span> <span class="p">[</span><span class="n">gradcam</span><span class="p">,</span> <span class="n">guidedbackprop</span><span class="p">]</span>
    <span class="n">benchmarkers</span> <span class="o">=</span> <span class="p">[</span><span class="n">faithfulness</span><span class="p">,</span> <span class="n">localization</span><span class="p">]</span>

    <span class="c1"># initialize runner with specified summary_dir</span>
    <span class="n">runner</span> <span class="o">=</span> <span class="n">ImageClassificationRunner</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">,</span> <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">activation_fn</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
    <span class="n">runner</span><span class="o">.</span><span class="n">register_saliency</span><span class="p">(</span><span class="n">explainers</span><span class="p">,</span> <span class="n">benchmarkers</span><span class="p">)</span>

    <span class="c1"># execute runner.run to generate explanation and evaluation results to save it to summary_dir</span>
    <span class="n">runner</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="id5">
<h3>使用限制<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>当前只支持图片分类下的CNN网络模型，比如：Lenet、Resnet、Alexnet。</p></li>
<li><p>输入的图片数据必须为单通道、三通道或四通道格式。</p></li>
<li><p>仅支持GPU和Ascend设备下的PyNative运行模式。</p></li>
<li><p>不同的 <code class="docutils literal notranslate"><span class="pre">ImageClassificationRunner</span></code> 对象需要使用不同的解释方法及度量方法对象，所以用户必须针对每个 <code class="docutils literal notranslate"><span class="pre">ImageClassificationRunner</span></code> 对象实例化独占的解释方法及度量方法对象，否则可能会产生错误。下方是一个正确的实例化示例。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gradcam</span> <span class="o">=</span> <span class="n">GradCAM</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="s1">&#39;layer4&#39;</span><span class="p">)</span>
<span class="n">guidedbackprop</span> <span class="o">=</span> <span class="n">GuidedBackprop</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

<span class="n">runner</span> <span class="o">=</span> <span class="n">ImageClassificationRunner</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir_1&#39;</span><span class="p">,</span> <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">activation_fn</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<span class="n">runner</span><span class="o">.</span><span class="n">register_saliency</span><span class="p">(</span><span class="n">explainers</span><span class="o">=</span><span class="p">[</span><span class="n">gradcam</span><span class="p">,</span> <span class="n">guidedbackprop</span><span class="p">])</span>
<span class="n">runner</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

<span class="c1"># generate another summary with GradCAM only</span>
<span class="n">runner2</span> <span class="o">=</span> <span class="n">ImageClassificationRunner</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir_2&#39;</span><span class="p">,</span> <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">activation_fn</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># reusing explainer instance in other runner, errors may occur</span>
<span class="c1"># runner2.register_saliency(explainers=[gradcam])</span>

<span class="c1"># instantiating a new GradCAM is the correct way</span>
<span class="n">gradcam2</span> <span class="o">=</span> <span class="n">GradCAM</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="s1">&#39;layer4&#39;</span><span class="p">)</span>
<span class="n">runner2</span><span class="o">.</span><span class="n">register_saliency</span><span class="p">(</span><span class="n">explainers</span><span class="o">=</span><span class="p">[</span><span class="n">gradcam2</span><span class="p">])</span>

<span class="n">runner2</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="mindinsight">
<h3>启动MindInsight<a class="headerlink" href="#mindinsight" title="Permalink to this headline">¶</a></h3>
<p>启动MindInsight系统，在顶部选择进入“模型解释”模块。可以看到所有的解释日志路径，当日志满足条件时，操作列会有“显著图可视化”的功能入口。</p>
<p><img alt="xai_index" src="../_images/xai_index.png" /></p>
</div>
</div>
<div class="section" id="id6">
<h2>页面及功能介绍<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id7">
<h3>显著图可视化<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>显著图可视化用于展示对模型决策结果影响最为显著的图片区域，通常高亮部分可视为图片被标记为目标分类的关键特征。</p>
<p><img alt="xai_saliency_map" src="../_images/xai_saliency_map.png" /></p>
<p>进入显著图可视化界面，会展示：</p>
<ul class="simple">
<li><p>用户通过Dataset的Python API接口设置的目标数据集。</p></li>
<li><p>真实标签、预测标签，以及模型对对应标签的预测概率。根据具体情况，系统会在对应标签的左上角增加TP，FN，FP（含义见界面提示信息）的旗标。</p></li>
<li><p>选中的解释方法给出的显著图。</p></li>
</ul>
<p>界面操作：</p>
<ol class="simple">
<li><p>通过界面上方的解释方法勾选需要的解释方法。</p></li>
<li><p>通过切换界面右上方的“叠加于原图”按钮可以选择让显著图叠加于原图上显示。</p></li>
<li><p>点击不同标签，显示模型对不同标签的显著图分析结果。对于不同的分类结果，通常模型的关注点也是不同的。</p></li>
<li><p>点选预测类型复选框，以显示具有已选类型的标签的图片：TP - 真阳性、 FN - 假阴性、 FP - 假阳性。</p></li>
<li><p>通过界面上方的标签筛选功能，筛选出指定标签图片。</p></li>
<li><p>通过界面右上角的图片排序改变图片显示的顺序，可选“概率值降序”或“不确定性值降序”。</p></li>
<li><p>点击解释方法最右边的“查看评分”，可以进入评估所有解释方法的界面。</p></li>
<li><p>点击图片可查看放大图。</p></li>
</ol>
<p><img alt="xai_saliency_map_detail" src="../_images/xai_saliency_map_detail.png" /></p>
</div>
<div class="section" id="id8">
<h3>解释方法评估<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id9">
<h4>综合评估<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h4>
<p>对当前提供的解释方法，从不同的评估维度进行评分。我们提供了多种评估度量维度，帮助用户对比不同解释方法在不同维度上的表现，从而挑选最适合用户使用的解释方法。用户可以根据对特定场景下看中的指标进行权重配置，得到综合得分。</p>
<p><img alt="xai_metrix_comprehensive" src="../_images/xai_metrix_comprehensive.png" /></p>
</div>
<div class="section" id="id10">
<h4>分类评估<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h4>
<p>分类评估页提供两种形式的对比，一种是同一解释方法的不同度量维度在各个标签下的分值，一种是对于同一度量维度，不同解释方法在各个标签下的分值。</p>
<p><img alt="xai_metrix_class" src="../_images/xai_metrix_class.png" /></p>
</div>
</div>
</div>
<div class="section" id="id11">
<h2>不确定性<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h2>
<p>模型决策结果存有不确定性, 名为 <a class="reference external" href="https://www.mindspore.cn/doc/api_python/zh-CN/r1.2/mindspore/nn_probability/mindspore.nn.probability.toolbox.UncertaintyEvaluation.html#mindspore.nn.probability.toolbox.UncertaintyEvaluation">Epistemic Uncertainty</a> 。计算方法是在模型中插入dropout层再多次重复推理，最后得出输出概率的标准偏差和95%置信区间：</p>
<p><img alt="xai_saliency_map" src="../_images/xai_uncertainty.png" /></p>
<p>模型和数据集的准备、使用限制跟前述的解释方法相同，用户通过调用 <code class="docutils literal notranslate"><span class="pre">ImageClassificationRunner</span></code> 的 <code class="docutils literal notranslate"><span class="pre">register_uncertainty()</span></code> 来启用不确定性计算，下方是一个使用例子。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">runner</span> <span class="o">=</span> <span class="n">ImageClassificationRunner</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir_1&#39;</span><span class="p">,</span> <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">activation_fn</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<span class="n">runner</span><span class="o">.</span><span class="n">register_saliency</span><span class="p">(</span><span class="n">explainers</span><span class="o">=</span><span class="p">[</span><span class="n">gradcam</span><span class="p">,</span> <span class="n">guidedbackprop</span><span class="p">])</span>
<span class="n">runner</span><span class="o">.</span><span class="n">register_uncertainty</span><span class="p">()</span>
<span class="n">runner</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre></div>
</div>
<p>要注意的是 <code class="docutils literal notranslate"><span class="pre">register_uncertainty()</span></code> 必须跟 <code class="docutils literal notranslate"><span class="pre">register_saliency()</span></code>一起使用，但调用次序没有限制。</p>
</div>
<div class="section" id="id12">
<h2>反事实<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h2>
<p>反事实是一种相对新的模型解释方法，是指对已得出的推理结果进行否定而重新表征。例如一张动物图片被模型分类为猫，我们可以通过解答反事实问题（例如：如何把这张图片进行编辑从而令其不会被模型分类为猫?）从而解释一个模型决策（例如：将这张图片分类为猫）。反事实解释存有不同的形式，<code class="docutils literal notranslate"><span class="pre">ImageClassificationRunner</span></code> 提供了一个容易使用的“基于遮掩的反事实（简称“HOC”）”接口。将来，会支持不同的反事实功能。</p>
<div class="section" id="id13">
<h3>基于遮掩的反事实<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p>HOC是一种基于遮掩的反事实方法，目的是在目标标签的预测概率高于阈值(暂固定为0.5)的约束条件下搜索出最小的图片显示区域。整个搜索是一个分层级的过程，首先把整个图片使用高斯模糊遮掩住，之后从最大的显示区块开始搜索，再深入搜索到更小的子区块以获得更精确的结果。最终我们会得到一个区块树，每一个节点代表一个正方形的显示区块，而子节点侧是在父节点范围内的更小的正方形显示区块。根节点代表了整个原始图片区域，而它的直接子节点就是第一层的显示区块。</p>
<p>目前，<code class="docutils literal notranslate"><span class="pre">ImageClassificationRunner</span></code> 会基于输入图片大小自动计算分层数量(一到三层)，显示区块大小，平移步幅及模糊遮掩图。第一层的显示区块边长为输入图片的短边的一半(向下舍入)，每下一层显示区块边长就会减半，最小为28个像素否则不会再增加下一层。平移步幅是显示区块边长的五分之一(向下舍入)。</p>
<p>模型和数据集的准备跟前述的解释方法相同，用户通过调用 <code class="docutils literal notranslate"><span class="pre">ImageClassificationRunner</span></code> 的 <code class="docutils literal notranslate"><span class="pre">register_hierarchical_occlusion()</span></code> 来启用HOC，下方是一个使用例子。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">runner</span> <span class="o">=</span> <span class="n">ImageClassificationRunner</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir_1&#39;</span><span class="p">,</span> <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">activation_fn</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<span class="n">runner</span><span class="o">.</span><span class="n">register_hierarchical_occlusion</span><span class="p">()</span>
<span class="n">runner</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre></div>
</div>
<p>用户可在同一个runner上配合使用 register_saliency() 。</p>
<div class="section" id="id14">
<h4>基于遮掩的反事实使用限制<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>包括所有前述的使用限制，但只支持三通道输入的模型。</p></li>
<li><p>图片数据必须为RGB三通道格式，短边的长度必须大于或等于56像素。</p></li>
<li><p>在只调用了<code class="docutils literal notranslate"><span class="pre">register_hierarchical_occlusion()</span></code>但没有调用<code class="docutils literal notranslate"><span class="pre">register_saliency()</span></code>的情况下，可以同时支持PyNative和Graph运行模式。</p></li>
</ul>
</div>
<div class="section" id="id15">
<h4>基于遮掩的反事实页面及功能介绍<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h4>
<p>可以看到在解释日志列表上所有使用了HOC功能的解释日志的”反事实解释”链接已经可被点击，点击后就会进入反事实页面。</p>
<p><img alt="xai_hoc_index" src="../_images/xai_hoc_index.png" /></p>
<p>基于遮掩的反事实解释页面展示了所有搜寻到的结果，包括：</p>
<ul class="simple">
<li><p>所有预测概率大于0.5的目标标签的样本及其原始图片。</p></li>
<li><p>目标标签的预测概率。</p></li>
<li><p>搜索过程中每个分层的结果图及其预测概率。</p></li>
</ul>
<p><img alt="xai_hoc" src="../_images/xai_hoc.png" /></p>
<p>界面操作：</p>
<ol class="simple">
<li><p>在左侧“图片列表”面板右上方有个“隐藏”开关，当开关开启时页面将会隐藏不含HOC解释结果的数据。开关默认为开启，用户可选择关闭以显示所有数据。</p></li>
<li><p>在左侧“图片列表”面板选择要显示样本的标签筛选及排序方法，可以选择使用预测概率排序。</p></li>
<li><p>在左侧“图片列表”面板流览样本或翻页，当点击了一个样本图片后，相关的HOC搜索结果会在其他的面板上显示。</p></li>
<li><p>在中央“原始图片”面板选择要显示的标签搜寻结果，只有预测概率大于0.5的标签才有HOC搜索结果。</p></li>
<li><p>在下方“逐层遮掩过程”面板检视搜寻过程的分层结果图，当点击了一张结果图后，它会被放大显示在右侧“查看解释”面板上。 (注意: 为了区分显示，已遮掩的区域被降低了亮度及转成了灰阶，但在实际的搜索中只是使用了高斯模糊作遮掩，并没有对亮度或彩度进行调整。)</p></li>
</ol>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="mindinsight_commands.html" class="btn btn-neutral float-right" title="MindInsight相关命令" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="debugger.html" class="btn btn-neutral float-left" title="使用调试器" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>