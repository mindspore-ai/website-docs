<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>训练看板和溯源 &mdash; MindSpore r0.5 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="性能调试" href="performance_profiling.html" />
    <link rel="prev" title="训练过程可视化" href="visualization_tutorials.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">实现一个图片分类应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">手把手安装和体验</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">使用指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation/data_preparation.html">准备数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">定义网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/saving_and_loading_model_parameters.html">模型参数的保存和加载</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/multi_platform_inference.html">多平台推理</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">应用实践</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="computer_vision_application.html">计算机视觉应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_application.html">自然语言处理应用</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型调优</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="debugging_in_pynative_mode.html">使用PyNative模式调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="customized_debugging_information.html">自定义调试信息</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="visualization_tutorials.html">训练过程可视化</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">训练看板和溯源</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">操作流程</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">准备训练脚本</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#summary">Summary数据收集</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id5">可视化组件</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id6">训练看板</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id12">模型溯源</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id13">数据溯源</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id14">对比看板</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id15">规格</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="performance_profiling.html">性能调试</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindinsight_commands.html">MindInsight相关命令</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">性能优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_tutorials.html">分布式并行训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed_precision.html">混合精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_kernel_fusion.html">图算融合</a></li>
<li class="toctree-l1"><a class="reference internal" href="aware_quantization.html">量化</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">端云使用</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">在云上使用MindSpore</a></li>
<li class="toctree-l1"><a class="reference internal" href="on_device_inference.html">端侧推理</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">网络迁移</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="network_migration.html">网络迁移</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI安全和隐私</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_security.html">模型安全</a></li>
<li class="toctree-l1"><a class="reference internal" href="differential_privacy.html">机器学习中的差分隐私</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="visualization_tutorials.html">训练过程可视化</a> &raquo;</li>
      <li>训练看板和溯源</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/advanced_use/dashboard_and_lineage.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1>训练看板和溯源<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r0.5/tutorials/source_zh_cn/advanced_use/dashboard_and_lineage.md" target="_blank"><img src="../_static/logo_source.png"></a>  
<a href="https://gitee.com/mindspore/docs/tree/r0.5/tutorials/notebook/mindinsight" target="_blank"><img src="../_static/logo_notebook.png"></a></p>
<section id="id2">
<h2>概述<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<p>训练过程中的标量、图像、计算图以及模型超参等信息记录到文件中，通过可视化界面供用户查看。</p>
</section>
<section id="id3">
<h2>操作流程<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>准备训练脚本，并在训练脚本中指定标量、图像、计算图、模型超参等信息记录到summary日志文件，接着运行训练脚本。</p></li>
<li><p>启动MindInsight，并通过启动参数指定summary日志文件目录，启动成功后，根据IP和端口访问可视化界面，默认访问地址为 <code class="docutils literal notranslate"><span class="pre">http://127.0.0.1:8080</span></code>。</p></li>
<li><p>在训练过程中，有数据写入summary日志文件时，即可在页面中查看可视的数据。</p></li>
</ul>
</section>
<section id="id4">
<h2>准备训练脚本<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h2>
<section id="summary">
<h3>Summary数据收集<a class="headerlink" href="#summary" title="Permalink to this headline"></a></h3>
<p>当前MindSpore支持将标量、图像、计算图、模型超参等信息保存到summary日志文件中，并通过可视化界面进行展示。</p>
<p>MindSpore目前支持三种方式将数据记录到summary日志文件中。</p>
<p><strong>方式一：通过 <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> 自动收集</strong></p>
<p>在MindSpore中通过 <code class="docutils literal notranslate"><span class="pre">Callback</span></code> 机制提供支持快速简易地收集一些常见的信息，包括计算图，损失值，学习率，参数权重等信息的 <code class="docutils literal notranslate"><span class="pre">Callback</span></code>, 叫做 <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code>。</p>
<p>在编写训练脚本时，仅需要实例化 <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code>，并将其应用到 <code class="docutils literal notranslate"><span class="pre">model.train</span></code> 或者 <code class="docutils literal notranslate"><span class="pre">model.eval</span></code> 中，
即可自动收集一些常见信息。<code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> 详细的用法可以参考 <code class="docutils literal notranslate"><span class="pre">API</span></code> 文档中 <code class="docutils literal notranslate"><span class="pre">mindspore.train.callback.SummaryCollector</span></code>。</p>
<p>样例代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">TruncatedNormal</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">SummaryCollector</span>

<span class="sd">&quot;&quot;&quot;AlexNet initial.&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">):</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span>
                     <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                     <span class="n">weight_init</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="n">pad_mode</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fc_with_initialize</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">weight_variable</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">TruncatedNormal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">)</span>  <span class="c1"># 0.02</span>


<span class="k">class</span> <span class="nc">AlexNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlexNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv5</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">MaxPool</span><span class="p">(</span><span class="n">ksize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">6</span><span class="o">*</span><span class="mi">6</span><span class="o">*</span><span class="mi">256</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv5</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">AlexNet</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">is_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>
<span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;./dataset_path&#39;</span><span class="p">)</span>

<span class="c1"># Init a SummaryCollector callback instance, and use it in model.train or model.eval</span>
<span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">,</span> <span class="n">collect_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Note: dataset_sink_mode should be set to False, else you should modify collect freq in SummaryCollector</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">ds_eval</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;./dataset_path&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">ds_eval</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">])</span>
</pre></div>
</div>
<p><strong>方式二：结合Summary算子和 <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code>，自定义收集网络中的数据</strong></p>
<p>MindSpore除了提供 <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code> 能够自动收集一些常见数据，还提供了Summary算子，支持在网络中自定义收集其他的数据，比如每一个卷积层的输入，或在损失函数中的损失值等。记录方式如下面的步骤所示。</p>
<p>步骤一：在继承 <code class="docutils literal notranslate"><span class="pre">nn.Cell</span></code> 的衍生类的 <code class="docutils literal notranslate"><span class="pre">construct</span></code> 函数中调用Summary算子来采集图像或标量数据或者其他数据。</p>
<p>比如，定义网络时，在网络的 <code class="docutils literal notranslate"><span class="pre">construct</span></code> 中记录图像数据；定义损失函数时，在损失函数的 <code class="docutils literal notranslate"><span class="pre">construct</span></code>中记录损失值。</p>
<p>如果要记录动态学习率，可以定义优化器时，在优化器的 <code class="docutils literal notranslate"><span class="pre">construct</span></code> 中记录学习率。</p>
<p>样例代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Optimizer</span>


<span class="k">class</span> <span class="nc">CrossEntropyLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Loss function definition.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CrossEntropyLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cross_entropy</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">OneHot</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># Init ScalarSummary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sm_scalar</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ScalarSummary</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">logits</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">label</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>

        <span class="c1"># Record loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sm_scalar</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>


<span class="k">class</span> <span class="nc">MyOptimizer</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimizer definition.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="o">......</span><span class="p">):</span>
        <span class="o">......</span>
        <span class="c1"># Initialize ScalarSummary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sm_scalar</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ScalarSummary</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">HistogramSummary</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="o">......</span>
        <span class="c1"># Record learning rate here</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sm_scalar</span><span class="p">(</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>

        <span class="c1"># Record weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">paramters</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1"># Record gradient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_summary</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;.gradient&quot;</span><span class="p">,</span> <span class="n">grads</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="o">......</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Net definition.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="o">......</span>

        <span class="c1"># Init ImageSummary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sm_image</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ImageSummary</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="c1"># Record image by Summary operator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sm_image</span><span class="p">(</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        <span class="o">......</span>
        <span class="k">return</span> <span class="n">out</span>

</pre></div>
</div>
<p>步骤二：在训练脚本中，实例化 <code class="docutils literal notranslate"><span class="pre">SummaryCollector</span></code>，并将其应用到 <code class="docutils literal notranslate"><span class="pre">model.train</span></code>。</p>
<p>样例代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">SummaryCollector</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">MyOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="n">train_ds</span> <span class="o">=</span> <span class="n">create_mindrecord_dataset_for_training</span><span class="p">()</span>

<span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">,</span> <span class="n">collect_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">train_ds</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">])</span>
</pre></div>
</div>
<p><strong>方式三：自定义Callback记录数据</strong></p>
<p>MindSpore支持自定义Callback, 并允许在自定义Callback中将数据记录到summary日志文件中，
并通过可视化页面进行查看。</p>
<p>下面的伪代码则展示在CNN网络中，开发者可以利用带有原始标签和预测标签的网络输出，生成混淆矩阵的图片,
然后通过 <code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code> 模块记录到summary日志文件中。
<code class="docutils literal notranslate"><span class="pre">SummaryRecord</span></code> 详细的用法可以参考 <code class="docutils literal notranslate"><span class="pre">API</span></code> 文档中 <code class="docutils literal notranslate"><span class="pre">mindspore.train.summary.SummaryRecord</span></code>。</p>
<p>样例代码如下：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">Callback</span>
<span class="kn">from</span> <span class="nn">mindspore.train.summary</span> <span class="kn">import</span> <span class="n">SummaryRecord</span>

<span class="k">class</span> <span class="nc">ConfusionMatrixCallback</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">summary_dir</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_summary_dir</span> <span class="o">=</span> <span class="n">summary_dir</span>
    
    <span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># init you summary record in here, when the train script run, it will be inited before training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span> <span class="o">=</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">summary_dir</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">exc_args</span><span class="p">):</span>
        <span class="c1"># Note: you must close the summary record, it will release the process pool resource</span>
        <span class="c1"># else your training script will not exit from training.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>

        <span class="c1"># create a confusion matric image, and record it to summary file</span>
        <span class="n">confusion_martrix</span> <span class="o">=</span> <span class="n">create_confusion_matrix</span><span class="p">(</span><span class="n">cb_params</span><span class="p">)</span>        
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s1">&#39;image&#39;</span><span class="p">,</span> <span class="s1">&#39;confusion_matrix&#39;</span><span class="p">,</span> <span class="n">confusion_matric</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step</span><span class="p">)</span>

<span class="c1"># init you train script</span>
<span class="o">...</span>

<span class="n">confusion_martrix</span> <span class="o">=</span> <span class="n">ConfusionMartrixCallback</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">cnn_network</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">confusion_martrix</span><span class="p">])</span>
</pre></div>
</div>
<p>上面的三种方式，支持记录计算图, 损失值等多种数据。除此以外，MindSpore还支持保存训练中其他阶段的计算图，通过
将训练脚本中 <code class="docutils literal notranslate"><span class="pre">context.set_context</span></code> 的 <code class="docutils literal notranslate"><span class="pre">save_graphs</span></code> 选项设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code>, 可以记录其他阶段的计算图，其中包括算子融合后的计算图。</p>
<p>在保存的文件中，<code class="docutils literal notranslate"><span class="pre">ms_output_after_hwopt.pb</span></code> 即为算子融合后的计算图，可以使用可视化页面对其进行查看。</p>
<blockquote>
<div><ul class="simple">
<li><p>目前MindSpore仅支持在Ascend 910 AI处理器上导出算子融合后的计算图。</p></li>
<li><p>在训练中使用Summary算子收集数据时，<code class="docutils literal notranslate"><span class="pre">HistogramSummary</span></code>算子会影响性能，所以请尽量少地使用。</p></li>
</ul>
</div></blockquote>
</section>
</section>
<section id="id5">
<h2>可视化组件<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h2>
<section id="id6">
<h3>训练看板<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<p>用户从训练列表中选择指定的训练，进入训练看板。</p>
<section id="id7">
<h4>标量可视化<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h4>
<p>标量可视化用于展示训练过程中，标量的变化趋势情况。</p>
<p><img alt="scalar.png" src="../_images/scalar.png" /></p>
<p>图1：标量趋势图</p>
<p>图1展示了神经网络在训练过程中损失值的变化过程。横坐标是训练步骤，纵坐标是损失值。</p>
<p>图中右上角有几个按钮功能，从左到右功能分别是全屏展示，切换Y轴比例，开启/关闭框选，分步回退和还原图形。</p>
<ul class="simple">
<li><p>全屏展示即全屏展示该标量曲线，再点击一次即可恢复。</p></li>
<li><p>切换Y轴比例是指可以将Y轴坐标进行对数转换。</p></li>
<li><p>开启/关闭框选是指可以框选图中部分区域，并放大查看该区域， 可以在已放大的图形上叠加框选。</p></li>
<li><p>分步回退是指对同一个区域连续框选并放大查看时，可以逐步撤销操作。</p></li>
<li><p>还原图形是指进行了多次框选后，点击此按钮可以将图还原回原始状态。</p></li>
</ul>
<p><img alt="scalar_select.png" src="../_images/scalar_select.png" /></p>
<p>图2：标量可视化功能区</p>
<p>图2展示的标量可视化的功能区，提供了根据选择不同标签，水平轴的不同维度和平滑度来查看标量信息的功能。</p>
<ul class="simple">
<li><p>标签：提供了对所有标签进行多项选择的功能，用户可以通过勾选所需的标签，查看对应的标量信息。</p></li>
<li><p>水平轴：可以选择“步骤”、“相对时间”、“绝对时间”中的任意一项，来作为标量曲线的水平轴。</p></li>
<li><p>平滑度：可以通过调整平滑度，对标量曲线进行平滑处理。</p></li>
<li><p>标量合成：可以选中两条标量曲线进行合成并展示在一个图中，以方便对两条曲线进行对比或者查看合成后的图。</p></li>
</ul>
<p><img alt="scalar_compound.png" src="../_images/scalar_compound.png" /></p>
<p>图3：Accuracy和Loss的标量合成图</p>
<p>图3展示Accuracy曲线和Loss曲线的标量合成图。标量合成的功能区与标量可视化的功能区相似。其中与标量可视化功能区不一样的地方，在于标签选择时，标量合成功能最多只能同时选择两个标签，将其曲线合成并展示。</p>
</section>
<section id="id8">
<h4>参数分布图可视化<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h4>
<p>参数分布图用于将用户所指定的张量以直方图的形式进行展示。</p>
<p><img alt="histogram.png" src="../_images/histogram.png" /></p>
<p>图4: 直方图展示</p>
<p>图4将用户所记录的张量以直方图的形式进行展示。点击图中右上角，可以将图放大。</p>
<p><img alt="histogram_func.png" src="../_images/histogram_func.png" /></p>
<p>图5: 参数分布图功能区</p>
<p>图5展示参数分布图的功能区，包含以下内容:</p>
<ul class="simple">
<li><p>标签选择：提供了对所有标签进行多项选择的功能，用户可以通过勾选所需的标签，查看对应的直方图。</p></li>
<li><p>纵轴：可以选择<code class="docutils literal notranslate"><span class="pre">步骤</span></code>、<code class="docutils literal notranslate"><span class="pre">相对时间</span></code>、<code class="docutils literal notranslate"><span class="pre">绝对时间</span></code>中的任意一项，来作为直方图纵轴显示的数据。</p></li>
<li><p>视角：可以选择<code class="docutils literal notranslate"><span class="pre">正视</span></code>和<code class="docutils literal notranslate"><span class="pre">俯视</span></code>中的一种。<code class="docutils literal notranslate"><span class="pre">正视</span></code>是指从正面的角度查看直方图，此时不同步骤之间的数据会覆盖在一起。<code class="docutils literal notranslate"><span class="pre">俯视</span></code>是指偏移以45度角俯视直方图区域，这时可以呈现不同步骤之间数据的差异。</p></li>
</ul>
</section>
<section id="id9">
<h4>计算图可视化<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h4>
<p>计算图可视化用于展示计算图的图结构，数据流以及控制流的走向，支持展示summary日志文件与通过<code class="docutils literal notranslate"><span class="pre">context</span></code>的<code class="docutils literal notranslate"><span class="pre">save_graphs</span></code>参数导出的<code class="docutils literal notranslate"><span class="pre">pb</span></code>文件。</p>
<p><img alt="graph.png" src="../_images/graph.png" /></p>
<p>图6：计算图展示区</p>
<p>图6展示了计算图的网络结构。如图中所展示的，在展示区中，选中其中一个算子（图中圈红算子），可以看到该算子有两个输入和一个输出（实线代表算子的数据流走向）。</p>
<p><img alt="graph_sidebar.png" src="../_images/graph_sidebar.png" /></p>
<p>图7：计算图功能区</p>
<p>图7展示了计算图可视化的功能区，包含以下内容：</p>
<ul class="simple">
<li><p>文件选择框: 可以选择查看不同文件的计算图。</p></li>
<li><p>搜索框：可以对节点进行搜索，输入节点名称点击回车，即可展示该节点。</p></li>
<li><p>缩略图：展示整个网络图结构的缩略图，在查看超大图结构时，方便查看当前浏览的区域。</p></li>
<li><p>节点信息：展示选中的节点的基本信息，包括节点的名称、属性、输入节点、输出节点等信息。</p></li>
<li><p>图例：展示的是计算图中各个图标的含义。</p></li>
</ul>
</section>
<section id="id10">
<h4>数据图可视化<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h4>
<p>数据图可视化用于展示单次模型训练的数据处理和数据增强信息。</p>
<p><img alt="data_function.png" src="../_images/data_function.png" /></p>
<p>图8：数据图功能区</p>
<p>图8展示的数据图功能区包含以下内容：</p>
<ul class="simple">
<li><p>图例：展示数据溯源图中各个图标的含义。</p></li>
<li><p>数据处理流水线：展示训练所使用的数据处理流水线，可以选择图中的单个节点查看详细信息。</p></li>
<li><p>节点信息：展示选中的节点的基本信息，包括使用的数据处理和增强算子的名称、参数等。</p></li>
</ul>
</section>
<section id="id11">
<h4>图像可视化<a class="headerlink" href="#id11" title="Permalink to this headline"></a></h4>
<p>图像可视化用于展示用户所指定的图片。</p>
<p><img alt="image.png" src="../_images/image_vi.png" /></p>
<p>图9：图像可视化</p>
<p>图9展示通过滑动图中“步骤”滑条，查看不同步骤的图片。</p>
<p><img alt="image_function.png" src="../_images/image_function.png" /></p>
<p>图10：图像可视化功能区</p>
<p>图10展示图像可视化的功能区，提供了选择查看不同标签，不同亮度和不同对比度来查看图片信息。</p>
<ul class="simple">
<li><p>标签：提供了对所有标签进行多项选择的功能，用户可以通过勾选所需的标签，查看对应的图片信息。</p></li>
<li><p>亮度调整：可以调整所展示的所有图片亮度。</p></li>
<li><p>对比度调整：可以调整所展示的所有图片对比度。</p></li>
</ul>
</section>
</section>
<section id="id12">
<h3>模型溯源<a class="headerlink" href="#id12" title="Permalink to this headline"></a></h3>
<p>模型溯源可视化用于展示所有训练的模型参数信息。</p>
<p><img alt="image.png" src="../_images/lineage_label.png" /></p>
<p>图11：模型参数选择区</p>
<p>图11展示的模型参数选择区，列举了可供查看的模型参数标签。用户可以通过勾选所需的标签，查看相应的模型参数。</p>
<p><img alt="image.png" src="../_images/lineage_model_chart.png" /></p>
<p>图12：模型溯源功能区</p>
<p>图12展示的模型溯源功能区，图像化展示了模型的参数信息。用户可以通过选择列的特定区域，展示区域范围内的模型信息。</p>
<p><img alt="image.png" src="../_images/lineage_model_table.png" /></p>
<p>图13：模型列表</p>
<p>图13分组展示所有模型信息，用户可以按指定列进行升序或降序展示模型信息。</p>
</section>
<section id="id13">
<h3>数据溯源<a class="headerlink" href="#id13" title="Permalink to this headline"></a></h3>
<p>数据溯源可视化用于展示所有训练的数据处理和数据增强信息。</p>
<p><img alt="data_label.png" src="../_images/data_label.png" /></p>
<p>图14：数据处理和增强算子选择区</p>
<p>图14展示的数据处理和数据增强算子选择区，列举了可供查看的数据处理和增强算子的名称。用户可以通过勾选所需的标签，查看相应的参数等信息。</p>
<p><img alt="data_chart.png" src="../_images/data_chart.png" /></p>
<p>图15：数据溯源功能区</p>
<p>图15展示的数据溯源功能区，图像化展示了数据处理和数据增强使用的参数信息。用户可以通过选择列的特定区域，展示区域范围内的参数信息。</p>
<p><img alt="data_table.png" src="../_images/data_table.png" /></p>
<p>图16：数据溯源列表</p>
<p>图16展示所有模型训练的数据处理和数据增强信息。</p>
<blockquote>
<div><p>如果用户筛选模型溯源随后切换到数据溯源页面时，折线图将展示最新一次筛选过的模型溯源列。</p>
</div></blockquote>
</section>
<section id="id14">
<h3>对比看板<a class="headerlink" href="#id14" title="Permalink to this headline"></a></h3>
<p>对比看板可视用于多个训练之间的标量曲线对比。</p>
<p><img alt="multi_scalars.png" src="../_images/multi_scalars.png" /></p>
<p>图17: 标量对比曲线图</p>
<p>图17展示了多个训练之间的标量曲线对比效果，横坐标是训练步骤，纵坐标是标量值。</p>
<p>图中右上角有几个按钮功能，从左到右功能分别是全屏展示，切换Y轴比例，开启/关闭框选，分步回退和还原图形。</p>
<ul class="simple">
<li><p>全屏展示即全屏展示该标量曲线，再点击一次即可恢复。</p></li>
<li><p>切换Y轴比例是指可以将Y轴坐标进行对数转换。</p></li>
<li><p>开启/关闭框选是指可以框选图中部分区域，并放大查看该区域， 可以在已放大的图形上叠加框选。</p></li>
<li><p>分步回退是指对同一个区域连续框选并放大查看时，可以逐步撤销操作。</p></li>
<li><p>还原图形是指进行了多次框选后，点击此按钮可以将图还原回原始状态。</p></li>
</ul>
<p><img alt="multi_scalars_select.png" src="../_images/multi_scalars_select.png" /></p>
<p>图18：对比看板可视功能区</p>
<p>图18展示的对比看板可视的功能区，提供了根据选择不同训练或标签，水平轴的不同维度和平滑度来进行标量对比的功能。</p>
<ul class="simple">
<li><p>训练: 提供了对所有训练进行多项选择的功能，用户可以通过勾选或关键字筛选所需的训练。</p></li>
<li><p>标签：提供了对所有标签进行多项选择的功能，用户可以通过勾选所需的标签，查看对应的标量信息。</p></li>
<li><p>水平轴：可以选择“步骤”、“相对时间”、“绝对时间”中的任意一项，来作为标量曲线的水平轴。</p></li>
<li><p>平滑度：可以通过调整平滑度，对标量曲线进行平滑处理。</p></li>
</ul>
</section>
</section>
<section id="id15">
<h2>规格<a class="headerlink" href="#id15" title="Permalink to this headline"></a></h2>
<p>为了控制列出summary列表的用时，MindInsight最多支持发现999个summary列表条目。</p>
<p>为了控制内存占用，MindInsight对标签（tag）数目和步骤（step）数目进行了限制：</p>
<ul class="simple">
<li><p>每个训练看板的最大标签数量为300个标签。标量标签、图片标签、计算图标签、参数分布图（直方图）标签的数量总和不得超过300个。特别地，每个训练看板最多有10个计算图标签。当实际标签数量超过这一限制时，将依照MindInsight的处理顺序，保留最近处理的300个标签。</p></li>
<li><p>每个训练看板的每个标量标签最多有1000个步骤的数据。当实际步骤的数目超过这一限制时，将对数据进行随机采样，以满足这一限制。</p></li>
<li><p>每个训练看板的每个图片标签最多有10个步骤的数据。当实际步骤的数目超过这一限制时，将对数据进行随机采样，以满足这一限制。</p></li>
<li><p>每个训练看板的每个参数分布图（直方图）标签最多有50个步骤的数据。当实际步骤的数目超过这一限制时，将对数据进行随机采样，以满足这一限制。</p></li>
</ul>
<p>出于性能上的考虑，MindInsight对比看板使用缓存机制加载训练的标量曲线数据，并进行以下限制：</p>
<ul class="simple">
<li><p>对比看板只支持在缓存中的训练进行比较标量曲线对比。</p></li>
<li><p>缓存最多保留最新（按修改时间排列）的15个训练。</p></li>
<li><p>用户最多同时对比5个训练的标量曲线。</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="visualization_tutorials.html" class="btn btn-neutral float-left" title="训练过程可视化" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="performance_profiling.html" class="btn btn-neutral float-right" title="性能调试" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>