

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ResNet-50二阶优化实践 &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="同步训练和验证模型" href="synchronization_training_and_evaluation.html" />
    <link rel="prev" title="自然语言处理应用" href="nlp_application.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/linear_regression.html">实现简单线性函数拟合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_start.html">实现一个图片分类应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/quick_video.html">手把手安装和体验</a></li>
</ul>
<p class="caption"><span class="caption-text">使用指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation/data_preparation.html">准备数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">定义网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/saving_and_loading_model_parameters.html">模型参数的保存和加载</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/multi_platform_inference.html">多平台推理</a></li>
</ul>
<p class="caption"><span class="caption-text">应用实践</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="computer_vision_application.html">计算机视觉应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_application.html">自然语言处理应用</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">ResNet-50二阶优化实践</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">概述</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">示例代码目录结构</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id3">准备环节</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id4">准备数据集</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">配置分布式环境变量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#ascend-910">Ascend 910</a></li>
<li class="toctree-l4"><a class="reference internal" href="#gpu">GPU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id6">加载处理数据集</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id7">定义网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="#thor">定义损失函数及THOR优化器</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id8">定义损失函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id9">定义优化器</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id10">训练网络</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id11">配置模型保存</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id12">配置训练网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id13">运行脚本</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id14">Ascend 910</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id16">模型推理</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id17">定义推理网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id18">执行推理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id19">Ascend 910</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id20">GPU</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="synchronization_training_and_evaluation.html">同步训练和验证模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="bert_poetry.html">智能写诗</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimize_the_performance_of_data_preparation.html">优化数据准备的性能</a></li>
<li class="toctree-l1"><a class="reference internal" href="mobilenetv2_incremental_learning.html">MobileNetV2 增量学习</a></li>
</ul>
<p class="caption"><span class="caption-text">模型调优</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debugging_in_pynative_mode.html">使用PyNative模式调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="customized_debugging_information.html">自定义调试信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization_tutorials.html">训练过程可视化</a></li>
</ul>
<p class="caption"><span class="caption-text">性能优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_tutorials.html">分布式并行训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed_precision.html">混合精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_kernel_fusion.html">图算融合</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization_aware.html">量化</a></li>
<li class="toctree-l1"><a class="reference internal" href="gradient_accumulation.html">梯度累积</a></li>
</ul>
<p class="caption"><span class="caption-text">推理服务</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="serving.html">基于MindSpore部署推理服务</a></li>
</ul>
<p class="caption"><span class="caption-text">端云使用</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">在云上使用MindSpore</a></li>
</ul>
<p class="caption"><span class="caption-text">网络迁移</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="network_migration.html">网络迁移</a></li>
</ul>
<p class="caption"><span class="caption-text">AI安全和隐私</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_security.html">模型安全</a></li>
<li class="toctree-l1"><a class="reference internal" href="differential_privacy.html">机器学习中的差分隐私</a></li>
<li class="toctree-l1"><a class="reference internal" href="fuzzer.html">AI模型安全测试</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>ResNet-50二阶优化实践</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/advanced_use/second_order_optimizer_for_resnet50_application.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="resnet-50">
<h1>ResNet-50二阶优化实践<a class="headerlink" href="#resnet-50" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">模型开发</span></code> <code class="docutils literal notranslate"><span class="pre">模型调优</span></code> <code class="docutils literal notranslate"><span class="pre">高级</span></code></p>
<!-- TOC --><ul class="simple">
<li><p><a class="reference external" href="#resnet-50%E4%BA%8C%E9%98%B6%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5">ResNet-50二阶优化实践</a></p>
<ul>
<li><p><a class="reference external" href="#%E6%A6%82%E8%BF%B0">概述</a></p></li>
<li><p><a class="reference external" href="#%E5%87%86%E5%A4%87%E7%8E%AF%E8%8A%82">准备环节</a></p>
<ul>
<li><p><a class="reference external" href="#%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86">准备数据集</a></p></li>
<li><p><a class="reference external" href="#%E9%85%8D%E7%BD%AE%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">配置分布式环境变量</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#%E5%8A%A0%E8%BD%BD%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E9%9B%86">加载处理数据集</a></p></li>
<li><p><a class="reference external" href="#%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C">定义网络</a></p></li>
<li><p><a class="reference external" href="#%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%8Athor%E4%BC%98%E5%8C%96%E5%99%A8">定义损失函数及THOR优化器</a></p>
<ul>
<li><p><a class="reference external" href="#%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0">定义损失函数</a></p></li>
<li><p><a class="reference external" href="#%E5%AE%9A%E4%B9%89%E4%BC%98%E5%8C%96%E5%99%A8">定义优化器</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#%E8%AE%AD%E7%BB%83%E7%BD%91%E7%BB%9C">训练网络</a></p>
<ul>
<li><p><a class="reference external" href="#%E9%85%8D%E7%BD%AE%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98">配置模型保存</a></p></li>
<li><p><a class="reference external" href="#%E9%85%8D%E7%BD%AE%E8%AE%AD%E7%BB%83%E7%BD%91%E7%BB%9C">配置训练网络</a></p></li>
<li><p><a class="reference external" href="#%E8%BF%90%E8%A1%8C%E8%84%9A%E6%9C%AC">运行脚本</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86">模型推理</a></p></li>
</ul>
</li>
</ul>
<!-- /TOC --><p><a href="https://gitee.com/mindspore/docs/blob/r0.7/tutorials/source_zh_cn/advanced_use/second_order_optimizer_for_resnet50_application.md" target="_blank"><img src="../_static/logo_source.png"></a>  </p>
<div class="section" id="id1">
<h2>概述<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>常见的优化算法可分为一阶优化算法和二阶优化算法。经典的一阶优化算法如SGD等，计算量小、计算速度快，但是收敛的速度慢，所需的迭代次数多。而二阶优化算法使用目标函数的二阶导数来加速收敛，能更快地收敛到模型最优值，所需要的迭代次数少，但由于二阶优化算法过高的计算成本，导致其总体执行时间仍然慢于一阶，故目前在深度神经网络训练中二阶优化算法的应用并不普遍。二阶优化算法的主要计算成本在于二阶信息矩阵（Hessian矩阵、<a class="reference external" href="https://arxiv.org/pdf/1808.07172.pdf">FIM矩阵</a>等）的求逆运算，时间复杂度约为$O(n^3)$。</p>
<p>MindSpore开发团队在现有的自然梯度算法的基础上，对FIM矩阵采用近似、切分等优化加速手段，极大的降低了逆矩阵的计算复杂度，开发出了可用的二阶优化器THOR。使用8块Ascend 910 AI处理器，THOR可以在72min内完成ResNet50-v1.5网络和ImageNet数据集的训练，相比于SGD+Momentum速度提升了近一倍。</p>
<p>本篇教程将主要介绍如何在Ascend 910 以及GPU上，使用MindSpore提供的二阶优化器THOR训练ResNet50-v1.5网络和ImageNet数据集。</p>
<blockquote>
<div><p>你可以在这里下载完整的示例代码：
<a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r0.7/model_zoo/official/cv/resnet_thor">https://gitee.com/mindspore/mindspore/tree/r0.7/model_zoo/official/cv/resnet_thor</a> 。</p>
</div></blockquote>
<div class="section" id="id2">
<h3>示例代码目录结构<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>├── resnet_thor
    ├── README.md
    ├── scripts                     
        ├── run_distribute_train.sh         <span class="c1"># launch distributed training for Ascend 910</span>
        └── run_eval.sh                     <span class="c1"># launch inference for Ascend 910</span>
        ├── run_distribute_train_gpu.sh     <span class="c1"># launch distributed training for GPU</span>
        └── run_eval_gpu.sh                 <span class="c1"># launch inference for GPU</span>
    ├── src                                  
        ├── crossentropy.py                 <span class="c1"># CrossEntropy loss function</span>
        ├── config.py                       <span class="c1"># parameter configuration</span>
        ├── dataset_helper.py               <span class="c1"># dataset helper for minddata dataset</span>
        ├── grad_reducer_thor.py            <span class="c1"># grad reduce for thor</span>
        ├── model_thor.py                   <span class="c1"># model for train</span>
        ├── resnet_thor.py                  <span class="c1"># resnet50_thor backone</span>
        ├── thor.py                         <span class="c1"># thor optimizer</span>
        ├── thor_layer.py                   <span class="c1"># thor layer</span>
        └── dataset.py                      <span class="c1"># data preprocessing    </span>
    ├── eval.py                             <span class="c1"># infer script</span>
    └── train.py                            <span class="c1"># train script</span>
    
</pre></div>
</div>
<p>整体执行流程如下：</p>
<ol class="simple">
<li><p>准备ImageNet数据集，处理需要的数据集；</p></li>
<li><p>定义ResNet50网络；</p></li>
<li><p>定义损失函数和THOR优化器；</p></li>
<li><p>加载数据集并进行训练，训练完成后，查看结果及保存模型文件；</p></li>
<li><p>加载保存的模型，进行推理。</p></li>
</ol>
</div>
</div>
<div class="section" id="id3">
<h2>准备环节<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>实践前，确保已经正确安装MindSpore。如果没有，可以通过<a class="reference external" href="https://www.mindspore.cn/install">MindSpore安装页面</a>安装MindSpore。</p>
<div class="section" id="id4">
<h3>准备数据集<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>下载完整的ImageNet2012数据集，将数据集解压分别存放到本地工作区的<code class="docutils literal notranslate"><span class="pre">ImageNet2012/ilsvrc</span></code>、<code class="docutils literal notranslate"><span class="pre">ImageNet2012/ilsvrc_eval</span></code>路径下。</p>
<p>目录结构如下：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>└─ImageNet2012
    ├─ilsvrc
    │      n03676483/
    │      n04067472/
    │      n01622779/
    │      ......
    └─ilsvrc_eval
    │      n03018349/
    │      n02504013
    │      n07871810
    │      ......
</pre></div>
</div>
</div>
<div class="section" id="id5">
<h3>配置分布式环境变量<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<div class="section" id="ascend-910">
<h4>Ascend 910<a class="headerlink" href="#ascend-910" title="Permalink to this headline">¶</a></h4>
<p>Ascend 910 AI处理器的分布式环境变量配置参考<a class="reference external" href="https://www.mindspore.cn/tutorial/zh-CN/r0.7/advanced_use/distributed_training_ascend.html#id4">分布式并行训练 (Ascend)</a>。</p>
</div>
<div class="section" id="gpu">
<h4>GPU<a class="headerlink" href="#gpu" title="Permalink to this headline">¶</a></h4>
<p>GPU的分布式环境配置参考<a class="reference external" href="https://www.mindspore.cn/tutorial/zh-CN/r0.7/advanced_use/distributed_training_gpu.html#id4">分布式并行训练 (GPU)</a>。</p>
</div>
</div>
</div>
<div class="section" id="id6">
<h2>加载处理数据集<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p>分布式训练时，通过并行的方式加载数据集，同时通过MindSpore提供的数据增强接口对数据集进行处理。加载处理数据集的脚本在源码的<code class="docutils literal notranslate"><span class="pre">src/dataset.py</span></code>脚本中。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore.common.dtype</span> <span class="k">as</span> <span class="nn">mstype</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.engine</span> <span class="k">as</span> <span class="nn">de</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.transforms.vision.c_transforms</span> <span class="k">as</span> <span class="nn">C</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.transforms.c_transforms</span> <span class="k">as</span> <span class="nn">C2</span>
<span class="kn">from</span> <span class="nn">mindspore.communication.management</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span><span class="p">,</span> <span class="n">get_group_size</span>

<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">do_train</span><span class="p">,</span> <span class="n">repeat_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;Ascend&quot;</span><span class="p">:</span>
        <span class="n">device_num</span><span class="p">,</span> <span class="n">rank_id</span> <span class="o">=</span> <span class="n">_get_rank_info</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">init</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>
        <span class="n">rank_id</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
        <span class="n">device_num</span> <span class="o">=</span> <span class="n">get_group_size</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">device_num</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">de</span><span class="o">.</span><span class="n">ImageFolderDatasetV2</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">de</span><span class="o">.</span><span class="n">ImageFolderDatasetV2</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                     <span class="n">num_shards</span><span class="o">=</span><span class="n">device_num</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="n">rank_id</span><span class="p">)</span>

    <span class="n">image_size</span> <span class="o">=</span> <span class="mi">224</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.485</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.456</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.406</span> <span class="o">*</span> <span class="mi">255</span><span class="p">]</span>
    <span class="n">std</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.229</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.224</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.225</span> <span class="o">*</span> <span class="mi">255</span><span class="p">]</span>
    <span class="c1"># define map operations</span>
    <span class="k">if</span> <span class="n">do_train</span><span class="p">:</span>
        <span class="n">trans</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">C</span><span class="o">.</span><span class="n">RandomCropDecodeResize</span><span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.08</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">1.333</span><span class="p">)),</span>
            <span class="n">C</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">C</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">),</span>
            <span class="n">C</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
        <span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">trans</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">C</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span>
            <span class="n">C</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
            <span class="n">C</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
            <span class="n">C</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">),</span>
            <span class="n">C</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
        <span class="p">]</span>
    <span class="n">type_cast_op</span> <span class="o">=</span> <span class="n">C2</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">operations</span><span class="o">=</span><span class="n">trans</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">operations</span><span class="o">=</span><span class="n">type_cast_op</span><span class="p">)</span>

    <span class="c1"># apply batch operations</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># apply dataset repeat operation</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat_num</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ds</span>
</pre></div>
</div>
<blockquote>
<div><p>MindSpore支持进行多种数据处理和增强的操作，各种操作往往组合使用，具体可以参考<a class="reference external" href="https://www.mindspore.cn/tutorial/zh-CN/r0.7/use/data_preparation/data_processing_and_augmentation.html">数据处理与数据增强</a>章节。</p>
</div></blockquote>
</div>
<div class="section" id="id7">
<h2>定义网络<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<p>本示例中使用的网络模型为ResNet50-v1.5，先定义<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r0.7/model_zoo/official/cv/resnet/src/resnet.py">ResNet50网络</a>，然后使用二阶优化器自定义的算子替换<code class="docutils literal notranslate"><span class="pre">Conv2d</span></code>和
和<code class="docutils literal notranslate"><span class="pre">Dense</span></code>算子。定义好的网络模型在在源码<code class="docutils literal notranslate"><span class="pre">src/resnet_thor.py</span></code>脚本中，自定义的算子<code class="docutils literal notranslate"><span class="pre">Conv2d_thor</span></code>和<code class="docutils literal notranslate"><span class="pre">Dense_thor</span></code>在<code class="docutils literal notranslate"><span class="pre">src/thor_layer.py</span></code>脚本中。</p>
<ul class="simple">
<li><p>使用<code class="docutils literal notranslate"><span class="pre">Conv2d_thor</span></code>替换原网络模型中的<code class="docutils literal notranslate"><span class="pre">Conv2d</span></code></p></li>
<li><p>使用<code class="docutils literal notranslate"><span class="pre">Dense_thor</span></code>替换原网络模型中的<code class="docutils literal notranslate"><span class="pre">Dense</span></code></p></li>
</ul>
<blockquote>
<div><p>使用THOR自定义的算子<code class="docutils literal notranslate"><span class="pre">Conv2d_thor</span></code>和<code class="docutils literal notranslate"><span class="pre">Dense_thor</span></code>是为了保存模型训练中的二阶矩阵信息，新定义的网络与原网络模型的backbone一致。</p>
</div></blockquote>
<p>网络构建完成以后，在<code class="docutils literal notranslate"><span class="pre">__main__</span></code>函数中调用定义好的ResNet50：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="kn">from</span> <span class="nn">src.resnet_thor</span> <span class="kn">import</span> <span class="n">resnet50</span>
<span class="o">...</span>
<span class="n">f</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="c1"># define the net</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">class_num</span><span class="p">,</span> <span class="n">damping</span><span class="o">=</span><span class="n">damping</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">,</span>
                   <span class="n">frequency</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">frequency</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="o">...</span>
</pre></div>
</div>
</div>
<div class="section" id="thor">
<h2>定义损失函数及THOR优化器<a class="headerlink" href="#thor" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id8">
<h3>定义损失函数<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>MindSpore支持的损失函数有<code class="docutils literal notranslate"><span class="pre">SoftmaxCrossEntropyWithLogits</span></code>、<code class="docutils literal notranslate"><span class="pre">L1Loss</span></code>、<code class="docutils literal notranslate"><span class="pre">MSELoss</span></code>等。THOR优化器需要使用<code class="docutils literal notranslate"><span class="pre">SoftmaxCrossEntropyWithLogits</span></code>损失函数。</p>
<p>损失函数的实现步骤在<code class="docutils literal notranslate"><span class="pre">src/crossentropy.py</span></code>脚本中。这里使用了深度网络模型训练中的一个常用trick：label smoothing，通过对真实标签做平滑处理，提高模型对分类错误标签的容忍度，从而可以增加模型的泛化能力。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CrossEntropy</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;CrossEntropy&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smooth_factor</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CrossEntropy</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">onehot</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">OneHot</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">smooth_factor</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">smooth_factor</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_classes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ce</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logit</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">one_hot_label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">onehot</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">logit</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ce</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">one_hot_label</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
<p>在<code class="docutils literal notranslate"><span class="pre">__main__</span></code>函数中调用定义好的损失函数：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="kn">from</span> <span class="nn">src.crossentropy</span> <span class="kn">import</span> <span class="n">CrossEntropy</span>
<span class="o">...</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="c1"># define the loss function</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">use_label_smooth</span><span class="p">:</span>
        <span class="n">config</span><span class="o">.</span><span class="n">label_smooth_factor</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">CrossEntropy</span><span class="p">(</span><span class="n">smooth_factor</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">label_smooth_factor</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">class_num</span><span class="p">)</span>
    <span class="o">...</span>
</pre></div>
</div>
</div>
<div class="section" id="id9">
<h3>定义优化器<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>THOR优化器的参数更新公式如下：</p>
<p>$$ \theta^{t+1} = \theta^t + \alpha F^{-1}\nabla E$$</p>
<p>参数更新公式中各参数的含义如下：</p>
<ul class="simple">
<li><p>$\theta$：网络中的可训参数；</p></li>
<li><p>$t$：迭代次数；</p></li>
<li><p>$\alpha$：学习率值，参数的更新步长；</p></li>
<li><p>$F^{-1}$：FIM矩阵，在网络中计算获得；</p></li>
<li><p>$\nabla E$：一阶梯度值。</p></li>
</ul>
<p>从参数更新公式中可以看出，THOR优化器需要额外计算的是每一层的FIM矩阵，每一层的FIM矩阵就是之前在自定义的网络模型中计算获得的。FIM矩阵可以对每一层参数更新的步长和方向进行自适应的调整，加速收敛的同时可以降低调参的复杂度。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="k">if</span> <span class="n">args_opt</span><span class="o">.</span><span class="n">device_target</span> <span class="o">==</span> <span class="s2">&quot;Ascend&quot;</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">src.thor</span> <span class="kn">import</span> <span class="n">THOR</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">src.thor</span> <span class="kn">import</span> <span class="n">THOR_GPU</span> <span class="k">as</span> <span class="n">THOR</span>
<span class="o">...</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="c1"># learning rate setting</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">get_model_lr</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">lr_init</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">lr_decay</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">lr_end_epoch</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">decay_epochs</span><span class="o">=</span><span class="mi">39</span><span class="p">)</span>
    <span class="c1"># define the optimizer</span>
    <span class="n">net_opt</span> <span class="o">=</span> <span class="n">opt</span> <span class="o">=</span> <span class="n">THOR</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()),</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">lr</span><span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
               <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;matrix_A&#39;</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()),</span>
               <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;matrix_G&#39;</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()),</span>
               <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;A_inv_max&#39;</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()),</span>
               <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;G_inv_max&#39;</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()),</span>
               <span class="n">config</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">)</span>
    <span class="o">...</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id10">
<h2>训练网络<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id11">
<h3>配置模型保存<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<p>MindSpore提供了callback机制，可以在训练过程中执行自定义逻辑，这里使用框架提供的<code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code>函数。
<code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code>可以保存网络模型和参数，以便进行后续的fine-tuning操作。
<code class="docutils literal notranslate"><span class="pre">TimeMonitor</span></code>、<code class="docutils literal notranslate"><span class="pre">LossMonitor</span></code>是MindSpore官方提供的callback函数，可以分别用于监控训练过程中单步迭代时间和<code class="docutils literal notranslate"><span class="pre">loss</span></code>值的变化。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">TimeMonitor</span><span class="p">,</span> <span class="n">LossMonitor</span>
<span class="o">...</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="c1"># define callbacks</span>
    <span class="n">time_cb</span> <span class="o">=</span> <span class="n">TimeMonitor</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="n">step_size</span><span class="p">)</span>
    <span class="n">loss_cb</span> <span class="o">=</span> <span class="n">LossMonitor</span><span class="p">()</span>
    <span class="n">cb</span> <span class="o">=</span> <span class="p">[</span><span class="n">time_cb</span><span class="p">,</span> <span class="n">loss_cb</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">:</span>
        <span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">save_checkpoint_epochs</span> <span class="o">*</span> <span class="n">step_size</span><span class="p">,</span>
                                     <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">keep_checkpoint_max</span><span class="p">)</span>
        <span class="n">ckpt_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;resnet&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="n">ckpt_save_dir</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
        <span class="n">cb</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ckpt_cb</span><span class="p">]</span>
    <span class="o">...</span>
</pre></div>
</div>
</div>
<div class="section" id="id12">
<h3>配置训练网络<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p>通过MindSpore提供的<code class="docutils literal notranslate"><span class="pre">model.train</span></code>接口可以方便地进行网络的训练。THOR优化器通过降低二阶矩阵更新频率，来减少计算量，提升计算速度，故重新定义一个Model_Thor类，继承MindSpore提供的Model类。在Model_Thor类中增加二阶矩阵更新频率控制参数，用户可以通过调整该参数，优化整体的性能。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="kn">from</span> <span class="nn">mindspore.train.loss_scale_manager</span> <span class="kn">import</span> <span class="n">FixedLossScaleManager</span>
<span class="kn">from</span> <span class="nn">src.model_thor</span> <span class="kn">import</span> <span class="n">Model_Thor</span> <span class="k">as</span> <span class="n">Model</span>
<span class="o">...</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="n">loss_scale</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">drop_overflow_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;Ascend&quot;</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">amp_level</span><span class="o">=</span><span class="s1">&#39;O2&#39;</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">,</span>
                      <span class="n">keep_batchnorm_fp32</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">},</span> <span class="n">frequency</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">frequency</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">},</span>
                      <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O2&quot;</span><span class="p">,</span> <span class="n">keep_batchnorm_fp32</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">frequency</span><span class="p">)</span>
    <span class="o">...</span>
</pre></div>
</div>
</div>
<div class="section" id="id13">
<h3>运行脚本<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p>训练脚本定义完成之后，调<code class="docutils literal notranslate"><span class="pre">scripts</span></code>目录下的shell脚本，启动分布式训练进程。</p>
<div class="section" id="id14">
<h4>Ascend 910<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h4>
<p>目前MindSpore分布式在Ascend上执行采用单卡单进程运行方式，即每张卡上运行1个进程，进程数量与使用的卡的数量一致。其中，0卡在前台执行，其他卡放在后台执行。每个进程创建1个目录，目录名称为<code class="docutils literal notranslate"><span class="pre">train_parallel</span></code>+ <code class="docutils literal notranslate"><span class="pre">device_id</span></code>，用来保存日志信息，算子编译信息以及训练的checkpoint文件。下面以使用8张卡的分布式训练脚本为例，演示如何运行脚本：</p>
<p>使用以下命令运行脚本：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sh</span> <span class="n">run_distribute_train</span><span class="o">.</span><span class="n">sh</span> <span class="p">[</span><span class="n">RANK_TABLE_FILE</span><span class="p">]</span> <span class="p">[</span><span class="n">DATASET_PATH</span><span class="p">]</span> <span class="p">[</span><span class="n">DEVICE_NUM</span><span class="p">]</span>
</pre></div>
</div>
<p>脚本需要传入变量<code class="docutils literal notranslate"><span class="pre">RANK_TABLE_FILE</span></code>、<code class="docutils literal notranslate"><span class="pre">DATASET_PATH</span></code>和<code class="docutils literal notranslate"><span class="pre">DEVICE_NUM</span></code>，其中：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">RANK_TABLE_FILE</span></code>：组网信息文件的路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DATASET_PATH</span></code>：训练数据集路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DEVICE_NUM</span></code>: 实际的运行卡数。
其余环境变量请参考安装教程中的配置项。</p></li>
</ul>
<p>训练过程中loss打印示例如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>...
epoch: <span class="m">1</span> step: <span class="m">5004</span>, loss is <span class="m">4</span>.4182425
epoch: <span class="m">2</span> step: <span class="m">5004</span>, loss is <span class="m">3</span>.740064
epoch: <span class="m">3</span> step: <span class="m">5004</span>, loss is <span class="m">4</span>.0546017
epoch: <span class="m">4</span> step: <span class="m">5004</span>, loss is <span class="m">3</span>.7598825
epoch: <span class="m">5</span> step: <span class="m">5004</span>, loss is <span class="m">3</span>.3744206
......
epoch: <span class="m">40</span> step: <span class="m">5004</span>, loss is <span class="m">1</span>.6907625
epoch: <span class="m">41</span> step: <span class="m">5004</span>, loss is <span class="m">1</span>.8217756
epoch: <span class="m">42</span> step: <span class="m">5004</span>, loss is <span class="m">1</span>.6453942
...
</pre></div>
</div>
<p>训练完后，每张卡训练产生的checkpoint文件保存在各自训练目录下，<code class="docutils literal notranslate"><span class="pre">device_0</span></code>产生的checkpoint文件示例如下:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>└─train_parallel0
    ├─resnet-1_5004.ckpt
    ├─resnet-2_5004.ckpt
    │      ......
    ├─resnet-42_5004.ckpt
</pre></div>
</div>
<p>其中，
<code class="docutils literal notranslate"><span class="pre">*.ckpt</span></code>：指保存的模型参数文件。checkpoint文件名称具体含义：<em>网络名称</em>-<em>epoch数</em>_<em>step数</em>.ckpt。</p>
<div class="section" id="id15">
<h5>GPU<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h5>
<p>在GPU硬件平台上，MindSpore采用OpenMPI的<code class="docutils literal notranslate"><span class="pre">mpirun</span></code>进行分布式训练，进程创建1个目录，目录名称为<code class="docutils literal notranslate"><span class="pre">train_parallel</span></code>，用来保存日志信息和训练的checkpoint文件。下面以使用8张卡的分布式训练脚本为例，演示如何运行脚本：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sh</span> <span class="n">run_distribute_train_gpu</span><span class="o">.</span><span class="n">sh</span> <span class="p">[</span><span class="n">DATASET_PATH</span><span class="p">]</span> <span class="p">[</span><span class="n">DEVICE_NUM</span><span class="p">]</span>
</pre></div>
</div>
<p>脚本需要传入变量<code class="docutils literal notranslate"><span class="pre">DATASET_PATH</span></code>和<code class="docutils literal notranslate"><span class="pre">DEVICE_NUM</span></code>，其中：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">DATASET_PATH</span></code>：训练数据集路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DEVICE_NUM</span></code>: 实际的运行卡数。</p></li>
</ul>
<p>在GPU训练时，无需设置<code class="docutils literal notranslate"><span class="pre">DEVICE_ID</span></code>环境变量，因此在主训练脚本中不需要调用<code class="docutils literal notranslate"><span class="pre">int(os.getenv('DEVICE_ID'))</span></code>来获取卡的物理序号，同时<code class="docutils literal notranslate"><span class="pre">context</span></code>中也无需传入<code class="docutils literal notranslate"><span class="pre">device_id</span></code>。我们需要将device_target设置为GPU，并需要调用<code class="docutils literal notranslate"><span class="pre">init(&quot;nccl&quot;)</span></code>来使能NCCL。</p>
<p>训练过程中loss打印示例如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>...
epoch: <span class="m">1</span> step: <span class="m">5004</span>, loss is <span class="m">4</span>.3069
epoch: <span class="m">2</span> step: <span class="m">5004</span>, loss is <span class="m">3</span>.5695
epoch: <span class="m">3</span> step: <span class="m">5004</span>, loss is <span class="m">3</span>.5893
epoch: <span class="m">4</span> step: <span class="m">5004</span>, loss is <span class="m">3</span>.1987
epoch: <span class="m">5</span> step: <span class="m">5004</span>, loss is <span class="m">3</span>.3526
......
epoch: <span class="m">40</span> step: <span class="m">5004</span>, loss is <span class="m">1</span>.9482
epoch: <span class="m">41</span> step: <span class="m">5004</span>, loss is <span class="m">1</span>.8950
epoch: <span class="m">42</span> step: <span class="m">5004</span>, loss is <span class="m">1</span>.9023
...
</pre></div>
</div>
<p>训练完后，保存的模型文件示例如下:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>└─train_parallel
    ├─ckpt_0
        ├─resnet-1_5004.ckpt
        ├─resnet-2_5004.ckpt
    	│      ......
        ├─resnet-42_5004.ckpt
	......
    ├─ckpt_7
        ├─resnet-1_5004.ckpt
        ├─resnet-2_5004.ckpt
        │      ......
        ├─resnet-42_5004.ckpt
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="id16">
<h2>模型推理<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h2>
<p>使用训练过程中保存的checkpoint文件进行推理，验证模型的泛化能力。首先通过<code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code>接口加载模型文件，然后调用<code class="docutils literal notranslate"><span class="pre">Model</span></code>的<code class="docutils literal notranslate"><span class="pre">eval</span></code>接口对输入图片类别作出预测，再与输入图片的真实类别做比较，得出最终的预测精度值。</p>
<div class="section" id="id17">
<h3>定义推理网络<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>使用<code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code>接口加载模型文件。</p></li>
<li><p>使用<code class="docutils literal notranslate"><span class="pre">model.eval</span></code>接口读入测试数据集，进行推理。</p></li>
<li><p>计算得出预测精度值。</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="o">...</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="c1"># define net</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">class_num</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">add_flags_recursive</span><span class="p">(</span><span class="n">thor</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># load checkpoint</span>
    <span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">args_opt</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">)</span>
    <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">param_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;damping&quot;</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
            <span class="n">param_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># define model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;top_1_accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;top_5_accuracy&#39;</span><span class="p">})</span>
	
    <span class="c1"># eval model</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;result:&quot;</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="s2">&quot;ckpt=&quot;</span><span class="p">,</span> <span class="n">args_opt</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id18">
<h3>执行推理<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h3>
<p>推理网络定义完成之后，调用/scripts目录下的shell脚本，进行推理。</p>
<div class="section" id="id19">
<h4>Ascend 910<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h4>
<p>在Ascend 910硬件平台上，推理的执行命令如下：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sh</span> <span class="n">run_eval</span><span class="o">.</span><span class="n">sh</span> <span class="p">[</span><span class="n">DATASET_PATH</span><span class="p">]</span> <span class="p">[</span><span class="n">CHECKPOINT_PATH</span><span class="p">]</span>
</pre></div>
</div>
<p>脚本需要传入变量<code class="docutils literal notranslate"><span class="pre">DATASET_PATH</span></code>和<code class="docutils literal notranslate"><span class="pre">CHECKPOINT_PATH</span></code>，其中：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">DATASET_PATH</span></code>：推理数据集路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CHECKPOINT_PATH</span></code>: 保存的checkpoint路径。</p></li>
</ul>
<p>目前推理使用的是单卡（默认device 0）进行推理，推理的结果如下：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">result</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;top_5_accuracy&#39;</span><span class="p">:</span> <span class="mf">0.9295574583866837</span><span class="p">,</span> <span class="s1">&#39;top_1_accuracy&#39;</span><span class="p">:</span> <span class="mf">0.761443661971831</span><span class="p">}</span> <span class="n">ckpt</span><span class="o">=</span><span class="n">train_parallel0</span><span class="o">/</span><span class="n">resnet</span><span class="o">-</span><span class="mf">42_5004.</span><span class="n">ckpt</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">top_5_accuracy</span></code>：对于一个输入图片，如果预测概率排名前五的标签中包含真实标签，即认为分类正确；</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">top_1_accuracy</span></code>：对于一个输入图片，如果预测概率最大的标签与真实标签相同，即认为分类正确。</p></li>
</ul>
</div>
<div class="section" id="id20">
<h4>GPU<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h4>
<p>在GPU硬件平台上，推理的执行命令如下：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sh</span> <span class="n">run_eval_gpu</span><span class="o">.</span><span class="n">sh</span> <span class="p">[</span><span class="n">DATASET_PATH</span><span class="p">]</span> <span class="p">[</span><span class="n">CHECKPOINT_PATH</span><span class="p">]</span>
</pre></div>
</div>
<p>脚本需要传入变量<code class="docutils literal notranslate"><span class="pre">DATASET_PATH</span></code>和<code class="docutils literal notranslate"><span class="pre">CHECKPOINT_PATH</span></code>，其中：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">DATASET_PATH</span></code>：推理数据集路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CHECKPOINT_PATH</span></code>: 保存的checkpoint路径。</p></li>
</ul>
<p>推理的结果如下：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">result</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;top_5_accuracy&#39;</span><span class="p">:</span> <span class="mf">0.9281169974391805</span><span class="p">,</span> <span class="s1">&#39;top_1_accuracy&#39;</span><span class="p">:</span> <span class="mf">0.7593830025608195</span><span class="p">}</span> <span class="n">ckpt</span><span class="o">=</span><span class="n">train_parallel0</span><span class="o">/</span><span class="n">resnet</span><span class="o">-</span><span class="mf">42_5004.</span><span class="n">ckpt</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="synchronization_training_and_evaluation.html" class="btn btn-neutral float-right" title="同步训练和验证模型" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="nlp_application.html" class="btn btn-neutral float-left" title="自然语言处理应用" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, MindSpore

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>