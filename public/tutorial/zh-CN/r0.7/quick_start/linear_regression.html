<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>实现简单线性函数拟合 &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="实现一个图片分类应用" href="quick_start.html" />
    <link rel="prev" title="MindSpore教程" href="../index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">快速入门</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">实现简单线性函数拟合</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id2">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">环境准备</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id4">生成数据集</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id5">定义数据集生成函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">生成测试数据</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id7">定义前向传播网络</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id8">初始化网络模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id9">查看初始化的网络模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">定义损失函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id11">损失函数与网络结合</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id12">定义反向传播网络</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id13">实现梯度函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id14">反向传播更新权重</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id15">定义模型拟合过程可视化函数</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id16">执行训练</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id17">总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">实现一个图片分类应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_video.html">手把手安装和体验</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">使用指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../use/data_preparation/data_preparation.html">准备数据</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/defining_the_network.html">定义网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/saving_and_loading_model_parameters.html">模型参数的保存和加载</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use/multi_platform_inference.html">多平台推理</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">应用实践</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/computer_vision_application.html">计算机视觉应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/nlp_application.html">自然语言处理应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/second_order_optimizer_for_resnet50_application.html">ResNet-50二阶优化实践</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/synchronization_training_and_evaluation.html">同步训练和验证模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/bert_poetry.html">智能写诗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/optimize_the_performance_of_data_preparation.html">优化数据准备的性能</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/mobilenetv2_incremental_learning.html">MobileNetV2 增量学习</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型调优</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/debugging_in_pynative_mode.html">使用PyNative模式调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/customized_debugging_information.html">自定义调试信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/visualization_tutorials.html">训练过程可视化</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">性能优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/distributed_training_tutorials.html">分布式并行训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/mixed_precision.html">混合精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/graph_kernel_fusion.html">图算融合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/quantization_aware.html">量化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/gradient_accumulation.html">梯度累积</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">推理服务</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/serving.html">基于MindSpore部署推理服务</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">端云使用</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/use_on_the_cloud.html">在云上使用MindSpore</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">网络迁移</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/network_migration.html">网络迁移</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI安全和隐私</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/model_security.html">模型安全</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/differential_privacy.html">机器学习中的差分隐私</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_use/fuzzer.html">AI模型安全测试</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>实现简单线性函数拟合</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/quick_start/linear_regression.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1>实现简单线性函数拟合<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">全流程</span></code> <code class="docutils literal notranslate"><span class="pre">初级</span></code> <code class="docutils literal notranslate"><span class="pre">中级</span></code> <code class="docutils literal notranslate"><span class="pre">高级</span></code></p>
<p>作者：<a class="reference external" href="https://github.com/helloyesterday">杨奕</a>    编辑：<a class="reference external" href="https://gitee.com/lvmingfu">吕明赋</a></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r0.7/tutorials/source_zh_cn/quick_start/linear_regression.md" target="_blank"><img src="../_static/logo_source.png"></a>
  
<a href="https://gitee.com/mindspore/docs/blob/r0.7/tutorials/notebook/linear_regression.ipynb" target="_blank"><img src="../_static/logo_notebook.png"></a></p>
<section id="id2">
<h2>概述<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<p>回归问题算法通常是利用一系列属性来预测一个值，预测的值是连续的。例如给出一套房子的一些特征数据，如面积、卧室数等等来预测房价，利用最近一周的气温变化和卫星云图来预测未来的气温情况等。如果一套房子实际价格为500万元，通过回归分析的预测值为499万元，则认为这是一个比较好的回归分析。在机器学习问题中，常见的回归分析有线性回归、多项式回归、逻辑回归等。本例子介绍线性回归算法，并通过MindSpore进行线性回归AI训练体验。</p>
<p>主要流程如下：</p>
<ol class="arabic simple">
<li><p>生成数据集</p></li>
<li><p>定义前向传播网络</p></li>
<li><p>定义反向传播网络</p></li>
<li><p>定义线性拟合过程的可视化函数</p></li>
<li><p>执行训练</p></li>
</ol>
<p>本次样例源代码请参考：<a class="reference external" href="https://gitee.com/mindspore/docs/blob/r0.7/tutorials/tutorial_code/linear_regression.py">https://gitee.com/mindspore/docs/blob/r0.7/tutorials/tutorial_code/linear_regression.py</a>。</p>
</section>
<section id="id3">
<h2>环境准备<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h2>
<p>系统：Ubuntu18.04</p>
<p>MindSpore版本：GPU</p>
<p>设置MindSpore运行配置</p>
<p>第三方支持包：<code class="docutils literal notranslate"><span class="pre">matplotlib</span></code>，未安装此包的，可使用命令<code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">matplotlib</span></code>预先安装。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;GPU&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">PYNATIVE_MODE</span></code>：自定义调试模式。</p>
<p><code class="docutils literal notranslate"><span class="pre">device_target</span></code>：设置MindSpore的训练硬件为GPU。</p>
</section>
<section id="id4">
<h2>生成数据集<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h2>
<section id="id5">
<h3>定义数据集生成函数<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">get_data</span></code>用于生成训练数据集和测试数据集。由于拟合的是线性数据，假定要拟合的目标函数为：$y=2x+3$，那么我们需要的训练数据集应随机分布于函数周边，这里采用了$y=2x+3+noise$的方式生成，其中<code class="docutils literal notranslate"><span class="pre">noise</span></code>为遵循标准正态分布规律的随机数值。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
 
<span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">num</span><span class="p">,</span><span class="n">w</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">3.0</span><span class="p">):</span>
    <span class="n">np_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">num</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">np_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">num</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
        <span class="n">np_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">noise</span>
        <span class="n">np_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np_x</span><span class="p">,</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np_y</span><span class="p">,</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p>数据生成函数将有以下两个作用。</p>
<ol class="arabic simple">
<li><p>生成训练数据，对模型函数进行训练。</p></li>
<li><p>生成验证数据，在训练结束后，对模型函数进行精度验证。</p></li>
</ol>
</section>
<section id="id6">
<h3>生成测试数据<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<p>使用数据生成函数<code class="docutils literal notranslate"><span class="pre">get_data</span></code>随机生成50组验证数据，并可视化展示。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">eval_x</span><span class="p">,</span> <span class="n">eval_label</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">x1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">=</span> <span class="n">eval_x</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">eval_label</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Eval_data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>输出结果：</p>
<p><img alt="png" src="../_images/linear_regression_eval_datasets.png" /></p>
</section>
</section>
<section id="id7">
<h2>定义前向传播网络<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h2>
<section id="id8">
<h3>初始化网络模型<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h3>
<p>使用<code class="docutils literal notranslate"><span class="pre">nn.Dense</span></code>定义了网络模型，即为线性模型，</p>
<p>$$y=wx+b\tag{1}$$</p>
<p>其中，权重值$w$对应<code class="docutils literal notranslate"><span class="pre">weight</span></code>，$b$对应<code class="docutils literal notranslate"><span class="pre">bias</span></code>，并将其打印出来。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">TruncatedNormal</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">TruncatedNormal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">),</span><span class="n">TruncatedNormal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;weight:&quot;</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">default_input</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;bias:&quot;</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">default_input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p>输出结果：</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>weight: -0.00034249047 bias: -0.019308656
</pre></div>
</div>
</section>
<section id="id9">
<h3>查看初始化的网络模型<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h3>
<p>我们将验证数据集和初始化的模型函数可视化。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">default_input</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span> <span class="o">+</span> <span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">default_input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;blue&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Eval data and net&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>输出结果：</p>
<p><img alt="png" src="../_images/model_net_and_eval_datasets.png" /></p>
<p>红色的点：为之前生成的50组验证数据集。</p>
<p>蓝色的线：初始化的模型网络。</p>
</section>
<section id="id10">
<h3>定义损失函数<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h3>
<p>我们的网络模型表达式为：</p>
<p>$$h(x)=wx+b\tag{2}$$</p>
<p>一般地，数学上对线性回归模型采用均方差的方式来判断模型是否拟合得很好，即均方差的值$J(w)$值越小，函数模型便拟合得越好，验证数据代入后，预测得到的y值就越准确。公式2对应m个数据的均方差公式为：</p>
<p>$$J(w)=\frac{1}{m}\sum_{i=1}^m(h(x_i)-y^{(i)})^2\tag{3}$$</p>
<p>为了方便后续的计算，我们采用0.5倍的均方差的表达式来进行计算，均方差值整体缩小至0.5倍的计算方式对判断模型拟合的好坏没有影响。</p>
<p>$$J(w)=\frac{1}{2m}\sum_{i=1}^m(h(x_i)-y^{(i)})^2\tag{4}$$</p>
<p>公式4即为网络训练中的损失函数，其中参数：</p>
<ul class="simple">
<li><p>$J(w)$为均方差。</p></li>
<li><p>$m$为样本数据的数量。</p></li>
<li><p>$h(x_i)$为第$i$个数据的$x_i$值代入模型网络（公式2）后的预测值。</p></li>
<li><p>$y^{(i)}$为第$i$个数据中的$y$值（label值）。</p></li>
</ul>
<p>在MindSpore中定义损失函数的方法如下。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>

<span class="k">class</span> <span class="nc">MyLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">_Loss</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">reduction</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">square</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Square</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">data</span><span class="o">-</span><span class="n">label</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_loss</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>其中:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">nn.loss.loss._Loss</span></code>：是MindSpore自定义loss算子的一个基类。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">P.Square</span></code>：MindSpore训练的框架中的平方算子，算子需要注册过才能在框架的计算图中使用。</p></li>
</ul>
</section>
<section id="id11">
<h3>损失函数与网络结合<a class="headerlink" href="#id11" title="Permalink to this headline"></a></h3>
<p>接下来我们需要将loss函数的表达式和网络net关联在一起，在MindSpore中需要<code class="docutils literal notranslate"><span class="pre">nn.WithLossCell</span></code>，实现方法如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">MyLoss</span><span class="p">()</span>
<span class="n">loss_opeartion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">WithLossCell</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span> 
</pre></div>
</div>
<p>其中：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">net</span></code>：网络模型。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">criterion</span></code>：即为实例化的loss函数。</p></li>
</ul>
<p>上述从数据代入到计算出loss值的过程为AI训练中的前向传播过程。</p>
</section>
</section>
<section id="id12">
<h2>定义反向传播网络<a class="headerlink" href="#id12" title="Permalink to this headline"></a></h2>
<p>有了损失函数后，我们如何使得损失函数最小呢？我们可以将公式1代入到损失函数公式4中展开：</p>
<p>$$J(w,b)=\frac{1}{2m}\sum_{i=1}^m(wx_i+b-y^{(i)})^2\tag{5}$$</p>
<p>公式5可以将$J(w)$看作为凹函数，对权重值$w$微分可求得：</p>
<p>$$\frac{\partial{J(w)}}{\partial{w}}=\frac{1}{m}\sum_{i=1}^mx_i(wx_i+b-y^{(i)})\tag{6}$$</p>
<p>由凹函数的特性可以知道，当公式6等于0时，损失函数有最小值：</p>
<p>$$\sum_{i=1}^mx_i(wx_i+b-y^{(i)})=0\tag{7}$$</p>
<p>假设有一个$w_{min}$使得公式7成立。我们如何将初始的权重$w_{s}$逐步的变成$w_{min}$，在这里采取迭代法，也就是梯度下降方法</p>
<p>当权重$w_{s}&lt;w_{min}$，那么我们需要更新权重$w_{s}$的值，将其往右移动使得权重值$w_{s}$变大，增加量为$\Delta{w}$，其中：</p>
<p>$$\Delta{w}=\alpha\frac{\partial{J(w_{s})}}{\partial{w}}\tag{8}$$</p>
<p>公式8中：</p>
<p>$\alpha$：表示一个系数,即深度学习中的学习率learning_rate，一般设置为正数。</p>
<p>$\frac{\partial{J(w_{s})}}{\partial{w}}$：表示损失函数$J(w)$在$w_{s}$的导数，可以理解为在$w_{s}$处的梯度下降率即坡度，由凹函数的性质可知，由于$w_{s}&lt;w_{min}$，所以其值为负数。</p>
<p>公式8为负数，那么我们对权重值向右移动的更新公式即可以写为：</p>
<p>$$w_{ud}=w_{s}-\alpha\frac{\partial{J(w_{s})}}{\partial{w}}\tag{9}$$</p>
<p>$w_{ud}$：更新的后权重数值。</p>
<p>$w_{s}$：表示初始的权重。</p>
<p>当$w_{s}&gt;w_{min}$，权重值需要左移即权重值变小接近$w_{min}$，才能使得损失函数逐步的变小，由凹函数的性质可知，在$w_{s}$处的导数为正（损失函数在$w_{min}$右边单调上升），公式8的值为正。其权重的更新公式为：</p>
<p>$$w_{ud}=w_{s}-\alpha\frac{\partial{J(w_{s})}}{\partial{w}}\tag{10}$$</p>
<p>当$w_{s}=w_{min}$时，到$\frac{\partial{J(w_{s})}}{\partial{w}}$=0，即梯度消失，其表达式也可写为公式9的样式。</p>
<p>在考虑了全区间的情况后，可以得出权重$w$的更新公式即为：</p>
<p>$$w_{ud}=w_{s}-\alpha\frac{\partial{J(w_{s})}}{\partial{w}}\tag{11}$$</p>
<p>当权重$w$在更新的过程中假如临近$w_{min}$在增加或者减少一个$\Delta{w}$，从左边或者右边越过了$w_{min}$，公式11都会使权重往反的方向移动，那么最终$w_{s}$的值会在$w_{min}$附近来回迭代，在实际训练中我们也是这样采用迭代的方式取得最优权重$w$，使得损失函数无限逼近局部最小值。</p>
<p>同理：对于公式5中的另一个权重$b$容易得出其更新公式为：</p>
<p>$$b_{ud}=b_{s}-\alpha\frac{\partial{J(b_{s})}}{\partial{b}}\tag{12}$$</p>
<p>当所有的权重更新完成后，将新的权重赋值给初始权重：即$w_{s}$=$w_{ud}$，$b_{s}$=$b_{ud}$。将新的初始权重传递回到模型函数中，这样就完成了反向传播的过程。</p>
<blockquote>
<div><p>当遇到多项式的回归模型时，上述梯度方法也适用，由于权重数量的增加，需要将权重的名称更新为$w_0,w_1,w_2,…,w_n$，引入矩阵的表达方式，公式将会更加简洁，这里就不多介绍了。</p>
</div></blockquote>
<section id="id13">
<h3>实现梯度函数<a class="headerlink" href="#id13" title="Permalink to this headline"></a></h3>
<p>在MindSpore中的所有要编入计算图的类都需要继承<code class="docutils literal notranslate"><span class="pre">nn.Cell</span></code>算子。MindSpore的梯度计算函数采用如下方式。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">composite</span> <span class="k">as</span> <span class="n">C</span>

<span class="k">class</span> <span class="nc">GradWrap</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; GradWrap definition &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">ParameterTuple</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span>
            <span class="n">network</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="k">return</span> <span class="n">C</span><span class="o">.</span><span class="n">GradOperation</span><span class="p">(</span><span class="n">get_by_list</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> \
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">,</span> <span class="n">weights</span><span class="p">)(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

</pre></div>
</div>
<p>上述代码中<code class="docutils literal notranslate"><span class="pre">GradWrap</span></code>实现的是对各个权重的微分$\frac{\partial{J(w)}}{\partial{w}}$，其展开式子参考公式6。</p>
</section>
<section id="id14">
<h3>反向传播更新权重<a class="headerlink" href="#id14" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">nn.RMSProp</span></code>为完成权重更新的函数，更新方式大致为公式11，但是考虑的因素更多，具体信息请参考<a class="reference external" href="https://www.mindspore.cn/api/zh-CN/r0.7/api/python/mindspore/mindspore.nn.html?highlight=rmsprop#mindspore.nn.RMSProp">官网说明</a>。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_network</span> <span class="o">=</span> <span class="n">GradWrap</span><span class="p">(</span><span class="n">loss_opeartion</span><span class="p">)</span> 
<span class="n">train_network</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RMSProp</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
</pre></div>
</div>
<p>通过以上操作，我们就完成了前向传播网络和反向传播网络的定义，接下来可以加载训练数据进行线性拟合了。</p>
</section>
</section>
<section id="id15">
<h2>定义模型拟合过程可视化函数<a class="headerlink" href="#id15" title="Permalink to this headline"></a></h2>
<p>定义一个可视化函数<code class="docutils literal notranslate"><span class="pre">plot_model_and_datasets</span></code>，将模型函数和验证数据集打印出来，观察其变化。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span> 

<span class="k">def</span> <span class="nf">plot_model_and_datasets</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">data_x</span><span class="p">,</span> <span class="n">data_y</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="p">((</span><span class="n">weight</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span> <span class="o">+</span> <span class="p">((</span><span class="n">bias</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data_x</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">data_y</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;blue&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="o">-</span><span class="mi">11</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="mi">25</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.02</span><span class="p">)</span>
</pre></div>
</div>
<p>上述函数的参数：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">weight</span></code>：模型函数的权重，即$w$。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bias</span></code>：模型函数的权重，即$b$。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data_x</span></code>：训练数据的$x$值。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data_y</span></code>：训练数据的$y$值。</p></li>
</ul>
<blockquote>
<div><p>可视化过程中，红色的点是验证数据集，黑色的点是单个batch的训练数据，蓝色的线条是正在训练的回归模型。</p>
</div></blockquote>
</section>
<section id="id16">
<h2>执行训练<a class="headerlink" href="#id16" title="Permalink to this headline"></a></h2>
<p>其训练过程如下：</p>
<ol class="arabic simple">
<li><p>设置训练的迭代次数<code class="docutils literal notranslate"><span class="pre">step_size</span></code>。</p></li>
<li><p>设置单次迭代的训练数据量<code class="docutils literal notranslate"><span class="pre">batch_size</span></code>。</p></li>
<li><p>正向传播训练<code class="docutils literal notranslate"><span class="pre">grads</span></code>。</p></li>
<li><p>反向传播训练<code class="docutils literal notranslate"><span class="pre">optim</span></code>。</p></li>
<li><p>图形展示模型函数和数据集。</p></li>
<li><p>清除本轮迭代的输出<code class="docutils literal notranslate"><span class="pre">display.clear_output</span></code>，起到动态可视化效果。</p></li>
</ol>
<p>迭代完成后，输出网络模型的权重值$w$和$b$。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>

<span class="n">step_size</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">step_size</span><span class="p">):</span>
    <span class="n">data_x</span><span class="p">,</span><span class="n">data_y</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">train_network</span><span class="p">(</span><span class="n">data_x</span><span class="p">,</span><span class="n">data_y</span><span class="p">)</span> 
    <span class="n">optim</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
    <span class="n">plot_model_and_datasets</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">default_input</span><span class="p">,</span> 
                            <span class="n">net</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">default_input</span><span class="p">,</span> <span class="n">data_x</span><span class="p">,</span> <span class="n">data_y</span><span class="p">)</span>
    <span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">eval_x</span><span class="p">)</span>
<span class="n">loss_output</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">eval_label</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;loss_value:&quot;</span><span class="p">,</span> <span class="n">loss_output</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
<span class="n">plot_model_and_datasets</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">default_input</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">default_input</span><span class="p">,</span> <span class="n">data_x</span><span class="p">,</span><span class="n">data_y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;weight:&quot;</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">default_input</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;bias:&quot;</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">default_input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p>输出结果：</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>loss_value: 0.42879593
</pre></div>
</div>
<p><img alt="gif" src="../_images/linear_regression.gif" /></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>weight: 1.9990227 bias: 2.9115517
</pre></div>
</div>
<p>可以看到最终得到的线性拟合的权重值非常接近目标函数权重weight=2、bias=3。</p>
</section>
<section id="id17">
<h2>总结<a class="headerlink" href="#id17" title="Permalink to this headline"></a></h2>
<p>本次体验我们了解了线性拟合的算法原理，并在MindSpore框架下实现了相应的算法定义，了解了线性拟合这类的线性回归模型在MindSpore中的训练过程，并最终拟合出了一条接近目标函数的模型函数。另外有兴趣的可以调整数据集的生成区间从（-10,10）扩展到（-100,100），看看权重值是否更接近目标函数；调整学习率大小，看看拟合的效率是否有变化；当然也可以探索如何使用MindSpore拟合$f(x)=ax^2+bx+c$这类的二次函数或者更高次的函数。</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="MindSpore教程" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="quick_start.html" class="btn btn-neutral float-right" title="实现一个图片分类应用" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>