<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>序列到序列（seq2seq）模型实现文本翻译 &mdash; MindSpore master documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="动态图与静态图" href="../pynative_mode_and_graph_mode.html" />
    <link rel="prev" title="FastText实现文本分类" href="text_sentiment_ngrams_tutorial.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">入门教程</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">基本介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quick_start.html">初学入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor.html">张量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dataset.html">数据加载及处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model.html">建立神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autograd.html">自动微分</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization.html">优化模型参数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../save_load_model.html">保存及加载模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inference.html">推理</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">进阶教程</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../custom.html">自定义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../image_and_video.html">图像处理</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../text.html">自然语言</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="rnn_classification.html">使用字符级RNN分类名称</a></li>
<li class="toctree-l2"><a class="reference internal" href="rnn_generation.html">使用字符级RNN生成名称</a></li>
<li class="toctree-l2"><a class="reference internal" href="text_sentiment_ngrams_tutorial.html">FastText实现文本分类</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">序列到序列（seq2seq）模型实现文本翻译</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#multi30k">Multi30K数据集处理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">合并原始数据</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mindrecord">生成MindRecord</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id4">seq2seq模型定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id5">seq2seq模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="#attention">Attention机制</a></li>
<li class="toctree-l4"><a class="reference internal" href="#gru">GRU</a></li>
<li class="toctree-l4"><a class="reference internal" href="#teacher-forcing">Teacher Forcing机制</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id6">模型训练</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id7">包装网络与损失函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8">自定义单步训练</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id9">训练流程</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../pynative_mode_and_graph_mode.html">动态图与静态图</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed_training.html">分布式训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inference_and_deploy.html">推理与部署</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../text.html">自然语言</a> &raquo;</li>
      <li>序列到序列（seq2seq）模型实现文本翻译</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/intermediate/text/text_translation_gru_tutorial.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="seq2seq">
<h1>序列到序列（seq2seq）模型实现文本翻译<a class="headerlink" href="#seq2seq" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/source_zh_cn/intermediate/text/text_translation_gru_tutorial.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.2/resource/_static/logo_source.png"></a></p>
<p>本教程通过Multi30k数据集来训练序列到序列（seq2seq）模型，以此实现将德语句子翻译成英语的功能。该教程包含以下三个方面：</p>
<ul class="simple">
<li><p>如何对文本类数据集进行处理，并生成MindRecord格式的数据。</p></li>
<li><p>基于GRU网络搭建一个序列到序列（seq2seq）网络。</p></li>
<li><p>读取数据集进行网络训练。</p></li>
</ul>
<blockquote>
<div><p>注意：该教程环境为MindSpore1.2.0版本。</p>
</div></blockquote>
<p>通过该教程将学会MindSpore搭建nlp模型所需要的全部流程，下面将逐步解释实现过程。</p>
<p>运行教程需要下载<a class="reference external" href="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/intermediate/seq2seq.zip">seq2seq</a>，在教程的同级目录下新建seq2seq文件夹，将下载好的数据集按照文件结构放到相应目录下。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>seq2seq
│ train.py                 # 训练脚本
│ create_data.py          # MindRecord数据集生成脚本
│ create_vocab.py          # vocab文件生成脚本
│
└─ nltk_predata           # 数据集文件夹  
│
└─ src                     # 模型定义
│   │   lr_schedule.py     # 定义学习率
│   │   loss.py            # 定义损失函数
│   │   gru.py             # 定义GRU和BGRU网络
│   │   dataset.py         # 读取数据
│   │   gru_for_train.py   # 定义TrainOneStepCell
│   │   seq2seq.py         # 定义Seq2Seq网络
│   │   weight_init.py     # 定义权重
│
└─ nltk_mindrecord         # 存储MindRecord文件夹
│
└─ output        # 存储结果文件夹
</pre></div>
</div>
<p>此外还需要下载自然语言工具包 <code class="docutils literal notranslate"><span class="pre">nltk</span></code> ，可通过 <code class="docutils literal notranslate"><span class="pre">pip</span></code> 或 <code class="docutils literal notranslate"><span class="pre">conda</span></code> 完成安装：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">nltk</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">()</span>
</pre></div>
</div>
<blockquote>
<div><p>如果nltk下载失败，<a class="reference external" href="https://github.com/nltk/nltk_data">点击链接</a>手动下载。</p>
</div></blockquote>
<section id="multi30k">
<h2>Multi30K数据集处理<a class="headerlink" href="#multi30k" title="Permalink to this headline"></a></h2>
<p>在之前步骤中下载的Multi30K数据集由简单的英语、德语句子组成，现在需要将原始数据集进行处理，以便于后续的模型训练过程。</p>
<p>数据集的处理过程可以分为以下两步：</p>
<ul class="simple">
<li><p>合并原始Multi30K数据集</p></li>
<li><p>数据处理，生成MindRecord数据集</p></li>
</ul>
<p>完成这两步需要分别在 <code class="docutils literal notranslate"><span class="pre">seq2seq/</span></code> 路径下执行：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>create_vocab.py
</pre></div>
</div>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>create_data.py
</pre></div>
</div>
<p>执行后 <code class="docutils literal notranslate"><span class="pre">nltk_predata</span></code> 和 <code class="docutils literal notranslate"><span class="pre">nltk_mindrecord</span></code> 文件目录新增如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>│
└─ nltk_predata            # 数据集文件夹
│   │   all.de.tok
│   │   all.en.tok
│   │   test.en.tok
│   │   test.de.tok
│   │   vocab.en
│   │   vocab.dn
│   │   train.en.tok
│   │   train.de.tok
│   │   val.en.tok
│   │   val.de.tok
│
└─ nltk_mindrecord         # 存储MindRecord文件夹
│   │   mindrecord_32
│   │   mindrecord_32.db
</pre></div>
</div>
<section id="id1">
<h3>合并原始数据<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">create_vocab.py</span></code> 脚本初步处理了Multi30k数据集。数据集中保存的是原始语句，其中标点符号和大小写等语法习惯符合原始语言规则，例如：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>A young girl is on a ride at an amusement park.
</pre></div>
</div>
<p>现在需要将原始的语言规则剔除，统一使用小写，统一将符号与单词用空格分开。通过调用已安装的工具包 <code class="docutils literal notranslate"><span class="pre">nltk</span></code> 中的 <code class="docutils literal notranslate"><span class="pre">word_tokenize</span></code> ，可以方便地规范原始语句。定义 <code class="docutils literal notranslate"><span class="pre">create_tokenized_sentences</span></code> 函数实现这些功能：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_tokenized_sentences</span><span class="p">(</span><span class="n">input_files</span><span class="p">,</span> <span class="n">language</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;分隔原始语句&quot;&quot;&quot;</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">total_lines</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_files</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>

    <span class="c1"># 逐句处理</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">total_lines</span><span class="p">:</span>
        <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r\n</span><span class="s1"> &#39;</span><span class="p">)</span>
        <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="c1"># 根据语言进行分词</span>
        <span class="n">tokenize_sentence</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">language</span><span class="p">)</span>
        <span class="n">str_sentence</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokenize_sentence</span><span class="p">)</span>
        <span class="n">sentence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">str_sentence</span><span class="p">)</span>

    <span class="c1"># 写入到.tok文件中</span>
    <span class="n">tokenize_file</span> <span class="o">=</span> <span class="n">input_files</span> <span class="o">+</span> <span class="s2">&quot;.tok&quot;</span>
    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">tokenize_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>现在这句话变为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>a young girl is on a ride at an amusement park .
</pre></div>
</div>
<p>经过之前的操作，生成了原始文件的 <code class="docutils literal notranslate"><span class="pre">*.tok</span></code> 形式。为了以后拆分与处理数据，定义 <code class="docutils literal notranslate"><span class="pre">merge_text</span></code> 函数将全部数据以新数据 <code class="docutils literal notranslate"><span class="pre">all_de.tok</span></code> ， <code class="docutils literal notranslate"><span class="pre">all_en.tok</span></code> 的形式处理保存。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">merge_text</span><span class="p">(</span><span class="n">root_dir</span><span class="p">,</span> <span class="n">file_list</span><span class="p">,</span> <span class="n">output_file</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; 合并文本文件 &quot;&quot;&quot;</span>
    <span class="n">output_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_dir</span><span class="p">,</span> <span class="n">output_file</span><span class="p">)</span>
    <span class="n">f_output</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span>

    <span class="c1"># 写入tok文件</span>
    <span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">file_list</span><span class="p">:</span>
        <span class="n">text_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_dir</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;.tok&quot;</span>
        <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">text_path</span><span class="p">)</span>
        <span class="n">f_output</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">f_output</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>然后创建”vocab.de”，”vocab.en”两个词频表，通过 <code class="docutils literal notranslate"><span class="pre">get_dataset_vocab</span></code> 函数统计单词在语句中出现的频率：</p>
<ul class="simple">
<li><p>统计每个句子中词语的频率。</p></li>
<li><p>将标志符写入词频表。</p></li>
<li><p>按照词语频率将词语写入词汇表。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_dataset_vocab</span><span class="p">(</span><span class="n">text_file</span><span class="p">,</span> <span class="n">vocab_file</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; 创建词汇表 &quot;&quot;&quot;</span>
    <span class="n">counter</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
    <span class="n">text_lines</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">text_file</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>

    <span class="c1"># 统计每个词的出现频率</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">text_lines</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r\n</span><span class="s1"> &#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">word</span><span class="p">:</span>
                <span class="n">counter</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span>
        <span class="n">basic_label</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&lt;unk&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;pad&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;sos&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;eos&gt;&quot;</span><span class="p">]</span>

    <span class="c1"># 在每行后加入换行符</span>
    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">basic_label</span><span class="p">:</span>
        <span class="n">vocab</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">label</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># 按照词的频率排序后写入词频表文件</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">f</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">vocab</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">key</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">vocab</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>现在完成了Multi30K数据集的数据预处理操作。</p>
</section>
<section id="mindrecord">
<h3>生成MindRecord<a class="headerlink" href="#mindrecord" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">create_data.py</span></code> 脚本继续处理数据获取特征，并转换为MindRecord格式。</p>
<section id="id2">
<h4>定义训练实例方法和提取训练特征方法<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h4>
<p>现在可以通过定义一个 <code class="docutils literal notranslate"><span class="pre">create_training_instance</span></code> 方法为语言文本增加开始和结束符，并通过 <code class="docutils literal notranslate"><span class="pre">SampleInstance</span></code> 类来创建一个训练的实例，该方法需要传递四个参数：</p>
<ul class="simple">
<li><p>source_words：原始语言语句。</p></li>
<li><p>target_words：翻译目标语言。</p></li>
<li><p>max_seq_length：最大序列长度。</p></li>
<li><p>clip_to_max_len：确认计算是否合理。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_training_instance</span><span class="p">(</span><span class="n">source_words</span><span class="p">,</span> <span class="n">target_words</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">,</span> <span class="n">clip_to_max_len</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;创建训练实例&quot;&quot;&quot;</span>
    <span class="n">EOS</span> <span class="o">=</span> <span class="s2">&quot;&lt;eos&gt;&quot;</span>
    <span class="n">SOS</span> <span class="o">=</span> <span class="s2">&quot;&lt;sos&gt;&quot;</span>
    <span class="c1"># 判断输入原始文本是否超过最长字节</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_words</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">max_seq_length</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_words</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">max_seq_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">clip_to_max_len</span><span class="p">:</span>
            <span class="n">source_words</span> <span class="o">=</span> <span class="n">source_words</span><span class="p">[:</span><span class="nb">min</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">source_words</span><span class="p">,</span> <span class="n">max_seq_length</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)])]</span>
            <span class="n">target_words</span> <span class="o">=</span> <span class="n">target_words</span><span class="p">[:</span><span class="nb">min</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">target_words</span><span class="p">,</span> <span class="n">max_seq_length</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)])]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
    <span class="c1"># 为句子增加开始符和结束符</span>
    <span class="n">source_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">SOS</span><span class="p">]</span> <span class="o">+</span> <span class="n">source_words</span> <span class="o">+</span> <span class="p">[</span><span class="n">EOS</span><span class="p">]</span>
    <span class="n">target_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">SOS</span><span class="p">]</span> <span class="o">+</span> <span class="n">target_words</span> <span class="o">+</span> <span class="p">[</span><span class="n">EOS</span><span class="p">]</span>
    <span class="c1"># 形成单个训练实例并返回输出</span>
    <span class="n">instance</span> <span class="o">=</span> <span class="n">SampleInstance</span><span class="p">(</span>
        <span class="n">source_tokens</span><span class="o">=</span><span class="n">source_tokens</span><span class="p">,</span>
        <span class="n">target_tokens</span><span class="o">=</span><span class="n">target_tokens</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">instance</span>
</pre></div>
</div>
<p>现在得到的训练实例 <code class="docutils literal notranslate"><span class="pre">instance</span></code> 为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>source_tokens: &lt;sos&gt; ein mann und eine frau lächeln in einem nachtclub . &lt;eos&gt;
target tokens: &lt;sos&gt; a man and a woman smiling in a nightclub . &lt;eos&gt;
</pre></div>
</div>
<p>接下来定义 <code class="docutils literal notranslate"><span class="pre">get_instance_features</span></code> 方法来提取实例语句中的特征，该方法需要提供如下参数：</p>
<ul class="simple">
<li><p>instance：实例对象。</p></li>
<li><p>tokenizer_src/tokenizer_trg：源/目标语言标记文件。</p></li>
<li><p>max_seq_length：最大序列长度。</p></li>
<li><p>bucket：分块数。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_instance_features</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="n">tokenizer_src</span><span class="p">,</span> <span class="n">tokenizer_trg</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">,</span> <span class="n">bucket</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;获取实例特征&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_find_bucket_length</span><span class="p">(</span><span class="n">source_tokens</span><span class="p">,</span> <span class="n">target_tokens</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;为文本寻找适合长度的bucket&quot;&quot;&quot;</span>
        <span class="n">source_ids</span> <span class="o">=</span> <span class="n">tokenizer_src</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="n">source_tokens</span><span class="p">)</span>
        <span class="n">target_ids</span> <span class="o">=</span> <span class="n">tokenizer_trg</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="n">target_tokens</span><span class="p">)</span>
        <span class="n">num</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">source_ids</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_ids</span><span class="p">))</span>
        <span class="k">assert</span> <span class="n">num</span> <span class="o">&lt;=</span> <span class="n">bucket</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">bucket</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">bucket</span><span class="p">[</span><span class="n">index</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">num</span> <span class="o">&lt;=</span> <span class="n">bucket</span><span class="p">[</span><span class="n">index</span><span class="p">]:</span>
                <span class="k">return</span> <span class="n">bucket</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">bucket</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_convert_ids_and_mask</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">input_tokens</span><span class="p">,</span> <span class="n">seq_max_bucket_length</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;将token映射为id，根据id生成mask&quot;&quot;&quot;</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">)</span>
        <span class="n">input_mask</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_seq_length</span>

        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">seq_max_bucket_length</span><span class="p">:</span>
            <span class="n">input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">input_mask</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span> <span class="o">==</span> <span class="n">seq_max_bucket_length</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_mask</span><span class="p">)</span> <span class="o">==</span> <span class="n">seq_max_bucket_length</span>

        <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span>

    <span class="c1"># 匹配文本长度，获取翻译前后文本的特征</span>
    <span class="n">seq_max_bucket_length</span> <span class="o">=</span> <span class="n">_find_bucket_length</span><span class="p">(</span><span class="n">instance</span><span class="o">.</span><span class="n">source_tokens</span><span class="p">,</span> <span class="n">instance</span><span class="o">.</span><span class="n">target_tokens</span><span class="p">)</span>
    <span class="n">source_ids</span><span class="p">,</span> <span class="n">source_mask</span> <span class="o">=</span> <span class="n">_convert_ids_and_mask</span><span class="p">(</span><span class="n">tokenizer_src</span><span class="p">,</span> <span class="n">instance</span><span class="o">.</span><span class="n">source_tokens</span><span class="p">,</span> <span class="n">seq_max_bucket_length</span><span class="p">)</span>
    <span class="n">target_ids</span><span class="p">,</span> <span class="n">target_mask</span> <span class="o">=</span> <span class="n">_convert_ids_and_mask</span><span class="p">(</span><span class="n">tokenizer_trg</span><span class="p">,</span> <span class="n">instance</span><span class="o">.</span><span class="n">target_tokens</span><span class="p">,</span> <span class="n">seq_max_bucket_length</span><span class="p">)</span>

    <span class="c1"># 建立特征有序字典保存处理后的特征</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">OrderedDict</span><span class="p">()</span>
    <span class="n">features</span><span class="p">[</span><span class="s2">&quot;source_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">source_ids</span><span class="p">)</span>
    <span class="n">features</span><span class="p">[</span><span class="s2">&quot;source_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">source_mask</span><span class="p">)</span>
    <span class="n">features</span><span class="p">[</span><span class="s2">&quot;target_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">target_ids</span><span class="p">)</span>
    <span class="n">features</span><span class="p">[</span><span class="s2">&quot;target_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">target_mask</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">features</span><span class="p">,</span> <span class="n">seq_max_bucket_length</span>
</pre></div>
</div>
<p>这里获得的 <code class="docutils literal notranslate"><span class="pre">feature</span></code> 特征值可表示为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>OrderedDict([
(&#39;source_ids&#39;, array([2, 5, 25, 21, 14, 776, 11, 6, 281, 20, 88, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])),
(&#39;source_mask&#39;, array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),
(&#39;target_ids&#39;, array([2, 4, 32, 20, 7, 508, 12, 4, 85, 13, 4, 211, 6, 7, 453, 5, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])),
(&#39;target_mask&#39;, array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,
 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))
])
</pre></div>
</div>
</section>
<section id="id3">
<h4>生成MindRecord数据集<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h4>
<p>创建 <code class="docutils literal notranslate"><span class="pre">feature_dict</span></code> ，保存上一步生成的 <code class="docutils literal notranslate"><span class="pre">feature</span></code> 特征值，并写入新文件中产生MindRecord数据集：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 创建`feature_dict`</span>
<span class="n">feature_dict</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">bucket</span><span class="p">:</span>
    <span class="n">feature_dict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># 生成MindRecord数据集</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">bucket</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">num_splits</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">output_file_name</span> <span class="o">=</span> <span class="n">output_file</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">output_file_name</span> <span class="o">=</span> <span class="n">output_file</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">FileWriter</span><span class="p">(</span><span class="n">output_file_name</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_splits</span><span class="p">)</span>
    <span class="n">data_schema</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;source_ids&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;int64&quot;</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]},</span>
                   <span class="s2">&quot;source_mask&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;int64&quot;</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]},</span>
                   <span class="s2">&quot;target_ids&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;int64&quot;</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]},</span>
                   <span class="s2">&quot;target_mask&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;int64&quot;</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]}</span>
                   <span class="p">}</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">add_schema</span><span class="p">(</span><span class="n">data_schema</span><span class="p">,</span> <span class="s2">&quot;gru&quot;</span><span class="p">)</span>
    <span class="n">features_</span> <span class="o">=</span> <span class="n">feature_dict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Bucket length </span><span class="si">%d</span><span class="s2"> has </span><span class="si">%d</span><span class="s2"> samples, start writing...&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">features_</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">features_</span><span class="p">:</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">write_raw_data</span><span class="p">([</span><span class="n">item</span><span class="p">])</span>
        <span class="n">total_written</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
<span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Wrote </span><span class="si">%d</span><span class="s2"> total instances&quot;</span><span class="p">,</span> <span class="n">total_written</span><span class="p">)</span>
</pre></div>
</div>
<p>生成的文件中， <code class="docutils literal notranslate"><span class="pre">*.db</span></code> 为索引文件。</p>
</section>
</section>
</section>
<section id="id4">
<h2>seq2seq模型定义<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h2>
<p>教程中用到的模型为seq2seq，并结合了GRU、Attention机制和Teacher Forcing机制。下面从整体到局部介绍模型的实现。</p>
<section id="id5">
<h3>seq2seq模型<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h3>
<p>seq2seq模型由编码器(Encoder)和解码器(Decoder)两部分组成，模型的输入和输出都是一个不定长文本序列。Encoder将原始文本序列编码，在每个时间步中输出隐藏状态，在最终时间步隐藏状态可转换为固定长度的向量，这就是上下文向量。Decoder会将向量再次转换为目标文本序列，从而实现文本翻译的目的。Encoder和Decoder一般都为RNN网络。</p>
<p><img alt="model" src="../../_images/seq2seq_1.png" /></p>
<blockquote>
<div><p>图片来源于<a class="reference external" href="https://zh.d2l.ai/chapter_recurrent-neural-networks/gru.html">动手学深度学习</a></p>
</div></blockquote>
</section>
<section id="attention">
<h3>Attention机制<a class="headerlink" href="#attention" title="Permalink to this headline"></a></h3>
<p>在上面介绍的seq2seq模型中，Encoder与Decoder之间只有定长向量联系，这样一来会造成信息的丢失，影响模型效果。
为了解决这一问题，采用注意力机制(Attention)来做动态处理。Attention机制下，Encoder会对每一个时间步的隐藏状态做加权平均得到上下文向量。Decoder在每一时间步中调整注意力权重，关注输入序列中的不同部分，最后得到输出。</p>
<p><img alt="model" src="../../_images/seq2seq_2.png" /></p>
<blockquote>
<div><p>图片来源于<a class="reference external" href="https://arxiv.org/pdf/1703.03906.pdf">Massive Exploration of Neural Machine Translation
Architectures</a></p>
</div></blockquote>
</section>
<section id="gru">
<h3>GRU<a class="headerlink" href="#gru" title="Permalink to this headline"></a></h3>
<p>GRU，即门控循环单元(Gated Recurrent Unit)，在RNN网络中用于捕捉时间序列中时间步距离较大的依赖关系。其中包含4部分：</p>
<ul class="simple">
<li><p>重置门(reset gate)：用于捕捉时间序列里短期的依赖关系；</p></li>
<li><p>更新门(update gate)：用于捕捉时间序列里长期的依赖关系；</p></li>
<li><p>候选隐藏状态：辅助隐藏状态的判定，由重置门、当前的输入、上一步的隐藏状态计算得出；</p></li>
<li><p>隐藏状态：由更新门、当前步的候选隐藏状态、上一步的隐藏状态计算得出；</p></li>
</ul>
<p><img alt="model" src="../../_images/seq2seq_3.png" /></p>
<blockquote>
<div><p>图片来源于<a class="reference external" href="https://zh.d2l.ai/chapter_recurrent-neural-networks/gru.html">动手学深度学习</a></p>
</div></blockquote>
<p>重置门和更新门控制了RNN网络中隐藏状态的计算方式。两者的输入元素为当前时间步的输入与上一时间步的隐藏状态，输出通过全连接层完成。</p>
<p>本案例中采用了GRU来构成Encoder和Decoder，GRU的实现主要是通过 <code class="docutils literal notranslate"><span class="pre">DynamicGRUV2</span></code> 算子完成的，使用方法可通过<a class="reference external" href="https://www.mindspore.cn/doc/api_python/zh-CN/r1.2/mindspore/ops/mindspore.ops.DynamicGRUV2.html#mindspore.ops.DynamicGRUV2">DynamicGRUV2</a>查看。</p>
</section>
<section id="teacher-forcing">
<h3>Teacher Forcing机制<a class="headerlink" href="#teacher-forcing" title="Permalink to this headline"></a></h3>
<p>RNN后期的迭代训练效果会受到前期结果的影响，然而前期的结果通常不太精确，这样一来就会影响到整个训练进程。为了解决这一问题，引入了Teacher Forcing机制。Teacher Forcing下，模型训练的输入不一定来自于上一次输出，也可能来自于训练集的真实输出。</p>
<p>在本案例的实现中，在数据处理环节定义了 <code class="docutils literal notranslate"><span class="pre">random_teacher_force</span></code> 函数来完成Teacher Forcing机制，并在Decoder时引入。</p>
</section>
</section>
<section id="id6">
<h2>模型训练<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h2>
<p>在终端中输入命令开始训练：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>train.py
</pre></div>
</div>
<p>训练后会获得文件：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─ output         # 存储ckpt文件夹
│   │   ckpt_0
│   loss_0.log
</pre></div>
</div>
<p>在本案例中，通过定义<code class="docutils literal notranslate"><span class="pre">GRUWithLossCell</span></code>与<code class="docutils literal notranslate"><span class="pre">GRUTrainOneStepWithLossScaleCell</span></code>，实现了模型的自定义训练。</p>
<section id="id7">
<h3>包装网络与损失函数<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h3>
<p>在<code class="docutils literal notranslate"><span class="pre">seq2seq/src/gru_for_train.py</span></code>文件中，由<code class="docutils literal notranslate"><span class="pre">GRUWithLossCell</span></code>类完成了网络与损失函数的包装：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">composite</span> <span class="k">as</span> <span class="n">C</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">src.loss</span> <span class="kn">import</span> <span class="n">NLLLoss</span>

<span class="k">class</span> <span class="nc">GRUWithLossCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
        <span class="c1"># 变量初始化</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GRUWithLossCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">NLLLoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logits_shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">src_vocab_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cast</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Cast</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_len</span> <span class="o">=</span> <span class="mi">32</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">AddN</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Shape</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">teacher_force</span><span class="p">):</span>
        <span class="c1"># 计算损失的平均值</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">teacher_force</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">loss_total</span> <span class="o">=</span> <span class="p">()</span>
        <span class="n">decoder_targets</span> <span class="o">=</span> <span class="n">decoder_inputs</span>
        <span class="n">decoder_output</span> <span class="o">=</span> <span class="n">logits</span>

        <span class="c1"># 遍历文本来计算loss值</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_len</span><span class="p">):</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="n">i</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="p">::,</span> <span class="p">::]),</span> <span class="n">decoder_targets</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
            <span class="n">loss_total</span> <span class="o">+=</span> <span class="p">(</span><span class="n">loss</span><span class="p">,)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">loss_total</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_len</span>
        <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
</section>
<section id="id8">
<h3>自定义单步训练<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h3>
<p>在本教程中采用了自定义的训练方式，在 <code class="docutils literal notranslate"><span class="pre">seq2seq/src/gru_for_train.py</span></code> 文件中， <code class="docutils literal notranslate"><span class="pre">GRUTrainOneStepWithLossScaleCell</span></code> 定义了完整的单步训练pipline，这里对主体过程进行解释：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">ParameterTuple</span><span class="p">,</span> <span class="n">context</span>

<span class="k">class</span> <span class="nc">GRUTrainOneStepWithLossScaleCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scale_update_cell</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># 变量初始化</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GRUTrainOneStepWithLossScaleCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">set_grad</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">add_flags</span><span class="p">(</span><span class="n">defer_inline</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">ParameterTuple</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">GradOperation</span><span class="p">(</span><span class="n">get_by_list</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                    <span class="n">sens_param</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reducer_flag</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allreduce</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">AllReduce</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradients</span> <span class="o">=</span> <span class="n">ClipGradients</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cast</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Cast</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alloc_status</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">NPUAllocFloatStatus</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">get_status</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">NPUGetFloatStatus</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear_before_grad</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">NPUClearFloatStatus</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduce_sum</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">(</span><span class="n">keep_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">less_equal</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">LessEqual</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hyper_map</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">HyperMap</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_scaling_manager</span> <span class="o">=</span> <span class="n">scale_update_cell</span>
        <span class="k">if</span> <span class="n">scale_update_cell</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">scale_update_cell</span><span class="o">.</span><span class="n">get_loss_scale</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

    <span class="nd">@C</span><span class="o">.</span><span class="n">add_flags</span><span class="p">(</span><span class="n">has_effect</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">teacher_force</span><span class="p">,</span> <span class="n">sens</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># 定义单步训练</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">teacher_force</span><span class="p">)</span>

        <span class="c1"># 分配并初始化状态变量，供状态获取算子使用，然后清空当前训练中是否发生计算异常的状态</span>
        <span class="n">init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alloc_status</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear_before_grad</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sens</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scaling_sens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scaling_sens</span> <span class="o">=</span> <span class="n">sens</span>

        <span class="c1"># 根据weight求此时的梯度，并修剪梯度</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">,</span> <span class="n">weights</span><span class="p">)(</span><span class="n">encoder_inputs</span><span class="p">,</span>
                                                 <span class="n">decoder_inputs</span><span class="p">,</span>
                                                 <span class="n">teacher_force</span><span class="p">,</span>
                                                 <span class="bp">self</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">scaling_sens</span><span class="p">,</span>
                                                           <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

        <span class="n">grads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyper_map</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">Partial</span><span class="p">(</span><span class="n">grad_scale</span><span class="p">,</span> <span class="n">scaling_sens</span><span class="p">),</span> <span class="n">grads</span><span class="p">)</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradients</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">GRADIENT_CLIP_TYPE</span><span class="p">,</span> <span class="n">GRADIENT_CLIP_VALUE</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reducer_flag</span><span class="p">:</span>
            <span class="n">grads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_reducer</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>

        <span class="c1"># 检查是否训练过程中溢出</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">get_status</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
        <span class="n">flag_sum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">init</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
        <span class="n">cond</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base</span><span class="p">,</span> <span class="n">flag_sum</span><span class="p">)</span>
        <span class="n">overflow</span> <span class="o">=</span> <span class="n">cond</span>
        <span class="k">if</span> <span class="n">sens</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">overflow</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_scaling_manager</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">cond</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">overflow</span><span class="p">:</span>
            <span class="n">succ</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">succ</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>

        <span class="c1"># 获得单步训练结果</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">cond</span><span class="p">,</span> <span class="n">scaling_sens</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">Depend</span><span class="p">(</span><span class="n">ret</span><span class="p">,</span> <span class="n">succ</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id9">
<h3>训练流程<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h3>
<p>在定义完单步训练流程之后，就可以将之前处理好的MindRecord数据集引入，完成整个网络的训练。在 <code class="docutils literal notranslate"><span class="pre">/seq2seq/train.py</span></code> 中实现了seq2seq网络的训练：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_train</span><span class="p">():</span>

    <span class="c1"># 配置训练参数</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">,</span> <span class="n">device_id</span><span class="o">=</span><span class="n">get_device_id</span><span class="p">(),</span> <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">get_rank_id</span><span class="p">()</span>
    <span class="n">device_num</span> <span class="o">=</span> <span class="n">get_device_num</span><span class="p">()</span>
    <span class="n">mindrecord_file</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">dataset_path</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">mindrecord_file</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dataset file </span><span class="si">{}</span><span class="s2"> not exists, please check!&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mindrecord_file</span><span class="p">))</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">mindrecord_file</span><span class="p">)</span>

    <span class="c1"># 加载训练数据集</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">create_gru_dataset</span><span class="p">(</span><span class="n">epoch_count</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dataset_path</span><span class="o">=</span><span class="n">mindrecord_file</span><span class="p">,</span> <span class="n">rank_size</span><span class="o">=</span><span class="n">device_num</span><span class="p">,</span> <span class="n">rank_id</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span>
    <span class="n">dataset_size</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dataset size is </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dataset_size</span><span class="p">))</span>

    <span class="c1"># 实例化训练网络</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">Seq2Seq</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">GRUWithLossCell</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>

    <span class="c1"># 设置学习率与优化器</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">dynamic_lr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">dataset_size</span><span class="p">)</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

    <span class="c1"># 使用loss scale功能训练网络</span>
    <span class="n">scale_manager</span> <span class="o">=</span> <span class="n">DynamicLossScaleManager</span><span class="p">(</span><span class="n">init_loss_scale</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">init_loss_scale_value</span><span class="p">,</span>
                                            <span class="n">scale_factor</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">scale_factor</span><span class="p">,</span>
                                            <span class="n">scale_window</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">scale_window</span><span class="p">)</span>

    <span class="c1"># 实现自定义训练</span>
    <span class="n">update_cell</span> <span class="o">=</span> <span class="n">scale_manager</span><span class="o">.</span><span class="n">get_update_cell</span><span class="p">()</span>
    <span class="n">netwithgrads</span> <span class="o">=</span> <span class="n">GRUTrainOneStepWithLossScaleCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">update_cell</span><span class="p">)</span>

    <span class="n">time_cb</span> <span class="o">=</span> <span class="n">TimeMonitor</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="n">dataset_size</span><span class="p">)</span>
    <span class="n">loss_cb</span> <span class="o">=</span> <span class="n">LossCallBack</span><span class="p">(</span><span class="n">rank_id</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span>
    <span class="n">cb</span> <span class="o">=</span> <span class="p">[</span><span class="n">time_cb</span><span class="p">,</span> <span class="n">loss_cb</span><span class="p">]</span>

    <span class="c1"># 保存训练后得到的ckpt</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">:</span>
        <span class="n">ckpt_config</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">ckpt_epoch</span> <span class="o">*</span> <span class="n">dataset_size</span><span class="p">,</span>
                                       <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">keep_checkpoint_max</span><span class="p">)</span>
        <span class="n">save_ckpt_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">outputs_dir</span><span class="p">,</span> <span class="s1">&#39;ckpt_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">get_rank_id</span><span class="p">())</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span><span class="p">)</span>
        <span class="n">ckpt_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">ckpt_config</span><span class="p">,</span>
                                  <span class="n">directory</span><span class="o">=</span><span class="n">save_ckpt_path</span><span class="p">,</span>
                                  <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">get_rank_id</span><span class="p">()))</span>
        <span class="n">cb</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ckpt_cb</span><span class="p">]</span>

    <span class="n">netwithgrads</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">netwithgrads</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">cb</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>结果如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">time</span><span class="p">:</span> <span class="mi">241324</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="mi">1807</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">11.231921</span>
<span class="n">epoch</span> <span class="n">time</span><span class="p">:</span> <span class="mf">182089.310</span> <span class="n">ms</span><span class="p">,</span> <span class="n">per</span> <span class="n">step</span> <span class="n">time</span><span class="p">:</span> <span class="mf">100.769</span> <span class="n">ms</span>
<span class="n">time</span><span class="p">:</span> <span class="mi">250849</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="mi">3614</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">9.823265</span>
<span class="n">epoch</span> <span class="n">time</span><span class="p">:</span> <span class="mf">68758.979</span> <span class="n">ms</span><span class="p">,</span> <span class="n">per</span> <span class="n">step</span> <span class="n">time</span><span class="p">:</span> <span class="mf">38.051</span> <span class="n">ms</span>
<span class="n">time</span><span class="p">:</span> <span class="mi">319569</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="mi">5421</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">5.0367875</span>
<span class="n">epoch</span> <span class="n">time</span><span class="p">:</span> <span class="mf">68720.336</span> <span class="n">ms</span><span class="p">,</span> <span class="n">per</span> <span class="n">step</span> <span class="n">time</span><span class="p">:</span> <span class="mf">38.030</span> <span class="n">ms</span>
<span class="n">time</span><span class="p">:</span> <span class="mi">388246</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="mi">7228</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">5.3077984</span>
<span class="n">epoch</span> <span class="n">time</span><span class="p">:</span> <span class="mf">68676.665</span> <span class="n">ms</span><span class="p">,</span> <span class="n">per</span> <span class="n">step</span> <span class="n">time</span><span class="p">:</span> <span class="mf">38.006</span> <span class="n">ms</span>
<span class="n">time</span><span class="p">:</span> <span class="mi">456916</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="mi">9035</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">5.719825</span>
<span class="n">epoch</span> <span class="n">time</span><span class="p">:</span> <span class="mf">68669.177</span> <span class="n">ms</span><span class="p">,</span> <span class="n">per</span> <span class="n">step</span> <span class="n">time</span><span class="p">:</span> <span class="mf">38.002</span> <span class="n">ms</span>
<span class="n">time</span><span class="p">:</span> <span class="mi">525606</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="mi">10842</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">4.744868</span>
<span class="n">epoch</span> <span class="n">time</span><span class="p">:</span> <span class="mf">68690.478</span> <span class="n">ms</span><span class="p">,</span> <span class="n">per</span> <span class="n">step</span> <span class="n">time</span><span class="p">:</span> <span class="mf">38.014</span> <span class="n">ms</span>
<span class="n">time</span><span class="p">:</span> <span class="mi">594282</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="mi">12649</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">4.5104113</span>
<span class="n">epoch</span> <span class="n">time</span><span class="p">:</span> <span class="mf">68676.141</span> <span class="n">ms</span><span class="p">,</span> <span class="n">per</span> <span class="n">step</span> <span class="n">time</span><span class="p">:</span> <span class="mf">38.006</span> <span class="n">ms</span>
<span class="n">time</span><span class="p">:</span> <span class="mi">662953</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="mi">14456</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">5.097201</span>
<span class="n">epoch</span> <span class="n">time</span><span class="p">:</span> <span class="mf">68670.483</span> <span class="n">ms</span><span class="p">,</span> <span class="n">per</span> <span class="n">step</span> <span class="n">time</span><span class="p">:</span> <span class="mf">38.002</span> <span class="n">ms</span>
<span class="n">time</span><span class="p">:</span> <span class="mi">731622</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="mi">9</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="mi">16263</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">4.185684</span>
<span class="n">epoch</span> <span class="n">time</span><span class="p">:</span> <span class="mf">68669.424</span> <span class="n">ms</span><span class="p">,</span> <span class="n">per</span> <span class="n">step</span> <span class="n">time</span><span class="p">:</span> <span class="mf">38.002</span> <span class="n">ms</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="text_sentiment_ngrams_tutorial.html" class="btn btn-neutral float-left" title="FastText实现文本分类" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../pynative_mode_and_graph_mode.html" class="btn btn-neutral float-right" title="动态图与静态图" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>