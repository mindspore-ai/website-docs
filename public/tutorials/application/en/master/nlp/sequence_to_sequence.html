<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Text Translation Implemented by Seq2Seq Model &mdash; MindSpore master documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="GAN for Image Generation" href="../generative/gan.html" />
    <link rel="prev" title="LSTM+CRF Sequence Labeling" href="sequence_labeling.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">CV</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cv/resnet50.html">ResNet-50 for Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/transfer_learning.html">ResNet50 Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/fgsm.html">FGSM Network Adversarial Attack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/vit.html">Vision Transformer Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/cnnctc.html">CNN and CTC for Recognizing Text from Images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/fcn8s.html">FCN for Image Semantic Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/shufflenet.html">ShuffleNet for Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/ssd.html">SSD for Object Detection</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NLP</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="sentiment_analysis.html">Sentiment Classification Implemented by RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="sequence_labeling.html">LSTM+CRF Sequence Labeling</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Text Translation Implemented by Seq2Seq Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#data-preparation">Data Preparation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#data-downloading-module">Data Downloading Module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-preprocessing">Data Preprocessing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#data-loader">Data Loader</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vocabulary">Vocabulary</a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-iterator">Data Iterator</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#model-building">Model Building</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#encoder">Encoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#attention-layer">Attention Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#decoder">Decoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#seq2seq">Seq2Seq</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#model-training">Model Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-inference">Model Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bleu-score">BLEU Score</a></li>
<li class="toctree-l2"><a class="reference internal" href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Generative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../generative/gan.html">GAN for Image Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generative/dcgan.html">Generating Cartoon Head Portrait via DCGAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generative/pix2pix.html">Pix2Pix for Image Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generative/cyclegan.html">CycleGAN for Image Style Migration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generative/diffusion.html">Diffusion Model</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Text Translation Implemented by Seq2Seq Model</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/nlp/sequence_to_sequence.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="text-translation-implemented-by-seq2seq-model">
<h1>Text Translation Implemented by Seq2Seq Model<a class="headerlink" href="#text-translation-implemented-by-seq2seq-model" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/tutorials/application/source_en/nlp/sequence_to_sequence.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>Sequence to sequence model, also called Seq2Seq model. It is a variant of the recurrent neural network (RNN) that breaks through a limitation of RNN models on the input and output sequence length and maps an input sequence to another output sequence with different length. Therefore, it is commonly used in machine translation.</p>
<p>The Seq2Seq model consists of encoder and decoder. The encoder encodes an input sequence into a vector with fixed length, and the decoder converts the vector into a vector with variable length.</p>
<p><img alt="avatar1" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/application/source_zh_cn/nlp/images/seq2seq_1.png" /></p>
<blockquote>
<div><p>Image source:</p>
<p><a class="reference external" href="https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb">https://github.com/bentrevett/pytorch-seq2seq/blob/master/3 - Neural Machine Translation by Jointly Learning to Align and Translate.ipynb</a></p>
</div></blockquote>
<p>Later, an attention mechanism is introduced after encoder and decoder, so that the model performs better in each task.</p>
</section>
<section id="data-preparation">
<h2>Data Preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline"></a></h2>
<p>The dataset we use is the <strong>Multi30K dataset</strong>, which is a large-scale dataset containing more than 30,000 images and each image has text descriptions in two languages.</p>
<ul class="simple">
<li><p>English description and corresponding German translation</p></li>
<li><p>Five independent and non-translated English and German descriptions that contain different details</p></li>
</ul>
<p>Because descriptions of images in different languages collected by the model are independent, the trained model can be better applicable to multi-modal content with noise.</p>
<p><img alt="avatar2" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/application/source_zh_cn/nlp/images/seq2seq_2.png" /></p>
<blockquote>
<div><p>Image source:</p>
<p>Elliott, D., Frank, S., Sima’an, K., &amp; Specia, L. (2016).Multi30K: Multilingual English-German Image Descriptions. CoRR, 1605.00459.</p>
</div></blockquote>
<p>First, we need to install the following dependency:</p>
<ul class="simple">
<li><p>BLEU Score calculation: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">nltk</span></code></p></li>
</ul>
<section id="data-downloading-module">
<h3>Data Downloading Module<a class="headerlink" href="#data-downloading-module" title="Permalink to this headline"></a></h3>
<p>Use <code class="docutils literal notranslate"><span class="pre">download</span></code> to download data and decompress the <code class="docutils literal notranslate"><span class="pre">tar.gz</span></code> file to a specified folder.</p>
<p>The directory structure of the downloaded dataset is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>home_path/.mindspore_examples
├─test
│      test2016.de
│      test2016.en
│      test2016.fr
│
├─train
│      train.de
│      train.en
│
└─valid
        val.de
        val.en
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">download</span> <span class="kn">import</span> <span class="n">download</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># Addresses for downloading training, validation, and test datasets</span>
<span class="n">urls</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/training.tar.gz&#39;</span><span class="p">,</span>
    <span class="s1">&#39;valid&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/validation.tar.gz&#39;</span><span class="p">,</span>
    <span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.quest.dcs.shef.ac.uk/wmt17_files_mmt/mmt_task1_test2016.tar.gz&#39;</span>
<span class="p">}</span>

<span class="c1"># Set the storage path to `home_path/.mindspore_examples`.</span>
<span class="n">cache_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="o">.</span><span class="n">home</span><span class="p">()</span> <span class="o">/</span> <span class="s1">&#39;.mindspore_examples&#39;</span>

<span class="n">train_path</span> <span class="o">=</span> <span class="n">download</span><span class="p">(</span><span class="n">urls</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;tar.gz&#39;</span><span class="p">)</span>
<span class="n">valid_path</span> <span class="o">=</span> <span class="n">download</span><span class="p">(</span><span class="n">urls</span><span class="p">[</span><span class="s1">&#39;valid&#39;</span><span class="p">],</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">,</span> <span class="s1">&#39;valid&#39;</span><span class="p">),</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;tar.gz&#39;</span><span class="p">)</span>
<span class="n">test_path</span> <span class="o">=</span> <span class="n">download</span><span class="p">(</span><span class="n">urls</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">),</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;tar.gz&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="data-preprocessing">
<h3>Data Preprocessing<a class="headerlink" href="#data-preprocessing" title="Permalink to this headline"></a></h3>
<p>When using data to perform operations such as model training, we need to preprocess the data as follows:</p>
<ol class="arabic simple">
<li><p>Load the dataset. Currently, the data is text in the form of sentences and requires word tokenization, that is, split sentences into independent tokens (characters or words).</p></li>
<li><p>Map each token to a numeric index starting from 0 (to save storage space and filter out tokens with low frequency). A set composed of tokens and numeric indexes is called vocabulary.</p></li>
<li><p>Add special placeholders to indicate the start and end of a sequence and unify the sequence length, and create a data iterator.</p></li>
</ol>
<section id="data-loader">
<h4>Data Loader<a class="headerlink" href="#data-loader" title="Permalink to this headline"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>


<span class="k">class</span> <span class="nc">Multi30K</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multi30K dataset loader</span>

<span class="sd">    Load the Multi30K dataset and process it as a Python iteration object.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>

        <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
            <span class="c1"># Tokenize sentences and unify the case.</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">tok</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\w+|[^\w\s]&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)]</span>

        <span class="c1"># Read Multi30K data and perform word tokenization.</span>
        <span class="n">members</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">)}</span>
        <span class="n">de_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">members</span><span class="p">[</span><span class="s1">&#39;de&#39;</span><span class="p">])</span>
        <span class="n">en_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">members</span><span class="p">[</span><span class="s1">&#39;en&#39;</span><span class="p">])</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">de_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">de_file</span><span class="p">:</span>
            <span class="n">de</span> <span class="o">=</span> <span class="n">de_file</span><span class="o">.</span><span class="n">readlines</span><span class="p">()[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">de</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenize</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">de</span><span class="p">]</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">en_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">en_file</span><span class="p">:</span>
            <span class="n">en</span> <span class="o">=</span> <span class="n">en_file</span><span class="o">.</span><span class="n">readlines</span><span class="p">()[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">en</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenize</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">en</span><span class="p">]</span>

        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">de</span><span class="p">,</span> <span class="n">en</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">Multi30K</span><span class="p">(</span><span class="n">train_path</span><span class="p">),</span> <span class="n">Multi30K</span><span class="p">(</span><span class="n">valid_path</span><span class="p">),</span> <span class="n">Multi30K</span><span class="p">(</span><span class="n">test_path</span><span class="p">)</span>
</pre></div>
</div>
<p>Test the decompression and word tokenization results and print the English and German text of test dataset, where we can see that each word and punctuation have been separated.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">de</span><span class="p">,</span> <span class="n">en</span> <span class="ow">in</span> <span class="n">test_dataset</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;de = </span><span class="si">{</span><span class="n">de</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;en = </span><span class="si">{</span><span class="n">en</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>de = [&#39;ein&#39;, &#39;mann&#39;, &#39;mit&#39;, &#39;einem&#39;, &#39;orangefarbenen&#39;, &#39;hut&#39;, &#39;,&#39;, &#39;der&#39;, &#39;etwas&#39;, &#39;anstarrt&#39;, &#39;.&#39;]
en = [&#39;a&#39;, &#39;man&#39;, &#39;in&#39;, &#39;an&#39;, &#39;orange&#39;, &#39;hat&#39;, &#39;starring&#39;, &#39;at&#39;, &#39;something&#39;, &#39;.&#39;]
</pre></div>
</div>
</section>
<section id="vocabulary">
<h4>Vocabulary<a class="headerlink" href="#vocabulary" title="Permalink to this headline"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Vocab</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Build a vocabulary based on the word frequency dictionary.&quot;&quot;</span>

<span class="sd">    special_tokens = [&#39;&lt;unk&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;bos&gt;&#39;, &#39;&lt;eos&gt;&#39;]</span>

<span class="sd">    def __init__(self, word_count_dict, min_freq=1):</span>
<span class="sd">        self.word2idx = {}</span>
<span class="sd">        for idx, tok in enumerate(self.special_tokens):</span>
<span class="sd">            self.word2idx[tok] = idx</span>

<span class="sd">        # Filter out tokens with low frequency.</span>
<span class="sd">        filted_dict = {</span>
<span class="sd">            w: c</span>
<span class="sd">            for w, c in word_count_dict.items() if c &gt;= min_freq</span>
<span class="sd">        }</span>
<span class="sd">        for w, _ in filted_dict.items():</span>
<span class="sd">            self.word2idx[w] = len(self.word2idx)</span>

<span class="sd">        self.idx2word = {idx: word for word, idx in self.word2idx.items()}</span>

<span class="sd">        self.bos_idx = self.word2idx[&#39;&lt;bos&gt;&#39;] # Special placeholder: start of a sequence</span>
<span class="sd">        self.eos_idx = self.word2idx[&#39;&lt;eos&gt;&#39;] # Special placeholder: end of a sequence</span>
<span class="sd">        self.pad_idx = self.word2idx[&#39;&lt;pad&gt;&#39;] # Special placeholder: supplementary character</span>
<span class="sd">        self.unk_idx = self.word2idx[&#39;&lt;unk&gt;&#39;] # Special placeholders: low-frequency tokens or unknown tokens</span>

<span class="sd">    def _word2idx(self, word):</span>
<span class="sd">        &quot;&quot;&quot;</span><span class="n">Map</span> <span class="n">words</span> <span class="n">to</span> <span class="n">numeric</span> <span class="n">indexes</span><span class="o">.</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        if word not in self.word2idx:</span>
<span class="s2">            return self.unk_idx</span>
<span class="s2">        return self.word2idx[word]</span>

<span class="s2">    def _idx2word(self, idx):</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="n">Map</span> <span class="n">numeric</span> <span class="n">indexes</span> <span class="n">to</span> <span class="n">words</span><span class="o">.</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        if idx not in self.idx2word:</span>
<span class="s2">            raise ValueError(&#39;input index is not in vocabulary.&#39;)</span>
<span class="s2">        return self.idx2word[idx]</span>

<span class="s2">    def encode(self, word_or_list):</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="n">Map</span> <span class="n">a</span> <span class="n">word</span> <span class="ow">or</span> <span class="n">word</span> <span class="n">array</span> <span class="n">to</span> <span class="n">a</span> <span class="n">numeric</span> <span class="n">index</span> <span class="ow">or</span> <span class="n">numeric</span> <span class="n">index</span> <span class="n">array</span><span class="o">.</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        if isinstance(word_or_list, list):</span>
<span class="s2">            return [self._word2idx(i) for i in word_or_list]</span>
<span class="s2">        return self._word2idx(word_or_list)</span>

<span class="s2">    def decode(self, idx_or_list):</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="n">Map</span> <span class="n">a</span> <span class="n">numeric</span> <span class="n">index</span> <span class="ow">or</span> <span class="n">numeric</span> <span class="n">index</span> <span class="n">array</span> <span class="n">to</span> <span class="n">a</span> <span class="n">single</span> <span class="n">word</span> <span class="ow">or</span> <span class="n">word</span> <span class="n">array</span><span class="o">.</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        if isinstance(idx_or_list, list):</span>
<span class="s2">            return [self._idx2word(i) for i in idx_or_list]</span>
<span class="s2">        return self._idx2word(idx_or_list)</span>

<span class="s2">    def __len__(self):</span>
<span class="s2">        return len(self.word2idx)</span>
</pre></div>
</div>
<p>After using the user-defined word frequency dictionary to test, we can see that the vocabulary has removed the token c whose frequency is less than 2. Since four default special placeholders are added, the overall length of vocabulary is 4 - 1 + 4 = 7.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">word_count</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span><span class="mi">20</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">}</span>

<span class="n">vocab</span> <span class="o">=</span> <span class="n">Vocab</span><span class="p">(</span><span class="n">word_count</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>7
</pre></div>
</div>
<p>Use <code class="docutils literal notranslate"><span class="pre">Counter</span></code> and <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code> in <code class="docutils literal notranslate"><span class="pre">collections</span></code> to calculate the frequency of each word in the entire English and German text. Build a word frequency dictionary, and then convert the dictionary into a vocabulary.</p>
<p>There is a tip when allocating numeric indexes: Map common tokens to indexes with smaller values to save spaces.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">OrderedDict</span>

<span class="k">def</span> <span class="nf">build_vocab</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="n">de_words</span><span class="p">,</span> <span class="n">en_words</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">de</span><span class="p">,</span> <span class="n">en</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
        <span class="n">de_words</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">de</span><span class="p">)</span>
        <span class="n">en_words</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">en</span><span class="p">)</span>

    <span class="n">de_count_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">de_words</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">en_count_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">en_words</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">Vocab</span><span class="p">(</span><span class="n">de_count_dict</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">Vocab</span><span class="p">(</span><span class="n">en_count_dict</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span> <span class="o">=</span> <span class="n">build_vocab</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Unique tokens in de vocabulary:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">de_vocab</span><span class="p">))</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Unique tokens in de vocabulary: 7882
</pre></div>
</div>
</section>
<section id="data-iterator">
<h4>Data Iterator<a class="headerlink" href="#data-iterator" title="Permalink to this headline"></a></h4>
<p>The last step of data preprocessing is to create a data iterator. After the previous processing (including batch processing, adding start and end placeholders, and unifying the sequence length), we return the data as tensors.</p>
<p>The following parameters are required for creating a data iterator:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dataset</span></code>: dataset after tokenization</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">de_vocab</span></code>: German vocabulary</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">en_vocab</span></code>: English vocabulary</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batch_size</span></code>: batch size, that is, the number of sequences in a batch</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_len</span></code>: maximum length of the sequence. The value is equal to the maximum valid text length plus 2 (placeholders for the start and end of a sequence). If the length is less than the maximum, supplement the length. If the length exceeds the maximum, discard the excess.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">drop_remainder</span></code>: indicates whether to discard the remaining batch.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>

<span class="k">class</span> <span class="nc">Iterator</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a data iterator.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">drop_reminder</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">de_vocab</span> <span class="o">=</span> <span class="n">de_vocab</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">en_vocab</span> <span class="o">=</span> <span class="n">en_vocab</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">=</span> <span class="n">max_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop_reminder</span> <span class="o">=</span> <span class="n">drop_reminder</span>

        <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">len</span> <span class="o">=</span> <span class="n">length</span> <span class="k">if</span> <span class="n">drop_reminder</span> <span class="k">else</span> <span class="n">length</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># The number of batches</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">pad</span><span class="p">(</span><span class="n">idx_list</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">max_len</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Unify the sequence length and record the valid length.&quot;&quot;&quot;</span>
            <span class="n">idx_pad_list</span><span class="p">,</span> <span class="n">idx_len</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
            <span class="c1"># If the current sequence length exceeds the maximum, the excess part is discarded. If the current sequence length is less than the maximum length, the length is padded with placeholders.</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx_list</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_len</span> <span class="o">-</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">idx_pad_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">vocab</span><span class="o">.</span><span class="n">bos_idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">i</span><span class="p">[:</span><span class="n">max_len</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">vocab</span><span class="o">.</span><span class="n">eos_idx</span><span class="p">]</span>
                    <span class="p">)</span>
                    <span class="n">idx_len</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">max_len</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">idx_pad_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">vocab</span><span class="o">.</span><span class="n">bos_idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="p">[</span><span class="n">vocab</span><span class="o">.</span><span class="n">eos_idx</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">idx_len</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">idx_pad_list</span><span class="p">,</span> <span class="n">idx_len</span>

        <span class="k">def</span> <span class="nf">sort_by_length</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Sort German/English field lengths.&quot;&quot;&quot;</span>
            <span class="n">data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">return</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>

        <span class="k">def</span> <span class="nf">encode_and_pad</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">max_len</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Convert text data in batches into numeric indexes and unify the length of each sequence.&quot;&quot;&quot;</span>
            <span class="c1"># Convert tokens in current batches into indexes.</span>
            <span class="n">src_data</span><span class="p">,</span> <span class="n">trg_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch_data</span><span class="p">)</span>
            <span class="n">src_idx</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">de_vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">src_data</span><span class="p">]</span>
            <span class="n">trg_idx</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">en_vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">trg_data</span><span class="p">]</span>

            <span class="c1"># Unify the sequence length.</span>
            <span class="n">src_idx</span><span class="p">,</span> <span class="n">trg_idx</span> <span class="o">=</span> <span class="n">sort_by_length</span><span class="p">(</span><span class="n">src_idx</span><span class="p">,</span> <span class="n">trg_idx</span><span class="p">)</span>
            <span class="n">src_idx_pad</span><span class="p">,</span> <span class="n">src_len</span> <span class="o">=</span> <span class="n">pad</span><span class="p">(</span><span class="n">src_idx</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
            <span class="n">trg_idx_pad</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pad</span><span class="p">(</span><span class="n">trg_idx</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">src_idx_pad</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg_idx_pad</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">len</span><span class="p">):</span>
            <span class="c1"># Obtain data in current batches.</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">len</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_reminder</span><span class="p">:</span>
                <span class="n">batch_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">batch_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>

            <span class="n">src_idx</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg_idx</span> <span class="o">=</span> <span class="n">encode_and_pad</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span><span class="p">)</span>
            <span class="c1"># Convert sequence data into tensors.</span>
            <span class="k">yield</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">src_idx</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> \
                <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">src_len</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> \
                <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">trg_idx</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">len</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_iterator</span> <span class="o">=</span> <span class="n">Iterator</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">drop_reminder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">valid_iterator</span> <span class="o">=</span> <span class="n">Iterator</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">drop_reminder</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">test_iterator</span> <span class="o">=</span> <span class="n">Iterator</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">drop_reminder</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="model-building">
<h2>Model Building<a class="headerlink" href="#model-building" title="Permalink to this headline"></a></h2>
<section id="encoder">
<h3>Encoder<a class="headerlink" href="#encoder" title="Permalink to this headline"></a></h3>
<p>In the encoder, we input a sequence <span class="math notranslate nohighlight">\(X=\{x_1, x_2, ..., x_T\}\)</span>, convert it into a vector at the embedding layer, cyclically calculate the hidden state <span class="math notranslate nohighlight">\(H=\{h_1, h_2, ..., h_T\}\)</span>, and return the context vector <span class="math notranslate nohighlight">\(z=h_T\)</span> in the last hidden state.</p>
<p>There are many ways to implement the encoder. Here, we use the gated recurrent units (GRU). Based on the RNN, it introduces the gate mechanism to control the input hidden state and the information output from the hidden state. The update gate (also called memory gate and represented by <span class="math notranslate nohighlight">\(z_t\)</span>) is used to control a degree to which state information <span class="math notranslate nohighlight">\(h_{t-1}\)</span> at the previous time is brought into the current state <span class="math notranslate nohighlight">\(h_t\)</span>. The reset gate (represented by <span class="math notranslate nohighlight">\(r_t\)</span>) controls how much information in the previous state <span class="math notranslate nohighlight">\(h_t\)</span> is written to the current candidate set <span class="math notranslate nohighlight">\(n_t\)</span>.</p>
<div class="math notranslate nohighlight">
\[h_t = \text{RNN}(e(x_t), h_{t-1})\]</div>
<p>Generally, bidirectional GRUs are used for text translation. That is, the text before and after the translation is considered during training. Each layer of the bidirectional GRUs consists of two RNNs. The hidden state of the forward RNN is calculated cyclically from left to right, and the hidden state of the reverse RNN is calculated from right to left. The formula is as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
h_t^\rightarrow &amp;= \text{EncoderGRU}^\rightarrow(e(x_t^\rightarrow),h_{t-1}^\rightarrow)\\
h_t^\leftarrow &amp;= \text{EncoderGRU}^\leftarrow(e(x_t^\leftarrow),h_{t-1}^\leftarrow)
\end{align*}\end{split}\]</div>
<p>After observing the last word in a sentence, each RNN network outputs a context vector. The output of the forward RNN is <span class="math notranslate nohighlight">\(z^\rightarrow=h_T^\rightarrow\)</span>, and the output of the reverse RNN is <span class="math notranslate nohighlight">\(z^\leftarrow=h_T^\leftarrow\)</span>.</p>
<p><img alt="avatar3" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/application/source_zh_cn/nlp/images/seq2seq_3.png" /></p>
<blockquote>
<div><p>Image source:</p>
<p><a class="reference external" href="https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb">https://github.com/bentrevett/pytorch-seq2seq/blob/master/3 - Neural Machine Translation by Jointly Learning to Align and Translate.ipynb</a></p>
</div></blockquote>
<p>The encoder returns <code class="docutils literal notranslate"><span class="pre">outputs</span></code> and <code class="docutils literal notranslate"><span class="pre">hidden</span></code>.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">outputs</span></code> indicates the hidden state of the top layer of the bidirectional GRUs. The shape is [max_len, batch_size, hid_dim * num_directions]. Take the time <span class="math notranslate nohighlight">\(t=1\)</span> as an example, its output is a concatenation of the top hidden state at the time <span class="math notranslate nohighlight">\(t=1\)</span> in the forward RNN and the reverse RNN at the time <span class="math notranslate nohighlight">\(t=T\)</span>, which is <span class="math notranslate nohighlight">\(h_1 = [h_1^\rightarrow; h_{T}^\leftarrow]\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hidden</span></code> indicates the final hidden state of each layer, that is, the context vector mentioned above. To use the initial hidden state <span class="math notranslate nohighlight">\(s_0\)</span> as the decoder, a single context vector <span class="math notranslate nohighlight">\(z\)</span> is required because the decoder is not bidirectional. Therefore, we concatenate the two context vectors together, passing them through a fully connected layer <span class="math notranslate nohighlight">\(g\)</span>, and apply the activation function <span class="math notranslate nohighlight">\(tanh\)</span>.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[z=\tanh(g(h_T^\rightarrow, h_T^\leftarrow)) = \tanh(g(z^\rightarrow, z^\leftarrow)) = s_0\]</div>
<p>MindSpore provides GRU interfaces which can be directly invoked during encoder setup. You can set <code class="docutils literal notranslate"><span class="pre">bidirectional=True</span></code> to enable bidirectional GRU.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="n">enc_hid_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">is_ascend</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">)</span> <span class="c1"># Embedding layer</span>

        <span class="k">if</span> <span class="n">is_ascend</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">emb_dim</span><span class="p">,</span> <span class="n">enc_hid_dim</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">compute_dtype</span><span class="p">)</span> <span class="c1"># Bidirectional GRU layer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">enc_hid_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">compute_dtype</span><span class="p">)</span> <span class="c1"># Fully-connected layer</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">emb_dim</span><span class="p">,</span> <span class="n">enc_hid_dim</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Bidirectional GRU layer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">enc_hid_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">)</span>  <span class="c1"># Fully-connected layer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="o">-</span><span class="n">dropout</span><span class="p">)</span> <span class="c1"># Dropout, preventing overfitting</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Encoder Building</span>

<span class="sd">        Args:</span>
<span class="sd">            src: indicates the source sequence, which has been converted into a numeric index and has a unified length. shape = [src len, batch_size]</span>
<span class="sd">            src_len: indicates the valid length. shape = [batch_size, ]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Convert the source sequence into a vector and perform dropout.</span>
        <span class="c1"># shape = [src len, batch size, emb dim]</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">src</span><span class="p">))</span>
        <span class="c1"># Calculate the output.</span>
        <span class="c1"># shape = [src len, batch size, enc hid dim*2]</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">seq_length</span><span class="o">=</span><span class="n">src_len</span><span class="p">)</span>
        <span class="c1"># Combine two context functions to adapt to the decoder.</span>
        <span class="c1"># shape = [batch size, dec hid dim]</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">hidden</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span> <span class="n">hidden</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>

        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">hidden</span>
</pre></div>
</div>
</section>
<section id="attention-layer">
<h3>Attention Layer<a class="headerlink" href="#attention-layer" title="Permalink to this headline"></a></h3>
<p>In machine translation, each generated word may correspond to a different word in the source sentence, while the traditional Seq2Seq model with no attention mechanism prefers to focus on the last word in the sentence. To further optimize the model, we introduce the attention mechanism.</p>
<p>The attention mechanism is to give higher weight to corresponding words in the source and target sentence. It integrates all information encoded and decoded so far, and outputs a vector <span class="math notranslate nohighlight">\(a_t\)</span> indicating the attention weight, which is used to determine which words should be given higher attention in the next prediction <span class="math notranslate nohighlight">\(\hat{y}_{t+}\)</span>.</p>
<p><img alt="avatar4" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/application/source_zh_cn/nlp/images/seq2seq_4.png" /></p>
<blockquote>
<div><p>Image source:</p>
<p><a class="reference external" href="https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb">https://github.com/bentrevett/pytorch-seq2seq/blob/master/3 - Neural Machine Translation by Jointly Learning to Align and Translate.ipynb</a></p>
</div></blockquote>
<p>First, we need to calculate the matching degree <span class="math notranslate nohighlight">\(E_t\)</span> between each hidden state in the encoder and the hidden state at the previous time in the decoder.</p>
<p>Up to the current time <span class="math notranslate nohighlight">\(t\)</span>, all information in the encoder is a combination of hidden states of all forward and reverse RNNs <span class="math notranslate nohighlight">\(H\)</span>, and is a sequence with <span class="math notranslate nohighlight">\(T\)</span> tensors; the information in the decoder is a hidden state <span class="math notranslate nohighlight">\(s_{t-1}\)</span> at the previous time, and is an independent tensor. To unify their dimensions, we need to repeat the decoder hidden state <span class="math notranslate nohighlight">\(s_{t-1}\)</span> at the previous time for <span class="math notranslate nohighlight">\(T\)</span> times, stack up the processed decoder and encoder information, input the information to the linear layer <code class="docutils literal notranslate"><span class="pre">att</span></code> and the activation function <span class="math notranslate nohighlight">\(\text{tanh}\)</span>, and calculate the energy <span class="math notranslate nohighlight">\(E_t\)</span> between the hidden state of encoder and decoder.</p>
<div class="math notranslate nohighlight">
\[E_t = \tanh(\text{attn}(s_{t-1}, H))\]</div>
<p>For current <span class="math notranslate nohighlight">\(E_t\)</span>, the shape of the tensor in each batch is [dec hid dim, src len]. Note that the final attention weight needs to be applied to the source sequence. Therefore, the dimension of the attention weight should correspond to the dimension [src len] of the source sentence. To this end, we introduce a learnable tensor <span class="math notranslate nohighlight">\(v\)</span>.</p>
<div class="math notranslate nohighlight">
\[\hat{a}_t = v E_t\]</div>
<p>We can think of <span class="math notranslate nohighlight">\(v\)</span> as the weight of the weighted sum of all encoder hidden states, that is, the attention degree to each word in the source sequence. The parameter of <span class="math notranslate nohighlight">\(v\)</span> is randomly initialized and learned with the rest of the model in backpropagation. Besides, <span class="math notranslate nohighlight">\(v\)</span> does not depend on time, so <span class="math notranslate nohighlight">\(v\)</span> used for each time step in decoding is consistent.</p>
<p>Finally, we use the <span class="math notranslate nohighlight">\(\text{softmax}\)</span> function to ensure that the size of each element in the attention vector <span class="math notranslate nohighlight">\(a_t\)</span> ranges from 0 to 1 and the sum of all elements is 1.</p>
<div class="math notranslate nohighlight">
\[a_t = \text{softmax}(\hat{a_t})\]</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hid_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">,</span> <span class="n">is_ascend</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">is_ascend</span><span class="p">:</span>
            <span class="c1"># Attention linear layer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">((</span><span class="n">enc_hid_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">dec_hid_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">compute_dtype</span><span class="p">)</span>
            <span class="c1"># v, represented by a linear layer without bias</span>
            <span class="c1"># shape = [1, dec hid dim]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">dec_hid_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">compute_dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">((</span><span class="n">enc_hid_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">dec_hid_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">dec_hid_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Attention layer</span>

<span class="sd">        Args:</span>
<span class="sd">            hidden: indicates the hidden state of the decoder at the previous time. shape = [batch size, dec hid dim]</span>
<span class="sd">            encoder_outputs: indicates the encoder output, forward and reverse RNN hidden state. shape = [src len, batch size, enc hid dim * 2]</span>
<span class="sd">            mask: replaces the attention weight of the &lt;pad&gt; placeholder with 0 or a small value. shape = [batch size, src len]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">src_len</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Repeat the decoder hidden state *src len* times to unify dimensions.</span>
        <span class="c1"># shape = [batch size, src len, dec hid dim]</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">hidden</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># Exchange the first and second dimensions in the encoder output to unify dimensions.</span>
        <span class="c1"># shape = [batch size, src len, enc hid dim*2]</span>
        <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Calculate E_t.</span>
        <span class="c1"># shape = [batch size, src len, dec hid dim]</span>
        <span class="n">energy</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)))</span>

        <span class="c1"># Calculate v * E_t.</span>
        <span class="c1"># shape = [batch size, src len]</span>
        <span class="n">attention</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">(</span><span class="n">energy</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># The attention weight of the &lt;pad&gt; placeholder in the sequence does not need to be considered.</span>
        <span class="n">attention</span> <span class="o">=</span> <span class="n">attention</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1e10</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attention</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="decoder">
<h3>Decoder<a class="headerlink" href="#decoder" title="Permalink to this headline"></a></h3>
<p>The decoder contains the attention layer. We apply the obtained attention weight vector <span class="math notranslate nohighlight">\(a_t\)</span> on the encoder hidden state <span class="math notranslate nohighlight">\(H\)</span> to obtain a vector <span class="math notranslate nohighlight">\(w_t\)</span> representing a weighted sum of the encoder hidden states.</p>
<div class="math notranslate nohighlight">
\[w_t = a_t H\]</div>
<p>We pass the vector <span class="math notranslate nohighlight">\(w_t\)</span>, together with the embedded input word <span class="math notranslate nohighlight">\(d(y_t)\)</span> and the previous decoder hidden state <span class="math notranslate nohighlight">\(s_{t-1}\)</span>, into the decoder RNN network, and send the output to the linear layer <span class="math notranslate nohighlight">\(f\)</span> to obtain a word prediction at the next time in the target sentence.</p>
<div class="math notranslate nohighlight">
\[s_t = \text{DecoderGRU}(d(y_t), w_t, s_{t-1})\]</div>
<div class="math notranslate nohighlight">
\[\hat{y}_{t+1} = f(d(y_t), w_t, s_t)\]</div>
<p><img alt="avatar5" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/application/source_zh_cn/nlp/images/seq2seq_5.png" /></p>
<blockquote>
<div><p>Image source:</p>
<p><a class="reference external" href="https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb">https://github.com/bentrevett/pytorch-seq2seq/blob/master/3 - Neural Machine Translation by Jointly Learning to Align and Translate.ipynb</a></p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="n">enc_hid_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">attention</span><span class="p">,</span> <span class="n">is_ascend</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_ascend</span> <span class="o">=</span> <span class="n">is_ascend</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">attention</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">is_ascend</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">((</span><span class="n">enc_hid_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">compute_dtype</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">((</span><span class="n">enc_hid_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">dec_hid_dim</span> <span class="o">+</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">compute_dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">((</span><span class="n">enc_hid_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">((</span><span class="n">enc_hid_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">dec_hid_dim</span> <span class="o">+</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="o">-</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Decoder Building</span>

<span class="sd">        Args:</span>
<span class="sd">            input: indicates the input words. shape = [batch size]</span>
<span class="sd">            hidden: indicates the hidden state of the decoder at the previous time. shape = [batch size, dec hid dim]</span>
<span class="sd">            encoder_outputs: indicates the encoder output, forward and reverse RNN hidden state. shape = [src len, batch size, enc hid dim * 2]</span>
<span class="sd">            mask: replaces the attention weight of the &lt;pad&gt; placeholder with 0 or a small value. shape = [batch size, src len]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Add additional dimensions for the input.</span>
        <span class="c1"># shape = [1, batch size]</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Embedding output of the input word, d (y_t)</span>
        <span class="c1"># shape = [1, batch size, emb dim]</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_ascend</span><span class="p">:</span>
            <span class="n">embedded</span> <span class="o">=</span> <span class="n">embedded</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">compute_dtype</span><span class="p">)</span>

        <span class="c1"># Attention weight vector, a_t</span>
        <span class="c1"># shape = [batch size, src len]</span>
        <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

        <span class="c1"># Add additional dimensions for the attention weight.</span>
        <span class="c1"># shape = [batch size, 1, src len]</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Exchange the first and second dimensions in the encoder hidden state.</span>
        <span class="c1"># shape = [batch size, src len, enc hid dim * 2]</span>
        <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Calculate w_t.</span>
        <span class="c1"># shape = [batch size, 1, enc hid dim * 2]</span>
        <span class="n">weighted</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>

        <span class="c1"># Exchange the first and second dimensions of w_t.</span>
        <span class="c1"># shape = [1, batch size, enc hid dim * 2]</span>
        <span class="n">weighted</span> <span class="o">=</span> <span class="n">weighted</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Stack the embedded and weighted, and then pass them into the RNN layer.</span>
        <span class="c1"># rnn_input shape = [1, batch size, (enc hid dim * 2) + emb dim]</span>
        <span class="c1"># output shape = [seq len = 1, batch size, dec hid dim * n directions]</span>
        <span class="c1"># hidden shape = [n layers (1) * n directions (1) = 1, batch size, dec hid dim]</span>
        <span class="n">rnn_input</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">embedded</span><span class="p">,</span> <span class="n">weighted</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">rnn_input</span><span class="p">,</span> <span class="n">hidden</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

        <span class="c1"># Remove the redundancy of dimension 1.</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="n">embedded</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">weighted</span> <span class="o">=</span> <span class="n">weighted</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Stack the embedded, weighted, and hidden, and pass them into the linear layer to predict the next word.</span>
        <span class="c1"># shape = [batch size, output dim]</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_out</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">output</span><span class="p">,</span> <span class="n">weighted</span><span class="p">,</span> <span class="n">embedded</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">hidden</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">a</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="seq2seq">
<h3>Seq2Seq<a class="headerlink" href="#seq2seq" title="Permalink to this headline"></a></h3>
<p>The Seq2Seq wrapper merges the encoder and decoder we created earlier.</p>
<p>The overall process is as follows:</p>
<ol class="arabic simple">
<li><p>An empty number column <code class="docutils literal notranslate"><span class="pre">outputs</span></code> is initialized to store every prediction result.</p></li>
<li><p>The source sequence <span class="math notranslate nohighlight">\(X\)</span> is used as the encoder input to output <span class="math notranslate nohighlight">\(z\)</span> and <span class="math notranslate nohighlight">\(H\)</span>.</p></li>
<li><p>The initial decoder hidden state is a context vector output in the encoder, that is, the last encoder hidden state <span class="math notranslate nohighlight">\(s_0 = z = h_T\)</span>.</p></li>
<li><p>The initial decoder input <span class="math notranslate nohighlight">\(y_1\)</span> is a placeholder &lt;bos&gt; indicating the start of a sequence.</p></li>
<li><p>Repeat the following steps:</p>
<ul class="simple">
<li><p>Set the input <span class="math notranslate nohighlight">\(y_t\)</span> of <span class="math notranslate nohighlight">\(t\)</span> at this time, the previous hidden state <span class="math notranslate nohighlight">\(s_{t-1}\)</span>, and all encoder hidden states <span class="math notranslate nohighlight">\(H\)</span> as inputs.</p></li>
<li><p>Output a prediction <span class="math notranslate nohighlight">\(\hat{y}_{t+1}\)</span> for the next time and a new hidden state <span class="math notranslate nohighlight">\(s_t\)</span>.</p></li>
<li><p>Save the prediction result to <code class="docutils literal notranslate"><span class="pre">outputs</span></code>.</p></li>
<li><p>Determine whether to use teacher forcing. If yes, use <span class="math notranslate nohighlight">\(y_{t+1} = \hat{y}_{t+1}\)</span>. If no, the word in the target sequence is used as the input at the next time.</p></li>
</ul>
</li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="k">class</span> <span class="nc">Seq2Seq</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">src_pad_idx</span><span class="p">,</span> <span class="n">teacher_forcing_ratio</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">src_pad_idx</span> <span class="o">=</span> <span class="n">src_pad_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">teacher_forcing_ratio</span> <span class="o">=</span> <span class="n">teacher_forcing_ratio</span>  <span class="c1"># The possibility of using teacher forcing</span>

    <span class="k">def</span> <span class="nf">create_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Mark the position of the &lt;pad&gt; placeholder in each sequence.&quot;&quot;&quot;</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">src</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">src_pad_idx</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mask</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg</span><span class="p">,</span> <span class="n">trg_len</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Seq2Seq model building</span>

<span class="sd">        Args:</span>
<span class="sd">            src: indicates the source sequence. shape = [src len, batch size]</span>
<span class="sd">            src_len: indicates the length of a source sequence. shape = [batch size]</span>
<span class="sd">            trg: indicates the target sequence. shape = [trg len, batch size]</span>
<span class="sd">            trg_len: indicates the length of a target sequence. shape = [trg len, batch size]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">trg_len</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">trg_len</span> <span class="o">=</span> <span class="n">trg</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1">#Storage decoder output</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Encoder:</span>
        <span class="c1"># Input: the source sequence and source sequence length</span>
        <span class="c1"># Output 1: encoder_outputs, indicating the hidden state of all forward and reverse RNNs in the encoder</span>
        <span class="c1"># Output 2: hidden, indicating the output after the last encoder hidden state in the forward and reverse RNNs is passed into the linear layer</span>
        <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">)</span>

        <span class="c1">#The first decoder input is the placeholder &lt;bos&gt;, indicating the start of a sequence.</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Mark the position of the &lt;pad&gt; placeholder in the source sequence.</span>
        <span class="c1"># shape = [batch size, src len]</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_mask</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">trg_len</span><span class="p">):</span>

            <span class="c1"># Decoder:</span>
            <span class="c1"># Input: source sentence sequence (inputs), previous hidden state (hidden), and encoder hidden state of all forward and reverse RNNs</span>
            <span class="c1"># Mark &lt;pad&gt; in each sentence so that this part can be ignored when the attention weight is calculated.</span>
            <span class="c1"># Output: prediction result (output), new hidden status (hidden), and attention weight (ignored)</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

            <span class="c1"># Save the prediction result into the previous storage.</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

            <span class="c1">#Find the token with the maximum prediction probability.</span>
            <span class="n">top1</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="c1">#If the model is in the training state, teacher forcing is used based on the preset probability.</span>
                <span class="n">minval</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="n">maxval</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="n">teacher_force</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">teacher_forcing_ratio</span>
                <span class="c1"># If teacher forcing is used, the corresponding token in the target sequence is used as the next input.</span>
                <span class="c1"># If teacher forcing is not used, the prediction result is used as the next input.</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">if</span> <span class="n">teacher_force</span> <span class="k">else</span> <span class="n">top1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">top1</span>

        <span class="c1"># Integrate all output as a tensor.</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="model-training">
<h2>Model Training<a class="headerlink" href="#model-training" title="Permalink to this headline"></a></h2>
<p>Model parameters, encoder, attention layer, decoder, and Seq2Seq network initialization.</p>
<p>Here we manually implement mixed precision, i.e. we compute with <code class="docutils literal notranslate"><span class="pre">compute_dtype</span></code> (mindspore.float16) in the process and convert the result back to <code class="docutils literal notranslate"><span class="pre">dtype</span></code> (mindspore.float32) in the final output.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">input_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">de_vocab</span><span class="p">)</span> <span class="c1"># Input dimension</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">en_vocab</span><span class="p">)</span> <span class="c1"># Output dimension</span>
<span class="n">enc_emb_dim</span> <span class="o">=</span> <span class="mi">256</span> <span class="c1"># Encoder embedding layer dimension</span>
<span class="n">dec_emb_dim</span> <span class="o">=</span> <span class="mi">256</span> <span class="c1"># Decoder embedding layer dimension</span>
<span class="n">enc_hid_dim</span> <span class="o">=</span> <span class="mi">512</span> <span class="c1"># Encoder hidden layer dimension</span>
<span class="n">dec_hid_dim</span> <span class="o">=</span> <span class="mi">512</span> <span class="c1"># Decoder hidden layer dimension</span>
<span class="n">enc_dropout</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Encoder Dropout</span>
<span class="n">dec_dropout</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Decoder Dropout</span>
<span class="n">src_pad_idx</span> <span class="o">=</span> <span class="n">de_vocab</span><span class="o">.</span><span class="n">pad_idx</span>  <span class="c1"># Numeric index of the pad placeholder in the German vocabulary</span>
<span class="n">trg_pad_idx</span> <span class="o">=</span> <span class="n">en_vocab</span><span class="o">.</span><span class="n">pad_idx</span>  <span class="c1"># Numeric index of the pad placeholder in the English vocabulary</span>

<span class="n">is_ascend</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">get_context</span><span class="p">(</span><span class="s1">&#39;device_target&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;Ascend&#39;</span>
<span class="n">compute_dtype</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float16</span>  <span class="c1"># Data type in calculation</span>
<span class="n">dtype</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span> <span class="c1"># Type of the returned data</span>

<span class="n">attn</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">enc_hid_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">,</span> <span class="n">is_ascend</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">enc_emb_dim</span><span class="p">,</span> <span class="n">enc_hid_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">,</span> <span class="n">enc_dropout</span><span class="p">,</span> <span class="n">is_ascend</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">dec_emb_dim</span><span class="p">,</span> <span class="n">enc_hid_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">,</span> <span class="n">dec_dropout</span><span class="p">,</span> <span class="n">attn</span><span class="p">,</span> <span class="n">is_ascend</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Seq2Seq</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">src_pad_idx</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize the loss function and optimizer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span> <span class="c1"># Loss function</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="n">trg_pad_idx</span><span class="p">)</span> <span class="c1"># Optimizer</span>
</pre></div>
</div>
<p>Note that the updated weight may be too large during model training. This will cause value overflow or underflow, resulting in gradient explosion. To solve this problem, you need to use gradient clipping after calculating the gradient after backpropagation, and then transfer the clipped gradient to the optimizer for network update.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="k">def</span> <span class="nf">clip_by_norm</span><span class="p">(</span><span class="n">clip_norm</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Regularize the tensor t based on the given tensor t and clipping parameter clip_norm.</span>

<span class="sd">    So that L2-norm of t in the axes dimension is less than or equal to the value of clip_norm.</span>

<span class="sd">    Args:</span>
<span class="sd">        t: tensor of type float</span>
<span class="sd">        clip_norm: scalar of type float. It is the gradient clipping threshold. The value must be greater than 0.</span>
<span class="sd">        axis: Union[None, int, tuple(int)]. The data type is int32. Calculate the L2-norm dimension, if the result is Norm, all dimensions are referenced.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Calculate L2-norm.</span>
    <span class="n">t2</span> <span class="o">=</span> <span class="n">t</span> <span class="o">*</span> <span class="n">t</span>
    <span class="n">l2sum</span> <span class="o">=</span> <span class="n">t2</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">l2sum</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="c1"># Replace the element whose value is 0 in the sum with 1 to avoid NaN.</span>
    <span class="n">l2sum_safe</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">l2sum</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">l2sum</span><span class="p">))</span>
    <span class="n">l2norm</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">l2sum_safe</span><span class="p">),</span> <span class="n">l2sum</span><span class="p">)</span>
    <span class="c1"># Compare the value of L2-norm with clip_norm. If the value of L2-norm exceeds the threshold, perform the clipping.</span>
    <span class="c1"># Clipping method: output(x) = (x * clip_norm)/max(|x|, clip_norm)</span>
    <span class="n">intermediate</span> <span class="o">=</span> <span class="n">t</span> <span class="o">*</span> <span class="n">clip_norm</span>
    <span class="n">cond</span> <span class="o">=</span> <span class="n">l2norm</span> <span class="o">&gt;</span> <span class="n">clip_norm</span>
    <span class="n">t_clip</span> <span class="o">=</span> <span class="n">intermediate</span> <span class="o">/</span> <span class="n">ops</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">l2norm</span><span class="p">,</span> <span class="n">clip_norm</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">t_clip</span>

</pre></div>
</div>
<p>During model training, use the validation dataset for validation and evaluation, and save the model with the best effect.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward_fn</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward network&quot;&quot;</span>
<span class="sd">    src = src.swapaxes(0, 1)</span>
<span class="sd">    trg = trg.swapaxes(0, 1)</span>

<span class="sd">    output = model(src, src_len, trg)</span>
<span class="sd">    output_dim = output.shape[-1]</span>
<span class="sd">    output = output.view(-1, output_dim)</span>
<span class="sd">    trg = trg[1:].view(-1)</span>
<span class="sd">    loss = loss_fn(output, trg)</span>

<span class="sd">    return loss</span>


<span class="sd"># Backpropagation calculation gradient</span>
<span class="sd">grad_fn = mindspore.value_and_grad(forward_fn, None, opt.parameters)</span>

<span class="sd">def train_step(src, src_len, trg, clip):</span>
<span class="sd">    &quot;&quot;&quot;</span><span class="n">Single</span><span class="o">-</span><span class="n">step</span> <span class="n">training</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    loss, grads = grad_fn(src, src_len, trg)</span>
<span class="s2">    grads = ops.HyperMap()(ops.partial(clip_by_norm, clip), grads) # Clipping gradient.</span>
<span class="s2">    opt(grads) #Update network parameters.</span>

<span class="s2">    return loss</span>


<span class="s2">def train(iterator, clip, epoch=0):</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="n">Model</span> <span class="n">training</span><span class="s2">&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># The training loss of all batches</span>
    <span class="n">total_steps</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># Number of training steps</span>

    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">num_batches</span><span class="p">)</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
        <span class="n">t</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg</span> <span class="ow">in</span> <span class="n">iterator</span><span class="p">():</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">train_step</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg</span><span class="p">,</span> <span class="n">clip</span><span class="p">)</span>  <span class="c1"># Loss of the current batch</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
            <span class="n">total_steps</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">curr_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">total_steps</span>  <span class="c1"># Average loss of current batch</span>
            <span class="n">t</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">curr_loss</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">})</span>
            <span class="n">t</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">total_steps</span>


<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">iterator</span><span class="p">):</span>
    <span class="s2">&quot;&quot;&quot;Model validation&quot;&quot;</span>
<span class="s2">    model.set_train(False)</span>
<span class="s2">    num_batches = len(iterator)</span>
<span class="s2">    total_loss = 0 # The training loss of all batches</span>
<span class="s2">    total_steps = 0 # Number of training steps</span>

<span class="s2">    with tqdm(total=num_batches) as t:</span>
<span class="s2">        for src, src_len, trg in iterator():</span>
<span class="s2">            loss = forward_fn(src, src_len, trg)  # Loss of the current batch</span>
<span class="s2">            total_loss += loss.asnumpy()</span>
<span class="s2">            total_steps += 1</span>
<span class="s2">            curr_loss = total_loss / total_steps  # Average loss of current batch</span>
<span class="s2">            t.set_postfix({&#39;loss&#39;: f&#39;</span><span class="si">{curr_loss:.2f}</span><span class="s2">&#39;})</span>
<span class="s2">            t.update(1)</span>

<span class="s2">    return total_loss / total_steps</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">save_checkpoint</span>

<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># Number of training epochs</span>
<span class="n">clip</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="c1"># Gradient clipping threshold</span>
<span class="n">best_valid_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span> <span class="c1"># Current best validation loss</span>
<span class="n">ckpt_file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">,</span> <span class="s1">&#39;seq2seq.ckpt&#39;</span><span class="p">)</span> <span class="c1"># Model save path</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="c1"># Train the model and update the network weight.</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">train_iterator</span><span class="p">,</span> <span class="n">clip</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="c1"># Validate the model after the network weight is updated.</span>
    <span class="n">valid_loss</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">valid_iterator</span><span class="p">)</span>

    <span class="c1"># Save the model with the best effect.</span>
    <span class="k">if</span> <span class="n">valid_loss</span> <span class="o">&lt;</span> <span class="n">best_valid_loss</span><span class="p">:</span>
        <span class="n">best_valid_loss</span> <span class="o">=</span> <span class="n">valid_loss</span>
        <span class="n">save_checkpoint</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ckpt_file_name</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Epoch: 0: 100%|██████████| 226/226 [04:17&lt;00:00,  1.14s/it, loss=4.90]
100%|██████████| 8/8 [00:06&lt;00:00,  1.24it/s, loss=4.74]
Epoch: 1: 100%|██████████| 226/226 [02:45&lt;00:00,  1.37it/s, loss=3.88]
100%|██████████| 8/8 [00:01&lt;00:00,  4.60it/s, loss=3.98]
Epoch: 2: 100%|██████████| 226/226 [02:46&lt;00:00,  1.36it/s, loss=3.19]
100%|██████████| 8/8 [00:01&lt;00:00,  4.54it/s, loss=3.63]
Epoch: 3: 100%|██████████| 226/226 [02:47&lt;00:00,  1.35it/s, loss=2.73]
100%|██████████| 8/8 [00:01&lt;00:00,  4.49it/s, loss=3.46]
Epoch: 4: 100%|██████████| 226/226 [02:48&lt;00:00,  1.34it/s, loss=2.40]
100%|██████████| 8/8 [00:01&lt;00:00,  4.56it/s, loss=3.38]
Epoch: 5: 100%|██████████| 226/226 [02:47&lt;00:00,  1.35it/s, loss=2.12]
100%|██████████| 8/8 [00:01&lt;00:00,  4.50it/s, loss=3.37]
Epoch: 6: 100%|██████████| 226/226 [02:45&lt;00:00,  1.37it/s, loss=1.91]
100%|██████████| 8/8 [00:01&lt;00:00,  4.55it/s, loss=3.40]
Epoch: 7: 100%|██████████| 226/226 [02:45&lt;00:00,  1.36it/s, loss=1.74]
100%|██████████| 8/8 [00:01&lt;00:00,  4.60it/s, loss=3.44]
Epoch: 8: 100%|██████████| 226/226 [02:45&lt;00:00,  1.37it/s, loss=1.59]
100%|██████████| 8/8 [00:01&lt;00:00,  4.54it/s, loss=3.44]
Epoch: 9: 100%|██████████| 226/226 [02:44&lt;00:00,  1.37it/s, loss=1.47]
100%|██████████| 8/8 [00:01&lt;00:00,  4.57it/s, loss=3.50]
</pre></div>
</div>
</section>
<section id="model-inference">
<h2>Model Inference<a class="headerlink" href="#model-inference" title="Permalink to this headline"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">translate_sentence</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Give a German sentence and return English translation.&quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># Segment the input sentences.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">tok</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\w+|[^\w\s]&#39;</span><span class="p">,</span> <span class="n">sentence</span><span class="o">.</span><span class="n">rstrip</span><span class="p">())]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">]</span>

    <span class="c1"># Add the start and end placeholders to unify the sequence length.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_len</span> <span class="o">-</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">src_len</span> <span class="o">=</span> <span class="n">max_len</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&lt;bos&gt;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">tokens</span><span class="p">[:</span><span class="n">max_len</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">src_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&lt;bos&gt;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">tokens</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_len</span> <span class="o">-</span> <span class="n">src_len</span><span class="p">)</span>

    <span class="c1"># Convert German words into numeric indexes.</span>
    <span class="n">src</span> <span class="o">=</span> <span class="n">de_vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
    <span class="n">src</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">src_len</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">src_len</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">trg</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">en_vocab</span><span class="o">.</span><span class="n">bos_idx</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Obtain the prediction result and convert it into English words.</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
    <span class="n">trg_indexes</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>
    <span class="n">eos_idx</span> <span class="o">=</span> <span class="n">trg_indexes</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">en_vocab</span><span class="o">.</span><span class="n">eos_idx</span><span class="p">)</span> <span class="k">if</span> <span class="n">en_vocab</span><span class="o">.</span><span class="n">eos_idx</span> <span class="ow">in</span> <span class="n">trg_indexes</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">trg_tokens</span> <span class="o">=</span> <span class="n">en_vocab</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">trg_indexes</span><span class="p">[:</span><span class="n">eos_idx</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">trg_tokens</span>
</pre></div>
</div>
<p>Use any set of text in the test dataset for prediction.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>

<span class="c1"># Load the trained model.</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">ckpt_file_name</span><span class="p">)</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>

<span class="c1"># Take the first group of sentences in the test dataset as an example.</span>
<span class="n">example_idx</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">src</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="p">[</span><span class="n">example_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">trg</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="p">[</span><span class="n">example_idx</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;src = </span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;trg = </span><span class="si">{</span><span class="n">trg</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>src = [&#39;ein&#39;, &#39;mann&#39;, &#39;mit&#39;, &#39;einem&#39;, &#39;orangefarbenen&#39;, &#39;hut&#39;, &#39;,&#39;, &#39;der&#39;, &#39;etwas&#39;, &#39;anstarrt&#39;, &#39;.&#39;]
trg = [&#39;a&#39;, &#39;man&#39;, &#39;in&#39;, &#39;an&#39;, &#39;orange&#39;, &#39;hat&#39;, &#39;starring&#39;, &#39;at&#39;, &#39;something&#39;, &#39;.&#39;]
</pre></div>
</div>
<p>View the prediction results.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">translation</span> <span class="o">=</span> <span class="n">translate_sentence</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;predicted trg = </span><span class="si">{</span><span class="n">translation</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>predicted trg = [&#39;a&#39;, &#39;man&#39;, &#39;in&#39;, &#39;an&#39;, &#39;orange&#39;, &#39;hat&#39;, &#39;,&#39;, &#39;something&#39;, &#39;.&#39;]
</pre></div>
</div>
</section>
<section id="bleu-score">
<h2>BLEU Score<a class="headerlink" href="#bleu-score" title="Permalink to this headline"></a></h2>
<p>The bilingual evaluation understudy (BLEU) is an algorithm for measuring the quality of sentences generated by the text translation model. It focuses on evaluating the similarity between the translation <span class="math notranslate nohighlight">\(\text{pred}\)</span> by machine and the reference translation <span class="math notranslate nohighlight">\(\text{label}\)</span> by humans. The score of each segment is calculated by comparing the segments of the machine translation with the reference translation, and the score is summed up with the weight. The basic rule is as follows:</p>
<ol class="arabic simple">
<li><p>Punish predictions that are too short. That is, if a machine translation is excessively short compared to a reference translation, it will be imposed penalty with high hit rate.</p></li>
<li><p>Configure high weights for long paragraphs. That is, if a complete hit of a long paragraph occurs, it indicates that the machine translation is close to the reference translation.</p></li>
</ol>
<p>The BLEU formula is as follows:</p>
<div class="math notranslate nohighlight">
\[exp(min(0, 1-\frac{len(\text{label})}{len(\text{pred})})\Pi^k_{n=1}p_n^{1/2^n})\]</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">len(label)</span></code>: length of the translation by humans</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">len(pred)</span></code>: length of the translation by machine</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">p_n</span></code>: n-gram precision</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.translate.bleu_score</span> <span class="kn">import</span> <span class="n">corpus_bleu</span>

<span class="k">def</span> <span class="nf">calculate_bleu</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
    <span class="n">trgs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">pred_trgs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>

        <span class="n">src</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1">#Source sentences: German</span>
        <span class="n">trg</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1">#Target sentences: English</span>

        <span class="c1"># Obtain the model prediction result.</span>
        <span class="n">pred_trg</span> <span class="o">=</span> <span class="n">translate_sentence</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
        <span class="n">pred_trgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_trg</span><span class="p">)</span>
        <span class="n">trgs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">trg</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">corpus_bleu</span><span class="p">(</span><span class="n">trgs</span><span class="p">,</span> <span class="n">pred_trgs</span><span class="p">)</span>

<span class="c1"># Calculate the BLEU score.</span>
<span class="n">bleu_score</span> <span class="o">=</span> <span class="n">calculate_bleu</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;BLEU score = </span><span class="si">{</span><span class="n">bleu_score</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>BLEU score = 31.54
</pre></div>
</div>
</section>
<section id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline"></a></h2>
<p>Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning
to align and translate. arXiv preprint arXiv:1409.0473.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="sequence_labeling.html" class="btn btn-neutral float-left" title="LSTM+CRF Sequence Labeling" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../generative/gan.html" class="btn btn-neutral float-right" title="GAN for Image Generation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>