

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Generating Cartoon Head Portrait via DCGAN &mdash; MindSpore master documentation</title>
  

  
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Sentiment Classification Implemented by RNN" href="../nlp/sentiment_analysis.html" />
    <link rel="prev" title="Model Adversarial Attack" href="fgsm.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">CV</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="resnet50.html">ResNet-50 for Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="transfer_learning.html">Image Classification Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="fgsm.html">Model Adversarial Attack</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Generating Cartoon Head Portrait via DCGAN</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#gan-basic-principle">GAN Basic Principle</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dcgan-basic-principle">DCGAN Basic Principle</a></li>
<li class="toctree-l2"><a class="reference internal" href="#data-preparation-and-processing">Data Preparation and Processing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#data-processing">Data Processing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#setting-up-a-gan">Setting Up a GAN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#generator">Generator</a></li>
<li class="toctree-l3"><a class="reference internal" href="#discriminator">Discriminator</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loss-and-optimizer">Loss and Optimizer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#loss-function">Loss Function</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#optimizer">Optimizer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#training-mode">Training Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="#result">Result</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">NLP</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../nlp/sentiment_analysis.html">Sentiment Classification Implemented by RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nlp/sequence_labeling.html">LSTM+CRF Sequence Labeling</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Generating Cartoon Head Portrait via DCGAN</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/cv/dcgan.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="generating-cartoon-head-portrait-via-dcgan">
<h1>Generating Cartoon Head Portrait via DCGAN<a class="headerlink" href="#generating-cartoon-head-portrait-via-dcgan" title="Permalink to this headline">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.8/tutorials/application/source_en/cv/dcgan.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_source_en.png"></a></p>
<p>In the following tutorial, we will use sample code to show how to set up the network, optimizer, calculate the loss function, and initialize the model weight. This <a class="reference external" href="https://download.mindspore.cn/dataset/Faces/faces.zip">Anime Avatar Face Image Dataset</a> contains 70,171 96 x 96 anime avatar face images.</p>
<div class="section" id="gan-basic-principle">
<h2>GAN Basic Principle<a class="headerlink" href="#gan-basic-principle" title="Permalink to this headline">¶</a></h2>
<p>Generative Adversarial Network (GAN) is a deep learning model, and is recently one of the most promising methods for unsupervised learning in complex distribution.</p>
<p>GAN was first proposed by Ian J. Goodfellow in his paper <a class="reference external" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">Generative Adversarial Nets</a> in 2014. It consists of two different models: <strong>generator</strong> and <strong>discriminator</strong>.</p>
<ul class="simple">
<li><p>The generator generates “fake” images that look like the images for training.</p></li>
<li><p>The discriminator determines whether the images output by the generator are real training images or fake images.</p></li>
</ul>
<p>In the training process, the generator continuously attempts to deceive the discriminator by generating a better fake image, and the discriminator gradually improves the capability of discriminating images in this process. It reaches the nash equilibrium when the distribution of the fake image generated by the generator is the same as that of the training image, that is, the confidence of true/false judgment of the discriminator is 50%. Let’s see some symbols that need to be used in the entire process:</p>
<p>Discriminator symbols:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span>: image data</p></li>
<li><p><span class="math notranslate nohighlight">\(D(x)\)</span>: discriminator network, which provides the probability of determining an image as a real image.</p></li>
</ul>
<p>During the discrimination, <span class="math notranslate nohighlight">\(D(x)\)</span> needs to process a 3 x 64 x 64 image in CHW format. When <span class="math notranslate nohighlight">\(x\)</span> comes from training data, the value of <span class="math notranslate nohighlight">\(D(x)\)</span> should be approximate to 1. When <span class="math notranslate nohighlight">\(x\)</span> comes from the generator, the value of <span class="math notranslate nohighlight">\(D(x)\)</span> should be approximate to 0. Therefore, <span class="math notranslate nohighlight">\(D(x)\)</span> may also be considered as a conventional binary classifier.</p>
<p>Generator symbols:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(z\)</span>: implicit vector extracted from the standard normal distribution</p></li>
<li><p><span class="math notranslate nohighlight">\(G(z)\)</span>: generator function that maps implicit vector <span class="math notranslate nohighlight">\(z\)</span> to the data space</p></li>
</ul>
<p>Function <span class="math notranslate nohighlight">\(G(z)\)</span> is used to generate a data distribution similar to the real data distribution <span class="math notranslate nohighlight">\(pdata(x)\)</span> based on the random Gaussian noise <span class="math notranslate nohighlight">\(z\)</span> by using a generative network, where <span class="math notranslate nohighlight">\(θ\)</span> is a network parameter. We want to find an optimal <span class="math notranslate nohighlight">\(θ\)</span> value so that <span class="math notranslate nohighlight">\(pG(x;θ)\)</span> and <span class="math notranslate nohighlight">\(pdata(x)\)</span> are as close as possible.</p>
<p><span class="math notranslate nohighlight">\(D(G(z))\)</span> indicates the probability that the fake image generated by the generator <span class="math notranslate nohighlight">\(G\)</span> is determined to be a real image. As described in <a class="reference external" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">Goodfellow’s paper</a>, <code class="docutils literal notranslate"><span class="pre">D</span></code> and <code class="docutils literal notranslate"><span class="pre">G</span></code> are in a game. <code class="docutils literal notranslate"><span class="pre">D</span></code> wants to correctly classify real and fake images to the greatest extent, that is, parameter <span class="math notranslate nohighlight">\(log D(x)\)</span>. <code class="docutils literal notranslate"><span class="pre">G</span></code> attempts to deceive <code class="docutils literal notranslate"><span class="pre">D</span></code> to minimize the probability that the fake image is recognized, that is, parameter <span class="math notranslate nohighlight">\(log(1−D(G(z)))\)</span>. A loss function of the GAN is as follows:</p>
<div class="math notranslate nohighlight">
\[\min_{G}\max_{D}V(D,G)=E_{x\sim_Pdata(x)}[log(D(x))]+E_{z\sim_Pz(z)}[log(1-D(G(z)))]\]</div>
<p>Theoretically, it reaches the nash equilibrium when <span class="math notranslate nohighlight">\(pG(x;θ) = pdata(x)\)</span>, where the discriminator randomly guesses whether the input is a real or fake image. The following describes the game process of the generator and discriminator:</p>
<p><img alt="gan" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/tutorials/application/source_zh_cn/cv/images/gan_image.png" /></p>
<p>In the preceding figure, the blue dotted line indicates the discriminator, the black dotted line indicates the real data distribution, the green solid line indicates the false data distribution generated by the generator, z indicates the implicit vector, and x indicates the generated fake image G(z).</p>
<ol class="simple">
<li><p>At the beginning of the training, the quality of the generator and discriminator is poor. The generator randomly generates a data distribution.</p></li>
<li><p>The discriminator optimizes the network by calculating the gradient and loss function. The data close to the real data distribution is determined as 1, and the data close to the data distribution generated by the generator is determined as 0.</p></li>
<li><p>The generator generates data that is closer to the actual data distribution through optimization.</p></li>
<li><p>The data generated by the generator reaches the same distribution as the real data. In this case, the output of the discriminator is 1/2.</p></li>
</ol>
</div>
<div class="section" id="dcgan-basic-principle">
<h2>DCGAN Basic Principle<a class="headerlink" href="#dcgan-basic-principle" title="Permalink to this headline">¶</a></h2>
<p>Deep Convolutional Generative Adversarial Network (DCGAN) is a direct extension of GAN. The difference is that DCGAN uses convolution and transposed convolutional layers in the discriminator and generator, respectively.</p>
<p>It was first proposed by Radford et al. in paper <a class="reference external" href="https://arxiv.org/pdf/1511.06434.pdf">Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks</a>. The discriminator consists of a hierarchical convolutional layer, a BatchNorm layer, and a LeakyReLU activation layer. Its input is a 3 x 64 x 64 image, and the output is the probability that the image is a real image. The generator consists of a transposed convolutional layer, a BatchNorm layer, and a ReLU activation layer. Its input is the implicit vector <span class="math notranslate nohighlight">\(z\)</span> extracted from the standard normal distribution, and the output is a 3 x 64 x 64 RGB image.</p>
<p>This tutorial uses the anime face dataset to train a GAN, which is then used to generate anime avatar face images.</p>
</div>
<div class="section" id="data-preparation-and-processing">
<h2>Data Preparation and Processing<a class="headerlink" href="#data-preparation-and-processing" title="Permalink to this headline">¶</a></h2>
<p>First, download the dataset to the specified directory and decompress it. The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindvision</span> <span class="kn">import</span> <span class="n">dataset</span>

<span class="n">dl_path</span> <span class="o">=</span> <span class="s2">&quot;./datasets&quot;</span>
<span class="n">dl_url</span> <span class="o">=</span> <span class="s2">&quot;https://download.mindspore.cn/dataset/Faces/faces.zip&quot;</span>

<span class="n">dl</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">DownLoad</span><span class="p">()</span> <span class="c1"># Download the dataset.</span>
<span class="n">dl</span><span class="o">.</span><span class="n">download_and_extract_archive</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">dl_url</span><span class="p">,</span> <span class="n">download_path</span><span class="o">=</span><span class="n">dl_path</span><span class="p">)</span>
</pre></div>
</div>
<p>The directory structure of the downloaded dataset is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./datasets/faces
├── 0.jpg
├── 1.jpg
├── 2.jpg
├── 3.jpg
├── 4.jpg
    ...
├── 70169.jpg
└── 70170.jpg
</pre></div>
</div>
<div class="section" id="data-processing">
<h3>Data Processing<a class="headerlink" href="#data-processing" title="Permalink to this headline">¶</a></h3>
<p>First, define some inputs for the execution process:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="c1"># Use the graph execution mode and specify the training platform to GPU. If the Ascend platform is required, replace it with Ascend.</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;GPU&quot;</span><span class="p">)</span>

<span class="n">data_root</span> <span class="o">=</span> <span class="s2">&quot;./datasets&quot;</span>  <span class="c1"># Dataset root directory</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span> <span class="c1"># Batch size</span>
<span class="n">image_size</span> <span class="o">=</span> <span class="mi">64</span> <span class="c1"># Size of the training image.</span>
<span class="n">nc</span> <span class="o">=</span> <span class="mi">3</span> <span class="c1"># Number of color channels.</span>
<span class="n">nz</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># Length of the implicit vector</span>
<span class="n">ngf</span> <span class="o">=</span> <span class="mi">64</span> <span class="c1"># Size of the feature map in the generator</span>
<span class="n">ndf</span> <span class="o">=</span> <span class="mi">64</span> <span class="c1"># Size of the feature map in the discriminator</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># Number of training epochs</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.0002</span> <span class="c1"># Learning rate</span>
<span class="n">beta1</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Beta 1 hyperparameter of the Adam optimizer</span>
</pre></div>
</div>
<p>Define the <code class="docutils literal notranslate"><span class="pre">create_dataset_imagenet</span></code> function to process and augment data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision</span> <span class="k">as</span> <span class="nn">vision</span>

<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">ops</span>

<span class="k">def</span> <span class="nf">create_dataset_imagenet</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Data loading&quot;&quot;&quot;</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">ImageFolderDataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                     <span class="n">decode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Data augmentation</span>
    <span class="n">transform_img</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">(),</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">((</span><span class="n">x</span> <span class="o">/</span> <span class="mi">255</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">nz</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">))</span>
    <span class="p">]</span>

    <span class="c1"># Data mapping</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">operations</span><span class="o">=</span><span class="n">transform_img</span><span class="p">,</span> <span class="n">column_order</span><span class="o">=</span><span class="p">[</span>\<span class="s2">&quot;image</span><span class="se">\&quot;</span><span class="s2">, </span><span class="se">\&quot;</span><span class="s2">latent_code</span><span class="se">\&quot;</span><span class="s2">])</span>

    <span class="c1"># Batch operation</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data_set</span>

<span class="c1"># Obtain the processed dataset.</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">create_dataset_imagenet</span><span class="p">(</span><span class="n">data_root</span><span class="p">)</span>

<span class="c1"># Obtain the dataset size.</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>
</pre></div>
</div>
<p>Use the <code class="docutils literal notranslate"><span class="pre">create_dict_iterator</span></code> function to convert data into a dictionary iterator, and then use the <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> module to visualize some training data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">data_iter</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

<span class="c1"># Visualize some training data.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">140</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">image</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_iter</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">][:</span><span class="mi">30</span><span class="p">],</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="png" src="../_images/output_81_0.png" /></p>
</div>
</div>
<div class="section" id="setting-up-a-gan">
<h2>Setting Up a GAN<a class="headerlink" href="#setting-up-a-gan" title="Permalink to this headline">¶</a></h2>
<p>After the data is processed, you can set up a GAN. According to the DCGAN paper, all model weights should be randomly initialized from a normal distribution with <code class="docutils literal notranslate"><span class="pre">mean</span></code> of 0 and <code class="docutils literal notranslate"><span class="pre">sigma</span></code> of 0.02.</p>
<div class="section" id="generator">
<h3>Generator<a class="headerlink" href="#generator" title="Permalink to this headline">¶</a></h3>
<p>Generator <code class="docutils literal notranslate"><span class="pre">G</span></code> maps the implicit vector <code class="docutils literal notranslate"><span class="pre">z</span></code> to the data space. Because the data is an image, this process also creates an RGB image with the same size as the real image. In practice, this function is implemented by using a series of <code class="docutils literal notranslate"><span class="pre">Conv2dTranspose</span></code> transposed convolutional layers. Each layer is paired with the <code class="docutils literal notranslate"><span class="pre">BatchNorm2d</span></code> layer and <code class="docutils literal notranslate"><span class="pre">ReLu</span></code> activation layer. The output data passes through the <code class="docutils literal notranslate"><span class="pre">tanh</span></code> function and returns a value within the data range of <code class="docutils literal notranslate"><span class="pre">[–1,1]</span></code>.</p>
<p>The following shows the image generated by DCGAN:</p>
<p><img alt="dcgangenerator" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/tutorials/application/source_zh_cn/cv/images/dcgan.png" /></p>
<blockquote>
<div><p>Image source: https://arxiv.org/pdf/1511.06434.pdf</p>
</div></blockquote>
<p>The generator structure in the code is determined by <code class="docutils literal notranslate"><span class="pre">nz</span></code>, <code class="docutils literal notranslate"><span class="pre">ngf</span></code>, and <code class="docutils literal notranslate"><span class="pre">nc</span></code> set in the input. <code class="docutils literal notranslate"><span class="pre">nz</span></code> is the length of implicit vector <code class="docutils literal notranslate"><span class="pre">z</span></code>, <code class="docutils literal notranslate"><span class="pre">ngf</span></code> determines the size of the feature map propagated by the generator, and <code class="docutils literal notranslate"><span class="pre">nc</span></code> is the number of channels in the output image.</p>
<p>The code implementation of the generator is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">initializer</span> <span class="k">as</span> <span class="n">init</span>

<span class="k">def</span> <span class="nf">conv_t</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;pad&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Define the transposed convolutional layer.&quot;&quot;&quot;</span>
    <span class="n">weight_init</span> <span class="o">=</span> <span class="n">init</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2dTranspose</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span>
                              <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                              <span class="n">weight_init</span><span class="o">=</span><span class="n">weight_init</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="n">pad_mode</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">bn</span><span class="p">(</span><span class="n">num_features</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Define the BatchNorm2d layer.&quot;&quot;&quot;</span>
    <span class="n">gamma_init</span> <span class="o">=</span> <span class="n">init</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="n">num_features</span><span class="p">,</span> <span class="n">gamma_init</span><span class="o">=</span><span class="n">gamma_init</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;DCGAN generator&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv_t</span><span class="p">(</span><span class="n">nz</span><span class="p">,</span> <span class="n">ngf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv_t</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">ngf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv_t</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">ngf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv_t</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">ngf</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn</span><span class="p">(</span><span class="n">ngf</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv_t</span><span class="p">(</span><span class="n">ngf</span><span class="p">,</span> <span class="n">nc</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Instantiate the generator.</span>
<span class="n">netG</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="discriminator">
<h3>Discriminator<a class="headerlink" href="#discriminator" title="Permalink to this headline">¶</a></h3>
<p>As described above, discriminator <code class="docutils literal notranslate"><span class="pre">D</span></code> is a binary network model, and outputs the probability that the image is determined as a real image. It is processed through a series of <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code>, <code class="docutils literal notranslate"><span class="pre">BatchNorm2d</span></code>, and <code class="docutils literal notranslate"><span class="pre">LeakyReLU</span></code> layers and obtains the final probability through the Sigmoid activation function.</p>
<p>The DCGAN paper mentions that using convolution instead of pooling for downsampling is a good way because it allows the network to learn its own pooling characteristics.</p>
<p>The code implementation of the discriminator is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;pad&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Define the convolutional layers.&quot;&quot;&quot;</span>
    <span class="n">weight_init</span> <span class="o">=</span> <span class="n">init</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span>
                     <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                     <span class="n">weight_init</span><span class="o">=</span><span class="n">weight_init</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="n">pad_mode</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;DCGAN discriminator&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">nc</span><span class="p">,</span> <span class="n">ndf</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">ndf</span><span class="p">,</span> <span class="n">ndf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn</span><span class="p">(</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">ndf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn</span><span class="p">(</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">ndf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn</span><span class="p">(</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Instantiate the discriminator.</span>
<span class="n">netD</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="loss-and-optimizer">
<h3>Loss and Optimizer<a class="headerlink" href="#loss-and-optimizer" title="Permalink to this headline">¶</a></h3>
<p>MindSpore encapsulates the loss function and optimizer into cells. Due to the particularity of the GAN structure, the loss of the GAN is the multi-output form of the discriminator and generator, which makes the GAN different from a common classification network. Therefore, we need to customize the <code class="docutils literal notranslate"><span class="pre">WithLossCell</span></code> class to connect the loss function to the GAN.</p>
</div>
</div>
<div class="section" id="loss-function">
<h2>Loss Function<a class="headerlink" href="#loss-function" title="Permalink to this headline">¶</a></h2>
<p>When <code class="docutils literal notranslate"><span class="pre">D</span></code> and <code class="docutils literal notranslate"><span class="pre">G</span></code> are defined, the binary cross-entropy loss function <a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/nn/mindspore.nn.BCELoss.html">BCELoss</a> defined in MindSpore will be used to add the loss function and optimizer to <code class="docutils literal notranslate"><span class="pre">D</span></code> and <code class="docutils literal notranslate"><span class="pre">G</span></code>.</p>
<ul class="simple">
<li><p>Connect the generator and loss function. The code is as follows:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># define loss function</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">WithLossCellG</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Connect the generator and loss function.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">netD</span><span class="p">,</span> <span class="n">netG</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WithLossCellG</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">netD</span> <span class="o">=</span> <span class="n">netD</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">netG</span> <span class="o">=</span> <span class="n">netG</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_code</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Construct the loss calculation structure of the generator.&quot;&quot;&quot;</span>
        <span class="n">fake_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netG</span><span class="p">(</span><span class="n">latent_code</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netD</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
        <span class="n">label_real</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">OnesLike</span><span class="p">()(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">label_real</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Connect the discriminator and loss function. The code is as follows:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">WithLossCellD</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Connect the discriminator and loss function.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">netD</span><span class="p">,</span> <span class="n">netG</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WithLossCellD</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">netD</span> <span class="o">=</span> <span class="n">netD</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">netG</span> <span class="o">=</span> <span class="n">netG</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">real_data</span><span class="p">,</span> <span class="n">latent_code</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Construct the loss calculation structure of the discriminator.&quot;&quot;&quot;</span>
        <span class="n">out_real</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netD</span><span class="p">(</span><span class="n">real_data</span><span class="p">)</span>
        <span class="n">label_real</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">OnesLike</span><span class="p">()(</span><span class="n">out_real</span><span class="p">)</span>
        <span class="n">loss_real</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">out_real</span><span class="p">,</span> <span class="n">label_real</span><span class="p">)</span>

        <span class="n">fake_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netG</span><span class="p">(</span><span class="n">latent_code</span><span class="p">)</span>
        <span class="n">fake_data</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
        <span class="n">out_fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netD</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
        <span class="n">label_fake</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ZerosLike</span><span class="p">()(</span><span class="n">out_fake</span><span class="p">)</span>
        <span class="n">loss_fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">out_fake</span><span class="p">,</span> <span class="n">label_fake</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss_real</span> <span class="o">+</span> <span class="n">loss_fake</span>
</pre></div>
</div>
<div class="section" id="optimizer">
<h3>Optimizer<a class="headerlink" href="#optimizer" title="Permalink to this headline">¶</a></h3>
<p>Two separate optimizers are set up here, one for <code class="docutils literal notranslate"><span class="pre">D</span></code> and the other for <code class="docutils literal notranslate"><span class="pre">G</span></code>. Both are Adam optimizers with <code class="docutils literal notranslate"><span class="pre">lr</span> <span class="pre">=</span> <span class="pre">0.0002</span></code> and <code class="docutils literal notranslate"><span class="pre">beta1</span> <span class="pre">=</span> <span class="pre">0.5</span></code>.</p>
<p>To trace the learning progress of the generator, during the training process, a batch of fixed implicit vectors <code class="docutils literal notranslate"><span class="pre">fixed_noise</span></code> that comply with Gaussian distribution are periodically input to <code class="docutils literal notranslate"><span class="pre">G</span></code>. We can see the images generated by the implicit vector.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a batch of implicit vectors to observe G.</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">fixed_noise</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">nz</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Set optimizers for the generator and discriminator, respectively.</span>
<span class="n">optimizerD</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">netD</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="n">beta1</span><span class="p">)</span>
<span class="n">optimizerG</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">netG</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="n">beta1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="training-mode">
<h2>Training Mode<a class="headerlink" href="#training-mode" title="Permalink to this headline">¶</a></h2>
<p>Training is divided into two parts: discriminator training and generator training.</p>
<ul>
<li><p>Train the discriminator.</p>
<p>The discriminator is trained to improve the probability of discriminating real images to the greatest extent. According to Goodfellow’s approach, we can update the discriminator by increasing its stochastic gradient so as to maximize the value of <span class="math notranslate nohighlight">\(log D(x) + log(1 - D(G(z))\)</span>.</p>
</li>
<li><p>Train the generator.</p>
<p>As stated in the DCGAN paper, we want to train the generator by minimizing the value of <span class="math notranslate nohighlight">\(log(1 - D(G(z)))\)</span> to produce better fake images.</p>
</li>
</ul>
<p>In the preceding two processes, the training loss is obtained, and statistics are collected at the end of each epoch. A batch of <code class="docutils literal notranslate"><span class="pre">fixed_noise</span></code> is pushed to the generator to intuitively trace the training progress of <code class="docutils literal notranslate"><span class="pre">G</span></code>.</p>
<p>The training process is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DCGAN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Define the DCGAN.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">myTrainOneStepCellForD</span><span class="p">,</span> <span class="n">myTrainOneStepCellForG</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DCGAN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">myTrainOneStepCellForD</span> <span class="o">=</span> <span class="n">myTrainOneStepCellForD</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">myTrainOneStepCellForG</span> <span class="o">=</span> <span class="n">myTrainOneStepCellForG</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">real_data</span><span class="p">,</span> <span class="n">latent_code</span><span class="p">):</span>
        <span class="n">output_D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">myTrainOneStepCellForD</span><span class="p">(</span><span class="n">real_data</span><span class="p">,</span> <span class="n">latent_code</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">netD_loss</span> <span class="o">=</span> <span class="n">output_D</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">output_G</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">myTrainOneStepCellForG</span><span class="p">(</span><span class="n">latent_code</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">netG_loss</span> <span class="o">=</span> <span class="n">output_G</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">netD_loss</span><span class="p">,</span> <span class="n">netG_loss</span>
</pre></div>
</div>
<p>Instantiate <code class="docutils literal notranslate"><span class="pre">WithLossCell</span></code> and <code class="docutils literal notranslate"><span class="pre">TrainOneStepCell</span></code> of the generator and discriminator.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiate `WithLossCell`.</span>
<span class="n">netD_with_criterion</span> <span class="o">=</span> <span class="n">WithLossCellD</span><span class="p">(</span><span class="n">netD</span><span class="p">,</span> <span class="n">netG</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
<span class="n">netG_with_criterion</span> <span class="o">=</span> <span class="n">WithLossCellG</span><span class="p">(</span><span class="n">netD</span><span class="p">,</span> <span class="n">netG</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="c1"># Instantiate `TrainOneStepCell`.</span>
<span class="n">myTrainOneStepCellForD</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">netD_with_criterion</span><span class="p">,</span> <span class="n">optimizerD</span><span class="p">)</span>
<span class="n">myTrainOneStepCellForG</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">netG_with_criterion</span><span class="p">,</span> <span class="n">optimizerG</span><span class="p">)</span>
</pre></div>
</div>
<p>Train the DCGAN cyclically, and collect the loss of the generator and discriminator every 50 iterations to facilitate subsequent drawing of the image of the loss function during the training process.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="c1"># Instantiate the DCGAN.</span>
<span class="n">dcgan</span> <span class="o">=</span> <span class="n">DCGAN</span><span class="p">(</span><span class="n">myTrainOneStepCellForD</span><span class="p">,</span> <span class="n">myTrainOneStepCellForG</span><span class="p">)</span>
<span class="n">dcgan</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>

<span class="c1"># Create an iterator.</span>
<span class="n">data_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">)</span>
<span class="n">G_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">D_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">image_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Start cyclic training.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting Training Loop...&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="c1"># Read data for each epoch of training.</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
        <span class="n">real_data</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">])</span>
        <span class="n">latent_code</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;latent_code&quot;</span><span class="p">])</span>
        <span class="n">netD_loss</span><span class="p">,</span> <span class="n">netG_loss</span> <span class="o">=</span> <span class="n">dcgan</span><span class="p">(</span><span class="n">real_data</span><span class="p">,</span> <span class="n">latent_code</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">i</span> <span class="o">==</span> <span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Output training records.</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[</span><span class="si">%2d</span><span class="s1">/</span><span class="si">%d</span><span class="s1">][</span><span class="si">%3d</span><span class="s1">/</span><span class="si">%d</span><span class="s1">]   Loss_D:</span><span class="si">%7.4f</span><span class="s1">  Loss_G:</span><span class="si">%7.4f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span>
                <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">netD_loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">netG_loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()))</span>
        <span class="n">D_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">netD_loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
        <span class="n">G_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">netG_loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>

    <span class="c1"># After each epoch ends, use the generator to generate a group of images.</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">netG</span><span class="p">(</span><span class="n">fixed_noise</span><span class="p">)</span>
    <span class="n">image_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>

    <span class="c1"># Save the network model parameters as a CKPT file.</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">netG</span><span class="p">,</span> <span class="s2">&quot;Generator.ckpt&quot;</span><span class="p">)</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">netD</span><span class="p">,</span> <span class="s2">&quot;Discriminator.ckpt&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">Starting</span> <span class="n">Training</span> <span class="n">Loop</span><span class="o">...</span>
    <span class="p">[</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">][</span>  <span class="mi">1</span><span class="o">/</span><span class="mi">549</span><span class="p">]</span>   <span class="n">Loss_D</span><span class="p">:</span> <span class="mf">2.4791</span>  <span class="n">Loss_G</span><span class="p">:</span> <span class="mf">4.5578</span>
    <span class="p">[</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">][</span> <span class="mi">51</span><span class="o">/</span><span class="mi">549</span><span class="p">]</span>   <span class="n">Loss_D</span><span class="p">:</span> <span class="mf">3.0025</span>  <span class="n">Loss_G</span><span class="p">:</span><span class="mf">10.6227</span>
    <span class="p">[</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">][</span><span class="mi">101</span><span class="o">/</span><span class="mi">549</span><span class="p">]</span>   <span class="n">Loss_D</span><span class="p">:</span> <span class="mf">0.8981</span>  <span class="n">Loss_G</span><span class="p">:</span> <span class="mf">7.0375</span>
    <span class="o">...</span>
    <span class="p">[</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">][</span><span class="mi">451</span><span class="o">/</span><span class="mi">549</span><span class="p">]</span>   <span class="n">Loss_D</span><span class="p">:</span> <span class="mf">0.6918</span>  <span class="n">Loss_G</span><span class="p">:</span> <span class="mf">2.9458</span>
    <span class="p">[</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">][</span><span class="mi">501</span><span class="o">/</span><span class="mi">549</span><span class="p">]</span>   <span class="n">Loss_D</span><span class="p">:</span> <span class="mf">0.5139</span>  <span class="n">Loss_G</span><span class="p">:</span> <span class="mf">4.7647</span>
    <span class="p">[</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">][</span><span class="mi">549</span><span class="o">/</span><span class="mi">549</span><span class="p">]</span>   <span class="n">Loss_D</span><span class="p">:</span> <span class="mf">1.2940</span>  <span class="n">Loss_G</span><span class="p">:</span> <span class="mf">3.6022</span>
    <span class="o">...</span>
    <span class="p">[</span><span class="mi">10</span><span class="o">/</span><span class="mi">10</span><span class="p">][</span><span class="mi">501</span><span class="o">/</span><span class="mi">549</span><span class="p">]</span>   <span class="n">Loss_D</span><span class="p">:</span> <span class="mf">0.4301</span>  <span class="n">Loss_G</span><span class="p">:</span> <span class="mf">2.1187</span>
    <span class="p">[</span><span class="mi">10</span><span class="o">/</span><span class="mi">10</span><span class="p">][</span><span class="mi">549</span><span class="o">/</span><span class="mi">549</span><span class="p">]</span>   <span class="n">Loss_D</span><span class="p">:</span> <span class="mf">0.6756</span>  <span class="n">Loss_G</span><span class="p">:</span> <span class="mf">1.2940</span>

</pre></div>
</div>
</div>
<div class="section" id="result">
<h2>Result<a class="headerlink" href="#result" title="Permalink to this headline">¶</a></h2>
<p>Run the following code to describe the relationship between the <code class="docutils literal notranslate"><span class="pre">D</span></code> and <code class="docutils literal notranslate"><span class="pre">G</span></code> loss and the training iteration:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Generator and Discriminator Loss During Training&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">G_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;G&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">D_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;D&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;iterations&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="png" src="../_images/output_261_0.png" /></p>
<p>Image generated by implicit vector <code class="docutils literal notranslate"><span class="pre">fixed_noise</span></code> during visual training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.animation</span> <span class="k">as</span> <span class="nn">animation</span>

<span class="k">def</span> <span class="nf">showGif</span><span class="p">(</span><span class="n">image_list</span><span class="p">):</span>
    <span class="n">show_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">120</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">image_list</span><span class="p">)):</span>
        <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
            <span class="n">row</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">image_list</span><span class="p">[</span><span class="n">epoch</span><span class="p">][</span><span class="n">i</span> <span class="o">*</span> <span class="mi">8</span><span class="p">:(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">8</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">images</span><span class="p">[:]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
        <span class="n">show_list</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)])</span>

    <span class="n">ani</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">ArtistAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">show_list</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">repeat_delay</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ani</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;./dcgan.gif&#39;</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="s1">&#39;pillow&#39;</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">showGif</span><span class="p">(</span><span class="n">image_list</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="dcgan" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/tutorials/application/source_zh_cn/cv/images/dcgan.gif" /></p>
<p>As shown in the preceding figure, the image quality becomes better as the number of training iterations increases. If the number of training epochs increases and the value of <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code> is greater than 50, the generated anime avatar face image is similar to that in the dataset. The following describes how to load the GAN parameter file <a class="reference external" href="https://download.mindspore.cn/vision/classification/Generator.ckpt">Generator.ckpt</a> in which the number of training epochs is 50 to generate an image. The code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindvision</span> <span class="kn">import</span> <span class="n">dataset</span>

<span class="n">dl_path</span> <span class="o">=</span> <span class="s2">&quot;./netG&quot;</span>
<span class="n">dl_url</span> <span class="o">=</span> <span class="s2">&quot;https://download.mindspore.cn/vision/classification/Generator.ckpt&quot;</span>

<span class="n">dl</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">DownLoad</span><span class="p">()</span>  <span class="c1"># Download the `Generator.ckpt` file.</span>
<span class="n">dl</span><span class="o">.</span><span class="n">download_url</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">dl_url</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="n">dl_path</span><span class="p">)</span>

<span class="c1"># Obtain model parameters from the file and load them to the network.</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;./netG/Generator.ckpt&quot;</span><span class="p">,</span> <span class="n">netG</span><span class="p">)</span>

<span class="n">img64</span> <span class="o">=</span> <span class="n">netG</span><span class="p">(</span><span class="n">fixed_noise</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">120</span><span class="p">)</span>
<span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">img64</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">8</span><span class="p">:(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">8</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">images</span><span class="p">[:]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="png" src="../_images/output_30_0.png" /></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../nlp/sentiment_analysis.html" class="btn btn-neutral float-right" title="Sentiment Classification Implemented by RNN" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="fgsm.html" class="btn btn-neutral float-left" title="Model Adversarial Attack" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>