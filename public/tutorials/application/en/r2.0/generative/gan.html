<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>GAN for Image Generation &mdash; MindSpore master documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Generating Cartoon Head Portrait via DCGAN" href="dcgan.html" />
    <link rel="prev" title="LSTM+CRF Sequence Labeling" href="../nlp/sequence_labeling.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">CV</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cv/resnet50.html">ResNet-50 for Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/transfer_learning.html">ResNet50 Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/fgsm.html">FGSM Network Adversarial Attack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/vit.html">Vision Transformer Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/cnnctc.html">CNN and CTC for Recognizing Text from Images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/fcn8s.html">FCN for Image Semantic Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/shufflenet.html">ShuffleNet for Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/ssd.html">SSD for Object Detection</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NLP</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../nlp/sentiment_analysis.html">Sentiment Classification Implemented by RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nlp/sequence_labeling.html">LSTM+CRF Sequence Labeling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Generative</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">GAN for Image Generation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#model-introduction">Model Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dataset">Dataset</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloading-a-dataset">Downloading a Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-loading">Data Loading</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dataset-visualization">Dataset Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implicit-vector-construction">Implicit Vector Construction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#model-building">Model Building</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#generator">Generator</a></li>
<li class="toctree-l3"><a class="reference internal" href="#discriminator">Discriminator</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loss-function-and-optimizer">Loss Function and Optimizer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#model-training">Model Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#effect-display">Effect Display</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-inference">Model Inference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dcgan.html">Generating Cartoon Head Portrait via DCGAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="pix2pix.html">Pix2Pix for Image Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="cyclegan.html">CycleGAN for Image Style Migration</a></li>
<li class="toctree-l1"><a class="reference internal" href="diffusion.html">Diffusion Model</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>GAN for Image Generation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/generative/gan.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="gan-for-image-generation">
<h1>GAN for Image Generation<a class="headerlink" href="#gan-for-image-generation" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.1/tutorials/application/source_en/generative/gan.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.1/resource/_static/logo_source_en.png" /></a></p>
<section id="model-introduction">
<h2>Model Introduction<a class="headerlink" href="#model-introduction" title="Permalink to this headline"></a></h2>
<p>Generative adversarial network (GAN) is a generative machine learning model, and is recently one of the most promising methods for unsupervised learning in complex distribution.</p>
<p>GAN was first proposed by Ian J. Goodfellow in his paper <a class="reference external" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">Generative Adversarial Nets</a> in 2014. It consists of two different models: generator (generative model) and discriminator (discriminative model).</p>
<ul class="simple">
<li><p>The generator generates “fake” images that look like the images for training.</p></li>
<li><p>The discriminator determines whether the images output by the generator are real images or fake images.</p></li>
</ul>
<p>GAN contains the generator and discriminator, which contest each other in a zero-sum game, and therefore generate good output.</p>
<p>The core of GAN model is to propose a new framework of estimating the generator through adversarial process. In this framework, two models will be trained at the same time: the generator <span class="math notranslate nohighlight">\(G\)</span> that captures data distribution and the discriminator <span class="math notranslate nohighlight">\(D\)</span> that estimates whether the sample comes from the training data.</p>
<p>In the training process, the generator continuously attempts to deceive the discriminator by generating a better fake image, and the discriminator gradually improves the capability of discriminating images in this process. It reaches the nash equilibrium when the distribution of the fake image generated by the generator is the same as that of the training image. That is, the confidence of true/false judgment of the discriminator is 50%.</p>
<p><span class="math notranslate nohighlight">\(x\)</span> represents the image data, and <span class="math notranslate nohighlight">\(D(x)\)</span> is used to represent the probability that the discriminator network determines the image as a real image. During the discrimination process, <span class="math notranslate nohighlight">\(D(x)\)</span> needs to process the image data whose size is <span class="math notranslate nohighlight">\(1\times 28\times 28\)</span> as a binary file. When <span class="math notranslate nohighlight">\(x\)</span> comes from training data, the value of <span class="math notranslate nohighlight">\(D(x)\)</span> should be approximate to <span class="math notranslate nohighlight">\(1\)</span>. When <span class="math notranslate nohighlight">\(x\)</span> comes from the generator, the value of <span class="math notranslate nohighlight">\(D(x)\)</span> should be approximate to <span class="math notranslate nohighlight">\(0\)</span>. Therefore, <span class="math notranslate nohighlight">\(D(x)\)</span> may also be considered as a conventional binary classifier.</p>
<p><span class="math notranslate nohighlight">\(z\)</span> represents the implicit vector extracted from the standard normal distribution, and <span class="math notranslate nohighlight">\(G(z)\)</span> represents the generator function that maps the implicit vector <span class="math notranslate nohighlight">\(z\)</span> to the data space. An objective of the function <span class="math notranslate nohighlight">\(G(z)\)</span> is to transform random noise <span class="math notranslate nohighlight">\(z\)</span> obeying Gaussian distribution into data distribution that approximates the true distribution <span class="math notranslate nohighlight">\(p_{data}(x)\)</span> by generating a network. We want to find <span class="math notranslate nohighlight">\(θ\)</span> so that <span class="math notranslate nohighlight">\(p_{G}(x;\theta)\)</span> is as close as possible to <span class="math notranslate nohighlight">\(p_{data}(x)\)</span>, where <span class="math notranslate nohighlight">\(\theta\)</span> represents a network parameter.</p>
<p><span class="math notranslate nohighlight">\(D(G(z))\)</span> indicates the probability that the fake image generated by the generator <span class="math notranslate nohighlight">\(G\)</span> is determined to be a real image. As described in <a class="reference external" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">Generative Adversarial Nets</a>, <span class="math notranslate nohighlight">\(D\)</span> and <span class="math notranslate nohighlight">\(G\)</span> are in a game. <span class="math notranslate nohighlight">\(D\)</span> wants to correctly classify real and fake images to the greatest extent, that is, parameter <span class="math notranslate nohighlight">\(\log D(x)\)</span>. <span class="math notranslate nohighlight">\(G\)</span> attempts to deceive <span class="math notranslate nohighlight">\(D\)</span> to minimize the probability that the fake image is recognized, that is, parameter <span class="math notranslate nohighlight">\(\log(1−D(G(z)))\)</span>. Therefore, a loss function of the GAN is:</p>
<div class="math notranslate nohighlight">
\[
\min\limits_{G}\max\limits_{D} V(D,G)=E_{x\sim p_{data}\;\,(x)}[\log D(x)]+E_{z\sim p_{z}\,(z)}[\log (1-D(G(z)))]
\]</div>
<p>Theoretically, it reaches the nash equilibrium when <span class="math notranslate nohighlight">\(p_{G}(x;\theta) = p_{data}(x)\)</span>, where the discriminator randomly guesses whether the input is a real or fake image. The following describes the game process of the generator and discriminator:</p>
<ol class="arabic simple">
<li><p>At the beginning of the training, the quality of the generator and discriminator is poor. The generator randomly generates a data distribution.</p></li>
<li><p>The discriminator optimizes the network by calculating the gradient and loss function. The data close to the real data distribution is determined as 1, and the data close to the data distribution generated by the generator is determined as 0.</p></li>
<li><p>The generator generates data that is closer to the real data distribution through optimization.</p></li>
<li><p>The data generated by the generator reaches the same distribution as the real data. In this case, the output of the discriminator is 1/2.</p></li>
</ol>
<p><img alt="gan" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.1/tutorials/application/source_zh_cn/cv/images/gan_image.png" /></p>
<p>In the preceding figure, the blue dotted line indicates the discriminator, the black dotted line indicates the real data distribution, the green solid line indicates the false data distribution generated by the generator, <span class="math notranslate nohighlight">\(z\)</span> indicates the implicit vector, and <span class="math notranslate nohighlight">\(x\)</span> indicates the generated fake image <span class="math notranslate nohighlight">\(G(z)\)</span>. The image comes from <a class="reference external" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">Generative Adversarial Nets</a>. For details about the training method, see the original paper.</p>
</section>
<section id="dataset">
<h2>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline"></a></h2>
<section id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h3>
<p>The <a class="reference external" href="http://yann.lecun.com/exdb/mnist/">MNIST dataset of handwritten digits</a> is a subset of the NIST dataset. There are 70,000 handwritten digit images, including 60,000 training samples and 10,000 test samples. The digit images are binary files, the image size is 28 x 28, and a single channel is used. Size normalization and centralization have been performed on images in advance.</p>
<p>This case uses the MNIST dataset to train a generative adversarial network that simulates the generation of handwritten digit images.</p>
</section>
<section id="downloading-a-dataset">
<h3>Downloading a Dataset<a class="headerlink" href="#downloading-a-dataset" title="Permalink to this headline"></a></h3>
<p>Use the <code class="docutils literal notranslate"><span class="pre">download</span></code> API to download the dataset and decompress it to the current directory. Before downloading data, use <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">download</span></code> to install the <code class="docutils literal notranslate"><span class="pre">download</span></code> package.</p>
<p>The directory structure of the downloaded dataset is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./MNIST_Data/
├─ train
│ ├─ train-images-idx3-ubyte
│ └─ train-labels-idx1-ubyte
└─ test
   ├─ t10k-images-idx3-ubyte
   └─ t10k-labels-idx1-ubyte
</pre></div>
</div>
<p>The code for downloading data is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download data.</span>
<span class="kn">from</span> <span class="nn">download</span> <span class="kn">import</span> <span class="n">download</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/MNIST_Data.zip&quot;</span>
<span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;zip&quot;</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Downloading data from https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/MNIST_Data.zip (10.3 MB)

file_sizes: 100%|███████████████████████████| 10.8M/10.8M [00:23&lt;00:00, 455kB/s]
Extracting zip file...
Successfully downloaded / unzipped to .
</pre></div>
</div>
</section>
<section id="data-loading">
<h3>Data Loading<a class="headerlink" href="#data-loading" title="Permalink to this headline"></a></h3>
<p>Use MindSpore’s own <code class="docutils literal notranslate"><span class="pre">MnistDatase</span></code> API to read and parse the source files of the MNIST dataset to build the dataset. Then, pre-process the data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">latent_size</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># Length of the implicit vector.</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MnistDataset</span><span class="p">(</span><span class="n">dataset_dir</span><span class="o">=</span><span class="s1">&#39;./MNIST_Data/train&#39;</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MnistDataset</span><span class="p">(</span><span class="n">dataset_dir</span><span class="o">=</span><span class="s1">&#39;./MNIST_Data/test&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">data_load</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="n">dataset1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">python_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># Data augmentation</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
        <span class="n">operations</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">latent_size</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)),</span>
        <span class="n">output_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;latent_code&quot;</span><span class="p">])</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">project</span><span class="p">([</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;latent_code&quot;</span><span class="p">])</span>

    <span class="c1"># Batch operations</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mnist_ds</span>

<span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">data_load</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>

<span class="n">iter_size</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iter size: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">iter_size</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Iter size: 468
</pre></div>
</div>
</section>
<section id="dataset-visualization">
<h3>Dataset Visualization<a class="headerlink" href="#dataset-visualization" title="Permalink to this headline"></a></h3>
<p>Use the <code class="docutils literal notranslate"><span class="pre">create_dict_iterator</span></code> function to convert data into a dictionary iterator, and then use the <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> module to visualize some training data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">data_iter</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">mnist_ds</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">figure</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">cols</span><span class="p">,</span> <span class="n">rows</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span>
<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">cols</span> <span class="o">*</span> <span class="n">rows</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">data_iter</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>
    <span class="n">figure</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="implicit-vector-construction">
<h3>Implicit Vector Construction<a class="headerlink" href="#implicit-vector-construction" title="Permalink to this headline"></a></h3>
<p>To track the learning progress of the generator, after each training epoch in the training process ends, a group of fixed implicit vectors <code class="docutils literal notranslate"><span class="pre">test_noise</span></code> that comply with Gaussian distribution are input to the generator, and the image effect generated by the fixed hidden code is used to evaluate the generator.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">dtype</span>

<span class="c1"># Create a batch of implicit vectors using random seeds.</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2323</span><span class="p">)</span>
<span class="n">test_noise</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">100</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">test_noise</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="model-building">
<h2>Model Building<a class="headerlink" href="#model-building" title="Permalink to this headline"></a></h2>
<p>The structure of the GAN model built in this case is roughly the same as that proposed in the original paper. However, the used dataset MNIST contains only single-channel small-sized images, and there are few identifiable parameters. To facilitate training, we can achieve satisfactory results by using a fully-connected network architecture and a <code class="docutils literal notranslate"><span class="pre">ReLU</span></code> activation function in the discriminator and generator, and omit the <code class="docutils literal notranslate"><span class="pre">Dropout</span></code> strategy for reducing parameters and the learnable activation function <code class="docutils literal notranslate"><span class="pre">Maxout</span></code> in the original paper.</p>
<section id="generator">
<h3>Generator<a class="headerlink" href="#generator" title="Permalink to this headline"></a></h3>
<p>The function of <code class="docutils literal notranslate"><span class="pre">Generator</span></code> is to map the implicit vector to the data space. Because the data is an image, this process also creates a grayscale image (or RGB color image) with the same size as the real image. In this case, this function is implemented through five <code class="docutils literal notranslate"><span class="pre">Dense</span></code> layers. Each layer is paired with the <code class="docutils literal notranslate"><span class="pre">BatchNorm1d</span></code> layer and the <code class="docutils literal notranslate"><span class="pre">ReLU</span></code> activation layer. The output data passes through the <code class="docutils literal notranslate"><span class="pre">Tanh</span></code> function and is returned within the range of [-1,1]. After instantiating the generator, you need to change the parameter name. Otherwise, an error is reported in static graph mode.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">img_size</span> <span class="o">=</span> <span class="mi">28</span> <span class="c1"># Training image length (width)</span>

<span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_size</span><span class="p">,</span> <span class="n">auto_prefix</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="n">auto_prefix</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">()</span>
        <span class="c1"># [N, 100] -&gt; [N, 128]</span>
        <span class="c1"># Input a 100-dimensional Gaussian distribution between 0 and 1, and then map it to 256 dimensions through the first-layer linear transformation.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">latent_size</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="c1"># [N, 128] -&gt; [N, 256]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">256</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="c1"># [N, 256] -&gt; [N, 512]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">512</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="c1"># [N, 512] -&gt; [N, 1024]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">1024</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="c1"># [N, 1024] -&gt; [N, 784]</span>
        <span class="c1"># It is converted into 784 dimensions through linear transformation.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">img_size</span> <span class="o">*</span> <span class="n">img_size</span><span class="p">))</span>
        <span class="c1"># After the Tanh activation function is used, the generated fake image data distribution is expected to range from -1 to 1.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>

<span class="n">net_g</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">latent_size</span><span class="p">)</span>
<span class="n">net_g</span><span class="o">.</span><span class="n">update_parameters_name</span><span class="p">(</span><span class="s1">&#39;generator&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="discriminator">
<h3>Discriminator<a class="headerlink" href="#discriminator" title="Permalink to this headline"></a></h3>
<p>As described above, <code class="docutils literal notranslate"><span class="pre">Discriminator</span></code> is a binary network model, and outputs the probability that the image is determined as a real image. It is processed through a series of <code class="docutils literal notranslate"><span class="pre">Dense</span></code> and <code class="docutils literal notranslate"><span class="pre">LeakyReLU</span></code> layers. Finally, the <code class="docutils literal notranslate"><span class="pre">Sigmoid</span></code> activation function is used to return the data within the range of [0, 1] to obtain the final probability. After instantiating the discriminator, you need to change the parameter name. Otherwise, an error is reported in static graph mode.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span> <span class="c1"># Discriminator</span>
<span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">auto_prefix</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="n">auto_prefix</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">()</span>
        <span class="c1"># [N, 784] -&gt; [N, 512]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">img_size</span> <span class="o">*</span> <span class="n">img_size</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>  <span class="c1"># The number of input features is 784, and the number of output features is 512.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>  <span class="c1"># Nonlinear mapping activation function with a default slope of 0.2.</span>
        <span class="c1"># [N, 512] -&gt; [N, 256]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span> <span class="c1"># Linear mapping.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
        <span class="c1"># [N, 256] -&gt; [N, 1]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>  <span class="c1"># Binary activation function, which maps real numbers to [0,1]</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x_flat</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">img_size</span> <span class="o">*</span> <span class="n">img_size</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x_flat</span><span class="p">)</span>

<span class="n">net_d</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span>
<span class="n">net_d</span><span class="o">.</span><span class="n">update_parameters_name</span><span class="p">(</span><span class="s1">&#39;discriminator&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="loss-function-and-optimizer">
<h3>Loss Function and Optimizer<a class="headerlink" href="#loss-function-and-optimizer" title="Permalink to this headline"></a></h3>
<p>After <code class="docutils literal notranslate"><span class="pre">Generator</span></code> and <code class="docutils literal notranslate"><span class="pre">Discriminator</span></code> are defined, the binary cross-entropy loss function <code class="docutils literal notranslate"><span class="pre">BCELoss</span></code> in MindSpore is used as the loss function. Both the generator and discriminator use the <code class="docutils literal notranslate"><span class="pre">Adam</span></code> optimizer. However, you need to build two optimizers with different names to update the parameters of the two models. For details, see the following code. Note that the parameter names of the optimizer also need to be changed.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.0002</span> <span class="c1"># Learning rate</span>

<span class="c1"># Loss function</span>
<span class="n">adversarial_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>

<span class="c1"># Optimizers</span>
<span class="n">optimizer_d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net_d</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">)</span>
<span class="n">optimizer_g</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net_g</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">)</span>
<span class="n">optimizer_g</span><span class="o">.</span><span class="n">update_parameters_name</span><span class="p">(</span><span class="s1">&#39;optim_g&#39;</span><span class="p">)</span>
<span class="n">optimizer_d</span><span class="o">.</span><span class="n">update_parameters_name</span><span class="p">(</span><span class="s1">&#39;optim_d&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="model-training">
<h2>Model Training<a class="headerlink" href="#model-training" title="Permalink to this headline"></a></h2>
<p>Training is divided into two parts.</p>
<p>The first part is to train the discriminator. The discriminator is trained to improve the probability of discriminating real images to the greatest extent. According to the method of the original paper, the discriminator is updated by increasing its stochastic gradient to maximize the value of <span class="math notranslate nohighlight">\(log D(x) + log(1 - D(G(z))\)</span>.</p>
<p>The second part is to train the generator. As described in the paper, <span class="math notranslate nohighlight">\(log(1 - D(G(z)))\)</span> is minimized to train the generator to produce better false images.</p>
<p>In the two parts, the losses in the training process are obtained separately, and the test is performed at the end of each epoch. The implicit vectors are pushed to the generator in batches to intuitively track the training effect of the <code class="docutils literal notranslate"><span class="pre">Generator</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">save_checkpoint</span>

<span class="n">total_epoch</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># Number of training epochs</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>  <span class="c1"># Batch size of the training set used for training</span>

<span class="c1"># Parameters for loading a pre-trained model</span>
<span class="n">pred_trained</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">pred_trained_g</span> <span class="o">=</span> <span class="s1">&#39;./result/checkpoints/Generator99.ckpt&#39;</span>
<span class="n">pred_trained_d</span> <span class="o">=</span> <span class="s1">&#39;./result/checkpoints/Discriminator99.ckpt&#39;</span>

<span class="n">checkpoints_path</span> <span class="o">=</span> <span class="s2">&quot;./result/checkpoints&quot;</span>  <span class="c1"># Path for saving results</span>
<span class="n">image_path</span> <span class="o">=</span> <span class="s2">&quot;./result/images&quot;</span>  <span class="c1"># Path for saving test results</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Loss calculation process of the generator</span>
<span class="k">def</span> <span class="nf">generator_forward</span><span class="p">(</span><span class="n">test_noises</span><span class="p">):</span>
    <span class="n">fake_data</span> <span class="o">=</span> <span class="n">net_g</span><span class="p">(</span><span class="n">test_noises</span><span class="p">)</span>
    <span class="n">fake_out</span> <span class="o">=</span> <span class="n">net_d</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
    <span class="n">loss_g</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">fake_out</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">fake_out</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">loss_g</span>

<span class="c1"># Loss calculation process of the discriminator</span>
<span class="k">def</span> <span class="nf">discriminator_forward</span><span class="p">(</span><span class="n">real_data</span><span class="p">,</span> <span class="n">test_noises</span><span class="p">):</span>
    <span class="n">fake_data</span> <span class="o">=</span> <span class="n">net_g</span><span class="p">(</span><span class="n">test_noises</span><span class="p">)</span>
    <span class="n">fake_out</span> <span class="o">=</span> <span class="n">net_d</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
    <span class="n">real_out</span> <span class="o">=</span> <span class="n">net_d</span><span class="p">(</span><span class="n">real_data</span><span class="p">)</span>
    <span class="n">real_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">real_out</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">real_out</span><span class="p">))</span>
    <span class="n">fake_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">fake_out</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">fake_out</span><span class="p">))</span>
    <span class="n">loss_d</span> <span class="o">=</span> <span class="n">real_loss</span> <span class="o">+</span> <span class="n">fake_loss</span>
    <span class="k">return</span> <span class="n">loss_d</span>

<span class="c1"># Gradient method</span>
<span class="n">grad_g</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">generator_forward</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">net_g</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
<span class="n">grad_d</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">discriminator_forward</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">net_d</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>

<span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">real_data</span><span class="p">,</span> <span class="n">latent_code</span><span class="p">):</span>
    <span class="c1"># Calculate discriminator loss and gradient.</span>
    <span class="n">loss_d</span><span class="p">,</span> <span class="n">grads_d</span> <span class="o">=</span> <span class="n">grad_d</span><span class="p">(</span><span class="n">real_data</span><span class="p">,</span> <span class="n">latent_code</span><span class="p">)</span>
    <span class="n">optimizer_d</span><span class="p">(</span><span class="n">grads_d</span><span class="p">)</span>
    <span class="n">loss_g</span><span class="p">,</span> <span class="n">grads_g</span> <span class="o">=</span> <span class="n">grad_g</span><span class="p">(</span><span class="n">latent_code</span><span class="p">)</span>
    <span class="n">optimizer_g</span><span class="p">(</span><span class="n">grads_g</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss_d</span><span class="p">,</span> <span class="n">loss_g</span>

<span class="c1"># Save the generated test image.</span>
<span class="k">def</span> <span class="nf">save_imgs</span><span class="p">(</span><span class="n">gen_imgs1</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i3</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">gen_imgs1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">i3</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">gen_imgs1</span><span class="p">[</span><span class="n">i3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">image_path</span> <span class="o">+</span> <span class="s2">&quot;/test_</span><span class="si">{}</span><span class="s2">.png&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>

<span class="c1"># Set the path for saving parameters.</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">checkpoints_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># Set the path for saving the images generated during the intermediate process.</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">net_g</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>
<span class="n">net_d</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>

<span class="c1"># Store the generator and discriminator loss.</span>
<span class="n">losses_g</span><span class="p">,</span> <span class="n">losses_d</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_epoch</span><span class="p">):</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mnist_ds</span><span class="p">):</span>
        <span class="n">start1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">image</span><span class="p">,</span> <span class="n">latent_code</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">image</span> <span class="o">=</span> <span class="p">(</span><span class="n">image</span> <span class="o">-</span> <span class="mf">127.5</span><span class="p">)</span> <span class="o">/</span> <span class="mf">127.5</span>  <span class="c1"># [0, 255] -&gt; [-1, 1]</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">d_loss</span><span class="p">,</span> <span class="n">g_loss</span> <span class="o">=</span> <span class="n">train_step</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">latent_code</span><span class="p">)</span>
        <span class="n">end1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch:[</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;3d</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">total_epoch</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;3d</span><span class="si">}</span><span class="s2">], &quot;</span>
                  <span class="sa">f</span><span class="s2">&quot;step:[</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="nb">iter</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;4d</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">iter_size</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;4d</span><span class="si">}</span><span class="s2">], &quot;</span>
                  <span class="sa">f</span><span class="s2">&quot;loss_d:</span><span class="si">{</span><span class="n">d_loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="si">:</span><span class="s2">&gt;4f</span><span class="si">}</span><span class="s2"> , &quot;</span>
                  <span class="sa">f</span><span class="s2">&quot;loss_g:</span><span class="si">{</span><span class="n">g_loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="si">:</span><span class="s2">&gt;4f</span><span class="si">}</span><span class="s2"> , &quot;</span>
                  <span class="sa">f</span><span class="s2">&quot;time:</span><span class="si">{</span><span class="p">(</span><span class="n">end1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start1</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;3f</span><span class="si">}</span><span class="s2">s, &quot;</span>
                  <span class="sa">f</span><span class="s2">&quot;lr:</span><span class="si">{</span><span class="n">lr</span><span class="si">:</span><span class="s2">&gt;6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;time of epoch </span><span class="si">{}</span><span class="s2"> is </span><span class="si">{:.2f}</span><span class="s2">s&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>

    <span class="n">losses_d</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d_loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
    <span class="n">losses_g</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">g_loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>

    <span class="c1"># After each epoch ends, use the generator to generate a group of images.</span>
    <span class="n">gen_imgs</span> <span class="o">=</span> <span class="n">net_g</span><span class="p">(</span><span class="n">test_noise</span><span class="p">)</span>
    <span class="n">save_imgs</span><span class="p">(</span><span class="n">gen_imgs</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">epoch</span><span class="p">)</span>

    <span class="c1"># Save the model weight file based on the epoch.</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">save_checkpoint</span><span class="p">(</span><span class="n">net_g</span><span class="p">,</span> <span class="n">checkpoints_path</span> <span class="o">+</span> <span class="s2">&quot;/Generator</span><span class="si">%d</span><span class="s2">.ckpt&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
        <span class="n">save_checkpoint</span><span class="p">(</span><span class="n">net_d</span><span class="p">,</span> <span class="n">checkpoints_path</span> <span class="o">+</span> <span class="s2">&quot;/Discriminator</span><span class="si">%d</span><span class="s2">.ckpt&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">))</span>

</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Epoch:[  0/200], step:[   0/ 468], loss_d:1.383930 , loss_g:0.693423 , time:0.864688s, lr:0.000200
Epoch:[  0/200], step:[  10/ 468], loss_d:1.356453 , loss_g:0.548430 , time:0.122673s, lr:0.000200
Epoch:[  0/200], step:[  20/ 468], loss_d:1.386923 , loss_g:0.628228 , time:0.120677s, lr:0.000200
Epoch:[  0/200], step:[  30/ 468], loss_d:1.385639 , loss_g:0.649491 , time:0.124667s, lr:0.000200
Epoch:[  0/200], step:[  40/ 468], loss_d:1.365866 , loss_g:0.683650 , time:0.122672s, lr:0.000200
...
Epoch:[ 99/200], step:[ 440/ 468], loss_d:1.170306 , loss_g:0.954169 , time:0.113697s, lr:0.000200
Epoch:[ 99/200], step:[ 450/ 468], loss_d:1.187954 , loss_g:0.970897 , time:0.113697s, lr:0.000200
Epoch:[ 99/200], step:[ 460/ 468], loss_d:1.277891 , loss_g:0.930688 , time:0.116688s, lr:0.000200
time of epoch 100 is 61.76s
Epoch:[100/200], step:[   0/ 468], loss_d:1.197745 , loss_g:0.951075 , time:0.134640s, lr:0.000200
Epoch:[100/200], step:[  10/ 468], loss_d:1.241353 , loss_g:0.939583 , time:0.131648s, lr:0.000200
Epoch:[100/200], step:[  20/ 468], loss_d:1.222481 , loss_g:0.900680 , time:0.129653s, lr:0.000200
...
Epoch:[199/200], step:[ 420/ 468], loss_d:1.215858 , loss_g:1.071604 , time:0.151593s, lr:0.000200
Epoch:[199/200], step:[ 430/ 468], loss_d:1.238803 , loss_g:0.920928 , time:0.135638s, lr:0.000200
Epoch:[199/200], step:[ 440/ 468], loss_d:1.212080 , loss_g:0.954983 , time:0.134640s, lr:0.000200
Epoch:[199/200], step:[ 450/ 468], loss_d:1.236587 , loss_g:0.897825 , time:0.133643s, lr:0.000200
Epoch:[199/200], step:[ 460/ 468], loss_d:1.214701 , loss_g:0.939405 , time:0.135638s, lr:0.000200
time of epoch 200 is 71.98s
</pre></div>
</div>
</section>
<section id="effect-display">
<h2>Effect Display<a class="headerlink" href="#effect-display" title="Permalink to this headline"></a></h2>
<p>Run the following code to describe the relationship between the <code class="docutils literal notranslate"><span class="pre">D</span></code> and <code class="docutils literal notranslate"><span class="pre">G</span></code> losses and the training iteration:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Generator and Discriminator Loss During Training&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses_g</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;G&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses_d</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;D&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="mi">220</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;iterations&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Image generated by implicit vector during visual training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">matplotlib.animation</span> <span class="k">as</span> <span class="nn">animation</span>

<span class="c1"># Convert the test image generated during training to a dynamic image.</span>
<span class="n">image_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_epoch</span><span class="p">):</span>
    <span class="n">image_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span> <span class="o">+</span> <span class="s2">&quot;/test_</span><span class="si">{}</span><span class="s2">.png&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">))</span>
<span class="n">show_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">image_list</span><span class="p">),</span> <span class="mi">5</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">show_list</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image_list</span><span class="p">[</span><span class="n">epoch</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)])</span>

<span class="n">ani</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">ArtistAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">show_list</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">repeat_delay</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ani</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;train_test.gif&#39;</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="s1">&#39;pillow&#39;</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

</pre></div>
</div>
<p><img alt="Dynamic test image during training" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.1/tutorials/application/source_zh_cn/generative/images/train_test.gif" /></p>
<p>As shown in the preceding figure, the image quality becomes better as the number of training epochs increases. If the value of <code class="docutils literal notranslate"><span class="pre">epoch</span></code> is greater than 100, the generated handwritten digit image is similar to that in the dataset. Now, let’s load the generator network model parameter file to generate an image. The code is as follows:</p>
</section>
<section id="model-inference">
<h2>Model Inference<a class="headerlink" href="#model-inference" title="Permalink to this headline"></a></h2>
<p>Now, let’s load the generator network model parameter file to generate an image. The code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">test_ckpt</span> <span class="o">=</span> <span class="s1">&#39;./result/checkpoints/Generator199.ckpt&#39;</span>

<span class="n">parameter</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">test_ckpt</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net_g</span><span class="p">,</span> <span class="n">parameter</span><span class="p">)</span>
<span class="c1"># Model generation result</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">net_g</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="c1"># Result display</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">120</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">):</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../nlp/sequence_labeling.html" class="btn btn-neutral float-left" title="LSTM+CRF Sequence Labeling" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="dcgan.html" class="btn btn-neutral float-right" title="Generating Cartoon Head Portrait via DCGAN" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
        <script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>