<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Vision Transformer Image Classification &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script><script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="CNN and CTC for Recognizing Text from Images" href="cnnctc.html" />
    <link rel="prev" title="FGSM Network Adversarial Attack" href="fgsm.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">CV</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="resnet50.html">ResNet-50 for Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="transfer_learning.html">ResNet50 Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="fgsm.html">FGSM Network Adversarial Attack</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Vision Transformer Image Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction-of-vit">Introduction of ViT</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#model-structure">Model Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-features">Model Features</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#environment-preparation-and-data-reading">Environment Preparation and Data Reading</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-analysis">Model Analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#basic-principle-of-transformer">Basic Principle of Transformer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#attention-module">Attention Module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#transformer-encoder">Transformer Encoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#input-for-vit-model">Input for ViT model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#building-vit-as-a-whole">Building ViT as a whole</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#model-training-and-inference">Model Training and Inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#model-training">Model Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-validation">Model Validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-inference">Model Inference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cnnctc.html">CNN and CTC for Recognizing Text from Images</a></li>
<li class="toctree-l1"><a class="reference internal" href="fcn8s.html">FCN for Image Semantic Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="shufflenet.html">ShuffleNet for Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="ssd.html">SSD for Object Detection</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NLP</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../nlp/sentiment_analysis.html">Sentiment Classification Implemented by RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nlp/sequence_labeling.html">LSTM+CRF Sequence Labeling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Generative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../generative/gan.html">GAN for Image Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generative/dcgan.html">Generating Cartoon Head Portrait via DCGAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generative/pix2pix.html">Pix2Pix for Image Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generative/cyclegan.html">CycleGAN for Image Style Migration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generative/diffusion.html">Diffusion Model</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Vision Transformer Image Classification</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/cv/vit.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="vision-transformer-image-classification">
<h1>Vision Transformer Image Classification<a class="headerlink" href="#vision-transformer-image-classification" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.2/tutorials/application/source_en/cv/vit.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.2/resource/_static/logo_source_en.svg" /></a></p>
<p>Thanks to <a class="reference external" href="https://gitee.com/sanjaychan">ZOMI</a> for contributing to this article.</p>
<section id="introduction-of-vit">
<h2>Introduction of ViT<a class="headerlink" href="#introduction-of-vit" title="Permalink to this headline"></a></h2>
<p>In recent years, the development of natural language processing models has been greatly facilitated by the development of models based on Self-Attention (SAA) structures, especially the proposal of Transformer model. Due to its computational efficiency and scalability, Transformers has been able to train models of unprecedented size with over 100B parameters.</p>
<p>ViT is the convergence result of two fields: natural language processing and computer vision. It can still achieve good results on image classification tasks without relying on convolutional operations.</p>
<section id="model-structure">
<h3>Model Structure<a class="headerlink" href="#model-structure" title="Permalink to this headline"></a></h3>
<p>The main structure of the ViT model is based on the Encoder part of the Transformer model (part of the structure order has been adjusted, e.g., the location of Normalization is different from that of the standard Transformer). Its structure diagram [1] is as follows:</p>
<p><img alt="vit-architecture" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.2/tutorials/application/source_zh_cn/cv/images/vit_architecture.png" /></p>
</section>
<section id="model-features">
<h3>Model Features<a class="headerlink" href="#model-features" title="Permalink to this headline"></a></h3>
<p>ViT model is mainly applied in the field of image classification. Therefore, its model structure has the following features compared to the traditional Transformer:</p>
<ol class="arabic simple">
<li><p>After the original image of the dataset is divided into multiple patches, the two-dimensional patches (without considering the channel) are converted into one-dimensional vectors. The one-dimensional vectors, the category vectors and the position vectors are added as model inputs.</p></li>
<li><p>The Block structure of the main body in the model is based on the Encoder structure of Transformer, but adjusts the position of Normalization, where the main structure is still the Multi-head Attention structure.</p></li>
<li><p>The model connects a fully connected layer after the Blocks stack, accepts the output of the category vector as input and uses it for classification. Typically, we refer to the final fully-onnected layer as Head and the Transformer Encoder part as backbone.</p></li>
</ol>
<p>The following code example will explain in detail the implementation of ImageNet classification task based on ViT.</p>
<blockquote>
<div><p>This tutorial runs on the CPU for too long and is not recommended to run on the CPU.</p>
</div></blockquote>
</section>
</section>
<section id="environment-preparation-and-data-reading">
<h2>Environment Preparation and Data Reading<a class="headerlink" href="#environment-preparation-and-data-reading" title="Permalink to this headline"></a></h2>
<p>Before you start experimenting, make sure you have installed a local Python environment and MindSpore.</p>
<p>First we need to download the dataset for this case. The complete ImageNet dataset can be downloaded via <a class="reference external" href="http://image-net.org">http://image-net.org</a>. The dataset applied in this case is a subset filtered out from ImageNet.</p>
<p>The first code will be downloaded and unpacked automatically when you run it. Make sure your dataset path is structured as follows.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>.dataset/
    ├── ILSVRC2012_devkit_t12.tar.gz
    ├── train/
    ├── infer/
    └── val/
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">download</span> <span class="kn">import</span> <span class="n">download</span>

<span class="n">dataset_url</span> <span class="o">=</span> <span class="s2">&quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/vit_imagenet_dataset.zip&quot;</span>
<span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;./&quot;</span>

<span class="n">path</span> <span class="o">=</span> <span class="n">download</span><span class="p">(</span><span class="n">dataset_url</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;zip&quot;</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Downloading data from https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/vit_imagenet_dataset.zip (489.1 MB)

file_sizes: 100%|████████████████████████████| 513M/513M [00:09&lt;00:00, 52.3MB/s]
Extracting zip file...
Successfully downloaded / unzipped to ./
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset</span> <span class="kn">import</span> <span class="n">ImageFolderDataset</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision</span> <span class="k">as</span> <span class="nn">transforms</span>


<span class="n">data_path</span> <span class="o">=</span> <span class="s1">&#39;./dataset/&#39;</span>
<span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.485</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.456</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.406</span> <span class="o">*</span> <span class="mi">255</span><span class="p">]</span>
<span class="n">std</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.229</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.224</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.225</span> <span class="o">*</span> <span class="mi">255</span><span class="p">]</span>

<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">ImageFolderDataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">trans_train</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomCropDecodeResize</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span>
                                      <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.08</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
                                      <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">1.333</span><span class="p">)),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
<span class="p">]</span>

<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">dataset_train</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">trans_train</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">dataset_train</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="model-analysis">
<h2>Model Analysis<a class="headerlink" href="#model-analysis" title="Permalink to this headline"></a></h2>
<p>The following is a detailed dissection of the internal structure of the ViT model through the code.</p>
<section id="basic-principle-of-transformer">
<h3>Basic Principle of Transformer<a class="headerlink" href="#basic-principle-of-transformer" title="Permalink to this headline"></a></h3>
<p>The Transformer model originated from a 2017 article [2]. The encoder-decoder type structure based on the Attention mechanism proposed in this article has been a great success in the field of natural language processing. The model structure is shown in the following figure:</p>
<p><img alt="transformer-architecture" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.2/tutorials/application/source_zh_cn/cv/images/transformer_architecture.png" /></p>
<p>Its main structure is composed of several Encoder and Decoder modules, where the detailed structure of Encoder and Decoder is shown in the following figure [2]:</p>
<p><img alt="encoder-decoder" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.2/tutorials/application/source_zh_cn/cv/images/encoder_decoder.png" /></p>
<p>Encoder and Decoder consist of many structures, such as Multi-Head Attention layer, Feed Forward layer, Normaliztion layer, and even Residual Connection (“Add” in the figure). However, one of the most important structures is the Multi-Head Attention structure, which is based on the Self-Attention mechanism and is a parallel composition of multiple Self-Attentions.</p>
<p>Therefore, understanding Self-Attention means understanding the core of Transformer.</p>
<section id="attention-module">
<h4>Attention Module<a class="headerlink" href="#attention-module" title="Permalink to this headline"></a></h4>
<p>The following is an explanation of Self-Attention, the core of which is to learn a weight for each word of the input vector. Given a task-related query vector Query vector, the similarity or relevance of Query and each Key is calculated to obtain the Attention distribution, i.e., the weight coefficient of each Key corresponding to Value is obtained, and then the Value is weighted and summed to obtain the final Attention value.</p>
<p>In the Self-Attention:</p>
<ol class="arabic">
<li><p>The initial input vector is first mapped into three vectors Q(Query), K(Key), and V(Value) by the Embedding layer, and since it is a parallel operation, the code is mapped into a dim x 3 vector and partitioned. In other words, if your input vector is a sequence of vectors (<span class="math notranslate nohighlight">\(x_1\)</span>, <span class="math notranslate nohighlight">\(x_2\)</span>, <span class="math notranslate nohighlight">\(x_3\)</span>), where <span class="math notranslate nohighlight">\( x_1\)</span>, <span class="math notranslate nohighlight">\(x_2\)</span>, <span class="math notranslate nohighlight">\(x_3\)</span> are one-dimensional vectors, each one-dimensional vector is mapped to Q, K, and V by the Embedding layer, only the Embedding matrix is different and the matrix parameters are obtained through learning. <strong>Here we can consider that the three matrices Q, K, V are a means to discover the correlation information between vectors, which needs to be obtained through learning. The reason for the number of vector is three is that two vectors can get the weights after point multiplication, and another vector is needed to carry the results of summing the weights, so at least three matrices are needed.</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{cases}
    q_i = W_q \cdot x_i &amp; \\
    k_i = W_k \cdot x_i,\hspace{1em} &amp;i = 1,2,3 \ldots \\
    v_i = W_v \cdot x_i &amp;
    \end{cases}
    \end{split}\tag{1}
    \]</div>
<p><img alt="self-attention1" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.2/tutorials/application/source_zh_cn/cv/images/self_attention_1.png" /></p>
</li>
<li><p>The self-attentiveness of the self-attentive mechanism is mainly reflected by the fact that its Q, K, and V all originate from itself, that is, the process is extracting the connections and features of the input vectors of different orders, which are finally expressed by the connection closeness between the vectors of different orders (the result of the product of Q and K after Softmax). <strong>After obtaining Q, K, V, we need to obtain the inter-vector weights, that is, to point multiple Q and K and divide by the square root of the dimension, and Softmax the results of all vectors. By the operation in equation (2), we obtain the relation weights between vectors.</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{cases}
    a_{1,1} = q_1 \cdot k_1 / \sqrt d \\
    a_{1,2} = q_1 \cdot k_2 / \sqrt d \\
    a_{1,3} = q_1 \cdot k_3 / \sqrt d
    \end{cases}
    \end{split}\tag{2}
    \]</div>
<p><img alt="self-attention3" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.2/tutorials/application/source_zh_cn/cv/images/self_attention_3.png" /></p>
<div class="math notranslate nohighlight">
\[ Softmax: \hat a_{1,i} = exp(a_{1,i}) / \sum_j exp(a_{1,j}),\hspace{1em} j = 1,2,3 \ldots \tag{3}\]</div>
<p><img alt="self-attention2" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.2/tutorials/application/source_zh_cn/cv/images/self_attention_2.png" /></p>
</li>
<li><p>The final output is obtained by weight sum of the mapped vector V with Q, K after Softmax, and the process can be understood as a global self-attentive representation. <strong>Each set of Q, K, and V ends up with a V output, which is the final result obtained by Self-Attention, and is the result of the current vector after combining its associated weights with other vectors.</strong></p>
<div class="math notranslate nohighlight">
\[
    b_1 = \sum_i \hat a_{1,i}v_i,\hspace{1em} i = 1,2,3...
    \tag{4}
    \]</div>
</li>
</ol>
<p>The following diagram provides an overall grasp of the entire Self-Attention process.</p>
<p><img alt="self-attention" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.2/tutorials/application/source_zh_cn/cv/images/self_attention_process.png" /></p>
<p>The multi-head attention mechanism is to split the vector originally processed by self-Attention into multiple Heads for processing, which can also be reflected in the code, which is one aspect of the attention structure that allows parallel acceleration.</p>
<p>To summarize, the multi-head attention mechanism maps the same query, key and value to different subspaces (Q_0,K_0,V_0) of the original high-dimensional space (Q,K,V) for self-attention computation while keeping the total number of parameters unchanged, and finally merges the attention information in different subspaces.</p>
<p>Therefore, for the same input vector, multiple attention mechanisms can process it simultaneously, i.e., using parallel computing to speed up the processing process and analyzing and utilizing the vector features during the processing. The following figure shows the multi-headed attention mechanism, whose parallelism capability is mainly reflected by the fact that <span class="math notranslate nohighlight">\(a_1\)</span> and <span class="math notranslate nohighlight">\(a_2\)</span> are obtained by partitioning the same vector in the following figure.</p>
<p><img alt="multi-head-attention" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.2/tutorials/application/source_zh_cn/cv/images/multi_head_attention.png" /></p>
<p>The following Multi-Head Attention code, combined with the explanation above, clearly shows the process.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">ops</span>


<span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">attention_keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Attention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
        <span class="n">head_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">//</span> <span class="n">num_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">head_dim</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="o">-</span><span class="n">attention_keep_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="o">-</span><span class="n">keep_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_matmul_v</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">BatchMatMul</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_matmul_k</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">BatchMatMul</span><span class="p">(</span><span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Attention construct.&quot;&quot;&quot;</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">qkv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">qkv</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">qkv</span><span class="p">,</span> <span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">c</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">))</span>
        <span class="n">qkv</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">qkv</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">qkv</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_matmul_k</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_drop</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_matmul_v</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_drop</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</section>
</section>
<section id="transformer-encoder">
<h3>Transformer Encoder<a class="headerlink" href="#transformer-encoder" title="Permalink to this headline"></a></h3>
<p>After understanding the Self-Attention structure, the basic structure of Transformer can be formed by splicing with Feed Forward, Residual Connection, etc. The following code implements structures of Feed Forward and Residual Connection.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Dict</span>


<span class="k">class</span> <span class="nc">FeedForward</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">in_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">hidden_features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">out_features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Cell</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FeedForward</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">out_features</span> <span class="o">=</span> <span class="n">out_features</span> <span class="ow">or</span> <span class="n">in_features</span>
        <span class="n">hidden_features</span> <span class="o">=</span> <span class="n">hidden_features</span> <span class="ow">or</span> <span class="n">in_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="o">-</span><span class="n">keep_prob</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Feed Forward construct.&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">ResidualCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cell</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ResidualCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">cell</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;ResidualCell construct.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span>
</pre></div>
</div>
<p>Next, Self-Attention is used to construct the TransformerEncoder part in the ViT model, similar to constructing the encoder part of a Transformer, as shown in the following figure [1]:</p>
<p><img alt="vit-encoder" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.2/tutorials/application/source_zh_cn/cv/images/vit_encoder.png" /></p>
<ol class="arabic simple">
<li><p>The basic structure in the ViT model is different from that of the standard Transformer, mainly in that the position of Normalization is placed before Self-Attention and Feed Forward, while other structures such as Residual Connection, Feed Forward, and Normalization are designed as the structure in the Transformer.</p></li>
<li><p>From the picture of Transformer structure, we can find that the stacking of multiple sub-encoders completes the construction of the model encoder. In the ViT model, this idea is still followed, and the number of stacking layers can be determined by configuring the hyperparameter num_layers.</p></li>
<li><p>The structures of Residual Connection and Normalization can ensure that the model has strong scalability (to ensure that the information will not degrade after deep processing, which is the role of Residual Connection), and the application of Normalization and dropout can enhance the model generalization ability.</p></li>
</ol>
<p>The Transformer structure can be clearly seen in the following source code. Combining the TransformerEncoder structure with a multilayer perceptron (MLP) forms the backbone part in the ViT model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">,</span>
                 <span class="n">attention_keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">drop_path_keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Cell</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
                 <span class="n">norm</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Cell</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TransformerEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="n">normalization1</span> <span class="o">=</span> <span class="n">norm</span><span class="p">((</span><span class="n">dim</span><span class="p">,))</span>
            <span class="n">normalization2</span> <span class="o">=</span> <span class="n">norm</span><span class="p">((</span><span class="n">dim</span><span class="p">,))</span>
            <span class="n">attention</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
                                  <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                                  <span class="n">keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">,</span>
                                  <span class="n">attention_keep_prob</span><span class="o">=</span><span class="n">attention_keep_prob</span><span class="p">)</span>

            <span class="n">feedforward</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
                                      <span class="n">hidden_features</span><span class="o">=</span><span class="n">mlp_dim</span><span class="p">,</span>
                                      <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
                                      <span class="n">keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>

            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span>
                    <span class="n">ResidualCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span><span class="n">normalization1</span><span class="p">,</span> <span class="n">attention</span><span class="p">])),</span>
                    <span class="n">ResidualCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span><span class="n">normalization2</span><span class="p">,</span> <span class="n">feedforward</span><span class="p">]))</span>
                <span class="p">])</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transformer construct.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="input-for-vit-model">
<h3>Input for ViT model<a class="headerlink" href="#input-for-vit-model" title="Permalink to this headline"></a></h3>
<p>The traditional Transformer structure is mainly used to deal with Word Embedding or Word Vector in the natural language domain. The main difference between word vectors and traditional image data is that word vectors are usually 1-dimensional vectors for stacking, while images are stacked in a 2-dimensional matrix. The multi-headed attention mechanism extracts the connection between word vectors, i.e., the contextual semantics, when dealing with the stack of 1-dimensional word vectors, which makes Transformer very useful in the field of natural language processing. How the 2-dimensional image matrix is transformed with 1-dimensional word vectors becomes a small threshold for Transformer to enter the field of image processing.</p>
<p>In the ViT model:</p>
<ol class="arabic simple">
<li><p>By dividing the input image into 16*16 patches on each channel, this step is done by a convolution operation, which can of course be done manually, but the convolution operation can also serve the purpose while still allowing for the same data processing. <strong>For example, an input 224 x 224 image is first convolved to get 16 x 16 patches, so the size of each patch is 14 x 14.</strong></p></li>
<li><p>The matrix of each patch is then stretched into a 1-dimensional vector, thus obtaining an approximate word vector stacking effect. <strong>The 14 x 14 patch obtained in the previous step is then converted to a vector of length 196.</strong></p></li>
</ol>
<p>This is the first processing step of the image input network. The code for the specific Patch Embedding is shown below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">PatchEmbedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="n">MIN_NUM_PATCHES</span> <span class="o">=</span> <span class="mi">4</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">image_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">224</span><span class="p">,</span>
                 <span class="n">patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
                 <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">768</span><span class="p">,</span>
                 <span class="n">input_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PatchEmbedding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_patches</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_size</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Path Embedding construct.&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span> <span class="o">*</span> <span class="n">w</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<p>After the input image is divided into patches, it goes through two processes, pos_embedding and class_embedding.</p>
<ol class="arabic simple">
<li><p>class_embedding mainly borrows from the BERT model for text classification, adding a class value before each word vector, usually in the first position of the vector. <strong>The 196-dimensional vector obtained in the previous step becomes 197-dimension after adding class_embedding.</strong></p></li>
<li><p>The added class_embedding is a parameter that can be learned. After continuous training of the network, the output of the first dimension in the output vector is ultimately used to determine the final output class. <strong>Since the input is 16 x 16 patch, the output is classified by taking 16 x 16 class_embeddings for classification.</strong></p></li>
<li><p>The pos_embedding is also a set of parameters that can be learned and will be added to the processed patch matrix.</p></li>
<li><p>Since pos_embedding is also a parameter that can be learned, it is joined similarly to the bias of fully-linked networks and convolution. <strong>This step is to create a trainable vector of 197-dimension to be added to the vector that has gone through class_embedding.</strong></p></li>
</ol>
<p>In fact, there are a total of 4 options for pos_embedding. But after the authors’ arguments, only adding pos_embedding and not adding pos_embedding has a significant impact. Whether pos_embedding is 1-dimensional or 2-dimensional has little effect on the classification result, so in code, the 1-dimensional pos_embedding is also applied. Since class_embedding is added before pos_embedding, the dimension of pos_embedding will be plus 1 than the dimension after patch stretching.</p>
<p>In general, the ViT model takes advantage of the Transformer model in processing contextual semantics by converting images into a “variant word vector” and then processing them. The significance of this conversion is that multiple patches are spatially connected, which is similar to a “spatial semantics”, and thus achieves better processing results.</p>
</section>
<section id="building-vit-as-a-whole">
<h3>Building ViT as a whole<a class="headerlink" href="#building-vit-as-a-whole" title="Permalink to this headline"></a></h3>
<p>The following code constructs a complete ViT model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">Normal</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">initializer</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Parameter</span>


<span class="k">def</span> <span class="nf">init</span><span class="p">(</span><span class="n">init_type</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">requires_grad</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Init.&quot;&quot;&quot;</span>
    <span class="n">initial</span> <span class="o">=</span> <span class="n">initializer</span><span class="p">(</span><span class="n">init_type</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">init_data</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initial</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">requires_grad</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ViT</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">image_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">224</span><span class="p">,</span>
                 <span class="n">input_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
                 <span class="n">patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
                 <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">768</span><span class="p">,</span>
                 <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span>
                 <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span>
                 <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3072</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">attention_keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">drop_path_keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Cell</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
                 <span class="n">norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">,</span>
                 <span class="n">pool</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;cls&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ViT</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">patch_embedding</span> <span class="o">=</span> <span class="n">PatchEmbedding</span><span class="p">(</span><span class="n">image_size</span><span class="o">=</span><span class="n">image_size</span><span class="p">,</span>
                                              <span class="n">patch_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span>
                                              <span class="n">embed_dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span>
                                              <span class="n">input_channels</span><span class="o">=</span><span class="n">input_channels</span><span class="p">)</span>
        <span class="n">num_patches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_embedding</span><span class="o">.</span><span class="n">num_patches</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cls_token</span> <span class="o">=</span> <span class="n">init</span><span class="p">(</span><span class="n">init_type</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
                              <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">),</span>
                              <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                              <span class="n">name</span><span class="o">=</span><span class="s1">&#39;cls&#39;</span><span class="p">,</span>
                              <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pos_embedding</span> <span class="o">=</span> <span class="n">init</span><span class="p">(</span><span class="n">init_type</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
                                  <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">),</span>
                                  <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                                  <span class="n">name</span><span class="o">=</span><span class="s1">&#39;pos_embedding&#39;</span><span class="p">,</span>
                                  <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">pool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="o">-</span><span class="n">keep_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span><span class="p">((</span><span class="n">embed_dim</span><span class="p">,))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span> <span class="o">=</span> <span class="n">TransformerEncoder</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span>
                                              <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
                                              <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                                              <span class="n">mlp_dim</span><span class="o">=</span><span class="n">mlp_dim</span><span class="p">,</span>
                                              <span class="n">keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">,</span>
                                              <span class="n">attention_keep_prob</span><span class="o">=</span><span class="n">attention_keep_prob</span><span class="p">,</span>
                                              <span class="n">drop_path_keep_prob</span><span class="o">=</span><span class="n">drop_path_keep_prob</span><span class="p">,</span>
                                              <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
                                              <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="o">-</span><span class="n">keep_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;ViT construct.&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">cls_tokens</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cls_token</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">cls_tokens</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_embedding</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<p>The overall flow diagram is shown below:</p>
<p><img alt="data-process" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.2/tutorials/application/source_en/cv/images/data_process.png" /></p>
</section>
</section>
<section id="model-training-and-inference">
<h2>Model Training and Inference<a class="headerlink" href="#model-training-and-inference" title="Permalink to this headline"></a></h2>
<section id="model-training">
<h3>Model Training<a class="headerlink" href="#model-training" title="Permalink to this headline"></a></h3>
<p>Before the model starts training, the loss function, optimizer, and callback function need to be set.</p>
<p>It takes a long time to train the ViT model completely, and it is recommended to adjust the epoch_size according to the needs of the project when it is actually applied. When the normal output of the step information in each Epoch means that the training is in progress, the model output can be used to view loss value, time and other indicators of the current training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">LossBase</span>
<span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">LossMonitor</span><span class="p">,</span> <span class="n">TimeMonitor</span><span class="p">,</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">ModelCheckpoint</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">train</span>

<span class="c1"># define super parameter</span>
<span class="n">epoch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">resize</span> <span class="o">=</span> <span class="mi">224</span>
<span class="n">step_size</span> <span class="o">=</span> <span class="n">dataset_train</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>

<span class="c1"># construct model</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">ViT</span><span class="p">()</span>

<span class="c1"># load ckpt</span>
<span class="n">vit_url</span> <span class="o">=</span> <span class="s2">&quot;https://download.mindspore.cn/vision/classification/vit_b_16_224.ckpt&quot;</span>
<span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;./ckpt/vit_b_16_224.ckpt&quot;</span>

<span class="n">vit_path</span> <span class="o">=</span> <span class="n">download</span><span class="p">(</span><span class="n">vit_url</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">vit_path</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>

<span class="c1"># define learning rate</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">cosine_decay_lr</span><span class="p">(</span><span class="n">min_lr</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                        <span class="n">max_lr</span><span class="o">=</span><span class="mf">0.00005</span><span class="p">,</span>
                        <span class="n">total_step</span><span class="o">=</span><span class="n">epoch_size</span> <span class="o">*</span> <span class="n">step_size</span><span class="p">,</span>
                        <span class="n">step_per_epoch</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span>
                        <span class="n">decay_epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># define optimizer</span>
<span class="n">network_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="p">)</span>


<span class="c1"># define loss function</span>
<span class="k">class</span> <span class="nc">CrossEntropySmooth</span><span class="p">(</span><span class="n">LossBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;CrossEntropy.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">smooth_factor</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CrossEntropySmooth</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">onehot</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">OneHot</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="o">=</span> <span class="n">sparse</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">smooth_factor</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">smooth_factor</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_classes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ce</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logit</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">onehot</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">logit</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ce</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>


<span class="n">network_loss</span> <span class="o">=</span> <span class="n">CrossEntropySmooth</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                  <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
                                  <span class="n">smooth_factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                                  <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>

<span class="c1"># set checkpoint</span>
<span class="n">ckpt_config</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">ckpt_callback</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;vit_b_16&#39;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s1">&#39;./ViT&#39;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">ckpt_config</span><span class="p">)</span>

<span class="c1"># initialize model</span>
<span class="c1"># &quot;Ascend + mixed precision&quot; can improve performance</span>
<span class="n">ascend_target</span> <span class="o">=</span> <span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">get_context</span><span class="p">(</span><span class="s2">&quot;device_target&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">ascend_target</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">network_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">network_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;acc&quot;</span><span class="p">},</span> <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O2&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">network_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">network_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;acc&quot;</span><span class="p">},</span> <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O0&quot;</span><span class="p">)</span>

<span class="c1"># train model</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch_size</span><span class="p">,</span>
            <span class="n">dataset_train</span><span class="p">,</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ckpt_callback</span><span class="p">,</span> <span class="n">LossMonitor</span><span class="p">(</span><span class="mi">125</span><span class="p">),</span> <span class="n">TimeMonitor</span><span class="p">(</span><span class="mi">125</span><span class="p">)],</span>
            <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Downloading data from https://download.mindspore.cn/vision/classification/vit_b_16_224.ckpt (330.2 MB)

file_sizes: 100%|████████████████████████████| 346M/346M [00:05&lt;00:00, 59.5MB/s]
Successfully downloaded file to ./ckpt/vit_b_16_224.ckpt
epoch: 1 step: 125, loss is 1.903618335723877
Train epoch time: 99857.517 ms, per step time: 798.860 ms
epoch: 2 step: 125, loss is 1.448015570640564
Train epoch time: 95555.111 ms, per step time: 764.441 ms
epoch: 3 step: 125, loss is 1.2555729150772095
Train epoch time: 95553.210 ms, per step time: 764.426 ms
epoch: 4 step: 125, loss is 1.3787992000579834
Train epoch time: 95569.835 ms, per step time: 764.559 ms
epoch: 5 step: 125, loss is 1.7505667209625244
Train epoch time: 95463.133 ms, per step time: 763.705 ms
epoch: 6 step: 125, loss is 2.5462236404418945
Train epoch time: 95428.906 ms, per step time: 763.431 ms
epoch: 7 step: 125, loss is 1.5103509426116943
Train epoch time: 95411.338 ms, per step time: 763.291 ms
epoch: 8 step: 125, loss is 1.4719784259796143
Train epoch time: 95644.054 ms, per step time: 765.152 ms
epoch: 9 step: 125, loss is 1.2415032386779785
Train epoch time: 95511.758 ms, per step time: 764.094 ms
epoch: 10 step: 125, loss is 1.098097562789917
Train epoch time: 95270.282 ms, per step time: 762.162 ms
</pre></div>
</div>
</section>
<section id="model-validation">
<h3>Model Validation<a class="headerlink" href="#model-validation" title="Permalink to this headline"></a></h3>
<p>The model validation process mainly applies interfaces such as ImageFolderDataset, CrossEntropySmooth and Model.</p>
<p>ImageFolderDataset is mainly used to read datasets.</p>
<p>CrossEntropySmooth is the loss function instantiation interface.</p>
<p>Model is mainly used to compile models.</p>
<p>Similar to the training process, data augmentation is first performed, then the ViT network structure is defined and pre-trained model parameters are loaded. Subsequently, the loss function and evaluation metrics are set, and the model is compiled and then validated. This case uses the Top_1_Accuracy and Top_5_Accuracy evaluation metrics, which are commonly used in the industry, to evaluate the model performance.</p>
<p>In this case, these two metrics represent the accuracy of the model prediction when the categories represented by the maximum or the top 5 output values are the prediction results in the output 1000-dimensional vector. Larger values of these two metrics represent higher model accuracy.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_val</span> <span class="o">=</span> <span class="n">ImageFolderDataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">trans_val</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">224</span> <span class="o">+</span> <span class="mi">32</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
<span class="p">]</span>

<span class="n">dataset_val</span> <span class="o">=</span> <span class="n">dataset_val</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">trans_val</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
<span class="n">dataset_val</span> <span class="o">=</span> <span class="n">dataset_val</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># construct model</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">ViT</span><span class="p">()</span>

<span class="c1"># load ckpt</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">vit_path</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>

<span class="n">network_loss</span> <span class="o">=</span> <span class="n">CrossEntropySmooth</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                  <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
                                  <span class="n">smooth_factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                                  <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>

<span class="c1"># define metric</span>
<span class="n">eval_metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Top_1_Accuracy&#39;</span><span class="p">:</span> <span class="n">train</span><span class="o">.</span><span class="n">Top1CategoricalAccuracy</span><span class="p">(),</span>
                <span class="s1">&#39;Top_5_Accuracy&#39;</span><span class="p">:</span> <span class="n">train</span><span class="o">.</span><span class="n">Top5CategoricalAccuracy</span><span class="p">()}</span>

<span class="k">if</span> <span class="n">ascend_target</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">network_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">network_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">eval_metrics</span><span class="p">,</span> <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O2&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">network_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">network_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">eval_metrics</span><span class="p">,</span> <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O0&quot;</span><span class="p">)</span>

<span class="c1"># evaluate model</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{&#39;Top_1_Accuracy&#39;: 0.75, &#39;Top_5_Accuracy&#39;: 0.928}
</pre></div>
</div>
<p>From the results, we can see that the Top_1_Accuracy and Top_5_Accuracy of the model reach a high level due to our loading of pre-trained model parameters, and this accuracy can be used as the standard in the actual project. If the pre-trained model parameters are not used, more epochs are needed for training.</p>
</section>
<section id="model-inference">
<h3>Model Inference<a class="headerlink" href="#model-inference" title="Permalink to this headline"></a></h3>
<p>Before performing model inference, a method for preprocessing data on the inferred images is first defined. This method allows us to resize and normalize our inference images so that they can match our input data during training.</p>
<p>In this case, a picture of Doberman is used as an inference picture to test the model performance, and the model is expected to give correct predicted results.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_infer</span> <span class="o">=</span> <span class="n">ImageFolderDataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;infer&quot;</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">trans_infer</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">([</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">]),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
<span class="p">]</span>

<span class="n">dataset_infer</span> <span class="o">=</span> <span class="n">dataset_infer</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">trans_infer</span><span class="p">,</span>
                                  <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">],</span>
                                  <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dataset_infer</span> <span class="o">=</span> <span class="n">dataset_infer</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Next, we will call the predict method of the model for the model.</p>
<p>In the inference process, the corresponding label can be obtained by index2label, and then the result is written on the corresponding image through the custom show_result interface.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">io</span>


<span class="k">class</span> <span class="nc">Color</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;dedine enum color.&quot;&quot;&quot;</span>
    <span class="n">red</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
    <span class="n">green</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">blue</span> <span class="o">=</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">cyan</span> <span class="o">=</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">yellow</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
    <span class="n">magenta</span> <span class="o">=</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
    <span class="n">white</span> <span class="o">=</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
    <span class="n">black</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">check_file_exist</span><span class="p">(</span><span class="n">file_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;check_file_exist.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">file_name</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;File `</span><span class="si">{</span><span class="n">file_name</span><span class="si">}</span><span class="s2">` does not exist.&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">color_val</span><span class="p">(</span><span class="n">color</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;color_val.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">color</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Color</span><span class="p">[</span><span class="n">color</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">color</span><span class="p">,</span> <span class="n">Color</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">color</span><span class="o">.</span><span class="n">value</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">color</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">color</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
        <span class="k">for</span> <span class="n">channel</span> <span class="ow">in</span> <span class="n">color</span><span class="p">:</span>
            <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">channel</span> <span class="o">&lt;=</span> <span class="mi">255</span>
        <span class="k">return</span> <span class="n">color</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">color</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">color</span> <span class="o">&lt;=</span> <span class="mi">255</span>
        <span class="k">return</span> <span class="n">color</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">color</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">color</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">color</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">color</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">3</span>
        <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">color</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">color</span> <span class="o">&lt;=</span> <span class="mi">255</span><span class="p">))</span>
        <span class="n">color</span> <span class="o">=</span> <span class="n">color</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">color</span><span class="p">)</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Invalid type for color: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">color</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">imread</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;imread.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">):</span>
        <span class="n">image</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">pass</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">check_file_exist</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mode</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">mode</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Image must be a `ndarray`, `str` or Path object.&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">image</span>


<span class="k">def</span> <span class="nf">imwrite</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">image_path</span><span class="p">,</span> <span class="n">auto_mkdir</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;imwrite.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">auto_mkdir</span><span class="p">:</span>
        <span class="n">dir_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">image_path</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">dir_name</span> <span class="o">!=</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
            <span class="n">dir_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">dir_name</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">dir_name</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="mi">777</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">image</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">win_name</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">wait_time</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;imshow&quot;&quot;&quot;</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">win_name</span><span class="p">,</span> <span class="n">imread</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">wait_time</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># prevent from hanging if windows was closed</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">closed</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">getWindowProperty</span><span class="p">(</span><span class="n">win_name</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">WND_PROP_VISIBLE</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span>
            <span class="c1"># if user closed window or if some key pressed</span>
            <span class="k">if</span> <span class="n">closed</span> <span class="ow">or</span> <span class="n">ret</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="k">break</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="n">wait_time</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">show_result</span><span class="p">(</span><span class="n">img</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                <span class="n">result</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
                <span class="n">text_color</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span>
                <span class="n">font_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
                <span class="n">row_width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
                <span class="n">show</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                <span class="n">win_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="n">wait_time</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                <span class="n">out_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mark the prediction results on the picture.&quot;&quot;&quot;</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">imread</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">row_width</span>
    <span class="n">text_color</span> <span class="o">=</span> <span class="n">color_val</span><span class="p">(</span><span class="n">text_color</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="n">v</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="n">label_text</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">label_text</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_COMPLEX</span><span class="p">,</span>
                    <span class="n">font_scale</span><span class="p">,</span> <span class="n">text_color</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">+=</span> <span class="n">row_width</span>
    <span class="k">if</span> <span class="n">out_file</span><span class="p">:</span>
        <span class="n">show</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">imwrite</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">out_file</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
        <span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">win_name</span><span class="p">,</span> <span class="n">wait_time</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">index2label</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Dictionary output for image numbers and categories of the ImageNet dataset.&quot;&quot;&quot;</span>
    <span class="n">metafile</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;ILSVRC2012_devkit_t12/data/meta.mat&quot;</span><span class="p">)</span>
    <span class="n">meta</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">loadmat</span><span class="p">(</span><span class="n">metafile</span><span class="p">,</span> <span class="n">squeeze_me</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s1">&#39;synsets&#39;</span><span class="p">]</span>

    <span class="n">nums_children</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">meta</span><span class="p">))[</span><span class="mi">4</span><span class="p">]</span>
    <span class="n">meta</span> <span class="o">=</span> <span class="p">[</span><span class="n">meta</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">num_children</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nums_children</span><span class="p">)</span> <span class="k">if</span> <span class="n">num_children</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">wnids</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">meta</span><span class="p">))[:</span><span class="mi">3</span><span class="p">]</span>
    <span class="n">clssname</span> <span class="o">=</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">clss</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;, &#39;</span><span class="p">))</span> <span class="k">for</span> <span class="n">clss</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">]</span>
    <span class="n">wnid2class</span> <span class="o">=</span> <span class="p">{</span><span class="n">wnid</span><span class="p">:</span> <span class="n">clss</span> <span class="k">for</span> <span class="n">wnid</span><span class="p">,</span> <span class="n">clss</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">wnids</span><span class="p">,</span> <span class="n">clssname</span><span class="p">)}</span>
    <span class="n">wind2class_name</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">wnid2class</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">mapping</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">class_name</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wind2class_name</span><span class="p">):</span>
        <span class="n">mapping</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_name</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">mapping</span>


<span class="c1"># Read data for inference</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">image</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset_infer</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">)):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">prob</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">mapping</span> <span class="o">=</span> <span class="n">index2label</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="p">{</span><span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="p">):</span> <span class="n">mapping</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="p">)]}</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    <span class="n">show_result</span><span class="p">(</span><span class="n">img</span><span class="o">=</span><span class="s2">&quot;./dataset/infer/n01440764/ILSVRC2012_test_00000279.JPEG&quot;</span><span class="p">,</span>
                <span class="n">result</span><span class="o">=</span><span class="n">output</span><span class="p">,</span>
                <span class="n">out_file</span><span class="o">=</span><span class="s2">&quot;./dataset/infer/ILSVRC2012_test_00000279.JPEG&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{236: &#39;Doberman&#39;}
</pre></div>
</div>
<p>After the inference process is completed, the inference result of the picture can be found under the inference folder, and it can be seen that the prediction result is Doberman, which is the same as the expected result and verifies the accuracy of the model.</p>
<p><img alt="infer-result" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.2/tutorials/application/source_zh_cn/cv/images/infer_result.jpg" /></p>
</section>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline"></a></h2>
<p>This case completes the process of training, validation and inference of a ViT model on ImageNet data, in which the key ViT model structure and principles are explained. By studying this case, understanding the source code can help users to master key concepts such as Multi-Head Attention, TransformerEncoder, pos_embedding, etc. If you want to understand ViT’s model principles in detail, it is recommended to read it in deeper detail based on the source code.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="fgsm.html" class="btn btn-neutral float-left" title="FGSM Network Adversarial Attack" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="cnnctc.html" class="btn btn-neutral float-right" title="CNN and CTC for Recognizing Text from Images" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>