<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Vision Transformer图像分类 &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script><script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="RNN实现情感分类" href="../nlp/sentiment_analysis.html" />
    <link rel="prev" title="DCGAN生成漫画头像" href="dcgan.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">计算机视觉</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="fgsm.html">FGSM网络对抗攻击</a></li>
<li class="toctree-l1"><a class="reference internal" href="dcgan.html">DCGAN生成漫画头像</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Vision Transformer图像分类</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#vision-transformervit简介">Vision Transformer（ViT）简介</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#模型结构">模型结构</a></li>
<li class="toctree-l3"><a class="reference internal" href="#模型特点">模型特点</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#环境准备与数据读取">环境准备与数据读取</a></li>
<li class="toctree-l2"><a class="reference internal" href="#模型解析">模型解析</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#transformer基本原理">Transformer基本原理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#attention模块">Attention模块</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#transformer-encoder">Transformer Encoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#vit模型的输入">ViT模型的输入</a></li>
<li class="toctree-l3"><a class="reference internal" href="#整体构建vit">整体构建ViT</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#模型训练与推理">模型训练与推理</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#模型训练">模型训练</a></li>
<li class="toctree-l3"><a class="reference internal" href="#模型验证">模型验证</a></li>
<li class="toctree-l3"><a class="reference internal" href="#模型推理">模型推理</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#总结">总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="#引用">引用</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">自然语言处理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../nlp/sentiment_analysis.html">RNN实现情感分类</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nlp/sequence_labeling.html">LSTM+CRF序列标注</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Vision Transformer图像分类</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/cv/vit.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="vision-transformer图像分类">
<h1>Vision Transformer图像分类<a class="headerlink" href="#vision-transformer图像分类" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://openi.pcl.ac.cn/MindSpore/docs/src/branch/r1.10/tutorials/application/source_zh_cn/cv/vit.ipynb?card=2&amp;image=MindSpore1.8.1"><img alt="在OpenI运行" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/resource/_static/logo_openi.png" /></a> <a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/r1.10/tutorials/application/zh_cn/cv/mindspore_vit.ipynb"><img alt="下载Notebook" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/resource/_static/logo_notebook.png" /></a> <a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/r1.10/tutorials/application/zh_cn/cv/mindspore_vit.py"><img alt="下载样例代码" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/resource/_static/logo_download_code.png" /></a> <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.10/tutorials/application/source_zh_cn/cv/vit.ipynb"><img alt="查看源文件" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/resource/_static/logo_source.png" /></a></p>
<section id="vision-transformervit简介">
<h2>Vision Transformer（ViT）简介<a class="headerlink" href="#vision-transformervit简介" title="Permalink to this headline"></a></h2>
<p>近些年，随着基于自注意（Self-Attention）结构的模型的发展，特别是Transformer模型的提出，极大地促进了自然语言处理模型的发展。由于Transformers的计算效率和可扩展性，它已经能够训练具有超过100B参数的空前规模的模型。</p>
<p>ViT则是自然语言处理和计算机视觉两个领域的融合结晶。在不依赖卷积操作的情况下，依然可以在图像分类任务上达到很好的效果。</p>
<section id="模型结构">
<h3>模型结构<a class="headerlink" href="#模型结构" title="Permalink to this headline"></a></h3>
<p>ViT模型的主体结构是基于Transformer模型的Encoder部分（部分结构顺序有调整，如：Normalization的位置与标准Transformer不同），其结构图[1]如下：</p>
<p><img alt="vit-architecture" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/tutorials/application/source_zh_cn/cv/images/vit_architecture.png" /></p>
</section>
<section id="模型特点">
<h3>模型特点<a class="headerlink" href="#模型特点" title="Permalink to this headline"></a></h3>
<p>ViT模型主要应用于图像分类领域。因此，其模型结构相较于传统的Transformer有以下几个特点：</p>
<ol class="arabic simple">
<li><p>数据集的原图像被划分为多个patch后，将二维patch（不考虑channel）转换为一维向量，再加上类别向量与位置向量作为模型输入。</p></li>
<li><p>模型主体的Block结构是基于Transformer的Encoder结构，但是调整了Normalization的位置，其中，最主要的结构依然是Multi-head Attention结构。</p></li>
<li><p>模型在Blocks堆叠后接全连接层，接受类别向量的输出作为输入并用于分类。通常情况下，我们将最后的全连接层称为Head，Transformer Encoder部分为backbone。</p></li>
</ol>
<p>下面将通过代码实例来详细解释基于ViT实现ImageNet分类任务。</p>
</section>
</section>
<section id="环境准备与数据读取">
<h2>环境准备与数据读取<a class="headerlink" href="#环境准备与数据读取" title="Permalink to this headline"></a></h2>
<p>开始实验之前，请确保本地已经安装了Python环境。</p>
<p>首先导入相关模块，配置相关超参数并读取数据集。</p>
<p>下载完整的<a class="reference external" href="http://image-net.org">ImageNet数据集</a>。</p>
<p>本案例应用的数据集是从ImageNet中筛选出来的子集，运行第一段代码时会自动下载并解压。</p>
<p>请确保你的数据集路径如以下结构。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>.dataset/
    ├── ILSVRC2012_devkit_t12.tar.gz
    ├── train/
    ├── infer/
    └── val/
</pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">download</span> <span class="kn">import</span> <span class="n">download</span>

<span class="n">dataset_url</span> <span class="o">=</span> <span class="s2">&quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/vit_imagenet_dataset.zip&quot;</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">download</span><span class="p">(</span><span class="n">dataset_url</span><span class="p">,</span> <span class="s2">&quot;./&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;zip&quot;</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Downloading data from https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/vit_imagenet_dataset.zip (489.1 MB)

file_sizes: 100%|████████████████████████████| 513M/513M [00:06&lt;00:00, 74.1MB/s]
Extracting zip file...
Successfully downloaded / unzipped to ./
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset</span> <span class="kn">import</span> <span class="n">ImageFolderDataset</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision</span> <span class="k">as</span> <span class="nn">transforms</span>

<span class="n">data_path</span> <span class="o">=</span> <span class="s1">&#39;./dataset/&#39;</span>
<span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.485</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.456</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.406</span> <span class="o">*</span> <span class="mi">255</span><span class="p">]</span>
<span class="n">std</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.229</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.224</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.225</span> <span class="o">*</span> <span class="mi">255</span><span class="p">]</span>

<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">ImageFolderDataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">trans_train</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomCropDecodeResize</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span>
                                      <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.08</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
                                      <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">1.333</span><span class="p">)),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
<span class="p">]</span>

<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">dataset_train</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">trans_train</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">dataset_train</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="模型解析">
<h2>模型解析<a class="headerlink" href="#模型解析" title="Permalink to this headline"></a></h2>
<p>下面将通过代码来细致剖析ViT模型的内部结构。</p>
<section id="transformer基本原理">
<h3>Transformer基本原理<a class="headerlink" href="#transformer基本原理" title="Permalink to this headline"></a></h3>
<p>Transformer模型源于2017年的一篇文章[2]。在这篇文章中提出的基于Attention机制的编码器-解码器型结构在自然语言处理领域获得了巨大的成功。模型结构如下图所示：</p>
<p><img alt="transformer-architecture" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/tutorials/application/source_zh_cn/cv/images/transformer_architecture.png" /></p>
<p>其主要结构为多个Encoder和Decoder模块所组成，其中Encoder和Decoder的详细结构如下图[2]所示：</p>
<p><img alt="encoder-decoder" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/tutorials/application/source_zh_cn/cv/images/encoder_decoder.png" /></p>
<p>Encoder与Decoder由许多结构组成，如：多头注意力（Multi-Head Attention）层、Feed Forward层、Normaliztion层和残差连接（Residual Connection，图中的“Add”）。</p>
<p>其中最重要的结构是多头注意力（Multi-Head Attention）结构，该结构基于自注意力（Self-Attention）机制，是多个Self-Attention的并行组成。所以，理解了Self-Attention就抓住了Transformer的核心。</p>
<section id="attention模块">
<h4>Attention模块<a class="headerlink" href="#attention模块" title="Permalink to this headline"></a></h4>
<p>以下是Self-Attention的解释，其核心内容是为输入向量的每个单词学习一个权重。通过给定一个任务相关的查询向量Query向量，计算Query和各个Key的相似性或者相关性得到注意力分布，即得到每个Key对应Value的权重系数，然后对Value进行加权求和得到最终的Attention数值。</p>
<p>在Self-Attention中:</p>
<ol class="arabic simple">
<li><p>最初的输入向量首先会经过Embedding层映射成Q（Query），K（Key），V（Value）三个向量，由于是并行操作，所以代码中是映射成为dim x
3的向量然后进行分割，换言之，如果你的输入向量为一个向量序列（<span class="math notranslate nohighlight">\(x_1\)</span>，<span class="math notranslate nohighlight">\(x_2\)</span>，<span class="math notranslate nohighlight">\(x_3\)</span>），其中的<span class="math notranslate nohighlight">\(x_1\)</span>，<span class="math notranslate nohighlight">\(x_2\)</span>，<span class="math notranslate nohighlight">\(x_3\)</span>都是一维向量，那么每一个一维向量都会经过Embedding层映射出Q，K，V三个向量，只是Embedding矩阵不同，矩阵参数也是通过学习得到的。<strong>这里大家可以认为，Q，K，V三个矩阵是发现向量之间关联信息的一种手段，需要经过学习得到，至于为什么是Q，K，V三个，主要是因为需要两个向量点乘以获得权重，又需要另一个向量来承载权重向加的结果，所以，最少需要3个矩阵。</strong></p></li>
</ol>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{cases}
q_i = W_q \cdot x_i &amp; \\
k_i = W_k \cdot x_i,\hspace{1em} &amp;i = 1,2,3 \ldots \\
v_i = W_v \cdot x_i &amp;
\end{cases}
\end{split}\tag{1}\]</div>
<p><img alt="self-attention1" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/tutorials/application/source_zh_cn/cv/images/self_attention_1.png" /></p>
<ol class="arabic simple" start="2">
<li><p>自注意力机制的自注意主要体现在它的Q，K，V都来源于其自身，也就是该过程是在提取输入的不同顺序的向量的联系与特征，最终通过不同顺序向量之间的联系紧密性（Q与K乘积经过Softmax的结果）来表现出来。<strong>Q，K，V得到后就需要获取向量间权重，需要对Q和K进行点乘并除以维度的平方根，对所有向量的结果进行Softmax处理，通过公式(2)的操作，我们获得了向量之间的关系权重。</strong></p></li>
</ol>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{cases}
a_{1,1} = q_1 \cdot k_1 / \sqrt d \\
a_{1,2} = q_1 \cdot k_2 / \sqrt d \\
a_{1,3} = q_1 \cdot k_3 / \sqrt d
\end{cases}
\end{split}\tag{2}\]</div>
<p><img alt="self-attention3" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/tutorials/application/source_zh_cn/cv/images/self_attention_3.png" /></p>
<div class="math notranslate nohighlight">
\[Softmax: \hat a_{1,i} = exp(a_{1,i}) / \sum_j exp(a_{1,j}),\hspace{1em} j = 1,2,3 \ldots \tag{3}\]</div>
<p><img alt="self-attention2" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/tutorials/application/source_zh_cn/cv/images/self_attention_2.png" /></p>
<ol class="arabic simple" start="3">
<li><p>其最终输出则是通过V这个映射后的向量与Q，K经过Softmax结果进行weight sum获得，这个过程可以理解为在全局上进行自注意表示。<strong>每一组Q，K，V最后都有一个V输出，这是Self-Attention得到的最终结果，是当前向量在结合了它与其他向量关联权重后得到的结果。</strong></p></li>
</ol>
<div class="math notranslate nohighlight">
\[b_1 = \sum_i \hat a_{1,i}v_i,\hspace{1em} i = 1,2,3...
\tag{4}\]</div>
<p>通过下图可以整体把握Self-Attention的全部过程。</p>
<p><img alt="self-attention" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/tutorials/application/source_zh_cn/cv/images/self_attention_process.png" /></p>
<p>多头注意力机制就是将原本self-Attention处理的向量分割为多个Head进行处理，这一点也可以从代码中体现，这也是attention结构可以进行并行加速的一个方面。</p>
<p>总结来说，多头注意力机制在保持参数总量不变的情况下，将同样的query, key和value映射到原来的高维空间（Q,K,V）的不同子空间(Q_0,K_0,V_0)中进行自注意力的计算，最后再合并不同子空间中的注意力信息。</p>
<p>所以，对于同一个输入向量，多个注意力机制可以同时对其进行处理，即利用并行计算加速处理过程，又在处理的时候更充分的分析和利用了向量特征。下图展示了多头注意力机制，其并行能力的主要体现在下图中的<span class="math notranslate nohighlight">\(a_1\)</span>和<span class="math notranslate nohighlight">\(a_2\)</span>是同一个向量进行分割获得的。</p>
<p><img alt="multi-head-attention" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/tutorials/application/source_zh_cn/cv/images/multi_head_attention.png" /></p>
<p>以下是Multi-Head Attention代码，结合上文的解释，代码清晰的展现了这一过程。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">ops</span>


<span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">attention_keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Attention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
        <span class="n">head_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">//</span> <span class="n">num_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">head_dim</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">attention_keep_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">keep_prob</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attn_matmul_v</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">BatchMatMul</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_matmul_k</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">BatchMatMul</span><span class="p">(</span><span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;注意力模块&quot;&quot;&quot;</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="c1"># 最初的输入向量首先会经过Embedding层映射成Q(Query)，K(Key), V(Value)三个向量</span>
        <span class="c1"># 由于是并行操作，所以代码中是映射成为dim*3的向量然后进行分割</span>
        <span class="n">qkv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1">#多头注意力机制就是将原本self-Attention处理的向量分割为多个Head进行处理</span>
        <span class="n">qkv</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">qkv</span><span class="p">,</span> <span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">c</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">))</span>
        <span class="n">qkv</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">qkv</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">qkv</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># 自注意力机制的自注意主要体现在它的Q，K，V都来源于其自身</span>
        <span class="c1"># 也就是该过程是在提取输入的不同顺序的向量的联系与特征</span>
        <span class="c1"># 最终通过不同顺序向量之间的联系紧密性（Q与K乘积经过Softmax的结果）来表现出来</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_matmul_k</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_drop</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>

        <span class="c1"># 其最终输出则是通过V这个映射后的向量与QK经过Softmax结果进行weight sum获得</span>
        <span class="c1"># 这个过程可以理解为在全局上进行自注意表示</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_matmul_v</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_drop</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="transformer-encoder">
<h3>Transformer Encoder<a class="headerlink" href="#transformer-encoder" title="Permalink to this headline"></a></h3>
<p>在了解了Self-Attention结构之后，通过与Feed Forward，Residual Connection等结构的拼接就可以形成Transformer的基础结构。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Dict</span>


<span class="k">class</span> <span class="nc">FeedForward</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">in_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">hidden_features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">out_features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Cell</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FeedForward</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">out_features</span> <span class="o">=</span> <span class="n">out_features</span> <span class="ow">or</span> <span class="n">in_features</span>
        <span class="n">hidden_features</span> <span class="o">=</span> <span class="n">hidden_features</span> <span class="ow">or</span> <span class="n">in_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">keep_prob</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;前向网络模块&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">ResidualCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cell</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ResidualCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">cell</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;残差网络模块&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span>
</pre></div>
</div>
</div>
<p>接下来就利用Self-Attention来构建ViT模型中的TransformerEncoder部分，类似于构建了一个Transformer的编码器部分，如下图[1]所示：</p>
<p><img alt="vit-encoder" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/tutorials/application/source_zh_cn/cv/images/vit_encoder.png" /></p>
<ol class="arabic simple">
<li><p>ViT模型中的基础结构与标准Transformer有所不同，主要在于Normalization的位置是放在Self-Attention和Feed Forward之前，其他结构如Residual Connection，Feed Forward，Normalization都如Transformer中所设计。</p></li>
<li><p>从Transformer结构的图片可以发现，多个子encoder的堆叠就完成了模型编码器的构建，在ViT模型中，依然沿用这个思路，通过配置超参数num_layers，就可以确定堆叠层数。</p></li>
<li><p>Residual Connection，Normalization的结构可以保证模型有很强的扩展性（保证信息经过深层处理不会出现退化的现象，这是Residual Connection的作用），Normalization和dropout的应用可以增强模型泛化能力。</p></li>
</ol>
<p>从以下源码中就可以清晰看到Transformer的结构。将TransformerEncoder结构和一个多层感知器（MLP）结合，就构成了ViT模型的backbone部分。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">,</span>
                 <span class="n">attention_keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">drop_path_keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Cell</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
                 <span class="n">norm</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Cell</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TransformerEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># 从vit_architecture图可以发现，多个子encoder的堆叠就完成了模型编码器的构建</span>
        <span class="c1"># 在ViT模型中，依然沿用这个思路，通过配置超参数num_layers，就可以确定堆叠层数</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="n">normalization1</span> <span class="o">=</span> <span class="n">norm</span><span class="p">((</span><span class="n">dim</span><span class="p">,))</span>
            <span class="n">normalization2</span> <span class="o">=</span> <span class="n">norm</span><span class="p">((</span><span class="n">dim</span><span class="p">,))</span>
            <span class="n">attention</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
                                  <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                                  <span class="n">keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">,</span>
                                  <span class="n">attention_keep_prob</span><span class="o">=</span><span class="n">attention_keep_prob</span><span class="p">)</span>

            <span class="n">feedforward</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
                                      <span class="n">hidden_features</span><span class="o">=</span><span class="n">mlp_dim</span><span class="p">,</span>
                                      <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
                                      <span class="n">keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>

            <span class="c1"># ViT模型中的基础结构与标准Transformer有所不同</span>
            <span class="c1"># 主要在于Normalization的位置是放在Self-Attention和Feed Forward之前</span>
            <span class="c1"># 其他结构如Residual Connection，Feed Forward，Normalization都如Transformer中所设计</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span>
                    <span class="c1"># Residual Connection，Normalization的结构可以保证模型有很强的扩展性</span>
                    <span class="c1"># 保证信息经过深层处理不会出现退化的现象，这是Residual Connection的作用</span>
                    <span class="c1"># Normalization和dropout的应用可以增强模型泛化能力</span>
                    <span class="n">ResidualCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span><span class="n">normalization1</span><span class="p">,</span>
                                                    <span class="n">attention</span><span class="p">])),</span>

                    <span class="n">ResidualCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span><span class="n">normalization2</span><span class="p">,</span>
                                                    <span class="n">feedforward</span><span class="p">]))</span>
                <span class="p">])</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transformer模块&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="vit模型的输入">
<h3>ViT模型的输入<a class="headerlink" href="#vit模型的输入" title="Permalink to this headline"></a></h3>
<p>传统的Transformer结构主要用于处理自然语言领域的词向量（Word Embedding or Word Vector），词向量与传统图像数据的主要区别在于，词向量通常是1维向量进行堆叠，而图片则是二维矩阵的堆叠，多头注意力机制在处理1维词向量的堆叠时会提取词向量之间的联系也就是上下文语义，这使得Transformer在自然语言处理领域非常好用，而2维图片矩阵如何与1维词向量进行转化就成为了Transformer进军图像处理领域的一个小门槛。</p>
<p>在ViT模型中：</p>
<ol class="arabic simple">
<li><p>通过将输入图像在每个channel上划分为16*16个patch，这一步是通过卷积操作来完成的，当然也可以人工进行划分，但卷积操作也可以达到目的同时还可以进行一次而外的数据处理；<strong>例如一幅输入224 x 224的图像，首先经过卷积处理得到16 x 16个patch，那么每一个patch的大小就是14 x 14。</strong></p></li>
<li><p>再将每一个patch的矩阵拉伸成为一个1维向量，从而获得了近似词向量堆叠的效果。<strong>上一步得到的14 x 14的patch就转换为长度为196的向量。</strong></p></li>
</ol>
<p>这是图像输入网络经过的第一步处理。具体Patch Embedding的代码如下所示：</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">PatchEmbedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="n">MIN_NUM_PATCHES</span> <span class="o">=</span> <span class="mi">4</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">image_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">224</span><span class="p">,</span>
                 <span class="n">patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
                 <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">768</span><span class="p">,</span>
                 <span class="n">input_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PatchEmbedding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_patches</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_size</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>

        <span class="c1"># 通过将输入图像在每个channel上划分为16*16个patch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Reshape</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transpose</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Transpose</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Path Embedding模块&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># 再将每一个patch的矩阵拉伸成为一个1维向量，从而获得了近似词向量堆叠的效果</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span> <span class="o">*</span> <span class="n">w</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
<p>输入图像在划分为patch之后，会经过pos_embedding 和 class_embedding两个过程。</p>
<ol class="arabic simple">
<li><p>class_embedding主要借鉴了BERT模型的用于文本分类时的思想，在每一个word vector之前增加一个类别值，通常是加在向量的第一位，<strong>上一步得到的196维的向量加上class_embedding后变为197维。</strong></p></li>
<li><p>增加的class_embedding是一个可以学习的参数，经过网络的不断训练，最终以输出向量的第一个维度的输出来决定最后的输出类别；<strong>由于输入是16 x 16个patch，所以输出进行分类时是取 16 x 16个class_embedding进行分类。</strong></p></li>
<li><p>pos_embedding也是一组可以学习的参数，会被加入到经过处理的patch矩阵中。</p></li>
<li><p>由于pos_embedding也是可以学习的参数，所以它的加入类似于全链接网络和卷积的bias。<strong>这一步就是创造一个长度维197的可训练向量加入到经过class_embedding的向量中。</strong></p></li>
</ol>
<p>实际上，pos_embedding总共有4种方案。但是经过作者的论证，只有加上pos_embedding和不加pos_embedding有明显影响，至于pos_embedding是1维还是2维对分类结果影响不大，所以，在我们的代码中，也是采用了1维的pos_embedding，由于class_embedding是加在pos_embedding之前，所以pos_embedding的维度会比patch拉伸后的维度加1。</p>
<p>总的而言，ViT模型还是利用了Transformer模型在处理上下文语义时的优势，将图像转换为一种“变种词向量”然后进行处理，而这样转换的意义在于，多个patch之间本身具有空间联系，这类似于一种“空间语义”，从而获得了比较好的处理效果。</p>
</section>
<section id="整体构建vit">
<h3>整体构建ViT<a class="headerlink" href="#整体构建vit" title="Permalink to this headline"></a></h3>
<p>以下代码构建了一个完整的ViT模型。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">Normal</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">initializer</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Parameter</span>


<span class="k">def</span> <span class="nf">init</span><span class="p">(</span><span class="n">init_type</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">requires_grad</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Init函数&quot;&quot;&quot;</span>
    <span class="n">initial</span> <span class="o">=</span> <span class="n">initializer</span><span class="p">(</span><span class="n">init_type</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">init_data</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initial</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">requires_grad</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ViT</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">image_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">224</span><span class="p">,</span>
                 <span class="n">input_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
                 <span class="n">patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
                 <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">768</span><span class="p">,</span>
                 <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span>
                 <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span>
                 <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3072</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">attention_keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">drop_path_keep_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Cell</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
                 <span class="n">norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">,</span>
                 <span class="n">pool</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;cls&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ViT</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">patch_embedding</span> <span class="o">=</span> <span class="n">PatchEmbedding</span><span class="p">(</span><span class="n">image_size</span><span class="o">=</span><span class="n">image_size</span><span class="p">,</span>
                                              <span class="n">patch_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span>
                                              <span class="n">embed_dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span>
                                              <span class="n">input_channels</span><span class="o">=</span><span class="n">input_channels</span><span class="p">)</span>
        <span class="n">num_patches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_embedding</span><span class="o">.</span><span class="n">num_patches</span>

        <span class="c1"># 此处增加class_embedding和pos_embedding，如果不是进行分类任务</span>
        <span class="c1"># 可以只增加pos_embedding，通过pool参数进行控制</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cls_token</span> <span class="o">=</span> <span class="n">init</span><span class="p">(</span><span class="n">init_type</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
                              <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">),</span>
                              <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                              <span class="n">name</span><span class="o">=</span><span class="s1">&#39;cls&#39;</span><span class="p">,</span>
                              <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># pos_embedding也是一组可以学习的参数，会被加入到经过处理的patch矩阵中</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_embedding</span> <span class="o">=</span> <span class="n">init</span><span class="p">(</span><span class="n">init_type</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
                                  <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">),</span>
                                  <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                                  <span class="n">name</span><span class="o">=</span><span class="s1">&#39;pos_embedding&#39;</span><span class="p">,</span>
                                  <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">pool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">keep_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span><span class="p">((</span><span class="n">embed_dim</span><span class="p">,))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span> <span class="o">=</span> <span class="n">TransformerEncoder</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span>
                                              <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
                                              <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                                              <span class="n">mlp_dim</span><span class="o">=</span><span class="n">mlp_dim</span><span class="p">,</span>
                                              <span class="n">keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">,</span>
                                              <span class="n">attention_keep_prob</span><span class="o">=</span><span class="n">attention_keep_prob</span><span class="p">,</span>
                                              <span class="n">drop_path_keep_prob</span><span class="o">=</span><span class="n">drop_path_keep_prob</span><span class="p">,</span>
                                              <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
                                              <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">keep_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ascend_target</span> <span class="o">=</span> <span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">get_context</span><span class="p">(</span><span class="s2">&quot;device_target&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;ViT模块&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># class_embedding主要借鉴了BERT模型的用于文本分类时的思想</span>
        <span class="c1"># 在每一个word vector之前增加一个类别值，通常是加在向量的第一位</span>
        <span class="n">cls_tokens</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cls_token</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="c1"># axis=1定义了会在向量的开头加入class_embedding</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ascend_target</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">cls_tokens</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">float16</span><span class="p">),</span> <span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">cls_tokens</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_embedding</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
<p>整体流程图如下所示：</p>
<p><img alt="data-process" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/tutorials/application/source_zh_cn/cv/images/data_process.png" /></p>
</section>
</section>
<section id="模型训练与推理">
<h2>模型训练与推理<a class="headerlink" href="#模型训练与推理" title="Permalink to this headline"></a></h2>
<section id="模型训练">
<h3>模型训练<a class="headerlink" href="#模型训练" title="Permalink to this headline"></a></h3>
<p>模型开始训练前，需要设定损失函数，优化器，回调函数等。</p>
<p>完整训练ViT模型需要很长的时间，实际应用时建议根据项目需要调整epoch_size，当正常输出每个Epoch的step信息时，意味着训练正在进行，通过模型输出可以查看当前训练的loss值和时间等指标。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">LossBase</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">LossMonitor</span><span class="p">,</span> <span class="n">TimeMonitor</span><span class="p">,</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">ModelCheckpoint</span>

<span class="c1"># 定义超参数</span>
<span class="n">epoch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">resize</span> <span class="o">=</span> <span class="mi">224</span>
<span class="n">step_size</span> <span class="o">=</span> <span class="n">dataset_train</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>

<span class="c1"># 实例化模型</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">ViT</span><span class="p">()</span>

<span class="c1"># 加载权重文件</span>
<span class="n">vit_url</span> <span class="o">=</span> <span class="s2">&quot;https://download.mindspore.cn/vision/classification/vit_b_16_224.ckpt&quot;</span>
<span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;./ckpt/vit_b_16_224.ckpt&quot;</span>

<span class="n">vit_path</span> <span class="o">=</span> <span class="n">download</span><span class="p">(</span><span class="n">vit_url</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">vit_path</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>

<span class="c1"># 定义学习率</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">cosine_decay_lr</span><span class="p">(</span><span class="n">min_lr</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                        <span class="n">max_lr</span><span class="o">=</span><span class="mf">0.00005</span><span class="p">,</span>
                        <span class="n">total_step</span><span class="o">=</span><span class="n">epoch_size</span> <span class="o">*</span> <span class="n">step_size</span><span class="p">,</span>
                        <span class="n">step_per_epoch</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span>
                        <span class="n">decay_epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># 定义优化器</span>
<span class="n">network_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="p">)</span>


<span class="c1"># 定义损失函数</span>
<span class="k">class</span> <span class="nc">CrossEntropySmooth</span><span class="p">(</span><span class="n">LossBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;交叉熵损失函数&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">smooth_factor</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CrossEntropySmooth</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">onehot</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">OneHot</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="o">=</span> <span class="n">sparse</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">smooth_factor</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">smooth_factor</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_classes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ce</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logit</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">onehot</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">logit</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ce</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>


<span class="n">network_loss</span> <span class="o">=</span> <span class="n">CrossEntropySmooth</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                  <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
                                  <span class="n">smooth_factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                                  <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>

<span class="c1"># 设置权重文件</span>
<span class="n">ckpt_config</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">ckpt_callback</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;vit_b_16&#39;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s1">&#39;./ViT&#39;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">ckpt_config</span><span class="p">)</span>

<span class="c1"># 初始化模型</span>
<span class="c1"># &quot;昇腾 + 混合精度&quot; 可以提高性能</span>
<span class="n">ascend_target</span> <span class="o">=</span> <span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">get_context</span><span class="p">(</span><span class="s2">&quot;device_target&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">ascend_target</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">network_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">network_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;acc&quot;</span><span class="p">},</span> <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O2&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">network_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">network_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;acc&quot;</span><span class="p">},</span> <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O0&quot;</span><span class="p">)</span>

<span class="c1"># 训练模型</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch_size</span><span class="p">,</span>
            <span class="n">dataset_train</span><span class="p">,</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ckpt_callback</span><span class="p">,</span> <span class="n">LossMonitor</span><span class="p">(</span><span class="mi">125</span><span class="p">),</span> <span class="n">TimeMonitor</span><span class="p">(</span><span class="mi">125</span><span class="p">)],</span>
            <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Downloading data from https://download.mindspore.cn/vision/classification/vit_b_16_224.ckpt (330.2 MB)

file_sizes: 100%|████████████████████████████| 346M/346M [00:06&lt;00:00, 53.1MB/s]
Successfully downloaded file to ./ckpt/vit_b_16_224.ckpt
epoch: 1 step: 125, loss is 2.0464668
Train epoch time: 87310.876 ms, per step time: 698.487 ms
epoch: 2 step: 125, loss is 2.1880982
Train epoch time: 13892.750 ms, per step time: 111.142 ms
epoch: 3 step: 125, loss is 1.4739448
Train epoch time: 15363.608 ms, per step time: 122.909 ms
epoch: 4 step: 125, loss is 1.3236868
Train epoch time: 15483.060 ms, per step time: 123.864 ms
epoch: 5 step: 125, loss is 1.2597866
Train epoch time: 15104.917 ms, per step time: 120.839 ms
epoch: 6 step: 125, loss is 1.2213771
Train epoch time: 14815.000 ms, per step time: 118.520 ms
epoch: 7 step: 125, loss is 1.5334704
Train epoch time: 14229.986 ms, per step time: 113.840 ms
epoch: 8 step: 125, loss is 1.3301002
Train epoch time: 14395.928 ms, per step time: 115.167 ms
epoch: 9 step: 125, loss is 1.2299211
Train epoch time: 13359.625 ms, per step time: 106.877 ms
epoch: 10 step: 125, loss is 1.1130466
Train epoch time: 13948.583 ms, per step time: 111.589 ms
</pre></div></div>
</div>
</section>
<section id="模型验证">
<h3>模型验证<a class="headerlink" href="#模型验证" title="Permalink to this headline"></a></h3>
<p>模型验证过程主要应用了Model，CrossEntropySmooth等接口。</p>
<p>Model主要用于编译模型。</p>
<p>CrossEntropySmooth是损失函数实例化接口。</p>
<p>与训练过程相似，首先定义网络结构，加载预训练模型参数。随后设置损失函数，评价指标等，编译模型后进行验证。本案例采用了业界通用的评价标准Top_1_Accuracy和Top_5_Accuracy评价指标来评价模型表现。</p>
<p>在本案例中，这两个指标代表了在输出的1000维向量中，以最大值或前5的输出值所代表的类别为预测结果时，模型预测的准确率。这两个指标的值越大，代表模型准确率越高。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_val</span> <span class="o">=</span> <span class="n">ImageFolderDataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">trans_val</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">224</span> <span class="o">+</span> <span class="mi">32</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
<span class="p">]</span>

<span class="n">dataset_val</span> <span class="o">=</span> <span class="n">dataset_val</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">trans_val</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
<span class="n">dataset_val</span> <span class="o">=</span> <span class="n">dataset_val</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># 构建模型</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">ViT</span><span class="p">()</span>

<span class="c1"># 加载权重文件</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">vit_path</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>

<span class="n">network_loss</span> <span class="o">=</span> <span class="n">CrossEntropySmooth</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                  <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
                                  <span class="n">smooth_factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                                  <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>

<span class="c1"># 定义评价标准</span>
<span class="n">eval_metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Top_1_Accuracy&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Top1CategoricalAccuracy</span><span class="p">(),</span>
                <span class="s1">&#39;Top_5_Accuracy&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Top5CategoricalAccuracy</span><span class="p">()}</span>

<span class="k">if</span> <span class="n">ascend_target</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">network_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">network_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">eval_metrics</span><span class="p">,</span> <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O2&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">network_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">network_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">eval_metrics</span><span class="p">,</span> <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O0&quot;</span><span class="p">)</span>

<span class="c1"># 评估模型</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;Top_1_Accuracy&#39;: 0.75, &#39;Top_5_Accuracy&#39;: 0.928}
</pre></div></div>
</div>
<p>从结果可以看出，由于我们加载了预训练模型参数，模型的Top_1_Accuracy和Top_5_Accuracy达到了很高的水平，实际项目中也可以以此准确率为标准。如果未使用预训练模型参数，则需要更多的epoch来训练。</p>
</section>
<section id="模型推理">
<h3>模型推理<a class="headerlink" href="#模型推理" title="Permalink to this headline"></a></h3>
<p>在进行模型推理之前，首先要定义一个对推理图片进行数据预处理的方法。该方法可以对我们的推理图片进行resize和normalize处理，这样才能与我们训练时的输入数据匹配。</p>
<p>本案例采用了一张Doberman的图片作为推理图片来测试模型表现，期望模型可以给出正确的预测结果。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_infer</span> <span class="o">=</span> <span class="n">ImageFolderDataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;infer&quot;</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">trans_infer</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">([</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">]),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
<span class="p">]</span>

<span class="n">dataset_infer</span> <span class="o">=</span> <span class="n">dataset_infer</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">trans_infer</span><span class="p">,</span>
                                  <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">],</span>
                                  <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dataset_infer</span> <span class="o">=</span> <span class="n">dataset_infer</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>接下来，我们将调用模型的predict方法进行模型推理。</p>
<p>在推理过程中通过index2label就可以获取对应标签，再通过show_result接口将结果写在对应图片上。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">io</span>


<span class="k">class</span> <span class="nc">Color</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;定义枚举类型的颜色&quot;&quot;&quot;</span>
    <span class="n">red</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
    <span class="n">green</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">blue</span> <span class="o">=</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">cyan</span> <span class="o">=</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">yellow</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
    <span class="n">magenta</span> <span class="o">=</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
    <span class="n">white</span> <span class="o">=</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
    <span class="n">black</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">check_file_exist</span><span class="p">(</span><span class="n">file_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;检查路径是否存在&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">file_name</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;File `</span><span class="si">{</span><span class="n">file_name</span><span class="si">}</span><span class="s2">` does not exist.&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">color_val</span><span class="p">(</span><span class="n">color</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;颜色变量&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">color</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Color</span><span class="p">[</span><span class="n">color</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">color</span><span class="p">,</span> <span class="n">Color</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">color</span><span class="o">.</span><span class="n">value</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">color</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">color</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
        <span class="k">for</span> <span class="n">channel</span> <span class="ow">in</span> <span class="n">color</span><span class="p">:</span>
            <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">channel</span> <span class="o">&lt;=</span> <span class="mi">255</span>
        <span class="k">return</span> <span class="n">color</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">color</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">color</span> <span class="o">&lt;=</span> <span class="mi">255</span>
        <span class="k">return</span> <span class="n">color</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">color</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">color</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">color</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">color</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">3</span>
        <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">color</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">color</span> <span class="o">&lt;=</span> <span class="mi">255</span><span class="p">))</span>
        <span class="n">color</span> <span class="o">=</span> <span class="n">color</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">color</span><span class="p">)</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Invalid type for color: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">color</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">imread</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;定义读方法&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">):</span>
        <span class="n">image</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">pass</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">check_file_exist</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mode</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">mode</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Image must be a `ndarray`, `str` or Path object.&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">image</span>


<span class="k">def</span> <span class="nf">imwrite</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">image_path</span><span class="p">,</span> <span class="n">auto_mkdir</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;定义写方法&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">auto_mkdir</span><span class="p">:</span>
        <span class="n">dir_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">image_path</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">dir_name</span> <span class="o">!=</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
            <span class="n">dir_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">dir_name</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">dir_name</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="mi">777</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">image</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">win_name</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">wait_time</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;定义展示图片的方法&quot;&quot;&quot;</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">win_name</span><span class="p">,</span> <span class="n">imread</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">wait_time</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># 防止在窗户关闭时挂起</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">closed</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">getWindowProperty</span><span class="p">(</span><span class="n">win_name</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">WND_PROP_VISIBLE</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span>
            <span class="c1"># 如果用户关闭了窗口或按下了某个键</span>
            <span class="k">if</span> <span class="n">closed</span> <span class="ow">or</span> <span class="n">ret</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="k">break</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="n">wait_time</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">show_result</span><span class="p">(</span><span class="n">img</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                <span class="n">result</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
                <span class="n">text_color</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span>
                <span class="n">font_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
                <span class="n">row_width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
                <span class="n">show</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                <span class="n">win_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="n">wait_time</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                <span class="n">out_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;在图片上标记预测结果&quot;&quot;&quot;</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">imread</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">row_width</span>
    <span class="n">text_color</span> <span class="o">=</span> <span class="n">color_val</span><span class="p">(</span><span class="n">text_color</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="n">v</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="n">label_text</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">label_text</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_COMPLEX</span><span class="p">,</span>
                    <span class="n">font_scale</span><span class="p">,</span> <span class="n">text_color</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">+=</span> <span class="n">row_width</span>
    <span class="k">if</span> <span class="n">out_file</span><span class="p">:</span>
        <span class="n">show</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">imwrite</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">out_file</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
        <span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">win_name</span><span class="p">,</span> <span class="n">wait_time</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">index2label</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ImageNet数据集的图像编号和类别的字典输出&quot;&quot;&quot;</span>
    <span class="n">metafile</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;ILSVRC2012_devkit_t12/data/meta.mat&quot;</span><span class="p">)</span>
    <span class="n">meta</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">loadmat</span><span class="p">(</span><span class="n">metafile</span><span class="p">,</span> <span class="n">squeeze_me</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s1">&#39;synsets&#39;</span><span class="p">]</span>

    <span class="n">nums_children</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">meta</span><span class="p">))[</span><span class="mi">4</span><span class="p">]</span>
    <span class="n">meta</span> <span class="o">=</span> <span class="p">[</span><span class="n">meta</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">num_children</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nums_children</span><span class="p">)</span> <span class="k">if</span> <span class="n">num_children</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">wnids</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">meta</span><span class="p">))[:</span><span class="mi">3</span><span class="p">]</span>
    <span class="n">clssname</span> <span class="o">=</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">clss</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;, &#39;</span><span class="p">))</span> <span class="k">for</span> <span class="n">clss</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">]</span>
    <span class="n">wnid2class</span> <span class="o">=</span> <span class="p">{</span><span class="n">wnid</span><span class="p">:</span> <span class="n">clss</span> <span class="k">for</span> <span class="n">wnid</span><span class="p">,</span> <span class="n">clss</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">wnids</span><span class="p">,</span> <span class="n">clssname</span><span class="p">)}</span>
    <span class="n">wind2class_name</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">wnid2class</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">mapping</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">class_name</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wind2class_name</span><span class="p">):</span>
        <span class="n">mapping</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_name</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">mapping</span>


<span class="c1"># 推理阶段读数据</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">image</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset_infer</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">)):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">prob</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">mapping</span> <span class="o">=</span> <span class="n">index2label</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="p">{</span><span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="p">):</span> <span class="n">mapping</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="p">)]}</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    <span class="n">show_result</span><span class="p">(</span><span class="n">img</span><span class="o">=</span><span class="s2">&quot;./dataset/infer/n01440764/ILSVRC2012_test_00000279.JPEG&quot;</span><span class="p">,</span>
                <span class="n">result</span><span class="o">=</span><span class="n">output</span><span class="p">,</span>
                <span class="n">out_file</span><span class="o">=</span><span class="s2">&quot;./dataset/infer/ILSVRC2012_test_00000279.JPEG&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{236: &#39;Doberman&#39;}
</pre></div></div>
</div>
<p>推理过程完成后，在推理文件夹下可以找到图片的推理结果，可以看出预测结果是Doberman，与期望结果相同，验证了模型的准确性。</p>
<p><img alt="infer-result" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/tutorials/application/source_zh_cn/cv/images/infer_result.jpg" /></p>
</section>
</section>
<section id="总结">
<h2>总结<a class="headerlink" href="#总结" title="Permalink to this headline"></a></h2>
<p>本案例完成了一个ViT模型在ImageNet数据上进行训练，验证和推理的过程，其中，对关键的ViT模型结构和原理作了讲解。通过学习本案例，理解源码可以帮助用户掌握Multi-Head Attention，TransformerEncoder，pos_embedding等关键概念，如果要详细理解ViT的模型原理，建议基于源码更深层次的详细阅读。</p>
</section>
<section id="引用">
<h2>引用<a class="headerlink" href="#引用" title="Permalink to this headline"></a></h2>
<p>[1] Dosovitskiy, Alexey, et al. “An image is worth 16x16 words: Transformers for image recognition at scale.” arXiv preprint arXiv:2010.11929 (2020).</p>
<p>[2] Vaswani, Ashish, et al. “Attention is all you need.”Advances in Neural Information Processing Systems. (2017).</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="dcgan.html" class="btn btn-neutral float-left" title="DCGAN生成漫画头像" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../nlp/sentiment_analysis.html" class="btn btn-neutral float-right" title="RNN实现情感分类" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>