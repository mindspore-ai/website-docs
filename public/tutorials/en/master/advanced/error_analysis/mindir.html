<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>IR File Analysis &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script><script src="../../_static/jquery.js"></script>
        <script src="../../_static/js/theme.js"></script><script src="../../_static/underscore.js"></script><script src="../../_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="CANN Common Error Analysis" href="cann_error_cases.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introduction.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/dataset.html">Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/transforms.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/model.html">Building a Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/autograd.html">Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/train.html">Model Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/save_load.html">Saving and Loading the Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/accelerate_with_static_graph.html">Accelerating with Static Graphs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../model.html">Advanced Encapsulation: Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">Model Module Customization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset.html">Advanced Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../derivation.html">Advanced Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../static_graph_expert_programming.html">Advanced Programming Techniques for Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mixed_precision.html">Automatic Mix Precision</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../error_analysis.html">Error Reporting Analysis</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="error_scenario_analysis.html">Error Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="minddata_debug.html">Data Processing Debugging Methods and Common Errors Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindrt_debug.html">Network Construction and Training Error Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="cann_error_cases.html">CANN Common Error Analysis</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">IR File Analysis</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../error_analysis.html">Error Reporting Analysis</a> &raquo;</li>
      <li>IR File Analysis</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/advanced/error_analysis/mindir.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section class="tex2jax_ignore mathjax_ignore" id="ir-file-analysis">
<h1>IR File Analysis<a class="headerlink" href="#ir-file-analysis" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/tutorials/source_en/advanced/error_analysis/mindir.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.svg" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>When a model compiled using MindSpore runs in the graph mode <code class="docutils literal notranslate"><span class="pre">set_context(mode=GRAPH_MODE)</span></code> and <code class="docutils literal notranslate"><span class="pre">set_context(save_graphs=2)</span></code> is set in the configuration, some intermediate files will be generated during graph compliation. These intermediate files are called IR files. Currently, there are two IR files:</p>
<ul class="simple">
<li><p>.ir file: An IR file that describes the model structure in text format and can be directly viewed using any text editors.</p></li>
<li><p>.dot file: When <code class="docutils literal notranslate"><span class="pre">set_context(save_graphs=3)</span></code> is set in the configuration, an IR file that describes the topology relationships between different nodes. You can use this file by <a class="reference external" href="http://graphviz.org/">graphviz</a> as the input to generate images for users to view the model structure. For models with multiple operators, it is recommended using the visualization component <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/dashboard.html#computational-graph-visualization">MindSpore Insight</a> to visualize computing graphs.</p></li>
</ul>
</section>
<section id="saving-ir">
<h2>Saving IR<a class="headerlink" href="#saving-ir" title="Permalink to this headline"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">set_context(save_graphs=2)</span></code> is used to save the intermediate code in each compilation phase. The intermediate code can be saved in two formats, and the .ir file with the extension ‘.ir’ is saved by default. If <code class="docutils literal notranslate"><span class="pre">set_context(save_graphs=3)</span></code> is set, a graphical .ir file with the extension <code class="docutils literal notranslate"><span class="pre">.dot</span></code> is printed. When the network scale is small, you are advised to use the graphical format that is more intuitive. When the network scale is large, you are advised to use the text format that is more efficient.</p>
<p>You can run the graphviz command to convert a .dot file to the picture format. For example, you can run the <code class="docutils literal notranslate"><span class="pre">dot</span> <span class="pre">-Tpng</span> <span class="pre">*.dot</span> <span class="pre">-o</span> <span class="pre">*.png</span></code> command to convert a <code class="docutils literal notranslate"><span class="pre">.dot</span></code> file to a .png file.</p>
<p>In the training script <code class="docutils literal notranslate"><span class="pre">train.py</span></code>, we add the following code to the <code class="docutils literal notranslate"><span class="pre">set_context</span></code> function, when running the training script, MindSpore will automatically store the IR file generated during compilation to the specified path.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">set_context</span><span class="p">(</span><span class="n">save_graphs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">save_graphs_path</span><span class="o">=</span><span class="s2">&quot;path/to/ir/files&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>After the training command is executed, several files were generated under the specified path.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>.
├──00_parse_0000.ir
├──00_parse_0001.dot
├──01_symbol_resolve_0002.ir
├──01_symbol_resolve_0003.dot
├──02_combine_like_graphs_0004.ir
├──02_combine_like_graphs_0005.dot
├──03_inference_opt_prepare_0006.ir
├──03_inference_opt_prepare_0007.dot
├──04_abstract_specialize_0008.ir
├──04_abstract_specialize_0009.dot
...
</pre></div>
</div>
<p>The IR files starting with digits and underscores are generated during the ME graph compilation. The compute graph is saved in each phase of the <code class="docutils literal notranslate"><span class="pre">pipeline</span></code>. Let’s see the important phases.</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">parse</span></code> phase parses the entrance function and this phase generates MindIR initially. If viewing the IR file, we can see that only the graph information of the top Cell is parsed in this phase.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">symbol_resolve</span></code> phase recursively parses entrance function, mainly recursive resolution entry functions directly or indirectly reference to other functions and objects. When using the unsupported syntax, it will get an error in this phase.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">abstract_specialize</span></code> phase means that the data type and shape information for all nodes in the IR is deduced from the input information. When you want to know the shape or data type of a specific operator in IR, you can view this IR file.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">optimize</span></code> phase refers hardware-independent optimization is performed. The automatic differential and automatic parallel functions are also performed. This stage can be subdivided into several substages. In the list of IR files, where the files prefixed with <code class="docutils literal notranslate"><span class="pre">opt_pass_</span> <span class="pre">[ordinal]</span></code> are IR files saved after the end of these sub-stages, non-framework developers do not need to pay too much attention.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">validate</span></code> phase will verify the compiled compute graph and check the temporary operators which should be removed in the prior phase. If any temporary operator exists, the process will report an error and exit.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">task_emit</span></code> phase will transfer the compute graph to the backend for further processing.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">execute</span></code> phase will execute the compute graph. The IR graph in this stage is the final graph in the phase of frontend.</p></li>
</ul>
<p>In addition, because the backend is closer to the bottom layer, non-framework developers do not need to pay much attention to other IR files saved during the backend optimization process (such as files that begin with <code class="docutils literal notranslate"><span class="pre">hwopt</span></code>). Non-framework developers only need to look at the file named <code class="docutils literal notranslate"><span class="pre">graph_build_[Graph</span> <span class="pre">Sequence</span> <span class="pre">Number]_[IR</span> <span class="pre">File</span> <span class="pre">Sequence</span> <span class="pre">Number].ir</span></code>, i.e. IR after all front and back end optimizations.</p>
<blockquote>
<div><p>Multiple files may be saved because the backend is optimized on subgraphs, which is different from the mechanism by which multiple subgraphs on the front end are saved in the same file.</p>
</div></blockquote>
</section>
<section id="ir-file-contents-introduction">
<h2>IR File Contents Introduction<a class="headerlink" href="#ir-file-contents-introduction" title="Permalink to this headline"></a></h2>
<p>The following is an example to describe the contents of the IR file. Run the script:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">save_graphs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">save_graphs_path</span><span class="o">=</span><span class="s2">&quot;./ir&quot;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">b</span> <span class="p">:</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">b</span>

<span class="n">input1</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">input2</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<section id="ir-introduction">
<h3>ir Introduction<a class="headerlink" href="#ir-introduction" title="Permalink to this headline"></a></h3>
<p>Use a text editing software (for example, <code class="docutils literal notranslate"><span class="pre">vi</span></code>) to open the <code class="docutils literal notranslate"><span class="pre">17_execute_0765.ir</span></code> file output after execution. The file contents are as follows (Here is MindSpore 2.1, and the content may have some imperceptible changes with the version upgrade):</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  1 # IR entry: @20_1___main___Net_construct.295
  2 # Total subgraphs: 3
  3
  4 # Attrs:
  5 check_set_strategy_valid_once_only : 1
  6 auto_parallel_finish_pre_action : 1
  7
  8 # Total params: 2
  9 # Params:
 10 %para1_x : &lt;Tensor[Float32], ()&gt;
 11 %para2_y : &lt;Tensor[Float32], ()&gt;
 12
 13 subgraph attr:
 14 check_set_strategy_valid_once_only : 1
 15 auto_parallel_finish_pre_action : 1
 16 subgraph instance: 20_1___main___Net_construct.295 : 0x55da18f612a0
 17 # In file t6.py:15/    def construct(self, x, y):/
 18 subgraph @20_1___main___Net_construct.295() {
 19   %0(a) = Sub(%para1_x, Tensor(shape=[], dtype=Float32, value=1)) primitive_attrs: {output_names: [output], input_names: [x, y]}
 20       : (&lt;Tensor[Float32], ()&gt;, &lt;Tensor[Float32], (), value=...&gt;) -&gt; (&lt;Tensor[Float32], ()&gt;)
 21       # Scope: (Default)
 22       # In file /workspace/mindspore/build/package/mindspore/ops/function/math_func.py:839/    return tensor_sub(input, other)/
 23   %1(b) = Add(%0, %para2_y) primitive_attrs: {output_names: [output], input_names: [x, y]}
 24       : (&lt;Tensor[Float32], ()&gt;, &lt;Tensor[Float32], ()&gt;) -&gt; (&lt;Tensor[Float32], ()&gt;)
 25       # Scope: (Default)
 26       # In file /workspace/mindspore/build/package/mindspore/ops/function/math_func.py:316/    return _get_cache_prim(P.Add)()(input, other)/
 27   %2([CNode]273) = Cast(%1, Bool) primitive_attrs: {output_names: [output], input_names: [x, dst_type], SrcT: F32, DstT: Bool}
 28       : (&lt;Tensor[Float32], ()&gt;, &lt;TypeType, NoShape&gt;) -&gt; (&lt;Tensor[Bool], ()&gt;)
 29       # Scope: (Default)
 30       # In file /workspace/mindspore/build/package/mindspore/_extends/parse/standard_method.py:3359/    return F.cast(x, mstype.bool_)/
 31   %3([CNode]298) = Partial(@21_3_✓__main___Net_construct.296, %1, %0) primitive_attrs: {side_effect_propagate: I64(1)}
 32       : (&lt;Func, NoShape&gt;, &lt;Tensor[Float32], ()&gt;, &lt;Tensor[Float32], ()&gt;) -&gt; (&lt;Func, NoShape&gt;)
 33       # Scope: (Default)
 34   %4([CNode]299) = Partial(@22_15_✗__main___Net_construct.297, %1) primitive_attrs: {side_effect_propagate: I64(1)}
 35       : (&lt;Func, NoShape&gt;, &lt;Tensor[Float32], ()&gt;) -&gt; (&lt;Func, NoShape&gt;)
 36       # Scope: (Default)
 37   %5([CNode]9) = Switch(%2, %3, %4)
 38       : (&lt;Tensor[Bool], ()&gt;, &lt;Func, NoShape&gt;, &lt;Func, NoShape&gt;) -&gt; (&lt;Func, NoShape&gt;)
 39       # Scope: (Default)
 40       # In file t6.py:18/        if b :/
 41   %6([CNode]12) = %5[@FuncUnion(@21_3_✓__main___Net_construct.296, @22_15_✗__main___Net_construct.297)]()
 42       : () -&gt; (&lt;Tensor[Float32], ()&gt;)
 43       # Scope: (Default)
 44       # In file t6.py:18/        if b :/
 45   Return(%6)
 46       : (&lt;Tensor[Float32], ()&gt;)
 47       # Scope: (Default)
 48       # In file t6.py:18/        if b :/
 49 }
 50
 51
 52 switch_input: 1
 53 subgraph attr:
 54 defer_inline : 0
 55 undeterminate : 0
 56 subgraph instance: 21_3_✓__main___Net_construct.296 : 0x55da18f59e20
 57 # In file t6.py:18/        if b :/
 58 subgraph @21_3_✓__main___Net_construct.296(%para3_b, %para4_a) {
 59   %0([CNode]8) = Div(%para4_a, %para3_b) primitive_attrs: {output_names: [output], input_names: [x, y]}
 60       : (&lt;Tensor[Float32], ()&gt;, &lt;Tensor[Float32], ()&gt;) -&gt; (&lt;Tensor[Float32], ()&gt;)
 61       # Scope: (Default)
 62       # In file /workspace/mindspore/build/package/mindspore/ops/function/math_func.py:998/    output = _get_cache_prim(P.Div)()(input, other)/
 63   %1(b) = Mul(%para3_b, %0) primitive_attrs: {output_names: [output], input_names: [x, y]}
 64       : (&lt;Tensor[Float32], ()&gt;, &lt;Tensor[Float32], ()&gt;) -&gt; (&lt;Tensor[Float32], ()&gt;)
 65       # Scope: (Default)
 66       # In file /workspace/mindspore/build/package/mindspore/ops/function/math_func.py:929/    return tensor_mul(input, other)/
 67   Return(%1)
 68       : (&lt;Tensor[Float32], ()&gt;)
 69       # Scope: (Default)
 70       # In file t6.py:19/            b = ops.mul(b, self.func(a, b))/
 71 }
 72
 73
 74 switch_input: 1
 75 subgraph attr:
 76 defer_inline : 0
 77 undeterminate : 0
 78 subgraph instance: 22_15_✗__main___Net_construct.297 : 0x55da18f62280
 79 # In file t6.py:18/        if b :/
 80 subgraph @22_15_✗__main___Net_construct.297(%para5_b) {
 81   Return(%para5_b)
 82       : (&lt;Tensor[Float32], ()&gt;)
 83       # Scope: (Default)
 84       # In file t6.py:18/        if b :/
 85 }
</pre></div>
</div>
<p>The above contents can be divided into two parts. The first part is the input list and the second part is the graph structure:</p>
<ul class="simple">
<li><p>Line 1 tells us <code class="docutils literal notranslate"><span class="pre">&#64;20_1___main___Net_construct.295</span></code>, the name of the top MindSpore graph about the network, which is the entry graph.</p></li>
<li><p>Line 2 tells us the number of subgraph parsed by the network. There are 3 graphs in this IR. Line 13 is the entry graph <code class="docutils literal notranslate"><span class="pre">20_1___main___Net_construct.295</span></code>. Line 52 is graph <code class="docutils literal notranslate"><span class="pre">21_3_✓__main___Net_construct.296</span></code>, parsed from the block when the condition of the if statement in the network is true. Line 74 is graph <code class="docutils literal notranslate"><span class="pre">22_15_✗__main___Net_construct.297</span></code>, parsed from the block when the condition of the if statement in the network is false.</p></li>
<li><p>Line 6 tells us how many inputs are in the network.</p></li>
<li><p>Line 10 to 11 are the input list, which is in the format of <code class="docutils literal notranslate"><span class="pre">%para[No.]_[name]</span> <span class="pre">:</span> <span class="pre">&lt;[data_type],</span> <span class="pre">(shape)&gt;</span></code>.</p></li>
</ul>
<p>Taking graph <code class="docutils literal notranslate"><span class="pre">&#64;20_1___main___Net_construct.295</span></code> as an example:</p>
<ul class="simple">
<li><p>Line 13 to 49 indicate the graph structure, which contains several nodes, namely, <code class="docutils literal notranslate"><span class="pre">CNode</span></code>. In this example, there are <code class="docutils literal notranslate"><span class="pre">Sub</span></code>, <code class="docutils literal notranslate"><span class="pre">Add</span></code>, <code class="docutils literal notranslate"><span class="pre">Mul</span></code> defined in the function <code class="docutils literal notranslate"><span class="pre">__init__</span></code>.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">CNode</span></code> (<a class="reference external" href="https://www.mindspore.cn/docs/en/master/design/all_scenarios.html#syntax">check the design of ANF-IR</a>) information format is as follows: from left to right, the ordinal number, node name - debug_name, operator name - op_name, input node - arg, attributes of the node - primitive_attrs, input and output specifications, source code parsing call stack and other information. Because the ANF graph is a unidirectional acyclic graph, the connection between nodes is displayed only based on the input relationship. The corresponding source code reflects the relationship between the <code class="docutils literal notranslate"><span class="pre">CNode</span></code> and the script source code. For example, line 44 is parsed from <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">b</span></code>.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>%[No.]([debug_name]) = [op_name]([arg], ...) primitive_attrs: {[key]: [value], ...}
    : (&lt;[input data_type]x[input shape]&gt;, ...) -&gt; (&lt;[output data_type]x[output shape]&gt;, ...)
    # Corresponding source code
</pre></div>
</div>
<p>About the corresponding source code:</p>
<ul class="simple">
<li><p>There are two mode for the corresponding source code displaying. The first mode is to display the complete call stack, such as <code class="docutils literal notranslate"><span class="pre">15_execute_0141.ir</span></code> on the frontend and <code class="docutils literal notranslate"><span class="pre">graph_build_0_136.ir</span></code> on the backend. The second mode only displays one code line for reducing the size of the IR file, which eliminates the call stack, such as <code class="docutils literal notranslate"><span class="pre">04_abstract_specialize_0012.ir</span></code>.</p></li>
<li><p>If the operator is a back propagation operator, the associated code line will not only display its own code, but also the corresponding forward code, identified by “Corresponding forward node candidate:”.</p></li>
<li><p>If the operator is a fusion operator, the associated code line will display the fusion related code, identified by “Corresponding code candidate:”, where the separator “-” is used to distinguish different codes.</p></li>
</ul>
<blockquote>
<div><ul class="simple">
<li><p>After several optimizations by the compiler, the node may undergo several changes (such as operator splitting and operator merging). The source code parsing call stack information of the node may not be in a one-to-one correspondence with the script. This is only an auxiliary method.</p></li>
<li><p>After the <code class="docutils literal notranslate"><span class="pre">kernel</span> <span class="pre">select</span></code> phase at the backend, two lines of input and output specification information (that is, the content after <code class="docutils literal notranslate"><span class="pre">:</span></code>) will appear. The first line represents the specifications on the <code class="docutils literal notranslate"><span class="pre">HOST</span></code> side, and the second line represents the specifications on the <code class="docutils literal notranslate"><span class="pre">DEVICE</span></code> side.</p></li>
</ul>
</div></blockquote>
</section>
<section id="dot-introduction">
<h3>dot Introduction<a class="headerlink" href="#dot-introduction" title="Permalink to this headline"></a></h3>
<p>We can use this file by <a class="reference external" href="http://graphviz.org/">graphviz</a> as the input to generate images for users to view the model structure. For example, under the Linux operating system, we can convert a PNG image by the following command.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>dot<span class="w"> </span>-Tpng<span class="w"> </span>-o<span class="w"> </span>04_abstract_specialize_0014.png<span class="w"> </span>04_abstract_specialize_0014.dot
</pre></div>
</div>
<p>The transformed image is shown below, and we can visually see the model structure. The different black boxes distinguish different subgraphs, and the blue arrows between graphs represent calling another graph. The blue area represents the parameter, the rectangle represents the parameter list of the graph, the hexagon and the black arrow represent the parameter as the input of the CNode to participate in the calculation process. The yellow rectangle represents the CNode. As can be seen from the picture, the CNode input starts from index 0, and the 0th input (that is, the purple or green area) represents what calculation the operator will perform, which is connected by a dotted arrow. The type is usually an operator primitive, or it can also be another graph. The rest inputs are the parameters required for the calculation.</p>
<p><img alt="04_abstract_specialize_0014.png" src="../../_images/dot_to_png.png" /></p>
<p>For models with multiple operators, the picture will be very large. It is recommended by using the visualization component <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/dashboard.html#computational-graph-visualization">MindSpore Insight</a> to visualize compute graphs.</p>
</section>
</section>
<section id="how-to-derive-the-cause-of-the-failure-based-on-the-analyze-fail-ir-file-analysis-graph">
<h2>How to derive the cause of the failure based on the analyze_fail.ir file analysis graph<a class="headerlink" href="#how-to-derive-the-cause-of-the-failure-based-on-the-analyze-fail-ir-file-analysis-graph" title="Permalink to this headline"></a></h2>
<p>In the process of MindSpore compiling a graph, the exceptions about graph evaluating fail usually happen. But we can find the reason by analyzing the exception information and analyze_fail.ir.</p>
<section id="example-1-parameters-number-mismatch">
<h3>Example 1: parameters number mismatch<a class="headerlink" href="#example-1-parameters-number-mismatch" title="Permalink to this headline"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>  <span class="mi">1</span> <span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
  <span class="mi">2</span> <span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
  <span class="mi">3</span> <span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
  <span class="mi">4</span>
  <span class="mi">5</span> <span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
  <span class="mi">6</span> <span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">save_graphs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">save_graphs_path</span><span class="o">=</span><span class="s2">&quot;./ir&quot;</span><span class="p">)</span>
  <span class="mi">7</span>
  <span class="mi">8</span> <span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
  <span class="mi">9</span>     <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
 <span class="mi">10</span>         <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
 <span class="mi">11</span>
 <span class="mi">12</span>     <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
 <span class="mi">13</span>         <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
 <span class="mi">14</span>
 <span class="mi">15</span>     <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
 <span class="mi">16</span>         <span class="n">a</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
 <span class="mi">17</span>         <span class="n">b</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
 <span class="mi">18</span>         <span class="n">c</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
 <span class="mi">19</span>
 <span class="mi">20</span> <span class="n">input1</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
 <span class="mi">21</span> <span class="n">input2</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
 <span class="mi">22</span> <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
 <span class="mi">23</span> <span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
 <span class="mi">24</span> <span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<p>An error happens.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  1 Traceback (most recent call last):
  2   File &quot;t2.py&quot;, line 23, in &lt;module&gt;
  3     out = net(input1, input2)
  4   File &quot;/workspace/mindspore/build/package/mindspore/nn/cell.py&quot;, line 640, in __call__
  5     out = self.compile_and_run(*args, **kwargs)
  6   File &quot;/workspace/mindspore/build/package/mindspore/nn/cell.py&quot;, line 964, in compile_and_run
  7     self.compile(*args, **kwargs)
  8   File &quot;/workspace/mindspore/build/package/mindspore/nn/cell.py&quot;, line 942, in compile
  9     jit_config_dict=self._jit_config_dict, *compile_args, **kwargs)
 10   File &quot;/workspace/mindspore/build/package/mindspore/common/api.py&quot;, line 1639, in compile
 11     result = self._graph_executor.compile(obj, args, kwargs, phase, self._use_vm_mode())
 12 TypeError: The parameters number of the function is 2, but the number of provided arguments is 3.
 13 FunctionGraph ID : func.21
 14 NodeInfo: In file t2.py:12
 15     def func(x, y):
 16
 17 ----------------------------------------------------
 18 - The Traceback of Net Construct Code:
 19 ----------------------------------------------------
 20 The function call stack (See file &#39;/workspace/mindspore/rank_0/om/analyze_fail.ir&#39; for more details. Get instructions about `analyze_fail.ir` at https://www.mindspore.cn/search?inputValue=analyze_fail.ir):
 21 # 0 In file t2.py:18
 22         c = ops.mul(b, self.func(a, a, b))
 23                        ^
 24
 25 ----------------------------------------------------
 26 - C++ Call Stack: (For framework developers)
 27 ----------------------------------------------------
 28 mindspore/ccsrc/pipeline/jit/static_analysis/stack_frame.cc:102 DoJump
</pre></div>
</div>
<p>Above exception is “TypeError: The parameters number of the function is 2, but the number of provided arguments is 3…”.
And it tells us <code class="docutils literal notranslate"><span class="pre">FunctionGraph</span> <span class="pre">ID</span> <span class="pre">:</span> <span class="pre">func.18</span></code> only needs two parameters, but actually gives 3.
We can find the related code is <code class="docutils literal notranslate"><span class="pre">self.func(a,</span> <span class="pre">a,</span> <span class="pre">b)</span></code> from ‘The function call stack … In file t2.py:18’.
Easily, by checking the code, we know that we gave too much parameter to the calling function.</p>
<p>Sometimes when the exception information is not enough easy to understand, or we want to see the part of graph information that have evaluated, we use text editing software (e.g., vi) to open the file (in parentheses on line 20) that prompts in the error message: <code class="docutils literal notranslate"><span class="pre">/home/workspace/mindspore/rank_0/om/analyze_fail.ir</span></code> with the following content (Here is MindSpore 2.1, and the content may have some imperceptible changes with the version upgrade):</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  1 # 1.This file shows the parsed IR info when graph evaluating failed to help find the problem.
  2 # 2.You can search the last `------------------------&gt;` to the node which is inferred failed.
  3 # 3.Refer to https://www.mindspore.cn/search?inputValue=analyze_fail.ir to get more instructions.
  4 # ===============================================================================
  5
  6 subgraph attr:
  7 subgraph instance: __main___Net_construct.1 : 0x5592157f3640
  8 # In file t2.py:15/    def construct(self, x, y):/
  9 subgraph @__main___Net_construct.1(%para1_x, %para2_y) {
 10   %1(a) = call @sub.19(%para1_x, I64(1))
 11       : (&lt;Tensor[Float32], ()&gt;, &lt;Int64, NoShape&gt;) -&gt; (&lt;Tensor[Float32], ()&gt;)
 12       #scope: (Default)
 13       # In file t2.py:16/        a = ops.sub(x, 1)/
 14   %2(b) = call @add.20(%1, %para2_y)
 15       : (&lt;Tensor[Float32], ()&gt;, &lt;Tensor[Float32], ()&gt;) -&gt; (&lt;Tensor[Float32], ()&gt;)
 16       #scope: (Default)
 17       # In file t2.py:17/        b = ops.add(a, y)/
 18
 19 #------------------------&gt; 0
 20   %3([CNode]7) = call @func.21(%1, %1, %2)
 21       : (&lt;Tensor[Float32], ()&gt;, &lt;Tensor[Float32], ()&gt;, &lt;Tensor[Float32], ()&gt;) -&gt; (&lt;null&gt;)
 22       #scope: (Default)
 23       # In file t2.py:18/        c = ops.mul(b, self.func(a, a, b))/
 24   %4(c) = call @mul.22(%2, %3)
 25       : (&lt;Tensor[Float32], ()&gt;, &lt;null&gt;) -&gt; (&lt;null&gt;)
 26       #scope: (Default)
 27       # In file t2.py:18/        c = ops.mul(b, self.func(a, a, b))/
 28   %5([CNode]8) = StopGradient(%4)
 29       : (&lt;null&gt;) -&gt; (&lt;null&gt;)
 30       #scope: (Default)
 31   %6([CNode]9) = Depend[side_effect_propagate: I64(1)](None, %5)
 32       : (&lt;null&gt;, &lt;null&gt;) -&gt; (&lt;null&gt;)
 33       #scope: (Default)
 34       # In file t2.py:15/    def construct(self, x, y):/
 35   Return(%6)
 36       : (&lt;null&gt;)
 37       #scope: (Default)
 38       # In file t2.py:15/    def construct(self, x, y):/
 39 }
 40 # Order:
 41 #   1: @__main___Net_construct.1:a{[0]: ValueNode&lt;FuncGraph&gt; sub.19, [1]: x, [2]: ValueNode&lt;Int64Imm&gt; 1}
 42 #   2: @__main___Net_construct.1:b{[0]: ValueNode&lt;FuncGraph&gt; add.20, [1]: a, [2]: y}
 43 #   3: @__main___Net_construct.1:[CNode]7{[0]: ValueNode&lt;FuncGraph&gt; func.21, [1]: a, [2]: a, [3]: b}
 44 #   4: @__main___Net_construct.1:c{[0]: ValueNode&lt;FuncGraph&gt; mul.22, [1]: b, [2]: [CNode]7}
 45 #   5: @__main___Net_construct.1:[CNode]18{[0]: ValueNode&lt;Primitive&gt; Return, [1]: [CNode]9}
 46
 47
 48 #===============================================================================
 49 # num of function graphs in stack: 1
</pre></div>
</div>
<p>The file <code class="docutils literal notranslate"><span class="pre">analyze_fail.ir</span></code> has the same information format with ir file. The only difference is <code class="docutils literal notranslate"><span class="pre">analyze_fail.ir</span></code> will locate the node which inferring failed.
Searching the point by the text of <code class="docutils literal notranslate"><span class="pre">------------------------&gt;</span></code>, we reach <code class="docutils literal notranslate"><span class="pre">------------------------&gt;</span> <span class="pre">0</span></code> at line 19. This points to the node that derives the error, which is <code class="docutils literal notranslate"><span class="pre">%3([CNode]5)</span> <span class="pre">=</span> <span class="pre">call</span> <span class="pre">&#64;func.21(%1,</span> <span class="pre">%1,</span> <span class="pre">%2)</span> <span class="pre">....</span></code>.
The node at line 45 to 48 have an error. Its IR expression is <code class="docutils literal notranslate"><span class="pre">%3([CNode]5)</span> <span class="pre">=</span> <span class="pre">call</span> <span class="pre">&#64;func.20(%1,</span> <span class="pre">%1,</span> <span class="pre">%2)</span> <span class="pre">...</span></code>. We can know the node have 3 parameters from <code class="docutils literal notranslate"><span class="pre">(%1,</span> <span class="pre">%1,</span> <span class="pre">%2)</span></code>. From the source parsing call stack, it can be known that the function is actually <code class="docutils literal notranslate"><span class="pre">self.func</span></code>, which is defined in the script as <code class="docutils literal notranslate"><span class="pre">def</span> <span class="pre">dunc(x,</span> <span class="pre">y):...</span></code>.
In the function definition, only two parameters are needed, so there will be a deduction failure error, and we need to modify the number of parameters passed in the script to solve the problem.</p>
</section>
<section id="example-2-biasadd-inputs-shape-mismatch">
<h3>Example 2: BiasAdd inputs shape mismatch<a class="headerlink" href="#example-2-biasadd-inputs-shape-mismatch" title="Permalink to this headline"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>  <span class="mi">1</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
  <span class="mi">2</span> <span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
  <span class="mi">3</span> <span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">ops</span><span class="p">,</span> <span class="n">set_context</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Parameter</span>
  <span class="mi">4</span> <span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">initializer</span>
  <span class="mi">5</span>
  <span class="mi">6</span> <span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
  <span class="mi">7</span>
  <span class="mi">8</span> <span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
  <span class="mi">9</span>     <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
 <span class="mi">10</span>         <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
 <span class="mi">11</span>         <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">8</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;weight&quot;</span><span class="p">)</span>
 <span class="mi">12</span>         <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;bias&quot;</span><span class="p">)</span>
 <span class="mi">13</span>
 <span class="mi">14</span>     <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">):</span>
 <span class="mi">15</span>         <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
 <span class="mi">16</span>         <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
 <span class="mi">17</span>         <span class="k">return</span> <span class="n">x</span>
 <span class="mi">18</span>
 <span class="mi">19</span> <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
 <span class="mi">20</span> <span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
 <span class="mi">21</span> <span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
 <span class="mi">22</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;out&#39;</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>An error happens.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  1 Traceback (most recent call last):
  2   File &quot;t2.py&quot;, line 21, in &lt;module&gt;
  3     out = net(x)
  4   File &quot;/workspace/mindspore/build/package/mindspore/nn/cell.py&quot;, line 640, in __call__
  5     out = self.compile_and_run(*args, **kwargs)
  6   File &quot;/workspace/mindspore/build/package/mindspore/nn/cell.py&quot;, line 964, in compile_and_run
  7     self.compile(*args, **kwargs)
  8   File &quot;/workspace/mindspore/build/package/mindspore/nn/cell.py&quot;, line 942, in compile
  9     jit_config_dict=self._jit_config_dict, *compile_args, **kwargs)
 10   File &quot;/workspace/mindspore/build/package/mindspore/common/api.py&quot;, line 1639, in compile
 11     result = self._graph_executor.compile(obj, args, kwargs, phase, self._use_vm_mode())
 12 ValueError: For &#39;BiasAdd&#39;, bias[0] shape should be equal to input_x[1] shape when data_format is NCHW.
 13
 14 ----------------------------------------------------
 15 - The Traceback of Net Construct Code:
 16 ----------------------------------------------------
 17 The function call stack (See file &#39;/workspace/mindspore/rank_0/om/analyze_fail.ir&#39; for more details. Get instructions about `analyze_fail.ir` at https://www.mindspore.cn/search?inputValue=analyze_fail.ir):
 18 # 0 In file t2.py:16
 19         x = ops.bias_add(x, self.bias)
 20             ^
 21 # 1 In file /workspace/mindspore/build/package/mindspore/ops/function/nn_func.py:5498
 22     return bias_add_op(input_x, bias)
 23            ^
 24
 25 ----------------------------------------------------
 26 - C++ Call Stack: (For framework developers)
 27 ----------------------------------------------------
 28 mindspore/core/ops/bias_add.cc:88 BiasAddInferShape
</pre></div>
</div>
<p>The above reports that the errors is caused by the mismatching of the shape of the first input and the second input of the operator <code class="docutils literal notranslate"><span class="pre">BiasAdd</span></code>. To further understand what changes have taken place in the shape of the operator, we use text editing software (e.g., vi) to open the file that prompts in the error message: <code class="docutils literal notranslate"><span class="pre">/home/workspace/mindspore/rank_0/om/analyze_fail.ir</span></code> with the following content (Here is MindSpore 2.1, and the content may have some imperceptible changes with the version upgrade):</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  1 # 1.This file shows the parsed IR info when graph evaluating failed to help find the problem.
  2 # 2.You can search the last `------------------------&gt;` to the node which is inferred failed.
  3 # 3.Refer to https://www.mindspore.cn/search?inputValue=analyze_fail.ir to get more instructions.
  4 # ===============================================================================
  5
  6 subgraph attr:
  7 subgraph instance: __main___Net_construct.1 : 0x5629496604e0
  8 # In file t2.py:14/    def construct(self, x1):/
  9 subgraph @__main___Net_construct.1(%para1_x1, %para2_bias, %para3_weight) {
 10   %1(x) = call @matmul.7(%para1_x1, %para3_weight)
 11       : (&lt;Tensor[Float32], (3, 32)&gt;, &lt;Ref[Tensor[Float32]], (32, 8)&gt;) -&gt; (&lt;Tensor[Float32], (3, 8)&gt;)
 12       #scope: (Default)
 13       # In file t2.py:15/        x = ops.matmul(x1, self.weight)/
 14
 15 #------------------------&gt; 0
 16   %2(x) = call @bias_add.6(%1, %para2_bias)
 17       : (&lt;Tensor[Float32], (3, 8)&gt;, &lt;Ref[Tensor[Float32]], (4)&gt;) -&gt; (&lt;null&gt;)
 18       #scope: (Default)
 19       # In file t2.py:16/        x = ops.bias_add(x, self.bias)/
 20   Return(%2)
 21       : (&lt;null&gt;)
 22       #scope: (Default)
 23       # In file t2.py:17/        return x/
 24 }
 25 # Order:
 26 #   1: @__main___Net_construct.1:x{[0]: ValueNode&lt;FuncGraph&gt; matmul.7, [1]: x1, [2]: weight}
 27 #   2: @__main___Net_construct.1:x{[0]: ValueNode&lt;FuncGraph&gt; bias_add.6, [1]: x, [2]: bias}
 28 #   3: @__main___Net_construct.1:[CNode]8{[0]: ValueNode&lt;Primitive&gt; Return, [1]: x}
 29
 30
 31 subgraph attr:
 32 subgraph instance: bias_add.6 : 0x56294970ce70
 33 # In file /workspace/mindspore/build/package/mindspore/ops/function/nn_func.py:5470/def bias_add(input_x, bias):/
 34 subgraph @bias_add.6(%para4_input_x, %para5_bias) {
 35   %1([CNode]10) = call @_get_cache_prim.9(ClassType)
 36       : (&lt;Func, NoShape&gt;) -&gt; (&lt;Func, NoShape&gt;)
 37       #scope: (Default)
 38       # In file /workspace/mindspore/build/package/mindspore/ops/function/nn_func.py:5497/    bias_add_op = _get_cache_prim(P.BiasAdd)(data_format=&quot;NCHW&quot;)/
 39   %2([CNode]11) = S-Prim-MakeTuple(&quot;data_format&quot;)
 40       : (&lt;String, NoShape&gt;) -&gt; (&lt;Tuple[String], TupleShape(NoShape)&gt;)
 41       #scope: (Default)
 42       # In file /workspace/mindspore/build/package/mindspore/ops/function/nn_func.py:5497/    bias_add_op = _get_cache_prim(P.BiasAdd)(data_format=&quot;NCHW&quot;)/
 43   %3([CNode]12) = S-Prim-MakeTuple(&quot;NCHW&quot;)
 44       : (&lt;String, NoShape&gt;) -&gt; (&lt;Tuple[String], TupleShape(NoShape)&gt;)
 45       #scope: (Default)
 46       # In file /workspace/mindspore/build/package/mindspore/ops/function/nn_func.py:5497/    bias_add_op = _get_cache_prim(P.BiasAdd)(data_format=&quot;NCHW&quot;)/
 47   %4([CNode]13) = S-Prim-make_dict(%2, %3)
 48       : (&lt;Tuple[String], TupleShape(NoShape)&gt;, &lt;Tuple[String], TupleShape(NoShape)&gt;) -&gt; (&lt;Dictionary[[data_format,],[String]], NoShape&gt;)
 49       #scope: (Default)
 50       # In file /workspace/mindspore/build/package/mindspore/ops/function/nn_func.py:5497/    bias_add_op = _get_cache_prim(P.BiasAdd)(data_format=&quot;NCHW&quot;)/
 51   %5(bias_add_op) = UnpackCall-unpack_call(%1, %4)
 52       : (&lt;Func, NoShape&gt;, &lt;Dictionary[[data_format,],[String]], NoShape&gt;) -&gt; (&lt;Func, NoShape&gt;)
 53       #scope: (Default)
 54       # In file /workspace/mindspore/build/package/mindspore/ops/function/nn_func.py:5497/    bias_add_op = _get_cache_prim(P.BiasAdd)(data_format=&quot;NCHW&quot;)/
 55
 56 #------------------------&gt; 1
 57   %6([CNode]14) = %5(%para4_input_x, %para5_bias)
 58       : (&lt;Tensor[Float32], (3, 8)&gt;, &lt;Ref[Tensor[Float32]], (4)&gt;) -&gt; (&lt;null&gt;)
 59       #scope: (Default)
 60       # In file /workspace/mindspore/build/package/mindspore/ops/function/nn_func.py:5498/    return bias_add_op(input_x, bias)/
 61   Return(%6)
 62       : (&lt;null&gt;)
 63       #scope: (Default)
 64       # In file /workspace/mindspore/build/package/mindspore/ops/function/nn_func.py:5498/    return bias_add_op(input_x, bias)/
 65 }
 66 # Order:
 67 #   1: @bias_add.6:[CNode]10{[0]: ValueNode&lt;FuncGraph&gt; _get_cache_prim.9, [1]: ValueNode&lt;ClassType&gt; class &#39;mindspore.ops.operations.nn_ops.BiasAdd&#39;}
 68 #   2: @bias_add.6:[CNode]11{[0]: ValueNode&lt;DoSignaturePrimitive&gt; S-Prim-MakeTuple, [1]: ValueNode&lt;StringImm&gt; data_format}
 69 #   3: @bias_add.6:[CNode]12{[0]: ValueNode&lt;DoSignaturePrimitive&gt; S-Prim-MakeTuple, [1]: ValueNode&lt;StringImm&gt; NCHW}
 70 #   4: @bias_add.6:[CNode]13{[0]: ValueNode&lt;DoSignaturePrimitive&gt; S-Prim-make_dict, [1]: [CNode]11, [2]: [CNode]12}
 71 #   5: @bias_add.6:bias_add_op{[0]: ValueNode&lt;UnpackCall&gt; MetaFuncGraph-unpack_call.15, [1]: [CNode]10, [2]: [CNode]13}
 72 #   6: @bias_add.6:[CNode]14{[0]: bias_add_op, [1]: input_x, [2]: bias}
 73 #   7: @bias_add.6:[CNode]16{[0]: ValueNode&lt;Primitive&gt; Return, [1]: [CNode]14}
 74
 75
 76 #===============================================================================
 77 # num of function graphs in stack: 2/3 (Ignored 1 internal frames).
</pre></div>
</div>
<p>Search <code class="docutils literal notranslate"><span class="pre">------------------------&gt;</span></code> to the position where inferring failed at line 15. According to <code class="docutils literal notranslate"><span class="pre">...(%1,</span> <span class="pre">%para2_bias)</span>&#160;&#160;&#160; <span class="pre">:</span> <span class="pre">(&lt;Tensor[Float32],</span> <span class="pre">(3,</span> <span class="pre">8)&gt;,</span> <span class="pre">&lt;Ref[Tensor[Float32]],</span> <span class="pre">(4)&gt;)</span> <span class="pre">-&gt;</span> <span class="pre">(</span></code><null><code class="docutils literal notranslate"><span class="pre">)</span></code>, <code class="docutils literal notranslate"><span class="pre">BiasAdd</span></code>’s inputs are <code class="docutils literal notranslate"><span class="pre">%1</span></code> and <code class="docutils literal notranslate"><span class="pre">%para2_bias</span></code>. That <code class="docutils literal notranslate"><span class="pre">%1</span></code>’ with shape <code class="docutils literal notranslate"><span class="pre">[3,</span> <span class="pre">8]</span></code> and <code class="docutils literal notranslate"><span class="pre">%para2_bias</span></code> with shape <code class="docutils literal notranslate"><span class="pre">[4]</span></code> doesn’t meet the requirement about <code class="docutils literal notranslate"><span class="pre">bias</span> <span class="pre">(Tensor)</span> <span class="pre">-</span> <span class="pre">The</span> <span class="pre">bias</span> <span class="pre">tensor,</span> <span class="pre">with</span> <span class="pre">shape</span> <span class="pre">(C).</span> <span class="pre">C</span> <span class="pre">must</span> <span class="pre">be</span> <span class="pre">the</span> <span class="pre">same</span> <span class="pre">as</span> <span class="pre">channel</span> <span class="pre">dimension</span> <span class="pre">C</span> <span class="pre">of</span> <span class="pre">input_x...</span></code> for <code class="docutils literal notranslate"><span class="pre">BiasAdd</span></code> API. Thus, an error happens.</p>
<p>To solve this problem, we need modify the shape of <code class="docutils literal notranslate"><span class="pre">%1</span></code> or <code class="docutils literal notranslate"><span class="pre">%para2_bias</span></code> (namely <code class="docutils literal notranslate"><span class="pre">self.bias</span></code>).</p>
<ul class="simple">
<li><p>For <code class="docutils literal notranslate"><span class="pre">%para2_bias</span></code> (namely <code class="docutils literal notranslate"><span class="pre">self.bias</span></code>), we modify the shape of <code class="docutils literal notranslate"><span class="pre">self.bias</span></code> by <code class="docutils literal notranslate"><span class="pre">self.bias</span> <span class="pre">=</span> <span class="pre">Parameter(initializer('zeros',</span> <span class="pre">[8]),</span> <span class="pre">name=&quot;bias&quot;)</span></code>.</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">%1</span></code>, we need know what <code class="docutils literal notranslate"><span class="pre">%1</span></code> is. According to line 10, <code class="docutils literal notranslate"><span class="pre">%1</span></code> is a <code class="docutils literal notranslate"><span class="pre">MatMul</span></code> with output shape <code class="docutils literal notranslate"><span class="pre">[3,</span> <span class="pre">8]</span></code>. Its inputs are <code class="docutils literal notranslate"><span class="pre">(%para1_x1,</span> <span class="pre">%para3_weight)</span></code>. The first input (namely given arg <code class="docutils literal notranslate"><span class="pre">x</span></code>) shape is <code class="docutils literal notranslate"><span class="pre">[3,</span> <span class="pre">32]</span></code> and the second input (namely <code class="docutils literal notranslate"><span class="pre">self.weight</span></code>) shape is <code class="docutils literal notranslate"><span class="pre">[32,</span> <span class="pre">8]</span></code>. To meet the requirement of <code class="docutils literal notranslate"><span class="pre">BiasAdd</span></code> with the data shape <code class="docutils literal notranslate"><span class="pre">[4]</span></code>, the shape of <code class="docutils literal notranslate"><span class="pre">%1</span></code> output needs to be <code class="docutils literal notranslate"><span class="pre">[3,</span> <span class="pre">4]</span></code>. Therefore, we modify <code class="docutils literal notranslate"><span class="pre">self.weight</span></code> by <code class="docutils literal notranslate"><span class="pre">self.weight</span> <span class="pre">=</span> <span class="pre">Parameter(initializer('normal',</span> <span class="pre">[32,</span> <span class="pre">4]),</span> <span class="pre">name=&quot;weight&quot;)</span></code>.</p></li>
</ul>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="cann_error_cases.html" class="btn btn-neutral float-left" title="CANN Common Error Analysis" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>