<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Callback Mechanism &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <script src="../../_static/js/theme.js"></script>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/js/training.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Evaluation Metrics" href="metric.html" />
    <link rel="prev" title="Advanced Encapsulation: Model" href="../model.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introduction.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/dataset.html">Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/transforms.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/model.html">Building a Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/autograd.html">Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/train.html">Model Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/save_load.html">Saving and Loading the Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/accelerate_with_static_graph.html">Accelerating with Static Graphs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../model.html">Advanced Encapsulation: Model</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Callback Mechanism</a></li>
<li class="toctree-l2"><a class="reference internal" href="metric.html">Evaluation Metrics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">Model Module Customization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset.html">Advanced Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../derivation.html">Advanced Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../static_graph_expert_programming.html">Advanced Programming Techniques for Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mixed_precision.html">Automatic Mix Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../error_analysis.html">Error Reporting Analysis</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../model.html">Advanced Encapsulation: Model</a> &raquo;</li>
      <li>Callback Mechanism</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/advanced/model/callback.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/tutorials/source_en/advanced/model/callback.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png" /></a></p>
<section id="callback-mechanism">
<h1>Callback Mechanism<a class="headerlink" href="#callback-mechanism" title="Permalink to this headline"></a></h1>
<p>During deep learning training, MindSpore provides the callback mechanism to promptly learn about the training status of the network model, observe the changes of network model parameters in real time, and implement customized operations during training.</p>
<p>The callback mechanism is generally used in the network model training process <code class="docutils literal notranslate"><span class="pre">model.train</span></code>. The MindSpore <code class="docutils literal notranslate"><span class="pre">model</span></code> executes callback functions based on the sequence in the callback list. You can set different callback classes to implement functions executed during or after training.</p>
<blockquote>
<div><p>For more information about built-in callback classes and how to use them, see <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/train/mindspore.train.Callback.html#mindspore.train.Callback">API</a>.</p>
</div></blockquote>
<section id="callback-introduction">
<h2>Callback Introduction<a class="headerlink" href="#callback-introduction" title="Permalink to this headline"></a></h2>
<p>When talking about callback, most users find it difficult to understand whether stacks or special scheduling modes are required. Actually, the callback can be explained as follows:</p>
<p>Assume that function A has a parameter which is function B. After function A is executed, function B is executed. This process is called callback.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">callback</span></code> in MindSpore is actually not a function but a class. You can use the callback mechanism to observe the internal status and related information of the network during training or perform specific actions in a specific period.</p>
<p>For example, monitor the loss function, save the model parameter <code class="docutils literal notranslate"><span class="pre">ckpt</span></code>, dynamically adjust the parameter <code class="docutils literal notranslate"><span class="pre">lr</span></code>, and terminate the training task in advance. The following uses the MNIST dataset as an example to describe several common built-in callback functions and customised callback functions.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset</span> <span class="kn">import</span> <span class="n">vision</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset</span> <span class="kn">import</span> <span class="n">MnistDataset</span>
<span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="c1"># Download data from open datasets</span>
<span class="kn">from</span> <span class="nn">download</span> <span class="kn">import</span> <span class="n">download</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/&quot;</span> \
      <span class="s2">&quot;notebook/datasets/MNIST_Data.zip&quot;</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="s2">&quot;./&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;zip&quot;</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">datapipe</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">image_transforms</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.3081</span><span class="p">,)),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="p">]</span>
    <span class="n">label_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">dataset</span> <span class="o">=</span> <span class="n">MnistDataset</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">image_transforms</span><span class="p">,</span> <span class="s1">&#39;image&#39;</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">label_transform</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dataset</span>

<span class="c1"># Define model</span>
<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense_relu_sequential</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_relu_sequential</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mf">1e-2</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Downloading data from https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/MNIST_Data.zip (10.3 MB)

file_sizes: 100%|██████████████████████████| 10.8M/10.8M [00:01&lt;00:00, 10.0MB/s]
Extracting zip file...
Successfully downloaded / unzipped to ./
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">datapipe</span><span class="p">(</span><span class="s1">&#39;MNIST_Data/train&#39;</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">datapipe</span><span class="p">(</span><span class="s1">&#39;MNIST_Data/test&#39;</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;accuracy&#39;</span><span class="p">})</span>
</pre></div>
</div>
</section>
<section id="common-built-in-callback-functions">
<h2>Common Built-in Callback Functions<a class="headerlink" href="#common-built-in-callback-functions" title="Permalink to this headline"></a></h2>
<p>MindSpore provides the <code class="docutils literal notranslate"><span class="pre">callback</span></code> capability to allow users to insert customized operations in a specific phase of training or inference.</p>
<section id="modelcheckpoint">
<h3>ModelCheckpoint<a class="headerlink" href="#modelcheckpoint" title="Permalink to this headline"></a></h3>
<p>To save the trained network model and parameters for re-inference or re-training, MindSpore provides the <a class="reference external" href="https://mindspore.cn/docs/en/master/api_python/train/mindspore.train.ModelCheckpoint.html#mindspore.train.ModelCheckpoint">ModelCheckpoint</a> API, which is generally used together with the <a class="reference external" href="https://mindspore.cn/docs/en/master/api_python/train/mindspore.train.CheckpointConfig.html#mindspore.train.CheckpointConfig">CheckpointConfig</a> API.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">ModelCheckpoint</span>

<span class="c1"># Set the configuration information of the saved model.</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="mi">1875</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="c1"># Instantiate the saved model callback API and define the storage path and prefix.</span>
<span class="n">ckpt_callback</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;mnist&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;./checkpoint&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

<span class="c1"># Start training and load the saved model and parameter callback function.</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ckpt_callback</span><span class="p">])</span>
</pre></div>
</div>
<p>After the preceding code is executed, the generated checkpoint file directory structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./checkpoint/
├── mnist-1_938.ckpt # file to save parameters
└── mnist-graph.meta # grapg after compiled
</pre></div>
</div>
</section>
<section id="lossmonitor">
<h3>LossMonitor<a class="headerlink" href="#lossmonitor" title="Permalink to this headline"></a></h3>
<p>To monitor the change of the loss function value during training, set <code class="docutils literal notranslate"><span class="pre">per_print_times</span></code> to control the interval of printing loss.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">LossMonitor</span>

<span class="n">loss_monitor</span> <span class="o">=</span> <span class="n">LossMonitor</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span>
<span class="c1"># Start training and load the saved model and parameter callback function. The input parameters of LossMonitor are learning rate (0.01) and stride (375).</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">loss_monitor</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 1 step: 300, loss is 0.45305341482162476
epoch: 1 step: 600, loss is 0.2915695905685425
epoch: 1 step: 900, loss is 0.5174192190170288
</pre></div>
</div>
<p>During training, LossMonitor monitors the loss value of training. And when you train and infer at the same time, LossMonitor monitors the loss value of training and the Metrics value of inferring.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">loss_monitor</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 1 step: 300, loss is 0.3167177438735962
epoch: 1 step: 600, loss is 0.36215940117836
epoch: 1 step: 900, loss is 0.25714176893234253
Eval result: epoch 1, metrics: {&#39;accuracy&#39;: 0.9202}
</pre></div>
</div>
</section>
<section id="timemonitor">
<h3>TimeMonitor<a class="headerlink" href="#timemonitor" title="Permalink to this headline"></a></h3>
<p>To monitor the execution time of training or testing, set <code class="docutils literal notranslate"><span class="pre">data_size</span></code> to control the interval of printing the execution time.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">TimeMonitor</span>

<span class="n">time_monitor</span> <span class="o">=</span> <span class="n">TimeMonitor</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">time_monitor</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Train epoch time: 7388.254 ms, per step time: 7.877 ms
</pre></div>
</div>
</section>
</section>
<section id="customized-callback-mechanism">
<h2>Customized Callback Mechanism<a class="headerlink" href="#customized-callback-mechanism" title="Permalink to this headline"></a></h2>
<p>MindSpore not only has powerful built-in callback functions, but also allows users to customize callback classes based on the <code class="docutils literal notranslate"><span class="pre">Callback</span></code> base class when they have special requirements.</p>
<p>You can customize callbacks based on the <code class="docutils literal notranslate"><span class="pre">Callback</span></code> base class as required. The <code class="docutils literal notranslate"><span class="pre">Callback</span></code> base class is defined as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Callback</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Callback base class&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called once before the network executing.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called before each epoch beginning.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called after each epoch finished.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called before each step beginning.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called after each step finished.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called once after network training.&quot;&quot;&quot;</span>
</pre></div>
</div>
<p>The callback mechanism can record important information during training and transfer a dictionary variable <code class="docutils literal notranslate"><span class="pre">RunContext.original_args()</span></code> to the callback object so that users can obtain related attributes from each customized callback, perform customized operations, and customize other variables and transfer them to the <code class="docutils literal notranslate"><span class="pre">RunContext.original_args()</span></code> object.</p>
<p>Common attributes in <code class="docutils literal notranslate"><span class="pre">RunContext.original_args()</span></code> are as follows:</p>
<ul class="simple">
<li><p>epoch_num: number of training epochs</p></li>
<li><p>batch_num: number of steps in an epoch</p></li>
<li><p>cur_epoch_num: number of current epochs</p></li>
<li><p>cur_step_num: number of current steps</p></li>
<li><p>loss_fn: loss function</p></li>
<li><p>optimizer: optimizer</p></li>
<li><p>train_network: training network</p></li>
<li><p>train_dataset: training dataset</p></li>
<li><p>net_outputs: network output</p></li>
<li><p>parallel_mode: parallel mode</p></li>
<li><p>list_callback: all callback functions</p></li>
</ul>
<p>You can understand the customized callback mechanism in the following two scenarios:</p>
<section id="customized-training-termination-time">
<h3>Customized Training Termination Time<a class="headerlink" href="#customized-training-termination-time" title="Permalink to this headline"></a></h3>
<p>The training can be terminated within a specified period. You can set a time threshold. When the training time reaches the threshold, the training process is terminated.</p>
<p>In the following code, the <code class="docutils literal notranslate"><span class="pre">run_context.original_args</span></code> method can be used to obtain the <code class="docutils literal notranslate"><span class="pre">cb_params</span></code> dictionary which contains the main attribute information described above.</p>
<p>In addition, you can modify and add values in the dictionary. Define an <code class="docutils literal notranslate"><span class="pre">init_time</span></code> object in the <code class="docutils literal notranslate"><span class="pre">begin</span></code> function and transfer it to the <code class="docutils literal notranslate"><span class="pre">cb_params</span></code> dictionary. After each step ends, the system checks whether the training time is greater than the configured time threshold. If the training time is greater than the configured time threshold, the system sends a training termination signal to <code class="docutils literal notranslate"><span class="pre">run_context</span></code> to terminate the training in advance and prints the current epoch, step, and loss values.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="k">class</span> <span class="nc">StopTimeMonitor</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_time</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Define the initialization process.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StopTimeMonitor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">run_time</span> <span class="o">=</span> <span class="n">run_time</span>            <span class="c1"># Define the execution time.</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Operations when training is started.&quot;&quot;&quot;</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">cb_params</span><span class="o">.</span><span class="n">init_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>   <span class="c1"># Obtain the current timestamp as the training start time.</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Begin training, time is: </span><span class="si">{</span><span class="n">cb_params</span><span class="o">.</span><span class="n">init_time</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Operations after each step ends.&quot;&quot;&quot;</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">epoch_num</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span>  <span class="c1"># Obtain the epoch value.</span>
        <span class="n">step_num</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span>    <span class="c1"># Obtain the step value.</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">net_outputs</span>         <span class="c1"># Obtain the loss value.</span>
        <span class="n">cur_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>               <span class="c1"># Obtain the current timestamp.</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">cur_time</span> <span class="o">-</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">init_time</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_time</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End training, time: </span><span class="si">{</span><span class="n">cur_time</span><span class="si">}</span><span class="s2">, epoch: </span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="s2">, step: </span><span class="si">{</span><span class="n">step_num</span><span class="si">}</span><span class="s2">, loss:</span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">run_context</span><span class="o">.</span><span class="n">request_stop</span><span class="p">()</span>       <span class="c1"># Stop training.</span>

<span class="n">datasize</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LossMonitor</span><span class="p">(</span><span class="n">datasize</span><span class="p">),</span> <span class="n">StopTimeMonitor</span><span class="p">(</span><span class="mi">4</span><span class="p">)])</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Begin training, time is: 1665892816.363511
End training, time: 1665892820.3696215, epoch: 1, step: 575, loss:Tensor(shape=[], dtype=Float32, value= 0.35758)
</pre></div>
</div>
<p>According to the preceding information, when step 4673 of the third epoch is complete, the running time reaches the threshold and the training ends.</p>
</section>
<section id="customized-model-saving-threshold">
<h3>Customized Model Saving Threshold<a class="headerlink" href="#customized-model-saving-threshold" title="Permalink to this headline"></a></h3>
<p>This callback mechanism is used to save the network model weight CKPT file when the loss is less than the specified threshold.</p>
<p>The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="c1"># Define the callback API for saving the CKPT file.</span>
<span class="k">class</span> <span class="nc">SaveCkptMonitor</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Define the initialization process.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SaveCkptMonitor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="c1"># Defines the loss threshold.</span>

    <span class="k">def</span> <span class="nf">on_train_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Define the operation to be performed when a step ends.&quot;&quot;&quot;</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">cur_loss</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">net_outputs</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span> <span class="c1"># Obtain the current loss value.</span>

        <span class="c1"># If the current loss value is less than the preset threshold, the training stops.</span>
        <span class="k">if</span> <span class="n">cur_loss</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">:</span>
            <span class="c1"># Name the file to be saved.</span>
            <span class="n">file_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;./checkpoint/</span><span class="si">{</span><span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span><span class="si">}</span><span class="s2">.ckpt&quot;</span>
            <span class="c1"># Save the network model.</span>
            <span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">save_obj</span><span class="o">=</span><span class="n">cb_params</span><span class="o">.</span><span class="n">train_network</span><span class="p">,</span> <span class="n">ckpt_file_name</span><span class="o">=</span><span class="n">file_name</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Saved checkpoint, loss:</span><span class="si">{:8.7f}</span><span class="s2">, current step num:</span><span class="si">{:4}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cur_loss</span><span class="p">,</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span><span class="p">))</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">SaveCkptMonitor</span><span class="p">(</span><span class="mf">0.05</span><span class="p">)])</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Saved checkpoint, loss:0.0390485, current step num: 154.
Saved checkpoint, loss:0.0481475, current step num: 234.
Saved checkpoint, loss:0.0477566, current step num: 361.
Saved checkpoint, loss:0.0314977, current step num: 444.
Saved checkpoint, loss:0.0463577, current step num: 513.
Saved checkpoint, loss:0.0408403, current step num: 764.
Saved checkpoint, loss:0.0308827, current step num: 899.
</pre></div>
</div>
<p>The directory structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./checkpoint/
├── 1_154.ckpt
├── 1_234.ckpt
├── 1_361.ckpt
├── 1_444.ckpt
├── 1_513.ckpt
├── 1_764.ckpt
├── 1_899.ckpt
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../model.html" class="btn btn-neutral float-left" title="Advanced Encapsulation: Model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="metric.html" class="btn btn-neutral float-right" title="Evaluation Metrics" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>