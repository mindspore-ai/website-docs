

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Callback Mechanism &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/js/training.js"></script>
        
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Module Customization" href="../modules.html" />
    <link rel="prev" title="Basic Usage of Models" href="model.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introduction.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/dataset.html">Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/transforms.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/model.html">Building a Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/autograd.html">Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/train.html">Model Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/save_load.html">Saving and Loading the Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../model.html">Advanced Encapsulation: Model</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="metric.html">Evaluation Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="model.html">Basic Usage of Models</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Callback Mechanism</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#callback-usage">Callback Usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#common-built-in-callback-functions">Common Built-in Callback Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#modelcheckpoint">ModelCheckpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="#lossmonitor">LossMonitor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#timemonitor">TimeMonitor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#customized-callback-mechanism">Customized Callback Mechanism</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#customized-training-termination-time">Customized Training Termination Time</a></li>
<li class="toctree-l4"><a class="reference internal" href="#customized-model-saving-threshold">Customized Model Saving Threshold</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">Module Customization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset.html">Advanced Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../derivation.html">Advanced Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compute_graph.html">Computation Graphs</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../model.html">Advanced Encapsulation: Model</a> &raquo;</li>
      <li>Callback Mechanism</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/advanced/model/callback.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section class="tex2jax_ignore mathjax_ignore" id="callback-mechanism">
<h1>Callback Mechanism<a class="headerlink" href="#callback-mechanism" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.10/tutorials/source_en/advanced/model/callback.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/resource/_static/logo_source_en.png"></a></p>
<p>During deep learning training, MindSpore provides the callback mechanism to promptly learn about the training status of the network model, observe the changes of network model parameters in real time, and implement customized operations during training.</p>
<p>The callback mechanism is generally used in the network model training process <code class="docutils literal notranslate"><span class="pre">model.train</span></code>. The MindSpore <code class="docutils literal notranslate"><span class="pre">model</span></code> executes callback functions based on the sequence in the callback list. You can set different callback classes to implement functions executed during or after training.</p>
<blockquote>
<div><p>For more information about built-in callback classes and how to use them, see <a class="reference external" href="https://www.mindspore.cn/docs/en/r1.10/api_python/mindspore/mindspore.Callback.html#mindspore.Callback">API</a>.</p>
</div></blockquote>
<section id="callback-usage">
<h2>Callback Usage<a class="headerlink" href="#callback-usage" title="Permalink to this headline"></a></h2>
<p>When talking about callback, most users find it difficult to understand whether stacks or special scheduling modes are required. Actually, the callback can be explained as follows:</p>
<p>Assume that function A has a parameter which is function B. After function A is executed, function B is executed. This process is called callback.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">callback</span></code> in MindSpore is actually not a function but a class. You can use the callback mechanism to observe the internal status and related information of the network during training or perform specific actions in a specific period.</p>
<p>For example, monitor the loss function, save the model parameter <code class="docutils literal notranslate"><span class="pre">ckpt</span></code>, dynamically adjust the parameter <code class="docutils literal notranslate"><span class="pre">lr</span></code>, and terminate the training task in advance.</p>
<p>The following uses the LeNet-5 model training based on the MNIST dataset as an example to describe several common MindSpore built-in callback classes.</p>
<p>Download and process MNIST data to build a LeNet-5 model. The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">download</span> <span class="kn">import</span> <span class="n">download</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset</span> <span class="kn">import</span> <span class="n">vision</span><span class="p">,</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">MnistDataset</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">Normal</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/&quot;</span> \
      <span class="s2">&quot;notebook/datasets/MNIST_Data.zip&quot;</span>

<span class="c1"># download dataset</span>
<span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="s2">&quot;./&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;zip&quot;</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># process dataset</span>
<span class="k">def</span> <span class="nf">proc_dataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">MnistDataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># define map operations</span>
    <span class="n">image_transforms</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.3081</span><span class="p">,)),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="p">]</span>

    <span class="n">label_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">label_transform</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">)</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">image_transforms</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">)</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mnist_ds</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">proc_dataset</span><span class="p">(</span><span class="s1">&#39;MNIST_Data/train&#39;</span><span class="p">)</span>

<span class="c1"># define LeNet-5 model</span>
<span class="k">class</span> <span class="nc">LeNet5</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_class</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet5</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_channel</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="n">num_class</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">create_model</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
    <span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
    <span class="n">net_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">net_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">net_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">()})</span>
    <span class="k">return</span> <span class="n">trainer</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Downloading data from https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/MNIST_Data.zip (10.3 MB)

file_sizes: 100%|██████████████████████████| 10.8M/10.8M [00:01&lt;00:00, 10.0MB/s]
Extracting zip file...
Successfully downloaded / unzipped to ./
</pre></div>
</div>
</section>
<section id="common-built-in-callback-functions">
<h2>Common Built-in Callback Functions<a class="headerlink" href="#common-built-in-callback-functions" title="Permalink to this headline"></a></h2>
<p>MindSpore provides the <code class="docutils literal notranslate"><span class="pre">callback</span></code> capability to allow users to insert customized operations in a specific phase of training or inference.</p>
<section id="modelcheckpoint">
<h3>ModelCheckpoint<a class="headerlink" href="#modelcheckpoint" title="Permalink to this headline"></a></h3>
<p>To save the trained network model and parameters for re-inference or re-training, MindSpore provides the <a class="reference external" href="https://mindspore.cn/docs/en/r1.10/api_python/mindspore/mindspore.ModelCheckpoint.html#mindspore.ModelCheckpoint">ModelCheckpoint</a> API, which is generally used together with the <a class="reference external" href="https://mindspore.cn/docs/en/r1.10/api_python/mindspore/mindspore.CheckpointConfig.html#mindspore.CheckpointConfig">CheckpointConfig</a> API.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">ModelCheckpoint</span>

<span class="c1"># Set the configuration information of the saved model.</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="mi">1875</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Instantiate the saved model callback API and define the storage path and prefix.</span>
<span class="n">ckpt_callback</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;mnist&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;./checkpoint&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

<span class="c1"># Start training and load the saved model and parameter callback function.</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ckpt_callback</span><span class="p">])</span>
</pre></div>
</div>
<p>After the preceding code is executed, the generated checkpoint file directory structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./checkpoint/
├── mnist-1_1875.ckpt # file to save parameters
└── mnist-graph.meta # grapg after compiled
</pre></div>
</div>
</section>
<section id="lossmonitor">
<h3>LossMonitor<a class="headerlink" href="#lossmonitor" title="Permalink to this headline"></a></h3>
<p>To monitor the change of the loss function value during training, set <code class="docutils literal notranslate"><span class="pre">per_print_times</span></code> to control the interval of printing loss.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">LossMonitor</span>

<span class="n">loss_monitor</span> <span class="o">=</span> <span class="n">LossMonitor</span><span class="p">(</span><span class="mi">1875</span><span class="p">)</span>
<span class="c1"># Start training and load the saved model and parameter callback function.</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">loss_monitor</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 1 step: 1875, loss is 0.008795851841568947
epoch: 2 step: 1875, loss is 0.007240554317831993
epoch: 3 step: 1875, loss is 0.0036914246156811714
</pre></div>
</div>
<p>During training, LossMonitor monitors the loss value of training. And when you train and infer at the same time, LossMonitor monitors the loss value of training and the Metrics value of inferring.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">test_dataset</span> <span class="o">=</span> <span class="n">proc_dataset</span><span class="p">(</span><span class="s1">&#39;MNIST_Data/test&#39;</span><span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">loss_monitor</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 1 step: 1875, loss is 0.0026960039976984262
Eval result: epoch 1, metrics: {&#39;Accuracy&#39;: 0.9888822115384616}
epoch: 2 step: 1875, loss is 0.00038617433165200055
Eval result: epoch 2, metrics: {&#39;Accuracy&#39;: 0.9877804487179487}
</pre></div>
</div>
</section>
<section id="timemonitor">
<h3>TimeMonitor<a class="headerlink" href="#timemonitor" title="Permalink to this headline"></a></h3>
<p>To monitor the execution time of training or testing, set <code class="docutils literal notranslate"><span class="pre">data_size</span></code> to control the interval of printing the execution time.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">TimeMonitor</span>

<span class="n">time_monitor</span> <span class="o">=</span> <span class="n">TimeMonitor</span><span class="p">(</span><span class="mi">1875</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">time_monitor</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Train epoch time: 3876.302 ms, per step time: 2.067 ms
</pre></div>
</div>
</section>
</section>
<section id="customized-callback-mechanism">
<h2>Customized Callback Mechanism<a class="headerlink" href="#customized-callback-mechanism" title="Permalink to this headline"></a></h2>
<p>MindSpore not only has powerful built-in callback functions, but also allows users to customize callback classes based on the <code class="docutils literal notranslate"><span class="pre">Callback</span></code> base class when they have special requirements.</p>
<p>You can customize callbacks based on the <code class="docutils literal notranslate"><span class="pre">Callback</span></code> base class as required. The <code class="docutils literal notranslate"><span class="pre">Callback</span></code> base class is defined as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Callback</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Callback base class&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called once before the network executing.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called before each epoch beginning.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called after each epoch finished.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called before each step beginning.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called after each step finished.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called once after network training.&quot;&quot;&quot;</span>
</pre></div>
</div>
<p>The callback mechanism can record important information during training and transfer a dictionary variable <code class="docutils literal notranslate"><span class="pre">RunContext.original_args()</span></code> to the callback object so that users can obtain related attributes from each customized callback, perform customized operations, and customize other variables and transfer them to the <code class="docutils literal notranslate"><span class="pre">RunContext.original_args()</span></code> object.</p>
<p>Common attributes in <code class="docutils literal notranslate"><span class="pre">RunContext.original_args()</span></code> are as follows:</p>
<ul class="simple">
<li><p>epoch_num: number of training epochs</p></li>
<li><p>batch_num: number of steps in an epoch</p></li>
<li><p>cur_epoch_num: number of current epochs</p></li>
<li><p>cur_step_num: number of current steps</p></li>
<li><p>loss_fn: loss function</p></li>
<li><p>optimizer: optimizer</p></li>
<li><p>train_network: training network</p></li>
<li><p>train_dataset: training dataset</p></li>
<li><p>net_outputs: network output</p></li>
<li><p>parallel_mode: parallel mode</p></li>
<li><p>list_callback: all callback functions</p></li>
</ul>
<p>You can understand the customized callback mechanism in the following two scenarios:</p>
<section id="customized-training-termination-time">
<h3>Customized Training Termination Time<a class="headerlink" href="#customized-training-termination-time" title="Permalink to this headline"></a></h3>
<p>The training can be terminated within a specified period. You can set a time threshold. When the training time reaches the threshold, the training process is terminated.</p>
<p>In the following code, the <code class="docutils literal notranslate"><span class="pre">run_context.original_args</span></code> method can be used to obtain the <code class="docutils literal notranslate"><span class="pre">cb_params</span></code> dictionary which contains the main attribute information described above.</p>
<p>In addition, you can modify and add values in the dictionary. Define an <code class="docutils literal notranslate"><span class="pre">init_time</span></code> object in the <code class="docutils literal notranslate"><span class="pre">begin</span></code> function and transfer it to the <code class="docutils literal notranslate"><span class="pre">cb_params</span></code> dictionary. After each step ends, the system checks whether the training time is greater than the configured time threshold. If the training time is greater than the configured time threshold, the system sends a training termination signal to <code class="docutils literal notranslate"><span class="pre">run_context</span></code> to terminate the training in advance and prints the current epoch, step, and loss values.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Callback</span>

<span class="k">class</span> <span class="nc">StopTimeMonitor</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_time</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Define the initialization process.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StopTimeMonitor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">run_time</span> <span class="o">=</span> <span class="n">run_time</span>             <span class="c1"># Define the execution time.</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Operations when training is started.&quot;&quot;&quot;</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">cb_params</span><span class="o">.</span><span class="n">init_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>   <span class="c1"># Obtain the current timestamp as the training start time.</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Begin training, time is: </span><span class="si">{</span><span class="n">cb_params</span><span class="o">.</span><span class="n">init_time</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">       </span><span class="sd">&quot;&quot;&quot;Operations after each step ends.&quot;&quot;&quot;</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">epoch_num</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span>  <span class="c1"># Obtain the epoch value.</span>
        <span class="n">step_num</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span>    <span class="c1"># Obtain the step value.</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">net_outputs</span>         <span class="c1"># Obtain the loss value.</span>
        <span class="n">cur_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>               <span class="c1"># Obtain the current timestamp.</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">cur_time</span> <span class="o">-</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">init_time</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_time</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End training, time: </span><span class="si">{</span><span class="n">cur_time</span><span class="si">}</span><span class="s2">, epoch: </span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="s2">, step: </span><span class="si">{</span><span class="n">step_num</span><span class="si">}</span><span class="s2">, loss:</span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">run_context</span><span class="o">.</span><span class="n">request_stop</span><span class="p">()</span>       <span class="c1"># Stop training.</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">proc_dataset</span><span class="p">(</span><span class="s1">&#39;MNIST_Data/train&#39;</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LossMonitor</span><span class="p">(),</span> <span class="n">StopTimeMonitor</span><span class="p">(</span><span class="mi">4</span><span class="p">)])</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Begin training, time is: 1673515004.6783535
epoch: 1 step: 1875, loss is 0.0006050781812518835
End training, time: 1673515009.1824663, epoch: 1, step: 1875, loss:0.0006050782
</pre></div>
</div>
<p>According to the preceding information, the progrem stopped immediately the running time reaches the threshold.</p>
</section>
<section id="customized-model-saving-threshold">
<h3>Customized Model Saving Threshold<a class="headerlink" href="#customized-model-saving-threshold" title="Permalink to this headline"></a></h3>
<p>This callback mechanism is used to save the network model weight CKPT file when the loss is less than the specified threshold.</p>
<p>The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">save_checkpoint</span>

<span class="c1"># Define the callback API for saving the CKPT file.</span>
<span class="k">class</span> <span class="nc">SaveCkptMonitor</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Define the initialization process.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SaveCkptMonitor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span>  <span class="c1"># Defines the loss threshold.</span>

    <span class="k">def</span> <span class="nf">on_train_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Define the operation to be performed when a step ends.&quot;&quot;&quot;</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">cur_loss</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">net_outputs</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span> <span class="c1"># Obtain the current loss value.</span>

        <span class="c1"># If the current loss value is less than the preset threshold, the training stops.</span>
        <span class="k">if</span> <span class="n">cur_loss</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">:</span>
            <span class="c1"># Name the file to be saved.</span>
            <span class="n">file_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;./checkpoint/</span><span class="si">{</span><span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span><span class="si">}</span><span class="s2">.ckpt&quot;</span>
            <span class="c1"># Save the network model.</span>
            <span class="n">save_checkpoint</span><span class="p">(</span><span class="n">save_obj</span><span class="o">=</span><span class="n">cb_params</span><span class="o">.</span><span class="n">train_network</span><span class="p">,</span> <span class="n">ckpt_file_name</span><span class="o">=</span><span class="n">file_name</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Saved checkpoint, loss:</span><span class="si">{:8.7f}</span><span class="s2">, current step num:</span><span class="si">{:4}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cur_loss</span><span class="p">,</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span><span class="p">))</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">proc_dataset</span><span class="p">(</span><span class="s1">&#39;MNIST_Data/train&#39;</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LossMonitor</span><span class="p">(),</span> <span class="n">SaveCkptMonitor</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)])</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 1 step: 1875, loss is 0.15191984176635742
epoch: 2 step: 1875, loss is 0.14701086282730103
epoch: 3 step: 1875, loss is 0.0020134493242949247
Saved checkpoint, loss:0.0020134, current step num:5625.
epoch: 4 step: 1875, loss is 0.018305214121937752
epoch: 5 step: 1875, loss is 0.00019801077723968774
Saved checkpoint, loss:0.0001980, current step num:9375.
</pre></div>
</div>
<p>Finally, the network weights whose loss value is less than the threshold is saved in <code class="docutils literal notranslate"><span class="pre">./checkpoint/</span></code> directory.</p>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="model.html" class="btn btn-neutral float-left" title="Basic Usage of Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../modules.html" class="btn btn-neutral float-right" title="Module Customization" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>