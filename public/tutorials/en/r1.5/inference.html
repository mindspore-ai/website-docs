<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Inference &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Simple Linear Function Fitting" href="linear_regression.html" />
    <link rel="prev" title="Saving and Loading the Model" href="save_load_model.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">Quick Start for Beginners</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Loading and Processing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Building a Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="autograd.html">Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimization.html">Training the Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_load_model.html">Saving and Loading the Model</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#inference-code">Inference Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="#build-script">Build Script</a></li>
<li class="toctree-l2"><a class="reference internal" href="#building-inference-code">Building Inference Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="#performing-inference-and-viewing-the-result">Performing Inference and Viewing the Result</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="linear_regression.html">Simple Linear Function Fitting</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Inference</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/inference.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="inference">
<h1>Inference<a class="headerlink" href="#inference" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">Device</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code> <code class="docutils literal notranslate"><span class="pre">Inference</span> <span class="pre">Application</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.5/tutorials/source_en/inference.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source_en.png"></a></p>
<p>This is the last tutorial. Introduction to inference is classified into Ascend AI Processor.</p>
<p>An Ascend AI Processor is an energy-efficient and highly integrated AI processor oriented to edge scenarios. It can implement multiple data analysis and inference computing, such as image and video analysis, and can be widely used in scenarios such as intelligent surveillance, robots, drones, and video servers. The following describes how to use MindSpore to perform inference on the Ascend AI Processors.</p>
<section id="inference-code">
<h2>Inference Code<a class="headerlink" href="#inference-code" title="Permalink to this headline"></a></h2>
<p>Create a directory to store the inference code project, for example, <code class="docutils literal notranslate"><span class="pre">/home/HwHiAiUser/mindspore_sample/ascend910_resnet50_preprocess_sample</span></code>. You can download the <a class="reference external" href="https://gitee.com/mindspore/docs/tree/r1.5/docs/sample_code/ascend910_resnet50_preprocess_sample">sample code</a> from the official website. The <code class="docutils literal notranslate"><span class="pre">model</span></code> directory is used to store the exported <a class="reference external" href="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/sample_resources/ascend310_resnet50_preprocess_sample/resnet50_imagenet.mindir">MindIR model file</a>, and the <code class="docutils literal notranslate"><span class="pre">test_data</span></code> directory is used to store the images to be classified, the images can be selected in <a class="reference external" href="http://image-net.org/download-images">ImageNet2012</a> validation dataset. The directory structure of the inference code project is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─ascend910_resnet50_preprocess_sample
    ├── CMakeLists.txt                   // Build script
    ├── README.md                         // Usage description
    ├── main.cc                           // Main function
    ├── model
    │   └── resnet50_imagenet.mindir      // MindIR model file
    └── test_data
        ├── ILSVRC2012_val_00002138.JPEG  // Input sample image 1
        ├── ILSVRC2012_val_00003014.JPEG  // Input sample image 2
        ├── ...                           // Input sample image n.
</pre></div>
</div>
<p>Namespaces that reference <code class="docutils literal notranslate"><span class="pre">mindspore</span></code> and <code class="docutils literal notranslate"><span class="pre">mindspore::dataset</span></code>.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">namespace</span><span class="w"> </span><span class="nn">ms</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">mindspore</span><span class="p">;</span>
<span class="k">namespace</span><span class="w"> </span><span class="nn">ds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">mindspore</span><span class="o">::</span><span class="nn">dataset</span><span class="p">;</span>
</pre></div>
</div>
<p>Initialize the environment, specify the hardware platform used for inference, and set DeviceID.</p>
<p>Set the hardware to Ascend 910 and set DeviceID to 0. The code example is as follows:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">ms</span><span class="o">::</span><span class="n">Context</span><span class="o">&gt;</span><span class="p">();</span>
<span class="k">auto</span><span class="w"> </span><span class="n">ascend910_info</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">ms</span><span class="o">::</span><span class="n">Ascend910DeviceInfo</span><span class="o">&gt;</span><span class="p">();</span>
<span class="n">ascend910_info</span><span class="o">-&gt;</span><span class="n">SetDeviceID</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="n">context</span><span class="o">-&gt;</span><span class="n">MutableDeviceInfo</span><span class="p">().</span><span class="n">push_back</span><span class="p">(</span><span class="n">ascend910_info</span><span class="p">);</span>
</pre></div>
</div>
<p>Load the model file.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Load the MindIR model.</span>
<span class="n">ms</span><span class="o">::</span><span class="n">Graph</span><span class="w"> </span><span class="n">graph</span><span class="p">;</span>
<span class="n">ms</span><span class="o">::</span><span class="n">Status</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ms</span><span class="o">::</span><span class="n">Serialization</span><span class="o">::</span><span class="n">Load</span><span class="p">(</span><span class="n">resnet_file</span><span class="p">,</span><span class="w"> </span><span class="n">ms</span><span class="o">::</span><span class="n">ModelType</span><span class="o">::</span><span class="n">kMindIR</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graph</span><span class="p">);</span>
<span class="c1">// Build a model using a graph.</span>
<span class="n">ms</span><span class="o">::</span><span class="n">Model</span><span class="w"> </span><span class="n">resnet50</span><span class="p">;</span>
<span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">resnet50</span><span class="p">.</span><span class="n">Build</span><span class="p">(</span><span class="n">ms</span><span class="o">::</span><span class="n">GraphCell</span><span class="p">(</span><span class="n">graph</span><span class="p">),</span><span class="w"> </span><span class="n">context</span><span class="p">);</span>
</pre></div>
</div>
<p>Obtain the input information required by the model.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">ms</span><span class="o">::</span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">model_inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">resnet50</span><span class="p">.</span><span class="n">GetInputs</span><span class="p">();</span>
</pre></div>
</div>
<p>Load the image file.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// ReadFile is a function used to read images.</span>
<span class="n">ms</span><span class="o">::</span><span class="n">MSTensor</span><span class="w"> </span><span class="nf">ReadFile</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="o">&amp;</span><span class="n">file</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">image</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ReadFile</span><span class="p">(</span><span class="n">image_file</span><span class="p">);</span>
</pre></div>
</div>
<p>Preprocess images.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Use the CPU operator provided by MindData to preprocess images.</span>

<span class="c1">// Create an operator to encode the input into the RGB format.</span>
<span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">ds</span><span class="o">::</span><span class="n">TensorTransform</span><span class="o">&gt;</span><span class="w"> </span><span class="n">decode</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">ds</span><span class="o">::</span><span class="n">vision</span><span class="o">::</span><span class="n">Decode</span><span class="p">());</span>
<span class="c1">// Create an operator to resize the image to the specified size.</span>
<span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">ds</span><span class="o">::</span><span class="n">TensorTransform</span><span class="o">&gt;</span><span class="w"> </span><span class="n">resize</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">ds</span><span class="o">::</span><span class="n">vision</span><span class="o">::</span><span class="n">Resize</span><span class="p">({</span><span class="mi">256</span><span class="p">}));</span>
<span class="c1">// Create an operator to normalize the input of the operator.</span>
<span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">ds</span><span class="o">::</span><span class="n">TensorTransform</span><span class="o">&gt;</span><span class="w"> </span><span class="n">normalize</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">ds</span><span class="o">::</span><span class="n">vision</span><span class="o">::</span><span class="n">Normalize</span><span class="p">(</span>
<span class="w">    </span><span class="p">{</span><span class="mf">0.485</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">255</span><span class="p">,</span><span class="w"> </span><span class="mf">0.456</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">255</span><span class="p">,</span><span class="w"> </span><span class="mf">0.406</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">255</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mf">0.229</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">255</span><span class="p">,</span><span class="w"> </span><span class="mf">0.224</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">255</span><span class="p">,</span><span class="w"> </span><span class="mf">0.225</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">255</span><span class="p">}));</span>
<span class="c1">// Create an operator to perform central cropping.</span>
<span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">ds</span><span class="o">::</span><span class="n">TensorTransform</span><span class="o">&gt;</span><span class="w"> </span><span class="n">center_crop</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">ds</span><span class="o">::</span><span class="n">vision</span><span class="o">::</span><span class="n">CenterCrop</span><span class="p">({</span><span class="mi">224</span><span class="p">,</span><span class="w"> </span><span class="mi">224</span><span class="p">}));</span>
<span class="c1">// Create an operator to transform shape (H, W, C) into shape (C, H, W).</span>
<span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">ds</span><span class="o">::</span><span class="n">TensorTransform</span><span class="o">&gt;</span><span class="w"> </span><span class="n">hwc2chw</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">ds</span><span class="o">::</span><span class="n">vision</span><span class="o">::</span><span class="n">HWC2CHW</span><span class="p">());</span>

<span class="c1">// Define a MindData data preprocessing function that contains the preceding operators in sequence.</span>
<span class="n">ds</span><span class="o">::</span><span class="n">Execute</span><span class="w"> </span><span class="nf">preprocessor</span><span class="p">({</span><span class="n">decode</span><span class="p">,</span><span class="w"> </span><span class="n">resize</span><span class="p">,</span><span class="w"> </span><span class="n">normalize</span><span class="p">,</span><span class="w"> </span><span class="n">center_crop</span><span class="p">,</span><span class="w"> </span><span class="n">hwc2chw</span><span class="p">});</span>

<span class="c1">// Call the data preprocessing function to obtain the processed image.</span>
<span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">preprocessor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">image</span><span class="p">);</span>
</pre></div>
</div>
<p>Start inference.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Create an output vector.</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">ms</span><span class="o">::</span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">outputs</span><span class="p">;</span>
<span class="c1">// Create an input vector.</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">ms</span><span class="o">::</span><span class="n">MSTensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">inputs</span><span class="p">;</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">Name</span><span class="p">(),</span><span class="w"> </span><span class="n">model_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">DataType</span><span class="p">(),</span><span class="w"> </span><span class="n">model_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">Shape</span><span class="p">(),</span>
<span class="w">                    </span><span class="n">image</span><span class="p">.</span><span class="n">Data</span><span class="p">().</span><span class="n">get</span><span class="p">(),</span><span class="w"> </span><span class="n">image</span><span class="p">.</span><span class="n">DataSize</span><span class="p">());</span>
<span class="c1">// Call the Predict function of the model for inference.</span>
<span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">resnet50</span><span class="p">.</span><span class="n">Predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs</span><span class="p">);</span>
</pre></div>
</div>
<p>Obtain the inference result.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Maximum value of the output probability.</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Image: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">image_file</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; infer result: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">GetMax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</pre></div>
</div>
</section>
<section id="build-script">
<h2>Build Script<a class="headerlink" href="#build-script" title="Permalink to this headline"></a></h2>
<p>Add the header file search path for the compiler:</p>
<div class="highlight-cmake notranslate"><div class="highlight"><pre><span></span><span class="nb">option</span><span class="p">(</span><span class="s">MINDSPORE_PATH</span><span class="w"> </span><span class="s2">&quot;mindspore install path&quot;</span><span class="w"> </span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">include_directories</span><span class="p">(</span><span class="o">${</span><span class="nv">MINDSPORE_PATH</span><span class="o">}</span><span class="p">)</span>
<span class="nb">include_directories</span><span class="p">(</span><span class="o">${</span><span class="nv">MINDSPORE_PATH</span><span class="o">}</span><span class="s">/include</span><span class="p">)</span>
</pre></div>
</div>
<p>Search for the required dynamic library in MindSpore.</p>
<div class="highlight-cmake notranslate"><div class="highlight"><pre><span></span><span class="nb">find_library</span><span class="p">(</span><span class="s">MS_LIB</span><span class="w"> </span><span class="s">libmindspore.so</span><span class="w"> </span><span class="o">${</span><span class="nv">MINDSPORE_PATH</span><span class="o">}</span><span class="s">/lib</span><span class="p">)</span>
<span class="nb">file</span><span class="p">(</span><span class="s">GLOB_RECURSE</span><span class="w"> </span><span class="s">MD_LIB</span><span class="w"> </span><span class="o">${</span><span class="nv">MINDSPORE_PATH</span><span class="o">}</span><span class="s">/_c_dataengine*</span><span class="p">)</span>
</pre></div>
</div>
<p>Use the specified source file to generate the target executable file and link the target file to the MindSpore library.</p>
<div class="highlight-cmake notranslate"><div class="highlight"><pre><span></span><span class="nb">add_executable</span><span class="p">(</span><span class="s">resnet50_sample</span><span class="w"> </span><span class="s">main.cc</span><span class="p">)</span>
<span class="nb">target_link_libraries</span><span class="p">(</span><span class="s">resnet50_sample</span><span class="w"> </span><span class="o">${</span><span class="nv">MS_LIB</span><span class="o">}</span><span class="w"> </span><span class="o">${</span><span class="nv">MD_LIB</span><span class="o">}</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><p>For details, see
<a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.5/docs/sample_code/ascend910_resnet50_preprocess_sample/CMakeLists.txt">https://gitee.com/mindspore/docs/blob/r1.5/docs/sample_code/ascend910_resnet50_preprocess_sample/CMakeLists.txt</a></p>
</div></blockquote>
</section>
<section id="building-inference-code">
<h2>Building Inference Code<a class="headerlink" href="#building-inference-code" title="Permalink to this headline"></a></h2>
<p>Go to the project directory <code class="docutils literal notranslate"><span class="pre">ascend910_resnet50_preprocess_sample</span></code> and set the following environment variables:</p>
<blockquote>
<div><p>If the device is Ascend 310, go to the project directory <code class="docutils literal notranslate"><span class="pre">ascend310_resnet50_preprocess_sample</span></code>. The following code uses Ascend 910 as an example.</p>
</div></blockquote>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Control the log print level. 0 indicates DEBUG, 1 indicates INFO, 2 indicates WARNING (default value), and 3 indicates ERROR.</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">GLOG_v</span><span class="o">=</span><span class="m">2</span>

<span class="c1"># Select the Conda environment.</span>
<span class="nv">LOCAL_ASCEND</span><span class="o">=</span>/usr/local/Ascend<span class="w"> </span><span class="c1"># Root directory of the running package</span>

<span class="c1"># Library on which the running package depends</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">LOCAL_ASCEND</span><span class="si">}</span>/ascend-toolkit/latest/fwkacllib/lib64:<span class="si">${</span><span class="nv">LOCAL_ASCEND</span><span class="si">}</span>/driver/lib64/common:<span class="si">${</span><span class="nv">LOCAL_ASCEND</span><span class="si">}</span>/driver/lib64/driver:<span class="si">${</span><span class="nv">LOCAL_ASCEND</span><span class="si">}</span>/opp/op_impl/built-in/ai_core/tbe/op_tiling:<span class="si">${</span><span class="nv">LD_LIBRARY_PATH</span><span class="si">}</span>

<span class="c1"># Libraries on which MindSpore depends</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="sb">`</span>pip3<span class="w"> </span>show<span class="w"> </span>mindspore-ascend<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>Location<span class="w"> </span><span class="p">|</span><span class="w"> </span>awk<span class="w"> </span><span class="s1">&#39;{print $2&quot;/mindspore/lib&quot;}&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>xargs<span class="w"> </span>realpath<span class="sb">`</span>:<span class="si">${</span><span class="nv">LD_LIBRARY_PATH</span><span class="si">}</span>

<span class="c1"># Configure necessary environment variables.</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">TBE_IMPL_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">LOCAL_ASCEND</span><span class="si">}</span>/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe<span class="w">            </span><span class="c1"># Path of the TBE operator</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">ASCEND_OPP_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">LOCAL_ASCEND</span><span class="si">}</span>/ascend-toolkit/latest/opp<span class="w">                                       </span><span class="c1"># OPP path</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">LOCAL_ASCEND</span><span class="si">}</span>/ascend-toolkit/latest/fwkacllib/ccec_compiler/bin/:<span class="si">${</span><span class="nv">PATH</span><span class="si">}</span><span class="w">                 </span><span class="c1"># Path of the TBE operator build tool</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">PYTHONPATH</span><span class="o">=</span><span class="si">${</span><span class="nv">TBE_IMPL_PATH</span><span class="si">}</span>:<span class="si">${</span><span class="nv">PYTHONPATH</span><span class="si">}</span><span class="w">                                                       </span><span class="c1"># Python library that TBE depends on</span>
</pre></div>
</div>
<p>Run the <code class="docutils literal notranslate"><span class="pre">cmake</span></code> command. In the command, <code class="docutils literal notranslate"><span class="pre">pip3</span></code> needs to be modified based on the actual situation:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cmake<span class="w"> </span>.<span class="w"> </span>-DMINDSPORE_PATH<span class="o">=</span><span class="sb">`</span>pip3<span class="w"> </span>show<span class="w"> </span>mindspore-ascend<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>Location<span class="w"> </span><span class="p">|</span><span class="w"> </span>awk<span class="w"> </span><span class="s1">&#39;{print $2&quot;/mindspore&quot;}&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>xargs<span class="w"> </span>realpath<span class="sb">`</span>
</pre></div>
</div>
<p>Run the <code class="docutils literal notranslate"><span class="pre">make</span></code> command for building.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>make
</pre></div>
</div>
<p>After building, the executable <code class="docutils literal notranslate"><span class="pre">main</span></code> file is generated in <code class="docutils literal notranslate"><span class="pre">ascend910_resnet50_preprocess_sample</span></code>.</p>
</section>
<section id="performing-inference-and-viewing-the-result">
<h2>Performing Inference and Viewing the Result<a class="headerlink" href="#performing-inference-and-viewing-the-result" title="Permalink to this headline"></a></h2>
<p>After the preceding operations are complete, you can learn how to perform inference.</p>
<p>Log in to the Ascend 910 environment, and create the <code class="docutils literal notranslate"><span class="pre">model</span></code> directory to store the <code class="docutils literal notranslate"><span class="pre">resnet50_imagenet.mindir</span></code> file, for example, <code class="docutils literal notranslate"><span class="pre">/home/HwHiAiUser/mindspore_sample/ascend910_resnet50_preprocess_sample/model</span></code>.
Create the <code class="docutils literal notranslate"><span class="pre">test_data</span></code> directory to store images, for example, <code class="docutils literal notranslate"><span class="pre">/home/HwHiAiUser/mindspore_sample/ascend910_resnet50_preprocess_sample/test_data</span></code>.
Then, perform the inference.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./resnet50_sample
</pre></div>
</div>
<p>Inference is performed on all images stored in the <code class="docutils literal notranslate"><span class="pre">test_data</span></code> directory. For example, if there are 2 images whose label is 0 in the <a class="reference external" href="http://image-net.org/download-images">ImageNet2012</a> validation set, the inference result is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Image: ./test_data/ILSVRC2012_val_00002138.JPEG infer result: 0
Image: ./test_data/ILSVRC2012_val_00003014.JPEG infer result: 0
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="save_load_model.html" class="btn btn-neutral float-left" title="Saving and Loading the Model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="linear_regression.html" class="btn btn-neutral float-right" title="Simple Linear Function Fitting" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>