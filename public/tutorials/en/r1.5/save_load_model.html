<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Saving and Loading the Model &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Inference" href="inference.html" />
    <link rel="prev" title="Training the Model" href="optimization.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">Quick Start for Beginners</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Loading and Processing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Building a Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="autograd.html">Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimization.html">Training the Model</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Saving and Loading the Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#saving-the-model">Saving the Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#saving-the-model-directly">Saving the Model Directly</a></li>
<li class="toctree-l3"><a class="reference internal" href="#saving-the-model-during-training">Saving the Model During Training</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#loading-the-model">Loading the Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#validating-the-model">Validating the Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#for-transfer-learning">For Transfer Learning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#exporting-the-model">Exporting the Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#exporting-a-mindir-file">Exporting a MindIR File</a></li>
<li class="toctree-l3"><a class="reference internal" href="#exporting-in-other-formats">Exporting in Other Formats</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#exporting-an-air-file">Exporting an AIR File</a></li>
<li class="toctree-l4"><a class="reference internal" href="#exporting-an-onnx-file">Exporting an ONNX File</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="linear_regression.html">Simple Linear Function Fitting</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Saving and Loading the Model</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/save_load_model.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="saving-and-loading-the-model">
<h1>Saving and Loading the Model<a class="headerlink" href="#saving-and-loading-the-model" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Export</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Loading</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.5/tutorials/source_en/save_load_model.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source_en.png"></a></p>
<p>In the previous tutorial, you learn how to train the network. In this tutorial, you will learn how to save and load a model, and how to export a saved model in a specified format to different platforms for inference.</p>
<section id="saving-the-model">
<h2>Saving the Model<a class="headerlink" href="#saving-the-model" title="Permalink to this headline"></a></h2>
<p>There are two main ways to save the interface of the model:</p>
<ol class="arabic simple">
<li><p>One is to simply save the network model, which can be saved before and after training. The advantage is that the interface is simple and easy to use, but only the state of the network model when the command is executed is retained;</p></li>
<li><p>The other one is to save the interface during networkmodel training. In the process of network model training,MindSpore automatically saves the parameters of the epochnumber and step number set during training, that is, theintermediate weight parameters generated during the modeltraining process are also saved to facilitate networkfine-tuning and stop training.</p></li>
</ol>
<section id="saving-the-model-directly">
<h3>Saving the Model Directly<a class="headerlink" href="#saving-the-model-directly" title="Permalink to this headline"></a></h3>
<p>Use the save_checkpoint provided by MindSpore to save the model, pass it to the network and save the path:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="c1"># The defined network model is net, which is generally used before or after training</span>
<span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="s2">&quot;./MyNet.ckpt&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">net</span></code> is the training network, and the definition method can be referred to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.5/model.html">Building a Neural Network</a>.</p>
</section>
<section id="saving-the-model-during-training">
<h3>Saving the Model During Training<a class="headerlink" href="#saving-the-model-during-training" title="Permalink to this headline"></a></h3>
<p>In the process of model training, use the <code class="docutils literal notranslate"><span class="pre">callbacks</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">model.train</span></code> to pass in the object <code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> that saves the model, which can save the model parameters and generate CheckPoint (abbreviated as ckpt) files.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>

<span class="n">ckpt_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">ckpt_cb</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">epoch_num</span></code> is the number of times that the dataset is traversed during training. The definition method can be referred to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.5/optimization.html">Training the Model</a>. <code class="docutils literal notranslate"><span class="pre">dataset</span></code> is the dataset to be loaded. The definition method can be referred to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.5/dataset.html">Loading and Processing Data</a>.</p>
<p>You can configure the checkpoint policies as required. The following describes the usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">CheckpointConfig</span>

<span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ckpt_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;resnet50&#39;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">ckpt_cb</span><span class="p">)</span>
</pre></div>
</div>
<p>In the preceding code, you need to initialize a <code class="docutils literal notranslate"><span class="pre">CheckpointConfig</span></code> class object to set the saving policy.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">save_checkpoint_steps</span></code> indicates the interval (in steps) for saving the checkpoint file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">keep_checkpoint_max</span></code> indicates the maximum number of checkpoint files that can be retained.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prefix</span></code> indicates the prefix of the generated checkpoint file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">directory</span></code> indicates the directory for storing files.</p></li>
</ul>
<p>Create a <code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> object and pass it to the <code class="docutils literal notranslate"><span class="pre">model.train</span></code> method. Then the checkpoint function can be used during training.</p>
<p>The generated checkpoint file is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>resnet50-graph.meta # Computational graph after build.
resnet50-1_32.ckpt  # The extension of the checkpoint file is .ckpt.
resnet50-2_32.ckpt  # The file name format contains the epoch and step correspond to the saved parameters.
resnet50-3_32.ckpt  # The file name indicates that the model parameters generated during the 32nd step of the third epoch are saved.
...
</pre></div>
</div>
<p>If you use the same prefix and run the training script for multiple times, checkpoint files with the same name may be generated. To help users distinguish files generated each time, MindSpore adds underscores (_) and digits to the end of the user-defined prefix. If you want to delete the <code class="docutils literal notranslate"><span class="pre">.ckpt</span></code> file, delete the <code class="docutils literal notranslate"><span class="pre">.meta</span></code> file at the same time.</p>
<p>For example, <code class="docutils literal notranslate"><span class="pre">resnet50_3-2_32.ckpt</span></code> indicates the checkpoint file generated during the 32nd step of the second epoch after the script is executed for the third time.</p>
</section>
</section>
<section id="loading-the-model">
<h2>Loading the Model<a class="headerlink" href="#loading-the-model" title="Permalink to this headline"></a></h2>
<p>To load the model weight, you need to create an instance of the same model and then use the <code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code> and <code class="docutils literal notranslate"><span class="pre">load_param_into_net</span></code> methods to load parameters.</p>
<p>The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>

<span class="n">resnet</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">()</span>
<span class="c1"># Store model parameters in the parameter dictionary.</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50-2_32.ckpt&quot;</span><span class="p">)</span>
<span class="c1"># Load parameters to the network.</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;accuracy&quot;</span><span class="p">})</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code> method loads the network parameters in the parameter file to the <code class="docutils literal notranslate"><span class="pre">param_dict</span></code> dictionary.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">load_param_into_net</span></code> method loads the parameters in the <code class="docutils literal notranslate"><span class="pre">param_dict</span></code> dictionary to the network or optimizer. After the loading, parameters in the network are stored by the checkpoint.</p></li>
</ul>
<section id="validating-the-model">
<h3>Validating the Model<a class="headerlink" href="#validating-the-model" title="Permalink to this headline"></a></h3>
<p>In the inference-only scenario, parameters are directly loaded to the network for subsequent inference and validation. The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define a validation dataset.</span>
<span class="n">dataset_eval</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">mnist_path</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">),</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Call eval() for inference.</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset_eval</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="for-transfer-learning">
<h3>For Transfer Learning<a class="headerlink" href="#for-transfer-learning" title="Permalink to this headline"></a></h3>
<p>You can load network parameters and optimizer parameters to the model in the case of task interruption, retraining, and fine-tuning. The sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the number of training epochs.</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># Define a training dataset.</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">mnist_path</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">),</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># Call train() for training.</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="exporting-the-model">
<h2>Exporting the Model<a class="headerlink" href="#exporting-the-model" title="Permalink to this headline"></a></h2>
<p>During model training, you can add checkpoints to save model parameters for inference and retraining. If you want to perform inference on different hardware platforms, you can generate MindIR, AIR, or ONNX files based on the network and checkpoint files.</p>
<p>The following describes how to save a checkpoint file and export a MindIR, AIR, or ONNX file.</p>
<blockquote>
<div><p>MindSpore is an all-scenario AI framework that uses MindSpore IR to unify intermediate representation of network models. Therefore, you are advised to export files in MindIR format.</p>
</div></blockquote>
<section id="exporting-a-mindir-file">
<h3>Exporting a MindIR File<a class="headerlink" href="#exporting-a-mindir-file" title="Permalink to this headline"></a></h3>
<p>If you want to perform inference across platforms or hardware (such as the Ascend AI Processors, MindSpore devices, or GPUs) after obtaining a checkpoint file, you can define the network and checkpoint to generate a model file in MINDIR format. Currently, the inference network export based on static graphs is supported and does not contain control flow semantics. An example of the code for exporting the file is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">export</span><span class="p">,</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">resnet</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">()</span>
<span class="c1"># Store model parameters in the parameter dictionary.</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50-2_32.ckpt&quot;</span><span class="p">)</span>

<span class="c1"># Load parameters to the network.</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">export</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;resnet50-2_32&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;MINDIR&#39;</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">input</span></code> specifies the input shape and data type of the exported model. If the network has multiple inputs, you need to pass them to the <code class="docutils literal notranslate"><span class="pre">export</span></code> method.  Example: <code class="docutils literal notranslate"><span class="pre">export(network,</span> <span class="pre">Tensor(input1),</span> <span class="pre">Tensor(input2),</span> <span class="pre">file_name='network',</span> <span class="pre">file_format='MINDIR')</span></code></p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">file_name</span></code> does not contain the “.mindir” suffix, the system will automatically add the “.mindir” suffix to it.</p></li>
</ul>
</div></blockquote>
</section>
<section id="exporting-in-other-formats">
<h3>Exporting in Other Formats<a class="headerlink" href="#exporting-in-other-formats" title="Permalink to this headline"></a></h3>
<section id="exporting-an-air-file">
<h4>Exporting an AIR File<a class="headerlink" href="#exporting-an-air-file" title="Permalink to this headline"></a></h4>
<p>If you want to perform inference on the Ascend AI Processor after obtaining a checkpoint file, use the network and checkpoint to generate a model file in AIR format. An example of the code for exporting the file is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">export</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;resnet50-2_32&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;AIR&#39;</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">input</span></code> specifies the input shape and data type of the exported model. If the network has multiple inputs, you need to pass them to the <code class="docutils literal notranslate"><span class="pre">export</span></code> method. Example: <code class="docutils literal notranslate"><span class="pre">export(network,</span> <span class="pre">Tensor(input1),</span> <span class="pre">Tensor(input2),</span> <span class="pre">file_name='network',</span> <span class="pre">file_format='AIR')</span></code></p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">file_name</span></code> does not contain the “.air” suffix, the system will automatically add the “.air” suffix to it.</p></li>
</ul>
</div></blockquote>
</section>
<section id="exporting-an-onnx-file">
<h4>Exporting an ONNX File<a class="headerlink" href="#exporting-an-onnx-file" title="Permalink to this headline"></a></h4>
<p>If you want to perform inference on other third-party hardware after obtaining a checkpoint file, use the network and checkpoint to generate a model file in ONNX format. An example of the code for exporting the file is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">export</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;resnet50-2_32&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;ONNX&#39;</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">input</span></code> specifies the input shape and data type of the exported model. If the network has multiple inputs, you need to pass them to the <code class="docutils literal notranslate"><span class="pre">export</span></code> method. Example: <code class="docutils literal notranslate"><span class="pre">export(network,</span> <span class="pre">Tensor(input1),</span> <span class="pre">Tensor(input2),</span> <span class="pre">file_name='network',</span> <span class="pre">file_format='ONNX')</span></code></p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">file_name</span></code> does not contain the “.onnx” suffix, the system will automatically add the “.onnx” suffix to it.</p></li>
<li><p>Currently, only the ONNX format export of ResNet series networks and BERT are supported.</p></li>
</ul>
</div></blockquote>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="optimization.html" class="btn btn-neutral float-left" title="Training the Model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="inference.html" class="btn btn-neutral float-right" title="Inference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>