<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Image Data Processing and Augmentation &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script><script src="../../_static/jquery.js"></script>
        <script src="../../_static/js/theme.js"></script><script src="../../_static/underscore.js"></script><script src="../../_static/doctools.js"></script><script src="../../_static/js/training.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script><script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Training and Evaluation" href="../train.html" />
    <link rel="prev" title="Common Data Processing and Augmentation" href="augment_common_data.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introduction.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/quick_start.html">Quickstart: Handwritten Digit Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/dataset.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/model.html">Building a Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/autograd.html">Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/train.html">Model Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/save_load.html">Saving and Loading the Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/infer.html">Inference and Deployment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../dataset.html">Data Processing</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="record.html">Converting Dataset to MindRecord</a></li>
<li class="toctree-l2"><a class="reference internal" href="augment_common_data.html">Common Data Processing and Augmentation</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Image Data Processing and Augmentation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#load-image-data">Load Image Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mindspore.dataset.vision module">mindspore.dataset.vision module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#randomcrop">RandomCrop</a></li>
<li class="toctree-l4"><a class="reference internal" href="#randomhorizontalflip">RandomHorizontalFlip</a></li>
<li class="toctree-l4"><a class="reference internal" href="#resize">Resize</a></li>
<li class="toctree-l4"><a class="reference internal" href="#invert">Invert</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#deprecated-c-transforms-and-py-transforms">Deprecated <code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> and <code class="docutils literal notranslate"><span class="pre">py_transforms</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#special-attention">Special Attention</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../train.html">Training and Evaluation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../dataset.html">Data Processing</a> &raquo;</li>
      <li>Image Data Processing and Augmentation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/advanced/dataset/augment_image_data.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="image-data-processing-and-augmentation">
<h1>Image Data Processing and Augmentation<a class="headerlink" href="#image-data-processing-and-augmentation" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/r1.8/tutorials/en/advanced/dataset/mindspore_augment_image_data.ipynb"><img alt="Download Notebook" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_notebook_en.png" /></a>  <a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/r1.8/tutorials/en/advanced/dataset/mindspore_augment_image_data.py"><img alt="Download Sample Code" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_download_code_en.png" /></a>  <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.8/tutorials/source_en/advanced/dataset/augment_image_data.ipynb"><img alt="View source files in Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_source_en.png" /></a></p>
<p>In a computer vision task, if the data volume is small or the scenario samples are simple, the training accuracy will be affected. In this case, you may preprocess images by performing image augmentation, to improve generalization of the model.</p>
<p>MindSpore provides the <code class="docutils literal notranslate"><span class="pre">vision</span></code> module for image augmentation.</p>
<p>The following sections will take the CIFAR-10 dataset and the MNIST dataset as examples to briefly introduce these two image data loading methods and use several commonly used vision augmentation operations. For more image dataset loading methods, refer to the API documentation <a class="reference external" href="https://www.mindspore.cn/docs/en/r1.8/api_python/mindspore.dataset.html#vision">mindspore.dataset</a>. For more vision augmentation operations, refer to the API documentation
<a class="reference external" href="https://www.mindspore.cn/docs/en/r1.8/api_python/mindspore.dataset.vision.html">mindspore.dataset.vision</a>.</p>
<section id="load-image-data">
<h2>Load Image Data<a class="headerlink" href="#load-image-data" title="Permalink to this headline"></a></h2>
<ol class="arabic simple">
<li><p>The following sample code downloads and decompresses the CIFAR-10 dataset and the MNIST dataset to the specified locations, respectively. This code is expected to take three to five minutes to execute when the network is in good condition.</p></li>
</ol>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">mindvision.dataset</span> <span class="kn">import</span> <span class="n">DownLoad</span>

<span class="n">dl_path_cifar10</span> <span class="o">=</span> <span class="s2">&quot;./datasets&quot;</span>
<span class="n">dl_url_cifar10</span> <span class="o">=</span> <span class="s2">&quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/cifar-10-binary.tar.gz&quot;</span>

<span class="n">dl</span> <span class="o">=</span> <span class="n">DownLoad</span><span class="p">()</span>

<span class="c1"># Download the CIFAR-10 dataset and unzip it</span>
<span class="n">dl</span><span class="o">.</span><span class="n">download_and_extract_archive</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">dl_url_cifar10</span><span class="p">,</span> <span class="n">download_path</span><span class="o">=</span><span class="n">dl_path_cifar10</span><span class="p">)</span>

<span class="c1"># MNIST dataset save path</span>
<span class="n">dl_path_mnist</span> <span class="o">=</span> <span class="s2">&quot;./mnist&quot;</span>
<span class="n">dl_url_mnist_labels</span> <span class="o">=</span> <span class="s2">&quot;http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz&quot;</span>
<span class="n">dl_url_mnist_images</span> <span class="o">=</span> <span class="s2">&quot;http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz&quot;</span>

<span class="c1"># Download the MNIST dataset and unzip it</span>
<span class="n">dl</span><span class="o">.</span><span class="n">download_and_extract_archive</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">dl_url_mnist_labels</span><span class="p">,</span> <span class="n">download_path</span><span class="o">=</span><span class="n">dl_path_mnist</span><span class="p">)</span>
<span class="n">dl</span><span class="o">.</span><span class="n">download_and_extract_archive</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">dl_url_mnist_images</span><span class="p">,</span> <span class="n">download_path</span><span class="o">=</span><span class="n">dl_path_mnist</span><span class="p">)</span>

<span class="n">image_gz</span> <span class="o">=</span> <span class="s2">&quot;./mnist/train-images-idx3-ubyte.gz&quot;</span>
<span class="n">label_gz</span> <span class="o">=</span> <span class="s2">&quot;./mnist/train-labels-idx1-ubyte.gz&quot;</span>

<span class="c1"># Delete compressed files</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">image_gz</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">image_gz</span><span class="p">)</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">label_gz</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">label_gz</span><span class="p">)</span>
</pre></div>
</div>
</div>
<ol class="arabic simple" start="2">
<li><p>Use the <a class="reference external" href="https://www.mindspore.cn/docs/en/r1.8/api_python/dataset/mindspore.dataset.Cifar10Dataset.html#mindspore.dataset.Cifar10Dataset">mindspore.dataset.Cifar10Dataset</a> interface to load the CIFAR-10 data, and use the <a class="reference external" href="https://www.mindspore.cn/docs/en/r1.8/api_python/dataset/mindspore.dataset.MnistDataset.html#mindspore.dataset.MnistDataset">mindspore.dataset.MnistDataset</a> interface to load the MNIST data. The example code is as follows:</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">DATA_DIR_MNIST</span> <span class="o">=</span> <span class="s2">&quot;./mnist/&quot;</span>
<span class="n">DATA_DIR_CIFAR10</span> <span class="o">=</span> <span class="s2">&quot;./datasets/cifar-10-batches-bin/&quot;</span>

<span class="n">ds</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Load the dataset and select 4 images</span>
<span class="n">dataset_cifar10</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">DATA_DIR_CIFAR10</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">dataset_mnist</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MnistDataset</span><span class="p">(</span><span class="n">DATA_DIR_MNIST</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">printDataset</span><span class="p">(</span><span class="n">dataset_list</span><span class="p">,</span> <span class="n">name_list</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show dataset&quot;&quot;&quot;</span>
    <span class="n">dataset_sizes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">dataset_list</span><span class="p">:</span>
        <span class="n">dataset_sizes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">())</span>
    <span class="n">row</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset_list</span><span class="p">)</span>      <span class="c1"># Displayed number of rows</span>
    <span class="n">column</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">dataset_sizes</span><span class="p">)</span>  <span class="c1"># Displayed number of columns</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">pos</span><span class="p">)</span>                          <span class="c1"># Display location</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray</span><span class="p">)</span>  <span class="c1"># Display content</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>                               <span class="c1"># Show title</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">name_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="s2">&quot; shape:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;label:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
            <span class="n">pos</span> <span class="o">=</span> <span class="n">pos</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">column</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">printDataset</span><span class="p">([</span><span class="n">dataset_cifar10</span><span class="p">,</span> <span class="n">dataset_mnist</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;CIFAR-10&quot;</span><span class="p">,</span> <span class="s2">&quot;MNIST&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CIFAR-10  shape: (32, 32, 3) label: 9
CIFAR-10  shape: (32, 32, 3) label: 2
CIFAR-10  shape: (32, 32, 3) label: 0
CIFAR-10  shape: (32, 32, 3) label: 8
MNIST  shape: (28, 28, 1) label: 7
MNIST  shape: (28, 28, 1) label: 2
MNIST  shape: (28, 28, 1) label: 4
MNIST  shape: (28, 28, 1) label: 4
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/advanced_dataset_augment_image_data_3_1.png" src="../../_images/advanced_dataset_augment_image_data_3_1.png" />
</div>
</div>
</section>
<section id="mindspore.dataset.vision module">
<h2>mindspore.dataset.vision module<a class="headerlink" href="#mindspore.dataset.vision module" title="Permalink to this headline"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">vision</span></code> is a module that supports vision augmentations. Some image augmentations are implemented with C++ OpenCV to provide high performance. Other additional image augmentations are developed with Python PIL.</p>
<p>To explicitly use OpenCV implementation, use the <code class="docutils literal notranslate"><span class="pre">Decode(to_pil=False)</span></code> operation to decode images and subsequent operations will have an OpenCV implemented operation selected(if it exists). To explicitly switch to PIL implementation in the data pipeline, use the <code class="docutils literal notranslate"><span class="pre">ToPIL()</span></code> operation followed by the desired operations.</p>
<p>To explicitly use PIL implementation, use the <code class="docutils literal notranslate"><span class="pre">Decode(to_pil=True)</span></code> operation to decode images and subsequent operations will have a PIL implemented operation selectedif(if it exists). To explicitly switch to OpenCV implementation in the data pipeline, use the <code class="docutils literal notranslate"><span class="pre">ToNumpy()</span></code> operation followed by the desired operations.</p>
<p>The following section shows some simple examples with a few vision operations.</p>
<section id="randomcrop">
<h3>RandomCrop<a class="headerlink" href="#randomcrop" title="Permalink to this headline"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">RandomCrop</span></code> operation crops the input image at a random location.</p>
<p>Parameter Description:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">size</span></code>: The output size of the cropped image.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">padding</span></code>: The number of pixels to pad each border of the image.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pad_if_needed</span></code>: Pad the image if either side is smaller than the given output size.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fill_value</span></code>: The pixel intensity of the borders.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">padding_mode</span></code>: The method of padding.</p></li>
</ul>
<p>The following example first uses the sequential sampler to load the CIFAR-10 dataset, then randomly crops the loaded image with a length and width of 10, and finally outputs the image shape and corresponding label before and after the crop, and displays the image.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision</span> <span class="k">as</span> <span class="nn">vision</span>

<span class="n">ds</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># CIFAR-10 dataset loading path</span>
<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="s2">&quot;./datasets/cifar-10-batches-bin/&quot;</span>

<span class="c1"># Pick 3 images using the SequentialSampler sampler</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">SequentialSampler</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>

<span class="c1"># Use RandomCrop to perform 10*10 random cropping operations on the original image</span>
<span class="n">random_crop</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">dataset2</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">random_crop</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>

<span class="n">printDataset</span><span class="p">([</span><span class="n">dataset1</span><span class="p">,</span> <span class="n">dataset2</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Source image&quot;</span><span class="p">,</span> <span class="s2">&quot;Cropped image&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Source image  shape: (32, 32, 3) label: 6
Source image  shape: (32, 32, 3) label: 9
Source image  shape: (32, 32, 3) label: 9
Cropped image  shape: (10, 10, 3) label: 6
Cropped image  shape: (10, 10, 3) label: 9
Cropped image  shape: (10, 10, 3) label: 9
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/advanced_dataset_augment_image_data_5_1.png" src="../../_images/advanced_dataset_augment_image_data_5_1.png" />
</div>
</div>
<p>As can be seen from the above printing and displayed image results, before and after the image is randomly cropped, the label does not change, but the shape changes. The resolution of the image before cropping is 32×32, and the resolution after cropping is 10×10.</p>
</section>
<section id="randomhorizontalflip">
<h3>RandomHorizontalFlip<a class="headerlink" href="#randomhorizontalflip" title="Permalink to this headline"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">RandomHorizontalFlip</span></code> operation randomly flips the input image horizontally.</p>
<p>Parameter Description:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code>: Probability of the image being flipped.</p></li>
</ul>
<p>The following example first uses the random sampler to load the CIFAR-10 dataset, then randomly flips the loaded image horizontally with a probability of 0.8, and finally outputs the image shape and corresponding label before and after the flip, and displays the image.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision</span> <span class="k">as</span> <span class="nn">vision</span>

<span class="n">ds</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># CIFAR-10 dataset loading path</span>
<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="s2">&quot;./datasets/cifar-10-batches-bin/&quot;</span>

<span class="c1"># Randomly pick 4 images using the RandomSampler sampler</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">RandomSampler</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>

<span class="c1"># Use RandomHorizontalFlip to randomly flip the original image horizontally</span>
<span class="n">random_horizontal_flip</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">dataset2</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">random_horizontal_flip</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>

<span class="n">printDataset</span><span class="p">([</span><span class="n">dataset1</span><span class="p">,</span> <span class="n">dataset2</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Source image&quot;</span><span class="p">,</span> <span class="s2">&quot;Flipped image&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Source image  shape: (32, 32, 3) label: 7
Source image  shape: (32, 32, 3) label: 8
Source image  shape: (32, 32, 3) label: 2
Source image  shape: (32, 32, 3) label: 9
Flipped image  shape: (32, 32, 3) label: 7
Flipped image  shape: (32, 32, 3) label: 8
Flipped image  shape: (32, 32, 3) label: 2
Flipped image  shape: (32, 32, 3) label: 9
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/advanced_dataset_augment_image_data_7_1.png" src="../../_images/advanced_dataset_augment_image_data_7_1.png" />
</div>
</div>
<p>It can be seen from the above printing and displayed image results that after the random horizontal flip operation, the shape and label of the image have not changed, and some images have been flipped horizontally.</p>
</section>
<section id="resize">
<h3>Resize<a class="headerlink" href="#resize" title="Permalink to this headline"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">Resize</span></code> operation scales the input image to the given size.</p>
<p>Parameter Description:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">size</span></code>: The output size of the resized image.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">interpolation</span></code>: Image interpolation mode.</p></li>
</ul>
<p>The following example first loads the <a class="reference external" href="#references">MNIST dataset [2]</a>, then scales the loaded image to (101, 101) size, and finally outputs the image shape and corresponding label before and after scaling, and displays the image.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision</span> <span class="k">as</span> <span class="nn">vision</span>

<span class="c1"># MNIST dataset loading path</span>
<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="s2">&quot;./mnist/&quot;</span>

<span class="c1"># Load the MNIST dataset and select 4 images</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MnistDataset</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Scale the image to 101x101 using the Resize operation</span>
<span class="n">resize</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">101</span><span class="p">,</span> <span class="mi">101</span><span class="p">])</span>
<span class="n">dataset2</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">resize</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>

<span class="n">printDataset</span><span class="p">([</span><span class="n">dataset1</span><span class="p">,</span> <span class="n">dataset2</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Source image&quot;</span><span class="p">,</span> <span class="s2">&quot;Resized image&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Source image  shape: (28, 28, 1) label: 5
Source image  shape: (28, 28, 1) label: 0
Source image  shape: (28, 28, 1) label: 4
Source image  shape: (28, 28, 1) label: 1
Resized image  shape: (101, 101, 1) label: 5
Resized image  shape: (101, 101, 1) label: 0
Resized image  shape: (101, 101, 1) label: 4
Resized image  shape: (101, 101, 1) label: 1
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/advanced_dataset_augment_image_data_9_1.png" src="../../_images/advanced_dataset_augment_image_data_9_1.png" />
</div>
</div>
<p>As can be seen from the above printing and displayed image results, before and after scaling, the shape of the image has changed, but the label has not changed. The image resolution before scaling is 28×28, and after scaling, the image resolution is 101×101.</p>
</section>
<section id="invert">
<h3>Invert<a class="headerlink" href="#invert" title="Permalink to this headline"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">Invert</span></code> operation inverts the input image in RGB mode.</p>
<p>The following example first loads the CIFAR-10 dataset, then defines and applies the invert operation on the loaded image, and finally outputs the image shape and label before and after inversion, and displays the image.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision</span> <span class="k">as</span> <span class="nn">vision</span>

<span class="n">ds</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">18</span><span class="p">)</span>

<span class="c1"># CIFAR-10 dataset loading path</span>
<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="s2">&quot;./datasets/cifar-10-batches-bin/&quot;</span>

<span class="c1"># Load the CIFAR-10 dataset and select 4 images</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Invert the image</span>
<span class="n">invert</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">Invert</span><span class="p">()</span>
<span class="n">dataset2</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">invert</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>

<span class="n">printDataset</span><span class="p">([</span><span class="n">dataset1</span><span class="p">,</span> <span class="n">dataset2</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Source image&quot;</span><span class="p">,</span> <span class="s2">&quot;Inverted image&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Source image  shape: (32, 32, 3) label: 8
Source image  shape: (32, 32, 3) label: 1
Source image  shape: (32, 32, 3) label: 9
Source image  shape: (32, 32, 3) label: 7
Inverted image  shape: (32, 32, 3) label: 8
Inverted image  shape: (32, 32, 3) label: 1
Inverted image  shape: (32, 32, 3) label: 9
Inverted image  shape: (32, 32, 3) label: 7
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/advanced_dataset_augment_image_data_11_1.png" src="../../_images/advanced_dataset_augment_image_data_11_1.png" />
</div>
</div>
<p>As can be seen from the above printing and displayed image results, before and after the inversion operation, the shape and label of the image have not changed, but the color has changed.</p>
</section>
</section>
<section id="deprecated-c-transforms-and-py-transforms">
<h2>Deprecated <code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> and <code class="docutils literal notranslate"><span class="pre">py_transforms</span></code><a class="headerlink" href="#deprecated-c-transforms-and-py-transforms" title="Permalink to this headline"></a></h2>
<p>Beginning in version 1.8 of MindSpore, the following vision modules are deprecated:</p>
<ul class="simple">
<li><p>mindspore.dataset.vision.c_transforms</p></li>
<li><p>mindspore.dataset.vision.py_transforms</p></li>
</ul>
<p>One should use the following unified module for which the underlying implementation may be C++ OpenCV code and/or Python PIL code:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.mindspore.cn/docs/en/r1.8/api_python/mindspore.dataset.vision.html">mindspore.dataset.vision</a></p></li>
</ul>
<section id="special-attention">
<h3>Special Attention<a class="headerlink" href="#special-attention" title="Permalink to this headline"></a></h3>
<p>When upgrading from the deprecated <code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> or <code class="docutils literal notranslate"><span class="pre">py_transforms</span></code> modules to the unified modules, the same operation that was used in <code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> or <code class="docutils literal notranslate"><span class="pre">py_transforms</span></code> can be used with no changes in operation name or input arguments.</p>
<p>Except for the following cases:</p>
<p>From deprecated <code class="docutils literal notranslate"><span class="pre">mindspore.dataset.vision.py_transforms</span></code>, when using unified <code class="docutils literal notranslate"><span class="pre">mindspore.dataset.vision</span></code>:</p>
<ul class="simple">
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">Decode()</span></code> with new argument <code class="docutils literal notranslate"><span class="pre">to_pil=True</span></code> for <code class="docutils literal notranslate"><span class="pre">Decode(to_pil=True)</span></code></p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">Cutout(...)</span></code> with unified operation name and new argument <code class="docutils literal notranslate"><span class="pre">is_hwc=False</span></code> for <code class="docutils literal notranslate"><span class="pre">CutOut(...,</span> <span class="pre">is_hwc=False)</span></code></p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">Normalize(...)</span></code> with new argument <code class="docutils literal notranslate"><span class="pre">is_hwc=False</span></code> for <code class="docutils literal notranslate"><span class="pre">Normalize(...,</span> <span class="pre">is_hwc=False)</span></code></p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">NormalizePad(...)</span></code> with new argument <code class="docutils literal notranslate"><span class="pre">is_hwc=False</span></code> for <code class="docutils literal notranslate"><span class="pre">NormalizePad(...,</span> <span class="pre">is_hwc=False)</span></code></p></li>
</ul>
<p>From deprecated <code class="docutils literal notranslate"><span class="pre">mindspore.dataset.vision.py_transforms</span></code> or <code class="docutils literal notranslate"><span class="pre">mindspore.dataset.vision.c_transforms</span></code>, when using unified <code class="docutils literal notranslate"><span class="pre">mindspore.dataset.vision</span></code>:</p>
<ul class="simple">
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">RgbToBgr</span></code> with unified operation name <code class="docutils literal notranslate"><span class="pre">ConvertColor</span></code></p></li>
</ul>
<p>From deprecated <code class="docutils literal notranslate"><span class="pre">mindspore.dataset.vision.py_transforms:</span></code></p>
<ul class="simple">
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">ToType</span></code> with unified operation name <code class="docutils literal notranslate"><span class="pre">TypeCast</span></code> in unified <code class="docutils literal notranslate"><span class="pre">mindspore.dataset.transforms</span></code></p></li>
</ul>
<blockquote>
<div><p>Please notice that when the operation throws an error, the error message provided from the deprecated operation may be different from the error message provided from the unified operation.</p>
</div></blockquote>
</section>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline"></a></h2>
<p>[1] Alex Krizhevsky. <a class="reference external" href="http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf">Learning_Multiple Layers of Features from Tiny Images</a>.</p>
<p>[2] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. <a class="reference external" href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf">Gradient-based learning applied to document recognition</a>.</p>
<blockquote>
<div><p>The sample code in this chapter relies on third-party support package <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code>, which can be installed using the command <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">matplotlib</span></code>. If this document is run under <code class="docutils literal notranslate"><span class="pre">Notebook</span></code>, you need to restart the kernel after installation to execute subsequent code.</p>
</div></blockquote>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="augment_common_data.html" class="btn btn-neutral float-left" title="Common Data Processing and Augmentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../train.html" class="btn btn-neutral float-right" title="Training and Evaluation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>