

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Saving and Exporting Models &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script src="../../_static/js/training.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="Training and Evaluation" href="../train.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introduction.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/quick_start.html">Quickstart: Handwritten Digit Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/dataset.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/model.html">Building a Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/autograd.html">Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/train.html">Model Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/save_load.html">Saving and Loading the Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/infer.html">Inference and Deployment</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../dataset.html">Data Processing</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../train.html">Training and Evaluation</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Saving and Exporting Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#saving-the-models">Saving the models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#saving-the-models-during-the-training">Saving the models during the training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#saving-models-directly">saving models directly</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#transfer-learning">Transfer Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-export">Model Export</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#export-mindir-model">Export MindIR Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#export-onnx-model">Export ONNX Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#export-air-model">Export AIR Model</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../train.html">Training and Evaluation</a> &raquo;</li>
        
      <li>Saving and Exporting Models</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/advanced/train/save.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="saving-and-exporting-models">
<h1>Saving and Exporting Models<a class="headerlink" href="#saving-and-exporting-models" title="Permalink to this headline">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.8/tutorials/source_en/advanced/train/save.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_source_en.png"></a></p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>During model training, you can add CheckPoints to save model parameters for inference and retraining after interruption. If you want to perform inference on different hardware platforms, you need to generate corresponding MindIR, AIR and ONNX format files based on the network and CheckPoint format files.</p>
<ul class="simple">
<li><p><strong>CheckPoint</strong>: The Protocol Buffers mechanism is adopted, which stores all the parameter values in the network. It is generally used to resume training after a training task is interrupted, or in a Fine Tune task after training.</p></li>
<li><p><strong>MindIR</strong>: MindSpore IR, is a kind of functional IR based on graph representation of MindSpore, which defines the extensible graph structure and the IR representation of the operator, and stores the network structure and weight parameter values. It eliminates model differences between different backends and is generally used to perform inference tasks across hardware platforms, such as performing inference on the Ascend 910 trained model on the Ascend 310, GPU, and MindSpore Lite side.</p></li>
<li><p><strong>ONNX</strong>: Open Neural Network Exchange, is an open file format designed for machine learning, storing both network structure and weight parameter values. Typically used for model migration between different frameworks or for use on the Inference Engine (TensorRT).</p></li>
<li><p><strong>AIR</strong>: Ascend Intermediate Representation, is an open file format defined by Huawei for machine learning, and stores network structure and weight parameter values, which can better adapt to Ascend AI processors. It is generally used to perform inference tasks on Ascend 310.</p></li>
</ul>
<p>The following uses examples to describe how to save MindSpore CheckPoint files, and how to export MindIR, AIR and ONNX files.</p>
</div>
<div class="section" id="saving-the-models">
<h2>Saving the models<a class="headerlink" href="#saving-the-models" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference external" href="https://mindspore.cn/tutorials/zh-CN/r1.8/beginner/save_load.html">Save and Load section</a> of the beginner tutorials describes how to save model parameters directly using <code class="docutils literal notranslate"><span class="pre">save_checkpoint</span></code> and using the Callback mechanism to save model parameters during training. This section further describes how to save model parameters during training and use <code class="docutils literal notranslate"><span class="pre">save_checkpoint</span></code> save model parameters directly.</p>
<div class="section" id="saving-the-models-during-the-training">
<h3>Saving the models during the training<a class="headerlink" href="#saving-the-models-during-the-training" title="Permalink to this headline">¶</a></h3>
<p>Saving model parameters during training. MindSpore provides two saving strategies, an iteration policy and a time policy, which can be set by creating a <code class="docutils literal notranslate"><span class="pre">CheckpointConfig</span></code> object. The iteration policy and the time policy cannot be used at the same time, where the iterative policy takes precedence over the time policy, and when set at the same time, only iteration policy can take effect. When the parameter display is set to None, the policy is abandoned. In addition, when an exception occurs during training, MindSpore also provides a breakpoint retrain function, that is, the system will automatically save the CheckPoint file when the exception occurs.</p>
<ol>
<li><p>Iteration policy</p>
<p><code class="docutils literal notranslate"><span class="pre">CheckpointConfig</span></code> can be configured according to the number of iterations, and the parameters of the iteration policy are as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">save_checkpoint_steps</span></code>: indicates how many CheckPoint files are saved every step, with a default value of 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">keep_checkpoint_max</span></code>: indicates how many CheckPoint files to save at most, with a default value of 5.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="c1"># Save one CheckPoint file every 32 steps, and up to 10 CheckPoint files</span>
<span class="n">config_ck</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>In the case that the iteration policy script ends normally, the CheckPoint file of the last step is saved by default.</p>
</li>
<li><p>Time policy</p>
<p><code class="docutils literal notranslate"><span class="pre">CheckpointConfig</span></code> can be configured according to the training duration, and the parameters of the configuration time policy are as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">save_checkpoint_seconds</span></code>: indicates how many seconds to save a CheckPoint file, with a default value of 0.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">keep_checkpoint_per_n_minutes</span></code>: indicates how many checkPoint files are kept every few minutes, with a default value of 0.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="c1"># Save a CheckPoint file every 30 seconds and a CheckPoint file every 3 minutes</span>
<span class="n">config_ck</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_seconds</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">keep_checkpoint_per_n_minutes</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">save_checkpoint_seconds</span></code> parameters cannot be used with <code class="docutils literal notranslate"><span class="pre">save_checkpoint_steps</span></code> parameters. If both parameters are set, the <code class="docutils literal notranslate"><span class="pre">save_checkpoint_seconds</span></code> parameters are invalid.</p>
</li>
<li><p>Breakpoint renewal</p>
<p>MindSpore provides a breakpoint renewal function, when the user turns on the function, if an exception occurs during training, MindSpore will automatically save the CheckPoint file (end-of-life CheckPoint) when the exception occurred. The function of breakpoint renewal is controlled by the <code class="docutils literal notranslate"><span class="pre">exception_save</span></code> parameter (bool type) in CheckpointConfig, which is turned on when set to True, and closed by False, which defaults to False. The end-of-life CheckPoint file saved by the breakpoint continuation function does not affect the CheckPoint saved in the normal process, and the naming mechanism and save path are consistent with the normal process settings, the only difference is that the ‘_breakpoint’ will be added at the end of the end of the CheckPoint file name to distinguish. Its usage is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="c1"># Configure the breakpoint continuation function to turn on</span>
<span class="n">config_ck</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">exception_save</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>If an exception occurs during training, the end-of-life CheckPoint is automatically saved, and if an exception occurs in the 10th step of the 10th epoch in the training, the saved end-of-life CheckPoint file is as follows.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># The end-of-life CheckPoint file name will be marked by &#39;_breakpoint&#39; to distinguish it from the normal process checkPoint.
resnet50-10_10_breakpoint.ckpt  
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="saving-models-directly">
<h3>saving models directly<a class="headerlink" href="#saving-models-directly" title="Permalink to this headline">¶</a></h3>
<p>You can use <code class="docutils literal notranslate"><span class="pre">save_checkpoint</span></code> function to save network weight parameters in the memory to a CheckPoint file directly, and the common parameters are as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">save_obj</span></code>: Cell object or data list.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ckpt_file_name</span></code>: Checkpoint file name. If the file already exists, the original file will be overwritten.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">integrated_save</span></code>: Whether to merge or save split Tensor in parallel scenarios. The default value is True.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">async_save</span></code>: Whether to execute asynchronously save the checkpoint file. The default value is False.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">append_dict</span></code>: Additional information that needs to be saved. The key of dict must be of type str, and the value type of dict must be float or bool. The default value is None.</p></li>
</ul>
<ol>
<li><p><code class="docutils literal notranslate"><span class="pre">save_obj</span></code> parameter</p>
<p>The <a class="reference external" href="https://mindspore.cn/tutorials/zh-CN/r1.8/beginner/save_load.html">Save and Load section</a> of the beginner tutorials describes how to save model parameters directly using <code class="docutils literal notranslate"><span class="pre">save_checkpoint</span></code> when <code class="docutils literal notranslate"><span class="pre">save_obj</span></code> is a Cell object. Here’s how to save model parameters when you pass in a list of data. When passing in a data list, each element of the list is of dictionary type, such as [{“name”: param_name, “data”: param_data} ,…], <code class="docutils literal notranslate"><span class="pre">param_name</span></code> type must be str, and the type of <code class="docutils literal notranslate"><span class="pre">param_data</span></code> must be Parameter or Tensor. An example is shown below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">save_list</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)},</span> <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;train_epoch&quot;</span><span class="p">,</span> <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)}]</span>
<span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">save_list</span><span class="p">,</span> <span class="s2">&quot;hyper_param.ckpt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">integrated_save</span></code> parameter</p>
<p>indicates whether the parameters are saved in a merge, and the default is True. In the model parallel scenario, Tensor is split into programs run by different cards. If integrated_save is set to True, these split Tensors are merged and saved in each checkpoint file, so that the checkpoint file saves the complete training parameters.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="s2">&quot;resnet50-2_32.ckpt&quot;</span><span class="p">,</span> <span class="n">integrated_save</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">async_save</span></code> parameter</p>
<p>indicates whether the asynchronous save function is enabled, which defaults to False. If set to True, multithreading is turned on to write checkpoint files, allowing training and save tasks to be performed in parallel, saving the total time the script runs when training large-scale networks.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="s2">&quot;resnet50-2_32.ckpt&quot;</span><span class="p">,</span> <span class="n">async_save</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">append_dict</span></code> parameter</p>
<p>additional information needs to be saved, the type is dict type, and currently only supports the preservation of basic types, including int, float, bool, etc</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">save_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;epoch_num&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">}</span>
<span class="c1"># In addition to the parameters in net, the information save_dict is also saved in the ckpt file</span>
<span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="s2">&quot;resnet50-2_32.ckpt&quot;</span><span class="p">,</span> <span class="n">append_dict</span><span class="o">=</span><span class="n">save_dict</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</div>
</div>
<div class="section" id="transfer-learning">
<h2>Transfer Learning<a class="headerlink" href="#transfer-learning" title="Permalink to this headline">¶</a></h2>
<p>In the transfer learning scenario, when using a pre-trained model for training, the model parameters in the CheckPoint file cannot be used directly, and they need to be modified according to the actual situation to be suitable for the current network model. This section describes how to remove the fully connected layer parameter from a pre-trained model for Resnet50.</p>
<p>First download the <a class="reference external" href="https://download.mindspore.cn/vision/classification/resnet50_224.ckpt">pre-trained model of Resnet50</a>, which is trained on the ImageNet dataset by the <code class="docutils literal notranslate"><span class="pre">resnet50</span></code> model in <a class="reference external" href="https://mindspore.cn/vision/docs/en/r0.1/index.html">MindSpore Vision</a>.</p>
<p>The training model is loaded using the <code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code> interface, which returns a Ditt type, the dictionary’s key is the name of each layer of the network, the type is the character Type Str; the value, dictionary value is the parameter value of the network layer, and the type is Parameter.</p>
<p>In the following example, since the number of classification classes of the Resnet50 pre-trained model is 1000, and the number of classification classes of the resnet50 network defined in the example is 2, the fully connected layer parameter in the pre-trained model needs to be deleted.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindvision.classification.models</span> <span class="kn">import</span> <span class="n">resnet50</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindvision.dataset</span> <span class="kn">import</span> <span class="n">DownLoad</span>

<span class="c1"># Download the pre-trained model for Resnet50</span>
<span class="n">dl</span> <span class="o">=</span> <span class="n">DownLoad</span><span class="p">()</span>
<span class="n">dl</span><span class="o">.</span><span class="n">download_url</span><span class="p">(</span><span class="s1">&#39;https://download.mindspore.cn/vision/classification/resnet50_224.ckpt&#39;</span><span class="p">)</span>
<span class="c1"># Define a resnet50 network with a classification class of 2</span>
<span class="n">resnet</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="c1"># Model parameters are saved to the param_dict</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50_224.ckpt&quot;</span><span class="p">)</span>

<span class="c1"># Get a list of parameter names for the fully connected layer</span>
<span class="n">param_filter</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">resnet</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()]</span>

<span class="k">def</span> <span class="nf">filter_ckpt_parameter</span><span class="p">(</span><span class="n">origin_dict</span><span class="p">,</span> <span class="n">param_filter</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Delete elements including param_filter parameter names in the origin_dict&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">origin_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span> <span class="c1"># Get all parameter names for the model</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">param_filter</span><span class="p">:</span> <span class="c1"># Iterate over the parameter names in the model to be deleted</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Delete parameter from checkpoint:&quot;</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
                <span class="k">del</span> <span class="n">origin_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                <span class="k">break</span>

<span class="c1"># Delete the full connection layer</span>
<span class="n">filter_ckpt_parameter</span><span class="p">(</span><span class="n">param_dict</span><span class="p">,</span> <span class="n">param_filter</span><span class="p">)</span>

<span class="c1"># Prints the updated model parameters</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Delete parameter from checkpoint: head.dense.weight
Delete parameter from checkpoint: head.dense.bias
</pre></div>
</div>
</div>
<div class="section" id="model-export">
<h2>Model Export<a class="headerlink" href="#model-export" title="Permalink to this headline">¶</a></h2>
<p>MindSpore’s <code class="docutils literal notranslate"><span class="pre">export</span></code> can export network models as files in a specified format for inference on other hardware platforms. The main parameters of <code class="docutils literal notranslate"><span class="pre">export</span></code> are as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">net</span></code>: MindSpore network structure.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputs</span></code>: The input of the network, the supported input type is Tensor. When there are multiple inputs, they need to be passed in together, such as <code class="docutils literal notranslate"><span class="pre">export(network,</span> <span class="pre">Tensor(input1),</span> <span class="pre">Tensor(input2),</span> <span class="pre">file_name='network',</span> <span class="pre">file_format='MINDIR')</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">file_name</span></code>: Export the file name of the model, if the <code class="docutils literal notranslate"><span class="pre">file_name</span></code> does not contain the corresponding suffix name (such as .mindir), the system will automatically add a suffix to the file name after setting the <code class="docutils literal notranslate"><span class="pre">file_format</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">file_format</span></code>: MindSpore currently supports exporting models in “AIR”, “ONNX” and “MINDIR” formats.</p></li>
</ul>
<p>The following describes the use of <code class="docutils literal notranslate"><span class="pre">export</span></code> to generate corresponding MindIR, AIR and ONNX format files for the resnet50 network and the corresponding CheckPoint format files.</p>
<div class="section" id="export-mindir-model">
<h3>Export MindIR Model<a class="headerlink" href="#export-mindir-model" title="Permalink to this headline">¶</a></h3>
<p>If you want to perform inference across platforms or hardware (Ascend AI processor, MindSpore on-device, GPU, etc.), you can generate the corresponding MindIR format model file through the network definition and CheckPoint. MindIR format file can be applied to MindSpore Lite. Currently, it supports inference network based on static graph mode. The following is to use the <code class="docutils literal notranslate"><span class="pre">resnet50</span></code> model in MindSpore Vision and the model file resnet50_224.ckpt trained by the model on the ImageNet dataset to export the MindIR format file.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindvision.classification.models</span> <span class="kn">import</span> <span class="n">resnet50</span>

<span class="n">resnet</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50_224.ckpt&quot;</span><span class="p">,</span> <span class="n">net</span><span class="o">=</span><span class="n">resnet</span><span class="p">)</span>

<span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Export the file resnet50_224.mindir to the current folder</span>
<span class="n">ms</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">input_np</span><span class="p">),</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;resnet50_224&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;MINDIR&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>If you wish to save the data preprocess operations into MindIR and use them to perform inference, you can pass the Dataset object into export method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision</span> <span class="k">as</span> <span class="nn">vision</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindvision.classification.models</span> <span class="kn">import</span> <span class="n">resnet50</span>
<span class="kn">from</span> <span class="nn">mindvision.dataset</span> <span class="kn">import</span> <span class="n">DownLoad</span>

<span class="k">def</span> <span class="nf">create_dataset_for_renset</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset&quot;&quot;&quot;</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">ImageFolderDataset</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.485</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.456</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.406</span> <span class="o">*</span> <span class="mi">255</span><span class="p">]</span>
    <span class="n">std</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.229</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.224</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.225</span> <span class="o">*</span> <span class="mi">255</span><span class="p">]</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="p">[</span><span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span> <span class="n">vision</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span> <span class="n">vision</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
                                        <span class="n">vision</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">),</span> <span class="n">vision</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()],</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">)</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data_set</span>

<span class="n">dataset_url</span> <span class="o">=</span> <span class="s2">&quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/beginner/DogCroissants.zip&quot;</span>
<span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;./datasets&quot;</span>
<span class="c1"># Download and extract the dataset</span>
<span class="n">dl</span> <span class="o">=</span> <span class="n">DownLoad</span><span class="p">()</span>
<span class="n">dl</span><span class="o">.</span><span class="n">download_and_extract_archive</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">dataset_url</span><span class="p">,</span> <span class="n">download_path</span><span class="o">=</span><span class="n">path</span><span class="p">)</span>
<span class="c1"># Load the dataset</span>
<span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;./datasets/DogCroissants/val/&quot;</span>
<span class="n">de_dataset</span> <span class="o">=</span> <span class="n">create_dataset_for_renset</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="c1"># Define the network</span>
<span class="n">resnet</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">()</span>

<span class="c1"># Load the preprocessing model parameters into the network</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50_224.ckpt&quot;</span><span class="p">,</span> <span class="n">net</span><span class="o">=</span><span class="n">resnet</span><span class="p">)</span>
<span class="c1"># Export a MindIR file with preprocessing information</span>
<span class="n">ms</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">de_dataset</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;resnet50_224&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;MINDIR&#39;</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">file_name</span></code> does not contain the “.mindir” suffix, the system will automatically add the “.mindir” suffix to it.</p></li>
</ul>
</div></blockquote>
<p>In order to avoid the hardware limitation of Protocol Buffers, when the exported model parameter size exceeds 1G, the framework will save the network structure and parameters separately by default.</p>
<ul class="simple">
<li><p>The name of the network structure file ends with the user-specified prefix plus _graph.mindir.</p></li>
<li><p>In the same level directory, there will be a folder with user-specified prefix plus _variables, which stores network parameters.
And when the parameter’s data size exceeds 1T, it will split to another file named data_1, data_2, etc.</p></li>
</ul>
<p>Taking the above code as an example, if the parameter size with the model exceeds 1G, the generated directory structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>├── resnet50_224_graph.mindir
└── resnet50_224_variables
    ├── data_1
    ├── data_2
    └── data_3
</pre></div>
</div>
</div>
<div class="section" id="export-onnx-model">
<h3>Export ONNX Model<a class="headerlink" href="#export-onnx-model" title="Permalink to this headline">¶</a></h3>
<p>When you have a CheckPoint file, if you want to do inference on Ascend AI processor, GPU, or CPU, you need to generate ONNX models based on the network and CheckPoint. The following is to use the <code class="docutils literal notranslate"><span class="pre">resnet50</span></code> model in MindSpore Vision and the model file trained by the model on the ImageNet dataset resnet50_224.ckpt, and export the ONNX format file.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindvision.classification.models</span> <span class="kn">import</span> <span class="n">resnet50</span>

<span class="n">resnet</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">()</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50_224.ckpt&quot;</span><span class="p">,</span> <span class="n">net</span><span class="o">=</span><span class="n">resnet</span><span class="p">)</span>

<span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Save the resnet50_224.onnx file to the current directory</span>
<span class="n">ms</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">input_np</span><span class="p">),</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;resnet50_224&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;ONNX&#39;</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">file_name</span></code> does not contain the “.onnx” suffix, the system will automatically add the “.onnx” suffix to it.</p></li>
<li><p>Currently, only the ONNX format export of ResNet series networks, YOLOV3, YOLOV4 and BERT are supported.</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="export-air-model">
<h3>Export AIR Model<a class="headerlink" href="#export-air-model" title="Permalink to this headline">¶</a></h3>
<p>If you want to perform inference on the Ascend AI processor, you can also generate the corresponding AIR format model file through the network definition and CheckPoint. The following is to use the <code class="docutils literal notranslate"><span class="pre">resnet50</span></code> model in MindSpore Vision and the model file trained by the model on the ImageNet dataset resnet50_224.ckpt, and export the AIR format file on the Ascend AI processor.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindvision.classification.models</span> <span class="kn">import</span> <span class="n">resnet50</span>

<span class="n">resnet</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">()</span>
<span class="c1"># Load parameters into the network</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50_224.ckpt&quot;</span><span class="p">,</span> <span class="n">net</span><span class="o">=</span><span class="n">resnet</span><span class="p">)</span>
<span class="c1"># Network input</span>
<span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># Save the resnet50_224.air file to the current directory</span>
<span class="n">ms</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">input_np</span><span class="p">),</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;resnet50_224&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;AIR&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>If file_name does not contain the “.air” suffix, the system will automatically add the “.air” suffix to it.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../train.html" class="btn btn-neutral float-left" title="Training and Evaluation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>