<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Basic Usage of Models &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script><script src="../../_static/jquery.js"></script>
        <script src="../../_static/js/theme.js"></script><script src="../../_static/underscore.js"></script><script src="../../_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Callback Mechanism" href="callback.html" />
    <link rel="prev" title="Evaluation Metrics" href="metric.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introduction.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/dataset.html">Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/transforms.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/model.html">Building a Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/autograd.html">Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/train.html">Model Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/save_load.html">Saving and Loading the Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../model.html">Advanced Encapsulation: Model</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="metric.html">Evaluation Metrics</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Basic Usage of Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#introduction-to-model">Introduction to Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#using-the-model-api">Using the Model API</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#download-and-process-dataset">Download and Process Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#define-model">Define Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#define-loss-function-and-optimizer">Define loss function and optimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#train-and-save-model">Train and Save Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="callback.html">Callback Mechanism</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">Module Customization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset.html">Advanced Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../derivation.html">Advanced Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compute_graph.html">Computation Graphs</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../model.html">Advanced Encapsulation: Model</a> &raquo;</li>
      <li>Basic Usage of Models</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/advanced/model/model.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="basic-usage-of-models">
<h1>Basic Usage of Models<a class="headerlink" href="#basic-usage-of-models" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.9/tutorials/source_en/advanced/model/model.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.9/resource/_static/logo_source_en.png" /></a></p>
<p>Generally, defining a training and evaluation network and running it directly can meet basic requirements.</p>
<p>On the one hand, <code class="docutils literal notranslate"><span class="pre">Model</span></code> can simplify code to some extent. For example, you do not need to manually traverse datasets. If you do not need to customize <code class="docutils literal notranslate"><span class="pre">nn.TrainOneStepCell</span></code>, you can use <code class="docutils literal notranslate"><span class="pre">Model</span></code> to automatically build a training network. You can use the <code class="docutils literal notranslate"><span class="pre">eval</span></code> API of <code class="docutils literal notranslate"><span class="pre">Model</span></code> to evaluate the model and directly output the evaluation result. You do not need to manually invoke the <code class="docutils literal notranslate"><span class="pre">clear</span></code>, <code class="docutils literal notranslate"><span class="pre">update</span></code>, and <code class="docutils literal notranslate"><span class="pre">eval</span></code> functions of evaluation metrics.</p>
<p>On the other hand, <code class="docutils literal notranslate"><span class="pre">Model</span></code> provides many high-level functions, such as data offloading and mixed precision. Without the help of <code class="docutils literal notranslate"><span class="pre">Model</span></code>, it takes a long time to customize these functions by referring to <code class="docutils literal notranslate"><span class="pre">Model</span></code>.</p>
<p>The following describes MindSpore models and how to use <code class="docutils literal notranslate"><span class="pre">Model</span></code> for model training, evaluation, and inference.</p>
<p><img alt="model" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.9/tutorials/source_en/advanced/model/images/model.png" /></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset</span> <span class="kn">import</span> <span class="n">MnistDataset</span><span class="p">,</span> <span class="n">vision</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">LossMonitor</span>
</pre></div>
</div>
<section id="introduction-to-model">
<h2>Introduction to Model<a class="headerlink" href="#introduction-to-model" title="Permalink to this headline"></a></h2>
<p><a class="reference external" href="https://www.mindspore.cn/docs/en/r1.9/api_python/mindspore/mindspore.Model.html#mindspore.Model">Model</a> is a high-level API provided by MindSpore for model training, evaluation, and inference. The common parameters of the API are as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">network</span></code>: neural network used for training or inference.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">loss_fn</span></code>: used loss function.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optimizer</span></code>: used optimizer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">metrics</span></code>: evaluation function used for model evaluation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eval_network</span></code>: network used for model evaluation. If the network is not defined, <code class="docutils literal notranslate"><span class="pre">Model</span></code> uses <code class="docutils literal notranslate"><span class="pre">network</span></code> and <code class="docutils literal notranslate"><span class="pre">loss_fn</span></code> for encapsulation.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Model</span></code> provides the following APIs for model training, evaluation, and inference:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">fit</span></code>: used to evaluate the model during training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train</span></code>: used for model training on the training set.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eval</span></code>: used to evaluate the model on the evaluation set.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">predict</span></code>: performs inference on a group of input data and outputs the prediction result.</p></li>
</ul>
<section id="using-the-model-api">
<h3>Using the Model API<a class="headerlink" href="#using-the-model-api" title="Permalink to this headline"></a></h3>
<p>For a neural network in a simple scenario, you can specify the feedforward network <code class="docutils literal notranslate"><span class="pre">network</span></code>, loss function <code class="docutils literal notranslate"><span class="pre">loss_fn</span></code>, optimizer <code class="docutils literal notranslate"><span class="pre">optimizer</span></code>,
and evaluation function <code class="docutils literal notranslate"><span class="pre">metrics</span></code> when defining <code class="docutils literal notranslate"><span class="pre">Model</span></code>.</p>
</section>
</section>
<section id="download-and-process-dataset">
<h2>Download and Process Dataset<a class="headerlink" href="#download-and-process-dataset" title="Permalink to this headline"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download data from open datasets</span>
<span class="kn">from</span> <span class="nn">download</span> <span class="kn">import</span> <span class="n">download</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/&quot;</span> \
      <span class="s2">&quot;notebook/datasets/MNIST_Data.zip&quot;</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="s2">&quot;./&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;zip&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">datapipe</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">image_transforms</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.3081</span><span class="p">,)),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="p">]</span>
    <span class="n">label_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">dataset</span> <span class="o">=</span> <span class="n">MnistDataset</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">image_transforms</span><span class="p">,</span> <span class="s1">&#39;image&#39;</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">label_transform</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dataset</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">datapipe</span><span class="p">(</span><span class="s1">&#39;MNIST_Data/train&#39;</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">datapipe</span><span class="p">(</span><span class="s1">&#39;MNIST_Data/test&#39;</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="define-model">
<h2>Define Model<a class="headerlink" href="#define-model" title="Permalink to this headline"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define model</span>
<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense_relu_sequential</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_relu_sequential</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="define-loss-function-and-optimizer">
<h2>Define loss function and optimizer<a class="headerlink" href="#define-loss-function-and-optimizer" title="Permalink to this headline"></a></h2>
<p>To train neural network model, loss function and optimizer function need to be defined.</p>
<ul class="simple">
<li><p>The loss function here uses <code class="docutils literal notranslate"><span class="pre">CrossEntropy</span> <span class="pre">Loss</span></code> .</p></li>
<li><p>The optimizer uses SGD here.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiate loss function and optimizer</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mf">1e-2</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="train-and-save-model">
<h2>Train and Save Model<a class="headerlink" href="#train-and-save-model" title="Permalink to this headline"></a></h2>
<p>Before starting the training, MindSpot needs to state in advance whether the network model needs to save the intermediate process and results
during the training process. Therefore, <code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> is used to save the network model and parameters for subsequent fine tuning.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">)</span>

<span class="n">ckpt_callback</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;mnist&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;./checkpoint&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="n">loss_callback</span> <span class="o">=</span> <span class="n">LossMonitor</span><span class="p">(</span><span class="n">steps_per_epoch</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">model.fit</span></code> provided by MindSpore can facilitate network training, and <code class="docutils literal notranslate"><span class="pre">LossMonitor</span></code> can monitor the change of loss value during training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;accuracy&#39;</span><span class="p">})</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ckpt_callback</span><span class="p">,</span> <span class="n">loss_callback</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 1 step: 937, loss is 0.5313149094581604
Eval result: epoch 1, metrics: {&#39;accuracy&#39;: 0.8557692307692307}
epoch: 2 step: 937, loss is 0.2875961363315582
Eval result: epoch 2, metrics: {&#39;accuracy&#39;: 0.9007411858974359}
epoch: 3 step: 937, loss is 0.19009104371070862
Eval result: epoch 3, metrics: {&#39;accuracy&#39;: 0.9191706730769231}
epoch: 4 step: 937, loss is 0.24231787025928497
Eval result: epoch 4, metrics: {&#39;accuracy&#39;: 0.9296875}
epoch: 5 step: 937, loss is 0.16016671061515808
Eval result: epoch 5, metrics: {&#39;accuracy&#39;: 0.9386017628205128}
epoch: 6 step: 937, loss is 0.4830142855644226
Eval result: epoch 6, metrics: {&#39;accuracy&#39;: 0.9444110576923077}
epoch: 7 step: 937, loss is 0.20778779685497284
Eval result: epoch 7, metrics: {&#39;accuracy&#39;: 0.9508213141025641}
epoch: 8 step: 937, loss is 0.22020074725151062
Eval result: epoch 8, metrics: {&#39;accuracy&#39;: 0.9540264423076923}
epoch: 9 step: 937, loss is 0.15951070189476013
Eval result: epoch 9, metrics: {&#39;accuracy&#39;: 0.9575320512820513}
epoch: 10 step: 937, loss is 0.11161471903324127
Eval result: epoch 10, metrics: {&#39;accuracy&#39;: 0.9608373397435898}
</pre></div>
</div>
<p>During training, the loss value will be printed, and the loss value will fluctuate, but in general, the loss value will gradually decrease and
the accuracy will gradually improve. The loss values run by each person are random and not necessarily identical.</p>
<p>The results obtained by running the test data set of the model verify the generalization ability of the model:</p>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">model.eval</span></code> to read in the test data set.</p></li>
<li><p>Use the saved model parameters for reasoning.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">acc</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>
<span class="n">acc</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{&#39;accuracy&#39;: 0.9641}
</pre></div>
</div>
<p>The model precision data can be seen from the print information. In the example, the precision data reaches more than 95%, and the model quality
is good. As the number of network iterations increases, the accuracy of the model will be further improved.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="metric.html" class="btn btn-neutral float-left" title="Evaluation Metrics" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="callback.html" class="btn btn-neutral float-right" title="Callback Mechanism" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>