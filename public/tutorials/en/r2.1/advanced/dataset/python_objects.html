<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Supporting Python Objects in Dataset Pipeline &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script><script src="../../_static/jquery.js"></script>
        <script src="../../_static/js/theme.js"></script><script src="../../_static/underscore.js"></script><script src="../../_static/doctools.js"></script><script src="../../_static/js/training.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Advanced Automatic Differentiation" href="../derivation.html" />
    <link rel="prev" title="Lightweight Data Processing" href="eager.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introduction.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/dataset.html">Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/transforms.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/model.html">Building a Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/autograd.html">Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/train.html">Model Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/save_load.html">Saving and Loading the Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../model.html">Advanced Encapsulation: Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">Model Module Customization</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../dataset.html">Advanced Data Processing</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="sampler.html">Data Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="record.html">Converting Dataset to MindRecord</a></li>
<li class="toctree-l2"><a class="reference internal" href="eager.html">Lightweight Data Processing</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Supporting Python Objects in Dataset Pipeline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../derivation.html">Advanced Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compute_graph.html">Computational Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mixed_precision.html">Automatic Mix Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../error_analysis.html">Error Reporting Analysis</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../dataset.html">Advanced Data Processing</a> &raquo;</li>
      <li>Supporting Python Objects in Dataset Pipeline</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/advanced/dataset/python_objects.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.1/tutorials/source_en/advanced/dataset/python_objects.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.1/resource/_static/logo_source_en.svg" /></a></p>
<section id="supporting-python-objects-in-dataset-pipeline">
<h1>Supporting Python Objects in Dataset Pipeline<a class="headerlink" href="#supporting-python-objects-in-dataset-pipeline" title="Permalink to this headline"></a></h1>
<p>Dataset pipeline accepts any Python type as input for some operations(such as <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>、user defined <code class="docutils literal notranslate"><span class="pre">map</span></code> operation、<code class="docutils literal notranslate"><span class="pre">batch(per_batch_map=...)</span></code>). To achieve this feature, Dataset pipeline uses Python <code class="docutils literal notranslate"><span class="pre">dict</span></code> to manager different types. The main difference compared to other data types is that Python <code class="docutils literal notranslate"><span class="pre">dict</span></code> will not be converted to a C++ type, and instead a reference will be maintained in the pipeline.</p>
<p>Note that while currently Dataset pipeline supports to recognize <code class="docutils literal notranslate"><span class="pre">dict</span></code> objects, you can also wrap other Python types inside a dictionary and send them to Dataset pipeline to achieve the same behavior. This article describes how to construct dictionary type to Dataset pipeline and acquire through iterator.</p>
<section id="sending-python-dict-to-dataset-pipeline">
<h2>Sending Python <code class="docutils literal notranslate"><span class="pre">dict</span></code> to Dataset Pipeline<a class="headerlink" href="#sending-python-dict-to-dataset-pipeline" title="Permalink to this headline"></a></h2>
<p>Sending Python <code class="docutils literal notranslate"><span class="pre">dict</span></code> objects to the Dataset pipeline is possible through different methods:</p>
<ol class="arabic simple">
<li><p>using a <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>, the user can customize it to return a <code class="docutils literal notranslate"><span class="pre">dict</span></code> object, or</p></li>
<li><p>within a Python callable object used in a <code class="docutils literal notranslate"><span class="pre">map</span></code> operation, the user can customize it to return a <code class="docutils literal notranslate"><span class="pre">dict</span></code> object, or</p></li>
<li><p>similarly, customize the <code class="docutils literal notranslate"><span class="pre">per_batch_map</span></code> function of a <code class="docutils literal notranslate"><span class="pre">batch</span></code> operation to return a <code class="docutils literal notranslate"><span class="pre">dict</span></code> object.</p></li>
</ol>
<section id="process-dict-with-generatordataset">
<h3>Process <code class="docutils literal notranslate"><span class="pre">dict</span></code> with GeneratorDataset<a class="headerlink" href="#process-dict-with-generatordataset" title="Permalink to this headline"></a></h3>
<p>Here is an example of sending <code class="docutils literal notranslate"><span class="pre">dict</span></code> objects to the Dataset pipeline using <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>.</p>
<p>In the example, <code class="docutils literal notranslate"><span class="pre">my_generator</span></code> returns 2 elements, corresponding to 2 data columns, where the dictionary is considered as <code class="docutils literal notranslate"><span class="pre">col1</span></code>. Specifically, the rules for data processing pipelines typically check whether the return value can be converted to a NumPy type, but no typecast check if the return value is a dictionary. Furthermore, there is no limit on the internal items it stores (number and type of keys/values).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="k">def</span> <span class="nf">my_generator</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">col1</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;number&quot;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span> <span class="s2">&quot;square&quot;</span><span class="p">:</span> <span class="n">i</span> <span class="o">**</span> <span class="mi">2</span><span class="p">}</span>
        <span class="n">col2</span> <span class="o">=</span> <span class="n">i</span>
        <span class="k">yield</span> <span class="n">col1</span><span class="p">,</span> <span class="n">col2</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">my_generator</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;col1&quot;</span><span class="p">,</span> <span class="s2">&quot;col2&quot;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{&#39;col1&#39;: {&#39;number&#39;: array(0), &#39;square&#39;: array(0)}, &#39;col2&#39;: array(0, dtype=int64)}
{&#39;col1&#39;: {&#39;number&#39;: array(1), &#39;square&#39;: array(1)}, &#39;col2&#39;: array(1, dtype=int64)}
{&#39;col1&#39;: {&#39;number&#39;: array(2), &#39;square&#39;: array(4)}, &#39;col2&#39;: array(2, dtype=int64)}
{&#39;col1&#39;: {&#39;number&#39;: array(3), &#39;square&#39;: array(9)}, &#39;col2&#39;: array(3, dtype=int64)}
{&#39;col1&#39;: {&#39;number&#39;: array(4), &#39;square&#39;: array(16)}, &#39;col2&#39;: array(4, dtype=int64)}
</pre></div>
</div>
</section>
<section id="process-dict-with-map-operation">
<h3>Process <code class="docutils literal notranslate"><span class="pre">dict</span></code> with Map Operation<a class="headerlink" href="#process-dict-with-map-operation" title="Permalink to this headline"></a></h3>
<p>Similar to <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>, each <code class="docutils literal notranslate"><span class="pre">dict</span></code> object is treated as one data column and there is no limitation on its content.</p>
<blockquote>
<div><p>Except for user-defined functions, none of the existing Dataset pipeline transforms (<code class="docutils literal notranslate"><span class="pre">mindspore.dataset.transforms</span></code>, <code class="docutils literal notranslate"><span class="pre">mindspore.dataset.vision</span></code>, etc.) support inputs of type <code class="docutils literal notranslate"><span class="pre">dict</span></code>.</p>
</div></blockquote>
<p>Here is an example of adding <code class="docutils literal notranslate"><span class="pre">dict</span></code> objects to the Dataset pipeline using <code class="docutils literal notranslate"><span class="pre">map</span></code> operation and a user-defined function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="k">def</span> <span class="nf">my_generator</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">i</span>

<span class="k">def</span> <span class="nf">my_pyfunc</span><span class="p">(</span><span class="n">col1</span><span class="p">):</span>
    <span class="n">new_col1</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;original_col1&quot;</span><span class="p">:</span> <span class="n">col1</span><span class="p">,</span> <span class="s2">&quot;square&quot;</span><span class="p">:</span> <span class="n">col1</span> <span class="o">**</span> <span class="mi">2</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">new_col1</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">my_generator</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;col1&quot;</span><span class="p">])</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">my_pyfunc</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;col1&quot;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{&#39;col1&#39;: {&#39;original_col1&#39;: array(0), &#39;square&#39;: array(0)}}
{&#39;col1&#39;: {&#39;original_col1&#39;: array(1), &#39;square&#39;: array(1)}}
{&#39;col1&#39;: {&#39;original_col1&#39;: array(2), &#39;square&#39;: array(4)}}
{&#39;col1&#39;: {&#39;original_col1&#39;: array(3), &#39;square&#39;: array(9)}}
{&#39;col1&#39;: {&#39;original_col1&#39;: array(4), &#39;square&#39;: array(16)}}
</pre></div>
</div>
</section>
<section id="process-dict-with-batch-operation">
<h3>Process <code class="docutils literal notranslate"><span class="pre">dict</span></code> with Batch Operation<a class="headerlink" href="#process-dict-with-batch-operation" title="Permalink to this headline"></a></h3>
<p>When <code class="docutils literal notranslate"><span class="pre">batch</span></code> operation is invoked on a dataset with a column containing dictionary objects, Dataset pipeline attempts to group corresponding values with the same keys inside the dictionaries together. Thus, it is necessary for all the dictionaries to have identical keys.</p>
<p>The result of the <code class="docutils literal notranslate"><span class="pre">batch</span></code> operation (for that column) will be one dictionary where all values are NumPy arrays. If such conversion results in an array of type <code class="docutils literal notranslate"><span class="pre">np.object_</span></code>, due to limitations on the model training side, an error message will be shown to the user and the Dataset pipeline terminates.</p>
<p>The following is a example demonstrating when dictionary object exists in dataset pipeline, how it batches the data of “power” key.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="k">def</span> <span class="nf">my_generator</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">col1</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;nested_dict&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;powers&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])}}</span>
        <span class="n">col2</span> <span class="o">=</span> <span class="n">i</span>
        <span class="k">yield</span> <span class="p">(</span><span class="n">col1</span><span class="p">,</span> <span class="n">col2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">my_pyfunc</span><span class="p">(</span><span class="n">col1</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">col1</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
    <span class="n">new_col1</span> <span class="o">=</span> <span class="n">col1</span><span class="p">[</span><span class="s2">&quot;nested_dict&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">new_col1</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">my_generator</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;col1&quot;</span><span class="p">,</span> <span class="s2">&quot;col2&quot;</span><span class="p">])</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">my_pyfunc</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;col1&quot;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&gt;&gt;&gt; before batch&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&gt;&gt;&gt; after batch&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; before batch
{&#39;col1&#39;: {&#39;powers&#39;: array([0, 0, 0])}, &#39;col2&#39;: array(0, dtype=int64)}
{&#39;col1&#39;: {&#39;powers&#39;: array([1, 1, 1])}, &#39;col2&#39;: array(1, dtype=int64)}
{&#39;col1&#39;: {&#39;powers&#39;: array([2, 4, 8])}, &#39;col2&#39;: array(2, dtype=int64)}
{&#39;col1&#39;: {&#39;powers&#39;: array([3, 9, 27])}, &#39;col2&#39;: array(3, dtype=int64)}
{&#39;col1&#39;: {&#39;powers&#39;: array([4, 16, 64])}, &#39;col2&#39;: array(4, dtype=int64)}
&gt;&gt;&gt; after batch
{&#39;col1&#39;: {&#39;powers&#39;: array([[0,  0,  0],
                           [1,  1,  1],
                           [2,  4,  8],
                           [3,  9, 27],
                           [4, 16, 64]])},
 &#39;col2&#39;: array([0, 1, 2, 3, 4], dtype=int64)}
</pre></div>
</div>
<p>If the user has provided a <code class="docutils literal notranslate"><span class="pre">per_batch_map</span></code> function, corresponding items inside the dictionaries (with respect to each key) will be grouped into Python lists. Here is an example of adding <code class="docutils literal notranslate"><span class="pre">dict</span></code> objects to the Dataset pipeline using <code class="docutils literal notranslate"><span class="pre">batch</span></code> operation with a <code class="docutils literal notranslate"><span class="pre">per_batch_map</span></code> function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="k">def</span> <span class="nf">my_generator</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">i</span>

<span class="k">def</span> <span class="nf">my_per_batch_map</span><span class="p">(</span><span class="n">col1</span><span class="p">,</span> <span class="n">batch_info</span><span class="p">):</span>
    <span class="n">new_col1</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;original_col1&quot;</span><span class="p">:</span> <span class="n">col1</span><span class="p">,</span> <span class="s2">&quot;index&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">)}</span>
    <span class="n">new_col2</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;copied_col1&quot;</span><span class="p">:</span> <span class="n">col1</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">new_col1</span><span class="p">,</span> <span class="n">new_col2</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">my_generator</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;col1&quot;</span><span class="p">])</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">per_batch_map</span><span class="o">=</span><span class="n">my_per_batch_map</span><span class="p">,</span> <span class="n">output_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;col1&quot;</span><span class="p">,</span> <span class="s2">&quot;col2&quot;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{&#39;col1&#39;: {&#39;original_col1&#39;: [array(0), array(1), array(2)], &#39;index&#39;: array([0, 1, 2])}, &#39;col2&#39;: {&#39;copied_col1&#39;: [array(0), array(1), array(2)]}}
{&#39;col1&#39;: {&#39;original_col1&#39;: [array(3), array(4), array(5)], &#39;index&#39;: array([0, 1, 2])}, &#39;col2&#39;: {&#39;copied_col1&#39;: [array(3), array(4), array(5)]}}
{&#39;col1&#39;: {&#39;original_col1&#39;: [array(6), array(7), array(8)], &#39;index&#39;: array([0, 1, 2])}, &#39;col2&#39;: {&#39;copied_col1&#39;: [array(6), array(7), array(8)]}}
</pre></div>
</div>
</section>
</section>
<section id="getting-python-dict-from-dataset-pipeline">
<h2>Getting Python <code class="docutils literal notranslate"><span class="pre">dict</span></code> from Dataset Pipeline<a class="headerlink" href="#getting-python-dict-from-dataset-pipeline" title="Permalink to this headline"></a></h2>
<p>Directly iterating through the dataset object can obtain dictionary type data. When using an iterator to retrieve data, the data processing pipeline will attempt to convert all values inside <code class="docutils literal notranslate"><span class="pre">dict</span></code> objects to Tensor type (if <code class="docutils literal notranslate"><span class="pre">output_numpy</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, it will be converted to NumPy arrays).</p>
<p>Note that this step will be applied recursively to all values inside nested dictionaries as well as all elements inside lists and tuples. For those types that cannot be converted to Tensor/NumPy arrays (such as class objects), they will be passed directly to model. If model can not recognize these types, error will be raised.</p>
<p>Here is an example shows how to acquire <code class="docutils literal notranslate"><span class="pre">dict</span></code> data from pipeline.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="k">def</span> <span class="nf">my_generator</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">col1</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;my_data&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">i</span><span class="p">)}</span>
        <span class="n">col2</span> <span class="o">=</span> <span class="n">i</span>
        <span class="k">yield</span> <span class="n">col1</span><span class="p">,</span> <span class="n">col2</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">my_generator</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;col1&quot;</span><span class="p">,</span> <span class="s2">&quot;col2&quot;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&gt;&gt;&gt; Iter dataset with converting all data to Tensor&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&gt;&gt;&gt; Iter dataset with converting all data to Numpy&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; Iter dataset with converting all data to Tensor
{&#39;col1&#39;: {&#39;my_data&#39;: Tensor(shape=[], dtype=Int64, value= 0)}, &#39;col2&#39;: Tensor(shape=[], dtype=Int64, value= 0)}
{&#39;col1&#39;: {&#39;my_data&#39;: Tensor(shape=[], dtype=Int64, value= 1)}, &#39;col2&#39;: Tensor(shape=[], dtype=Int64, value= 1)}
{&#39;col1&#39;: {&#39;my_data&#39;: Tensor(shape=[], dtype=Int64, value= 2)}, &#39;col2&#39;: Tensor(shape=[], dtype=Int64, value= 2)}
{&#39;col1&#39;: {&#39;my_data&#39;: Tensor(shape=[], dtype=Int64, value= 3)}, &#39;col2&#39;: Tensor(shape=[], dtype=Int64, value= 3)}
{&#39;col1&#39;: {&#39;my_data&#39;: Tensor(shape=[], dtype=Int64, value= 4)}, &#39;col2&#39;: Tensor(shape=[], dtype=Int64, value= 4)}
&gt;&gt;&gt; Iter dataset with converting all data to Numpy
{&#39;col1&#39;: {&#39;my_data&#39;: array(0)}, &#39;col2&#39;: array(0, dtype=int64)}
{&#39;col1&#39;: {&#39;my_data&#39;: array(1)}, &#39;col2&#39;: array(1, dtype=int64)}
{&#39;col1&#39;: {&#39;my_data&#39;: array(2)}, &#39;col2&#39;: array(2, dtype=int64)}
{&#39;col1&#39;: {&#39;my_data&#39;: array(3)}, &#39;col2&#39;: array(3, dtype=int64)}
{&#39;col1&#39;: {&#39;my_data&#39;: array(4)}, &#39;col2&#39;: array(4, dtype=int64)}
</pre></div>
</div>
<p>In the model training/inference scenario, there are the following constraints when obtaining <code class="docutils literal notranslate"><span class="pre">dict</span></code> data from the data pipeline.</p>
<ul>
<li><p>In <a class="reference external" href="https://mindspore.cn/tutorials/experts/en/r2.1/optimize/execution_opt.html#data-sinking">data sink mode</a>, since the data sink channel currently cannot support dictionary type data, sending dictionary type data to it will cause errors. Therefore, it is suggested to consider turning off the data sink mode (<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode=False</span></code>), or expanding dictionary type data into list or tuple type data at the last data processing node, for example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="k">def</span> <span class="nf">my_generator</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">col1</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;my_data&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="s1">&#39;my_data2&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)}</span>
        <span class="k">yield</span> <span class="n">col1</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">my_generator</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;col1&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&gt;&gt;&gt; get data in dict type&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">dict_to_tuple</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>

<span class="c1"># flatten the dict object bedfore it passed into network</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">dict_to_tuple</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;col1&#39;</span><span class="p">],</span> <span class="n">output_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;my_data&#39;</span><span class="p">,</span> <span class="s1">&#39;my_data2&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&gt;&gt;&gt; get data in sequence type&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; get data in dict type
[{&#39;my_data&#39;: Tensor(shape=[], dtype=Int64, value= 0), &#39;my_data2&#39;: Tensor(shape=[], dtype=Int64, value= 1)}]
[{&#39;my_data&#39;: Tensor(shape=[], dtype=Int64, value= 1), &#39;my_data2&#39;: Tensor(shape=[], dtype=Int64, value= 2)}]
[{&#39;my_data&#39;: Tensor(shape=[], dtype=Int64, value= 2), &#39;my_data2&#39;: Tensor(shape=[], dtype=Int64, value= 3)}]
[{&#39;my_data&#39;: Tensor(shape=[], dtype=Int64, value= 3), &#39;my_data2&#39;: Tensor(shape=[], dtype=Int64, value= 4)}]
[{&#39;my_data&#39;: Tensor(shape=[], dtype=Int64, value= 4), &#39;my_data2&#39;: Tensor(shape=[], dtype=Int64, value= 5)}]
&gt;&gt;&gt; get data in sequence type
[Tensor(shape=[], dtype=Int64, value= 0), Tensor(shape=[], dtype=Int64, value= 1)]
[Tensor(shape=[], dtype=Int64, value= 1), Tensor(shape=[], dtype=Int64, value= 2)]
[Tensor(shape=[], dtype=Int64, value= 2), Tensor(shape=[], dtype=Int64, value= 3)]
[Tensor(shape=[], dtype=Int64, value= 3), Tensor(shape=[], dtype=Int64, value= 4)]
[Tensor(shape=[], dtype=Int64, value= 4), Tensor(shape=[], dtype=Int64, value= 5)]
</pre></div>
</div>
</li>
<li><p>In non data sink mode, there is no limit, just pay attention to whether the types stored in the dictionary can be recognized and processed by the model.</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="eager.html" class="btn btn-neutral float-left" title="Lightweight Data Processing" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../derivation.html" class="btn btn-neutral float-right" title="Advanced Automatic Differentiation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>