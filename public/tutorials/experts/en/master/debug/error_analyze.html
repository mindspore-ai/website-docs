

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Error Analysis &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Custom Debugging Information" href="custom_debug.html" />
    <link rel="prev" title="Function Debug" href="function_debug.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Data Processing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dataset/augment.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/cache.html">Single-Node Data Cache</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/optimize.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption"><span class="caption-text">Graph Compilation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../network/control_flow.html">Process Control Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/op_overload.html">Compiling Performance Optimization for Static Graph Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/jit_class.html">Calling the Custom Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/constexpr.html">Construct Constants In the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/dependency_control.html">Dependency Control</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Training Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../optimize/execution_opt.html">Sinking Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/gradient_accumulation.html">Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/adaptive_summation.html">Adaptive Gradient Summation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/dimention_reduce_training.html">Dimension Reduction Training Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/thor.html">Second-order Optimization</a></li>
</ul>
<p class="caption"><span class="caption-text">Custom Operator</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom.html">Custom Operators (Custom-based)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/ms_kernel.html">MindSpore Hybrid Syntax Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom_adv.html">Advanced Usage of Custom Operators</a></li>
</ul>
<p class="caption"><span class="caption-text">Automatic Vectorization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../vmap/vmap.html">Automatic Vectorization (Vmap)</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../infer/inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/ascend_310_air.html">Inference on the Ascend 310 AI Processor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/model_compression.html">Model Compression</a></li>
</ul>
<p class="caption"><span class="caption-text">Debugging and Tuning</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="function_debug.html">Function Debug</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Error Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_debug.html">Custom Debugging Information</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindir.html">Reading IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="dump.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="pynative_debug.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="pynative.html">Applying PyNative Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="fixing_randomness.html">Fixed Randomness to Reproduce Run Results of Script</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="performance_optimization.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference external" href="https://mindspore.cn/mindinsight/docs/en/master/accuracy_problem_preliminary_location.html">Precision Optimizationâ†—</a></li>
<li class="toctree-l1"><a class="reference internal" href="fault_recover.html">Fault Recovery</a></li>
</ul>
<p class="caption"><span class="caption-text">Distributed Parallel</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../parallel/overview.html">Distributed Parallelism Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/operator_parallel.html">Operator-level Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/pipeline_parallel.html">Pipeline Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/optimizer_parallel.html">Optimizer Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/recompute.html">Recomputation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/host_device_training.html">Host&amp;Device Heterogeneous</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/parameter_server_training.html">Parameter Server Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/train_ascend.html">Semi-automatic Parallelism Integration Case</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/parallel_training_quickstart.html">Automatic Parallelism Case</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/startup_method.html">Distributed Parallel Startup Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/distributed_inference.html">Distributed Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/distributed_case.html">Distributed High-Level Configuration Case</a></li>
</ul>
<p class="caption"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../env/env_var_list.html">Environment Variables</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="function_debug.html">Function Debug</a> &raquo;</li>
        
      <li>Error Analysis</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/debug/error_analyze.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="error-analysis">
<h1>Error Analysis<a class="headerlink" href="#error-analysis" title="Permalink to this headline">Â¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/master/tutorials/experts/source_en/debug/error_analyze.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png"></a>Â Â </p>
<p>As mentioned before, error analysis refers to analyzing and inferring possible error causes based on the obtained network and framework information (such as error messages and network code).</p>
<p>During error analysis, the first step is to identify the scenario where the error occurs and determine whether the error is caused by data loading and processing or network construction and training. You can determine whether it is a data or network problem based on the format of the error message. In the distributed parallel scenario, you can use a single-device execution network for verification. If there is no data loading and processing or network construction and training problem, the error is caused by a parallel scenario problem. The following describes the error analysis methods in different scenarios.</p>
<div class="section" id="data-loading-and-processing-error-analysis">
<h2>Data Loading and Processing Error Analysis<a class="headerlink" href="#data-loading-and-processing-error-analysis" title="Permalink to this headline">Â¶</a></h2>
<p>When an error is reported during data processing, check whether C++ error messages are contained as shown in Figure 1. Typically, the name of the data processing operation using the C++ language is the same as that using Python. Therefore, you can determine the data processing operation that reports the error based on the error message and locate the error in the Python code.</p>
<p><img alt="minddata-errmsg" src="https://gitee.com/mindspore/docs/raw/master/tutorials/experts/source_zh_cn/debug/images/minddata_errmsg.png" /></p>
<p><em>Figure 1</em></p>
<p>As shown in the following figure, <code class="docutils literal notranslate"><span class="pre">batch_op.cc</span></code> reports a C++ error. The batch operation combines multiple consecutive pieces of data in a dataset into a batch for data processing, which is implemented at the backend. According to the error description, the input data does not meet the parameter requirements of the batch operation. Data to be batch operated has the same shape, and the sizes of different shapes are displayed.</p>
<p>Data loading and processing has three phases: data preparation, data loading, and data augmentation. The following table lists common errors.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Error Type</th>
<th>Error Description</th>
<th>Case Analysis</th>
</tr>
</thead>
<tbody>
<tr>
<td>Data preparation error</td>
<td>The dataset is faulty, involving a path or MindRecord file problem.</td>
<td><a href="https://www.mindspore.cn/tutorials/experts/en/master/debug/minddata_debug.html">Error Case</a></td>
</tr>
<tr>
<td>Data loading error</td>
<td>Incorrect resource configuration, customized loading method, or iterator usage in the data loading phase.</td>
<td><a href="https://www.mindspore.cn/tutorials/experts/en/master/debug/minddata_debug.html">Error Case</a></td>
</tr>
<tr>
<td>Data augmentation error</td>
<td>Unmatched data format/size, high resource usage, or multi-thread suspension.</td>
<td><a href="https://www.mindspore.cn/tutorials/experts/en/master/debug/minddata_debug.html">Error Case</a></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="network-construction-and-training-error-analysis">
<h2>Network Construction and Training Error Analysis<a class="headerlink" href="#network-construction-and-training-error-analysis" title="Permalink to this headline">Â¶</a></h2>
<p>The network construction and training process can be executed in the dynamic graph mode or static graph mode, and has two phases: build and execution. The error analysis method varies according to the execution phase in different modes.</p>
<p>The following table lists common network construction and training errors.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Error Type</th>
<th>Error Description</th>
<th>Case Analysis</th>
</tr>
</thead>
<tbody>
<tr>
<td>Incorrect context configuration</td>
<td>An error occurs when the system configures the context.</td>
<td><a href="https://mindspore.cn/tutorials/experts/en/master/debug/mindrt_debug.html">Error Analysis</a></td>
</tr>
<tr>
<td>Syntax error</td>
<td>Python syntax errors and MindSpore static graph syntax errors, such as unsupported control flow syntax and tensor slicing errors</td>
<td><a href="https://mindspore.cn/tutorials/experts/en/master/debug/mindrt_debug.html">Error Analysis</a></td>
</tr>
<tr>
<td>Operator build error</td>
<td>The operator parameter value, type, or shape does not meet the requirements, or the operator function is restricted.</td>
<td><a href="https://mindspore.cn/tutorials/experts/en/master/debug/mindrt_debug.html">Error Analysis</a></td>
</tr>
<tr>
<td>Operator execution error</td>
<td>Input data exceptions, operator implementation errors, function restrictions, resource restrictions, etc.</td>
<td><a href="https://mindspore.cn/tutorials/experts/en/master/debug/mindrt_debug.html">Error Analysis</a></td>
</tr>
<tr>
<td>Insufficient resources</td>
<td>The device memory is insufficient, the number of function call stacks exceeds the threshold, and the number of flow resources exceeds the threshold.</td>
<td><a href="https://mindspore.cn/tutorials/experts/en/master/debug/mindrt_debug.html">Error Analysis</a></td>
</tr>
</tbody>
</table>
<div class="section" id="error-analysis-of-the-dynamic-graph-mode">
<h3>Error Analysis of the Dynamic Graph Mode<a class="headerlink" href="#error-analysis-of-the-dynamic-graph-mode" title="Permalink to this headline">Â¶</a></h3>
<p>In dynamic graph mode, the program is executed line by line according to the code writing sequence, and the execution result can be returned in time. Figure 2 shows the error message reported during dynamic graph build. The error message is from the Python frontend, indicating that the number of function parameters does not meet the requirements. Through the Python call stack, you can locate the error code: <code class="docutils literal notranslate"><span class="pre">c</span> <span class="pre">=</span> <span class="pre">self.mul(b,</span> <span class="pre">self.func(a,a,b))</span></code>.</p>
<p>Generally, the error message may contain <code class="docutils literal notranslate"><span class="pre">WARNING</span></code> logs. During error analysis, analyze the error message following Traceback first.</p>
<p><img alt="pynative-errmsg" src="https://gitee.com/mindspore/docs/raw/master/tutorials/experts/source_zh_cn/debug/images/pynative_errmsg.png" /></p>
<p><em>Figure 2</em></p>
<p>In dynamic graph mode, common network construction and training errors are found in environment configuration, Python syntax, and operator usage. The general analysis method is as follows:</p>
<ul class="simple">
<li><p>Determine the object where the error is reported based on the error description, for example, the operator API name.</p></li>
<li><p>Locate the code line where the error is reported based on the Python call stack information.</p></li>
<li><p>Analyze the code input data and calculation logic at the position where the error occurs, and find the error cause based on the description and specifications of the error object in the <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/mindspore.html">MindSpore API</a>.</p></li>
</ul>
</div>
<div class="section" id="error-analysis-of-the-static-graph-mode">
<h3>Error Analysis of the Static Graph Mode<a class="headerlink" href="#error-analysis-of-the-static-graph-mode" title="Permalink to this headline">Â¶</a></h3>
<p>In static graph mode, MindSpore builds the network structure into a computational graph, and then performs the computation operations involved in the graph. Therefore, errors reported in static graph mode include computational graph build errors and computational graph execution errors. Figure 3 shows the error message reported during computational graph build. When an error occurs, the <code class="docutils literal notranslate"><span class="pre">analyze_failed.ir</span></code> file is automatically saved to help analyze the location of the error code.</p>
<p><img alt="graph-errmsg" src="https://gitee.com/mindspore/docs/raw/master/tutorials/experts/source_zh_cn/debug/images/graph_errmsg.png" /></p>
<p><em>Figure 3</em></p>
<p>The general error analysis method in static graph mode is as follows:</p>
<p>Check whether the error is caused by graph build or graph execution based on the error description.</p>
<ul class="simple">
<li><p>If the error is reported during computational graph build, analyze the cause and location of the failure based on the error description and the <code class="docutils literal notranslate"><span class="pre">analyze_failed.ir</span></code> file automatically saved when the error occurs.</p></li>
<li><p>If the error is reported during computational graph execution, the error may be caused by insufficient resources or improper operator execution. You need to further distinguish the error based on the error message. If the error is reported during operator execution, locate the operator, use the dump function to save the input data of the operator, and analyze the cause of the error based on the input data.</p></li>
</ul>
<p>For details about how to analyze and infer the failure cause, see the analysis methods described in <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/debug/mindir.html#how-to-derive-the-cause-of-the-failure-based-on-the-analyze-fail-ir-file-analysis-graph"><code class="docutils literal notranslate"><span class="pre">analyze_failed.ir</span></code></a>.</p>
<p>For details about how to use Dump to save the operator input data, see <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/debug/dump.html">Dump Function Debugging</a>.</p>
</div>
</div>
<div class="section" id="distributed-parallel-error-analysis">
<h2>Distributed Parallel Error Analysis<a class="headerlink" href="#distributed-parallel-error-analysis" title="Permalink to this headline">Â¶</a></h2>
<p>MindSpore provides the distributed parallel training function and supports multiple parallel modes. The following table lists common distributed parallel training errors and possible causes.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Error Type</th>
<th>Error Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Incorrect policy configuration</td>
<td>Incorrect operator logic.</td>
</tr>
<tr>
<td></td>
<td>Incorrect scalar policy configuration.</td>
</tr>
<tr>
<td></td>
<td>No policy configuration.</td>
</tr>
<tr>
<td>Parallel script error</td>
<td>Incorrect script startup, or unmatched parallel configuration and startup task.</td>
</tr>
</tbody>
</table>
<div class="section" id="incorrect-policy-configuration">
<h3>Incorrect Policy Configuration<a class="headerlink" href="#incorrect-policy-configuration" title="Permalink to this headline">Â¶</a></h3>
<p>Policy check errors may be reported after you enable automatic parallelism using <code class="docutils literal notranslate"><span class="pre">mindspore.set_auto_parallel_context(parallel_mode=&quot;semi_auto_parallel&quot;)</span></code>. These policy check errors are reported due to specific operator slicing restrictions. The following uses three examples to describe how to analyze the three types of errors.</p>
<div class="section" id="incorrect-operator-logic">
<h4>Incorrect Operator Logic<a class="headerlink" href="#incorrect-operator-logic" title="Permalink to this headline">Â¶</a></h4>
<p>The error message is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">ERROR</span><span class="p">]</span><span class="n">Check</span> <span class="n">StridedSliceInfo1414</span><span class="p">:</span> <span class="n">When</span> <span class="n">there</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">mask</span><span class="p">,</span> <span class="n">the</span> <span class="nb">input</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">supported</span> <span class="n">to</span> <span class="n">be</span> <span class="n">split</span>
</pre></div>
</div>
<p>The following shows a piece of possible error code where the network input is a [2, 4] tensor. The network is sliced to obtain the first half of dimension 0 in the input tensor. It is equivalent to the x[:1, :]operation in NumPy, where x is the input tensor. On the network, the (2,1) policy is configured for the stridedslice operator to slice dimension 0.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="n">stridedslice</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">StridedSlice</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">MyStridedSlice</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyStridedSlice</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">slice</span> <span class="o">=</span> <span class="n">stridedslice</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x is a two-dimensional tensor</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Error cause:</p>
<p>The piece of code performs the slice operation on dimension 0. However, the configured policy (2,1) indicates that the slice operation is performed on both dimension 0 and dimension 1 of the input tensor. According to the description of operator slicing in the <a class="reference external" href="https://www.mindspore.cn/docs/en/master/note/operator_list_parallel.html">MindSpore API</a>,</p>
<blockquote>
<div><p>only the mask whose value is all 0s is supported. All dimensions that are sliced must be extracted together. The input dimensions whose strides is not set to 1 cannot be sliced.</p>
</div></blockquote>
<p>Dimensions that are sliced cannot be separately extracted. Therefore, the policy must be modified as follows:</p>
<p>Change the policy of dimension 0 from 2 to 1. In this way, dimension 0 will be sliced into one, that is, dimension 0 will not be sliced. Therefore, the policy meets the operator restrictions and the policy check is successful.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyStridedSlice</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyStridedSlice</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">slice</span> <span class="o">=</span> <span class="n">stridedslice</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x is a two-dimensional tensor</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="incorrect-scalar-policy-configuration">
<h4>Incorrect Scalar Policy Configuration<a class="headerlink" href="#incorrect-scalar-policy-configuration" title="Permalink to this headline">Â¶</a></h4>
<p>Error message:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">ERROR</span><span class="p">]</span> <span class="n">The</span> <span class="n">strategy</span> <span class="ow">is</span> <span class="o">...</span><span class="p">,</span> <span class="n">strategy</span> <span class="nb">len</span><span class="p">:</span><span class="o">.</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">equal</span> <span class="n">to</span> <span class="n">inputs</span> <span class="nb">len</span><span class="p">:</span><span class="o">.</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span>
</pre></div>
</div>
<p>Possible error code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySub</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MySub</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sub</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)))</span>
    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x is a two-dimensional tensor</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>The input of many operators can be scalars, such as addition, subtraction, multiplication, and division operations and axis of operators such as concat and gather. For such operations with scalar input, do not configure policies for these scalars. If the preceding method is used to configure a policy for the subtraction operation and the policy (1,) is configured for scalar 1, an error is reported.
That is, the length of the policy whose index is 1 is 1, which is not equal to the length 0 of the corresponding input. In this case, the input is a scalar.</p>
<p>Modified code:</p>
<p>In this case, set an empty policy for the scalar or do not set any policy (recommended method).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">sub</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),()))</span>

<span class="bp">self</span><span class="o">.</span><span class="n">sub</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),))</span>
</pre></div>
</div>
</div>
<div class="section" id="no-policy-configuration">
<h4>No Policy Configuration<a class="headerlink" href="#no-policy-configuration" title="Permalink to this headline">Â¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">ERROR</span><span class="p">]</span><span class="n">The</span> <span class="n">strategy</span> <span class="ow">is</span> <span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">shape</span> <span class="mi">4</span> <span class="n">can</span> <span class="ow">not</span> <span class="n">be</span> <span class="n">divisible</span> <span class="n">by</span> <span class="n">strategy</span> <span class="n">value</span> <span class="mi">8</span>
</pre></div>
</div>
<p>Possible error code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySub</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MySub</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sub</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x is a two-dimensional tensor</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>The following piece of code runs training in an 8-device environment in semi-automatic parallel mode. No policy is configured for the Sub operator in the example and the default policy of the Sub operator is data parallel. Assume that the input x is a matrix of size [2, 4]. After the build starts, an error is reported, indicating that the input dimensions are insufficient for slicing. In this case, you need to modify the policy as follows (ensure that the number of dimensions for slicing are less than that of the input tensor):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySub</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MySub</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sub</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">()))</span>
    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x is a two-dimensional tensor</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>(2, 1) indicates that dimension 0 of the first input tensor is sliced into two parts, and dimension 1 is sliced into one, that is, dimension 1 is not sliced. The second input of <code class="docutils literal notranslate"><span class="pre">ops.Sub</span></code> is a scalar that cannot be sliced. Therefore, the slicing policy is set to empty ().</p>
</div>
</div>
<div class="section" id="parallel-script-error">
<h3>Parallel Script Error<a class="headerlink" href="#parallel-script-error" title="Permalink to this headline">Â¶</a></h3>
<p>The following is a piece of code for running an 8-device Ascend environment and using the bash script to start the training task.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="nb">set</span><span class="w"> </span>-e
<span class="nv">EXEC_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">RANK_SIZE</span><span class="o">=</span><span class="m">8</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">RANK_TABLE_FILE</span><span class="o">=</span><span class="si">${</span><span class="nv">EXEC_PATH</span><span class="si">}</span>/rank_table_8pcs.json

<span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span>i&lt;RANK_SIZE<span class="p">;</span>i++<span class="o">))</span>
<span class="k">do</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span>device<span class="nv">$i</span>
<span class="w">    </span>mkdir<span class="w"> </span>device<span class="nv">$i</span>
<span class="w">    </span>cp<span class="w"> </span>./train.py<span class="w"> </span>./device<span class="nv">$i</span>
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span>./device<span class="nv">$i</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span><span class="nv">$i</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span><span class="nv">$i</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training for device </span><span class="nv">$i</span><span class="s2">&quot;</span>
<span class="w">    </span>env<span class="w"> </span>&gt;<span class="w"> </span>env<span class="nv">$i</span>.log
<span class="w">    </span>python<span class="w"> </span>./train.py<span class="w"> </span>&gt;<span class="w"> </span>train.log<span class="nv">$i</span><span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span>../
<span class="k">done</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;The program launch succeed, the log is under device0/train.log0.&quot;</span>
</pre></div>
</div>
<p>Errors may occur in the following scenarios:</p>
<ol class="simple">
<li><p>The number of training tasks (<code class="docutils literal notranslate"><span class="pre">RANK_SIZE</span></code>) started using the for loop does not match the number of devices configured in the <code class="docutils literal notranslate"><span class="pre">rank_table_8pcs.json</span></code> configuration file. As a result, an error is reported.</p></li>
<li><p>The command for executing the training script is not executed in asynchronous mode (<code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">./train.py</span> <span class="pre">&gt;</span> <span class="pre">train.log$i</span> <span class="pre">2&gt;&amp;1</span></code>). As a result, training tasks are started at different time, and an error is reported. In this case, add the <code class="docutils literal notranslate"><span class="pre">&amp;</span></code> operator to the end of the command, indicating that the command is executed asynchronously in the subshell. In this way, multiple tasks can be started synchronously.</p></li>
</ol>
<p>In parallel scenarios, you may encounter the <code class="docutils literal notranslate"><span class="pre">Distribute</span> <span class="pre">Task</span> <span class="pre">Failed</span></code> error. In this case, analyze whether the error occurs in the computational graph build phase or the execution phase of printing training loss to further locate the error.</p>
<p>For details, visit the following website:</p>
<p>For more information about distributed parallel errors in MindSpore, see <a class="reference external" href="https://www.hiascend.com/forum/thread-0231108039303484155-1-1.html">Distributed Task Failed</a>.</p>
</div>
</div>
<div class="section" id="cann-error-analysis">
<h2>CANN Error Analysis<a class="headerlink" href="#cann-error-analysis" title="Permalink to this headline">Â¶</a></h2>
<blockquote>
<div><ul class="simple">
<li><p>This section is only applicable to Ascend platform, CANN (Compute Architecture for Neural Networks) is Huawei heterogeneous computing architecture for AI scenarios, and MindSpore of Ascend platform runs on top of CANN.</p></li>
</ul>
</div></blockquote>
<p>When running MindSpore on the Ascend platform, certain scenarios will encounter errors from the underlying CANN. Such errors are generally reported in the log with the <code class="docutils literal notranslate"><span class="pre">Ascend</span> <span class="pre">error</span> <span class="pre">occurred</span></code> keyword, and the error message consists of the error code and the error content, as follows:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">ERROR</span><span class="p">]</span><span class="w"> </span><span class="n">PROFILER</span><span class="p">(</span><span class="mi">138694</span><span class="p">,</span><span class="n">ffffaa6c8480</span><span class="p">,</span><span class="n">python</span><span class="p">)</span><span class="o">:</span><span class="mi">2022</span><span class="mo">-01</span><span class="mi">-10-14</span><span class="o">:</span><span class="mi">19</span><span class="o">:</span><span class="mf">56.741.053</span><span class="w"> </span><span class="p">[</span><span class="n">mindspore</span><span class="o">/</span><span class="n">ccsrc</span><span class="o">/</span><span class="n">profiler</span><span class="o">/</span><span class="n">device</span><span class="o">/</span><span class="n">ascend</span><span class="o">/</span><span class="n">ascend_profiling</span><span class="p">.</span><span class="n">cc</span><span class="o">:</span><span class="mi">51</span><span class="p">]</span><span class="w"> </span><span class="n">ReportErrorMessage</span><span class="p">]</span><span class="w"> </span><span class="n">Ascend</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="n">occurred</span><span class="p">,</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="n">message</span><span class="o">:</span>
<span class="nl">EK0001</span><span class="p">:</span><span class="w"> </span><span class="n">Path</span><span class="w"> </span><span class="p">[</span><span class="o">/</span><span class="n">ms_test</span><span class="o">/</span><span class="n">csj</span><span class="o">/</span><span class="n">csj</span><span class="o">/</span><span class="n">user_scene</span><span class="o">/</span><span class="n">profiler_chinese_ä¸­æ–‡</span><span class="o">/</span><span class="n">resnet</span><span class="o">/</span><span class="n">scripts</span><span class="o">/</span><span class="n">train</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">profiler</span><span class="p">]</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="p">[</span><span class="n">profilerResultPath</span><span class="p">]</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">invalid</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">does</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">exist</span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">Path</span><span class="w"> </span><span class="n">name</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">only</span><span class="w"> </span><span class="n">contain</span><span class="w"> </span><span class="n">A</span><span class="o">-</span><span class="n">Za</span><span class="o">-</span><span class="n">z0</span><span class="mi">-9</span><span class="o">-</span><span class="n">_</span><span class="p">.</span>
</pre></div>
</div>
<p>One of the CANN error codes consists of 6 characters, such as <code class="docutils literal notranslate"><span class="pre">EK0001</span></code> above, which contains three fields:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: left;">Field 1</th>
<th style="text-align: left;">Field 2</th>
<th style="text-align: left;">Field 3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Level (1 position)</td>
<td style="text-align: left;">Module (1 position)</td>
<td style="text-align: left;">Error code (4 positions)</td>
</tr>
</tbody>
</table>
<p>Among them, the level is divided into E, W, I, respectively, indicating error, alarm, prompt class. Module indicates the CANN module that reports errors, as shown in the following table:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: left;">Err error code</th>
<th style="text-align: left;">CANN module</th>
<th style="text-align: left;">Err error code</th>
<th style="text-align: left;">CANN module</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">E10000-E19999</td>
<td style="text-align: left;">GE</td>
<td style="text-align: left;">EE0000-EE9999</td>
<td style="text-align: left;">runtime</td>
</tr>
<tr>
<td style="text-align: left;">E20000-E29999</td>
<td style="text-align: left;">FE</td>
<td style="text-align: left;">EF0000-EF9999</td>
<td style="text-align: left;">LxFusion</td>
</tr>
<tr>
<td style="text-align: left;">E30000-E39999</td>
<td style="text-align: left;">AICPU</td>
<td style="text-align: left;">EG0000-EG9999</td>
<td style="text-align: left;">mstune</td>
</tr>
<tr>
<td style="text-align: left;">E40000-E49999</td>
<td style="text-align: left;">TEFusion</td>
<td style="text-align: left;">EH0000-EH9999</td>
<td style="text-align: left;">ACL</td>
</tr>
<tr>
<td style="text-align: left;">E50000-E89999</td>
<td style="text-align: left;">AICORE</td>
<td style="text-align: left;">EI0000-EJ9999</td>
<td style="text-align: left;">HCCL&amp;HCCP</td>
</tr>
<tr>
<td style="text-align: left;">E90000-EB9999</td>
<td style="text-align: left;">TBE Compiling front and back ends</td>
<td style="text-align: left;">EK0000-EK9999</td>
<td style="text-align: left;">Profiling</td>
</tr>
<tr>
<td style="text-align: left;">EC0000-EC9999</td>
<td style="text-align: left;">Autotune</td>
<td style="text-align: left;">EL0000-EL9999</td>
<td style="text-align: left;">Driver</td>
</tr>
<tr>
<td style="text-align: left;">ED0000-ED9999</td>
<td style="text-align: left;">RLTune</td>
<td style="text-align: left;">EZ0000-EZ9999</td>
<td style="text-align: left;">Operator public error</td>
</tr>
</tbody>
</table>
<blockquote>
<div><p>AICORE operator: The AI Core operator is the main component of the computational core of the Ascend AI processor and is responsible for performing computationally intensive operator related to vector and tensor.
AICPU operator: AI CPU operator is the AI CPU responsible for executing CPU-like operator (including control operator, scalar and vector, and other general-purpose computations) in the Hayes SoC of the Ascend processor.</p>
</div></blockquote>
<p>Among the 4-bit error codes, 0000~8999 are user-class errors and 9000~9999 are internal error codes. Generally, user-class error users can correct the error by themselves according to the error message, while internal error codes need to contact Huawei for troubleshooting. You can go to <a class="reference external" href="https://gitee.com/mindspore">MindSpore Community</a> or <a class="reference external" href="https://gitee.com/ascend">Ascend Community</a> to submit issue to get help. Some common error reporting scenarios are shown in the following table:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Common Error Types</th>
<th>Error Description</th>
<th>Case Analysis</th>
</tr>
</thead>
<tbody>
<tr>
<td>AICORE Operator Compilation Problem</td>
<td>AICORE Operator Error During Compilation</td>
<td><a href="https://www.mindspore.cn/tutorials/experts/en/master/debug/cann_error_cases.html#aicore-operator-compilation-problem">AICORE Operator Compilation Problem</a></td>
</tr>
<tr>
<td>AICORE Operator Execution Problem</td>
<td>AICORE Operator Error During Execution</td>
<td><a href="https://mindspore.cn/tutorials/experts/en/master/debug/cann_error_cases.html#aicore-operator-execution-problem">AICORE Operator Execution Problem</a></td>
</tr>
<tr>
<td>AICPU Operator Execution Problem</td>
<td>AICPU Operator Error During Execution</td>
<td><a href="https://mindspore.cn/tutorials/experts/en/master/debug/cann_error_cases.html#aicpu-operator-execution-problem">AICPU Operator Execution Problem</a></td>
</tr>
<tr>
<td>runtime FAQ</td>
<td>Including input data exceptions, operator implementation errors, functional limitations, resource limitations, etc.</td>
<td><a href="https://mindspore.cn/tutorials/experts/en/master/debug/cann_error_cases.html#runtime-faq">runtime FAQ</a></td>
</tr>
<tr>
<td>HCCL &amp; HCCP FAQ</td>
<td>Common communication problems during multi-machine multi-card training, including socket build timeout, notify wait timeout, ranktable configuration error, etc.</td>
<td><a href="https://mindspore.cn/tutorials/experts/en/master/debug/cann_error_cases.html#hccl-hccp-faq">HCCL &amp; HCCP FAQ</a></td>
</tr>
<tr>
<td>profiling FAQ</td>
<td>Errors when running profiling for performance tuning</td>
<td><a href="https://mindspore.cn/tutorials/experts/en/master/debug/cann_error_cases.html#profiling-faq">profiling FAQ</a></td>
</tr>
</tbody>
</table>
<p>For more information about CANN errors, refer to the <a class="reference external" href="https://www.hiascend.com/document/moreVersion/zh/CANNCommunityEdition/">Ascend CANN Developer Documentation</a> to check the troubleshooting section of the corresponding CANN version.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="custom_debug.html" class="btn btn-neutral float-right" title="Custom Debugging Information" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="function_debug.html" class="btn btn-neutral float-left" title="Function Debug" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>