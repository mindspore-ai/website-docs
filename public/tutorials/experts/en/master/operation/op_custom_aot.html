<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Advanced Usage of aot-type Custom Operators &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Sinking Mode" href="../optimize/execution_opt.html" />
    <link rel="prev" title="Custom Operator Registration" href="op_custom_adv.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Distributed Parallel</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../parallel/overview.html">Distributed Parallelism Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/startup_method.html">Distributed Parallel Startup Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/data_parallel.html">Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/semi_auto_parallel.html">Semi-automatic Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/auto_parallel.html">Automatic Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/manual_parallel.html">Manually Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/parameter_server_training.html">Parameter Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/model_save_load.html">Model Saving and Loading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/recover.html">Fault Recovery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/optimize_technique.html">Optimization Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/others.html">Experimental Characteristics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/distributed_case.html">Distributed High-Level Configuration Case</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Custom Operator</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="op_custom.html">Custom Operators (Custom-based)</a></li>
<li class="toctree-l1"><a class="reference internal" href="ms_kernel.html">MindSpore Hybrid Syntax Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="op_custom_adv.html">Custom Operator Registration</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Advanced Usage of aot-type Custom Operators</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-introduction-to-the-advanced-usage-features-of-aot-type-custom-operators">The Introduction to the Advanced Usage Features of aot-type Custom Operators</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#auto-compilation-of-aot-type-custom-operators">Auto-compilation of aot-type Custom Operators</a></li>
<li class="toctree-l3"><a class="reference internal" href="#attributes-and-intermediate-variables-of-aot-type-custom-operators">Attributes and Intermediate Variables of aot-type Custom Operators</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dynamic-shape-support-for-aot-type-custom-operators">Dynamic Shape Support for aot-type Custom Operators</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#the-introduction-aot-type-custom-operator-advanced-usage-interface">The Introduction aot-type Custom Operator Advanced Usage Interface</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#main-function">Main Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="#initialization-function">Initialization Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="#shape-inference-function">Shape Inference Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="#operator-attribute-registration-python">Operator Attribute Registration (Python)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#advanced-usage-example-of-aot-type-custom-operator">Advanced Usage Example of aot-type Custom Operator</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#operator-implementation-file-c++/cuda-kernel-cc">Operator Implementation File (C++/CUDA): kernel.cc</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#operator-attribute-class">Operator Attribute Class</a></li>
<li class="toctree-l4"><a class="reference internal" href="#operator-initialization-function">Operator Initialization Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="#operator-shape-inference-function">Operator Shape Inference Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="#operator-computation-function-main-function">Operator Computation Function (Main Function)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#operator-definition-file-test-custom-aot-py">Operator Definition File: test_custom_aot.py</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#operator-registration">Operator Registration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#operator-definition">Operator Definition</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#operator-call">Operator Call</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling.html">Profiling↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/execution_opt.html">Sinking Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/graph_fusion_engine.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/op_compilation.html">Incremental Operator Build</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/mem_reuse.html">Memory Reuse</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Algorithm Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../optimize/gradient_accumulation.html">Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/thor.html">Second-order Optimization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">High-level Functional Programming</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../vmap/vmap.html">Automatic Vectorization (Vmap)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../func_programming/Jacobians_Hessians.html">Computing Jacobian and Hessian Matrices Using Functional Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../func_programming/per_sample_gradients.html">Per-sample-gradients</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Processing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dataset/augment.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/cache.html">Single-Node Data Cache</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/optimize.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../infer/inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/model_compression.html">Model Compression</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Complex Problem Debugging</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../debug/dump.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/aoe.html">Ascend Optimization Engine (AOE)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/rdr.html">Running Data Recorder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/fault_recover.html">Fault Recovery</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Advanced Usage of aot-type Custom Operators</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/operation/op_custom_aot.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="advanced-usage-of-aot-type-custom-operators">
<h1>Advanced Usage of aot-type Custom Operators<a class="headerlink" href="#advanced-usage-of-aot-type-custom-operators" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/tutorials/experts/source_en/operation/op_custom_aot.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.svg" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>aot-type custom operators use a pre-compilation approach, which requires developers to write the source code files for the corresponding function based on a specific interface, and compile the source code files in advance into a dynamic link library.
Then, during network runtime, the framework will automatically call and execute the function in the dynamic link library.
aot-type custom operators support CUDA language for GPU platforms and C and C++ languages for CPU platforms. For basic knowledge of developing aot-type custom operators, please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/operation/op_custom.html#defining-custom-operator-of-aot-type">basic tutorial</a>.</p>
<p>In this tutorial, we will demonstrate advanced features of aot-type custom operators, including:</p>
<ul class="simple">
<li><p>auto-compilation of aot type custom operators;</p></li>
<li><p>Attributes and intermediate variables of aot-type custom operators;</p></li>
<li><p>Dynamic shape support for aot-type custom operators.</p></li>
</ul>
<p>For the complete source code of the example, check <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/master/tests/st/ops/graph_kernel/custom/test_custom_aot_fused.py">here</a> in the MindSpore source code.</p>
</section>
<section id="the-introduction-to-the-advanced-usage-features-of-aot-type-custom-operators">
<h2>The Introduction to the Advanced Usage Features of aot-type Custom Operators<a class="headerlink" href="#the-introduction-to-the-advanced-usage-features-of-aot-type-custom-operators" title="Permalink to this headline"></a></h2>
<section id="auto-compilation-of-aot-type-custom-operators">
<h3>Auto-compilation of aot-type Custom Operators<a class="headerlink" href="#auto-compilation-of-aot-type-custom-operators" title="Permalink to this headline"></a></h3>
<p>When the user’s aot type custom operator file is a single file and does not require custom compilation options during compilation, users can use the automatic compilation feature.
In this way, users will provide the source file for the implementation of the custom operator, and MindSpore will automatically compile the source file into a binary library.
Currently, this function supports C++ file compilation based on GCC and CUDA file compilation based on NVCC. When using the automatic compilation function, there are several points to note:</p>
<ul class="simple">
<li><p>MindSpore recognizes the method of automatic compilation as a file name suffix. In order to use the auto compilation feature, please use a source file with a suffix of <code class="docutils literal notranslate"><span class="pre">cpp</span></code>, <code class="docutils literal notranslate"><span class="pre">cc</span></code>, or <code class="docutils literal notranslate"><span class="pre">cu</span></code>. In other cases, MindSpore will process as a binary library path.</p></li>
<li><p>The result of automatic compilation is in the folder akg_kernel_meta.</p></li>
<li><p>The default compilation options are:</p>
<ul>
<li><p>C++: <code class="docutils literal notranslate"><span class="pre">g++</span> <span class="pre">-std=c++17</span> <span class="pre">--shared</span> <span class="pre">-fPIC</span> <span class="pre">-D_GLIBCXX_USE_CXX11_ABI=0</span> <span class="pre">-I./</span> <span class="pre">-o</span> <span class="pre">$object_path,</span> <span class="pre">$source_path</span></code></p></li>
<li><p>CUDA 10: <code class="docutils literal notranslate"><span class="pre">nvcc</span> <span class="pre">--shared</span> <span class="pre">-Xcompiler</span> <span class="pre">-fPIC</span> <span class="pre">-O3</span> <span class="pre">-gencode</span> <span class="pre">arch=compute_70,</span> <span class="pre">code=sm_70</span> <span class="pre">--use_fast_math</span> <span class="pre">--expt-relaxed-constexpr</span> <span class="pre">-D_GLIBCXX_USE_CXX11_ABI=0</span> <span class="pre">-I./</span> <span class="pre">-o</span> <span class="pre">$object_path,</span> <span class="pre">$source_path</span></code></p></li>
<li><p>CUDA 11(or higher version): <code class="docutils literal notranslate"><span class="pre">nvcc</span> <span class="pre">--shared</span> <span class="pre">-Xcompiler</span> <span class="pre">-fPIC</span> <span class="pre">-O3</span> <span class="pre">-gencode</span> <span class="pre">arch=compute_80,</span> <span class="pre">code=sm_80</span> <span class="pre">--use_fast_math</span> <span class="pre">--expt-relaxed-constexpr</span> <span class="pre">-D_GLIBCXX_USE_CXX11_ABI=0</span> <span class="pre">-I./</span> <span class="pre">-o</span> <span class="pre">$object_path,</span> <span class="pre">$source_path</span></code></p></li>
</ul>
</li>
<li><p>MindSpore requires the compilation option of <code class="docutils literal notranslate"><span class="pre">-D_</span> <span class="pre">GLIBCXX_</span> <span class="pre">USE_</span> <span class="pre">CXX11_</span> <span class="pre">ABI</span> <span class="pre">=</span> <span class="pre">0</span></code>, so please avoid using a CUDA software stack with a version lower than 10.1.168 on GPU platforms.</p></li>
</ul>
</section>
<section id="attributes-and-intermediate-variables-of-aot-type-custom-operators">
<h3>Attributes and Intermediate Variables of aot-type Custom Operators<a class="headerlink" href="#attributes-and-intermediate-variables-of-aot-type-custom-operators" title="Permalink to this headline"></a></h3>
<p>Many commonly used operators have attributes, such as the kernel size, padding, and strides of the convlution operator.
Operators with different attribute values have the same computational logic, with the only difference being the values of the attributes during initialization.
In addition, during the calculation process of the operator, some additional memory spaces may be needed to store the intermediate variables.
The following calculation is an example. If we consider the <code class="docutils literal notranslate"><span class="pre">input_1</span></code> and <code class="docutils literal notranslate"><span class="pre">input_2</span></code> to calculate <code class="docutils literal notranslate"><span class="pre">output</span></code> as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tmp</span> <span class="o">=</span> <span class="n">Add</span><span class="p">(</span><span class="n">input_1</span><span class="p">,</span> <span class="n">input_2</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">ReduceSum</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, we need to add the following intermediate variables and attributes to the operator in the computation function, including:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tmp</span></code> as an intermediate variable to record the intermediate result of addition;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">axis</span></code> as an attribute of type <code class="docutils literal notranslate"><span class="pre">int</span></code>, and <code class="docutils literal notranslate"><span class="pre">keep_dims</span></code> as an attribute of type <code class="docutils literal notranslate"><span class="pre">bool</span></code>.</p></li>
</ul>
<p>aot-type custom operators provide functionality to add attributes, and then we can define a class of custom operators with a single source code.
These operators have the same computational logic but achieve different computational effects by assigning values to the attributes during operator initialization.
Additionally, to allow MindSpore to manage memory allocation and release, aot-type custom operators provide interfaces to specify the size of intermediate variables, allowing MindSpore to allocate memory for computation.</p>
</section>
<section id="dynamic-shape-support-for-aot-type-custom-operators">
<h3>Dynamic Shape Support for aot-type Custom Operators<a class="headerlink" href="#dynamic-shape-support-for-aot-type-custom-operators" title="Permalink to this headline"></a></h3>
<p>Dynamic Shape refers to that the shapes of inputs or outputs of an operator depends on the specific operation and cannot be calculated in advance at compile time.
Specifically, there are two cases: the shapes of the operator’s inputs are unknown at compile time, and the shapes of the operator’s outputs depend on the specific input values.
The case that the shapes of the operator’s inputs are unknown at compile time is more common.
Any operator, regardless of their own calculation logic, needs to support this case if it is used in a network that supports dynamic shape inputs.</p>
<p>Currently, the aot type custom operators support the dynamic shape scenario when the shape of the operator’s input is unknown at compile time.
This is achieved by defining a C++ version of the shape derivation function to support type derivation for custom operators in this scenario.</p>
<p>It should be noted that custom operators do not yet support dynamic shape scenarios where the shape of the operator output depends on the value of a specific input.</p>
</section>
</section>
<section id="the-introduction-aot-type-custom-operator-advanced-usage-interface">
<h2>The Introduction aot-type Custom Operator Advanced Usage Interface<a class="headerlink" href="#the-introduction-aot-type-custom-operator-advanced-usage-interface" title="Permalink to this headline"></a></h2>
<section id="main-function">
<h3>Main Function<a class="headerlink" href="#main-function" title="Permalink to this headline"></a></h3>
<p>In the source code file, the main function of the operator implementation function must follow the following specifications:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">FuncName</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">nparam</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">ndims</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="o">**</span><span class="n">shapes</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">dtypes</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">extra</span><span class="p">);</span>
</pre></div>
</div>
<p>The function name <code class="docutils literal notranslate"><span class="pre">FuncName</span></code> can be replaced with any valid function name. The return value is of type int, with 0 indicating normal exit and non-zero indicating an exception. The meaning of the parameter list is as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">nparam</span></code> (int): The total number of inputs, outputs, and intermediate variables. For example, if the operator has 2 inputs, 1 output, and 1 intermediate variable, then <code class="docutils literal notranslate"><span class="pre">nparam</span></code> is 4.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">params</span></code> (void **): An array of pointers to inputs, outputs, and intermediate variables. For example, if the operator has 2 inputs, 1 output, and 1 intermediate variable, then <code class="docutils literal notranslate"><span class="pre">params[0]</span></code> points to the memory of the first input data, <code class="docutils literal notranslate"><span class="pre">params[1]</span></code> points to the memory of the second input data, <code class="docutils literal notranslate"><span class="pre">params[2]</span></code> points to the memory of the output data, and <code class="docutils literal notranslate"><span class="pre">params[3]</span></code> points to the memory of the intermediate variable.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ndims</span></code> (int *): An array of dimensions for inputs, output,s and intermediate variables. For example, if <code class="docutils literal notranslate"><span class="pre">params[i]</span></code> is a tensor with shape [1024, 1024], then <code class="docutils literal notranslate"><span class="pre">ndims[i]</span></code> is 2.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shapes</span></code> (int64_t **): An array of shapes for inputs, outputs, and intermediate variables. For example, if <code class="docutils literal notranslate"><span class="pre">params[i]</span></code> is a tensor with shape [1024, 1024], then <code class="docutils literal notranslate"><span class="pre">shapes[i][0]</span></code> is 1024 and <code class="docutils literal notranslate"><span class="pre">shapes[i][1]</span></code> is 1024.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dtypes</span></code> (const char **): An array of data types for inputs, outputs, and intermediate variables. The elements in <code class="docutils literal notranslate"><span class="pre">dtypes</span></code> can take values among the list “float32”, “float16”, “float”, “float64”, “int”, “int8”, “int16”, “int32”, “int64”, “uint”, “uint8”, “uint16”, “uint32”, “uint64”, and “bool”.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">stream</span></code> (void *): The pointer to a CUDA stream, only required for GPU operator implementation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">extra_void</span></code> (void *): The pointer to a data structure related to attributes.</p></li>
</ul>
</section>
<section id="initialization-function">
<h3>Initialization Function<a class="headerlink" href="#initialization-function" title="Permalink to this headline"></a></h3>
<p>To support operator attributes and intermediate variables, we need to define an operator initialization function. The definition of the operator initialization function must follow the following specifications:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">FuncNameInit</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">ndims</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="o">**</span><span class="n">shapes</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">dtypes</span><span class="p">,</span><span class="w"> </span><span class="n">AotExtra</span><span class="w"> </span><span class="o">*</span><span class="n">extra</span><span class="p">);</span>
</pre></div>
</div>
<p>The function name <code class="docutils literal notranslate"><span class="pre">FuncName</span></code> is the name of the operator main function. The return value is of type int, with 0 indicating normal exit and non-zero indicating an exception. The meaning of the parameter list is as follows:</p>
<ul class="simple">
<li><p>ndims (int *): Array of dimensions for input and output shapes.</p></li>
<li><p>shapes (int64_t **): Array of shapes for inputs and outputs.</p></li>
<li><p>dtypes (const char **): Array of data types for inputs and outputs.</p></li>
<li><p>extra (AotExtra *): Custom operator extensions with attributes. The <code class="docutils literal notranslate"><span class="pre">AotExtra</span></code> type is defined in the header file <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/master/tests/st/ops/graph_kernel/custom/aot_test_files/custom_aot_extra.h">custom_aot_extra.h</a> provided by MindSpore.</p></li>
</ul>
</section>
<section id="shape-inference-function">
<h3>Shape Inference Function<a class="headerlink" href="#shape-inference-function" title="Permalink to this headline"></a></h3>
<p>To support dynamic shape, a C++ version of the shape inference function needs to be added to the custom operator of Aot type. The definition of the operator shape inference function must meet the following specifications:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">FuncNameInferShape</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">ndims</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="o">**</span><span class="n">shapes</span><span class="p">,</span><span class="w"> </span><span class="n">AotExtra</span><span class="w"> </span><span class="o">*</span><span class="n">extra</span><span class="p">)</span>
</pre></div>
</div>
<p>The function name <code class="docutils literal notranslate"><span class="pre">FuncName</span></code> is the name of the operator main function.
The return value is of type <code class="docutils literal notranslate"><span class="pre">std::vector&lt;int64_t&gt;</span></code> and represents the output shape.
The meaning of the parameter list is as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ndims</span></code> (int *): Array of dimensions for input shapes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shapes</span></code> (int64_t **): Array of shapes for inputs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">extra</span></code> (AotExtra *): Pointer to an extension for attribute-bearing custom operators. The <code class="docutils literal notranslate"><span class="pre">AotExtra</span></code> type is defined in the header file <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/master/tests/st/ops/graph_kernel/custom/aot_test_files/custom_aot_extra.h">custom_aot_extra.h</a> provided by MindSpore.</p></li>
</ul>
</section>
<section id="operator-attribute-registration-python">
<h3>Operator Attribute Registration (Python)<a class="headerlink" href="#operator-attribute-registration-python" title="Permalink to this headline"></a></h3>
<p>The initialization of operator attributes is implemented through the operator registration function. For each attribute, we create an <code class="docutils literal notranslate"><span class="pre">attr</span></code> for the operator registration file, setting the attribute name and value. The registration function is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">attr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">param_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">value_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">default_value</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
<p>Please refer to the <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/ops/mindspore.ops.CustomRegOp.html#mindspore-ops-customregop">CustomRegOp</a> interface documentation for the meaning of each parameter. When registering a custom operator of Aot type, we set the following four parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: the name of the attribute of the aot-type custom operator;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">param_type</span></code>: the parameter type of the attribute. For attributes of aot-type custom operators, this input is fixed to be “required”, which means it is a required parameter;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">value_type</span></code>: the numerical type of the attribute. For attributes of aot-type custom operators, this input can be a specific numerical type or “all”, which means no restrictions on the type;</p></li>
<li><p>The last input needs to specify the input name as <code class="docutils literal notranslate"><span class="pre">value=</span></code>, and the input value is the value of the attribute.</p></li>
</ul>
</section>
</section>
<section id="advanced-usage-example-of-aot-type-custom-operator">
<h2>Advanced Usage Example of aot-type Custom Operator<a class="headerlink" href="#advanced-usage-example-of-aot-type-custom-operator" title="Permalink to this headline"></a></h2>
<p>Now we introduce the advanced usage of custom Aot operators using an example of a fused Add and ReduceSum operator. The operator first adds two inputs, and then performs sum operation along a certain axis. The basic calculation logic is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tmp</span> <span class="o">=</span> <span class="n">Add</span><span class="p">(</span><span class="n">input_1</span><span class="p">,</span> <span class="n">input_2</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">ReduceSum</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, we need to add the following intermediate variables and attributes in the computation function, including:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tmp</span></code> is an intermediate variable that records the intermediate result of the addition;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">axis</span></code> is a property of type <code class="docutils literal notranslate"><span class="pre">int</span></code>, and <code class="docutils literal notranslate"><span class="pre">keep_dims</span></code> is a property of type <code class="docutils literal notranslate"><span class="pre">bool</span></code>.</p></li>
</ul>
<section id="operator-implementation-file-c++/cuda-kernel-cc">
<h3>Operator Implementation File (C++/CUDA): kernel.cc<a class="headerlink" href="#operator-implementation-file-c++/cuda-kernel-cc" title="Permalink to this headline"></a></h3>
<p>To implement the operator, we create a source file named <code class="docutils literal notranslate"><span class="pre">kernel.cc</span></code>, which includes an operator attribute class <code class="docutils literal notranslate"><span class="pre">add_reduce_kernel_attr</span></code> and three functions: <code class="docutils literal notranslate"><span class="pre">CustomKernelInit</span></code>, <code class="docutils literal notranslate"><span class="pre">CustomKernelInferShape</span></code>, and <code class="docutils literal notranslate"><span class="pre">CustomKernel</span></code>.</p>
<section id="operator-attribute-class">
<h4>Operator Attribute Class<a class="headerlink" href="#operator-attribute-class" title="Permalink to this headline"></a></h4>
<p>First, we define a data structure to store operator attributes, which inherits from <code class="docutils literal notranslate"><span class="pre">AotKernelData</span></code>.
<code class="docutils literal notranslate"><span class="pre">AotKernelData</span></code> is the base class for custom operator attribute data structures.
By downloading the header file <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/master/tests/st/ops/graph_kernel/custom/aot_test_files/custom_aot_extra.h">custom_aot_extra.h</a> provided by MindSpore and placing it in the same directory as the source file, we can use the related interfaces by including it with <code class="docutils literal notranslate"><span class="pre">#include</span> <span class="pre">&quot;custom_aot_extra.h&quot;</span></code> at the beginning of the file.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;custom_aot_extra.h&quot;</span>
<span class="k">class</span><span class="w"> </span><span class="nc">add_reduce_kernel_attr</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">AotKernelData</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">axis</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">keep_dim</span><span class="p">;</span>
<span class="p">};</span>
</pre></div>
</div>
<p>Here, we define the following variables in the attribute class <code class="docutils literal notranslate"><span class="pre">add_kernel</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">axis</span></code> : member variable, type is <code class="docutils literal notranslate"><span class="pre">int64_t</span></code>;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">keep_dim</span></code> : member variable, type is <code class="docutils literal notranslate"><span class="pre">bool</span></code>.</p></li>
</ul>
</section>
<section id="operator-initialization-function">
<h4>Operator Initialization Function<a class="headerlink" href="#operator-initialization-function" title="Permalink to this headline"></a></h4>
<p>After defining the operator attribute class, we define the operator initialization function. Notice that the initialization function name here is <code class="docutils literal notranslate"><span class="pre">CustomKernelInit</span></code>, and the corresponding prefix for the following functions should be <code class="docutils literal notranslate"><span class="pre">CustomKernel</span></code>.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">CustomKernelInit</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">ndims</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="o">**</span><span class="n">shapes</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">dtypes</span><span class="p">,</span><span class="w"> </span><span class="n">AotExtra</span><span class="w"> </span><span class="o">*</span><span class="n">extra</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">workspace_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">ndims</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">workspace_size</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="n">shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">workspace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">workspace_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)};</span>
<span class="w">  </span><span class="n">extra</span><span class="o">-&gt;</span><span class="n">SetWorkSpace</span><span class="p">(</span><span class="n">workspace</span><span class="p">);</span>

<span class="w">  </span><span class="n">add_reduce_kernel_attr</span><span class="w"> </span><span class="o">*</span><span class="n">kernel_data_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">add_reduce_kernel_attr</span><span class="p">;</span>
<span class="w">  </span><span class="n">kernel_data_ptr</span><span class="o">-&gt;</span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">extra</span><span class="o">-&gt;</span><span class="n">Attr</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;axis&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="n">kernel_data_ptr</span><span class="o">-&gt;</span><span class="n">keep_dim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">extra</span><span class="o">-&gt;</span><span class="n">Attr</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;keep_dim&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="n">extra</span><span class="o">-&gt;</span><span class="n">SetKernelData</span><span class="p">(</span><span class="n">kernel_data_ptr</span><span class="p">);</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Here, we need a intermediate variable <code class="docutils literal notranslate"><span class="pre">workspace</span></code> to record the intermediate result of addition. The method is as follows:</p>
<ol class="arabic simple">
<li><p>Calculate the memory size required for <code class="docutils literal notranslate"><span class="pre">workspace</span></code>: Since the size of <code class="docutils literal notranslate"><span class="pre">workspace</span></code> is the same as that of the first input, we multiply the size of each dimension of <code class="docutils literal notranslate"><span class="pre">shapes[0]</span></code> to calculate the number of elements in <code class="docutils literal notranslate"><span class="pre">workspace</span></code>, and then multiply it by <code class="docutils literal notranslate"><span class="pre">sizeof(float)</span></code> to get the memory size (assuming the element type is float by default).</p></li>
<li><p>Store all the memory sizes of intermediate variables in a <code class="docutils literal notranslate"><span class="pre">std::vector&lt;size_t&gt;</span></code> object: <code class="docutils literal notranslate"><span class="pre">std::vector&lt;size_t&gt;</span> <span class="pre">workspace</span> <span class="pre">=</span> <span class="pre">{workspace_size</span> <span class="pre">*</span> <span class="pre">sizeof(float)};</span></code>. Here, since there is only one intermediate variable, the vector has only one element.</p></li>
<li><p>Set the memory size of the intermediate variable using the <code class="docutils literal notranslate"><span class="pre">SetWorkSpace</span></code> function of <code class="docutils literal notranslate"><span class="pre">AotExtra</span> <span class="pre">*extra</span></code>: <code class="docutils literal notranslate"><span class="pre">extra-&gt;SetWorkSpace(workspace)</span></code>.</p></li>
</ol>
<p>In addition, we need to obtain the values of two attributes, <code class="docutils literal notranslate"><span class="pre">axis</span></code> and <code class="docutils literal notranslate"><span class="pre">keep_dim</span></code>, as follows:</p>
<ol class="arabic simple">
<li><p>Create a pointer to an <code class="docutils literal notranslate"><span class="pre">add_reduce_kernel_attr</span></code> object: <code class="docutils literal notranslate"><span class="pre">add_reduce_kernel_attr</span> <span class="pre">*kernel_ptr</span> <span class="pre">=</span> <span class="pre">new</span> <span class="pre">add_reduce_kernel_attr</span></code>.</p></li>
<li><p>Retrieve the attribute values from <code class="docutils literal notranslate"><span class="pre">extra</span></code> and store them in the member variables of <code class="docutils literal notranslate"><span class="pre">kernel_ptr</span></code>: <code class="docutils literal notranslate"><span class="pre">kernel_data_ptr-&gt;axis</span> <span class="pre">=</span> <span class="pre">extra-&gt;Attr&lt;int64_t&gt;(&quot;axis&quot;);</span> <span class="pre">kernel_data_ptr-&gt;keep_dim</span> <span class="pre">=</span> <span class="pre">extra-&gt;Attr&lt;bool&gt;(&quot;keep_dim&quot;);</span></code>. Here, <code class="docutils literal notranslate"><span class="pre">reduce_axis</span></code> and <code class="docutils literal notranslate"><span class="pre">keep_dim</span></code> are of type <code class="docutils literal notranslate"><span class="pre">int</span></code> and <code class="docutils literal notranslate"><span class="pre">bool</span></code> respectively. We use the corresponding template function of <code class="docutils literal notranslate"><span class="pre">extra-&gt;Attr&lt;T&gt;(std::string</span> <span class="pre">name)</span></code> to obtain the value of the attribute with the given type.</p></li>
<li><p>Store <code class="docutils literal notranslate"><span class="pre">kernel_ptr</span></code> in <code class="docutils literal notranslate"><span class="pre">extra</span></code> for use during operator calculation: <code class="docutils literal notranslate"><span class="pre">extra-&gt;SetKernelData(kernel_ptr)</span></code>.</p></li>
</ol>
<p>Note: The supported types for <code class="docutils literal notranslate"><span class="pre">T</span></code> in step 2 are <code class="docutils literal notranslate"><span class="pre">bool</span></code>, <code class="docutils literal notranslate"><span class="pre">string</span></code>, <code class="docutils literal notranslate"><span class="pre">int64_t</span></code>, <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">std::vector&lt;int64_t&gt;</span></code>, <code class="docutils literal notranslate"><span class="pre">std::vector&lt;float&gt;</span></code>, <code class="docutils literal notranslate"><span class="pre">std::vector&lt;std::vector&lt;int64_t&gt;&gt;</span></code>, and <code class="docutils literal notranslate"><span class="pre">std::vector&lt;std::vector&lt;float&gt;&gt;</span></code>.</p>
</section>
<section id="operator-shape-inference-function">
<h4>Operator Shape Inference Function<a class="headerlink" href="#operator-shape-inference-function" title="Permalink to this headline"></a></h4>
<p>To define a dynamic shape scene, we define a C++ version of the operator shape inference function as follows. Notice that the operator shape inference function name is <code class="docutils literal notranslate"><span class="pre">CustomKernelInferShape</span></code>, and shares the same prefix <code class="docutils literal notranslate"><span class="pre">CustomKernel</span></code> with the initialization function name <code class="docutils literal notranslate"><span class="pre">CustomKernelInit</span></code>.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;custom_aot_extra.h&quot;</span>

<span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">CustomKernelInferShape</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">ndims</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="o">**</span><span class="n">shapes</span><span class="p">,</span><span class="w"> </span><span class="n">AotExtra</span><span class="w"> </span><span class="o">*</span><span class="n">extra</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">kDynRankSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-2</span><span class="p">;</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">kDynRankSize</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="p">{</span><span class="n">shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]};</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">extra</span><span class="o">-&gt;</span><span class="n">Attr</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;axis&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">keep_dim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">extra</span><span class="o">-&gt;</span><span class="n">Attr</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;keep_dim&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">keep_dim</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">axis</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]};</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="p">{</span><span class="n">shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">};</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="p">{</span><span class="n">shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">axis</span><span class="p">]};</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>In the above example, we need to note the following:</p>
<ul class="simple">
<li><p>According to the MindSpore specifications, dynamic shape inputs includes two cases: the dynamic shape case and the dynamic rank case, with corresponding shape inputs as follows:</p>
<ul>
<li><p>the dynamic shape case: If the size of a certain dimension of the input is unknown, it is represented by -1. For example, the shape of the input is [1024, -1, 1024], which indicates that the input is a three-dimensional tensor with dimensions of 1024 and -1 for the second dimension;</p></li>
<li><p>the dynamic rank case: The number of dimensions of the input is unknown, and the shape of the input is fixed as [-2, ].</p></li>
</ul>
</li>
<li><p>To support C++ shape inference functions, we need to handle cases when inputs are either dynamic shape or dynamic rank. For example, in the above example, if the input is of dynamic rank, the output will also be of dynamic rank. Therefore, when we find that the input is [-2, ], we directly return [-2, ].</p></li>
<li><p>For scenarios where the output shape depends on attributes, you can use the <code class="docutils literal notranslate"><span class="pre">extra-&gt;Attr&lt;T&gt;(std::string</span> <span class="pre">name)</span></code> template interface to obtain attributes.</p></li>
</ul>
</section>
<section id="operator-computation-function-main-function">
<h4>Operator Computation Function (Main Function)<a class="headerlink" href="#operator-computation-function-main-function" title="Permalink to this headline"></a></h4>
<p>The interface specification of the operator computation function is the same as that of a custom operator without attributes.
It is worth noting that the operator main function name <code class="docutils literal notranslate"><span class="pre">CustomKernel</span></code> needs to be the same as the prefix of the initialization function name <code class="docutils literal notranslate"><span class="pre">CustomKernelInit</span></code> and the operator shape inference function name <code class="docutils literal notranslate"><span class="pre">CustomKernelInferShape</span></code> mentioned above.
The main function, together with the above two functions, forms the source file <code class="docutils literal notranslate"><span class="pre">kernel.cc</span></code>.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">CustomKernel</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">nparam</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">ndims</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="o">**</span><span class="n">shapes</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">dtypes</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">stream</span><span class="p">,</span>
<span class="w">                         </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">extra_void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">constexpr</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">OUTPUT_INDEX</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>

<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">input_1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">input_2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">tmp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">3</span><span class="p">]);</span>

<span class="w">  </span><span class="c1">// Add</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">in_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">ndims</span><span class="p">[</span><span class="n">OUTPUT_INDEX</span><span class="p">];</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">in_size</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="n">shapes</span><span class="p">[</span><span class="n">OUTPUT_INDEX</span><span class="p">][</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">in_size</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">tmp</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input_1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">input_2</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// ReduceSum</span>
<span class="w">  </span><span class="n">AotExtra</span><span class="w"> </span><span class="o">*</span><span class="n">extra</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="n">AotExtra</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">extra_void</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">kernel_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="n">add_reduce_kernel_attr</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">extra</span><span class="o">-&gt;</span><span class="n">KernelData</span><span class="p">());</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">keep_dim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kernel_ptr</span><span class="o">-&gt;</span><span class="n">keep_dim</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kernel_ptr</span><span class="o">-&gt;</span><span class="n">axis</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">input_dim_1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">];</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">keep_dim</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">shapes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">shapes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">shapes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">ext</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">axis</span><span class="p">];</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">size</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">ext</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input_dim_1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">axis</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">axis</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">axis</span><span class="p">;</span>
<span class="w">      </span><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tmp</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>In the computation of Add, we used the intermediate variable of the operator, and the method is as follows:</p>
<ol class="arabic simple">
<li><p>Convert the pointers in the <code class="docutils literal notranslate"><span class="pre">params</span></code> array to <code class="docutils literal notranslate"><span class="pre">float</span> <span class="pre">*</span></code> one by one. According to the introduction of the interface above, the elements in the array are: two input address pointers (<code class="docutils literal notranslate"><span class="pre">input_1</span></code> and <code class="docutils literal notranslate"><span class="pre">input_2</span></code>), an output address pointer (<code class="docutils literal notranslate"><span class="pre">output</span></code>), and an intermediate variable address pointer (<code class="docutils literal notranslate"><span class="pre">tmp</span></code>);</p></li>
<li><p>Store the result of adding the two inputs into the intermediate variable: <code class="docutils literal notranslate"><span class="pre">tmp[i]</span> <span class="pre">=</span> <span class="pre">input_1[i]</span> <span class="pre">+</span> <span class="pre">input_2[i]</span></code>.</p></li>
</ol>
<p>In the computation of ReduceSum, we used the attribute value of the operator, and the method is as follows:</p>
<ol class="arabic simple">
<li><p>Convert the <code class="docutils literal notranslate"><span class="pre">extra_void</span></code> type to a <code class="docutils literal notranslate"><span class="pre">AotExtra</span></code> type pointer: <code class="docutils literal notranslate"><span class="pre">AotExtra</span> <span class="pre">*extra</span> <span class="pre">=</span> <span class="pre">static_cast&lt;AotExtra</span> <span class="pre">*&gt;(extra_void)</span></code>.</p></li>
<li><p>Get the <code class="docutils literal notranslate"><span class="pre">kernel_ptr</span></code> object pointer created in the initialization function from <code class="docutils literal notranslate"><span class="pre">extra</span></code>: <code class="docutils literal notranslate"><span class="pre">auto</span> <span class="pre">kernel_ptr</span> <span class="pre">=</span> <span class="pre">static_cast&lt;add_reduce_kernel_attr</span> <span class="pre">*&gt;(extra-&gt;KernelData())</span></code>. Here, <code class="docutils literal notranslate"><span class="pre">extra-&gt;KernelData()</span></code> obtains a void object pointer, which needs to be further converted to the <code class="docutils literal notranslate"><span class="pre">kernel_ptr</span></code> object pointer.</p></li>
<li><p>Use the attribute values stored in <code class="docutils literal notranslate"><span class="pre">kernel_ptr</span></code> for calculation: <code class="docutils literal notranslate"><span class="pre">bool</span> <span class="pre">keep_dim</span> <span class="pre">=</span> <span class="pre">kernel_ptr-&gt;keep_dim;</span> <span class="pre">int64_t</span> <span class="pre">axis</span> <span class="pre">=</span> <span class="pre">kernel_ptr-&gt;axis;</span></code>. Here, we obtain the variables <code class="docutils literal notranslate"><span class="pre">keep_dim</span></code> and <code class="docutils literal notranslate"><span class="pre">axis</span></code> from <code class="docutils literal notranslate"><span class="pre">kernel_ptr</span></code> for computation.</p></li>
</ol>
</section>
</section>
<section id="operator-definition-file-test-custom-aot-py">
<h3>Operator Definition File: test_custom_aot.py<a class="headerlink" href="#operator-definition-file-test-custom-aot-py" title="Permalink to this headline"></a></h3>
<p>To add aot-type custom operator to a MindSpore network using the above functions, we create the file <code class="docutils literal notranslate"><span class="pre">test_custom_aot.py</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Cell</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">DataType</span><span class="p">,</span> <span class="n">CustomRegOp</span>

<span class="k">class</span> <span class="nc">ReduceDynNet</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">out_types</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ReduceDynNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">reduce_cpu_info</span> <span class="o">=</span> <span class="n">CustomRegOp</span><span class="p">(</span><span class="s2">&quot;reduce_kernel_cpu&quot;</span><span class="p">)</span> \
            <span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;x1&quot;</span><span class="p">)</span> \
            <span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">)</span> \
            <span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">)</span> \
            <span class="o">.</span><span class="n">dtype_format</span><span class="p">(</span><span class="n">DataType</span><span class="o">.</span><span class="n">None_None</span><span class="p">,</span> <span class="n">DataType</span><span class="o">.</span><span class="n">None_None</span><span class="p">,</span> <span class="n">DataType</span><span class="o">.</span><span class="n">None_None</span><span class="p">)</span> \
            <span class="o">.</span><span class="n">attr</span><span class="p">(</span><span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="s2">&quot;required&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span> \
            <span class="o">.</span><span class="n">attr</span><span class="p">(</span><span class="s2">&quot;keep_dim&quot;</span><span class="p">,</span> <span class="s2">&quot;required&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">keep_dim</span><span class="p">)</span> \
            <span class="o">.</span><span class="n">target</span><span class="p">(</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span> \
            <span class="o">.</span><span class="n">get_op_info</span><span class="p">()</span>
        <span class="c1"># As the shape inference function of C++ version is defined above, the ouptut_shape can be &#39;None&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">program</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Custom</span><span class="p">(</span><span class="s2">&quot;./kernel.cc:CustomKernel&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">out_types</span><span class="p">,</span> <span class="s2">&quot;aot&quot;</span><span class="p">,</span> <span class="n">reg_info</span><span class="o">=</span><span class="n">reduce_cpu_info</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">ReduceDynNet</span></code> in this file includes two parts: the operator registration function and the operator definition class.</p>
<section id="operator-registration">
<h4>Operator Registration<a class="headerlink" href="#operator-registration" title="Permalink to this headline"></a></h4>
<p>The assignment of operator attributes during initialization is implemented through the operator registration function.
For the function of custom operator registration, please refer to the relevant documentation of <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/ops/mindspore.ops.CustomRegOp.html#mindspore-ops-customregop">CustomRegOp</a>.
For each attribute, we create an <code class="docutils literal notranslate"><span class="pre">attr</span></code> for the operator registration file <code class="docutils literal notranslate"><span class="pre">reduce_cpu_info</span></code>, setting the attribute name and value.</p>
<p>Each <code class="docutils literal notranslate"><span class="pre">attr</span></code> item here has four inputs: the first is the name, such as <code class="docutils literal notranslate"><span class="pre">&quot;axis&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;keep_dim&quot;</span></code>; the middle two are <code class="docutils literal notranslate"><span class="pre">&quot;required&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;all&quot;</span></code>; the last input needs to specify the input name as <code class="docutils literal notranslate"><span class="pre">value=</span></code>, and the input value is the value of the attribute, for example, <code class="docutils literal notranslate"><span class="pre">value=axis</span></code> and <code class="docutils literal notranslate"><span class="pre">value=keep_dim</span></code> here.
We determine the values of these two parameters from the network input, and these values should match the types used in the <code class="docutils literal notranslate"><span class="pre">extra-&gt;Attr&lt;T&gt;</span></code> template interface in the initialization function and shape inference function above.</p>
<p>In addition, if we need to define multiple operator registration files, we need to use different operator file names, which is the argument of <code class="docutils literal notranslate"><span class="pre">CustomRegOp</span></code>, here it is <code class="docutils literal notranslate"><span class="pre">&quot;add_with_attr_kernel_cpu&quot;</span></code>. If we want to define another operator with the same prototype but different attribute values, the name cannot be duplicated.</p>
</section>
<section id="operator-definition">
<h4>Operator Definition<a class="headerlink" href="#operator-definition" title="Permalink to this headline"></a></h4>
<p>In the Python file above, a custom operator of type <code class="docutils literal notranslate"><span class="pre">aot</span></code> is defined using the interface <code class="docutils literal notranslate"><span class="pre">Custom</span></code> of MindSpore: <code class="docutils literal notranslate"><span class="pre">self.program</span> <span class="pre">=</span> <span class="pre">ops.Custom(&quot;./kernel.cc:CustomKernel&quot;,</span> <span class="pre">None,</span> <span class="pre">out_types,</span> <span class="pre">&quot;aot&quot;,</span> <span class="pre">reg_info=reduce_cpu_info)</span></code>. Since we defined the C++ version of the shape inference function earlier, <code class="docutils literal notranslate"><span class="pre">ouptut_shape</span></code> can be set to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
<p>Notice that in the operator definition, we directly use the source file name <code class="docutils literal notranslate"><span class="pre">./kernel.cc</span></code>, so we are utilizing the automatic compilation feature provided by MindSpore. Make sure that the corresponding compiler (g++ in this case, and nvcc for GPU environment) is available in the environment.</p>
</section>
</section>
<section id="operator-call">
<h3>Operator Call<a class="headerlink" href="#operator-call" title="Permalink to this headline"></a></h3>
<p>As a test, we add the <code class="docutils literal notranslate"><span class="pre">__main__</span></code> function to the <code class="docutils literal notranslate"><span class="pre">test_custom_aot.py</span></code> file:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">keep_dim</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>

    <span class="n">input_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">input_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">test</span> <span class="o">=</span> <span class="n">ReduceDynNet</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dim</span><span class="p">)</span>
    <span class="n">dyn_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1"># set the net to dynamic shape</span>
    <span class="n">test</span><span class="o">.</span><span class="n">set_inputs</span><span class="p">(</span><span class="n">dyn_x</span><span class="p">,</span> <span class="n">dyn_x</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">input_x</span><span class="p">),</span><span class="n">Tensor</span><span class="p">(</span><span class="n">input_y</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>Execute the file to call the operator:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>test_custom_aot.py
</pre></div>
</div>
<p>Execution result is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[10. 10. 10. 10.]
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="op_custom_adv.html" class="btn btn-neutral float-left" title="Custom Operator Registration" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../optimize/execution_opt.html" class="btn btn-neutral float-right" title="Sinking Mode" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>