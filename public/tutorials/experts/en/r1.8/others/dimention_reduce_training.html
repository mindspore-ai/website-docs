<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Dimension Reduction Training Algorithm &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Custom Operators (Custom-based)" href="../operation/op_custom.html" />
    <link rel="prev" title="Adaptive Gradient Summation Algorithm" href="adaptive_summation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Data Processing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dataset/augment.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/eager.html">Lightweight Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/cache.html">Single-Node Data Cache</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/optimize.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">network</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../network/op_overload.html">Compiler optimization for optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/custom_cell_reverse.html">Customizing <strong>bprop</strong> Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/ms_class.html">Calling the Custom Class</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Training Optimization</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="gradient_accumulation.html">Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="adaptive_summation.html">Adaptive Gradient Summation Algorithm</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Dimension Reduction Training Algorithm</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#preparation">Preparation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#configuring-the-distributed-environment-variables">Configuring the Distributed Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="#preparing-the-dataset">Preparing the Dataset</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#first-stage-regular-training">First Stage: Regular Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#runtime-mode-and-backend-device-settings">Runtime Mode and Backend Device Settings</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loading-the-dataset">Loading the Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-network">Defining the Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-training-model">Defining the Training Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training-the-model">Training the Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#testing-the-model">Testing the Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#experiment-result">Experiment Result</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#second-stage-boost-mode">Second Stage: boost Mode</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-network-and-loading-the-initialization-weights">Defining the network and loading the initialization weights</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-training-model-1">Defining the Training Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training-the-model-1">Training the Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#experiment-result-1">Experiment Result</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Custom Operator</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom.html">Custom Operators (Custom-based)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../infer/inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/cpu_gpu_mindir.html">Inference on a GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/ascend_910_mindir.html">Inference on the Ascend 910 AI processor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/ascend_310_mindir.html">Inference Using the MindIR Model on Ascend 310 AI Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/ascend_310_air.html">Inference on the Ascend 310 AI Processor</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Debugging and Tuning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../debug/performance_optimization.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference external" href="https://mindspore.cn/mindinsight/docs/en/r1.8/accuracy_problem_preliminary_location.html">Precision Optimization↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Distributed Parallel</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../parallel/introduction.html">Distributed Parallel Training Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/distributed_case.html">Distributed Case</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/distributed_inference.html">Distributed Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/save_load.html">Saving and Loading Models in Hybrid Parallel Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/multi_dimensional.html">Multi Dimensional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/other_features.html">Other Features</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../env/env_var_list.html">Environment Variables</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Dimension Reduction Training Algorithm</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/others/dimention_reduce_training.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="dimension-reduction-training-algorithm">
<h1>Dimension Reduction Training Algorithm<a class="headerlink" href="#dimension-reduction-training-algorithm" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.8/tutorials/experts/source_en/others/dimention_reduce_training.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_source_en.png" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>This tutorial introduces the training method of dimension reduction training, and the purpose is to solve the problem of slow convergence of the network in the later stage of training.</p>
<p>In general network training, the early convergence is relatively fast. The late convergence enters the stable stage, and the convergence is slower. In order to improve the convergence speed in the later stage, the dimension reduction training divides the network training into two stages. In the first stage, the network is trained in the traditional way, keeping N (N&gt;32) weight files. It is recommended to abandon the weight files in the early stage, such as the first stage of training 50 epochs, starting from the 21st epoch to save the weight file. Each epoch saves 2 weight files, and there are 60 weight files at the end of the first stage. In the second stage, the weight file obtained in the first stage is loaded, and the PCA (Principal Component Analysis) is reduced. The weight is reduced from high dimension (M) to low dimension (32). The gradient descent direction and length of the weight are searched for in the low dimension, and then the weight is backprojected to the high dimension, updating the weight.</p>
<p>In view of the time-consuming  single-card training, this tutorial will use the data parallel mode on the Ascend 910 AI processor hardware platform to introduce the regular training of the first stage and how to achieve the second phase of dimension reduction training in the Boost mode by taking the resNet-50 training process on ImageNet 2012 as an example.</p>
</section>
<section id="preparation">
<h2>Preparation<a class="headerlink" href="#preparation" title="Permalink to this headline"></a></h2>
<blockquote>
<div><p>Download the complete sample code from:</p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/tree/r1.8/docs/sample_code/dimension_reduce_training">https://gitee.com/mindspore/docs/tree/r1.8/docs/sample_code/dimension_reduce_training</a></p>
<p>The models library links referenced in the code:</p>
<p><a class="reference external" href="https://gitee.com/mindspore/models">https://gitee.com/mindspore/models</a></p>
</div></blockquote>
<section id="configuring-the-distributed-environment-variables">
<h3>Configuring the Distributed Environment Variables<a class="headerlink" href="#configuring-the-distributed-environment-variables" title="Permalink to this headline"></a></h3>
<p>When performing distributed training on the local Ascend processor, you need to configure the networking information file of the current multi-card environment. The json file of an 8-card environment is configured as follows, and the configuration file is named rank_table_8pcs.json. rank_table can be generated using the <a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.8/utils/hccl_tools/hccl_tools.py">hccl_tools.py</a> below the models.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1.0&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;server_count&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;server_list&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;server_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;10.*.*.*&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.1.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.2.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.3.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;3&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.4.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;3&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;4&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.1.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;4&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;5&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.2.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;5&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;6&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.3.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;6&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;7&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.4.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;7&quot;</span><span class="p">}],</span>
<span class="w">             </span><span class="nt">&quot;host_nic_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;reserve&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;completed&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="preparing-the-dataset">
<h3>Preparing the Dataset<a class="headerlink" href="#preparing-the-dataset" title="Permalink to this headline"></a></h3>
<p>Used dataset: <a class="reference external" href="http://www.image-net.org/">ImageNet 2012</a></p>
<ul class="simple">
<li><p>The size of the dataset: 1000 classes and 224*224 color images in totoal</p>
<ul>
<li><p>Training set: 1,281,167 images in total</p></li>
<li><p>Test set: 50000 images in total</p></li>
</ul>
</li>
<li><p>Data format: JPEG</p></li>
<li><p>Download the dataset, and the directory structure is as follows:</p></li>
</ul>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─dataset
    ├─train                 # Training the dataset
    └─validation_preprocess # Evaluating the dataset
</pre></div>
</div>
</section>
</section>
<section id="first-stage-regular-training">
<h2>First Stage: Regular Training<a class="headerlink" href="#first-stage-regular-training" title="Permalink to this headline"></a></h2>
<blockquote>
<div><p>The main training sample code for the first phase:</p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.8/docs/sample_code/dimension_reduce_training/train_stage_1.py">https://gitee.com/mindspore/docs/blob/r1.8/docs/sample_code/dimension_reduce_training/train_stage_1.py</a>.</p>
</div></blockquote>
<section id="runtime-mode-and-backend-device-settings">
<h3>Runtime Mode and Backend Device Settings<a class="headerlink" href="#runtime-mode-and-backend-device-settings" title="Permalink to this headline"></a></h3>
<p>Specify the operating mode, running card number, parallel mode. through the context interface provided by MindSpore, and initialize the HCCL communication through init.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device_target</span><span class="p">)</span>
<span class="n">device_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;DEVICE_ID&#39;</span><span class="p">))</span>
<span class="n">set_context</span><span class="p">(</span><span class="n">device_id</span><span class="o">=</span><span class="n">device_id</span><span class="p">)</span>
<span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">device_num</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">parallel_mode</span><span class="o">=</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">DATA_PARALLEL</span><span class="p">,</span> <span class="n">gradients_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">all_reduce_fusion_config</span> <span class="o">=</span> <span class="p">[</span><span class="mi">85</span><span class="p">,</span> <span class="mi">160</span><span class="p">]</span>
<span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">all_reduce_fusion_config</span><span class="o">=</span><span class="n">all_reduce_fusion_config</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="loading-the-dataset">
<h3>Loading the Dataset<a class="headerlink" href="#loading-the-dataset" title="Permalink to this headline"></a></h3>
<p>Image loading interface ImageFolderDataset is used to load the ImageNet 2012 dataset by using MindSpore. The dataset is processed through the data augmentation interface provided by MindSpore, and this part of the code is imported by <a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.8/official/cv/resnet/src/dataset.py">dataset.py</a> in the <code class="docutils literal notranslate"><span class="pre">resnet</span></code> directory in the models.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># define train dataset</span>
<span class="n">train_data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">)</span>
<span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="o">=</span><span class="n">train_data_path</span><span class="p">,</span> <span class="n">do_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">train_image_size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span>
                          <span class="n">eval_image_size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device_target</span><span class="p">,</span> <span class="n">distribute</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">step_size</span> <span class="o">=</span> <span class="n">ds_train</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="defining-the-network">
<h3>Defining the Network<a class="headerlink" href="#defining-the-network" title="Permalink to this headline"></a></h3>
<p>The build code for the ResNet-50 network is imported by <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.8/docs/sample_code/adasum/resnet.py">resnet.py</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># define net</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="mi">1001</span><span class="p">)</span>
<span class="n">init_weight</span><span class="p">(</span><span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="defining-the-training-model">
<h3>Defining the Training Model<a class="headerlink" href="#defining-the-training-model" title="Permalink to this headline"></a></h3>
<p>Define the loss functions loss and optimizer required by the model.</p>
<p>Loss uses CrossEntropySmooth, imported by <a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.8/official/cv/resnet/src/CrossEntropySmooth.py">CrossEntropySmooth.py</a> in the <code class="docutils literal notranslate"><span class="pre">resnet</span></code> directory in ModelZoo.</p>
<p>The build code for the learning rate lr is imported by <a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.8/official/cv/resnet/src/lr_generator.py">lr_generator.py</a> in the <code class="docutils literal notranslate"><span class="pre">resnet</span></code> directory in the models.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># define loss</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">CrossEntropySmooth</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="n">smooth_factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1001</span><span class="p">)</span>
<span class="n">loss_scale</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">drop_overflow_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># define optimizer</span>
<span class="n">group_params</span> <span class="o">=</span> <span class="n">init_group_params</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">get_lr</span><span class="p">(</span><span class="n">lr_init</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lr_end</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">warmup_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">total_epochs</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span>
            <span class="n">lr_decay_mode</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">group_params</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span>

<span class="c1"># define metrics</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;acc&quot;</span><span class="p">}</span>

<span class="c1"># define model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O2&quot;</span><span class="p">,</span>
              <span class="n">boost_level</span><span class="o">=</span><span class="s2">&quot;O0&quot;</span><span class="p">,</span> <span class="n">keep_batchnorm_fp32</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="training-the-model">
<h3>Training the Model<a class="headerlink" href="#training-the-model" title="Permalink to this headline"></a></h3>
<p>Before the training starts, define the callback function callback, add the training time information output, loss information output, and weight saving, where the model weights are only saved on 0 cards.</p>
<p>callback_1 save all the weights of the network and the state of the optimizer, and callback_2 only the weights in the network that participate in the update for the second phase of PCA.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># define callback_1</span>
<span class="n">cb</span> <span class="o">=</span> <span class="p">[</span><span class="n">TimeMonitor</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="n">step_size</span><span class="p">),</span> <span class="n">LossMonitor</span><span class="p">()]</span>
<span class="k">if</span> <span class="n">get_rank_id</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">step_size</span> <span class="o">*</span> <span class="mi">10</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">ck_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;resnet&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;./checkpoint_stage_1&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
    <span class="n">cb</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ck_cb</span><span class="p">]</span>

<span class="c1"># define callback_2: save weights for stage 2</span>
<span class="k">if</span> <span class="n">get_rank_id</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
                                 <span class="n">saved_network</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
    <span class="n">ck_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;resnet&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;./checkpoint_stage_1/checkpoint_pca&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
    <span class="n">cb</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ck_cb</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;============== Starting Training ==============&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">70</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">cb</span><span class="p">,</span> <span class="n">sink_size</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="testing-the-model">
<h3>Testing the Model<a class="headerlink" href="#testing-the-model" title="Permalink to this headline"></a></h3>
<p>First define the test model, then load the test data set to test the accuracy of the model. Judged by rank_id, the model is tested only on 0 cards.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">get_rank_id</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;============== Starting Testing ==============&quot;</span><span class="p">)</span>
    <span class="n">eval_data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">)</span>
    <span class="n">ds_eval</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="o">=</span><span class="n">eval_data_path</span><span class="p">,</span> <span class="n">do_train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ds_eval</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Please check dataset size &gt; 0 and batch_size &lt;= dataset size&quot;</span><span class="p">)</span>

    <span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">ds_eval</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;============== </span><span class="si">{}</span><span class="s2"> ==============&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="experiment-result">
<h3>Experiment Result<a class="headerlink" href="#experiment-result" title="Permalink to this headline"></a></h3>
<p>After 70 rounds of epoch, the accuracy on the test set is about 66.05%.</p>
<ol class="arabic">
<li><p>Call the run script [run_stage_1.sh] (https://gitee.com/mindspore/docs/blob/r1.8/docs/sample_code/dimension_reduce_training/run_stage_1.sh) to view the run results. Running the script requires a given dataset path, and the model is saved under device0_stage_1/checkpoint_stage_1 by default.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>run_stage_1.sh<span class="w"> </span>./imagenet
</pre></div>
</div>
<p>The output is as follows, and you can see that the loss value gradually decreases with the training:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>============== Starting Training ==============
epoch: 1 step: 625 loss is  5.2477064
...
epoch: 10 step: 625 loss is  3.0178385
...
epoch: 30 step: 625 loss is  2.4231198
...
...
epoch: 70 step: 625 loss is  2.3120291
</pre></div>
</div>
</li>
<li><p>View the inference precision.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>============== Starting Testing ==============
============== {&#39;Accuracy&#39;: 0.6604992988782051} ==============
</pre></div>
</div>
</li>
</ol>
</section>
</section>
<section id="second-stage-boost-mode">
<h2>Second Stage: boost Mode<a class="headerlink" href="#second-stage-boost-mode" title="Permalink to this headline"></a></h2>
<p>Based on the weight file obtained in the first stage, in the Boost mode, we can realize the function of dimension reduction training by simply calling the dimension reduction training interface of mindspore.boost.</p>
<blockquote>
<div><p>The main training sample code for the second phase:</p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.8/docs/sample_code/dimension_reduce_training/train_boost_stage_2.py">https://gitee.com/mindspore/docs/blob/r1.8/docs/sample_code/dimension_reduce_training/train_boost_stage_2.py</a>.</p>
</div></blockquote>
<p>The code for the second and first stages is essentially the same, and only the inconsistencies are described below.</p>
<section id="defining-the-network-and-loading-the-initialization-weights">
<h3>Defining the network and loading the initialization weights<a class="headerlink" href="#defining-the-network-and-loading-the-initialization-weights" title="Permalink to this headline"></a></h3>
<p>After the network is built, the weight file at the end of the first stage of training is loaded, and the second stage of training is carried out on this basis.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># define net</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="mi">1001</span><span class="p">)</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">pretrained_weight_path</span><span class="p">):</span>
    <span class="n">weight_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">pretrained_weight_path</span><span class="p">)</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">weight_dict</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="defining-the-training-model-1">
<h3>Defining the Training Model<a class="headerlink" href="#defining-the-training-model-1" title="Permalink to this headline"></a></h3>
<p>Unlike the first phase, the second stage uses the SGD optimizer to update the network weights. In addition to this, the parameters required for dimension reduction training need to be configured, which is built in the form of a dictionary. First of all, you need to set the type of boost to manual setting, open dimension reduction training (dim_reduce), then configure the number of cards used by each server node, and finally configure some hyperparameters of dimension reduction training. In addition, when defining the model, you also need to open the boost_level (set to “O1” or “O2”).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># define loss</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">CrossEntropySmooth</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="n">smooth_factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1001</span><span class="p">)</span>

<span class="c1"># define optimizer</span>
<span class="n">group_params</span> <span class="o">=</span> <span class="n">init_group_params</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">group_params</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># define metrics</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;acc&quot;</span><span class="p">}</span>

<span class="c1"># define boost config dictionary</span>
<span class="n">boost_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;boost&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;mode&quot;</span><span class="p">:</span> <span class="s2">&quot;manual&quot;</span><span class="p">,</span>
        <span class="s2">&quot;dim_reduce&quot;</span><span class="p">:</span> <span class="kc">True</span>
    <span class="p">},</span>
    <span class="s2">&quot;common&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;device_num&quot;</span><span class="p">:</span> <span class="mi">8</span>
    <span class="p">},</span>
    <span class="s2">&quot;dim_reduce&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;rho&quot;</span><span class="p">:</span> <span class="mf">0.55</span><span class="p">,</span>
        <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span>
        <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
        <span class="s2">&quot;sigma&quot;</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span>
        <span class="s2">&quot;n_component&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>                                                 <span class="c1"># PCA component</span>
        <span class="s2">&quot;pca_mat_path&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">pca_mat_path</span><span class="p">,</span>                                 <span class="c1"># the path to load pca mat</span>
        <span class="s2">&quot;weight_load_dir&quot;</span><span class="p">:</span> <span class="s2">&quot;./checkpoint_stage_1/checkpoint_pca&quot;</span><span class="p">,</span>          <span class="c1"># the directory to load weight file saved as ckpt.</span>
        <span class="s2">&quot;timeout&quot;</span><span class="p">:</span> <span class="mi">1200</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># define model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="n">boost_level</span><span class="o">=</span><span class="s2">&quot;O1&quot;</span><span class="p">,</span> <span class="n">boost_config_dict</span><span class="o">=</span><span class="n">boost_dict</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="training-the-model-1">
<h3>Training the Model<a class="headerlink" href="#training-the-model-1" title="Permalink to this headline"></a></h3>
<p>In the second stage, we set epoch as 2.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># define callback</span>
<span class="n">cb</span> <span class="o">=</span> <span class="p">[</span><span class="n">TimeMonitor</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="n">step_size</span><span class="p">),</span> <span class="n">LossMonitor</span><span class="p">()]</span>
<span class="k">if</span> <span class="n">get_rank_id</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ck_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;resnet&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;./checkpoint_stage_2&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
    <span class="n">cb</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ck_cb</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;============== Starting Training ==============&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">cb</span><span class="p">,</span> <span class="n">sink_size</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="experiment-result-1">
<h3>Experiment Result<a class="headerlink" href="#experiment-result-1" title="Permalink to this headline"></a></h3>
<p>After 2 rounds of epoch, the accuracy on the test set is about 74.31%.</p>
<ol class="arabic">
<li><p>Call the run script <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.8/docs/sample_code/dimension_reduce_training/run_stage_2.sh">run_stage_2.sh</a> to view the run results. Running the script requires a given dataset path. Weight file at the end of the first phase of training, and weight file saved in the second phase under device0_stage_2/checkpoint_stage_2 by default.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>run_stage_2.sh<span class="w"> </span>./imagenet<span class="w"> </span>./device0_stage_1/checkpoint_stage_1/resnet-70_625.ckpt
</pre></div>
</div>
<p>If you have already done PCA to the weights of the first stage and saved the feature transformation matrix, you can give the feature transformation matrix file path, eliminating the process of finding the feature transformation matrix.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>run_stage_2.sh<span class="w"> </span>./imagenet<span class="w"> </span>./device0_stage_1/checkpoint_stage_1/resnet-70_625.ckpt<span class="w"> </span>/path/pca_mat.npy
</pre></div>
</div>
<p>The output is as follows, and you can see that the loss value gradually decreases with the training:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 1 step: 625 loss is  2.3422508
epoch: 2 step: 625 loss is  2.1641185
</pre></div>
</div>
</li>
<li><p>Look at the inference precision, and the code saves the checkpoint to the current directory, and then loads the checkpoint to perform the inference.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>============== Starting Testing ==============
============== {&#39;Accuracy&#39;: 0.7430964543269231} ==============
</pre></div>
</div>
</li>
</ol>
<p>Generally ResNet-50 training 80 epochs also only reached 70.18%. Using dimension reduction training, we can reach 74.31% in 72 epochs.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="adaptive_summation.html" class="btn btn-neutral float-left" title="Adaptive Gradient Summation Algorithm" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../operation/op_custom.html" class="btn btn-neutral float-right" title="Custom Operators (Custom-based)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>