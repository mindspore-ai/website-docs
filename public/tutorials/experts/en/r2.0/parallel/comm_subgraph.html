<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Communication Subgraph Extraction and Reuse &mdash; MindSpore master documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Dataset Slicing" href="dataset_slice.html" />
    <link rel="prev" title="Distributed Training Communication Fusion" href="comm_fusion.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Data Processing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dataset/augment.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/cache.html">Single-Node Data Cache</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/optimize.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Graph Compilation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../network/control_flow.html">Process Control Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/op_overload.html">Compiling Performance Optimization for Static Graph Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/jit_class.html">Calling the Custom Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/constexpr.html">Construct Constants In the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/dependency_control.html">Dependency Control</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Training Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../optimize/execution_opt.html">Sinking Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/gradient_accumulation.html">Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/adaptive_summation.html">Adaptive Gradient Summation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/dimention_reduce_training.html">Dimension Reduction Training Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/thor.html">Second-order Optimization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Custom Operator</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom.html">Custom Operators (Custom-based)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/ms_kernel.html">MindSpore Hybrid Syntax Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom_adv.html">Advanced Usage of Custom Operators</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Automatic Vectorization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../vmap/vmap.html">Automatic Vectorization (Vmap)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../infer/inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/model_compression.html">Model Compression</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Debugging and Tuning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../debug/function_debug.html">Function Debug</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/performance_optimization.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference external" href="https://mindspore.cn/mindinsight/docs/en/r2.0/accuracy_problem_preliminary_location.html">Precision Optimization↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Distributed Parallel</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Distributed Parallel Training Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="parallel_training_quickstart.html">Quick Start Distributed Parallel Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="communicate_ops.html">Distributed Set Communication Primitives</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_case.html">Distributed Case</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_inference.html">Distributed Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_load.html">Saving and Loading Models in Hybrid Parallel Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="fault_recover.html">Distributed Fault Recovery</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_dimensional.html">Multi Dimensional</a></li>
<li class="toctree-l1"><a class="reference internal" href="resilience_train_and_predict.html">Distributed Resilience Training and Inference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="other_features.html">Other Features</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="sharding_propagation.html">Sharding Propagation</a></li>
<li class="toctree-l2"><a class="reference internal" href="parameter_server_training.html">Parameter Server Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="comm_fusion.html">Distributed Training Communication Fusion</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Communication Subgraph Extraction and Reuse</a></li>
<li class="toctree-l2"><a class="reference internal" href="dataset_slice.html">Dataset Slicing</a></li>
<li class="toctree-l2"><a class="reference internal" href="pynative_shard_function_parallel.html">Functional Operator Sharding</a></li>
<li class="toctree-l2"><a class="reference internal" href="ms_operator.html">Performing Distributed Training on K8S Clusters</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../env/env_var_list.html">Environment Variables</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="other_features.html">Other Features</a> &raquo;</li>
      <li>Communication Subgraph Extraction and Reuse</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/parallel/comm_subgraph.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="communication-subgraph-extraction-and-reuse">
<h1>Communication Subgraph Extraction and Reuse<a class="headerlink" href="#communication-subgraph-extraction-and-reuse" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r2.0/tutorials/experts/source_en/parallel/comm_subgraph.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0/resource/_static/logo_source_en.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>In order to improve the accuracy of the model, it is a common means to continuously expand the model size, and it is not uncommon to see large models with more than 100 million parameters at present. However, as the scale of large models such as Pangu increases, the number of communication operators required for distributed training also rises dramatically. It will increase the communication time consumption for model compilation, and consume a large amount of stream resources. When the number of required streams exceeds the hardware limit, the model size cannot continue to scale up, thus becoming a bottleneck in the development of large models.</p>
<p>By extracting communication subgraphs by categorizing communication operators and reducing the number of communication operators in graph compilation, on the one hand, communication time consumption and model compilation time consumption can be reduced; on the other hand, the stream occupancy is reduced, making the model further scalable. For example, micro size can be further increased in pipeline parallel mode.</p>
<p>This feature currently only supports Ascend backend graph mode, and involves scenarios for distributed training. When there are a large number of communication operators in the computational graph, users can use this feature to improve graph compilation performance and reduce graph compilation time.</p>
</section>
<section id="basic-principle">
<h2>Basic Principle<a class="headerlink" href="#basic-principle" title="Permalink to this headline"></a></h2>
<p>With this feature turned on, the MindSpore framework will perform the following steps:</p>
<ol class="arabic simple">
<li><p>Check if it is a graph mode and if this feature is turned on, otherwise it does not enter the optimization step of this feature.</p></li>
<li><p>Identify all reusable communication operators in the computational graph.</p></li>
<li><p>Group communication operators of the same type, the same shape, the same dtype and the same group in the same group. If the number of communication operators in a group exceeds the upper limit of communication operators that can be carried on a stream, the communication operator subgraph is created according to the operator type, shape, and dtype of the group.</p></li>
<li><p>Replace the communication operator in the original computational graph with the Call node and call the corresponding communication subgraph.</p></li>
</ol>
<p><img alt="Comm Subgraph Reuse Description" src="../_images/comm_subgraph.png" /></p>
<p>Since the communication operator in the communication subgraph occupies only one communication stream, the number of communication streams actually used will drop to 1 after replacing the communication operator in the original computational graph with a call to the communication subgraph. For example, if there are 30 AllReduce operators that can be grouped in the same group, and each communication stream can carry up to 3 communication operators, 10 communication streams are required before this feature can be turned on. With this feature turned on, the AllReduce subgraph occupies only 1 communication stream, thus saving 9 communication streams. Also, the time consumed by graph compilation for communication will be reduced due to the reduced number of communication operators processed in the compilation phase.</p>
</section>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this headline"></a></h2>
<p>The user can turn on the feature switch via the environment variable MS_COMM_COMPILER_OPT and configure the upper limit of the communication operators that can be reused. MS_COMM_COMPILER_OPT can be set to -1 or a positive integer to turn on this feature. If this environment variable is not set or set to another value, this feature will not be turned on. For the detailed information, refer to the following table. When this feature is turned on, the INFO log prints “MAX_COMM_OP_REUSE_NUM: xxx”, indicating the upper limit of the reusable communication operator being used by the framework.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>MS_COMM_COMPILER_OPT</p></th>
<th class="head"><p>Descriptions</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>-1</p></td>
<td><p>Turn on this feature and use default communication operator reuse limit of the framework: 1000</p></td>
</tr>
<tr class="row-odd"><td><p>Positive Integer</p></td>
<td><p>Turn on this feature, and use a positive integer set by the user as the upper limit of communication operator reuse</p></td>
</tr>
<tr class="row-even"><td><p>Not setting/Others</p></td>
<td><p>Turn off this feature</p></td>
</tr>
</tbody>
</table>
<p>Since the root diagram generates a large number of labels for multiple calls to the communication subgraph, when the user sets the MS_COMM_COMPILER_OPT value too large and exceeds the number limit of labels in the hardware, it will trigger the framework to report an error. Users can search the following logs to reduce the MS_COMM_COMPILER_OPT value appropriately:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>Label<span class="w"> </span>list<span class="w"> </span>size:<span class="w">  </span><span class="c1"># Indicate the total number of labels used for graph compilation</span>
Reuse<span class="w"> </span>comm<span class="w"> </span>op<span class="w"> </span>reused_comm_sub_graphs_<span class="w"> </span>size:<span class="w">  </span><span class="c1"># Indicate the number of communication operators that will eventually be reused</span>
Start<span class="w"> </span>reuse<span class="w"> </span><span class="c1"># This number of logs indicates the number of communication subgraphs generated</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="comm_fusion.html" class="btn btn-neutral float-left" title="Distributed Training Communication Fusion" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="dataset_slice.html" class="btn btn-neutral float-right" title="Dataset Slicing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>