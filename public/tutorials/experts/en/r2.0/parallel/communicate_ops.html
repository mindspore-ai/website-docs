<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Distributed Set Communication Primitives &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Distributed Case" href="distributed_case.html" />
    <link rel="prev" title="Quick Start Distributed Parallel Training" href="parallel_training_quickstart.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Data Processing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dataset/augment.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/cache.html">Single-Node Data Cache</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/optimize.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Graph Compilation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../network/control_flow.html">Process Control Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/op_overload.html">Compiling Performance Optimization for Static Graph Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/jit_class.html">Calling the Custom Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/constexpr.html">Construct Constants In the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/dependency_control.html">Dependency Control</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Training Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../optimize/execution_opt.html">Sinking Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/gradient_accumulation.html">Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/adaptive_summation.html">Adaptive Gradient Summation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/dimention_reduce_training.html">Dimension Reduction Training Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/thor.html">Second-order Optimization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Custom Operator</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom.html">Custom Operators (Custom-based)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/ms_kernel.html">MindSpore Hybrid Syntax Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom_adv.html">Advanced Usage of Custom Operators</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Automatic Vectorization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../vmap/vmap.html">Automatic Vectorization (Vmap)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../infer/inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/model_compression.html">Model Compression</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Debugging and Tuning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../debug/function_debug.html">Function Debug</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/performance_optimization.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference external" href="https://mindspore.cn/mindinsight/docs/en/r2.0/accuracy_problem_preliminary_location.html">Precision Optimization↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Distributed Parallel</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Distributed Parallel Training Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="parallel_training_quickstart.html">Quick Start Distributed Parallel Training</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Distributed Set Communication Primitives</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_case.html">Distributed Case</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_inference.html">Distributed Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_load.html">Saving and Loading Models in Hybrid Parallel Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="fault_recover.html">Distributed Fault Recovery</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_dimensional.html">Multi Dimensional</a></li>
<li class="toctree-l1"><a class="reference internal" href="resilience_train_and_predict.html">Distributed Resilience Training and Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="other_features.html">Other Features</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../env/env_var_list.html">Environment Variables</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Distributed Set Communication Primitives</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/parallel/communicate_ops.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="distributed-set-communication-primitives">
<h1>Distributed Set Communication Primitives<a class="headerlink" href="#distributed-set-communication-primitives" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.0/tutorials/experts/source_en/parallel/communicate_ops.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0/resource/_static/logo_source_en.png" /></a></p>
<p>Distributed training involves communication operations such as <code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>, <code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code>, <code class="docutils literal notranslate"><span class="pre">AllGather</span></code> and <code class="docutils literal notranslate"><span class="pre">Broadcast</span></code> for data transfer, and we will explain their meaning and sample code in the following sections.</p>
<p>Examples of different communication operations by using 4 GPUs are given in each of the following sections. The output in the example comes from the results of the <code class="docutils literal notranslate"><span class="pre">rank0</span></code> program on card 0. The user needs to save each section code below as a separate communication.py. Because it involves a multi-card program, the user needs to go through the <code class="docutils literal notranslate"><span class="pre">mpirun</span></code> command to start communication.py. The <code class="docutils literal notranslate"><span class="pre">mpirun</span></code> commands requires the installation of OpenMPI as well as NCCL, and please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r2.0/parallel/train_gpu.html">here</a> for the corresponding installation.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mpirun<span class="w"> </span>-output-filename<span class="w"> </span>log<span class="w"> </span>-merge-stderr-to-stdout<span class="w"> </span>-np<span class="w"> </span><span class="m">4</span><span class="w"> </span>python<span class="w"> </span>communication.py
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">-np</span></code> in the above code means that 4 process tasks will be started, occupying cards 0, 1, 2 and 3 respectively, and the output logs will be saved under the <code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code> directory. The user can view the output of the program here. <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">communication.py</span></code> indicates starting the script.</p>
<section id="allreduce">
<h2>AllReduce<a class="headerlink" href="#allreduce" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="https://gitee.com/mindspore/docs/raw/r2.0/tutorials/experts/source_zh_cn/parallel/images/allreduce.png" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">AllReduce</span></code> operation sums the input Tensor of the <code class="docutils literal notranslate"><span class="pre">AllReduce</span></code> operator in each card. Finally, the output of the <code class="docutils literal notranslate"><span class="pre">AllReduce</span></code> operator in each card is the same value. For example, as shown in the figure above, the input to the AllReduce operator for each card is <code class="docutils literal notranslate"><span class="pre">0,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">3</span></code>. After <code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>, the output of each card is the sum of all card inputs as 6(0+1+2+3).</p>
<p>The sample code is as follows: we initialize the value of the <code class="docutils literal notranslate"><span class="pre">AllReduce</span></code> operator input in each process based on the rank number (the communication number to which each card belongs), e.g. for card 0, we request an input of size 1x1 with a value of 0. Then call the <code class="docutils literal notranslate"><span class="pre">AllReduce</span></code> operator to communicate among the cards with communication domain <code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code> (communication range of all cards i.e. nccl_world_group) and print the output results.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_reduce_sum</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">AllReduce</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s2">&quot;nccl_world_group&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">value</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">value</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The card 0 runs as follows, and the output log path is <code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[6.]]
</pre></div>
</div>
</section>
<section id="allgather">
<h2>AllGather<a class="headerlink" href="#allgather" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="https://gitee.com/mindspore/docs/raw/r2.0/tutorials/experts/source_zh_cn/parallel/images/allgather.png" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">AllGather</span></code> operation will stitch the 0th dimension of the input Tensor on each card, and the final output of each card is the same value. For example, as shown above, the input of each card is a Tensor of size 1x1. After the <code class="docutils literal notranslate"><span class="pre">AllGather</span></code> operation, the output shape of the <code class="docutils literal notranslate"><span class="pre">AllGather</span></code> operator of each card is [4,1]. The element values with index [0,0] are from the input [[0.0]] of card 0 <code class="docutils literal notranslate"><span class="pre">AllGather</span></code>, and the element values with index [1,0] are from the input [[1.0]] of card 1 <code class="docutils literal notranslate"><span class="pre">AllGather</span></code>.</p>
<p>The sample code is as follows: we initialize the value of the <code class="docutils literal notranslate"><span class="pre">AllGather</span></code> operator input in each process based on the rank number (the communication number to which each card belongs), e.g. for card 0, we request an input of size 1x1 with a value of 0. Then call the <code class="docutils literal notranslate"><span class="pre">AllGather</span></code> operator to communicate among the cards with communication domain <code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code> (communication range of all cards i.e. nccl_world_group) and print the output results.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_gather</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">AllGather</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">value</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">value</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The result of the run is as follows, with the output log path <code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[0.],
 [1.],
 [2.],
 [3.]]
</pre></div>
</div>
</section>
<section id="reducescatter">
<h2>ReduceScatter<a class="headerlink" href="#reducescatter" title="Permalink to this headline"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code> operation will first sum the input of each card and then slice the data by number of cards in the 0th dimension and distribute the data to the corresponding card. For example, as shown above, the input of each card is a 4x1 Tensor. <code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code> first sums the input to get Tensor of [0, 4, 8, 12], and then distributes it to get Tensor of size 1x1 per card. For example, the output result corresponding to card 0 is [[0.0]], and the output result corresponding to card 1 is [[4.0]].</p>
<p>The sample code is as follows: we initialize the value of the <code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code> operator input in each process based on the rank number (the communication number to which each card belongs), e.g. for card 0, we request an input of size 4x1 with a value of 0. Then call the <code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code> operator to communicate among the cards with communication domain <code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code> (communication range of all cards i.e. nccl_world_group) and print the output results.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduce_scatter</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceScatter</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduce_scatter</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The running result is as follows, with the output log path <code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[0.]]
</pre></div>
</div>
</section>
<section id="broadcast">
<h2>Broadcast<a class="headerlink" href="#broadcast" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="https://gitee.com/mindspore/docs/raw/r2.0/tutorials/experts/source_zh_cn/parallel/images/broadcast.png" /></p>
<p>The sample code is as follows: we set the root node of the <code class="docutils literal notranslate"><span class="pre">Broadcast</span></code> operator to card 0, indicating that data will be broadcast from card 0 to other cards. We request an input of size 1x1 with a value of 0. Then call the <code class="docutils literal notranslate"><span class="pre">Broadcast</span></code> operator to communicate among the cards with communication domain <code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code> (communication range of all cards i.e. nccl_world_group). Finally, the output value of each card is from card 0.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">broadcast</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Broadcast</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">broadcast</span><span class="p">((</span><span class="n">x</span><span class="p">,))</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The result of the run is as follows, with the output log path <code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[0]]
</pre></div>
</div>
</section>
<section id="neighborexchange">
<h2>NeighborExchange<a class="headerlink" href="#neighborexchange" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="https://gitee.com/mindspore/docs/raw/r2.0/tutorials/experts/source_zh_cn/parallel/images/NeighborExchange.png" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">NeighborExchange</span></code> operation will provide a set of data to be sent to each of the other specific cards while receiving data from the specific card. For example, in the above figure, rank 0 sends a Tensor with shape [16,16] to rank 1 and receives a Tensor with shape [32,32] from rank 1. rank 1 sends a Tensor with shape [32,32] to rank 0 and receives a Tensor with shape [16,16] from rank 0. Finally, the rank 0 outputs the received Tensor with shape [32,32], and rank 1 outputs the received Tensor with [16,16].</p>
<p>The example code as follows: we use the <code class="docutils literal notranslate"><span class="pre">NeighborExchange</span></code> operator for data exchange between card 0 and card 1, sending data from card 0 to card 1, and receiving data from card 1. Card 1 sends data to card 0 and receives data from card 0. Finally each card outputs the received data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Net0</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net0</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchange</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],),</span> <span class="n">send_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],),</span> <span class="n">recv_type</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span><span class="p">((</span><span class="n">x</span><span class="p">,))</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">Net1</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net1</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchange</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">recv_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],),</span> <span class="n">send_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],),</span> <span class="n">recv_type</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span><span class="p">((</span><span class="n">x</span><span class="p">,))</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">rank_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;RANK_ID&quot;</span><span class="p">))</span>
<span class="k">if</span> <span class="p">(</span><span class="n">rank_id</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net0</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net1</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>Use a shell script to start the 2-card script. The <code class="docutils literal notranslate"><span class="pre">rank_table_file</span></code> file below can be generated by hccl_tools.py under <a class="reference external" href="https://gitee.com/mindspore/models">models</a>, which corresponds to the directory file <code class="docutils literal notranslate"><span class="pre">models/utils/</span> <span class="pre">hccl_tools</span></code>. The sample shell script is as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_HCCL_CONFIG_PATH</span><span class="o">=</span>rank_table_file
<span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_NUM</span><span class="o">=</span><span class="m">2</span>
<span class="nv">BASE_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$0</span><span class="k">)</span><span class="s2">&quot;</span><span class="p">;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>
<span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;<span class="nv">$DEVICE_NUM</span><span class="p">;</span><span class="w"> </span>i++<span class="o">))</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>mkdir<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>cp<span class="w"> </span>-r<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/neighborexchange.py<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>/
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training for device </span><span class="nv">$i</span><span class="s2">&quot;</span>
<span class="w">    </span>python<span class="w"> </span>neighborexchange.py<span class="w"> </span>&gt;<span class="w"> </span>log.txt<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="k">done</span>
</pre></div>
</div>
<p>The results of rank0 are:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[2. 2.]
 [2. 2.]]
</pre></div>
</div>
<p>The results of rank1 are:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[1. 1. 1.]
 [1. 1. 1.]
 [1. 1. 1.]]
</pre></div>
</div>
</section>
<section id="neighborexchangev2">
<h2>NeighborExchangeV2<a class="headerlink" href="#neighborexchangev2" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="https://gitee.com/mindspore/docs/raw/r2.0/tutorials/experts/source_zh_cn/parallel/images/neighborexchangev2.png" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">NeighborExchangeV2</span></code> operation sends part of the data in the Tensor to the surrounding 8 cards according to the attribute settings, and receives data from the surrounding 8 cards and stitches them into a new Tensor, which is often used in scenarios where a large Tensor is sliced on multiple cards for distributed convolutional operations. Attributes send_rank_ids and recv_rank_ids are 8 numbers, respectively, indicating sending/receiving rank_id in 8 directions, and filling -1 means no send/no receive. As shown above, figure 2 indicates the order corresponding to the 8 directions. The attributes send_lens and recv_lens are four numbers that represent the send/receive lengths in the four directions [top, bottom, left, right], respectively. For example, in Figure 1 above, a 16-card example is shown, taking rank 10 as an example, setting send_rank_ids=[6,7,11,15,14,13,9,5], the data of rank 10 is sliced and sent to rank 5, 6, 7, 11, 15, 14, 13, 9 respectively, for example, red in Figure is sent to rank 5, red, yellow and blue to rank 6, blue to rank 7, etc. Setting recv_rank_ids=[6,7,11,15,14,13,9,5], at the same time rank10 receives some data from each of these cards stitched into the corresponding direction to form a new Tensor output, as shown in the figure with rank10 and the light green part.</p>
<p>The sample code is as follows: we use the <code class="docutils literal notranslate"><span class="pre">NeighborExchangeV2</span></code> operator for data exchange between card 0 and card 1, sending the data below card 0 to card 1 and receiving the data from card 1 stitched below. Card 1 sends the upper part of the data to card 0 and receives the data from card 0 stitched on top. Finally each card outputs the received data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Net0</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net0</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchangeV2</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">send_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="k">class</span> <span class="nc">Net1</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net1</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchangeV2</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">send_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">rank_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;RANK_ID&quot;</span><span class="p">))</span>
<span class="k">if</span> <span class="p">(</span><span class="n">rank_id</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net0</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net1</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>Use a shell script to start the 2-card script. The <code class="docutils literal notranslate"><span class="pre">rank_table_file</span></code> file below can be generated by hccl_tools.py under <a class="reference external" href="https://gitee.com/mindspore/models">models</a>, which corresponds to the directory file <code class="docutils literal notranslate"><span class="pre">models/utils/</span> <span class="pre">hccl_tools</span></code>. The sample shell script is as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_HCCL_CONFIG_PATH</span><span class="o">=</span>rank_table_file
<span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_NUM</span><span class="o">=</span><span class="m">2</span>
<span class="nv">BASE_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$0</span><span class="k">)</span><span class="s2">&quot;</span><span class="p">;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>
<span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;<span class="nv">$DEVICE_NUM</span><span class="p">;</span><span class="w"> </span>i++<span class="o">))</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>mkdir<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>cp<span class="w"> </span>-r<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/neighborexchangev2.py<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>/
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training for device </span><span class="nv">$i</span><span class="s2">&quot;</span>
<span class="w">    </span>python<span class="w"> </span>neighborexchangev2.py<span class="w"> </span>&gt;<span class="w"> </span>log.txt<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="k">done</span>
</pre></div>
</div>
<p>The results of rank0 are:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[1. 1.]
   [1. 1.]
   [2. 2.]]]]
</pre></div>
</div>
<p>The results of rank1 are:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[1. 1.]
   [2. 2.]
   [2. 2.]]]]
</pre></div>
</div>
</section>
<section id="alltoall">
<h2>AlltoAll<a class="headerlink" href="#alltoall" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="https://gitee.com/mindspore/docs/raw/r2.0/tutorials/experts/source_zh_cn/parallel/images/alltoall.png" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">AlltoAll</span></code> operation will slice the input data into a specific number of chunks in a specific dimension and send them to other ranks in order, while receiving input from other ranks and stitching the data together in a specific dimension in order. For example, in the above figure, the Tensor is sliced into 5 pieces in dimension 0, while receiving data from other ranks and stitching them in dimension 1, and finally outputting the stitched data.</p>
<p>The sample code is as follows: we use <code class="docutils literal notranslate"><span class="pre">AlltoAll</span></code> operator to exchange the data of 8 cards, slice each card in the negative second dimension, and send the slice data to other cards in order, and receive the data from other cards and stitch them in the negative first dimension. Finally, each card outputs the stitched data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_to_all</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">AlltoAll</span><span class="p">(</span><span class="n">split_count</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">split_dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="n">concat_dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_to_all</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">rank_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;RANK_ID&quot;</span><span class="p">))</span>
<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">rank_id</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>To start the 8-card script by using a shell script, the <code class="docutils literal notranslate"><span class="pre">rank_table_file</span></code> file below can be generated by hccl_tools.py under <a class="reference external" href="https://gitee.com/mindspore/models">models</a>, which corresponds to the directory file <code class="docutils literal notranslate"><span class="pre">models/utils/</span> <span class="pre">hccl_tools</span></code>. The sample shell script is as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_HCCL_CONFIG_PATH</span><span class="o">=</span>rank_table_file
<span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_NUM</span><span class="o">=</span><span class="m">8</span>
<span class="nv">BASE_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$0</span><span class="k">)</span><span class="s2">&quot;</span><span class="p">;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>
<span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;<span class="nv">$DEVICE_NUM</span><span class="p">;</span><span class="w"> </span>i++<span class="o">))</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>mkdir<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>cp<span class="w"> </span>-r<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/alltoall.py<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>/
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training for device </span><span class="nv">$i</span><span class="s2">&quot;</span>
<span class="w">    </span>python<span class="w"> </span>alltoall.py<span class="w"> </span>&gt;<span class="w"> </span>log.txt<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="k">done</span>
</pre></div>
</div>
<p>The results of rank0 to rank7 are:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[0. 1. 2. 3. 4. 5. 6. 7.]]]]
</pre></div>
</div>
</section>
<section id="notes">
<h2>Notes<a class="headerlink" href="#notes" title="Permalink to this headline"></a></h2>
<p>On the Ascend chip, the three operators, NeighborExchange, NeighborExchangeV2, and AlltoAll, need to be fully-connected for network allocation.</p>
<p>The fully connected network allocation supports communication between any cards with no limit to the number of cards. The fully-connected network allocation method is available in the <a class="reference external" href="https://support.huawei.com/enterprise/en/ascend-computing/a300t-9000-pid-250702906?category=developer-documents">HCCN Tool Interface Reference</a> for configuration. For fully-connected network allocation, all cards need to have the same VLan ID, IP in the same network segment, static routing table and ARP configured to other cards. <strong>VLan ID needs to be configured on the switch</strong>, and the reference sample of the single 8-card configuration IP changes is as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Configure IP to the same network segment</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0

<span class="c1"># Strategy routing</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>table<span class="w"> </span><span class="m">100</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>table<span class="w"> </span><span class="m">101</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>table<span class="w"> </span><span class="m">102</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>table<span class="w"> </span><span class="m">103</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>table<span class="w"> </span><span class="m">104</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>table<span class="w"> </span><span class="m">105</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>table<span class="w"> </span><span class="m">106</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>table<span class="w"> </span><span class="m">107</span>

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>table<span class="w"> </span><span class="m">100</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>table<span class="w"> </span><span class="m">101</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>table<span class="w"> </span><span class="m">102</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>table<span class="w"> </span><span class="m">103</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>table<span class="w"> </span><span class="m">104</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>table<span class="w"> </span><span class="m">105</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>table<span class="w"> </span><span class="m">106</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>table<span class="w"> </span><span class="m">107</span>

<span class="c1"># Static ARPs</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:16
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:15
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:14

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:17
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:15
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:14

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:17
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:16
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:14

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:17
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:16
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:15

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0e
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0d
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0c

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0f
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0d
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0c

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0f
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0e
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0c

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0f
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0e
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0d
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="parallel_training_quickstart.html" class="btn btn-neutral float-left" title="Quick Start Distributed Parallel Training" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="distributed_case.html" class="btn btn-neutral float-right" title="Distributed Case" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>