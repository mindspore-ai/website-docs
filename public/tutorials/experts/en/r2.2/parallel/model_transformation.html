<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Model Transformation &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Fault Recovery" href="recover.html" />
    <link rel="prev" title="Model Loading" href="model_loading.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Distributed Parallel</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Distributed Parallelism Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="startup_method.html">Distributed Parallel Startup Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_parallel.html">Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="semi_auto_parallel.html">Semi-automatic Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_parallel.html">Automatic Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="manual_parallel.html">Manually Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter_server_training.html">Parameter Server</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="model_save_load.html">Model Saving and Loading</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="model_saving.html">Model Saving</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_loading.html">Model Loading</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Model Transformation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="recover.html">Fault Recovery</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimize_technique.html">Optimization Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="others.html">Experimental Characteristics</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_case.html">Distributed High-Level Configuration Case</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Custom Operator</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom.html">Custom Operators (Custom-based)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/ms_kernel.html">MindSpore Hybrid Syntax Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom_adv.html">Custom Operator Registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom_aot.html">Advanced Usage of aot-type Custom Operators</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r2.2/performance_profiling.html">Profiling↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/execution_opt.html">Sinking Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/graph_fusion_engine.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/op_compilation.html">Incremental Operator Build</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/mem_reuse.html">Memory Reuse</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Algorithm Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../optimize/gradient_accumulation.html">Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/thor.html">Second-order Optimization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">High-level Functional Programming</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../vmap/vmap.html">Automatic Vectorization (Vmap)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../func_programming/Jacobians_Hessians.html">Computing Jacobian and Hessian Matrices Using Functional Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../func_programming/per_sample_gradients.html">Per-sample-gradients</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Processing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dataset/augment.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/cache.html">Single-Node Data Cache</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/optimize.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../infer/inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/model_compression.html">Model Compression</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Complex Problem Debugging</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../debug/dump.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/aoe.html">Ascend Optimization Engine (AOE)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/rdr.html">Running Data Recorder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/fault_recover.html">Fault Recovery</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="model_save_load.html">Model Saving and Loading</a> &raquo;</li>
      <li>Model Transformation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/parallel/model_transformation.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section class="tex2jax_ignore mathjax_ignore" id="model-transformation">
<h1>Model Transformation<a class="headerlink" href="#model-transformation" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.2/tutorials/experts/source_en/parallel/model_transformation.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.2/resource/_static/logo_source_en.svg" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<section id="background">
<h3>Background<a class="headerlink" href="#background" title="Permalink to this headline"></a></h3>
<p>When using MindSpore for distributed training, it is often necessary to transform the distributed Checkpoint obtained from training to carry out the next steps, such as inference, fine-tuning, and multi-stage training. In this tutorial, we will introduce how to transform the Checkpoint obtained from distributed training to carry out resilient training and inference with distributed strategies and cluster card changes.</p>
<blockquote>
<div><p>This function only supports SEMI_AUTO_PARALLEL and AUTO_PARALLEL modes.</p>
</div></blockquote>
</section>
<section id="usage-scenarios">
<h3>Usage Scenarios<a class="headerlink" href="#usage-scenarios" title="Permalink to this headline"></a></h3>
<p>If you encounter the following scenario, refer to this tutorial operation for resilience training and inference:</p>
<p>Scenario 1: Using M cards for training, and using N cards for fine-tuning training, where M and N can have no multiplicative relationship.
Scenario 2: Training is divided into multiple phases, each with a different cluster size.
Scenario 3: Using M cards for training, and using N cards for inference, where M and N can have no multiplicative relationship.
Scenario 4: Changes need to be made to the network sharding strategy.</p>
<p>Related interfaces:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mindspore.transform_checkpoints(src_checkpoints_dir,</span> <span class="pre">dst_checkpoints_dir,</span> <span class="pre">src_strategy_file,</span> <span class="pre">dst_strategy_file)</span></code>: Transform Checkpoint of the distributed network from a source sharding strategy to a target sharding strategy, where <code class="docutils literal notranslate"><span class="pre">src_checkpoints_dir</span></code> is the directory where the source Checkpoint file is located, and its subdirectories are required to be stored in the format <code class="docutils literal notranslate"><span class="pre">rank_x/checkpoint_x.ckpt</span></code>, with x being the corresponding rank id. <code class="docutils literal notranslate"><span class="pre">dst_checkpoints_dir</span></code> is the directory where the target checkpoint file is stored, <code class="docutils literal notranslate"><span class="pre">src_strategy_file</span></code> is the name of the source sharding strategy file, and <code class="docutils literal notranslate"><span class="pre">dst_strategy_file</span></code> is the name of the target sharding strategy file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mindspore.rank_list_for_transform(rank_id,</span> <span class="pre">src_strategy_file,</span> <span class="pre">dst_strategy_file)</span></code>: Get the rank list of source Checkpoint file required for the Checkpoint file of the target rank during the transformation of a distributed Checkpoint.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mindspore.transform_checkpoint_by_rank(rank_id,</span> <span class="pre">checkpoint_files_map,</span> <span class="pre">save_checkpoint_file_name,</span> <span class="pre">src_strategy_file,</span> <span class="pre">dst_strategy_file)</span></code>: Transform a Checkpoint of a distributed network from a source sharding strategy to a target sharding strategy for a specific rank, where <code class="docutils literal notranslate"><span class="pre">rank_id</span></code> is the rank number of the Checkpoint to be transformed. <code class="docutils literal notranslate"><span class="pre">checkpoint_files_map</span></code> is the source Checkpoint dictionary whose key is the rank number and the value is the path to the Checkpoint file corresponding to that rank number. <code class="docutils literal notranslate"><span class="pre">save_checkpoint_file_name</span></code> is the path and name of the target Checkpoint for the current rank.</p></li>
</ol>
</section>
</section>
<section id="operation-practice">
<h2>Operation Practice<a class="headerlink" href="#operation-practice" title="Permalink to this headline"></a></h2>
<p>As an example of training on an Ascend 8-card and fine-tuning on 4-card, the overall procedure is as follows:</p>
<ol class="arabic simple">
<li><p>Perform training, configure the storage location of the model parameter sharding strategy file, and automatically generate the Checkpoint file and the model parameter sharding strategy file.</p></li>
<li><p>Compile the fine-tuned network, configure the location of the distributed strategy file storage, and automatically generate the model parameter slice and sharding strategy file.</p></li>
<li><p>The user transforms the saved Checkpoint file based on the strategy file involved in training and inference.</p></li>
<li><p>After compiling the fine-tuned network, load the distributed Checkpoint file obtained from the transformation.</p></li>
<li><p>Execute the fine-tuned network.</p></li>
</ol>
<p>It should be noted that loading distributed Checkpoint requires compiling the network first.</p>
<section id="example-code-description">
<h3>Example Code Description<a class="headerlink" href="#example-code-description" title="Permalink to this headline"></a></h3>
<blockquote>
<div><p>Download the complete example code: <a class="reference external" href="https://gitee.com/mindspore/docs/tree/r2.2/docs/sample_code/model_saving_loading">model_saving_loading</a>.</p>
</div></blockquote>
<p>The directory structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─ sample_code
    ├─ model_saving_loading
       ├── model_transformation_infer.py
       ├── model_transformation_retrain.py
       ├── pipeline_train.py
       ├── pipeline_transformation_retrain.py
       ├── run_infer_convert.sh
       ├── run_infer.sh
       ├── run_retrain_convert.sh
       ├── run_retrain.sh
       ├── run_pipeline_train.sh
       ├── run_retrain_pipeline_convert.sh
       ├── run_retrain_pipeline.sh
       ...
    ...
</pre></div>
</div>
<p>The functions of each file are as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model_transformation_infer.py</span></code>: Scripts for inference after model transformation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model_transformation_retrain.py</span></code>: Scripts for second-stage training after model transformation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pipeline_transformation_retrain.py</span></code>: Scripts for second-stage training after pipeline parallel model transformation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pipeline_train.py</span></code>: Scripts for pipeline parallel training of networks.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">run_infer_convert.sh</span></code>: Scripts that perform model transformation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">run_retrain_convert.sh</span></code>: Scripts that perform model transformation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">run_retrain_pipeline_convert.sh</span></code>: Scripts that perform pipeline parallel model transformation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">run_infer.sh</span></code>: Scripts that perform model inference.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">run_retrain.sh</span></code>: Scripts that perform second-stage training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">run_retrain_pipeline.sh</span></code>: Scripts for executing second-stage training pipeline parallel model.</p></li>
</ul>
</section>
<section id="saving-the-distributed-model">
<h3>Saving the Distributed Model<a class="headerlink" href="#saving-the-distributed-model" title="Permalink to this headline"></a></h3>
<p>First, follow the <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r2.2/parallel/model_saving.html">Model Saving</a> tutorial to perform 8-card distributed training with a parallel mode of <code class="docutils literal notranslate"><span class="pre">SEMI_AUTO_</span> <span class="pre">PARALLEL</span></code> or <code class="docutils literal notranslate"><span class="pre">AUTO_PARALLEL</span></code>, while customizing the <code class="docutils literal notranslate"><span class="pre">strategy_ckpt_config</span></code> parameter by calling the <code class="docutils literal notranslate"><span class="pre">set_auto_parallel_context</span></code> interface to configure the model sharding strategy file storage path. After training for a period of time, call the <code class="docutils literal notranslate"><span class="pre">train.ModelCheckpoint</span></code> function of storage Checkpoint to store the distributed checkpoint.</p>
<p>At the end of the training, the source Checkpoint file directory as well as the source sharding strategy file will be generated at the current path:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>src_checkpoints/
src_strategy.ckpt
</pre></div>
</div>
<blockquote>
<div><p>Subdirectory within src_checkpoints are required to be stored in the <code class="docutils literal notranslate"><span class="pre">rank_x/checkpoint_x.ckpt</span></code> format.</p>
</div></blockquote>
<p>That is, the directory structure of src_checkpoints is changed to the following:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>src_checkpoints
 ├─ rank_0
 |   └─ checkpoint_0.ckpt
 ├─ rank_1
 |   └─ checkpoint_1.ckpt
 ├─ rank_2
 |   └─ checkpoint_2.ckpt
 ├─ rank_3
 |   └─ checkpoint_3.ckpt
 ├─ rank_4
 |   └─ checkpoint_4.ckpt
 ├─ rank_5
 |   └─ checkpoint_5.ckpt
 ├─ rank_6
 |   └─ checkpoint_6.ckpt
 └─ rank_7
     └─ checkpoint_7.ckpt
...
</pre></div>
</div>
</section>
<section id="generating-target-strategy-files">
<h3>Generating Target Strategy Files<a class="headerlink" href="#generating-target-strategy-files" title="Permalink to this headline"></a></h3>
<p>Then the network under the new card or sharding strategy needs to be compiled to generate the model sharding strategy file for the target network. In this example, the original strategy is trained with 8 cards, the <code class="docutils literal notranslate"><span class="pre">ops.MatMul()</span></code> operator parallel strategy of layer1 is ((2, 1), (1, 2)), the optimizer parallel is not turned on, and the strategy file is named as src_strategy.ckpt. The target strategy is trained with 4 cards, the <code class="docutils literal notranslate"><span class="pre">ops.MatMul()</span></code> operator parallel strategy of layer1 is ((2, 2), (2, 1)) and optimizer parallel is turned on, the strategy file is named as dst_stategy.ckpt.</p>
<section id="configuring-distributed-environment">
<h4>Configuring Distributed Environment<a class="headerlink" href="#configuring-distributed-environment" title="Permalink to this headline"></a></h4>
<p>Specify the run mode, run device, run card number via the context interface. Configure and save the distributed strategy file via <code class="docutils literal notranslate"><span class="pre">strategy_ckpt_config</span></code>, enable optimizer parallel and initialize HCCL or NCCL communication via init.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">parallel_mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">SEMI_AUTO_PARALLEL</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">strategy_ckpt_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;save_file&quot;</span><span class="p">:</span> <span class="n">args_opt</span><span class="o">.</span><span class="n">dst_strategy_file</span><span class="p">})</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">enable_parallel_optimizer</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="network-definition-and-loading-the-dataset">
<h4>Network Definition and Loading the Dataset<a class="headerlink" href="#network-definition-and-loading-the-dataset" title="Permalink to this headline"></a></h4>
<p>The network definition modifies the <code class="docutils literal notranslate"><span class="pre">ops.MatMul()</span></code> operator parallel strategy for layer1 in the original network:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">ops</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">initializer</span>

<span class="k">class</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;normal&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;normal&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">out_channels</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">matmul</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">MatMul</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Add</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer3</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="n">net</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">matmul</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
<span class="n">net</span><span class="o">.</span><span class="n">layer3</span><span class="o">.</span><span class="n">matmul</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>

<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
    <span class="n">dataset_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;DATA_PATH&quot;</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MnistDataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">)</span>
    <span class="n">image_transforms</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">ds</span><span class="o">.</span><span class="n">vision</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="n">ds</span><span class="o">.</span><span class="n">vision</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.3081</span><span class="p">,)),</span>
        <span class="n">ds</span><span class="o">.</span><span class="n">vision</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="p">]</span>
    <span class="n">label_transform</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">image_transforms</span><span class="p">,</span> <span class="s1">&#39;image&#39;</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">label_transform</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dataset</span>

<span class="n">data_set</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="performing-compilation-on-the-target-network">
<h4>Performing Compilation on the Target Network<a class="headerlink" href="#performing-compilation-on-the-target-network" title="Permalink to this headline"></a></h4>
<p>The distributed Checkpoint transformation depends on the original distributed strategy file and the target distributed strategy file. When performing the training of the network under the original strategy, the distributed strategy file is stored, so it is necessary to obtain the distributed strategy file under the target strategy separately. The distributed strategy file for the target strategy network can be obtained by performing compilation of the network with the target strategy. Compilation of the network can be performed separately through the <code class="docutils literal notranslate"><span class="pre">model.infer_train_layout</span></code> interface.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">ops</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mf">1e-2</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">infer_train_layout</span><span class="p">(</span><span class="n">data_set</span><span class="p">)</span>
</pre></div>
</div>
<p>When the target network is to perform inference, <code class="docutils literal notranslate"><span class="pre">model.infer_train_layout</span></code> is replaced with <code class="docutils literal notranslate"><span class="pre">model.infer_preict_layout</span></code> to perform compilation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">predict_data</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">infer_predict_layout</span><span class="p">(</span><span class="n">predict_data</span><span class="p">)</span>
</pre></div>
</div>
<p>After compilation, you can get the target sharding strategy file <code class="docutils literal notranslate"><span class="pre">dst_strategy.ckpt</span></code>.</p>
</section>
</section>
<section id="executing-distributed-checkpoint-transformation">
<h3>Executing Distributed Checkpoint Transformation<a class="headerlink" href="#executing-distributed-checkpoint-transformation" title="Permalink to this headline"></a></h3>
<p>In this step, you need to call the distributed Checkpoint transformation interface for distributed Checkpoint transformation. Distributed Checkpoint provides two interfaces for Checkpoint transformation. The first interface, <code class="docutils literal notranslate"><span class="pre">transform_checkpoints</span></code>, requires the user to place all checkpoints in a single directory, and the subdirectories must be named in the format “rank_0, rank_1, rank_2, …”. The user calls this interface to transform the entire directory directly, which is easier to use, but the transformation requires a slightly higher memory overhead. The second interface, <code class="docutils literal notranslate"><span class="pre">transform_checkpoint_by_rank</span></code>, is used to get the checkpoints for a particular rank, which has more flexibility and lower memory overhead, and needs to be used in conjunction with the <code class="docutils literal notranslate"><span class="pre">rank_list_for_transform</span></code> interface to determine original Checkpoints are needed to get the target checkpoints for this rank.</p>
<ol class="arabic">
<li><p>Use the interface <code class="docutils literal notranslate"><span class="pre">transform_checkpoints</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">ms</span><span class="o">.</span><span class="n">transform_checkpoints</span><span class="p">(</span><span class="n">args_opt</span><span class="o">.</span><span class="n">src_checkpoints_dir</span><span class="p">,</span> <span class="n">args_opt</span><span class="o">.</span><span class="n">dst_checkpoints_dir</span><span class="p">,</span> <span class="s2">&quot;checkpoint_&quot;</span><span class="p">,</span> <span class="n">args_opt</span><span class="o">.</span><span class="n">src_strategy_file</span><span class="p">,</span> <span class="n">args_opt</span><span class="o">.</span><span class="n">dst_strategy_file</span><span class="p">)</span>
</pre></div>
</div>
<p>The method is used in the example code <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.2/docs/sample_code/model_saving_loading/model_transformation_retrain.py"><code class="docutils literal notranslate"><span class="pre">model_transformation_retrain.py</span></code></a>.</p>
</li>
<li><p>Call the <code class="docutils literal notranslate"><span class="pre">transform_checkpoint_by_rank</span></code> interface to perform a parameter merge on the original Checkpoint corresponding to the current rank.</p>
<blockquote>
<div><p>Ensure that the subdirectory “rank_x” exists in dst_checkpoints_dir.</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">get_rank</span>

<span class="n">rank_list</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">rank_list_for_transform</span><span class="p">(</span><span class="n">get_rank</span><span class="p">(),</span> <span class="n">args_opt</span><span class="o">.</span><span class="n">src_strategy_file</span><span class="p">,</span> <span class="n">args_opt</span><span class="o">.</span><span class="n">dst_strategy_file</span><span class="p">)</span>
<span class="n">checkpoint_file_map</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">rank_id</span> <span class="ow">in</span> <span class="n">rank_list</span><span class="p">:</span>
    <span class="n">checkpoint_file_map</span><span class="p">[</span><span class="n">rank_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args_opt</span><span class="o">.</span><span class="n">src_checkpoints_dir</span><span class="p">,</span> <span class="s2">&quot;rank_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rank_id</span><span class="p">),</span> <span class="s2">&quot;checkpoint_</span><span class="si">{}</span><span class="s2">.ckpt&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rank_id</span><span class="p">))</span>
<span class="n">save_checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args_opt</span><span class="o">.</span><span class="n">dst_checkpoints_dir</span><span class="p">,</span> <span class="s2">&quot;rank_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">get_rank</span><span class="p">()),</span> <span class="s2">&quot;checkpoint_</span><span class="si">{}</span><span class="s2">.ckpt&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">get_rank</span><span class="p">()))</span>
<span class="n">ms</span><span class="o">.</span><span class="n">transform_checkpoint_by_rank</span><span class="p">(</span><span class="n">get_rank</span><span class="p">(),</span> <span class="n">checkpoint_file_map</span><span class="p">,</span> <span class="n">save_checkpoint_path</span><span class="p">,</span> <span class="n">args_opt</span><span class="o">.</span><span class="n">src_strategy_file</span><span class="p">,</span> <span class="n">args_opt</span><span class="o">.</span><span class="n">dst_strategy_file</span><span class="p">)</span>
</pre></div>
</div>
<p>The method is used in the example code <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.2/docs/sample_code/model_saving_loading/model_transformation_infer.py"><code class="docutils literal notranslate"><span class="pre">model_transformation_infer.py</span></code></a>.</p>
</li>
</ol>
<p>After execution, a directory of transformed target Checkpoint files will be generated:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>dst_checkpoints/
</pre></div>
</div>
</section>
<section id="loading-the-transformed-checkpoint-files">
<h3>Loading the Transformed Checkpoint Files<a class="headerlink" href="#loading-the-transformed-checkpoint-files" title="Permalink to this headline"></a></h3>
<p>The network for the target strategy is compiled and the <code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code> interface is called to load the model parameter data from the transformed Checkpoint file.</p>
<p>Compile the network using the <code class="docutils literal notranslate"><span class="pre">model.infer_train_layout</span></code> (for training) or <code class="docutils literal notranslate"><span class="pre">model.infer_predict_layout</span></code> (for inference) interfaces, at which point the weight Shape is sliced in the compilation process. Call the <code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code> interface to load the model parameter data for each card from the Checkpoint file.</p>
<p>The target network is the training scenario:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">train</span>

<span class="n">save_checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args_opt</span><span class="o">.</span><span class="n">dst_checkpoints_dir</span><span class="p">,</span> <span class="s2">&quot;rank_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">get_rank</span><span class="p">()),</span> <span class="s2">&quot;checkpoint_</span><span class="si">{}</span><span class="s2">.ckpt&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">get_rank</span><span class="p">()))</span>
<span class="n">loss_cb</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">LossMonitor</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">infer_train_layout</span><span class="p">(</span><span class="n">data_set</span><span class="p">)</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">save_checkpoint_path</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">data_set</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">loss_cb</span><span class="p">])</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">save_checkpoint_path</span></code>: The name of the Checkpoint model parameter file corresponding to the current rank that needs to be loaded.</p></li>
</ul>
<p>The target network is the inference scenario:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">save_checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args_opt</span><span class="o">.</span><span class="n">dst_checkpoints_dir</span><span class="p">,</span> <span class="s2">&quot;rank_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">get_rank</span><span class="p">()),</span> <span class="s2">&quot;checkpoint_</span><span class="si">{}</span><span class="s2">.ckpt&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">get_rank</span><span class="p">()))</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">save_checkpoint_path</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">infer_predict_layout</span><span class="p">(</span><span class="n">predict_data</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="n">predict_result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">predict_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">predict_result</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">predict_data</span></code>: Tensor data for inference.</p></li>
</ul>
</section>
<section id="running-stand-alone-4-card-script">
<h3>Running Stand-alone 4-card Script<a class="headerlink" href="#running-stand-alone-4-card-script" title="Permalink to this headline"></a></h3>
<p>Next, the corresponding scripts are called by commands to perform second-stage fine-tuning training after model transformation, using the <code class="docutils literal notranslate"><span class="pre">mpirun</span></code> startup method with a 4-card distributed script as an example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>run_retrain_convert.sh
bash<span class="w"> </span>run_retrain.sh
</pre></div>
</div>
<p>Or infer after the model transformation:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>run_infer_convert.sh
bash<span class="w"> </span>run_infer.sh
</pre></div>
</div>
<p>After the execution is completed, the log file is saved to the <code class="docutils literal notranslate"><span class="pre">log_output</span></code> directory, the target Checkpoint file is saved in the <code class="docutils literal notranslate"><span class="pre">dst_checkpoints</span></code> folder, and the target strategy file is saved in <code class="docutils literal notranslate"><span class="pre">dst_strategy.ckpt</span></code>, with the following directory structure of the files:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>├─ src_strategy.ckpt
├─ dst_strategy.ckpt
├─ log_output
|   └─ 1
|       ├─ rank.0
|       |   └─ stdout
|       ├─ rank.1
|       |   └─ stdout
|       ...
├─ dst_checkpoints
|   ├─ rank_0
|   |   └─ checkpoint_0.ckpt
|   ├─ rank_1
|   |   └─ checkpoint_1.ckpt
|   |   ...
|   ...
...
</pre></div>
</div>
<p>The part of results of the Loss after the second-stage fine-tuned training are saved in <code class="docutils literal notranslate"><span class="pre">log_output/1/rank.*/stdout</span></code>, as exemplified below:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 1, step: 20, loss is 0.10617774
epoch: 1, step: 40, loss is 0.06953259
epoch: 1, step: 60, loss is 0.08409108
epoch: 1, step: 80, loss is 0.08699021
epoch: 1, step: 100, loss is 0.07113413
...
</pre></div>
</div>
<p>In the case of an inference task, the results are saved in <code class="docutils literal notranslate"><span class="pre">log_output/1/rank.*/stdout</span></code>, as exemplified below:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[ 0.05044775 -0.94413316  0.84689134 -0.2881832   0.66444755  1.0564336
  -0.04191193  0.25590348 -0.690101   -0.6532427 ]]
</pre></div>
</div>
</section>
<section id="pipeline-parallel-model-transformation">
<h3>Pipeline Parallel Model Transformation<a class="headerlink" href="#pipeline-parallel-model-transformation" title="Permalink to this headline"></a></h3>
<p><a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r2.2/parallel/pipeline_parallel.html">Pipelining Parallel</a> is to slice a linear network to get multiple sub-networks, which are pipelined among multiple cards. Therefore, the sharding strategy file stored for each subgraph is inconsistent, and all the sharding strategies are aggregated together to get the complete slicing information of the network.
Therefore, for the dimension of pipeline parallel, compared to the transformation of other dimensions, it is necessary to perform an operation of aggregating the sharding strategy file before getting the aggregated sharding strategy file, and use this file as the strategy file on which the distributed Checkpoint transformation depends. In addition, there is no difference with the previous <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r2.2/parallel/model_transformation.html#executing-distributed-checkpoint-transformation">Executing Distributed Checkpoint Transformation</a>.</p>
<p>Related interfaces:</p>
<p><code class="docutils literal notranslate"><span class="pre">mindspore.merge_pipeline_strategys(src_strategy_dirs,</span> <span class="pre">dst_strategy_file)</span></code>: the sharding strategy file that aggregates the subgraphs of all pipeline parallels in pipeline parallel mode. <code class="docutils literal notranslate"><span class="pre">src_strategy_dirs</span></code> is the directory containing the sharding strategy files for all pipeline-parallel subgraphs, and the sharding strategy files are obtained by storing them by the <code class="docutils literal notranslate"><span class="pre">mindspore.set_auto_parallel_context(strategy_ckpt_config)</span></code> interface. <code class="docutils literal notranslate"><span class="pre">dst_strategy_file</span></code> is the path to the file where the converged sharding strategy is stored.</p>
<p>First, 8-card pipeline parallel training is executed, where pipeline parallel dimension is 2 and optimizer parallelism is turned on.</p>
<p>The training code is in <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.2/docs/sample_code/model_saving_loading/pipeline_train.py">pipeline_train.py</a>. The network structure adds a pipeline parallel configuration based on the chapter <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r2.2/parallel/model_saving.html">Model Saving</a> with parallel dimension 2.</p>
<p>The core code is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">train</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span>
<span class="o">...</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">parallel_mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">SEMI_AUTO_PARALLEL</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">pipeline_stages</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">enable_parallel_optimizer</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">strategy_ckpt_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;save_file&quot;</span><span class="p">:</span> <span class="s2">&quot;./src_pipeline_strategys/src_strategy_</span><span class="si">{}</span><span class="s2">.ckpt&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">get_rank</span><span class="p">())})</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="o">...</span>
<span class="n">ckpt_config</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">integrated_save</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ckpoint_cb</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;checkpoint&quot;</span><span class="p">,</span>
                                   <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;./src_checkpoints_pipeline/rank_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">get_rank</span><span class="p">()),</span>
                                   <span class="n">config</span><span class="o">=</span><span class="n">ckpt_config</span><span class="p">)</span>
<span class="n">net_with_grads</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">PipelineCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">WithLossCell</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">),</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">net_with_grads</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">data_set</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">loss_cb</span><span class="p">,</span> <span class="n">ckpoint_cb</span><span class="p">])</span>
</pre></div>
</div>
<blockquote>
<div><p>The sharding strategy file is inconsistent for each card, so it needs to be saved separately and stored in “src_pipeline_strategys/src_strategy_x.ckpt” format.</p>
</div></blockquote>
<p>Execute the 8-card training script execution command as:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>run_pipeline_train.sh
</pre></div>
</div>
<p>After execution, the source Checkpoint file directory and the source sharding strategy file will be generated with the file directory structure:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>├─ src_checkpoints_pipeline
|   ├─ rank_0
|   |   ├─ checkpoint-3_1875.ckpt
|   |   └─ checkpoint-graph.meta
|   ├─ rank_1
|   |   ├─ checkpoint-3_1875.ckpt
|   |   ...
|   ...
├─ src_pipeline_strategys
|   ├─ src_strategy_0.ckpt
|   ├─ src_strategy_1.ckpt
|   ├─ src_strategy_2.ckpt
|   ├─ src_strategy_3.ckpt
|   ├─ src_strategy_4.ckpt
|   ├─ src_strategy_5.ckpt
|   ├─ src_strategy_6.ckpt
|   └─ src_strategy_7.ckpt
...
</pre></div>
</div>
<p>Refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r2.2/parallel/model_transformation.html#performing-compilation-on-the-target-network">Performing a compilation of the target network</a> section, and similarly compile the target network in order to obtain the sharding strategy file for the target network.</p>
<p>The next step unfolds the distributed Checkpoint dimension transformation containing pipeline parallel dimensions, first merging the sharding strategy files obtained from pipline training using interface <code class="docutils literal notranslate"><span class="pre">merge_pipeline_strategys</span></code>, and then performing the distributed Checkpoint transformation using interface <code class="docutils literal notranslate"><span class="pre">transform_checkpoints</span></code> or <code class="docutils literal notranslate"><span class="pre">transform_checkpoint_by_rank</span></code>.</p>
<p>The example introduces an interface that uses <code class="docutils literal notranslate"><span class="pre">transform_checkpoints</span></code>, and the interface that uses <code class="docutils literal notranslate"><span class="pre">transform_checkpoint_by_rank</span></code>. Refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r2.2/parallel/model_transformation.html#executing-distributed-checkpoint-transformation">Executing Distributed Checkpoint Transformation</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">ms</span><span class="o">.</span><span class="n">merge_pipeline_strategys</span><span class="p">(</span><span class="n">args_opt</span><span class="o">.</span><span class="n">src_strategy_dir</span><span class="p">,</span> <span class="n">args_opt</span><span class="o">.</span><span class="n">src_strategy_file</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">transform_checkpoints</span><span class="p">(</span><span class="n">args_opt</span><span class="o">.</span><span class="n">src_checkpoints_dir</span><span class="p">,</span> <span class="n">args_opt</span><span class="o">.</span><span class="n">dst_checkpoints_dir</span><span class="p">,</span> <span class="s2">&quot;checkpoint_&quot;</span><span class="p">,</span> <span class="n">args_opt</span><span class="o">.</span><span class="n">src_strategy_file</span><span class="p">,</span> <span class="n">args_opt</span><span class="o">.</span><span class="n">dst_strategy_file</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><p>Subdirectories within src_checkpoints_dir are required to be stored in the format “rank_x/checkpoint_x.ckpt”.</p>
</div></blockquote>
<p>The example script execution command to transform the entire Checkpoint catalog is:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>run_retrain_pipeline_convert.sh
</pre></div>
</div>
<p>After the transformation is completed, refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r2.2/parallel/model_transformation.html#loading-the-transformed-checkpoint-files">Loading the Transformed Checkpoint Files</a> section to execute the distributed network without pipeline dimension.</p>
<p>In the example, the script execution command for loading the transformed Checkpoint for second-stage fine-tuning training is:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>run_retrain_pipeline.sh
</pre></div>
</div>
<p>After the execution is complete, you can see that the loss is decreasing from 0.15:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 1, step: 20, loss is 0.15090162
epoch: 1, step: 40, loss is 0.13296325
epoch: 1, step: 60, loss is 0.14676111
epoch: 1, step: 80, loss is 0.11930083
epoch: 1, step: 100, loss is 0.0784434
epoch: 1, step: 120, loss is 0.10741685
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="model_loading.html" class="btn btn-neutral float-left" title="Model Loading" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="recover.html" class="btn btn-neutral float-right" title="Fault Recovery" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>