<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Using Dump in the Graph Mode &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Ascend Optimization Engine (AOE)" href="aoe.html" />
    <link rel="prev" title="Model Compression" href="../infer/model_compression.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Distributed Parallel</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../parallel/overview.html">Distributed Parallelism Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/startup_method.html">Distributed Parallel Startup Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/data_parallel.html">Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/semi_auto_parallel.html">Semi-automatic Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/auto_parallel.html">Automatic Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/manual_parallel.html">Manually Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/parameter_server_training.html">Parameter Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/model_save_load.html">Model Saving and Loading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/recover.html">Fault Recovery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/optimize_technique.html">Optimization Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/others.html">Experimental Characteristics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/distributed_case.html">Distributed High-Level Configuration Case</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Custom Operator</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom.html">Custom Operators (Custom-based)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/ms_kernel.html">MindSpore Hybrid Syntax Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom_adv.html">Custom Operator Registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom_aot.html">Advanced Usage of aot-type Custom Operators</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling.html">Profiling↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/execution_opt.html">Sinking Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/graph_fusion_engine.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/op_compilation.html">Incremental Operator Build</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/mem_reuse.html">Memory Reuse</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Algorithm Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../optimize/gradient_accumulation.html">Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/thor.html">Second-order Optimization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">High-level Functional Programming</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../vmap/vmap.html">Automatic Vectorization (Vmap)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../func_programming/Jacobians_Hessians.html">Computing Jacobian and Hessian Matrices Using Functional Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../func_programming/per_sample_gradients.html">Per-sample-gradients</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Processing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dataset/augment.html">Auto Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/cache.html">Single-Node Data Cache</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/optimize.html">Optimizing the Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../infer/inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/model_compression.html">Model Compression</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Complex Problem Debugging</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Using Dump in the Graph Mode</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#debugging-process">Debugging Process</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#data-preparation">Data preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-analysis">Data analysis</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#applicable-scene">Applicable Scene</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#dump-introduction">Dump Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#synchronous-dump">Synchronous Dump</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#synchronous-dump-step">Synchronous Dump Step</a></li>
<li class="toctree-l3"><a class="reference internal" href="#synchronous-dump-data-object-directory">Synchronous Dump Data Object Directory</a></li>
<li class="toctree-l3"><a class="reference internal" href="#introduction-to-synchronous-dump-data-file">Introduction to Synchronous Dump Data File</a></li>
<li class="toctree-l3"><a class="reference internal" href="#synchronous-dump-data-analysis-sample">Synchronous Dump Data Analysis Sample</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#asynchronous-dump">Asynchronous Dump</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#asynchronous-dump-step">Asynchronous Dump Step</a></li>
<li class="toctree-l3"><a class="reference internal" href="#asynchronous-dump-data-object-directory">Asynchronous Dump Data Object Directory</a></li>
<li class="toctree-l3"><a class="reference internal" href="#introduction-to-asynchronous-dump-data-file">Introduction to Asynchronous Dump Data File</a></li>
<li class="toctree-l3"><a class="reference internal" href="#asynchronous-dump-data-analysis-sample">Asynchronous Dump Data Analysis Sample</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="aoe.html">Ascend Optimization Engine (AOE)</a></li>
<li class="toctree-l1"><a class="reference internal" href="rdr.html">Running Data Recorder</a></li>
<li class="toctree-l1"><a class="reference internal" href="fault_recover.html">Fault Recovery</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Using Dump in the Graph Mode</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/debug/dump.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section class="tex2jax_ignore mathjax_ignore" id="using-dump-in-the-graph-mode">
<h1>Using Dump in the Graph Mode<a class="headerlink" href="#using-dump-in-the-graph-mode" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.3/tutorials/experts/source_en/debug/dump.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3/resource/_static/logo_source_en.svg" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>The input and output of the operator can be saved for debugging through the data dump when the training result deviates from the expectation.</p>
<ul class="simple">
<li><p>For the dynamic graph mode, the Dump function only support overflow detection ability on Ascend. To view those nodes which are not overflow, please use the native Python execution capabilities. Users can view and record the corresponding input and output during the running of the network script.</p></li>
<li><p>For the static graph mode, MindSpore provides the Dump function to save the graph and the input and output data of the operator during model training to a disk file.</p></li>
</ul>
<section id="debugging-process">
<h3>Debugging Process<a class="headerlink" href="#debugging-process" title="Permalink to this headline"></a></h3>
<p>Using dump to help debugging is divided into two steps: 1. Data preparation; 2. Data analysis.</p>
<section id="data-preparation">
<h4>Data preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline"></a></h4>
<p>The data preparation phase uses synchronous Dump or asynchronous Dump to generate Dump data. See <a class="reference internal" href="#synchronous-dump-step"><span class="std std-doc">Synchronous Dump Step</span></a> and <a class="reference internal" href="#asynchronous-dump-step"><span class="std std-doc">Asynchronous Dump Step</span></a> for details.</p>
<p>When preparing data, you can refer to the following best practices:</p>
<ol class="arabic simple">
<li><p>Set the <code class="docutils literal notranslate"><span class="pre">iteration</span></code> parameter to save only the data of the iteration with the problem and the previous iteration. For example, if the problem to be analyzed will appear in the 10th iteration (counting from 1), you can set it as follows: <code class="docutils literal notranslate"><span class="pre">&quot;iteration&quot;:</span> <span class="pre">&quot;8</span> <span class="pre">|</span> <span class="pre">9&quot;</span></code>. Note that the <code class="docutils literal notranslate"><span class="pre">iteration</span></code> parameter evaluates iterations from 0. Saving the data of the above two iterations can help problem analysis under most scenarios.</p></li>
<li><p>After the iteration with problems is completed, it is recommended that you use <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/api_python/train/mindspore.train.RunContext.html#mindspore.train.RunContext.request_stop">run_context.request_stop()</a> or other methods to stop the training in advance.</p></li>
</ol>
</section>
<section id="data-analysis">
<h4>Data analysis<a class="headerlink" href="#data-analysis" title="Permalink to this headline"></a></h4>
<p>If you have installed MindSpore Insight, you can use offline debugger of MindSpore Insight to analyze it. See <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/debugger_offline.html">Using the Offline Debugger</a> for the usage of offline debugger.</p>
<p>If MindSpore Insight is not installed, you need to analyze the data through the following steps.</p>
<ol class="arabic">
<li><p>Find the corresponding operator from the script.</p>
<p>The Dump function needs to use the IR file of the final execution graph (The IR file contains the full name of the operator, and the dependency of the operator on the input and output of the computational graph, and also contains the trace information from the operator to the corresponding script code). The IR file can be viewed with the <code class="docutils literal notranslate"><span class="pre">vi</span></code> command. For the configuration of the Dump function, see <a class="reference internal" href="#synchronous-dump-step"><span class="std std-doc">Synchronous Dump Step</span></a> and <a class="reference internal" href="#asynchronous-dump-step"><span class="std std-doc">Asynchronous Dump Step</span></a>. For the directory structure of the Dump output, see <a class="reference internal" href="#synchronous-dump-data-object-directory"><span class="std std-doc">Synchronous Dump Data Object Directory</span></a> and <a class="reference internal" href="#asynchronous-dump-data-object-directory"><span class="std std-doc">Asynchronous Dump Data Object Directory</span></a>. Then find the operator corresponding to the code in the script through the graph file, and refer to <a class="reference internal" href="#synchronous-dump-data-analysis-sample"><span class="std std-doc">Synchronous Dump Data Analysis Sample</span></a> and <a class="reference internal" href="#asynchronous-dump-data-analysis-sample"><span class="std std-doc">Asynchronous Dump Data Analysis Sample</span></a>.</p>
</li>
<li><p>From operator to Dump data.</p>
<p>After understanding the mapping relationship between the script and the operator, you can determine the name of the operator you want to analyze and find the dump file corresponding to the operator. Please refer to <a class="reference internal" href="#synchronous-dump-data-object-directory"><span class="std std-doc">Synchronous Dump Data Object Directory</span></a> and <a class="reference internal" href="#asynchronous-dump-data-object-directory"><span class="std std-doc">Asynchronous Dump Data Object Directory</span></a>.</p>
</li>
<li><p>Analyze Dump data.</p>
<p>By analyzing Dump data, it can be compared with other third-party frameworks. For the synchronous Dump data format, please refer to <a class="reference internal" href="#introduction-to-synchronous-dump-data-file"><span class="std std-doc">Introduction to Synchronous Dump Data File</span></a>. For the asynchronous Dump data format, please refer to <a class="reference internal" href="#introduction-to-asynchronous-dump-data-file"><span class="std std-doc">Introduction to Asynchronous Dump Data File</span></a>.</p>
</li>
</ol>
</section>
</section>
<section id="applicable-scene">
<h3>Applicable Scene<a class="headerlink" href="#applicable-scene" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>Analysis of static graph operator results.</p>
<p>Through the IR diagram obtained by the Dump function, you can understand the mapping relationship between the script code and the execution operator (for details, see <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/advanced/error_analysis/mindir.html#overview">MindSpore IR Introduction</a>). Combining the input and output data of the execution operator, it is possible to analyze possible overflow, gradient explosion and disappearance during the training process, and backtrack to the code that may have problems in the script.</p>
</li>
<li><p>Analysis of the feature map.</p>
<p>Analyze the information of the feature map by obtaining the output data of the layer.</p>
</li>
<li><p>Model migration.</p>
<p>In the scenario of migrating a model from a third-party framework (TensorFlow and PyTorch) to MindSpore, by comparing the output data of  operator at the same position, analyzing whether the training results of the third-party framework and MindSpore for the same model are close enough to locate the model precision issues.</p>
</li>
</ol>
</section>
</section>
<section id="dump-introduction">
<h2>Dump Introduction<a class="headerlink" href="#dump-introduction" title="Permalink to this headline"></a></h2>
<p>MindSpore provides two modes: synchronous Dump and asynchronous Dump:</p>
<ul class="simple">
<li><p>The mechanism of synchronous Dump is that after the execution of each step in the network training process, the Host side initiates a Dump action, copies the data in the operator address from the Device to the Host, and saves the file. Synchronous Dump will turn off memory reuse between operators by default to avoid reading dirty data.</p></li>
<li><p>Asynchronous Dump is a function developed specifically for the sinking of the entire Ascend image. It can dump data while executing the operator. The data will be dumped immediately after the execution of an operator. Therefore, the correct data can be generated by turning on the memory reuse, but the corresponding network training speed will be slower.</p></li>
</ul>
<p>The configuration files required for different modes and the data format of dump are different:</p>
<ul class="simple">
<li><p>When Dump is enabled on Ascend, the operator to be dumped will automatically close memory reuse.</p></li>
<li><p>Asynchronous Dump full ability only supports graph mode on Ascend, overflow detection ability only support graph mode and PyNative mode on Ascend. Memory reuse will not be turned off when asynchronous Dump is enabled.</p></li>
<li><p>Default is Asynchronous Dump mode. If synchronous Dump mode is needed, “e2e_dump_settings” should be set in configuration file.</p></li>
<li><p>Dump does not support heterogeneous training. If Dump is enabled for heterogeneous training scenario, the generated Dump data object directory maybe not in the expected directory structure.</p></li>
</ul>
</section>
<section id="synchronous-dump">
<h2>Synchronous Dump<a class="headerlink" href="#synchronous-dump" title="Permalink to this headline"></a></h2>
<section id="synchronous-dump-step">
<h3>Synchronous Dump Step<a class="headerlink" href="#synchronous-dump-step" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>Create a configuration file in json format , and the name and location of the JSON file can be customized.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;common_dump_settings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;dump_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;/absolute_path&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;net_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ResNet50&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;iteration&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0|5-8|100-120&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;saved_data&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tensor&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;input_output&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;kernels&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;Default/Conv-op12&quot;</span><span class="p">],</span>
<span class="w">        </span><span class="nt">&quot;support_device&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">]</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;e2e_dump_settings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enable&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;trans_flag&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dump_mode</span></code>: 0: all operator data in the network dumped out; 1: the operator data specified in Dump <code class="docutils literal notranslate"><span class="pre">&quot;kernels&quot;</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>: The absolute path to Dump saved data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>: The customized net name: “ResNet50”.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration</span></code>: Specify the iterations of data required to be dumped, type is string. Use “|” to separate the step data of different intervals to be saved. For example, “0 | 5-8 | 100-120” represents dump the data of the 1st, 6th to 9th, and 101st to 121st steps. If iteration set to “all”, data of every iteration will be dumped.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">saved_data</span></code>: Specify what data is to be dumped, type is string. Use “tensor” to indicate complete tensor data Dumped, use “statistic” to dump tensor statistics, use “full” to dump both tensor data and statistics. Synchronous statistics dump is only supported on GPU. Using “statistic” or “full” on CPU or Ascend will result in exception. Default setting is “tensor”.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output</span></code>: 0: dump input and output of kernel, 1:dump input of kernel, 2:dump output of kernel. This configuration parameter only supports Ascend and CPU, and GPU can only dump the output of operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernels</span></code>: This item can be configured in two formats:</p>
<ol class="arabic simple">
<li><p>List of operator names. Turn on the IR save switch <code class="docutils literal notranslate"><span class="pre">set_context(save_graphs=2)</span></code> and execute the network to obtain the operator name from the generated <code class="docutils literal notranslate"><span class="pre">trace_code_graph_{graph_id}</span></code>IR file. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/advanced/error_analysis/mindir.html#saving-ir">Saving IR</a>.
Note that whether setting <code class="docutils literal notranslate"><span class="pre">set_context(save_graphs=2)</span></code> may cause the different IDs of the same operator, so when dump specified operators, keep this setting unchanged after obtaining the operator name. Or you can obtain the operator names from the file <code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code> saved by Dump. Refer to <a class="reference internal" href="#synchronous-dump-data-object-directory"><span class="std std-doc">Synchronous Dump Data Object Directory</span></a>.</p></li>
<li><p>You can also specify an operator type. When there is no operator scope information or operator id information in the string, the background considers it as an operator type, such as “conv”. The matching rule of operator type is: when the operator name contains an operator type string, the matching is considered successful (case insensitive). For example, “conv” can match operators “Conv2D-op1234” and “Conv3D-op1221”.</p></li>
</ol>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">support_device</span></code>: Supported devices, default setting is <code class="docutils literal notranslate"><span class="pre">[0,1,2,3,4,5,6,7]</span></code>. You can specify specific device ids to dump specific device data. This configuration parameter is invalid on the CPU, because there is no concept of device on the CPU, but it is still need to reserve this parameter in the json file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">enable</span></code>: When set to true, enable Synchronous Dump. When set to false, asynchronous dump will be used on Ascend and synchronous dump will still be used on GPU.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trans_flag</span></code>: Enable trans flag. Transform the device data format into NCHW. If it is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the data will be saved in the 4D format (NCHW) format on the Host side; if it is <code class="docutils literal notranslate"><span class="pre">False</span></code>, the data format on the Device side will be retained. This configuration parameter is invalid on the CPU, because there is no format conversion on the CPU, but it is still need to reserve this parameter in the json file.</p></li>
</ul>
</li>
<li><p>Set Dump environment variable.</p>
<p>Specify the json configuration file of Dump.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_DUMP_CONFIG</span><span class="o">=</span><span class="si">${</span><span class="nv">xxx</span><span class="si">}</span>
</pre></div>
</div>
<p>“xxx” represents the absolute path to the configuration file.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_DUMP_CONFIG</span><span class="o">=</span>/path/to/data_dump.json
</pre></div>
</div>
<p>If the <code class="docutils literal notranslate"><span class="pre">path</span></code> field is not set or set to an empty string in the Dump configuration file, you also need to configure the environment variable <code class="docutils literal notranslate"><span class="pre">MS_DIAGNOSTIC_DATA_PATH</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MS_DIAGNOSTIC_DATA_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">yyy</span><span class="si">}</span>
</pre></div>
</div>
<p>Then “$MS_DIAGNOSTIC_DATA_PATH/debug_dump” is regarded as <code class="docutils literal notranslate"><span class="pre">path</span></code>. If the <code class="docutils literal notranslate"><span class="pre">path</span></code> field is set in Dump configuration file, the actual value of the field is still the same.</p>
<p>Note:</p>
<ul class="simple">
<li><p>Set the environment variables before executing the training script. Setting environment variables during training will not take effect.</p></li>
<li><p>Dump environment variables need to be configured before calling <code class="docutils literal notranslate"><span class="pre">mindspore.communication.init</span></code>.</p></li>
</ul>
</li>
<li><p>Execute the training script to dump data.</p>
<p>After the training is started, if the <code class="docutils literal notranslate"><span class="pre">MINDSPORE_DUMP_CONFIG</span></code> environment variable is correctly configured, the content of the configuration file will be read and the operator data will be saved according to the data storage path specified in the Dump configuration.
In synchronous mode, if you want to dump data in GPU environment, you must use the non-data sink mode (set the <code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">model.train</span></code> or <code class="docutils literal notranslate"><span class="pre">DatasetHelper</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>) to ensure that you can get the dump data of each step.
If <code class="docutils literal notranslate"><span class="pre">model.train</span></code> or <code class="docutils literal notranslate"><span class="pre">DatasetHelper</span></code> is not called in the script, the default is non-data sinking mode. Using the Dump function will automatically generate the IR file of the final execution graph.</p>
<p>You can set <code class="docutils literal notranslate"><span class="pre">set_context(reserve_class_name_in_scope=False)</span></code> in your training script to avoid dump failure because of file name is too long.</p>
</li>
<li><p>Read and parse synchronous dump data through <code class="docutils literal notranslate"><span class="pre">numpy.load</span></code>, refer to <a class="reference internal" href="#introduction-to-synchronous-dump-data-file"><span class="std std-doc">Introduction to Synchronous Dump Data File</span></a>.</p></li>
</ol>
</section>
<section id="synchronous-dump-data-object-directory">
<h3>Synchronous Dump Data Object Directory<a class="headerlink" href="#synchronous-dump-data-object-directory" title="Permalink to this headline"></a></h3>
<p>After starting the training, the data objects saved by the synchronous Dump include the final execution graph (<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code> file) and the input and output data of the operators in the graph. The data directory structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{path}/
    - rank_{rank_id}/
        - .dump_metadata/
        - {net_name}/
            - {graph_id}/
                - {iteration_id}/
                    statistic.csv
                    {op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}.{input_output_index}.{slot}.{format}.npy
                - constants/
                    Parameter.data-{data_id}.0.0.{timestamp}.output.0.DefaultFormat.npy
            ...
        - graphs/
            ms_output_trace_code_graph_{graph_id}.pb
            ms_output_trace_code_graph_{graph_id}.ir
        - execution_order/
            ms_execution_order_graph_{graph_id}.csv
            ms_global_execution_order_graph_{graph_id}.csv
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>: the absolute path set in the <code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code> configuration file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rank_id</span></code>: the id of the logic device.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>: the network name set in the <code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code> configuration file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">graph_id</span></code>: the id of the training graph.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration_id</span></code>: the iteration of the training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_type</span></code>: the type of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_name</span></code>: the name of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">task_id</span></code>: the id of the task.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">stream_id</span></code>: the id of the stream.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">timestamp</span></code>: the time stamp.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output_index</span></code> : the index of input or output. For example, <code class="docutils literal notranslate"><span class="pre">output_0</span></code> means that the file is the data of the first output Tensor of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">slot</span></code>: the id of the slot.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">format</span></code>: the format of the data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data_id</span></code>: the id of constant data.</p></li>
</ul>
<p>For multi-graph networks, due to the control flow, some subgraphs may not be executed, but Dump only saves the executed nodes, so the {graph_id} in the <code class="docutils literal notranslate"><span class="pre">.pb</span></code> file name in the graphs directory does not necessarily exist in the {graph_id} directory under {net_name}.</p>
<p>Only when <code class="docutils literal notranslate"><span class="pre">saved_data</span></code> is “statistic” or “full”, <code class="docutils literal notranslate"><span class="pre">statistic.csv</span></code> is generated. Only when <code class="docutils literal notranslate"><span class="pre">saved_data</span></code> is “tensor” or “full”, <code class="docutils literal notranslate"><span class="pre">{op_type}.</span> <span class="pre">{op_name}.</span> <span class="pre">{task_id}.</span> <span class="pre">{stream_id}.</span> <span class="pre">{timestamp}.</span> <span class="pre">{input_output_index}.</span> <span class="pre">{slot}.</span> <span class="pre">{format}.npy</span></code> named complete tensor information is generated.</p>
</section>
<section id="introduction-to-synchronous-dump-data-file">
<h3>Introduction to Synchronous Dump Data File<a class="headerlink" href="#introduction-to-synchronous-dump-data-file" title="Permalink to this headline"></a></h3>
<p>The data file generated by the synchronous Dump is a binary file with the suffix <code class="docutils literal notranslate"><span class="pre">.npy</span></code>, and the file naming format is:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}.{input_output_index}.{slot}.{format}.npy
</pre></div>
</div>
<p>The constant data file generated by the synchronous Dump is in the same format as data file, whereas {op_type}, {task_id}, {stream_id}, {input_output_index}, {slot}, {format} are unchanged for all constant data. Note, non-Tensor type will not generate data file.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Parameter.data-{data_id}.0.0.{timestamp}.output.0.DefaultFormat.npy
</pre></div>
</div>
<p>User can use Numpy interface <code class="docutils literal notranslate"><span class="pre">numpy.load</span></code> to read the data.</p>
<p>The statistics file generated by the synchronous dump is named <code class="docutils literal notranslate"><span class="pre">statistic.csv</span></code>. This file stores key statistics for all tensors dumped under the same directory as itself (with the file names <code class="docutils literal notranslate"><span class="pre">{op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}.{input_output_index}.{slot}.{format}.npy</span></code>). Each row in <code class="docutils literal notranslate"><span class="pre">statistic.csv</span></code> summarizes a single tensor, each row contains the statistics: Op Type, Op Name, Task ID, Stream ID, Timestamp, IO, Slot, Data Size, Data Type, Shape, Max Value, Min Value, Avg Value, Count, Negative Zero Count, Positive Zero Count, NaN Count, Negative Inf Count, Positive Inf Count, Zero Count. Note that opening this file with Excel may cause data to be displayed incorrectly. Please use commands like <code class="docutils literal notranslate"><span class="pre">vi</span></code> or <code class="docutils literal notranslate"><span class="pre">cat</span></code>, or use Excel to import csv from text for viewing.</p>
<p>The suffixes of the final execution graph files generated by synchronous Dump are <code class="docutils literal notranslate"><span class="pre">.pb</span></code> and <code class="docutils literal notranslate"><span class="pre">.ir</span></code> respectively, and the file naming format is:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ms_output_trace_code_graph_{graph_id}.pb
ms_output_trace_code_graph_{graph_id}.ir
</pre></div>
</div>
<p>The files with the suffix <code class="docutils literal notranslate"><span class="pre">.ir</span></code> can be opened and viewed by the <code class="docutils literal notranslate"><span class="pre">vi</span></code> command.</p>
<p>The suffix of the node execution sequence file generated by the synchronous Dump is <code class="docutils literal notranslate"><span class="pre">.csv</span></code>, and the file naming format is:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ms_execution_order_graph_{graph_id}.csv
</pre></div>
</div>
<p>The suffix of the graph execution history file is <code class="docutils literal notranslate"><span class="pre">.csv</span></code>. The file naming format is:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ms_global_execution_order_graph_{graph_id}.csv
</pre></div>
</div>
<p>This file stores the list of iterations in which the graph was executed. After the graph is compiled, it may be split into multiple sub-graphs. Since sub-graphs share the same graph execution history with root graph, only root graph will generate an execution history file.</p>
<p><code class="docutils literal notranslate"><span class="pre">.dump_metadata</span></code> records the original training information, and <code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code> saves the dump configuration set by the user.</p>
</section>
<section id="synchronous-dump-data-analysis-sample">
<h3>Synchronous Dump Data Analysis Sample<a class="headerlink" href="#synchronous-dump-data-analysis-sample" title="Permalink to this headline"></a></h3>
<p>In order to better demonstrate the process of using dump to save and analyze data, we provide a set of <a class="reference external" href="https://gitee.com/mindspore/docs/tree/r2.3/docs/sample_code/dump">complete sample script</a> , you only need to execute <code class="docutils literal notranslate"><span class="pre">bash</span> <span class="pre">dump_sync_dump.sh</span></code> for synchronous dump.</p>
<p>After the graph corresponding to the script is saved to the disk through the Dump function, the final execution graph file <code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code> will be generated. This file saves the stack information of each operator in the corresponding graph, and records the generation script corresponding to the operator.</p>
<p>Take <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.3/docs/sample_code/dump/train_alexnet.py">AlexNet script</a> as an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">):</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span>
                     <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                     <span class="n">weight_init</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="n">pad_mode</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">fc_with_initialize</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">weight_variable</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">TruncatedNormal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">AlexNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Alexnet</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlexNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv5</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">*</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The construct function.</span>

<span class="sd">        Args:</span>
<span class="sd">           x(int): Input of the network.</span>

<span class="sd">        Returns:</span>
<span class="sd">           Tensor, the output of the network.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv5</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
<span class="o">...</span>
</pre></div>
</div>
<p>If the user wants to view the code at line 175 in the script:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>After executing the network training, you can find multiple operator information corresponding to the line of code from the final execution graph (<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code> file). The content of the file corresponding to Conv2D-op12 is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  %20(equivoutput) = Conv2D(%17, %19) {instance name: conv2d} primitive_attrs: {IsFeatureMapInputList: (0), kernel_size: (3, 3), mode: 1, out_channel: 384, input_names: [
x, w],    pri_format: NC1HWC0, pad: (0, 0, 0, 0), visited: true, pad_mod: same, format: NCHW,  pad_list: (1, 1, 1, 1), precision_flag: reduce, groups: 1, output_used_num:
(1), stream_id:     0, stride: (1, 1, 1, 1), group: 1, dilation: (1, 1, 1, 1), output_names: [output], IsFeatureMapOutput: true, ms_function_graph: true}
       : (&lt;Tensor[Float32], (32, 256, 13, 13)&gt;, &lt;Tensor[Float32], (384, 256, 3, 3)&gt;) -&gt; (&lt;Tensor[Float32], (32, 384, 13, 13)&gt;)
       : (&lt;Float16xNC1HWC0[const vector][32, 16, 13, 13, 16]&gt;, &lt;Float16xFracZ[const vector][144, 24, 16, 16]&gt;) -&gt; (&lt;Float32xNC1HWC0[const vector][32, 24, 13, 13, 16]&gt;)
       : full_name_with_scope: (Default/network-WithLossCell/_backbone-AlexNet/conv3-Conv2d/Conv2D-op12)
       ...
       # In file ./tain_alexnet.py(175)/        x = self.conv3(x)/
       ...
</pre></div>
</div>
<p>The meanings of the lines in the file content shown above are as follows:</p>
<ul>
<li><p>The input and output of the operator on the Host side (the first line) and the Device side (the second line, some operators may not exist). It can be seen from the execution graph that the operator has two inputs (left side of the arrow) and one output (right side of the arrow).</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>   : (&lt;Tensor[Float32], (32, 256, 13, 13)&gt;, &lt;Tensor[Float32], (384, 256, 3, 3)&gt;) -&gt; (&lt;Tensor[Float32], (32, 384, 13, 13)&gt;)
   : (&lt;Float16xNC1HWC0[const vector][32, 16, 13, 13, 16]&gt;, &lt;Float16xFracZ[const vector][144, 24, 16, 16]&gt;) -&gt; (&lt;Float32xNC1HWC0[const vector][32, 24, 13, 13, 16]&gt;)
</pre></div>
</div>
</li>
<li><p>Operator name. It can be seen from the execution graph that the full name of the operator in the final execution graph is <code class="docutils literal notranslate"><span class="pre">Default/network-WithLossCell/_backbone-AlexNet/conv3-Conv2d/Conv2D-op12</span></code>.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>: (Default/network-WithLossCell/_backbone-AlexNet/conv3-Conv2d/Conv2D-op12)
</pre></div>
</div>
</li>
<li><p>The training script code corresponding to the operator. By searching the training script code to be queried, multiple matching operators can be found.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># In file {Absolute path of model_zoo}/official/cv/alexnet/src/alexnet.py(175)/        x = self.conv3(x)/
</pre></div>
</div>
</li>
</ul>
<p>Through the operator name and input and output information, you can find the only corresponding Tensor data file. For example, if you want to view the dump file corresponding to the first output data of the Conv2D-op12 operator, you can obtain the following information:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">operator_name</span></code>: <code class="docutils literal notranslate"><span class="pre">Conv2D-op12</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output_index</span></code>: <code class="docutils literal notranslate"><span class="pre">output.0</span></code> indicates that the file is the data of the first output Tensor of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">slot</span></code>: 0, this tensor only has one slot.</p></li>
</ul>
<p>Search for the corresponding file name in the data object file directory saved by Dump:
<code class="docutils literal notranslate"><span class="pre">Conv2d.Conv2D-op12.0.0.1623124369613540.output.0.DefaultFormat.npy</span></code>.</p>
<p>When restoring data, execute:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;Conv2D.Conv2D-op12.0.0.1623124369613540.output.0.DefaultFormat.npy&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Generate the numpy.array data.</p>
</section>
</section>
<section id="asynchronous-dump">
<h2>Asynchronous Dump<a class="headerlink" href="#asynchronous-dump" title="Permalink to this headline"></a></h2>
<p>Large networks (such as Bert Large) will cause memory overflow when using synchronous dumps. MindSpore provides debugging capabilities for large networks through asynchronous dumps.</p>
<section id="asynchronous-dump-step">
<h3>Asynchronous Dump Step<a class="headerlink" href="#asynchronous-dump-step" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>Create configuration file:<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>.</p>
<p>The name and location of the JSON file can be customized.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;common_dump_settings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;dump_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;/absolute_path&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;net_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ResNet50&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;iteration&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0|5-8|100-120&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;saved_data&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tensor&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;input_output&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;kernels&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;Default/Conv-op12&quot;</span><span class="p">],</span>
<span class="w">        </span><span class="nt">&quot;support_device&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">],</span>
<span class="w">        </span><span class="nt">&quot;op_debug_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;file_format&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;npy&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dump_mode</span></code>: 0: all operator data in the network dumped out; 1: dump kernels data in kernels list; 2: dump the kernels data specified by <code class="docutils literal notranslate"><span class="pre">set_dump</span></code> in the scripts, see <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/api_python/mindspore/mindspore.set_dump.html">mindspore.dump</a> for the usage of <code class="docutils literal notranslate"><span class="pre">set_dump</span></code>. When overflow detection is enabled, the setting of this field becomes invalid, and Dump only saves the data of the overflow node.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>: The absolute path to save Dump data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>: The customized net name: “ResNet50”.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration</span></code>: Specify the iterations to dump, type is string. Use “|” to separate the step data of different intervals to be saved. For example, “0 | 5-8 | 100-120” represents dump the data of the 1st, 6th to 9th, and 101st to 121st steps. If iteration set to “all”, data of every iteration will be dumped. When overflow detection is enabled for PyNative mode, it must be set to “all”.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">saved_data</span></code>: Specify what data is to be dumped, type is string. Use “tensor” to dump tensor data, use “statistic” to dump tensor statistics, use “full” to dump both tensor data and statistics. Default setting is “tensor”. Asynchronous statistics dump is only supported when <code class="docutils literal notranslate"><span class="pre">file_format</span></code> is set to <code class="docutils literal notranslate"><span class="pre">npy</span></code>, using “statistic” or “full” when <code class="docutils literal notranslate"><span class="pre">file_format</span></code> is set to <code class="docutils literal notranslate"><span class="pre">bin</span></code> will result in exception.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output</span></code>: When set to 0, it means to Dump the operator’s input and output; when set to 1, it means to Dump the operator’s input; setting it to 2 means to Dump the output of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernels</span></code>: This item can be configured in two formats:</p>
<ol class="arabic simple">
<li><p>List of operator names. Turn on the IR save switch <code class="docutils literal notranslate"><span class="pre">set_context(save_graphs=2)</span></code> and execute the network to obtain the operator name from the generated <code class="docutils literal notranslate"><span class="pre">trace_code_graph_{graph_id}</span></code>IR file. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/advanced/error_analysis/mindir.html#saving-ir">Saving IR</a>.
Note that whether setting <code class="docutils literal notranslate"><span class="pre">set_context(save_graphs=2)</span></code> may cause the different IDs of the same operator, so when dump specified operators, keep this setting unchanged after obtaining the operator name. Or you can obtain the operator names from the file <code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code> saved by Dump. Refer to <a class="reference internal" href="#synchronous-dump-data-object-directory"><span class="std std-doc">Synchronous Dump Data Object Directory</span></a>.</p></li>
<li><p>You can also specify an operator type. When there is no operator scope information or operator id information in the string, the background considers it as an operator type, such as “conv”. The matching rule of operator type is: when the operator name contains an operator type string, the matching is considered successful (case insensitive). For example, “conv” can match operators “Conv2D-op1234” and “Conv3D-op1221”.</p></li>
</ol>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">support_device</span></code>: Supported devices, default setting is <code class="docutils literal notranslate"><span class="pre">[0,1,2,3,4,5,6,7]</span></code>. You can specify specific device ids to dump specific device data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_debug_mode</span></code>: This attribute is used for operator overflow debugging. 0: disable overflow check function; 1: enable AiCore overflow check; 2: enable Atomic overflow check; 3: enable all overflow check function. Set it to 0 when Dump data is processed. If it is not set to 0, only the data of the overflow operator will be dumped.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">file_format</span></code>: Dump file type. It can be either <code class="docutils literal notranslate"><span class="pre">npy</span></code> and <code class="docutils literal notranslate"><span class="pre">bin</span></code>. <code class="docutils literal notranslate"><span class="pre">npy</span></code>: data will be dumped in npy files as host format. <code class="docutils literal notranslate"><span class="pre">bin</span></code>: data will be dumped in protobuf file as device format and need to be transformed to parse using the provided data analysis tool. Please refer to <a class="reference internal" href="#asynchronous-dump-data-analysis-sample"><span class="std std-doc">Asynchronous Dump Data Analysis Sample</span></a> for details. The default value is <code class="docutils literal notranslate"><span class="pre">bin</span></code>.</p></li>
</ul>
</li>
<li><p>Set Dump environment variable.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_DUMP_CONFIG</span><span class="o">=</span><span class="si">${</span><span class="nv">Absolute</span><span class="p"> path of data_dump.json</span><span class="si">}</span>
</pre></div>
</div>
<p>If the <code class="docutils literal notranslate"><span class="pre">path</span></code> field is not set or set to an empty string in the Dump configuration file, you also need to configure the environment variable <code class="docutils literal notranslate"><span class="pre">MS_DIAGNOSTIC_DATA_PATH</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MS_DIAGNOSTIC_DATA_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">yyy</span><span class="si">}</span>
</pre></div>
</div>
<p>Then “$MS_DIAGNOSTIC_DATA_PATH/debug_dump” is regarded as <code class="docutils literal notranslate"><span class="pre">path</span></code>. If the <code class="docutils literal notranslate"><span class="pre">path</span></code> field in configuration file is not empty, it is still used as the path to save Dump data.</p>
<ul class="simple">
<li><p>Set the environment variables before executing the training script. Setting environment variables during training will not take effect.</p></li>
<li><p>Dump environment variables need to be configured before calling <code class="docutils literal notranslate"><span class="pre">mindspore.communication.init</span></code>.</p></li>
</ul>
</li>
<li><p>Execute the training script to dump data.</p>
<p>You can set <code class="docutils literal notranslate"><span class="pre">set_context(reserve_class_name_in_scope=False)</span></code> in your training script to avoid dump failure because of file name is too long.</p>
</li>
<li><p>Refer to <a class="reference internal" href="#asynchronous-dump-data-analysis-sample"><span class="std std-doc">Asynchronous Dump Data Analysis Sample</span></a> to analyze the Dump data file.</p>
<p>Note:</p>
<ul class="simple">
<li><p>If you need to dump all or part of the operator, you can modify the <code class="docutils literal notranslate"><span class="pre">dump_mode</span></code> option in the json configuration file to 0 or 1.</p></li>
<li><p>For communication operators(<code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>, <code class="docutils literal notranslate"><span class="pre">AllGather</span></code>, <code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code>, <code class="docutils literal notranslate"><span class="pre">Broadcast</span></code>, <code class="docutils literal notranslate"><span class="pre">NeighborExchange</span></code>, <code class="docutils literal notranslate"><span class="pre">NeighborExchange2</span></code>, <code class="docutils literal notranslate"><span class="pre">AlltoAll</span></code>), because the input address will be overwritten by the output when executed on the device, asynchronous dump cannot directly save its input data, but will save the output data of its input operator. You can view the input operator of the communication operator through the ir graph.</p></li>
<li><p>Using the Dump function will automatically generate the IR file of the final execution graph.</p></li>
</ul>
</li>
</ol>
</section>
<section id="asynchronous-dump-data-object-directory">
<h3>Asynchronous Dump Data Object Directory<a class="headerlink" href="#asynchronous-dump-data-object-directory" title="Permalink to this headline"></a></h3>
<p>If set <code class="docutils literal notranslate"><span class="pre">file_format</span></code> to <code class="docutils literal notranslate"><span class="pre">npy</span></code>, see <a class="reference internal" href="#synchronous-dump-data-object-directory"><span class="std std-doc">Synchronous Dump Data Object Directory</span></a> for the dump data object directory.</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">file_format</span></code> value or the <code class="docutils literal notranslate"><span class="pre">file_format</span></code> value is <code class="docutils literal notranslate"><span class="pre">bin</span></code> is not configured, the data object directory is structured as follows.</p>
<p>On the Ascend910 hardware platform, the data objects saved by asynchronous Dump include the final execution graph (<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code> file) and the input and output data of the operators in the graph. If overflow detection is enabled, the overflow file (file <code class="docutils literal notranslate"><span class="pre">Opdebug.Node_OpDebug.{task_id}.{stream_id}.{timestamp}</span></code>) will also be saved when overflow is detected.</p>
<p>The directory structure of graph mode is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{path}/
    - rank_{rank_id}/
        - .dump_metadata/
        - debug_files (Only be saved when overflow detection is enabled in dynamic shapes or non task sinking scenarios)/
            - {iteration_id}/
                Opdebug.Node_OpDebug.{task_id}.{stream_id}.{timestamp}
                ...
        - {net_name}/
            - {graph_id}/
                - {iteration_id}/
                    statistic.csv
                    {op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}
                    Opdebug.Node_OpDebug.{task_id}.{stream_id}.{timestamp} (Only be saved when overflow detection is enabled in task sinking scenarios)
                    mapping.csv
                - constants/
                    Parameter.data-{data_id}.0.0.{timestamp}.output.0.DefaultFormat.npy
            ...
        - graphs/
            ms_output_trace_code_graph_{graph_id}.pb
            ms_output_trace_code_graph_{graph_id}.ir
        - execution_order/
            ms_execution_order_graph_{graph_id}.csv
            ms_global_execution_order_graph_{graph_id}.csv
</pre></div>
</div>
<p>The directory structure of Pynative mode is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{path}/
    - rank_{rank_id}/
        - .dump_metadata/
        - debug_files/
            - {iteration_id}/
                Opdebug.Node_OpDebug.{task_id}.{stream_id}.{timestamp}
                ...
        - {net_name}/
            - {graph_id}/
                - {iteration_id}/
                    statistic.csv
                    {op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}
                    mapping.csv
                - constants/
                    Parameter.data-{data_id}.0.0.{timestamp}.output.0.DefaultFormat.npy
            ...
        - graphs/
            ms_output_trace_code_graph_{graph_id}.pb
            ms_output_trace_code_graph_{graph_id}.ir
        - execution_order/
            ms_execution_order_graph_{graph_id}.csv
            ms_global_execution_order_graph_{graph_id}.csv
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>: the absolute path set in the <code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code> configuration file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rank_id</span></code>: the id of the logic device.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>: the network name set in the <code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code> configuration file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">graph_id</span></code>: the id of the training graph.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration_id</span></code>: the iteration of the training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_type</span></code>: the type of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_name</span></code>: the name of the operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">task_id</span></code>: the id of the task.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">stream_id</span></code>: the id of the stream.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">timestamp</span></code>: the time stamp.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data_id</span></code>: the id of constant data.</p></li>
</ul>
<p>Due to the control flow, some sub-graphs may not be executed, but Dump only saves the executed nodes, so the {graph_id} in the <code class="docutils literal notranslate"><span class="pre">.pb</span></code> file name in the graphs directory does not necessarily exist in the {graph_id} directory under {net_name}.</p>
<p>For multi-graph networks, such as dynamic shape scenario, the iterations of all graphs on each device are counted uniformly.</p>
<p>If the length of the tensor file name defined according to the naming rules exceeds the OS file name length limit (usually 255 characters), the tensor file will be renamed to a string of random numbers. The mapping relationship will be written to the file ‘mapping.csv’ in the same directory.</p>
<p>For PyNative mode, since there is no forward graph and only the backward graph and optimization graph are saved, there may be situations where overflow nodes cannot find corresponding graph files.</p>
<p>In PyNative mode, because there is no forward graph or iteration_id, the value of graph_id and iteration_id for the forward node is 0, not the actual value. For reverse nodes or nodes in the optimizer, the data files are saved in the corresponding {graph_id}/{iteration_id} directory, and the corresponding overflow files are saved in debug_files/0 directory.</p>
</section>
<section id="introduction-to-asynchronous-dump-data-file">
<h3>Introduction to Asynchronous Dump Data File<a class="headerlink" href="#introduction-to-asynchronous-dump-data-file" title="Permalink to this headline"></a></h3>
<p>If set <code class="docutils literal notranslate"><span class="pre">file_format</span></code> to <code class="docutils literal notranslate"><span class="pre">npy</span></code>, see <a class="reference internal" href="#introduction-to-synchronous-dump-data-file"><span class="std std-doc">Introduction to Synchronous Dump Data File</span></a> for the introduction to dump data file.</p>
<p>If not configured <code class="docutils literal notranslate"><span class="pre">file_format</span></code> or set <code class="docutils literal notranslate"><span class="pre">file_format</span></code> to <code class="docutils literal notranslate"><span class="pre">bin</span></code>, after the training is started, the original data file generated by asynchronous Dump or overflow files generated by overflow detection are in protobuf format. They need to be parsed using the data analysis tool that comes with the HiSilicon Run package. For details, please refer to <a class="reference external" href="https://www.hiascend.com/document/detail/en/CANNCommunityEdition/600alphaX/developmenttools/devtool/atlasaccuracy_16_0078.html">How to view dump data files</a>.</p>
<p>The data format on the Device side may be different from the definition in the calculation diagram on the Host side. The data format of the asynchronous dump is the Device side format. If you want to convert to the Host side format, you can refer to <a class="reference external" href="https://www.hiascend.com/document/detail/en/CANNCommunityEdition/600alphaX/developmenttools/devtool/atlasaccuracy_16_0077.html">How to convert dump data file format</a>.</p>
<p>If the file is saved in <code class="docutils literal notranslate"><span class="pre">bin</span></code> format, the file naming format is:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}
</pre></div>
</div>
<p>Take the Conv2D-op12 of AlexNet network as an example: <code class="docutils literal notranslate"><span class="pre">Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802</span></code>, where <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> is <code class="docutils literal notranslate"><span class="pre">{op_type}</span></code>, <code class="docutils literal notranslate"><span class="pre">Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12</span></code> is <code class="docutils literal notranslate"><span class="pre">{op_name}</span></code>, and <code class="docutils literal notranslate"><span class="pre">2</span></code> is <code class="docutils literal notranslate"><span class="pre">{task_id'</span> <span class="pre">}</span></code>, <code class="docutils literal notranslate"><span class="pre">7</span></code> is <code class="docutils literal notranslate"><span class="pre">{stream_id'</span> <span class="pre">}</span></code>, <code class="docutils literal notranslate"><span class="pre">161243956333802</span></code> is <code class="docutils literal notranslate"><span class="pre">{timestamp}</span></code>.</p>
<p>If “.”, “/”, “”, and spaces appear in <code class="docutils literal notranslate"><span class="pre">op_type</span></code> and <code class="docutils literal notranslate"><span class="pre">op_name</span></code>, they will be converted to underscores.</p>
<p>The original data file generated by dump can also be parsed by using the data parsing tool DumpParser of MindSpore Insight. Please refer to <a class="reference external" href="https://gitee.com/mindspore/mindinsight/blob/master/mindinsight/parser/README.md#">DumpParser Introduction</a> for the usage of DumpParser. The data format parsed by MindSpore Insight is exactly the same as that of synchronous dump.</p>
<p>If setting <code class="docutils literal notranslate"><span class="pre">file_format</span></code> to <code class="docutils literal notranslate"><span class="pre">npy</span></code>, the naming convention of data files generated by asynchronous dump is the same as those of synchronous dump. Please refer to <a class="reference internal" href="#introduction-to-synchronous-dump-data-file"><span class="std std-doc">Introduction to Synchronous Dump Data File</span></a>. The overflow file generated by overflow detection is in the <code class="docutils literal notranslate"><span class="pre">json</span></code> format, and the content analysis of the overflow file can refer to the <a class="reference external" href="https://www.hiascend.com/document/detail/en/CANNCommunityEdition/600alphaX/infacldevg/aclcppdevg/aclcppdevg_000160.html">Analyzing the Data File of an Overflow/Underflow Operator</a> .</p>
<p>The <code class="docutils literal notranslate"><span class="pre">saved_data</span></code> option only takes effect when <code class="docutils literal notranslate"><span class="pre">file_format</span></code> is “npy”. If <code class="docutils literal notranslate"><span class="pre">saved_data</span></code> is “statistic” or “full”, tensor statistics will be dumped in <code class="docutils literal notranslate"><span class="pre">statistic.csv</span></code>. When <code class="docutils literal notranslate"><span class="pre">saved_data</span></code> is “tensor” or “full”, full tensor data will be dumped in <code class="docutils literal notranslate"><span class="pre">{op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}.{input_output_index}.{slot}.{format}.npy</span></code>. The format of the statistic file will be the same as that of synchonous dump. Please refer to <a class="reference internal" href="#introduction-to-synchronous-dump-data-file"><span class="std std-doc">Introduction to Synchronous Dump Data File</span></a>.</p>
<p>The constant dump file, final execution graph file and execution order file naming rules generated by asynchronous Dump are the same as that of synchronous Dump. You can refer to <a class="reference internal" href="#introduction-to-synchronous-dump-data-file"><span class="std std-doc">Introduction to Synchronous Dump Data File</span></a>.</p>
</section>
<section id="asynchronous-dump-data-analysis-sample">
<h3>Asynchronous Dump Data Analysis Sample<a class="headerlink" href="#asynchronous-dump-data-analysis-sample" title="Permalink to this headline"></a></h3>
<p>In order to better demonstrate the process of using dump to save and analyze data, we provide a set of <a class="reference external" href="https://gitee.com/mindspore/docs/tree/r2.3/docs/sample_code/dump">complete sample script</a> , you only need to execute <code class="docutils literal notranslate"><span class="pre">bash</span> <span class="pre">run_async_dump.sh</span></code> for asynchronous dump.</p>
<p>Through the asynchronous Dump function, the data files generated by the operator asynchronous Dump can be obtained. If <code class="docutils literal notranslate"><span class="pre">file_format</span></code> in the Dump configure file is set to “npy”, then the step 1, 2 in the follows steps can be skipped. If <code class="docutils literal notranslate"><span class="pre">file_format</span></code> is not set or set to “bin”, the tensor files need to be converted to <code class="docutils literal notranslate"><span class="pre">.npy</span></code> format.</p>
<ol class="arabic">
<li><p>Parse the dumped file using <code class="docutils literal notranslate"><span class="pre">msaccucmp.py</span></code> provied in the run package, the path where the <code class="docutils literal notranslate"><span class="pre">msaccucmp.py</span></code> file is located may be different on different environments. You can find it through the <code class="docutils literal notranslate"><span class="pre">find</span></code> command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>find<span class="w"> </span><span class="si">${</span><span class="nv">run_path</span><span class="si">}</span><span class="w"> </span>-name<span class="w"> </span><span class="s2">&quot;msaccucmp.py&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">run_path</span></code>: The installation path of the run package.</p></li>
</ul>
</li>
<li><p>After finding the <code class="docutils literal notranslate"><span class="pre">msaccucmp.py</span></code>, go to the <code class="docutils literal notranslate"><span class="pre">/absolute_path</span></code> directory and run the following command to parse the Dump data:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span><span class="si">${</span><span class="nv">The</span><span class="p"> absolute path of msaccucmp.py</span><span class="si">}</span><span class="w"> </span>convert<span class="w"> </span>-d<span class="w"> </span><span class="o">{</span>file<span class="w"> </span>path<span class="w"> </span>of<span class="w"> </span>dump<span class="o">}</span><span class="w"> </span>-out<span class="w"> </span><span class="o">{</span>file<span class="w"> </span>path<span class="w"> </span>of<span class="w"> </span>output<span class="o">}</span>
</pre></div>
</div>
<p>The {file path of dump} can be path to a single <code class="docutils literal notranslate"><span class="pre">.bin</span></code> file, or the folder that include the <code class="docutils literal notranslate"><span class="pre">.bin</span></code> files.</p>
<p>If you need to convert the data format, please refer to the user instructions link <a class="reference external" href="https://www.hiascend.com/document/detail/en/CANNCommunityEdition/600alphaX/developmenttools/devtool/atlasaccuracy_16_0077.html">https://www.hiascend.com/document/detail/en/CANNCommunityEdition/600alphaX/developmenttools/devtool/atlasaccuracy_16_0077.html</a>.</p>
<p>For example, the data file generated by Dump is:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802
</pre></div>
</div>
<p>Then execute:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3.7.5<span class="w"> </span>msaccucmp.py<span class="w"> </span>convert<span class="w"> </span>-d<span class="w"> </span>/path/to/Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802<span class="w"> </span>-out<span class="w"> </span>./output<span class="w"> </span>-f<span class="w"> </span>NCHW<span class="w"> </span>-t<span class="w"> </span>npy
</pre></div>
</div>
<p>All input and output data for this operator can be generated under <code class="docutils literal notranslate"><span class="pre">./output</span></code>. Each data is saved as a file with the <code class="docutils literal notranslate"><span class="pre">.npy</span></code> suffix in the format <code class="docutils literal notranslate"><span class="pre">NCHW</span></code>. The result is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802.input.0.32x256x13x13.npy
Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802.input.1.384x256x3x3.npy
Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802.output.0.32x384x13x13.npy
</pre></div>
</div>
<p>At the end of the file name, you can see which input or output the file is the operator, and the dimensional information of the data. For example, by the first <code class="docutils literal notranslate"><span class="pre">.npy</span></code> file name</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802.input.0.32x256x13x13.npy
</pre></div>
</div>
<p>It can be seen that the file is the 0th input of the operator, and the dimension information of the data is <code class="docutils literal notranslate"><span class="pre">32x256x13x13</span></code>.</p>
</li>
<li><p>The corresponding data can be read through <code class="docutils literal notranslate"><span class="pre">numpy.load(&quot;file_name&quot;)</span></code>. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802.input.0.32x256x13x13.npy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../infer/model_compression.html" class="btn btn-neutral float-left" title="Model Compression" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="aoe.html" class="btn btn-neutral float-right" title="Ascend Optimization Engine (AOE)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>