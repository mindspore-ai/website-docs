<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>数据处理性能优化 &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script src="../_static/translations.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script><script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="模型推理总览" href="../infer/inference.html" />
    <link rel="prev" title="单节点数据缓存" href="cache.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">分布式并行</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../parallel/overview.html">分布式并行总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/startup_method.html">分布式并行启动方式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/data_parallel.html">数据并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/semi_auto_parallel.html">半自动并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/auto_parallel.html">自动并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/manual_parallel.html">手动并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/parameter_server_training.html">参数服务器</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/model_save_load.html">模型保存与加载</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/recover.html">故障恢复</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/optimize_technique.html">优化方法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/others.html">实验特性</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/distributed_case.html">分布式高阶配置案例</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">自定义算子</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom.html">自定义算子（基于Custom表达）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/ms_kernel.html">MindSpore Hybrid 语法规范</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom_adv.html">自定义算子注册</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom_aot.html">aot类型自定义算子进阶用法</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">性能优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/master/performance_profiling.html">Profiling↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/execution_opt.html">下沉模式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/graph_fusion_engine.html">使能图算融合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/op_compilation.html">算子增量编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/mem_reuse.html">内存复用</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">算法优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../optimize/gradient_accumulation.html">梯度累积</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/thor.html">二阶优化</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">高阶函数式编程</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../vmap/vmap.html">自动向量化Vmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../func_programming/Jacobians_Hessians.html">使用函数变换计算雅可比矩阵和黑塞矩阵</a></li>
<li class="toctree-l1"><a class="reference internal" href="../func_programming/per_sample_gradients.html">Per-sample-gradients</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">数据处理</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="augment.html">自动数据增强</a></li>
<li class="toctree-l1"><a class="reference internal" href="cache.html">单节点数据缓存</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">数据处理性能优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#下载数据集">下载数据集</a></li>
<li class="toctree-l2"><a class="reference internal" href="#数据加载性能优化">数据加载性能优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="#shuffle性能优化">shuffle性能优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="#数据增强性能优化">数据增强性能优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="#batch操作性能优化">batch操作性能优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="#操作系统性能优化">操作系统性能优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="#单卡训练-vs-多卡训练并行度优化建议">单卡训练 VS 多卡训练并行度优化建议</a></li>
<li class="toctree-l2"><a class="reference internal" href="#自动数据加速">自动数据加速</a></li>
<li class="toctree-l2"><a class="reference internal" href="#数据异构加速">数据异构加速</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../infer/inference.html">模型推理总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/model_compression.html">模型压缩</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">复杂问题调试</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../debug/dump.html">Dump功能调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/aoe.html">AOE调优工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/rdr.html">Running Data Recorder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/fault_recover.html">故障恢复</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>数据处理性能优化</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/dataset/optimize.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="数据处理性能优化">
<h1>数据处理性能优化<a class="headerlink" href="#数据处理性能优化" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/master/tutorials/experts/zh_cn/dataset/mindspore_optimize.ipynb"><img alt="下载Notebook" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_notebook.svg" /></a> <a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/master/tutorials/experts/zh_cn/dataset/mindspore_optimize.py"><img alt="下载样例代码" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_download_code.svg" /></a> <a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/tutorials/experts/source_zh_cn/dataset/optimize.ipynb"><img alt="查看源文件" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.svg" /></a></p>
<p>数据是整个深度学习中最重要的一环，因为数据的好坏决定了最终结果的上限，模型的好坏只是去无限逼近这个上限，所以高质量的数据输入，会在整个深度神经网络中起到积极作用，数据在整个数据处理和数据增强的过程像经过pipeline管道的水一样，源源不断地流向训练系统，如图所示：</p>
<p><img alt="pipeline" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/experts/source_zh_cn/dataset/images/pipeline.png" /></p>
<p>MindSpore Dataset为用户提供了数据加载以及数据增强的功能，在数据的整个pipeline过程中，其中的每一步骤如果都能够进行合理的运用，那么数据的性能会得到很大的优化和提升。</p>
<p>本次体验将基于CIFAR-10数据集来为大家展示如何在数据加载、数据处理和数据增强的过程中进行性能的优化。</p>
<p>此外，操作系统的存储、架构和计算资源也会一定程度上影响数据处理的性能。</p>
<section id="下载数据集">
<h2>下载数据集<a class="headerlink" href="#下载数据集" title="Permalink to this headline"></a></h2>
<p>运行以下命令来获取数据集：</p>
<p>下载CIFAR-10二进制格式数据集，并将数据集文件解压到<code class="docutils literal notranslate"><span class="pre">./datasets/</span></code>目录下，数据加载的时候使用该数据集。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">download</span> <span class="kn">import</span> <span class="n">download</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/cifar-10-binary.tar.gz&quot;</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="s2">&quot;./datasets&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;tar.gz&quot;</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># 下载CIFAR-10数据集</span>

<span class="n">test_path</span> <span class="o">=</span> <span class="s2">&quot;./datasets/cifar-10-batches-bin/test&quot;</span>
<span class="n">train_path</span> <span class="o">=</span> <span class="s2">&quot;./datasets/cifar-10-batches-bin/train&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">test_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">test_path</span><span class="p">,</span> <span class="s2">&quot;test_batch.bin&quot;</span><span class="p">)):</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">move</span><span class="p">(</span><span class="s2">&quot;./datasets/cifar-10-batches-bin/test_batch.bin&quot;</span><span class="p">,</span> <span class="n">test_path</span><span class="p">)</span>
<span class="p">[</span><span class="n">shutil</span><span class="o">.</span><span class="n">move</span><span class="p">(</span><span class="s2">&quot;./datasets/cifar-10-batches-bin/&quot;</span><span class="o">+</span><span class="n">i</span><span class="p">,</span> <span class="n">train_path</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;./datasets/cifar-10-batches-bin/&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="s2">&quot;./datasets/cifar-10-batches-bin/&quot;</span><span class="o">+</span><span class="n">i</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">i</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.html&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="n">i</span><span class="p">))]</span>
</pre></div>
</div>
</div>
<p>解压后的数据集文件的目录结构如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./datasets/cifar-10-batches-bin
├── readme.html
├── test
│   └── test_batch.bin
└── train
    ├── batches.meta.txt
    ├── data_batch_1.bin
    ├── data_batch_2.bin
    ├── data_batch_3.bin
    ├── data_batch_4.bin
    └── data_batch_5.bin
</pre></div>
</div>
</section>
<section id="数据加载性能优化">
<h2>数据加载性能优化<a class="headerlink" href="#数据加载性能优化" title="Permalink to this headline"></a></h2>
<p>MindSpore支持加载计算机视觉、自然语言处理等领域的常用数据集、特定格式的数据集以及用户自定义的数据集。不同数据集加载接口的底层实现方式不同，性能也存在着差异，如下所示：</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 19%" />
<col style="width: 46%" />
<col style="width: 19%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>常用数据集</p></th>
<th class="head"><p>标准格式（MindRecord等）</p></th>
<th class="head"><p>用户自定义</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>底层实现</p></td>
<td><p>C++</p></td>
<td><p>C++</p></td>
<td><p>Python</p></td>
</tr>
<tr class="row-odd"><td><p>性能</p></td>
<td><p>高</p></td>
<td><p>高</p></td>
<td><p>中</p></td>
</tr>
</tbody>
</table>
<p>可参考下图选择适合当前场景的数据集加载接口：</p>
<p><img alt="data-loading-performance-scheme" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/experts/source_zh_cn/dataset/images/data_loading_performance_scheme.png" /></p>
<p>数据加载性能优化建议如下：</p>
<ul>
<li><p>对于已经提供加载接口的常用数据集，优先使用MindSpore提供的数据集加载接口进行加载，可以获得较好的加载性能，具体内容请参考框架提供的<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/mindspore.dataset.html">数据集加载接口</a>，如果性能仍无法满足需求，则可采取多线程并发方案，即：将数据集接口的参数<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>（默认值：8）增大来取得更好的性能。</p></li>
<li><p>不支持的数据集格式，推荐先将数据集转换为MindRecord数据格式后再使用<code class="docutils literal notranslate"><span class="pre">MindDataset</span></code>类进行加载（详细使用方法参考<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/dataset/mindspore.dataset.MindDataset.html">API</a>），具体内容请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/master/advanced/dataset/record.html">将数据集转换为MindSpore数据格式</a>，如果性能仍无法满足需求，则可采取多线程并发方案，即：将数据集接口的参数<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>（默认值：8）增大来取得更好的性能。</p></li>
<li><p>不支持的数据集格式，算法快速验证场景，优选用户自定义<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>类实现（详细使用方法参考<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/dataset/mindspore.dataset.GeneratorDataset.html">API</a>），如果性能仍无法满足需求，则可采取多进程/多线程并发方案，即：</p>
<ol class="arabic">
<li><p>增大数据集接口的参数<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>（默认值：1）来提升并发度；</p></li>
<li><p>将数据集接口的参数<code class="docutils literal notranslate"><span class="pre">python_multiprocessing</span></code>设置为<code class="docutils literal notranslate"><span class="pre">True(默认值)</span></code>/<code class="docutils literal notranslate"><span class="pre">False</span></code>来启动多进程模式/多线程模式，多进程模式适用于cpu计算密集型任务，多线程适用于IO密集型任务；</p>
<p>注意：如果配置 <code class="docutils literal notranslate"><span class="pre">python_multiprocessing=True</span></code>（默认值：True）和 <code class="docutils literal notranslate"><span class="pre">num_parallel_workers&gt;1</span></code>（默认值：1）表示启动了多进程方式进行数据load加速，此时随着数据集迭代，子进程的内存占用会逐渐增加，主要是因为自定义数据集的子进程以 Copy-On-Write 的方式获取主进程中的成员变量。举例：如果自定义数据集 <code class="docutils literal notranslate"><span class="pre">__init__</span></code> 函数中包含大量成员变量数据（例如：在数据集构建时加载了一个非常大的文件名列表）并且使用了多进程方式，那这可能会导致产生OOM的问题（总内存的预估使用量是：(子进程数量 + 1) *
父进程的内存大小）。最简单的解决方法是成员变量用非引用数据类型 （如：Pandas、Numpy或PyArrow对象）替换Python对象（如：list / dict / int / float / string等），或者加载更少的元数据以减小成员变量，或者配置 <code class="docutils literal notranslate"><span class="pre">python_multiprocessing=False</span></code> 使用多线程方式。</p>
</li>
<li><p>如果有<code class="docutils literal notranslate"><span class="pre">Using</span> <span class="pre">shared</span> <span class="pre">memory</span> <span class="pre">queue,</span> <span class="pre">but</span> <span class="pre">rowsize</span> <span class="pre">is</span> <span class="pre">larger</span> <span class="pre">than</span> <span class="pre">allocated</span> <span class="pre">memory</span> <span class="pre">...</span></code>日志提示，那么将数据集接口的参数<code class="docutils literal notranslate"><span class="pre">max_rowsize</span></code>（默认值：6M）按日志提示进行增大来提升进程间数据传递的效率。</p></li>
</ol>
</li>
</ul>
<p>基于以上的数据加载性能优化建议，本次体验分别使用框架提供的数据集加载操作<code class="docutils literal notranslate"><span class="pre">Cifar10Dataset</span></code>类（详细使用方法参考<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/dataset/mindspore.dataset.Cifar10Dataset.html">API</a>）、数据转换后使用<code class="docutils literal notranslate"><span class="pre">MindDataset</span></code>类、使用<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>类进行数据加载，代码演示如下：</p>
<ol class="arabic simple">
<li><p>使用数据集加载操作<code class="docutils literal notranslate"><span class="pre">Cifar10Dataset</span></code>类加载CIFAR-10数据集，这里使用的是CIFAR-10二进制格式的数据集，加载数据时采取多线程优化方案，开启了4个线程并发完成任务，最后对数据创建了字典迭代器，并通过迭代器读取了一条数据记录。</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="n">cifar10_path</span> <span class="o">=</span> <span class="s2">&quot;./datasets/cifar-10-batches-bin/train&quot;</span>

<span class="c1"># create Cifar10Dataset for reading data</span>
<span class="n">cifar10_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">cifar10_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="c1"># create a dictionary iterator and read a data record through the iterator</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">cifar10_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;image&#39;: Tensor(shape=[32, 32, 3], dtype=UInt8, value=
[[[181, 185, 194],
  [184, 187, 196],
  [189, 192, 201],
  ...
  [178, 181, 191],
  [171, 174, 183],
  [166, 170, 179]],
 [[182, 185, 194],
  [184, 187, 196],
  [189, 192, 201],
  ...
  [180, 183, 192],
  [173, 176, 185],
  [167, 170, 179]],
 [[185, 188, 197],
  [187, 190, 199],
  [193, 196, 205],
  ...
  [182, 185, 194],
  [176, 179, 188],
  [170, 173, 182]],
 ...
 [[176, 174, 185],
  [172, 171, 181],
  [174, 172, 183],
  ...
  [168, 171, 180],
  [164, 167, 176],
  [160, 163, 172]],
 [[172, 170, 181],
  [171, 169, 180],
  [173, 171, 182],
  ...
  [164, 167, 176],
  [160, 163, 172],
  [156, 159, 168]],
 [[171, 169, 180],
  [173, 171, 182],
  [177, 175, 186],
  ...
  [162, 165, 174],
  [158, 161, 170],
  [152, 155, 164]]]), &#39;label&#39;: Tensor(shape=[], dtype=UInt32, value= 6)}
</pre></div></div>
</div>
<ol class="arabic simple" start="2">
<li><p>使用<code class="docutils literal notranslate"><span class="pre">Cifar10ToMR</span></code>这个类将CIFAR-10数据集转换为MindSpore数据格式，这里使用的是CIFAR-10 python文件格式的数据集，然后使用<code class="docutils literal notranslate"><span class="pre">MindDataset</span></code>类加载MindSpore数据格式数据集，加载数据采取多线程优化方案，开启了4个线程并发完成任务，最后对数据创建了字典迭代器，并通过迭代器读取了一条数据记录。</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.mindrecord</span> <span class="kn">import</span> <span class="n">Cifar10ToMR</span>

<span class="n">trans_path</span> <span class="o">=</span> <span class="s2">&quot;./transform/&quot;</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">trans_path</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">trans_path</span><span class="p">)</span>

<span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s2">&quot;rm -f </span><span class="si">{}</span><span class="s2">cifar10*&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">trans_path</span><span class="p">))</span>

<span class="c1"># download CIFAR-10 python</span>
<span class="n">py_url</span> <span class="o">=</span> <span class="s2">&quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/cifar-10-python.tar.gz&quot;</span>
<span class="n">download</span><span class="p">(</span><span class="n">py_url</span><span class="p">,</span> <span class="s2">&quot;./datasets&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;tar.gz&quot;</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">cifar10_path</span> <span class="o">=</span> <span class="s1">&#39;./datasets/cifar-10-batches-py&#39;</span>
<span class="n">cifar10_mindrecord_path</span> <span class="o">=</span> <span class="s1">&#39;./transform/cifar10.record&#39;</span>

<span class="n">cifar10_transformer</span> <span class="o">=</span> <span class="n">Cifar10ToMR</span><span class="p">(</span><span class="n">cifar10_path</span><span class="p">,</span> <span class="n">cifar10_mindrecord_path</span><span class="p">)</span>
<span class="c1"># execute transformation from CIFAR-10 to MindRecord</span>
<span class="n">cifar10_transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">([</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>

<span class="c1"># create MindDataset for reading data</span>
<span class="n">cifar10_mind_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MindDataset</span><span class="p">(</span><span class="n">dataset_files</span><span class="o">=</span><span class="n">cifar10_mindrecord_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="c1"># create a dictionary iterator and read a data record through the iterator</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">cifar10_mind_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;data&#39;: Tensor(shape=[1289], dtype=UInt8, value= [255, 216, 255, 224,   0,  16,  74,  70,  73,  70,   0,   1,   1,   0,   0,   1,   0,   1,   0,   0, 255, 219,   0,  67,
   0,   2,   1,   1,   1,   1,   1,   2,   1,   1,   1,   2,   2,   2,   2,   2,   4,   3,   2,   2,   2,   2,   5,   4,
   4,   3,   4,   6,   5,   6,   6,   6,   5,   6,   6,   6,   7,   9,   8,   6,   7,   9,   7,   6,   6,   8,  11,   8,
   9,  10,  10,  10,  10,  10,   6,   8,  11,  12,  11,  10,  12,   9,  10,  10,  10, 255, 219,   0,  67,   1,   2,   2,
   ...
   ...
   ...
  39, 227, 206, 143, 241,  91, 196, 154, 230, 189, 125, 165, 105, 218,  94, 163, 124, 146,  11, 187,  29,  34, 217, 210,
  23, 186,  56,  14, 192,  19, 181,   1,  57,  36,  14,  51, 211, 173, 105,   9, 191, 100, 212, 174, 122,  25, 110,  39,
  11, 133, 193, 226, 169,  73,  36, 234,  69,  90, 222,  93,  31, 223, 115, 255, 217]), &#39;id&#39;: Tensor(shape=[], dtype=Int64, value= 46084), &#39;label&#39;: Tensor(shape=[], dtype=Int64, value= 5)}
</pre></div></div>
</div>
<ol class="arabic simple" start="3">
<li><p>使用<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>类加载自定义数据集，并且采取多进程优化方案，开启了4个进程并发完成任务，最后对数据创建了字典迭代器，并通过迭代器读取了一条数据记录。</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="k">def</span> <span class="nf">generator_func</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
        <span class="k">yield</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">i</span><span class="p">]),)</span>

<span class="c1"># create GeneratorDataset for reading data</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">generator_func</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">],</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># create a dictionary iterator and read a data record through the iterator</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;data&#39;: Tensor(shape=[1], dtype=Int64, value= [0])}
</pre></div></div>
</div>
</section>
<section id="shuffle性能优化">
<h2>shuffle性能优化<a class="headerlink" href="#shuffle性能优化" title="Permalink to this headline"></a></h2>
<p>shuffle操作主要是对有序的数据集或者进行过repeat的数据集进行混洗，MindSpore专门为用户提供了<code class="docutils literal notranslate"><span class="pre">shuffle</span></code>函数，它是基于内存缓存实现的，其中设定的<code class="docutils literal notranslate"><span class="pre">buffer_size</span></code>参数越大，混洗程度越大，但内存空间、时间消耗也会更大。该接口支持用户在整个pipeline的任何时候都可以对数据进行混洗，具体内容请参考<a class="reference external" href="https://mindspore.cn/tutorials/zh-CN/master/beginner/dataset.html#shuffle">shuffle处理</a>。</p>
<p>但是因为它是基于内存缓存方式实现，该方式的性能不如直接在<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/mindspore.dataset.html">数据集加载操作</a>中设置<code class="docutils literal notranslate"><span class="pre">shuffle=True</span></code>（默认值：True）参数直接对数据进行混洗。</p>
<p>shuffle方案选择参考如下：</p>
<p><img alt="shuffle-performance-scheme" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/experts/source_zh_cn/dataset/images/shuffle_performance_scheme.png" /></p>
<p>shuffle性能优化建议如下：</p>
<ul class="simple">
<li><p>直接使用数据集加载接口中的<code class="docutils literal notranslate"><span class="pre">shuffle=True</span></code>参数进行数据的混洗；</p></li>
<li><p>如果使用的是<code class="docutils literal notranslate"><span class="pre">shuffle</span></code>函数，当混洗效果无法满足需求，可通过调大<code class="docutils literal notranslate"><span class="pre">buffer_size</span></code>参数的值来优化混洗效果；当机器内存占用率过高时，可通过调小<code class="docutils literal notranslate"><span class="pre">buffer_size</span></code>参数的值来降低内存占用率。</p></li>
</ul>
<p>基于以上的shuffle方案建议，本次体验分别使用数据集加载操作<code class="docutils literal notranslate"><span class="pre">Cifar10Dataset</span></code>类的<code class="docutils literal notranslate"><span class="pre">shuffle</span></code>参数和<code class="docutils literal notranslate"><span class="pre">shuffle</span></code>函数进行数据的混洗，代码演示如下：</p>
<ol class="arabic simple">
<li><p>使用数据集加载接口<code class="docutils literal notranslate"><span class="pre">Cifar10Dataset</span></code>类加载CIFAR-10数据集，这里使用的是CIFAR-10二进制格式的数据集，并且设置<code class="docutils literal notranslate"><span class="pre">shuffle</span></code>参数为True来进行数据混洗，最后对数据创建了字典迭代器，并通过迭代器读取了一条数据记录。</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cifar10_path</span> <span class="o">=</span> <span class="s2">&quot;./datasets/cifar-10-batches-bin/train&quot;</span>

<span class="c1"># create Cifar10Dataset for reading data</span>
<span class="n">cifar10_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">cifar10_path</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># create a dictionary iterator and read a data record through the iterator</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">cifar10_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;image&#39;: Tensor(shape=[32, 32, 3], dtype=UInt8, value=
[[[213, 205, 194],
  [215, 207, 196],
  [219, 210, 200],
  ...
  [253, 254, 249],
  [253, 254, 249],
  [253, 254, 249]],
 [[218, 208, 198],
  [220, 210, 200],
  [222, 212, 202],
  ...
  [253, 254, 249],
  [253, 254, 249],
  [253, 254, 249]],
 [[219, 209, 198],
  [222, 211, 200],
  [224, 214, 202],
  ...
  [254, 253, 248],
  [254, 253, 248],
  [254, 253, 248]],
 ...
 [[135, 141, 139],
  [135, 141, 139],
  [146, 152, 150],
  ...
  [172, 174, 172],
  [181, 182, 182],
  [168, 168, 167]],
 [[113, 119, 117],
  [109, 115, 113],
  [117, 123, 121],
  ...
  [155, 159, 156],
  [150, 155, 155],
  [135, 140, 140]],
 [[121, 127, 125],
  [117, 123, 121],
  [121, 127, 125],
  ...
  [180, 184, 180],
  [141, 146, 144],
  [125, 130, 129]]]), &#39;label&#39;: Tensor(shape=[], dtype=UInt32, value= 8)}
</pre></div></div>
</div>
<ol class="arabic simple" start="2">
<li><p>使用<code class="docutils literal notranslate"><span class="pre">shuffle</span></code>函数进行数据混洗，参数<code class="docutils literal notranslate"><span class="pre">buffer_size</span></code>设置为3，数据采用<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>类自定义生成。</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generator_func</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="k">yield</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">3</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">4</span><span class="p">]),)</span>

<span class="n">ds1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">generator_func</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;before shuffle:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">ds1</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>

<span class="n">ds2</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;after shuffle:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">ds2</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
before shuffle:
[0 1 2 3 4]
[1 2 3 4 5]
[2 3 4 5 6]
[3 4 5 6 7]
[4 5 6 7 8]
after shuffle:
[2 3 4 5 6]
[3 4 5 6 7]
[1 2 3 4 5]
[0 1 2 3 4]
[4 5 6 7 8]
</pre></div></div>
</div>
</section>
<section id="数据增强性能优化">
<h2>数据增强性能优化<a class="headerlink" href="#数据增强性能优化" title="Permalink to this headline"></a></h2>
<p>在训练任务中，尤其是当数据集比较小的时候，用户可以使用数据增强的方法来预处理图片，达到丰富数据集的目的。MindSpore为用户提供了多种数据增强操作，其中包括：</p>
<ul class="simple">
<li><p>Vision类数据增强操作，主要基于C++实现，见<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/mindspore.dataset.transforms.html#%E8%A7%86%E8%A7%89">Vision数据增强</a>。</p></li>
<li><p>NLP类数据增强操作，主要基于C++实现，见<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/mindspore.dataset.transforms.html#%E6%96%87%E6%9C%AC">NLP数据增强</a>。</p></li>
<li><p>Audio类数据增强操作，主要基于C++实现，见<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/mindspore.dataset.transforms.html#%E9%9F%B3%E9%A2%91">Audio数据增强</a>。</p></li>
<li><p>并且用户可根据特定的需求，自定义Python数据增强函数（Python实现）。</p></li>
</ul>
<p>数据增强操作由于实现方式不同（C++实现 VS Python实现），其性能存在差异，具体如下所示：</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 22%" />
<col style="width: 78%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>编程语言</p></th>
<th class="head"><p>说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>C++</p></td>
<td><p>使用C++代码实现，性能较高</p></td>
</tr>
<tr class="row-odd"><td><p>Python</p></td>
<td><p>使用Python代码实现，更加灵活</p></td>
</tr>
</tbody>
</table>
<p>数据增强操作选择参考：</p>
<p><img alt="data-enhancement-performance-scheme" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/experts/source_zh_cn/dataset/images/data_enhancement_performance_scheme.png" /></p>
<p>数据增强性能优化建议如下：</p>
<ul>
<li><p>优先使用MindSpore提供的数据增强操作，能获得更好的性能，如果性能仍无法满足需求，可采取如下方式进行优化：</p>
<ol class="arabic">
<li><p>多线程优化</p>
<p>增大<code class="docutils literal notranslate"><span class="pre">map</span></code>接口的参数<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>（默认值：8）来取得更好的性能。</p>
</li>
<li><p>融合算子优化</p>
<p>在当前CPU占用率比较高时（如：单机多卡训练），使用融合操作（将两个或多个操作的功能聚合到一个操作中）来降低CPU占用会获得更好性能，可以通过配置环境变量<code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">OPTIMIZE=true</span></code>来使其生效。融合示例如下： <img alt="operation-fusion" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/experts/source_zh_cn/dataset/images/operation_fusion.png" /></p>
</li>
<li><p>Compose优化</p>
<p>在当前CPU占用率比较高时（如：单机多卡训练），通过一个map操作接收多个增强操作（会按照顺序应用这些操作）来降低CPU降低竞争以取得更好性能。示例如下：</p>
<p><img alt="compose" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/experts/source_zh_cn/dataset/images/compose.png" /></p>
</li>
</ol>
</li>
</ul>
<ul class="simple">
<li><p>如果用户使用自定义Python函数进行数据增强，当性能仍无法满足需求，则可采取多进程/多线程并发方案，参考如下，但如果还是无法提升性能，就需要对自定义的Python函数进行优化。</p>
<ol class="arabic simple">
<li><p>增大<code class="docutils literal notranslate"><span class="pre">map</span></code>接口的参数<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>（默认值：8）来提升并发度；</p></li>
<li><p>将<code class="docutils literal notranslate"><span class="pre">map</span></code>接口的参数<code class="docutils literal notranslate"><span class="pre">python_multiprocessing</span></code>设置为<code class="docutils literal notranslate"><span class="pre">True</span></code>/<code class="docutils literal notranslate"><span class="pre">False(默认值)</span></code>来启动多进程模式/多线程模式，多进程模式适用于cpu计算密集型任务，多线程适用于IO密集型任务；</p></li>
<li><p>如果有<code class="docutils literal notranslate"><span class="pre">Using</span> <span class="pre">shared</span> <span class="pre">memory</span> <span class="pre">queue,</span> <span class="pre">but</span> <span class="pre">rowsize</span> <span class="pre">is</span> <span class="pre">larger</span> <span class="pre">than</span> <span class="pre">allocated</span> <span class="pre">memory</span> <span class="pre">...</span></code>日志提示，那么将<code class="docutils literal notranslate"><span class="pre">map</span></code>接口的参数<code class="docutils literal notranslate"><span class="pre">max_rowsize</span></code>（默认值：6M）按日志提示进行增大来提升进程间数据传递的效率。</p></li>
</ol>
</li>
</ul>
<p>基于以上的数据增强性能优化建议，本次体验分别使用实现在C++层的数据增强操作和自定义Python函数进行数据增强，演示代码如下所示：</p>
<ol class="arabic simple">
<li><p>使用实现在C++层的数据增强操作，采用多线程优化方案，开启了4个线程并发完成任务，并且采用了融合算子优化方案，框架中使用<code class="docutils literal notranslate"><span class="pre">RandomResizedCrop</span></code>融合类替代<code class="docutils literal notranslate"><span class="pre">RandomResize</span></code>类和<code class="docutils literal notranslate"><span class="pre">RandomCrop</span></code>类。</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset.vision</span> <span class="k">as</span> <span class="nn">vision</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">cifar10_path</span> <span class="o">=</span> <span class="s2">&quot;./datasets/cifar-10-batches-bin/train&quot;</span>

<span class="c1"># create Cifar10Dataset for reading data</span>
<span class="n">cifar10_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">cifar10_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">((</span><span class="mi">800</span><span class="p">,</span> <span class="mi">800</span><span class="p">))</span>
<span class="c1"># apply the transform to the dataset through dataset.map()</span>
<span class="n">cifar10_dataset</span> <span class="o">=</span> <span class="n">cifar10_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">transforms</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">cifar10_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/dataset_optimize_37_0.png" src="../_images/dataset_optimize_37_0.png" />
</div>
</div>
<ol class="arabic simple" start="2">
<li><p>使用自定义Python函数进行数据增强，数据增强时采用多进程优化方案，开启了4个进程并发完成任务。</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generator_func</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="k">yield</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">3</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">4</span><span class="p">]),)</span>

<span class="n">ds3</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">generator_func</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;before map:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">ds3</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">,)</span>
<span class="n">ds4</span> <span class="o">=</span> <span class="n">ds3</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">preprocess</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">python_multiprocessing</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;after map:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">ds4</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
before map:
[0 1 2 3 4]
[1 2 3 4 5]
[2 3 4 5 6]
[3 4 5 6 7]
[4 5 6 7 8]
after map:
[ 0  1  4  9 16]
[ 1  4  9 16 25]
[ 4  9 16 25 36]
[ 9 16 25 36 49]
[16 25 36 49 64]
</pre></div></div>
</div>
</section>
<section id="batch操作性能优化">
<h2>batch操作性能优化<a class="headerlink" href="#batch操作性能优化" title="Permalink to this headline"></a></h2>
<p>在数据处理的最后阶段，会使用batch操作将多条数据组织成一个batch，然后再传递给网络用于训练。对于batch操作的性能优化建议如下：</p>
<ul class="simple">
<li><p>如果仅配置了batch_size和drop_remainder，且batch_size比较大时，建议增大<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>（默认值：8）来取得更好的性能；</p></li>
<li><p>如果使用了per_batch_map功能，那么建议配置如下：</p>
<ol class="arabic simple">
<li><p>增大参数<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>（默认值：8）来提升并发度；</p></li>
<li><p>将参数<code class="docutils literal notranslate"><span class="pre">python_multiprocessing</span></code>设置为<code class="docutils literal notranslate"><span class="pre">True</span></code>/<code class="docutils literal notranslate"><span class="pre">False(默认值)</span></code>来启动多进程模式/多线程模式，多进程模式适用于cpu计算密集型任务，多线程适用于IO密集型任务；</p></li>
<li><p>如果有<code class="docutils literal notranslate"><span class="pre">Using</span> <span class="pre">shared</span> <span class="pre">memory</span> <span class="pre">queue,</span> <span class="pre">but</span> <span class="pre">rowsize</span> <span class="pre">is</span> <span class="pre">larger</span> <span class="pre">than</span> <span class="pre">allocated</span> <span class="pre">memory</span> <span class="pre">...</span></code>日志提示，那么将<code class="docutils literal notranslate"><span class="pre">batch</span></code>接口的参数<code class="docutils literal notranslate"><span class="pre">max_rowsize</span></code>（默认值：6M）按日志提示进行增大来提升进程间数据传递的效率。</p></li>
</ol>
</li>
</ul>
</section>
<section id="操作系统性能优化">
<h2>操作系统性能优化<a class="headerlink" href="#操作系统性能优化" title="Permalink to this headline"></a></h2>
<p>由于MindSpore的数据处理主要在Host端进行，运行环境的配置也会对处理性能产生影响，主要体现在存储设备、NUMA架构和CPU计算资源等方面。</p>
<ol class="arabic">
<li><p>存储设备</p>
<p>数据的加载过程涉及频繁的磁盘操作，磁盘读写的性能直接影响了数据加载的速度。当数据集较大时，推荐使用固态硬盘进行数据存储，固态硬盘的读写速度普遍较普通磁盘高，能够减少I/O操作对数据处理性能的影响。</p>
<p>一般地，加载后的数据将会被缓存到操作系统的页面缓存中，在一定程度上降低了后续读取的开销，加速了后续Epoch的数据加载速度。用户也可以通过MindSpore提供的<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/dataset/cache.html">单节点缓存技术</a>，手动缓存加载增强后的数据，避免了重复的数据加载和数据增强。</p>
</li>
<li><p>NUMA架构</p>
<p>NUMA的全称为Non-Uniform Memory Access，即非一致性内存访问，是为了解决传统的对称多处理器（SMP）架构中的可扩展性问题而诞生的一种内存架构。在传统架构中，多个处理器共用一条内存总线，容易产生带宽不足、内存冲突等问题。</p>
<p>而在NUMA架构中，处理器和内存被划分为多个组，每个组称为一个节点（Node），各个节点拥有独立的集成内存控制器（IMC）总线，用于节点内通信，不同节点间则通过快速路径互连（QPI）进行通信。对于某一节点来说，处在同节点内的内存被称为本地内存，处在其他节点的内存被称为外部内存，访问本地内存的延迟会小于访问外部内存的延迟。</p>
<p>在数据处理过程中，可以通过将进程与节点绑定，来减小内存访问的延迟。一般我们可以使用以下命令进行进程与node节点的绑定，或者可以通过配置环境变量<code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">DATASET_ENABLE_NUMA=True</span></code>使得每个训练进程绑定至不同的numa节点。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>numactl<span class="w"> </span>--cpubind<span class="o">=</span><span class="m">0</span><span class="w"> </span>--membind<span class="o">=</span><span class="m">0</span><span class="w"> </span>python<span class="w"> </span>train.py
</pre></div>
</div>
</li>
<li><p>CPU计算资源</p>
<p>尽管可以通过多线程并行技术加快数据处理的速度，但是实际运行时并不能保证CPU计算资源完全被利用起来。如果能够人为地事先完成计算资源配置的设定，将能在一定程度上提高CPU计算资源的利用率。</p>
<ul>
<li><p>计算资源的分配</p>
<p>在分布式训练中，同一设备上可能开启多个训练进程。默认情况下，各个进程的资源分配与抢占将会遵循操作系统本身的策略进行，当进程较多时，频繁的资源竞争可能会导致数据处理性能的下降。如果能够事先设定各个进程的计算资源分配，就能避免这种资源竞争带来的开销。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>numactl<span class="w"> </span>--cpubind<span class="o">=</span><span class="m">0</span><span class="w"> </span>python<span class="w"> </span>train.py
</pre></div>
</div>
</li>
<li><p>CPU频率设置</p>
<p>出于节约能效的考虑，操作系统会根据需要适时调整CPU的运行频率，但更低的功耗意味着计算性能的下降，会减慢数据处理的速度。要想充分发挥CPU的最大算力，需要手动设置CPU的运行频率。如果发现操作系统的CPU运行模式为平衡模式或者节能模式，可以通过将其调整为性能模式，提升数据处理的性能。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cpupower<span class="w"> </span>frequency-set<span class="w"> </span>-g<span class="w"> </span>performance
</pre></div>
</div>
</li>
<li><p>多线程竞争</p>
<p>如果用户在数据处理阶段使用了<code class="docutils literal notranslate"><span class="pre">cv2</span></code>，<code class="docutils literal notranslate"><span class="pre">numpy</span></code>，<code class="docutils literal notranslate"><span class="pre">numba</span></code>三方库，且使用<code class="docutils literal notranslate"><span class="pre">top</span></code>命令查看CPU时，出现<code class="docutils literal notranslate"><span class="pre">sy</span></code>占用高，而<code class="docutils literal notranslate"><span class="pre">us</span></code>占用低，说明出现了线程竞争，那么通过如下方式解决：</p>
<ol class="arabic simple">
<li><p>如果数据处理阶段有 <code class="docutils literal notranslate"><span class="pre">opencv</span></code> 的 <code class="docutils literal notranslate"><span class="pre">cv2</span></code> 操作，那么通过 <code class="docutils literal notranslate"><span class="pre">cv2.setNumThreads(2)</span></code> 设置 <code class="docutils literal notranslate"><span class="pre">cv2</span></code> 全局线程数减少线程竞争；</p></li>
<li><p>如果数据处理阶段有 <code class="docutils literal notranslate"><span class="pre">numpy</span></code> 操作，那么通过 <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">OPENBLAS_NUM_THREADS=1</span></code> 设置OPENBLAS线程数减少线程竞争；</p></li>
<li><p>如果数据处理阶段有 <code class="docutils literal notranslate"><span class="pre">numba</span></code> 操作，那么通过 <code class="docutils literal notranslate"><span class="pre">numba.set_num_threads(1)</span></code> 设置并行度来减少线程竞争。</p></li>
</ol>
</li>
<li><p>CPU/内存占用率高</p>
<p>因为MindSpore Dataset主要是使用Host侧CPU和内存做数据处理，在一些资源（CPU和Memory）比较紧张的环境，在进行数据预处理时会出现CPU占用过高，或者内存占用高的情况。那么可以通过如下方法降低CPU及内存占用率，但同时也会损失一些性能。更详细的使用指导可参考：<a class="reference external" href="https://blog.csdn.net/guozhijian521/article/details/123552540">https://blog.csdn.net/guozhijian521/article/details/123552540</a></p>
<ol class="arabic simple">
<li><p>在定义数据集 <code class="docutils literal notranslate"><span class="pre">**Dataset</span></code> 对象前，设置Dataset数据处理预取的大小，<code class="docutils literal notranslate"><span class="pre">ds.config.set_prefetch_size(2)</span></code>；</p></li>
<li><p>在定义 <code class="docutils literal notranslate"><span class="pre">**Dataset</span></code> 对象时，设置其参数 <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> 为1；</p></li>
<li><p>如果对 <code class="docutils literal notranslate"><span class="pre">**Dataset</span></code> 对象进一步使用了 <code class="docutils literal notranslate"><span class="pre">.map(...)</span></code> 操作，可以设置 <code class="docutils literal notranslate"><span class="pre">.map(...)</span></code> 的参数 <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> 为1；</p></li>
<li><p>如果对 <code class="docutils literal notranslate"><span class="pre">**Dataset</span></code> 对象进一步使用了 <code class="docutils literal notranslate"><span class="pre">.batch(...)</span></code> 操作，可以设置 <code class="docutils literal notranslate"><span class="pre">.batch(...)</span></code> 的参数 <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> 为1；</p></li>
<li><p>如果对 <code class="docutils literal notranslate"><span class="pre">**Dataset</span></code> 对象进一步使用了 <code class="docutils literal notranslate"><span class="pre">.shuffle(...)</span></code> 操作，可以把参数 <code class="docutils literal notranslate"><span class="pre">buffer_size</span></code> 设置减少；</p></li>
<li><p>如果有多个 <code class="docutils literal notranslate"><span class="pre">.map(...)</span></code> 操作，可以将多个 <code class="docutils literal notranslate"><span class="pre">.map(...)</span></code> 操作合并为一个。</p></li>
</ol>
</li>
</ul>
</li>
</ol>
</section>
<section id="单卡训练-vs-多卡训练并行度优化建议">
<h2>单卡训练 VS 多卡训练并行度优化建议<a class="headerlink" href="#单卡训练-vs-多卡训练并行度优化建议" title="Permalink to this headline"></a></h2>
<p>在使用MindSpore进行单卡或多卡训练时，num_parallel_workers参数的设置应遵循以下原则：</p>
<ul class="simple">
<li><p>各数据加载和处理操作所设置的num_parallel_workers参数之和应不大于CPU所支持的最大线程数，否则将造成各个操作间的资源竞争。</p></li>
<li><p>在设置num_parallel_workers参数之前，建议先使用MindSpore的Profiler(性能分析)工具分析训练中各个操作的性能情况，将更多的资源分配给性能较差的操作，即设置更大的num_parallel_workers，使得各个操作之间的吞吐达到平衡，避免不必要的等待。</p></li>
<li><p>在单卡训练场景中，提高num_parallel_workers参数往往能直接提高处理性能，但在多卡场景下，由于CPU竞争加剧，一味地提高num_parallel_workers可能会导致性能劣化，需要在实际训练中尝试使用折中数值。</p></li>
</ul>
</section>
<section id="自动数据加速">
<h2>自动数据加速<a class="headerlink" href="#自动数据加速" title="Permalink to this headline"></a></h2>
<p>MindSpore提供了一种自动数据调优的工具——Dataset AutoTune，用于在训练过程中根据环境资源的情况自动调整数据处理管道的并行度，最大化利用系统资源加速数据处理管道的处理速度。详细用法请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/dataset/dataset_autotune.html">自动数据加速</a>。</p>
</section>
<section id="数据异构加速">
<h2>数据异构加速<a class="headerlink" href="#数据异构加速" title="Permalink to this headline"></a></h2>
<p>MindSpore提供了一种运算负载均衡的技术，可以将MindSpore的Tensor运算分配到不同的异构硬件上，一方面均衡不同硬件之间的运算开销，另一方面利用异构硬件的优势对运算进行加速。详细用法请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/dataset/dataset_offload.html">数据异构加速</a>。</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="cache.html" class="btn btn-neutral float-left" title="单节点数据缓存" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../infer/inference.html" class="btn btn-neutral float-right" title="模型推理总览" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>