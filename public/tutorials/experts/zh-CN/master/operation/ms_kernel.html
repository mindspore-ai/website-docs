

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>MindSpore Hybrid 语法规范 &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/translations.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="自定义算子进阶用法" href="op_custom_adv.html" />
    <link rel="prev" title="自定义算子（基于Custom表达）" href="op_custom.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">数据处理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dataset/augment.html">自动数据增强</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/cache.html">单节点数据缓存</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/optimize.html">数据处理性能优化</a></li>
</ul>
<p class="caption"><span class="caption-text">图编译</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../network/control_flow.html">流程控制语句</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/op_overload.html">静态图网络编译性能优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/jit_class.html">调用自定义类</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/constexpr.html">网络内构造常量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/dependency_control.html">依赖控制</a></li>
</ul>
<p class="caption"><span class="caption-text">模型训练优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../optimize/execution_opt.html">下沉模式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/gradient_accumulation.html">梯度累积</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/adaptive_summation.html">自适应梯度求和算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/dimention_reduce_training.html">降维训练算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/thor.html">二阶优化</a></li>
</ul>
<p class="caption"><span class="caption-text">自定义算子</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="op_custom.html">自定义算子（基于Custom表达）</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">MindSpore Hybrid 语法规范</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#概述">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#语法规则">语法规则</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#变量">变量</a></li>
<li class="toctree-l3"><a class="reference internal" href="#计算表达">计算表达</a></li>
<li class="toctree-l3"><a class="reference internal" href="#循环">循环</a></li>
<li class="toctree-l3"><a class="reference internal" href="#调度原语">调度原语</a></li>
<li class="toctree-l3"><a class="reference internal" href="#属性">属性</a></li>
<li class="toctree-l3"><a class="reference internal" href="#关键词">关键词</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#常见报错信息及错误归因">常见报错信息及错误归因</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="op_custom_adv.html">自定义算子进阶用法</a></li>
</ul>
<p class="caption"><span class="caption-text">自动向量化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../vmap/vmap.html">自动向量化Vmap</a></li>
</ul>
<p class="caption"><span class="caption-text">模型推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../infer/inference.html">模型推理总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/ascend_310_air.html">Ascend 310 AI处理器上使用AIR模型进行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/model_compression.html">模型压缩</a></li>
</ul>
<p class="caption"><span class="caption-text">调试调优</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../debug/function_debug.html">功能调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/performance_optimization.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference external" href="https://mindspore.cn/mindinsight/docs/zh-CN/master/accuracy_problem_preliminary_location.html">精度调优↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/fault_recover.html">故障恢复</a></li>
</ul>
<p class="caption"><span class="caption-text">分布式并行</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../parallel/operator_parallel.html">算子级并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/pipeline_parallel.html">流水线并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/optimizer_parallel.html">优化器并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/recompute.html">重计算</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/host_device_training.html">Host&amp;Device异构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/parameter_server_training.html">Parameter Server模式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/train_ascend.html">快速入门分布式并行训练(半自动并行)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/parallel_training_quickstart.html">快速入门分布式并行训练(自动并行)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/distributed_inference.html">分布式推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/distributed_case.html">分布式案例</a></li>
</ul>
<p class="caption"><span class="caption-text">环境变量</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../env/env_var_list.html">环境变量</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>MindSpore Hybrid 语法规范</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/operation/ms_kernel.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="mindspore-hybrid-语法规范">
<h1>MindSpore Hybrid 语法规范<a class="headerlink" href="#mindspore-hybrid-语法规范" title="Permalink to this headline">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/master/tutorials/experts/source_zh_cn/operation/ms_kernel.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.png"></a></p>
<div class="section" id="概述">
<h2>概述<a class="headerlink" href="#概述" title="Permalink to this headline">¶</a></h2>
<p>MindSpore Hybrid DSL的语法与Python语法类似，例如函数定义、缩进和注释。把MindSpore Hybrid DSL书写的函数加上<code class="docutils literal notranslate"><span class="pre">kernel</span></code>装饰器后可以当做普通的<code class="docutils literal notranslate"><span class="pre">numpy</span></code>函数使用，也可以用于Custom的进行自定义算子。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">kernel</span>

<span class="nd">@kernel</span>
<span class="k">def</span> <span class="nf">outer_product</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">allocate</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i0</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">i1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">c</span><span class="p">[</span><span class="n">i0</span><span class="p">,</span> <span class="n">i1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">i2</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">d</span><span class="p">[</span><span class="n">i0</span><span class="p">,</span> <span class="n">i2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="n">i0</span><span class="p">,</span> <span class="n">i2</span><span class="p">]</span>
                <span class="n">c</span><span class="p">[</span><span class="n">i0</span><span class="p">,</span> <span class="n">i1</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="n">i0</span><span class="p">,</span> <span class="n">i1</span><span class="p">]</span> <span class="o">+</span> <span class="n">sin</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">i0</span><span class="p">,</span> <span class="n">i2</span><span class="p">]</span> <span class="o">*</span> <span class="n">b</span><span class="p">[</span><span class="n">i2</span><span class="p">,</span> <span class="n">i1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">c</span>

<span class="n">np_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">np_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">outer_product</span><span class="p">(</span><span class="n">np_x</span><span class="p">,</span> <span class="n">np_y</span><span class="p">))</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np_x</span><span class="p">)</span>
<span class="n">input_y</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np_y</span><span class="p">)</span>

<span class="n">test_op_akg</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Custom</span><span class="p">(</span><span class="n">outer_product</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">test_op_akg</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="语法规则">
<h2>语法规则<a class="headerlink" href="#语法规则" title="Permalink to this headline">¶</a></h2>
<div class="section" id="变量">
<h3>变量<a class="headerlink" href="#变量" title="Permalink to this headline">¶</a></h3>
<p>MindSpore Hybrid DSL中的变量包括Tensor和Scalar两种形式。</p>
<p>对于Tensor类型的变量，除了在输入中提供的变量，其他变量都需要在使用前申明 <code class="docutils literal notranslate"><span class="pre">shape</span></code>和 <code class="docutils literal notranslate"><span class="pre">dtype</span></code>。</p>
<ul class="simple">
<li><p>对于输出Tensor使用 <code class="docutils literal notranslate"><span class="pre">output_tensor</span></code>，用法为：<code class="docutils literal notranslate"><span class="pre">output_tensor(shape,</span> <span class="pre">dtype)</span></code>。</p></li>
<li><p>对于中间结果使用 <code class="docutils literal notranslate"><span class="pre">allocate</span></code>，用法为：<code class="docutils literal notranslate"><span class="pre">allocate(shape,</span> <span class="pre">dtype)</span></code>。</p></li>
</ul>
<p>Tensor分配的示例代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@kernel</span>
<span class="k">def</span> <span class="nf">kernel_func</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="c1"># a和b作为输入tensor，可以直接使用</span>

    <span class="c1"># d为一个数据类型为fp16,形状为(2,)的Tensor，在下面的code中作为中间变量使用</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">allocate</span><span class="p">((</span><span class="mi">2</span><span class="p">,),</span> <span class="s2">&quot;float16&quot;</span><span class="p">)</span>
    <span class="c1"># c为一个数据类型与b相同,形状与a相同的Tensor，在下面的code中作为函数输出使用</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="c1"># d作为中间变量，给c赋值</span>
    <span class="n">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
            <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># c作为输出</span>
    <span class="k">return</span> <span class="n">c</span>
</pre></div>
</div>
<p>对于Scalar类变量，会将它第一次的赋值运算作为声明。赋值操作可以是一个立即数，也可以是一个计算表达式。Scalar类变量第一次赋值的地方决定了它的定义域（例如，某一个for loop之内），在定义域之外使用Scalar变量会报错。</p>
<p>Scalar变量使用的示例代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@kernel</span>
<span class="k">def</span> <span class="nf">kernel_func</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span> <span class="c1"># i loop</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="c1"># j loop</span>
            <span class="c1"># 用一个立即数给Scalar赋值</span>
            <span class="n">d</span> <span class="o">=</span> <span class="mf">2.0</span>
            <span class="c1"># 用表达式给Scalar赋值</span>
            <span class="n">e</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="c1"># 正常使用scalar</span>
            <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span> <span class="o">+</span> <span class="n">e</span>

    <span class="c1"># Wrong: c[0, 0] = d</span>
    <span class="c1"># 不能在超出Scalar d的定义域（j loop）之外的范围使用</span>

    <span class="k">return</span> <span class="n">c</span>
</pre></div>
</div>
<p>与原生Python语言不同的是，变量一旦创建，<code class="docutils literal notranslate"><span class="pre">shape</span></code>和 <code class="docutils literal notranslate"><span class="pre">dtype</span></code>就不能改变。</p>
</div>
<div class="section" id="计算表达">
<h3>计算表达<a class="headerlink" href="#计算表达" title="Permalink to this headline">¶</a></h3>
<p>MindSpore Hybrid DSL支持基本的四则运算表达，包括 <code class="docutils literal notranslate"><span class="pre">+,</span> <span class="pre">-,</span> <span class="pre">*,</span> <span class="pre">/</span></code>，及赋值运算符，包括 <code class="docutils literal notranslate"><span class="pre">=,</span> <span class="pre">+=,</span> <span class="pre">-=,</span> <span class="pre">*=,</span> <span class="pre">/=</span></code>。
用户可以像写Python表达一样书写计算表达式利用变量计算和为变量赋值。</p>
<p><strong>所有的计算需要基于标量计算，如果是Tensor对象那么写清楚所有index，即 <code class="docutils literal notranslate"><span class="pre">C[i,</span> <span class="pre">j]</span> <span class="pre">=</span> <span class="pre">A[i,</span> <span class="pre">j]</span> <span class="pre">+</span> <span class="pre">B[i,</span> <span class="pre">j]</span></code>。当前不支持 <code class="docutils literal notranslate"><span class="pre">C</span> <span class="pre">=</span> <span class="pre">A</span> <span class="pre">+</span> <span class="pre">B</span></code>这种向量化的写法。</strong></p>
<p>在书写计算表达式时，用户需要自行负责类型的合法性。表达式左右两边的类型需要保持一致，否则在<strong>算子编译环节</strong>会报错。计算式中的整数立即数会被认定为int32，而浮点立即数会被认定为float32。MindSpore Hybrid DSL不提供任何隐式的类型转化，所有类型转化都需要显式的书写出来。类型名即对应类型转换函数的名字，包括：</p>
<ul class="simple">
<li><p>int32</p></li>
<li><p>float16</p></li>
<li><p>float32</p></li>
<li><p>(仅GPU后端)int8, int16, int64, float64</p></li>
</ul>
<p>类型转换代码示例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@kernel</span>
<span class="k">def</span> <span class="nf">kernel_func</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="p">((</span><span class="mi">2</span><span class="p">,),</span> <span class="s2">&quot;float16&quot;</span><span class="p">)</span>

    <span class="c1"># Wrong: c[0] = 0.1 此处c的类型为fp16, 而0.1的类型为fp32</span>
    <span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">float16</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># float16(0.1)把表达式的类型转化为fp16</span>
    <span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">float16</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span> <span class="c1"># float16(a[0, 0])把表达式的类型转化为fp16</span>

    <span class="k">return</span> <span class="n">c</span>
</pre></div>
</div>
</div>
<div class="section" id="循环">
<h3>循环<a class="headerlink" href="#循环" title="Permalink to this headline">¶</a></h3>
<p>当前只支持 <code class="docutils literal notranslate"><span class="pre">for</span></code> loop，不支持 <code class="docutils literal notranslate"><span class="pre">while</span></code>、 <code class="docutils literal notranslate"><span class="pre">break</span></code>、 <code class="docutils literal notranslate"><span class="pre">continue</span></code>关键词。</p>
<p>基本循环的写法和Python一样，循环维度的表达可以使用 <code class="docutils literal notranslate"><span class="pre">range</span></code>和 <code class="docutils literal notranslate"><span class="pre">grid</span></code>关键词。<code class="docutils literal notranslate"><span class="pre">range</span></code>表示一维的循环维度，接受一个参数表示循环的上限，例如：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@kernel</span>
<span class="k">def</span> <span class="nf">kernel_func</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="s2">&quot;float16&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
                <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
    <span class="k">return</span>  <span class="n">c</span>
</pre></div>
</div>
<p>则循环表达的计算空间为 <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">i</span> <span class="pre">&lt;</span> <span class="pre">3,</span> <span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">j</span> <span class="pre">&lt;</span> <span class="pre">4,</span> <span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">k</span> <span class="pre">&lt;</span> <span class="pre">5</span></code>。</p>
<p><code class="docutils literal notranslate"><span class="pre">grid</span></code>表示多维网格，接受的输入为 <code class="docutils literal notranslate"><span class="pre">tuple</span></code> ，例如上面的代码用 <code class="docutils literal notranslate"><span class="pre">grid</span></code>表达后如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@kernel</span>
<span class="k">def</span> <span class="nf">kernel_func</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="s2">&quot;float16&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">grid</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">)):</span>
        <span class="n">out</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span>
    <span class="k">return</span>  <span class="n">c</span>
</pre></div>
</div>
<p>此时，参数 <code class="docutils literal notranslate"><span class="pre">arg</span></code>等价于一个三维index <code class="docutils literal notranslate"><span class="pre">(i,j,k)</span></code>，其上限分别为4，5，6。对参数 <code class="docutils literal notranslate"><span class="pre">arg</span></code>我们可以取其中的某个分量，例如</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@kernel</span>
<span class="k">def</span> <span class="nf">kernel_func</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="s2">&quot;float16&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">grid</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">)):</span>
        <span class="n">out</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">arg</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="k">return</span>  <span class="n">c</span>
</pre></div>
</div>
<p>那么循环内的表达式等价于 <code class="docutils literal notranslate"><span class="pre">out[i,</span> <span class="pre">j,</span> <span class="pre">k]</span> <span class="pre">=</span> <span class="pre">a[i,</span> <span class="pre">j,</span> <span class="pre">k]</span> <span class="pre">+</span> <span class="pre">b[i]</span></code>。</p>
</div>
<div class="section" id="调度原语">
<h3>调度原语<a class="headerlink" href="#调度原语" title="Permalink to this headline">¶</a></h3>
<p>从1.8版本开始，MindSpore Hybrid DSL 提供调度原语以描述不同类型的循环。在 Ascend 后端，调度原语将协助新 DSA 多面体调度器生成代码。此类调度原语包括：<code class="docutils literal notranslate"><span class="pre">serial</span></code>， <code class="docutils literal notranslate"><span class="pre">vectorize</span></code>， <code class="docutils literal notranslate"><span class="pre">parallel</span></code>，和 <code class="docutils literal notranslate"><span class="pre">reduce</span></code>。</p>
<p><code class="docutils literal notranslate"><span class="pre">serial</span></code> 会提示调度器该循环在调度生成时应保持前后顺序，不要做会改变顺序的调度变换，例如：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@kernel</span>
<span class="k">def</span> <span class="nf">serial_test</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">row</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">col</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">serial</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">serial</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
            <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">b</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">b</span>
</pre></div>
</div>
<p>这里 <code class="docutils literal notranslate"><span class="pre">serial</span></code> 提示 <code class="docutils literal notranslate"><span class="pre">i</span></code> 和 <code class="docutils literal notranslate"><span class="pre">j</span></code> 的计算有依赖关系，调度时应保持 <code class="docutils literal notranslate"><span class="pre">i</span></code> 和 <code class="docutils literal notranslate"><span class="pre">j</span></code> 从小的大的顺序。</p>
<p><code class="docutils literal notranslate"><span class="pre">vectorize</span></code> 一般用于最内层循环，会提示调度器该循环有生成向量化指令的机会，例如：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@kernel</span>
<span class="k">def</span> <span class="nf">vector_test</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">row</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">col</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">vectorize</span><span class="p">(</span><span class="n">col</span><span class="p">):</span>
            <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
<p>这里 <code class="docutils literal notranslate"><span class="pre">vectorize</span></code> 提示最内层 <code class="docutils literal notranslate"><span class="pre">j</span></code> 轴循环包含同质化计算，调度时可以生成向量化指令加速内层循环。</p>
<p><code class="docutils literal notranslate"><span class="pre">parallel</span></code> 一般用于最外层循环，会提示调度器该循环有并行执行机会，例如：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@kernel</span>
<span class="k">def</span> <span class="nf">parallel_test</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">row</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">col</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">parallel</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">col</span><span class="p">):</span>
            <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
<p>这里 <code class="docutils literal notranslate"><span class="pre">parallel</span></code> 提示最外层 <code class="docutils literal notranslate"><span class="pre">i</span></code> 轴循环无依赖关系，调度时可以并行加速。</p>
<p><code class="docutils literal notranslate"><span class="pre">reduce</span></code> 会提示调度器该循环为运算中的一个 Reduction 轴，例如：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">reduce_test</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="p">((</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">),</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">row</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">col</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
        <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">reduce</span><span class="p">(</span><span class="n">col</span><span class="p">):</span>
            <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
<p>这里 <code class="docutils literal notranslate"><span class="pre">reduce</span></code> 对应的 <code class="docutils literal notranslate"><span class="pre">k</span></code> 轴为累加轴。</p>
<p>用户在使用调度原语的时候需要注意：</p>
<ul class="simple">
<li><p>上述调度原语只会在 Ascend 后端影响调度。在CPU和GPU后端，上述调度原语将被处理成普通的 <code class="docutils literal notranslate"><span class="pre">for</span></code> 循环关键词。</p></li>
<li><p>调度原语对于调度器只是提示作用，当调度原语的提示和调度器自身的分析验证相矛盾时，调度器将把上述调度原语将被处理成普通的 <code class="docutils literal notranslate"><span class="pre">for</span></code> 循环关键词。</p></li>
</ul>
</div>
<div class="section" id="属性">
<h3>属性<a class="headerlink" href="#属性" title="Permalink to this headline">¶</a></h3>
<p>当前只支持对Tensor对象属性shape和dtype，例如 <code class="docutils literal notranslate"><span class="pre">a.shape</span></code>，<code class="docutils literal notranslate"><span class="pre">c.dtype</span></code>。</p>
<p>一个Tensor的shape属性会表达为一个 <code class="docutils literal notranslate"><span class="pre">tuple</span></code>，我们可以对它进行<strong>固定</strong>下标的取分量操作，例如 <code class="docutils literal notranslate"><span class="pre">a.shape[0]</span></code>。</p>
<p>同时，在 <code class="docutils literal notranslate"><span class="pre">grid</span></code>关键词中我们接受某个Tensor对象的 <code class="docutils literal notranslate"><span class="pre">shape</span></code>属性，那么循环的维度由Tensor的维度决定。例如：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@kernel</span>
<span class="k">def</span> <span class="nf">kernel_func</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;float16&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">grid</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
        <span class="n">out</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">arg</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="k">return</span>  <span class="n">c</span>
</pre></div>
</div>
<p>如果a是一个二维Tensor，那么循环内的表达式等价于 <code class="docutils literal notranslate"><span class="pre">out[i,</span> <span class="pre">j]</span> <span class="pre">=</span> <span class="pre">a[i,</span> <span class="pre">j]</span> <span class="pre">+</span> <span class="pre">b[i]</span></code>。而如果a是一个三维Tensor，那么循环内的表达式等价于 <code class="docutils literal notranslate"><span class="pre">out[i,</span> <span class="pre">j,</span> <span class="pre">k]</span> <span class="pre">=</span> <span class="pre">a[i,</span> <span class="pre">j,</span> <span class="pre">k]</span> <span class="pre">+</span> <span class="pre">b[i]</span></code>。</p>
</div>
<div class="section" id="关键词">
<h3>关键词<a class="headerlink" href="#关键词" title="Permalink to this headline">¶</a></h3>
<p>当前支持的关键词包括</p>
<ul class="simple">
<li><p>全平台支持数学函数：<code class="docutils literal notranslate"><span class="pre">log</span></code>、<code class="docutils literal notranslate"><span class="pre">exp</span></code>、<code class="docutils literal notranslate"><span class="pre">sqrt</span></code>、<code class="docutils literal notranslate"><span class="pre">tanh</span></code>、<code class="docutils literal notranslate"><span class="pre">power</span></code>、<code class="docutils literal notranslate"><span class="pre">floor</span></code></p></li>
<li><p>内存分配：<code class="docutils literal notranslate"><span class="pre">allocate</span></code>、 <code class="docutils literal notranslate"><span class="pre">output_tensor</span></code></p></li>
<li><p>数据类型转化：<code class="docutils literal notranslate"><span class="pre">int32</span></code>、 <code class="docutils literal notranslate"><span class="pre">float16</span></code>、 <code class="docutils literal notranslate"><span class="pre">float32</span></code>、 <code class="docutils literal notranslate"><span class="pre">float64</span></code></p></li>
<li><p>循环表达：<code class="docutils literal notranslate"><span class="pre">for</span></code>、 <code class="docutils literal notranslate"><span class="pre">range</span></code>、 <code class="docutils literal notranslate"><span class="pre">grid</span></code></p></li>
<li><p>调度源语：<code class="docutils literal notranslate"><span class="pre">serial</span></code>、 <code class="docutils literal notranslate"><span class="pre">vec</span></code>、 <code class="docutils literal notranslate"><span class="pre">parallel</span></code>、 <code class="docutils literal notranslate"><span class="pre">reduce</span></code></p></li>
<li><p>在当前版本中，我们对CPU/GPU后端提供部分进阶关键词：</p>
<ul>
<li><p>数学函数：<code class="docutils literal notranslate"><span class="pre">rsqrt</span></code>、 <code class="docutils literal notranslate"><span class="pre">erf</span></code>、 <code class="docutils literal notranslate"><span class="pre">isnan</span></code>、 <code class="docutils literal notranslate"><span class="pre">sin</span></code>、 <code class="docutils literal notranslate"><span class="pre">cos</span></code>、 <code class="docutils literal notranslate"><span class="pre">isinf</span></code>、 <code class="docutils literal notranslate"><span class="pre">isfinite</span></code>、 <code class="docutils literal notranslate"><span class="pre">atan</span></code>、 <code class="docutils literal notranslate"><span class="pre">atan2</span></code>(仅GPU)、 <code class="docutils literal notranslate"><span class="pre">expm1</span></code>(仅GPU)、 <code class="docutils literal notranslate"><span class="pre">floor</span></code>、 <code class="docutils literal notranslate"><span class="pre">ceil</span></code>、 <code class="docutils literal notranslate"><span class="pre">trunc</span></code>、 <code class="docutils literal notranslate"><span class="pre">round</span></code>、 <code class="docutils literal notranslate"><span class="pre">ceil_div</span></code></p></li>
<li><p>数据类型转换：<code class="docutils literal notranslate"><span class="pre">int8</span></code>，<code class="docutils literal notranslate"><span class="pre">int16</span></code>，<code class="docutils literal notranslate"><span class="pre">int64</span></code></p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="常见报错信息及错误归因">
<h2>常见报错信息及错误归因<a class="headerlink" href="#常见报错信息及错误归因" title="Permalink to this headline">¶</a></h2>
<p>为了帮助用户高效地开发和定位bug，MindSpore Hybrid DSL 提供如下报错信息，包括</p>
<ul class="simple">
<li><p>TypeError: 当使用了<code class="docutils literal notranslate"><span class="pre">while</span></code>, <code class="docutils literal notranslate"><span class="pre">break</span></code> 和 <code class="docutils literal notranslate"><span class="pre">continue</span></code> 等 MindSpore Hybrid DSL 不支持的 Python 关键词。</p></li>
<li><p>ValueError:</p>
<ul>
<li><p>使用了不属于上面的内置函数名；</p></li>
<li><p>对张量取非 <code class="docutils literal notranslate"><span class="pre">shape</span></code> 或者 <code class="docutils literal notranslate"><span class="pre">dtype</span></code> 的属性。</p></li>
</ul>
</li>
<li><p>其他常见报错：</p>
<ul>
<li><p>“SyntaxError”: 写的 DSL 不符合基本 Python 语法（非上面的进阶用法中定义的MindSpore Hybrid DSL语法），由 Python 解释器本身报错；</p></li>
<li><p>“ValueError: Compile error”及“The pointer[kernel_mod] is null”: Python DSL符合语法但是编译失败，由 AKG 报错，具体错误原因检查 AKG 相关报错信息；</p></li>
<li><p>“Launch graph failed”: Python DSL符合语法，编译成功但是运行失败。具体原因参考硬件的报错信息。例如在昇腾芯片上遇到运行失败时，MindSpore 端会显示 “Ascend error occurred” 及对应硬件报错信息。</p></li>
</ul>
</li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="op_custom_adv.html" class="btn btn-neutral float-right" title="自定义算子进阶用法" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="op_custom.html" class="btn btn-neutral float-left" title="自定义算子（基于Custom表达）" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>