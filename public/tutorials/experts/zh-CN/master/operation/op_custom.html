<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>自定义算子（基于Custom表达） &mdash; MindSpore master 文档</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="MindSpore Hybrid 语法规范" href="ms_kernel.html" />
    <link rel="prev" title="异构存储" href="../parallel/memory_offload.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">静态图使用规范</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../network/control_flow.html">流程控制语句</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/jit_class.html">调用自定义类</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/constexpr.html">网络内构造常量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/dependency_control.html">依赖控制</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">分布式并行</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../parallel/overview.html">分布式并行总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/basic_cases.html">分布式基础案例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/operator_parallel.html">算子级并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/pipeline_parallel.html">流水线并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/optimizer_parallel.html">优化器并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/recompute.html">重计算</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/host_device_training.html">Host&amp;Device异构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/parameter_server_training.html">Parameter Server模式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/startup_method.html">分布式并行启动方式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/distributed_inference.html">分布式推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/distributed_case.html">分布式高阶配置案例</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">自定义算子</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">自定义算子（基于Custom表达）</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#概述">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#基本用法">基本用法</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hybrid类型的自定义算子开发">Hybrid类型的自定义算子开发</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tbe类型的自定义算子开发">tbe类型的自定义算子开发</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aicpu类型的自定义算子开发">aicpu类型的自定义算子开发</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aot类型的自定义算子开发">aot类型的自定义算子开发</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#gpu示例">GPU示例</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cpu示例">CPU示例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pyfunc类型的自定义算子开发">pyfunc类型的自定义算子开发</a></li>
<li class="toctree-l3"><a class="reference internal" href="#julia类型的自定义算子开发">julia类型的自定义算子开发</a></li>
<li class="toctree-l3"><a class="reference internal" href="#akg类型的自定义算子开发">akg类型的自定义算子开发</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#开发用例">开发用例</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#用例一-基于pyfunc模式定义sin算子">用例一：基于pyfunc模式定义sin算子</a></li>
<li class="toctree-l3"><a class="reference internal" href="#用例二-利用hybrid类型的自定义算子实现三维张量的加法函数">用例二：利用hybrid类型的自定义算子实现三维张量的加法函数</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ms_kernel.html">MindSpore Hybrid 语法规范</a></li>
<li class="toctree-l1"><a class="reference internal" href="op_custom_adv.html">自定义算子注册</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">性能优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/master/performance_profiling.html">Profiling↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/execution_opt.html">下沉模式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/op_overload.html">静态图网络编译性能优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/graph_fusion_engine.html">使能图算融合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/op_compilation.html">算子增量编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/mem_reuse.html">内存复用</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">算法优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../optimize/gradient_accumulation.html">梯度累积</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/adaptive_summation.html">自适应梯度求和算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/dimention_reduce_training.html">降维训练算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/thor.html">二阶优化</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">高阶函数式编程</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../vmap/vmap.html">自动向量化Vmap</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">数据处理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dataset/augment.html">自动数据增强</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/cache.html">单节点数据缓存</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/optimize.html">数据处理性能优化</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../infer/inference.html">模型推理总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/model_compression.html">模型压缩</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">复杂问题调试</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../debug/dump.html">Dump功能调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/aoe.html">AOE调优工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/rdr.html">Running Data Recorder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/fault_recover.html">故障恢复</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>自定义算子（基于Custom表达）</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/operation/op_custom.md.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="自定义算子基于custom表达">
<h1>自定义算子（基于Custom表达）<a class="headerlink" href="#自定义算子基于custom表达" title="永久链接至标题"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/master/tutorials/experts/source_zh_cn/operation/op_custom.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.png"></a></p>
<section id="概述">
<h2>概述<a class="headerlink" href="#概述" title="永久链接至标题"></a></h2>
<p>当开发网络遇到内置算子不足以满足需求时，你可以利用MindSpore的Python API中的<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/ops/mindspore.ops.Custom.html#mindspore-ops-custom">Custom</a>原语方便快捷地进行不同类型自定义算子的定义和使用。</p>
<p>传统的添加一个自定义算子的方式，需要完成算子原语注册、算子实现、算子信息注册三部分工作。</p>
<p>其中：</p>
<ul class="simple">
<li><p>算子原语：定义了算子在网络中的前端接口原型，也是组成网络模型的基础单元，主要包括算子的名称、属性（可选）、输入输出名称、输出shape推理方法、输出数据类型推理方法等信息。</p></li>
<li><p>算子实现：在Python侧定义函数（Ascend自定义算子）或C++侧定义类（GPU和CPU自定义算子），描述算子内部计算逻辑的实现。</p></li>
<li><p>算子信息：描述自定义算子的基本信息，如算子名称、支持的输入输出数据类型、支持的输入输出数据格式和属性等。它是后端做算子选择和映射时的依据。</p></li>
</ul>
<p>相比于传统自定义算子方式，基于<code class="docutils literal notranslate"><span class="pre">Custom</span></code>原语自定义算子具有如下优势：</p>
<ul class="simple">
<li><p>不同的自定义算子对应的算子原语都是<code class="docutils literal notranslate"><span class="pre">Custom</span></code>原语，无需对每个自定义算子定义一个相应的算子原语。上述提到的三部分工作可以在网络脚本中以统一的接口进行实现，并作为网络表达的一部分，不需要对MindSpore框架进行侵入式修改和重新编译。</p></li>
<li><p>实现了不同方式自定义算子的接口和使用统一，方便网络开发者根据需要灵活选用不同的自定义方式。</p></li>
<li><p>新增支持hybrid等自定义算子方式，并且可以跨平台使用。</p></li>
</ul>
</section>
<section id="基本用法">
<h2>基本用法<a class="headerlink" href="#基本用法" title="永久链接至标题"></a></h2>
<p>基于<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/ops/mindspore.ops.Custom.html#mindspore-ops-custom">Custom</a>原语的自定义算子支持的算子开发方式包括：hybrid、tbe、aicpu、aot、pyfunc、julia、akg。</p>
<p>不同的算子开发方式差异如下：</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-left head"><p>算子开发方式</p></th>
<th class="text-left head"><p>开发语言</p></th>
<th class="text-left head"><p>编译方式</p></th>
<th class="text-left head"><p>支持平台</p></th>
<th class="text-left head"><p>推荐场景</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><span class="xref myst">hybrid</span></p></td>
<td class="text-left"><p>MindSpore HYBRID DSL</p></td>
<td class="text-left"><p>JIT</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td class="text-left"><p>全平台通用开发和快速验证</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span class="xref myst">tbe</span></p></td>
<td class="text-left"><p>TBE DSL</p></td>
<td class="text-left"><p>JIT</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
<td class="text-left"><p>Ascend AICORE自定义算子场景</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span class="xref myst">aicpu</span></p></td>
<td class="text-left"><p>C/C++</p></td>
<td class="text-left"><p>AOT</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
<td class="text-left"><p>Ascend AICPU自定义算子场景</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span class="xref myst">aot</span></p></td>
<td class="text-left"><p>C/C++/CUDA</p></td>
<td class="text-left"><p>AOT</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td class="text-left"><p>高性能手写、对接调用第三方算子库场景</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span class="xref myst">pyfunc</span></p></td>
<td class="text-left"><p>Python</p></td>
<td class="text-left"><p>JIT</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td class="text-left"><p>快速算法验证、需要与Python进行交互等场景</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span class="xref myst">julia</span></p></td>
<td class="text-left"><p>Julia</p></td>
<td class="text-left"><p>JIT</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td class="text-left"><p>科学计算场景、需要使用Julia编程等场景</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span class="xref myst">akg</span></p></td>
<td class="text-left"><p>MindSpore AKG DSL</p></td>
<td class="text-left"><p>JIT</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td class="text-left"><p>用于开发验证场景，不建议普通用户使用</p></td>
</tr>
</tbody>
</table>
<blockquote>
<div><ul class="simple">
<li><p>DSL全称是Domain Specific Language。</p></li>
<li><p>AOT（Ahead Of Time）编译方式指的是，算子实现函数需提前被编译为动态链接库，然后在网络运行时由框架自动调用；JIT（Just In Time）编译方式则不需要提前编译算子实现函数，而是在网络编译或运行期间被框架直接调用。</p></li>
</ul>
</div></blockquote>
<p>不同平台的不同场景下的推荐开发方式如下：</p>
<ul class="simple">
<li><p>Ascend: hybrid（通用场景），aicpu（不规则运算的高性能实现）；</p></li>
<li><p>GPU: hybrid（通用场景），aot（基于CUDA的高性能实现）；</p></li>
<li><p>CPU: hybrid（通用场景），aot（基于C++的高性能实现）。</p></li>
</ul>
<p>不同的开发方式使用不同的开发语言实现算子计算逻辑，但是自定义算子的开发流程是一致的，包括算子实现、算子输出shape和数据类型推理和算子信息注册（可选）。网络开发者可以根据需要选用不同的自定义算子开发方式。下面分别介绍这几种自定义算子开发方式，每种开发方式均提供示例。</p>
<blockquote>
<div><p>更多示例可参考MindSpore源码中<a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/master/tests/st/ops/graph_kernel/custom">tests/st/ops/graph_kernel/custom</a>下的用例。</p>
</div></blockquote>
<section id="hybrid类型的自定义算子开发">
<h3>Hybrid类型的自定义算子开发<a class="headerlink" href="#hybrid类型的自定义算子开发" title="永久链接至标题"></a></h3>
<p>Hybrid类型的自定义算子是自定义算子的默认定义类型。通过使用Hybrid类型的自定义算子，用户可以用类Python的语法描述算子计算逻辑，且无需关注MindSpore框架对于算子定义的工程细节，让用户专注于算法本身。</p>
<p>Hybrid类型的自定义算子使用<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/operation/ms_kernel.html#%E8%AF%AD%E6%B3%95%E8%A7%84%E5%88%99">MindSpore Hybrid DSL</a>描述算子内部计算逻辑的实现。用MindSpore Hybrid DSL定义的函数可以被<a class="reference external" href="https://gitee.com/mindspore/akg">AKG算子编译器</a>解析进行JIT编译生成高效算子，在大规模模型的训练推理中使用。同时，用MindSpore Hybrid DSL定义的函数可以当做一个<code class="docutils literal notranslate"><span class="pre">numpy</span></code>函数直接调用，方便用户调试的同时也可以灵活的切换到<span class="xref myst">pyfunc 类型的自定义算子</span>，做到一次开发，多个模式多个平台多个场景复用的自定义算子表达。</p>
<p>下面用例(test_custom_hybrid.py)介绍hybrid类型的自定义算子开发流程，其中自定义算子实现两个输入张量相加的功能。
值得注意的是，Hybrid类型的自定义算子采取源码变换的方式打通MindSpore的图编译器和算子编译器，用户可以直接使用MindSpore Hybrid DSL提供的关键词，例如下面的<code class="docutils literal notranslate"><span class="pre">output_tensor</span></code>，而无需引入对应Python函数。更多MindSpore Hybrid DSL关键词的介绍，参见<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/operation/ms_kernel.html#%E5%85%B3%E9%94%AE%E8%AF%8D">MindSpore Hybrid DSL关键词</a>。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">kernel</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;GPU&quot;</span><span class="p">)</span>

<span class="c1"># 算子实现，Hybrid DSL</span>
<span class="nd">@kernel</span>
<span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i0</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">i1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">c</span><span class="p">[</span><span class="n">i0</span><span class="p">,</span> <span class="n">i1</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i0</span><span class="p">,</span> <span class="n">i1</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i0</span><span class="p">,</span> <span class="n">i1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">c</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># 定义hybrid类型的自定义算子(Custom的默认模式)</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Custom</span><span class="p">(</span><span class="n">add</span><span class="p">)</span>

    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x0</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x1</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>本例中，有如下几点需要说明：</p>
<ul class="simple">
<li><p>Hybrid类型是Custom的默认类型。</p></li>
<li><p>Hybrid类型自定义算子的输入必须是一个带有<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/ops/mindspore.ops.kernel.html"><code class="docutils literal notranslate"><span class="pre">&#64;kernel</span></code></a>的函数。</p></li>
<li><p>Hybrid类型自定义算子定义时可以使用自带的自动shape/dtype推导函数，也可以手动输入shape/dtype推导函数。</p></li>
</ul>
<p>执行用例：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>test_custom_hybrid.py
</pre></div>
</div>
<p>执行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[2. 2.]
 [4. 4.]]
</pre></div>
</div>
</section>
<section id="tbe类型的自定义算子开发">
<h3>tbe类型的自定义算子开发<a class="headerlink" href="#tbe类型的自定义算子开发" title="永久链接至标题"></a></h3>
<p>tbe类型的自定义算子使用TBE（Tensor Boost Engine）算子DSL，描述算子内部计算逻辑的实现。算子DSL开发可以参考<a class="reference external" href="https://www.hiascend.com/document/detail/zh/canncommercial/51RC2/operatordev/tbedevg/tbedevg_000003.html">TBE文档</a>。</p>
<p>算子输出shape和数据类型推理可以通过定义Python函数实现，描述算子输出shape和数据类型的推导逻辑。</p>
<p>这种类型的自定义算子需要注册算子信息，算子信息生成方式请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/operation/op_custom_adv.html#%E7%AE%97%E5%AD%90%E4%BF%A1%E6%81%AF%E6%B3%A8%E5%86%8C">算子信息注册</a>。</p>
<p>下面以test_custom_tbe.py为例介绍tbe类型的自定义算子开发流程，其中自定义算子实现两个输入张量相加的功能。</p>
<p>test_custom_tbe.py内容：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">DataType</span><span class="p">,</span> <span class="n">CustomRegOp</span><span class="p">,</span> <span class="n">custom_info_register</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>

<span class="c1"># 算子实现，注册算子信息</span>
<span class="nd">@custom_info_register</span><span class="p">(</span><span class="n">CustomRegOp</span><span class="p">()</span> \
                      <span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> \
                      <span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">)</span> \
                      <span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;output&quot;</span><span class="p">)</span> \
                      <span class="o">.</span><span class="n">dtype_format</span><span class="p">(</span><span class="n">DataType</span><span class="o">.</span><span class="n">F16_Default</span><span class="p">,</span> <span class="n">DataType</span><span class="o">.</span><span class="n">F16_Default</span><span class="p">,</span> <span class="n">DataType</span><span class="o">.</span><span class="n">F16_Default</span><span class="p">)</span> \
                      <span class="o">.</span><span class="n">dtype_format</span><span class="p">(</span><span class="n">DataType</span><span class="o">.</span><span class="n">F32_Default</span><span class="p">,</span> <span class="n">DataType</span><span class="o">.</span><span class="n">F32_Default</span><span class="p">,</span> <span class="n">DataType</span><span class="o">.</span><span class="n">F32_Default</span><span class="p">)</span> \
                      <span class="o">.</span><span class="n">target</span><span class="p">(</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span> \
                      <span class="o">.</span><span class="n">get_op_info</span><span class="p">())</span>
<span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">kernel_name</span><span class="o">=</span><span class="s2">&quot;add&quot;</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">te.lang.cce</span>
    <span class="kn">from</span> <span class="nn">te</span> <span class="kn">import</span> <span class="n">tvm</span>
    <span class="n">data0</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;data0&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="n">data1</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;data1&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">b</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">cce</span><span class="o">.</span><span class="n">vadd</span><span class="p">(</span><span class="n">data0</span><span class="p">,</span> <span class="n">data1</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tvm</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">cce</span><span class="p">():</span>
        <span class="n">sch</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">cce</span><span class="o">.</span><span class="n">auto_schedule</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;print_ir&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">kernel_name</span><span class="p">,</span> <span class="s2">&quot;tensor_list&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">data0</span><span class="p">,</span> <span class="n">data1</span><span class="p">,</span> <span class="n">res</span><span class="p">]}</span>
    <span class="n">te</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">cce</span><span class="o">.</span><span class="n">cce_build_code</span><span class="p">(</span><span class="n">sch</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># 定义tbe类型的自定义算子</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Custom</span><span class="p">(</span><span class="n">add</span><span class="p">,</span> <span class="n">out_shape</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">out_dtype</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">func_type</span><span class="o">=</span><span class="s2">&quot;tbe&quot;</span><span class="p">)</span>

    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x0</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x1</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>本例中，有如下几点需要说明：</p>
<ul class="simple">
<li><p>用Python lambda函数定义输出shape和数据类型推理函数，并分别传给<code class="docutils literal notranslate"><span class="pre">Custom</span></code>原语的<code class="docutils literal notranslate"><span class="pre">out_shape</span></code>和<code class="docutils literal notranslate"><span class="pre">out_dtype</span></code>参数。本例中lambda函数表明输出shape和数据类型和第一个输入张量的信息相同。</p></li>
<li><p>通过<code class="docutils literal notranslate"><span class="pre">CustomRegOp</span></code>生成算子信息，并通过<code class="docutils literal notranslate"><span class="pre">custom_info_register</span></code>装饰器注册算子信息。</p></li>
</ul>
<p>执行用例：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>test_custom_tbe.py
</pre></div>
</div>
<p>执行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[2. 2.]
 [4. 4.]]
</pre></div>
</div>
</section>
<section id="aicpu类型的自定义算子开发">
<h3>aicpu类型的自定义算子开发<a class="headerlink" href="#aicpu类型的自定义算子开发" title="永久链接至标题"></a></h3>
<p>aicpu类型的自定义算子采用AOT编译方式，要求算子开发者基于提供的特定接口，手写算子实现函数对应的源码文件，并提前将源码文件编译为动态链接库，然后框架会根据开发者在算子属性中配置的动态链接库名称，找到对应动态链接库并加载算子。具体算子实现参考<a class="reference external" href="https://www.hiascend.com/document/detail/zh/canncommercial/51RC2/operatordev/aicpudevg/aicpudevg_000026.html">CANN AICPU 自定义算子开发</a>。</p>
<p>算子输出shape和数据类型推理可以通过定义Python函数实现，描述算子输出shape和数据类型的推导逻辑。</p>
<p>这种类型的自定义算子需要注册算子信息，算子信息生成方式请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/operation/op_custom_adv.html#%E7%AE%97%E5%AD%90%E4%BF%A1%E6%81%AF%E6%B3%A8%E5%86%8C">算子信息注册</a>，aicpu类型的自定义算子，需要额外指定<code class="docutils literal notranslate"><span class="pre">attr(&quot;cust_aicpu&quot;,</span>&#160; <span class="pre">&quot;required&quot;,</span> <span class="pre">&quot;str&quot;,</span> <span class="pre">&quot;mindspore_aicpu_kernels&quot;)</span></code>的属性，用于MindSpore找到对应的算子实现的动态链接库。</p>
<blockquote>
<div><ul class="simple">
<li><p>需要注意的是，aicpu类型的自定义算子开发后编译成的动态链接库，需要存放到MindSpore的lib目录下，比如MindSpore安装在虚拟环境<code class="docutils literal notranslate"><span class="pre">/home/conda/envs/aicpu/lib/python3.7/site-packages/mindspore</span></code>下，则aicpu的so文件需要放到<code class="docutils literal notranslate"><span class="pre">/home/conda/envs/aicpu/lib/python3.7/site-packages/mindspore/lib/</span></code>目录下。</p></li>
<li><p>“cust_aicpu”的值为字符串，用算子动态链接库的名字去除<code class="docutils literal notranslate"><span class="pre">lib</span></code>前缀与<code class="docutils literal notranslate"><span class="pre">.so</span></code>后缀表示，如<code class="docutils literal notranslate"><span class="pre">libmindspore_aicpu_kernels.so</span></code>则设为<code class="docutils literal notranslate"><span class="pre">&quot;mindspore_aicpu_kernels&quot;</span></code>即可。</p></li>
</ul>
</div></blockquote>
<p>下面以test_dropout_aicpu.py为例介绍aicpu类型的自定义算子开发流程，其中自定义算子实现了dropout的功能，并且编译好的算子动态链接库，我们命名为libmindspore_aicpu_kernels.so，并已将该动态链接库放至mindspore根目录的lib下。</p>
<p>test_dropout_aicpu.py内容：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">CustomRegOp</span><span class="p">,</span> <span class="n">DataType</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>

<span class="c1"># 算子实现，注册算子信息</span>
<span class="n">acos_op_info</span> <span class="o">=</span> <span class="n">CustomRegOp</span><span class="p">(</span><span class="s2">&quot;Abs&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">fusion_type</span><span class="p">(</span><span class="s2">&quot;OPAQUE&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;required&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="s2">&quot;required&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">attr</span><span class="p">(</span><span class="s2">&quot;cust_aicpu&quot;</span><span class="p">,</span> <span class="s2">&quot;required&quot;</span><span class="p">,</span> <span class="s2">&quot;str&quot;</span><span class="p">,</span> <span class="s2">&quot;mindspore_aicpu_kernels&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">dtype_format</span><span class="p">(</span><span class="n">DataType</span><span class="o">.</span><span class="n">F16_Default</span><span class="p">,</span> <span class="n">DataType</span><span class="o">.</span><span class="n">F16_Default</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">dtype_format</span><span class="p">(</span><span class="n">DataType</span><span class="o">.</span><span class="n">F32_Default</span><span class="p">,</span> <span class="n">DataType</span><span class="o">.</span><span class="n">F32_Default</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">dtype_format</span><span class="p">(</span><span class="n">DataType</span><span class="o">.</span><span class="n">F64_Default</span><span class="p">,</span> <span class="n">DataType</span><span class="o">.</span><span class="n">F64_Default</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">target</span><span class="p">(</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">get_op_info</span><span class="p">()</span>


<span class="c1"># 定义自定义算子网络</span>
<span class="k">class</span> <span class="nc">NetAbs</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NetAbs</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Custom</span><span class="p">(</span><span class="s2">&quot;acos_aicpu&quot;</span><span class="p">,</span> <span class="n">out_shape</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">cust_attr</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                             <span class="n">out_dtype</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">cust_attr</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">func_type</span><span class="o">=</span><span class="s2">&quot;aicpu&quot;</span><span class="p">,</span>
                             <span class="n">reg_info</span><span class="o">=</span><span class="n">acos_op_info</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cust_aicpu_so_path</span> <span class="o">=</span> <span class="s2">&quot;mindspore_aicpu_kernels&quot;</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cust_aicpu_so_path</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># 定义aicpu类型的自定义算子</span>
    <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">abs_nn</span> <span class="o">=</span> <span class="n">NetAbs</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">abs_nn</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output shape: &quot;</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>本例中，有如下几点需要说明：</p>
<ul class="simple">
<li><p>可以用多种方式指定<code class="docutils literal notranslate"><span class="pre">Custom</span></code>原语的<code class="docutils literal notranslate"><span class="pre">out_shape</span></code>和<code class="docutils literal notranslate"><span class="pre">out_dtype</span></code>参数，可以给定类型，也可以用Python lambda函数等设置。本例中lambda函数表明输出的两个shape与输入相同，第一个输出的数据类型和输入张量的信息相同，第二个输出的数据类型为bool类型。</p></li>
<li><p>通过<code class="docutils literal notranslate"><span class="pre">CustomRegOp</span></code>生成算子信息，并通过<code class="docutils literal notranslate"><span class="pre">Custom</span></code>的<code class="docutils literal notranslate"><span class="pre">reg_info</span></code>接口传入。</p></li>
</ul>
<p>执行用例：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>test_dropout_aicpu.py
</pre></div>
</div>
<p>执行结果（由于dropout算子具有随机性，多次运行结果存在差异）：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>output shape:  (1, 1, 2, 3)
</pre></div>
</div>
</section>
<section id="aot类型的自定义算子开发">
<h3>aot类型的自定义算子开发<a class="headerlink" href="#aot类型的自定义算子开发" title="永久链接至标题"></a></h3>
<p>aot类型的自定义算子采用AOT编译方式，要求网络开发者基于特定接口，手写算子实现函数对应的源码文件，并提前将源码文件编译为动态链接库，然后在网络运行时框架会自动调用执行动态链接库中的函数。在算子实现的开发语言方面，GPU平台支持CUDA，CPU平台支持C和C++。源码文件中的算子实现函数的接口规范如下：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">func_name</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">nparam</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">ndims</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="o">**</span><span class="n">shapes</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">dtypes</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">extra</span><span class="p">);</span>
</pre></div>
</div>
<p>其中，函数名<code class="docutils literal notranslate"><span class="pre">func_name</span></code>可替换成任意有效函数名。返回值为int类型，约定0表示正常退出，非0表示发生异常。参数列表的含义如下：</p>
<ul class="simple">
<li><p>nparam (int): 输入输出总数。比如算子有2个输入，1个输出，则nparam的值为3。</p></li>
<li><p>params (void **): 输入输出指针数组。比如算子有2个输入，1个输出，params[0]指向第一个输入数据，params[1]指向第二个输入数据，params[2]指向输出数据。</p></li>
<li><p>ndims (int *): 输入输出shape维度数组。比如params[i]是个shape[1024, 1024]的张量，则ndims[i]的值为2。</p></li>
<li><p>shapes (int64_t **): 输入输出shape数组。比如params[i]是个shape[1024, 1024]的张量，则shapes[i][0]的值为1024，shapes[i][1]的值为1024。</p></li>
<li><p>dtypes (const char **): 输入输出数据类型数组。dtypes里的元素取值可为：”float32”, “float16”, “float”, “float64”, “int”, “int8”, “int16”, “int32”, “int64”, “uint”, “uint8”, “uint16”, “uint32”, “uint64”, “bool”。</p></li>
<li><p>stream (void *): CUDA流指针，仅定义GPU算子实现时需要。</p></li>
<li><p>extra (void *): 用于后续扩展。</p></li>
</ul>
<p>算子输出shape和数据类型推理可以通过定义Python函数实现，描述算子输出shape和数据类型的推导逻辑。</p>
<p>若自定义算子只支持特定的输入输出数据类型，则需要定义算子信息，算子信息生成方式请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/operation/op_custom_adv.html#%E7%AE%97%E5%AD%90%E4%BF%A1%E6%81%AF%E6%B3%A8%E5%86%8C">算子信息注册</a>。</p>
<p>下面通过例子介绍GPU平台和CPU平台上aot类型的自定义算子开发流程，其中自定义算子实现两个输入张量相加的功能。</p>
<section id="gpu示例">
<h4>GPU示例<a class="headerlink" href="#gpu示例" title="永久链接至标题"></a></h4>
<p>使用CUDA语言，编写算子实现的源码文件add.cu：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#define THREADS 1024</span>
<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">CustomAddKernel</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">input1</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">input2</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">THREADS</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input1</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">input2</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>

<span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">CustomAdd</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">nparam</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">ndims</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="o">**</span><span class="n">shapes</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">dtypes</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">stream</span><span class="p">,</span>
<span class="w">                         </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">extra</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">custream</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="n">cudaStream_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">nparam</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">input1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">input2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">ndims</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">size</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="n">shapes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">THREADS</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nparam</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">strcmp</span><span class="p">(</span><span class="n">dtypes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="s">&quot;float32&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">CustomAddKernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">n</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">THREADS</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">custream</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">input1</span><span class="p">),</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">input2</span><span class="p">),</span>
<span class="w">                                                   </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">output</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>将add.cu编译成动态库add.so：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>nvcc<span class="w"> </span>--shared<span class="w"> </span>-Xcompiler<span class="w"> </span>-fPIC<span class="w"> </span>-o<span class="w"> </span>add.so<span class="w"> </span>add.cu
</pre></div>
</div>
<p>编写测试用例test_custom_aot.py：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;GPU&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># 定义aot类型的自定义算子</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Custom</span><span class="p">(</span><span class="s2">&quot;./add.so:CustomAdd&quot;</span><span class="p">,</span> <span class="n">out_shape</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">out_dtype</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">func_type</span><span class="o">=</span><span class="s2">&quot;aot&quot;</span><span class="p">)</span>

    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x0</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x1</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>本例中，有如下几点需要说明：</p>
<ul class="simple">
<li><p>本例中需要将test_custom_aot.py和add.so放置在同一目录下，若add.so在其他目录，则需要将<code class="docutils literal notranslate"><span class="pre">Custom</span></code>第一个参数里路径修改为add.so的绝对路径。</p></li>
<li><p>用Python lambda函数定义输出shape和数据类型推理函数，并分别传给<code class="docutils literal notranslate"><span class="pre">Custom</span></code>原语的<code class="docutils literal notranslate"><span class="pre">out_shape</span></code>和<code class="docutils literal notranslate"><span class="pre">out_dtype</span></code>参数。本例中lambda函数表明输出shape和数据类型和第一个输入张量的信息相同。</p></li>
<li><p>未注册算子信息，所以自定义算子的算子信息将会从算子输入中推理。</p></li>
</ul>
<p>执行用例：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>test_custom_aot.py
</pre></div>
</div>
<p>执行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[2. 2.]
 [4. 4.]]
</pre></div>
</div>
</section>
<section id="cpu示例">
<h4>CPU示例<a class="headerlink" href="#cpu示例" title="永久链接至标题"></a></h4>
<p>使用C或者C++语言，编写算子实现的源码文件add.cc：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;string.h&gt;</span>
<span class="k">using</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">decltype</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
<span class="k">using</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">decltype</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">long</span><span class="p">));</span>

<span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">CustomAdd</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">nparam</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">ndims</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="o">**</span><span class="n">shapes</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">dtypes</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">extra</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">nparam</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">input1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">input2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nparam</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">size</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="n">shapes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nparam</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">strcmp</span><span class="p">(</span><span class="n">dtypes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="s">&quot;float32&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">size</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">input2</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>将add.cc编译成动态库add.so：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>g++<span class="w"> </span>--shared<span class="w"> </span>-fPIC<span class="w"> </span>-o<span class="w"> </span>add.so<span class="w"> </span>add.cc
</pre></div>
</div>
<p>编写测试用例test_custom_aot.py：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># 定义aot类型的自定义算子</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Custom</span><span class="p">(</span><span class="s2">&quot;./add.so:CustomAdd&quot;</span><span class="p">,</span> <span class="n">out_shape</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">out_dtype</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">func_type</span><span class="o">=</span><span class="s2">&quot;aot&quot;</span><span class="p">)</span>

    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x0</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x1</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>本例中，有如下几点需要说明：</p>
<ul class="simple">
<li><p>本例中需要将test_custom_aot.py和add.so放置在同一目录下，若add.so在其他目录，则需要将<code class="docutils literal notranslate"><span class="pre">Custom</span></code>第一个参数里路径修改为add.so的绝对路径。</p></li>
<li><p>用Python lambda函数定义输出shape和数据类型推理函数，并分别传给<code class="docutils literal notranslate"><span class="pre">Custom</span></code>原语的<code class="docutils literal notranslate"><span class="pre">out_shape</span></code>和<code class="docutils literal notranslate"><span class="pre">out_dtype</span></code>参数。本例中lambda函数表明输出shape和数据类型和第一个输入张量的信息相同。</p></li>
<li><p>未注册算子信息，所以自定义算子的算子信息将会从算子输入中推理。</p></li>
</ul>
<p>执行用例：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>test_custom_aot.py
</pre></div>
</div>
<p>执行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[2. 2.]
 [4. 4.]]
</pre></div>
</div>
</section>
</section>
<section id="pyfunc类型的自定义算子开发">
<h3>pyfunc类型的自定义算子开发<a class="headerlink" href="#pyfunc类型的自定义算子开发" title="永久链接至标题"></a></h3>
<p>pyfunc类型的自定义算子使用原生Python语法定义算子实现函数，描述算子内部计算逻辑的实现。网络运行时框架会自动调用此函数。</p>
<p>算子输出shape和数据类型推理可以通过定义Python函数实现，描述算子输出shape和数据类型的推导逻辑。</p>
<p>若自定义算子只支持特定的输入输出数据类型，则需要定义算子信息，算子信息生成方式请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/operation/op_custom_adv.html#%E7%AE%97%E5%AD%90%E4%BF%A1%E6%81%AF%E6%B3%A8%E5%86%8C">算子信息注册</a>。</p>
<p>下面以test_custom_pyfunc.py为例介绍pyfunc类型的自定义算子开发流程，其中自定义算子实现两个输入张量相加的功能。</p>
<p>test_custom_pyfunc.py内容：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># 定义pyfunc类型的自定义算子</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Custom</span><span class="p">(</span><span class="n">add</span><span class="p">,</span> <span class="n">out_shape</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">out_dtype</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">func_type</span><span class="o">=</span><span class="s2">&quot;pyfunc&quot;</span><span class="p">)</span>

    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x0</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x1</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>本例中，有如下几点需要说明：</p>
<ul class="simple">
<li><p>用Python lambda函数定义输出shape和数据类型推理函数，并分别传给<code class="docutils literal notranslate"><span class="pre">Custom</span></code>原语的<code class="docutils literal notranslate"><span class="pre">out_shape</span></code>和<code class="docutils literal notranslate"><span class="pre">out_dtype</span></code>参数。本例中lambda函数表明输出shape和数据类型和第一个输入张量的信息相同。</p></li>
<li><p>未注册算子信息，所以自定义算子的算子信息将会从算子输入中推理。</p></li>
</ul>
<p>执行用例：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>test_custom_pyfunc.py
</pre></div>
</div>
<p>执行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[2. 2.]
 [4. 4.]]
</pre></div>
</div>
</section>
<section id="julia类型的自定义算子开发">
<h3>julia类型的自定义算子开发<a class="headerlink" href="#julia类型的自定义算子开发" title="永久链接至标题"></a></h3>
<p>julia类型的自定义算子使用Julia语法定义算子实现函数，描述算子内部计算逻辑的实现。网络运行时框架会自动调用执行相应的Julia函数。</p>
<p>算子输出shape和数据类型推导可以通过定义Python函数实现，描述算子输出shape和数据类型的推导逻辑。</p>
<p>若自定义算子只支持特定的输入输出数据类型，则需要定义算子信息，算子信息生成方式请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/operation/op_custom_adv.html#%E7%AE%97%E5%AD%90%E4%BF%A1%E6%81%AF%E6%B3%A8%E5%86%8C">算子信息注册</a>。</p>
<p>下面以两个输入张量相加为例，介绍julia类型的自定义算子开发流程:</p>
<p>首先，用户需要通过单独文件实现Julia函数，如(add.jl)：</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># add.jl</span>
<span class="k">module</span><span class="w"> </span><span class="n">Add</span>
<span class="c"># inputs: x, y, output: z, output should use .= to inplace assign</span>
<span class="k">function</span><span class="w"> </span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="p">)</span>
<span class="w">    </span><span class="n">z</span><span class="w"> </span><span class="o">.=</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y</span>
<span class="k">end</span>
<span class="k">end</span>
</pre></div>
</div>
<p>其次，在网络脚本中通过自定义算子方式引用上面所写的Julia函数，以test_custom_julia.py为例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># 定义julia类型的自定义算子</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Custom</span><span class="p">(</span><span class="s2">&quot;./add.jl:Add:add&quot;</span><span class="p">,</span> <span class="n">out_shape</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">out_dtype</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">func_type</span><span class="o">=</span><span class="s2">&quot;julia&quot;</span><span class="p">)</span>
    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x0</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x1</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>本例中，有如下几点需要说明：</p>
<ul class="simple">
<li><p>用Python lambda函数定义输出shape和数据类型推理函数，并分别传给<code class="docutils literal notranslate"><span class="pre">Custom</span></code>原语的<code class="docutils literal notranslate"><span class="pre">out_shape</span></code>和<code class="docutils literal notranslate"><span class="pre">out_dtype</span></code>参数。本例中lambda函数表明输出shape和数据类型和第一个输入张量的信息相同。</p></li>
<li><p>未注册算子信息，所以自定义算子的算子信息将会从算子输入中推理。</p></li>
</ul>
<p>执行用例：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>test_custom_julia.py
</pre></div>
</div>
<p>执行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[2. 2.]
 [4. 4.]]
</pre></div>
</div>
<p>注意事项：</p>
<ol class="arabic">
<li><p>用户需确保下载正确版本的Julia，即version&gt;=1.6.0。</p></li>
<li><p>由于运行时调用的Julia C api是从<code class="docutils literal notranslate"><span class="pre">libjulia.so</span></code>中获取的，因此需要用户设置<code class="docutils literal notranslate"><span class="pre">julia/lib</span></code>到<code class="docutils literal notranslate"><span class="pre">LD_LIBRARY_PATH</span></code>，以julia-1.6.5为例:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># download julia-1.6.5</span>
wget<span class="w"> </span>https://julialang-s3.julialang.org/bin/linux/x64/1.6/julia-1.6.5-linux-x86_64.tar.gz
<span class="c1"># extract file</span>
tar<span class="w"> </span>xvf<span class="w"> </span>julia-1.6.5-linux-x86_64.tar.gz
<span class="c1"># if $JULIA_DIR not exist</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$PWD</span>/julia-1.6.5/lib:<span class="nv">$LD_LIBRARY_PATH</span>
<span class="c1"># else</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$JULIA_DIR</span>/lib:<span class="nv">$LD_LIBRARY_PATH</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">Custom</span></code> 第一个入参指定用户书写的Julia函数需按照<code class="docutils literal notranslate"><span class="pre">file_name:module_name:func_name</span></code>格式指定，<code class="docutils literal notranslate"><span class="pre">file_name</span></code>需包含文件路径，建议使用绝对路径。</p></li>
<li><p>Julia代码文件需包含<code class="docutils literal notranslate"><span class="pre">module</span></code>, <code class="docutils literal notranslate"><span class="pre">module</span></code>内包含<code class="docutils literal notranslate"><span class="pre">function</span></code>，且<code class="docutils literal notranslate"><span class="pre">module</span></code>/<code class="docutils literal notranslate"><span class="pre">function</span></code>都以<code class="docutils literal notranslate"><span class="pre">end</span></code>结束。</p></li>
<li><p>Julia函数的输入输出顺序需与算子的输入输出顺序一致。</p></li>
<li><p>Julia函数的最终输出，即kernel output的赋值需要使用<code class="docutils literal notranslate"><span class="pre">.=</span></code>，否则结果无法写入内存。</p></li>
<li><p>Julia代码支持<a class="reference external" href="https://docs.julialang.org/en/v1/">Julia</a>的常用语法，用户需自行保证语法正确，函数可正确执行。</p></li>
<li><p>用户想在Julia文件内使用Julia的第三方软件包，需自行下载对应软件以确保能正确调用，可以通过 <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">pkg;</span> <span class="pre">pkg.add(&quot;somepkg&quot;)</span></code>进行安装。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">julia</span> <span class="pre">array</span></code>在内存上是<code class="docutils literal notranslate"><span class="pre">column</span> <span class="pre">major</span></code>排列的，而<code class="docutils literal notranslate"><span class="pre">numpy</span> <span class="pre">array</span></code>是<code class="docutils literal notranslate"><span class="pre">row</span> <span class="pre">major</span></code>排列的，如果Julia和numpy做比较，非elemwise计算需考虑内存排布。在Julia函数中，可以通过如下代码示例进行<code class="docutils literal notranslate"><span class="pre">numpy</span> <span class="pre">array</span></code>和<code class="docutils literal notranslate"><span class="pre">julia</span> <span class="pre">array</span></code>的相互转换:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">function</span><span class="w"> </span><span class="n">change_input_to_row_major</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">permutedims</span><span class="p">(</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">reverse</span><span class="p">(</span><span class="n">size</span><span class="p">(</span><span class="n">x</span><span class="p">))),</span><span class="w"> </span><span class="n">length</span><span class="p">(</span><span class="n">size</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">:-</span><span class="mi">1</span><span class="o">:</span><span class="mi">1</span><span class="p">)</span>
<span class="k">end</span>

<span class="k">function</span><span class="w"> </span><span class="n">change_output_to_row_major</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">reshape</span><span class="p">(</span><span class="n">permutedims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="p">(</span><span class="n">size</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">:-</span><span class="mi">1</span><span class="o">:</span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="k">end</span>
</pre></div>
</div>
<p>以矩阵乘为例：</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># julia array is column-major, numpy array is row-major</span>
<span class="c"># user should change julia or numpy&#39;s layout to keep same behavior</span>
<span class="cm">#= EXAMPLE</span>
<span class="cm">A[2,3]               B[3,4]               C[2,4]</span>
<span class="cm">NUMPY:</span>
<span class="cm">[[1, 2, 3]       [[1, 2, 3, 4]         [[38, 44, 50,  56]</span>
<span class="cm"> [4, 5, 6]]       [5, 6, 7, 8]          [83, 98, 113,128]]</span>
<span class="cm">                  [9,10,11,12]]</span>
<span class="cm">JULIA:</span>
<span class="cm">change_input_to_row_major:</span>
<span class="cm">1.inputs read numpy data from memory:</span>
<span class="cm">[[1, 3, 5]       [[1, 4, 7,10]</span>
<span class="cm"> [2, 4, 6]]       [2, 5, 8,11]</span>
<span class="cm">                  [3, 6, 9,12]]</span>
<span class="cm">2.inputs after reshape(reverse(shape)):</span>
<span class="cm">[[1, 4]          [[1, 5, 9]</span>
<span class="cm"> [2, 5]           [2, 6,10]</span>
<span class="cm"> [3, 6]]          [3, 7,11]</span>
<span class="cm">                  [4, 8,12]]</span>
<span class="cm">3.inputs after transpose/permutedims:</span>
<span class="cm">[[1, 2, 3]       [[1, 2, 3, 4]         [[38, 44, 50,  56]</span>
<span class="cm"> [4, 5, 6]]       [5, 6, 7, 8]          [83, 98, 113,128]]</span>
<span class="cm">                  [9,10,11,12]]</span>
<span class="cm">change_output_to_row_major:</span>
<span class="cm">1.output after transpose/permutedims:</span>
<span class="cm">                                       [[38, 83]</span>
<span class="cm">                                        [44, 98]</span>
<span class="cm">                                        [50,113]</span>
<span class="cm">                                        [56,128]</span>
<span class="cm">2.output after reshape:</span>
<span class="cm">                                       [[38, 50, 83, 113]</span>
<span class="cm">                                        [44, 56, 98, 128]]</span>
<span class="cm">3.output read numpy data from memory:</span>
<span class="cm">                                       [[38, 44, 50,  56]</span>
<span class="cm">                                        [83, 98,113, 128]]</span>
<span class="cm">=#</span>
<span class="k">function</span><span class="w"> </span><span class="n">foo!</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="p">)</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">change_input_to_row_major</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="w">    </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">change_input_to_row_major</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="w">    </span><span class="n">z</span><span class="w"> </span><span class="o">.=</span><span class="w"> </span><span class="n">gemm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="p">)</span>
<span class="w">    </span><span class="n">z</span><span class="w"> </span><span class="o">.=</span><span class="w"> </span><span class="n">change_output_to_row_major</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="k">end</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="akg类型的自定义算子开发">
<h3>akg类型的自定义算子开发<a class="headerlink" href="#akg类型的自定义算子开发" title="永久链接至标题"></a></h3>
<p>akg类型的自定义算子使用<a class="reference external" href="https://gitee.com/mindspore/akg">MindSpore AKG</a>算子DSL，描述算子内部计算逻辑的实现。MindSpore AKG是基于TVM（Tensor Virtual Machine）和Polyhedral技术的算子开发和编译框架，支持Hybrid、IR builder和TVM compute等多种类型的算子DSL。</p>
<p>算子输出shape和数据类型推理可以通过定义Python函数实现，描述算子输出shape和数据类型的推导逻辑。</p>
<p>若算子包含属性或者只支持特定的输入输出数据类型或数据格式，则需要注册算子信息，算子信息生成方式请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/operation/op_custom_adv.html#%E7%AE%97%E5%AD%90%E4%BF%A1%E6%81%AF%E6%B3%A8%E5%86%8C">算子信息注册</a>。若未注册算子信息，在后端做算子选择和映射的时候，将会从当前算子的输入中推导算子信息。</p>
<p>下面以test_custom_akg.py为例介绍akg类型的自定义算子开发流程，其中自定义算子实现两个输入张量相加的功能。</p>
<p>test_custom_akg.py内容：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;GPU&quot;</span><span class="p">)</span>

<span class="c1"># 算子实现，Hybrid DSL</span>
<span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i0</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">i1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">c</span><span class="p">[</span><span class="n">i0</span><span class="p">,</span> <span class="n">i1</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i0</span><span class="p">,</span> <span class="n">i1</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i0</span><span class="p">,</span> <span class="n">i1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">c</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># 定义akg类型的自定义算子</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Custom</span><span class="p">(</span><span class="n">add</span><span class="p">,</span> <span class="n">out_shape</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">out_dtype</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">func_type</span><span class="o">=</span><span class="s2">&quot;akg&quot;</span><span class="p">)</span>

    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x0</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x1</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>本例中，有如下几点需要说明：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">set_context(device_target=&quot;GPU&quot;)</span></code>表示算子运行在GPU平台，若要运行在Ascend平台，请编译Ascend版本的MindSpore，并将device_target的值设置为”Ascend”。</p></li>
<li><p>用Python lambda函数定义输出shape和数据类型推理函数，并分别传给<code class="docutils literal notranslate"><span class="pre">Custom</span></code>原语的<code class="docutils literal notranslate"><span class="pre">out_shape</span></code>和<code class="docutils literal notranslate"><span class="pre">out_dtype</span></code>参数。本例中lambda函数表明输出shape和数据类型和第一个输入张量的信息相同。</p></li>
<li><p>未注册算子信息，所以自定义算子的算子信息将会从算子输入中推理。</p></li>
</ul>
<p>执行用例：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>test_custom_akg.py
</pre></div>
</div>
<p>执行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[2. 2.]
 [4. 4.]]
</pre></div>
</div>
</section>
</section>
<section id="开发用例">
<h2>开发用例<a class="headerlink" href="#开发用例" title="永久链接至标题"></a></h2>
<p>开发前，我们导入 MindSpore 的相关依赖。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">kernel</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Cell</span>

<span class="c1">#############################################</span>
<span class="c1"># 这里选用你使用的平台类型：CPU, GPU 或者 Ascend #</span>
<span class="c1">#############################################</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;GPU&quot;</span><span class="p">)</span>
<span class="c1"># 选用CPU使用下面一行</span>
<span class="c1"># ms.set_context(mode=ms.GRAPH_MODE, device_target=&quot;CPU&quot;)</span>
<span class="c1"># 选用Ascend使用下面一行</span>
<span class="c1"># ms.set_context(mode=ms.GRAPH_MODE, device_target=&quot;CPU&quot;)</span>
</pre></div>
</div>
<section id="用例一-基于pyfunc模式定义sin算子">
<h3>用例一：基于pyfunc模式定义sin算子<a class="headerlink" href="#用例一-基于pyfunc模式定义sin算子" title="永久链接至标题"></a></h3>
<p>首先，我们写一个基于numpy的计算正弦函数的Python原生函数。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sin_by_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>然后我们要定义两个函数，一个是张量形状的推导函数（infer_shape），另一个是张量数据类型的推导函数（infer_dtype）。这里要注意：</p>
<ul class="simple">
<li><p>张量形状的推导函数是输入张量的形状；</p></li>
<li><p>张量数据类型的推导函数是输入张量的数据类型。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">infer_shape</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>

    <span class="c1">#    1. 这里的输入x是算子输入张量的形状</span>
    <span class="c1">#    2. sin函数是逐元素计算，输入的形状和输出的一样</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">infer_dtype</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>

    <span class="c1">#    1. 这里的输入x是算子输入张量的数据类型</span>
    <span class="c1">#    2. sin函数输入的数据类型和输出的一样</span>
    <span class="k">return</span> <span class="n">x</span>

</pre></div>
</div>
<p>下面我们用上面的函数自定义一个算子，其输入包括</p>
<ul class="simple">
<li><p>func：自定义算子的函数表达，这里我们用<code class="docutils literal notranslate"><span class="pre">sin_by_numpy</span></code>函数；</p></li>
<li><p>out_shape: 输出形状的推导函数，这里我们用<code class="docutils literal notranslate"><span class="pre">infer_shape</span></code>函数；</p></li>
<li><p>out_dtype: 输出数据类型的推导函数，这里我们用<code class="docutils literal notranslate"><span class="pre">infer_dtype</span></code>函数；</p></li>
<li><p>func_type: 自定义算子类型，这里我们用<code class="docutils literal notranslate"><span class="pre">&quot;pyfunc&quot;</span></code>。</p></li>
</ul>
<p>然后我们调用算子计算结果。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sin_by_numpy_op</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Custom</span><span class="p">(</span><span class="n">func</span> <span class="o">=</span> <span class="n">sin_by_numpy</span><span class="p">,</span>     <span class="c1"># 这里填入自定义算子的函数表达</span>
                             <span class="n">out_shape</span> <span class="o">=</span> <span class="n">infer_shape</span><span class="p">,</span> <span class="c1"># 这里填入输出形状的推导函数</span>
                             <span class="n">out_dtype</span> <span class="o">=</span> <span class="n">infer_dtype</span><span class="p">,</span> <span class="c1"># 这里填入输出数据类型的推导函数</span>
                             <span class="n">func_type</span> <span class="o">=</span> <span class="s2">&quot;pyfunc&quot;</span>     <span class="c1"># 这里填入自定义算子类型</span>
                            <span class="p">)</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">result_cus</span> <span class="o">=</span> <span class="n">sin_by_numpy_op</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result_cus</span><span class="p">)</span>
</pre></div>
</div>
<p>我们可以得到结果为，即上面输入对应的sin值。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[0.         0.84147096 0.19866933 0.29552022 0.38941833]
</pre></div>
</div>
</section>
<section id="用例二-利用hybrid类型的自定义算子实现三维张量的加法函数">
<h3>用例二：利用hybrid类型的自定义算子实现三维张量的加法函数<a class="headerlink" href="#用例二-利用hybrid类型的自定义算子实现三维张量的加法函数" title="永久链接至标题"></a></h3>
<p>首先，我们写一个基于MindSpore Hybrid DSL书写一个计算三维张量相加的函数。</p>
<p>注意：</p>
<ul class="simple">
<li><p>对于输出张量使用 <code class="docutils literal notranslate"><span class="pre">output_tensor</span></code>，用法为：<code class="docutils literal notranslate"><span class="pre">output_tensor(shape,</span> <span class="pre">dtype)</span></code>；</p></li>
<li><p>所有的计算需要基于标量计算，如果是Tensor对象，那么需要写清楚所有index；</p></li>
<li><p>基本循环的写法和Python一样，循环维度的表达可以使用 <code class="docutils literal notranslate"><span class="pre">range</span></code>。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@kernel</span>
<span class="k">def</span> <span class="nf">tensor_add_3d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="c1">#    1. 你需要一个三层循环</span>
    <span class="c1">#    2. 第i层循环的上界可以用x.shape[i]获得</span>
    <span class="c1">#    3. 你需要基于每个元素表达计算，例如加法为 x[i, j, k] + y[i, j, k]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]):</span>
                <span class="n">result</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">result</span>
</pre></div>
</div>
<p>下面我们用上面的函数自定义一个算子。</p>
<p>注意到基于<code class="docutils literal notranslate"><span class="pre">kernel</span></code>的<code class="docutils literal notranslate"><span class="pre">hybrid</span></code>函数时，我们可以使用自动的形状和数据类型推导。</p>
<p>因此我们只用给一个<code class="docutils literal notranslate"><span class="pre">func</span></code>输入（<code class="docutils literal notranslate"><span class="pre">func_type</span></code>的默认值为<code class="docutils literal notranslate"><span class="pre">&quot;hybrid&quot;</span></code>）。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tensor_add_3d_op</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Custom</span><span class="p">(</span><span class="n">func</span> <span class="o">=</span> <span class="n">tensor_add_3d</span><span class="p">)</span>
<span class="n">input_tensor_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">input_tensor_y</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">result_cus</span> <span class="o">=</span> <span class="n">tensor_add_3d_op</span><span class="p">(</span><span class="n">input_tensor_x</span><span class="p">,</span> <span class="n">input_tensor_y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result_cus</span><span class="p">)</span>
</pre></div>
</div>
<p>同时我们可以使用<code class="docutils literal notranslate"><span class="pre">pyfunc</span></code>模式验证上面定义的正确性。</p>
<p>这里我们不需要重新定义算子计算函数<code class="docutils literal notranslate"><span class="pre">tensor_add_3d</span></code>，直接将<code class="docutils literal notranslate"><span class="pre">func_type</span></code>改为<code class="docutils literal notranslate"><span class="pre">&quot;pyfunc&quot;</span></code>即可。</p>
<p>注意<code class="docutils literal notranslate"><span class="pre">pyfunc</span></code>模式时我们需要手写类型推导函数。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">infer_shape_py</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">infer_dtype_py</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="n">tensor_add_3d_py_func</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Custom</span><span class="p">(</span><span class="n">func</span> <span class="o">=</span> <span class="n">tensor_add_3d</span><span class="p">,</span>
                                   <span class="n">out_shape</span> <span class="o">=</span> <span class="n">infer_shape_py</span><span class="p">,</span>
                                   <span class="n">out_dtype</span> <span class="o">=</span> <span class="n">infer_dtype_py</span><span class="p">,</span>
                                   <span class="n">func_type</span> <span class="o">=</span> <span class="s2">&quot;pyfunc&quot;</span><span class="p">)</span>

<span class="n">result_pyfunc</span> <span class="o">=</span> <span class="n">tensor_add_3d_py_func</span><span class="p">(</span><span class="n">input_tensor_x</span><span class="p">,</span> <span class="n">input_tensor_y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result_pyfunc</span><span class="p">)</span>
</pre></div>
</div>
<p>我们可以得到如下结果，即两个Tensor的和。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span> [[[3. 3. 3. 3.]
  [3. 3. 3. 3.]
  [3. 3. 3. 3.]]

 [[3. 3. 3. 3.]
  [3. 3. 3. 3.]
  [3. 3. 3. 3.]]]
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../parallel/memory_offload.html" class="btn btn-neutral float-left" title="异构存储" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="ms_kernel.html" class="btn btn-neutral float-right" title="MindSpore Hybrid 语法规范" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2022, MindSpore.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>