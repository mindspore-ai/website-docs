<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>分布式集合通信原语 &mdash; MindSpore master documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="分布式案例" href="distributed_case.html" />
    <link rel="prev" title="分布式并行总览" href="introduction.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">数据处理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dataset/augment.html">自动数据增强</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/eager.html">轻量化数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/cache.html">单节点数据缓存</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/optimize.html">数据处理性能优化</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">图编译</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../network/control_flow.html">流程控制语句</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/op_overload.html">静态图网络编译性能优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/custom_cell_reverse.html">自定义Cell的反向传播函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/ms_class.html">调用自定义类</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/constexpr.html">网络内构造常量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/dependency_control.html">依赖控制</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型训练优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../others/mixed_precision.html">混合精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="../others/gradient_accumulation.html">梯度累积算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../others/adaptive_summation.html">自适应梯度求和算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../others/dimention_reduce_training.html">降维训练算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../others/thor.html">二阶优化</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">自定义算子</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom.html">自定义算子（基于Custom表达）</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../infer/inference.html">模型推理总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/cpu_gpu_mindir.html">GPU推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/ascend_910_mindir.html">Ascend 910 AI处理器上推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/ascend_310_mindir.html">Ascend 310 AI处理器上使用MindIR模型进行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/ascend_310_air.html">Ascend 310 AI处理器上使用AIR模型进行推理</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">调试调优</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../debug/function_debug.html">功能调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/performance_optimization.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference external" href="https://mindspore.cn/mindinsight/docs/zh-CN/r1.10/accuracy_problem_preliminary_location.html">精度调优↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">分布式并行</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">分布式并行总览</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">分布式集合通信原语</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_case.html">分布式案例</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_inference.html">分布式推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_load.html">保存和加载模型（HyBrid Parallel模式）</a></li>
<li class="toctree-l1"><a class="reference internal" href="fault_recover.html">分布式故障恢复</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_dimensional.html">多维度混合并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="other_features.html">其他特性</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">环境变量</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../env/env_var_list.html">环境变量</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>分布式集合通信原语</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/parallel/communicate_ops.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="分布式集合通信原语">
<h1>分布式集合通信原语<a class="headerlink" href="#分布式集合通信原语" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.10/tutorials/experts/source_zh_cn/parallel/communicate_ops.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/resource/_static/logo_source.png"></a></p>
<p>在分布式训练中涉及例如<code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>、<code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code>、<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>和<code class="docutils literal notranslate"><span class="pre">Broadcast</span></code>等通信操作进行数据传输，我们将在下述的章节分别阐述其含义和示例代码。</p>
<p>下述每个章节中给出了使用4张GPU进行不同通信操作的示例。示例中的输出来自于0号卡<code class="docutils literal notranslate"><span class="pre">rank0</span></code>程序的结果。用户需要将下述每个章节代码另存为communication.py。因为涉及到多卡程序，用户需要通过<code class="docutils literal notranslate"><span class="pre">mpirun</span></code>命令去启动communication.py。其中<code class="docutils literal notranslate"><span class="pre">mpirun</span></code>命令需要安装OpenMPI以及NCCL，对应的安装请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r1.10/parallel/train_gpu.html">此处</a>。准备好communication.py后，在命令行中输入如下启动命令，即可启动多卡程序：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mpirun<span class="w"> </span>-output-filename<span class="w"> </span>log<span class="w"> </span>-merge-stderr-to-stdout<span class="w"> </span>-np<span class="w"> </span><span class="m">4</span><span class="w"> </span>python<span class="w"> </span>communication.py
</pre></div>
</div>
<p>上述代码中的<code class="docutils literal notranslate"><span class="pre">-np</span></code>表示将启动4个进程任务，分别占用0，1，2，3号卡，并且将输出日志保存在<code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>目录下面。用户可以在此查看程序的输出结果。<code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">communication.py</span></code>表示启动脚本。</p>
<section id="allreduce">
<h2>AllReduce<a class="headerlink" href="#allreduce" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="../_images/allreduce.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>操作会将每卡中<code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>算子的输入Tensor进行求和操作，最终每卡的<code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>算子输出是相同的数值。例如上图所示，每张卡AllReduce算子输入分别为<code class="docutils literal notranslate"><span class="pre">0,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">3</span></code>。经过<code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>之后，每张卡输出的结果为所有卡输入之和为6(0+1+2+3)。</p>
<p>示例代码如下：我们根据rank号(每张卡所属通信编号)初始化每个进程中<code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>算子输入的数值，例如卡0，我们申请了一个1x1大小，数值为0的输入。然后调用<code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>算子，在通信域为<code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code>的卡(所有卡的通信范围即nccl_world_group)中进行通信，并且打印输出结果。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_reduce_sum</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">AllReduce</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s2">&quot;nccl_world_group&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">value</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">value</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>其中0卡的运行结果如下，输出日志路径为<code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[6.]]
</pre></div>
</div>
</section>
<section id="allgather">
<h2>AllGather<a class="headerlink" href="#allgather" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="../_images/allgather.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">AllGather</span></code>操作会将每张卡的输入Tensor的第0维度上进行拼接，最终每张卡输出是相同的数值。例如上图所示，每卡的输入是大小为1x1的Tensor，经过<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>操作之后，每卡<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>算子的输出shape为[4,1]。其中索引为[0,0]的元素值来自于0号卡<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>的输入[[0.0]]，索引为[1,0]的元素值来自于1号卡<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>的输入[[1.0]]。</p>
<p>示例代码如下：我们根据rank号(每张卡所属通信编号)初始化每个进程中<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>算子输入的数值，例如卡0，我们申请了一个1x1大小，数值为0的输入。然后调用<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>算子，在通信域为<code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code>的卡(所有卡的通信范围即nccl_world_group)中进行通信，并且打印输出结果。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_gather</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">AllGather</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">value</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">value</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果如下，输出日志路径为<code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[0.],
 [1.],
 [2.],
 [3.]]
</pre></div>
</div>
</section>
<section id="reducescatter">
<h2>ReduceScatter<a class="headerlink" href="#reducescatter" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="../_images/reducescatter.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code>操作会将每张卡的输入先进行求和，然后在第0维度按卡数切分，将数据分发到对应的卡上。例如上图所示，每卡的输入均为4x1的Tensor。<code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code>先对输入求和得到[0, 4, 8, 12]的Tensor，然后进行分发，每卡获得1x1大小的Tensor。例如卡0对应的输出结果为[[0.0]]，卡1对应的输出结果为[[4.0]]。</p>
<p>示例代码如下：我们根据rank号(每张卡所属通信编号)初始化每个进程中<code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code>算子输入的数值，例如卡0，我们申请了一个4x1大小，数值为0的输入。然后调用<code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code>算子，在通信域为<code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code>的卡(所有卡的通信范围即nccl_world_group)中进行通信，并且打印输出结果。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduce_scatter</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceScatter</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduce_scatter</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果如下，输出日志路径为<code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[0.]]
</pre></div>
</div>
</section>
<section id="broadcast">
<h2>Broadcast<a class="headerlink" href="#broadcast" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="../_images/broadcast.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">Broadcast</span></code>操作是将某张卡的输入广播到其他卡上，常见于参数的初始化。例如上图中，将0卡大小为1x1的Tensor进行广播，最终每张卡输出均为[[0]]。</p>
<p>示例代码如下：我们将<code class="docutils literal notranslate"><span class="pre">Broadcast</span></code>算子的根节点设置为0号卡，表示将从0号卡广播数据到其他卡上。同时申请了一个1x1大小，数值为0的输入。然后调用<code class="docutils literal notranslate"><span class="pre">Broadcast</span></code>算子，在通信域为<code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code>的卡(所有卡的通信范围即nccl_world_group)中进行通信，最终每张卡的输出数值来自卡0。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">broadcast</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Broadcast</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">broadcast</span><span class="p">((</span><span class="n">x</span><span class="p">,))</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果如下，输出日志路径为<code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[0]]
</pre></div>
</div>
</section>
<section id="neighborexchange">
<h2>NeighborExchange<a class="headerlink" href="#neighborexchange" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="../_images/NeighborExchange.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">NeighborExchange</span></code>操作会将提供一组数据分别发往其它特定的卡上，同时从特定的卡接收数据。例如上图中，rank 0 向rank 1发送shape为[16,16]的Tensor， 并接收rank 1发送的shape为[32,32]的Tensor；rank 1 向rank 0发送shape为[32,32]的Tensor， 并接收rank 0发送的shape为[16,16]的Tensor。最终rank 0输出了接收到的shape为[32,32]的Tensor， rank 1输出接收到的[16,16]的Tensor。</p>
<p>示例代码如下：我们使用<code class="docutils literal notranslate"><span class="pre">NeighborExchange</span></code>算子进行0号卡和1号卡之间的数据交换，将0号卡的数据发送到1号卡，并接收来自1号卡的数据；1号卡将数据发送到0号卡，并接收来自0号卡的数据；最终每张卡输出接收到的数据。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Net0</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net0</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchange</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],),</span> <span class="n">send_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],),</span> <span class="n">recv_type</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span><span class="p">((</span><span class="n">x</span><span class="p">,))</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">Net1</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net1</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchange</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">recv_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],),</span> <span class="n">send_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],),</span> <span class="n">recv_type</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span><span class="p">((</span><span class="n">x</span><span class="p">,))</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">rank_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;RANK_ID&quot;</span><span class="p">))</span>
<span class="k">if</span> <span class="p">(</span><span class="n">rank_id</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net0</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net1</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>使用shell脚本启动2卡脚本，下述中的<code class="docutils literal notranslate"><span class="pre">rank_table_file</span></code>文件可以使用<a class="reference external" href="https://gitee.com/mindspore/models">models</a>下面的hccl_tools.py生成，对应的目录文件为<code class="docutils literal notranslate"><span class="pre">models/utils/hccl_tools</span></code>。示例shell脚本如下：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_HCCL_CONFIG_PATH</span><span class="o">=</span>rank_table_file
<span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_NUM</span><span class="o">=</span><span class="m">2</span>
<span class="nv">BASE_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$0</span><span class="k">)</span><span class="s2">&quot;</span><span class="p">;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>
<span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;<span class="nv">$DEVICE_NUM</span><span class="p">;</span><span class="w"> </span>i++<span class="o">))</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>mkdir<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>cp<span class="w"> </span>-r<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/neighborexchange.py<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>/
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training for device </span><span class="nv">$i</span><span class="s2">&quot;</span>
<span class="w">    </span>python<span class="w"> </span>neighborexchange.py<span class="w"> </span>&gt;<span class="w"> </span>log.txt<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="k">done</span>
</pre></div>
</div>
<p>rank0的结果为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[2. 2.]
 [2. 2.]]
</pre></div>
</div>
<p>rank1的结果为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[1. 1. 1.]
 [1. 1. 1.]
 [1. 1. 1.]]
</pre></div>
</div>
</section>
<section id="neighborexchangev2">
<h2>NeighborExchangeV2<a class="headerlink" href="#neighborexchangev2" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="../_images/neighborexchangev2.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">NeighborExchangeV2</span></code>操作会将Tensor中按照属性设置将部分数据发送给周边的8张卡，且从周边的8张卡中接收数据并拼接成新的Tensor，常用于将大Tensor切分在多卡上进行分布式卷积运算的场景。其中，属性send_rank_ids和recv_rank_ids分别为8个数字，表示8个方向上发送/接收的rank_id，填-1表示不发送/不接收，如上图图二表示对应8个方向上的顺序；属性send_lens和recv_lens分别为4个数字，表示[top, bottom, left, right] 四个方向上的发送/接收长度。例如上图图一中为一个16卡的示例， 以图中rank 10为例，设定send_rank_ids=[6,7,11,15,14,13,9,5]，将rank10的数据进行切分后分别向rank 5、6、7、11、15、14、13、9发送了对应部分的数据，例如图中红色发给rank5，红色、黄色和蓝色发给rank6，蓝色发给rank7等；设定recv_rank_ids=[6,7,11,15,14,13,9,5]，则同时rank10从这些卡分别接收了一些数据拼接到对应方向上，组成了新的Tensor输出，例如图中的rank10和浅绿色部分所示。</p>
<p>示例代码如下：我们使用<code class="docutils literal notranslate"><span class="pre">NeighborExchangeV2</span></code>算子进行0号卡和1号卡之间的数据交换，将0号卡的下方的数据发送到1号卡，并接收来自1号卡的数据拼接在下方；1号卡将上方部分数据发送到0号卡，并接收来自0号卡的数据拼接在上方；最终每张卡输出接收到的数据。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Net0</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net0</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchangeV2</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">send_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="k">class</span> <span class="nc">Net1</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net1</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchangeV2</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">send_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">rank_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;RANK_ID&quot;</span><span class="p">))</span>
<span class="k">if</span> <span class="p">(</span><span class="n">rank_id</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net0</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net1</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>使用shell脚本启动2卡脚本，下述中的<code class="docutils literal notranslate"><span class="pre">rank_table_file</span></code>文件可以使用<a class="reference external" href="https://gitee.com/mindspore/models">models</a>下面的hccl_tools.py生成，对应的目录文件为<code class="docutils literal notranslate"><span class="pre">models/utils/hccl_tools</span></code>。示例shell脚本如下：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_HCCL_CONFIG_PATH</span><span class="o">=</span>rank_table_file
<span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_NUM</span><span class="o">=</span><span class="m">2</span>
<span class="nv">BASE_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$0</span><span class="k">)</span><span class="s2">&quot;</span><span class="p">;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>
<span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;<span class="nv">$DEVICE_NUM</span><span class="p">;</span><span class="w"> </span>i++<span class="o">))</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>mkdir<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>cp<span class="w"> </span>-r<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/neighborexchangev2.py<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>/
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training for device </span><span class="nv">$i</span><span class="s2">&quot;</span>
<span class="w">    </span>python<span class="w"> </span>neighborexchangev2.py<span class="w"> </span>&gt;<span class="w"> </span>log.txt<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="k">done</span>
</pre></div>
</div>
<p>rank 0结果为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[1. 1.]
   [1. 1.]
   [2. 2.]]]]
</pre></div>
</div>
<p>rank 1结果为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[1. 1.]
   [2. 2.]
   [2. 2.]]]]
</pre></div>
</div>
</section>
<section id="alltoall">
<h2>AlltoAll<a class="headerlink" href="#alltoall" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="../_images/alltoall.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">AlltoAll</span></code>操作会将输入数据在特定的维度切分成特定的块数，并按顺序发送给其他rank，同时从其他rank接收输入，按顺序在特定的维度拼接数据。例如上图中，将Tensor在0维切分成5块，同时接收其它rank的数据，并在1维进行拼接，最后输出拼接后的数据。</p>
<p>示例代码如下：我们使用<code class="docutils literal notranslate"><span class="pre">AlltoAll</span></code>算子进行8卡的数据交换，把每张卡在第-2维进行切分，并按顺序把切分的数据发送给其它卡，同时接收其它卡的数据，在-1维进行拼接；最终每张卡输出拼接后的数据。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_to_all</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">AlltoAll</span><span class="p">(</span><span class="n">split_count</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">split_dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="n">concat_dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_to_all</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">rank_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;RANK_ID&quot;</span><span class="p">))</span>
<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">rank_id</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>使用shell脚本启动8卡脚本，下述中的<code class="docutils literal notranslate"><span class="pre">rank_table_file</span></code>文件可以使用<a class="reference external" href="https://gitee.com/mindspore/models">models</a>下面的hccl_tools.py生成，对应的目录文件为<code class="docutils literal notranslate"><span class="pre">models/utils/hccl_tools</span></code>。示例shell脚本如下：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_HCCL_CONFIG_PATH</span><span class="o">=</span>rank_table_file
<span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_NUM</span><span class="o">=</span><span class="m">8</span>
<span class="nv">BASE_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$0</span><span class="k">)</span><span class="s2">&quot;</span><span class="p">;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>
<span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;<span class="nv">$DEVICE_NUM</span><span class="p">;</span><span class="w"> </span>i++<span class="o">))</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>mkdir<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>cp<span class="w"> </span>-r<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/alltoall.py<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>/
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training for device </span><span class="nv">$i</span><span class="s2">&quot;</span>
<span class="w">    </span>python<span class="w"> </span>alltoall.py<span class="w"> </span>&gt;<span class="w"> </span>log.txt<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="k">done</span>
</pre></div>
</div>
<p>rank0~rank7的结果为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[0. 1. 2. 3. 4. 5. 6. 7.]]]]
</pre></div>
</div>
</section>
<section id="注意事项">
<h2>注意事项<a class="headerlink" href="#注意事项" title="Permalink to this headline"></a></h2>
<p>在昇腾芯片上，NeighborExchange、NeighborExchangeV2、AlltoAll这三个算子需要进行全连接配网。</p>
<p>全连接配网支持任意卡之间进行通信，没有数量限制。全连接配网方式可参考<a class="reference external" href="https://support.huawei.com/enterprise/zh/ascend-computing/a300t-9000-pid-250702906?category=developer-documents">HCCN Tool 接口参考</a>进行配置。全连接配网时，所有卡需要VLan ID相同、IP在同一网段，配置到其他卡的静态路由表和ARP。其中，<strong>VLan ID需要在交换机上进行配置</strong>，其他IP等改动的单机8卡配置参考样例如下：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 配置IP到同一网段</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0

<span class="c1"># 策略路由</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>table<span class="w"> </span><span class="m">100</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>table<span class="w"> </span><span class="m">101</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>table<span class="w"> </span><span class="m">102</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>table<span class="w"> </span><span class="m">103</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>table<span class="w"> </span><span class="m">104</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>table<span class="w"> </span><span class="m">105</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>table<span class="w"> </span><span class="m">106</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>table<span class="w"> </span><span class="m">107</span>

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>table<span class="w"> </span><span class="m">100</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>table<span class="w"> </span><span class="m">101</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>table<span class="w"> </span><span class="m">102</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>table<span class="w"> </span><span class="m">103</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>table<span class="w"> </span><span class="m">104</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>table<span class="w"> </span><span class="m">105</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>table<span class="w"> </span><span class="m">106</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>table<span class="w"> </span><span class="m">107</span>

<span class="c1"># 静态ARP</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:16
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:15
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:14

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:17
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:15
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:14

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:17
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:16
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:14

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:17
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:16
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:15

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0e
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0d
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0c

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0f
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0d
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0c

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0f
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0e
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0c

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0f
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0e
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0d
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="introduction.html" class="btn btn-neutral float-left" title="分布式并行总览" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="distributed_case.html" class="btn btn-neutral float-right" title="分布式案例" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>