<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>错误分析 &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">数据处理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dataset/augment.html">自动数据增强</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/eager.html">轻量化数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/cache.html">单节点数据缓存</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/optimize.html">数据处理性能优化</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">网络构建</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../network/op_overload.html">优化器的编译优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/custom_cell_reverse.html">自定义Cell的反向</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/ms_class.html">调用自定义类</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型训练优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../others/mixed_precision.html">混合精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="../others/gradient_accumulation.html">梯度累积算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../others/adaptive_summation.html">自适应梯度求和算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../others/dimention_reduce_training.html">降维训练算法</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">自定义算子</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom.html">自定义算子（基于Custom表达）</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../infer/inference.html">模型推理总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/cpu_gpu_mindir.html">GPU推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/ascend_910_mindir.html">Ascend 910 AI处理器上推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/ascend_310_mindir.html">Ascend 310 AI处理器上使用MindIR模型进行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/ascend_310_air.html">Ascend 310 AI处理器上使用AIR模型进行推理</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">调试调优</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="function_debug.html">功能调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_optimization.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference external" href="https://mindspore.cn/mindinsight/docs/zh-CN/r1.8/accuracy_problem_preliminary_location.html">精度调优↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">分布式并行</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../parallel/introduction.html">分布式并行总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/communicate_ops.html">分布式集合通信原语</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/distributed_case.html">分布式案例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/distributed_inference.html">分布式推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/save_load.html">保存和加载模型（HyBrid Parallel模式）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/fault_recover.html">分布式故障恢复</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/multi_dimensional.html">多维度混合并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/other_features.html">其他特性</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">环境变量</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../env/env_var_list.html">环境变量</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>错误分析</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/debug/error_analyze.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="错误分析">
<h1>错误分析<a class="headerlink" href="#错误分析" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.8/tutorials/experts/source_zh_cn/debug/error_analyze.md"><img alt="查看源文件" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_source.png" /></a>  </p>
<p>如前文所述，错误分析是指基于获取到的网络、框架各种信息（例如：错误信息、网络代码等信息）进行错误原因分析，推断错误的可能原因。</p>
<p>错误分析首先需要区分问题场景，确认是数据加载与处理问题还是网络构建与训练问题。通常通过报错信息的格式可判断是数据问题还是网络问题。在分布式并行场景下，需要确认是否是并行场景问题。此时，可通过单卡执行网络进行验证，如果不存在数据加载与处理、网络构建与训练等问题，即是并行场景问题。接下来将对不同场景下的错误分析方法进行说明。</p>
<section id="数据加载与处理错误分析">
<h2>数据加载与处理错误分析<a class="headerlink" href="#数据加载与处理错误分析" title="Permalink to this headline"></a></h2>
<p>数据处理过程出现报错时，报错信息如图1所示，在报错信息中包含C++侧报错信息。通常数据处理的C++侧算子与Python侧同名，可以通过报错信息，确定Python代码中哪个数据处理算子报错，找到报错代码位置。</p>
<p><img alt="" src="../_images/minddata_errmsg.png" /></p>
<p>图 1</p>
<p>如图所示，C++报错的位置在<code class="docutils literal notranslate"><span class="pre">batch_op.cc</span></code>。 batch算子将数据集中连续多条数据合并为一个批处理数据，这是batch算子的后端实现。由报错描述可知，输入数据不满足batch算子的参数要求：合并的数据具有相同的shape，同时可以看到不同shape的大小。</p>
<p>数据加载与处理可以分三个阶段，包括数据准备、数据加载、数据增强。常见的报错如下表所示：</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>常见错误类型</p></th>
<th class="head"><p>错误说明</p></th>
<th class="head"><p>案例分析</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>数据准备错误</p></td>
<td><p>数据集本身问题，包括数据集路径问题以及MindRecord 文件问题</p></td>
<td><p><a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r1.8/debug/minddata_debug.html#%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87">数据准备错误案例</a></p></td>
</tr>
<tr class="row-odd"><td><p>数据加载错误</p></td>
<td><p>数据加载阶段的资源配置错误、自定义加载方法错误以及迭代器使用错误等</p></td>
<td><p><a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r1.8/debug/minddata_debug.html#%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD">数据加载错误案例</a></p></td>
</tr>
<tr class="row-even"><td><p>数据增强错误</p></td>
<td><p>数据格式不匹配、数据尺寸不匹配、资源占用问题、多线程卡死</p></td>
<td><p><a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r1.8/debug/minddata_debug.html#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA">数据增强错误案例</a></p></td>
</tr>
</tbody>
</table>
</section>
<section id="网络构建与训练错误分析">
<h2>网络构建与训练错误分析<a class="headerlink" href="#网络构建与训练错误分析" title="Permalink to this headline"></a></h2>
<p>网络构建与训练过程，按执行模式可以分为动态图模式和静态图模式，按执行阶段可以为编译阶段和执行阶段。不同模式下，不同执行阶段，错误分析的方法不同。</p>
<p>网络构建与训练过程的常见的报错类型如下表所示：</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>常见错误类型</p></th>
<th class="head"><p>错误说明</p></th>
<th class="head"><p>案例分析</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>context配置问题</p></td>
<td><p>系统进行上下文配置时的错误</p></td>
<td><p><a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r1.8/debug/mindrt_debug.html#context%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98">context配置问题分析</a></p></td>
</tr>
<tr class="row-odd"><td><p>语法错误</p></td>
<td><p>包括Python语法错误和MindSpore静态图语法错误，例如控制流语法不支持、Tensor切片错误等</p></td>
<td><p><a class="reference external" href="https://mindspore.cn/tutorials/experts/zh-CN/r1.8/debug/mindrt_debug.html#%E8%AF%AD%E6%B3%95%E9%97%AE%E9%A2%98">语法错误分析</a></p></td>
</tr>
<tr class="row-even"><td><p>算子编译错误</p></td>
<td><p>包括算子参数值/类型/shape不满足要求、算子功能限制等</p></td>
<td><p><a class="reference external" href="https://mindspore.cn/tutorials/experts/zh-CN/r1.8/debug/mindrt_debug.html#%E7%AE%97%E5%AD%90%E7%BC%96%E8%AF%91%E9%94%99%E8%AF%AF">算子编译错误分析</a></p></td>
</tr>
<tr class="row-odd"><td><p>算子执行错误</p></td>
<td><p>包括输入数据异常、算子实现错误、功能限制、资源限制等</p></td>
<td><p><a class="reference external" href="https://mindspore.cn/tutorials/experts/zh-CN/r1.8/debug/mindrt_debug.html#%E7%AE%97%E5%AD%90%E6%89%A7%E8%A1%8C%E9%94%99%E8%AF%AF">算子执行错误分析</a></p></td>
</tr>
<tr class="row-even"><td><p>资源不足</p></td>
<td><p>包括设备内存不足、函数调用栈超限、流资源超限等</p></td>
<td><p><a class="reference external" href="https://mindspore.cn/tutorials/experts/zh-CN/r1.8/debug/mindrt_debug.html#%E8%B5%84%E6%BA%90%E4%B8%8D%E8%B6%B3">资源不足分析</a></p></td>
</tr>
</tbody>
</table>
<ul>
<li><p>动态图模式错误分析</p>
<p>动态图模式下，程序按照代码的编写顺序逐行执行，执行结果能够及时返回。 动态图编译报错的报错信息如图2所示，报错内容是Python前端的报错描述：函数参数个数与要求不符。通过Python调用栈，可以找到用户报错代码的位置：<code class="docutils literal notranslate"><span class="pre">c</span> <span class="pre">=</span> <span class="pre">self.mul(b,</span> <span class="pre">self.func(a,a,b))</span></code>。</p>
<p>通常情况下，报错信息中可能包含有<code class="docutils literal notranslate"><span class="pre">WARNING</span></code>日志，进行错误分析时优先分析Traceback后面的报错内容。</p>
<p><img alt="" src="../_images/pynative_errmsg.png" /></p>
<p>图 2</p>
<p>动态图模式下，网络构建与训练常见的错误问题主要是环境配置问题、Python语法问题、算子使用问题等。一般分析方法如下：</p>
<ul class="simple">
<li><p>根据报错描述内容，确认报错的对象，比如对应的算子API名称；</p></li>
<li><p>根据Python调用栈信息，找到报错的代码行位置；</p></li>
<li><p>分析报错位置的代码输入数据和计算逻辑，结合<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore.html">MindSpore API文档</a>中对应的报错对象的说明和规格限制，分析出现报错问题的原因。</p></li>
</ul>
</li>
<li><p>静态图模式错误分析</p>
<p>静态图模式下，MindSpore首先将网络结构编译成计算图，然后再执行图中涉及的计算操作。因此，静态图模式下的报错问题包括计算图编译报错问题和计算图执行报错问题。计算图编译报错的报错信息如图3所示，发生报错时自动保存<code class="docutils literal notranslate"><span class="pre">analyze_failed.dat</span></code>文件，帮助分析报错代码的位置。</p>
<p><img alt="" src="../_images/graph_errmsg.png" /></p>
<p>图 3</p>
<p>静态图模式错误分析的一般方法是：</p>
<p>根据报错描述内容，确认计算图报错的类型，即是计算图编译报错问题还是计算图执行报错问题：</p>
<ul class="simple">
<li><p>如果是计算图编译报错，根据报错描述和发生报错时自动保存的<code class="docutils literal notranslate"><span class="pre">analyze_failed.dat</span></code>文件，分析计算图推导失败的原因和位置；</p></li>
<li><p>如果是计算图执行报错，可能是资源不足导致的执行报错，也可能是算子的执行报错，需要根据报错信息进行区分。如果是算子执行报错，首先确认是哪个算子，然后使用Dump功能保存算子的输入数据，通过输入数据分析算子报错的原因；</p></li>
</ul>
<p>分析计算图推导失败的原因可以参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r1.8/debug/mindir.html#%E5%A6%82%E4%BD%95%E6%A0%B9%E6%8D%AEanalyze-faildat%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90%E5%9B%BE%E6%8E%A8%E5%AF%BC%E5%A4%B1%E8%B4%A5%E7%9A%84%E5%8E%9F%E5%9B%A0"><code class="docutils literal notranslate"><span class="pre">analyze_failed.dat</span></code>分析方法</a>。</p>
<p>使用Dump保存算子输入数据可以参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r1.8/debug/dump.html">Dump功能调试</a>。</p>
</li>
</ul>
</section>
<section id="分布式并行错误分析">
<h2>分布式并行错误分析<a class="headerlink" href="#分布式并行错误分析" title="Permalink to this headline"></a></h2>
<p>MindSpore提供分布式并行训练功能，支持多种并行模式。分布式并行常见问题和可能原因如下：</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>常见错误类型</p></th>
<th class="head"><p>错误说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>策略配置错误</p></td>
<td><p>算子本身的逻辑导致的策略检查报错</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>常数策略配置错误</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>未配置策略时策略检查报错</p></td>
</tr>
<tr class="row-odd"><td><p>并行脚本错误</p></td>
<td><p>包括脚本启动方式错误、并行配置与启动任务不匹配</p></td>
</tr>
</tbody>
</table>
<ul>
<li><p>策略配置错误</p>
<p>当用户通过 <code class="docutils literal notranslate"><span class="pre">context.set_autoparallel_context(parallel_mode=&quot;semi_auto_parallel&quot;)</span></code>使能自动并行之后，大概率会遇到一些策略检查的报错。这些策略检查来自于特定算子的切分限制。以下举三个例子来说明如何针对这三种错误进行分析。</p>
<ul>
<li><p>算子本身的逻辑导致的策略检查报错</p>
<p>报错信息：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">ERROR</span><span class="p">]</span><span class="n">Check</span> <span class="n">StridedSliceInfo1414</span><span class="p">:</span> <span class="n">When</span> <span class="n">there</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">mask</span><span class="p">,</span> <span class="n">the</span> <span class="nb">input</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">supported</span> <span class="n">to</span> <span class="n">be</span> <span class="n">split</span>
</pre></div>
</div>
<p>可能的错误代码如下，网络的输入是一个[2, 4]的Tensor。网络中是一个slice操作，取输入Tensor中第0维度的前一半。等价的操作类似于numpy中的x[:1, :]其中x就是我们的输入Tensor。在网络中，我们给stridedslice算子配置了(2,1)的策略。表示在第0维度进行了切分。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="n">stridedslice</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">StridedSlice</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">MyStridedSlice</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyStridedSlice</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">slice</span> <span class="o">=</span> <span class="n">stridedslice</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),))</span>

<span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># x is a two-dimensional tensor</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>错误原因：</p>
<p>这段代码在第0维度进行了取切片操作。但是配置的策略(2,1)表示分别对输入Tensor的第0维度和第1维度进行取切片操作。根据目前<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/note/operator_list_parallel.html">MindSpore API文档</a>中对算子切分的说明，</p>
<blockquote>
<div><p>仅支持值为全0的mask；需要切分的维度必须全部提取；输入在strides不为1对应的维度不支持切分</p>
</div></blockquote>
<p>被切分的维度不允许进行取切片的操作，因此需要修改策略如下：</p>
<p>将第0维度的策略从2改成了1。表示第0维度将会被切分成1份，也就是表明不会切分，因此策略满足算子的限制，策略检查成功。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyStridedSlice</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyStridedSlice</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">slice</span> <span class="o">=</span> <span class="n">stridedslice</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),))</span>

<span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># x is a two-dimensional tensor</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>常数策略配置错误</p>
<p>错误信息：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">ERROR</span><span class="p">]</span> <span class="n">The</span> <span class="n">strategy</span> <span class="ow">is</span> <span class="o">...</span><span class="p">,</span> <span class="n">strategy</span> <span class="nb">len</span><span class="p">:</span><span class="o">.</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">equal</span> <span class="n">to</span> <span class="n">inputs</span> <span class="nb">len</span><span class="p">:</span><span class="o">.</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span>
</pre></div>
</div>
<p>可能的错误代码：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySub</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MySub</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sub</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)))</span>
<span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># x is a two-dimensional tensor</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>有很多算子的输入可以是常量，比如加减乘除的运算、concat/gather等算子的axis，对于此类输入有常量scalar的运算，配置算子策略时需注意，不要为这些常量配置策略。如果按照如上方式为减法运算配置策略，对于常量1配置了策略（1，）则会报错。
意思是输入策略的index=1处也就是（1,）这个策略的长度是1，不等于对应的输入的长度是0，因为此时的输入是一个常数标量。</p>
<p>修改后代码：</p>
<p>正确的方式是为常量配置为空策略，或者直接不为其配置（建议此种方式）。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">sub</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),()))</span>

<span class="bp">self</span><span class="o">.</span><span class="n">sub</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),))</span>
</pre></div>
</div>
</li>
<li><p>未配置策略时策略检查报错</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">ERROR</span><span class="p">]</span><span class="n">The</span> <span class="n">strategy</span> <span class="ow">is</span> <span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">shape</span> <span class="mi">4</span> <span class="n">can</span> <span class="ow">not</span> <span class="n">be</span> <span class="n">divisible</span> <span class="n">by</span> <span class="n">strategy</span> <span class="n">value</span> <span class="mi">8</span>
</pre></div>
</div>
<p>可能的错误代码：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySub</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MySub</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sub</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># x is a two-dimensional tensor</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>这段代码在8卡环境下以半自动并行模式运行，因为没有对示例中Sub算子配置策略，Sub算子的默认策略为数据并行。假设输入的x是大小为[2, 4]的矩阵。那么在开始编译之后，就会报错说最后导致输入的维度不够切分而报错。因此这种情况下，我们需要修改策略如下（切分度要小于输入Tensor的维度）。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySub</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MySub</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sub</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">()))</span>
<span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># x is a two-dimensional tensor</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>其中，切分策略(2, 1)表示对第一个输入Tensor的第0维切分2份，第1维切分成1份即不切分。由于<code class="docutils literal notranslate"><span class="pre">ops.Sub</span></code>第二个输入是一个标量无法切分，所以设置切分策略维空()。</p>
</li>
</ul>
</li>
<li><p>并行脚本错误</p>
<p>使用8卡Ascend设备进行训练时，利用bash脚本进行启动任务，正常情况下的脚本如下所示：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="nb">set</span><span class="w"> </span>-e
<span class="nv">EXEC_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">RANK_SIZE</span><span class="o">=</span><span class="m">8</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">RANK_TABLE_FILE</span><span class="o">=</span><span class="si">${</span><span class="nv">EXEC_PATH</span><span class="si">}</span>/rank_table_8pcs.json

<span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span>i&lt;RANK_SIZE<span class="p">;</span>i++<span class="o">))</span>
<span class="k">do</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span>device<span class="nv">$i</span>
<span class="w">    </span>mkdir<span class="w"> </span>device<span class="nv">$i</span>
<span class="w">    </span>cp<span class="w"> </span>./train.py<span class="w"> </span>./device<span class="nv">$i</span>
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span>./device<span class="nv">$i</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span><span class="nv">$i</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span><span class="nv">$i</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training for device </span><span class="nv">$i</span><span class="s2">&quot;</span>
<span class="w">    </span>env<span class="w"> </span>&gt;<span class="w"> </span>env<span class="nv">$i</span>.log
<span class="w">    </span>python<span class="w"> </span>./train.py<span class="w"> </span>&gt;<span class="w"> </span>train.log<span class="nv">$i</span><span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span>../
<span class="k">done</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;The program launch succeed, the log is under device0/train.log0.&quot;</span>
</pre></div>
</div>
<p>通常容易出现的错误的场景有：</p>
<p>1）使用for循环启动的训练任务数<code class="docutils literal notranslate"><span class="pre">RANK_SIZE</span></code>与配置文件<code class="docutils literal notranslate"><span class="pre">rank_table_8pcs.json</span></code>中配置的设备数不匹配，引起报错。</p>
<p>2）执行训练脚本的命令没有使用异步执行的方式：<code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">./train.py</span> <span class="pre">&gt;</span> <span class="pre">train.log$i</span> <span class="pre">2&gt;&amp;1</span></code>，造成不同的训练任务拉起的时间不一致，一起报错。正确的方式是在执行命令后加 <code class="docutils literal notranslate"><span class="pre">&amp;</span></code> 操作符，表示将命令放在子shell中异步执行，由此实现多个任务同步启动。</p>
<p>并行场景经常遇到<code class="docutils literal notranslate"><span class="pre">Distribute</span> <span class="pre">Task</span> <span class="pre">Failed</span></code>问题， 此时需要分析报错问题时出现在计算图编译阶段，还是在打印训练loss的执行阶段，这个可以缩小问题的范围。</p>
<p>参考实例：</p>
<p><a class="reference external" href="https://bbs.huaweicloud.com/forum/thread-181820-1-1.html">MindSpore 分布式并行问题 - Distribute Task Failed</a>。</p>
</li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>