

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>切分策略传播 &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/translations.js"></script>
        
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Parameter Server模式" href="parameter_server_training.html" />
    <link rel="prev" title="其他特性" href="other_features.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">数据处理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dataset/augment.html">自动数据增强</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/cache.html">单节点数据缓存</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/optimize.html">数据处理性能优化</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">图编译</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../network/control_flow.html">流程控制语句</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/op_overload.html">静态图网络编译性能优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/jit_class.html">调用自定义类</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/constexpr.html">网络内构造常量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/dependency_control.html">依赖控制</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型训练优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../optimize/execution_opt.html">下沉模式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/gradient_accumulation.html">梯度累积</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/adaptive_summation.html">自适应梯度求和算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/dimention_reduce_training.html">降维训练算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/thor.html">二阶优化</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">自定义算子</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom.html">自定义算子（基于Custom表达）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/ms_kernel.html">MindSpore Hybrid 语法规范</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom_adv.html">自定义算子进阶用法</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">自动向量化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../vmap/vmap.html">自动向量化Vmap</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../infer/inference.html">模型推理总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/gpu_mindir.html">GPU推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/ascend_910_mindir.html">Ascend 910 AI处理器上推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/ascend_310_mindir.html">Ascend 310 AI处理器上使用MindIR模型进行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/ascend_310_air.html">Ascend 310 AI处理器上使用AIR模型进行推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/model_compression.html">模型压缩</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">调试调优</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../debug/function_debug.html">功能调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/performance_optimization.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference external" href="https://mindspore.cn/mindinsight/docs/zh-CN/r2.0.0-alpha/accuracy_problem_preliminary_location.html">精度调优↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">分布式并行</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">分布式并行总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="parallel_training_quickstart.html">快速入门分布式并行训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="communicate_ops.html">分布式集合通信原语</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_case.html">分布式案例</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_inference.html">分布式推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_load.html">保存和加载模型（HyBrid Parallel模式）</a></li>
<li class="toctree-l1"><a class="reference internal" href="fault_recover.html">分布式故障恢复</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_dimensional.html">多维度混合并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="resilience_train_and_predict.html">分布式弹性训练与推理</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="other_features.html">其他特性</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">切分策略传播</a></li>
<li class="toctree-l2"><a class="reference internal" href="parameter_server_training.html">Parameter Server模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="comm_fusion.html">分布式训练通信融合</a></li>
<li class="toctree-l2"><a class="reference internal" href="dataset_slice.html">数据集切分</a></li>
<li class="toctree-l2"><a class="reference internal" href="pynative_shard_function_parallel.html">函数式算子切分</a></li>
<li class="toctree-l2"><a class="reference internal" href="ms_operator.html">在K8S集群上进行分布式训练</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">环境变量</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../env/env_var_list.html">环境变量</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="other_features.html">其他特性</a> &raquo;</li>
      <li>切分策略传播</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/parallel/sharding_propagation.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="切分策略传播">
<h1>切分策略传播<a class="headerlink" href="#切分策略传播" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r2.0.0-alpha/tutorials/experts/source_zh_cn/parallel/sharding_propagation.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0.0-alpha/resource/_static/logo_source.png"></a></p>
<section id="背景">
<h2>背景<a class="headerlink" href="#背景" title="Permalink to this headline"></a></h2>
<p>分布式算子、张量排布和张量重排布是MindSpore中算子级并行中的基本概念。在<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r2.0.0-alpha/design/distributed_training_design.html#%E8%87%AA%E5%8A%A8%E5%B9%B6%E8%A1%8C%E5%8E%9F%E7%90%86">这里</a>，以例子的形式介绍了这些概念。现在，我们形式化地定义这些概念。</p>
<p>算子级并行属于“单程序多数据”（Single Program Multiple Data，SPMD）的一种实现。同一段程序执行在不同数据分片上。MindSpore将单机版本的程序转换成并行版本的程序。该转换是细粒度的，会将单机版本程序中每个算子替换成分布式算子，同时保证替换是数学等价的。</p>
<section id="分布式算子">
<h3>分布式算子<a class="headerlink" href="#分布式算子" title="Permalink to this headline"></a></h3>
<p>分布式算子：运行在多设备上的分布式算子保证了与单机版本算子计算语义等价性。也就是：给定相同输入，分布式算子与单机版本算子总是得到相同的输出。</p>
<p>考虑矩阵乘算子（MatMul），其输入是两个矩阵X和W，Y = MatMul(X, W)。将此算子切到4台设备上并行执行。如果矩阵X在4台设备上都有副本，而W按列切分4份，每台设备有一份，那么单机版本MatMul算子对应的分布式算子同样是MatMul；即每台设备上都将执行MatMul算子。如果将X按照列切分4份，W按行切4份，每台机器各得到X和W的一个分片，那么单机版本MatMul算子对应的分布式算子是MatMul-&gt;AllReduce；即每台设备上都将顺序执行MatMul和AllReduce两个算子，才能保证数学等价性。</p>
<p>除了“单程序”（Single Program，SP）外，“多数据”（Multiple Data，MD）也需要指定，也就是哪台设备得到数据的哪个切片。为此，我们先定义切分策略（Sharding Strategy）。</p>
</section>
<section id="切分策略">
<h3>切分策略<a class="headerlink" href="#切分策略" title="Permalink to this headline"></a></h3>
<p>切分策略：算子的切分策略是一个二维数组，表示该算子的每个输入张量中的每个维度的切片数量。这里的切分都是均匀切分。</p>
<p>由切分策略，可以推导出<strong>张量排布</strong>，用以描述张量是如何分布在各个设备上的。</p>
</section>
<section id="张量排布">
<h3>张量排布<a class="headerlink" href="#张量排布" title="Permalink to this headline"></a></h3>
<p>张量排布：给定一个算子的切分策略，能够推导出该算子的输入和输出张量的<strong>张量排布</strong>；张量排布是由<strong>逻辑设备矩阵</strong>和<strong>张量映射</strong>构成的。逻辑设备矩阵是该算子的输入和输出张量共用的，为一维数组，表示设备是如何组织的。张量映射是二维数组，表示张量的某一维切分到逻辑设备矩阵的某一维。</p>
<p>同样考虑矩阵乘算子（MatMul），其输入是两个矩阵X和W：Y = MatMul(X, W)。给算子配置切分策略为[[2, 1], [1, 4]]，因此而得到的张量排布和每台设备上执行的计算如下图所示。X沿行均匀切分为2份，W沿列均匀切分为4份（如下图(b)）。根据切分策略，推导出逻辑设备矩阵和张量映射，如下图(c)所示。各个设备的坐标因此也确定下来了，描述了其在逻辑设备矩阵中的位置。张量在各个设备中的分布由设备的坐标决定。由下图(c)中表的‘2’列得出：设备0—设备3得到X<sub>0</sub>分片，设备4—设备7得到X<sub>1</sub>分片。由下图(c)中表的‘4’列得出：设备0和设备4得到W<sub>0</sub>分片，设备1和设备5得到W<sub>1</sub>分片，设备2和设备6得到W<sub>2</sub>分片，设备3和设备7得到W<sub>3</sub>分片。因此，各台设备上的计算也确定下来了，如下图(d)所示。</p>
<p><img alt="tensor_layout" src="../_images/tensor_layout_zh.png" /></p>
<p>对于有数据依赖的两个算子（即一个算子的输出张量被第二个算子使用），两个算子对于该数据依赖张量定义的张量排布可能不同（由于逻辑设备矩阵不同或张量映射不同），因此提出了<strong>张量重排布</strong>，用以转换不一致的排布。这里给出张量重排布的定义，省略了具体算法。</p>
</section>
<section id="张量重排布">
<h3>张量重排布<a class="headerlink" href="#张量重排布" title="Permalink to this headline"></a></h3>
<p>张量重排布：给定同一张量的两个不一致的张量排布，张量重排布能够将源排布转换到目的排布，同时保证转换产生的通信代价最小。</p>
<p>这里的通信代价指的是每台设备通信的数据量。</p>
<p>考虑两个矩阵乘算子的例子：Z = MatMul(X, W), O = MatMul(Z, Y)。为了使得张量重排布起作用，两个矩阵乘算子配置了不同的切分策略，使得张量Z的排布不一致。在下图(a)中，第一个矩阵乘算子的输出张量Z是按行切分的，然而第二个矩阵乘算子要求张量Z是完整的，因此张量重排布推导出这里需要插入AllGather算子完成转换[1]。在下图(b)中，第一个矩阵乘算子的输出张量Z是按行切分的，然而第二个矩阵乘算子要求张量Z是按列切分的，故张量重排布推导出这里需要插入AllToAll算子完成转换。</p>
<p><img alt="tensor_redistribution" src="../_images/tensor_redistribution_zh.png" /></p>
</section>
</section>
<section id="切分策略传播的基本原理">
<h2>切分策略传播的基本原理<a class="headerlink" href="#切分策略传播的基本原理" title="Permalink to this headline"></a></h2>
<p>给定计算图，<strong>切分策略传播</strong>（Sharding Propagation）使得策略由配置的算子传播到整张计算图的所有算子。在传播过程中，策略选择的目标是最小化张量重排布产生的通信代价。</p>
<p>切分策略传播的输入是带有一些算子切分策略的计算图，其中的点表示算子，有向边表示数据依赖关系。切分策略传播的执行流程如下：</p>
<ol class="arabic simple">
<li><p>为未配置切分策略的算子生成可行的切分策略；</p></li>
<li><p>为每条边生成重排布策略及相应的代价；</p></li>
<li><p>从已配置切分策略的算子出发，利用广度优先搜索将切分策略传播到其它未配置切分策略的算子。传播过程的目标是最小化每条边上的重排布通信代价。若在当前传播路径上遇到已配置策略的算子，则停止传播。</p></li>
</ol>
<p>下图所示的是切分策略传播的一个流程实例。在给定带有切分策略的计算图后，首先为没有配置切分策略的算子枚举其可行的策略，如下图(b)所示。然后，为每条边枚举重排布策略和相应的代价。如下图(c)所示，这里的重排布策略定义为二元组[<em>s_strategy</em>, <em>t_strategy</em>]，其中<em>s_strategy</em>表示的是源算子（下图(c)中的ReLU）的切分策略，<em>t_strategy</em>表示的是目的算子（下图(c)中的MatMul）的切分策略。当沿着一条边传播到下一个算子时（如图中ReLU切分策略已确定，为[2, 4]，下一步要决定MatMul算子的切分策略），总是在表中选择引起通信代价最小的目的算子的策略（即为MatMul选择[[2, 4], [4, 1]]）。最后，所有算子的切分策略都被确定，如下图(d)所示。</p>
<p><img alt="sharding_propagation" src="../_images/sharding_propagation_zh.png" /></p>
</section>
<section id="操作实践">
<h2>操作实践<a class="headerlink" href="#操作实践" title="Permalink to this headline"></a></h2>
<section id="样例代码说明">
<h3>样例代码说明<a class="headerlink" href="#样例代码说明" title="Permalink to this headline"></a></h3>
<blockquote>
<div><p>可以在这里下载完整的样例代码：</p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/tree/r2.0.0-alpha/docs/sample_code/sharding_propagation">https://gitee.com/mindspore/docs/tree/r2.0.0-alpha/docs/sample_code/sharding_propagation</a>。</p>
</div></blockquote>
<p>目录结构如下，其中，<code class="docutils literal notranslate"><span class="pre">rank_table_8pcs.json</span></code>是配置当前Ascend多卡环境的组网信息文件（关于该配置文件的说明，参见<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r2.0.0-alpha/parallel/train_ascend.html#%E9%85%8D%E7%BD%AE%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">这里</a>），<code class="docutils literal notranslate"><span class="pre">train.py</span></code>是模型定义脚本，<code class="docutils literal notranslate"><span class="pre">run.sh</span></code>是执行脚本。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─sample_code
    ├─sharding_propagatinon
    │      rank_table_8pcs.json
    │      run.sh
    │      train.py
    ...
</pre></div>
</div>
</section>
<section id="模型定义">
<h3>模型定义<a class="headerlink" href="#模型定义" title="Permalink to this headline"></a></h3>
<p>我们定义以FeedForward Network（<code class="docutils literal notranslate"><span class="pre">FFN</span></code>）为例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FFN</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</section>
<section id="配置切分策略传播">
<h3>配置切分策略传播<a class="headerlink" href="#配置切分策略传播" title="Permalink to this headline"></a></h3>
<p>在FFN中为MatMul配置切分策略：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="o">.</span><span class="n">matmul</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
</pre></div>
</div>
<p>配置并行模式为自动并行的切分策略传播：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">parallel_mode</span><span class="o">=</span><span class="s2">&quot;auto_parallel&quot;</span><span class="p">,</span> <span class="n">search_mode</span><span class="o">=</span><span class="s2">&quot;sharding_propagation&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="训练模型并检查切分策略">
<h3>训练模型并检查切分策略<a class="headerlink" href="#训练模型并检查切分策略" title="Permalink to this headline"></a></h3>
<p>执行命令<code class="docutils literal notranslate"><span class="pre">bash</span> <span class="pre">run.sh</span> <span class="pre">8</span></code>。通过在<code class="docutils literal notranslate"><span class="pre">train.py</span></code>中设置context: <code class="docutils literal notranslate"><span class="pre">save_graphs=True</span></code>，可以打印出编译过程中的IR图。我们选取设备0对应的IR图。</p>
<p>在<code class="docutils literal notranslate"><span class="pre">step_parallel_begin_xxxx.ir</span></code>中，可以看到每个计算算子都被配置了切分策略。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>...
  %3(x) = MatMul(%1, %2) {instance name: matmul} primitive_attrs: {input_names: [x1, x2], out_strategy: None, transpose_x2: false, transpose_b: false, in_strategy: ((2, 1), (1, 4)), output_names: [output], transpose_a: false, transpose_x1: false}
 {in_strategy: ((2, 1), (1, 4))}      : (&lt;Tensor[Float32], (64, 64)&gt;, &lt;Tensor[Float32], (64, 64)&gt;) -&gt; (&lt;Tensor[Float32], (64, 64)&gt;)
  %4([CNode]453) = Load($(@1_construct_wrapper.298:para4_dense1.bias), %para15_u)
      : (&lt;Ref[Tensor(F32)], (64)&gt;, &lt;UMonad&gt;) -&gt; (&lt;Tensor[Float32], (64)&gt;)
  %5(x) = Add(%3, %4) {instance name: add} primitive_attrs: {output_names: [output], input_names: [x, y]}
 {in_strategy: ((2, 4), (4))}      : (&lt;Tensor[Float32], (64, 64)&gt;, &lt;Tensor[Float32], (64)&gt;) -&gt; (&lt;Tensor[Float32], (64, 64)&gt;)
  %6(x) = ReLU(%5) {instance name: relu} primitive_attrs: {output_names: [output], input_names: [x]}
 {in_strategy: ((2, 4))}      : (&lt;Tensor[Float32], (64, 64)&gt;) -&gt; (&lt;Tensor[Float32], (64, 64)&gt;)
  %7([CNode]447) = Load($(@1_construct_wrapper.298:para5_dense2.weight), %para15_u)
      : (&lt;Ref[Tensor(F32)], (64, 64)&gt;, &lt;UMonad&gt;) -&gt; (&lt;Tensor[Float32], (64, 64)&gt;)
  %8(x) = MatMul(%6, %7) {instance name: matmul} primitive_attrs: {output_names: [output], transpose_a: false, input_names: [x1, x2], transpose_x2: false, transpose_x1: false, transpose_b: false}
 {in_strategy: ((2, 4), (4, 1))}      : (&lt;Tensor[Float32], (64, 64)&gt;, &lt;Tensor[Float32], (64, 64)&gt;) -&gt; (&lt;Tensor[Float32], (64, 64)&gt;)
  %9([CNode]449) = Load($(@1_construct_wrapper.298:para6_dense2.bias), %para15_u)
      : (&lt;Ref[Tensor(F32)], (64)&gt;, &lt;UMonad&gt;) -&gt; (&lt;Tensor[Float32], (64)&gt;)
  %10(x) = Add(%8, %9) {instance name: add} primitive_attrs: {output_names: [output], input_names: [x, y]}
 {in_strategy: ((2, 4), (4))}      : (&lt;Tensor[Float32], (64, 64)&gt;, &lt;Tensor[Float32], (64)&gt;) -&gt; (&lt;Tensor[Float32], (64, 64)&gt;)
...
</pre></div>
</div>
<p>在<code class="docutils literal notranslate"><span class="pre">xx_validate_xxx.ir</span></code>中，可以看到各个算子的输入输出张量是已经被切分后的。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>...
  %2(equivx) = MatMul(%0, %1) {instance name: matmul} primitive_attrs: {input_names: [x1, x2], out_strategy: None, transpose_x2: false, transpose_b: false, in_strategy: ((2, 1), (1, 4)), output_names: [output], transpose_a: false, transpose_x1: false}
 {in_strategy: ((2, 1), (1, 4))}      : (&lt;Tensor[Float32], (32, 64)&gt;, &lt;Tensor[Float32], (64, 16)&gt;) -&gt; (&lt;Tensor[Float32], (32, 16)&gt;)
      # In file ./train.py(33)/        x = self.matmul(x, self.weight)/
  %3(equiv[CNode]453) = Load(%para4_dense1.bias, U)
      : (&lt;Ref[Tensor(F32)], (16)&gt;, &lt;UMonad&gt;) -&gt; (&lt;Tensor[Float32], (16)&gt;)
  %4(equivx) = Add(%2, %3) {instance name: add} primitive_attrs: {output_names: [output], input_names: [x, y]}
 {in_strategy: ((2, 4), (4))}      : (&lt;Tensor[Float32], (32, 16)&gt;, &lt;Tensor[Float32], (16)&gt;) -&gt; (&lt;Tensor[Float32], (32, 16)&gt;)
      # In file ./train.py(34)/        x = self.add(x, self.bias)/
  %5(equivx) = ReLU(%4) {instance name: relu} primitive_attrs: {output_names: [output], input_names: [x]}
 {in_strategy: ((2, 4))}      : (&lt;Tensor[Float32], (32, 16)&gt;) -&gt; (&lt;Tensor[Float32], (32, 16)&gt;)
      # In file ./train.py(48)/        x = self.relu(x)/
  %6(equiv[CNode]447) = Load(%para5_dense2.weight, U)
      : (&lt;Ref[Tensor(F32)], (16, 64)&gt;, &lt;UMonad&gt;) -&gt; (&lt;Tensor[Float32], (16, 64)&gt;)
  %7(equivx) = MatMul(%5, %6) {instance name: matmul} primitive_attrs: {output_names: [output], transpose_a: false, input_names: [x1, x2], transpose_x2: false, transpose_x1: false, transpose_b: false}
 {in_strategy: ((2, 4), (4, 1))}      : (&lt;Tensor[Float32], (32, 16)&gt;, &lt;Tensor[Float32], (16, 64)&gt;) -&gt; (&lt;Tensor[Float32], (32, 64)&gt;)
      # In file ./train.py(33)/        x = self.matmul(x, self.weight)/
  %8(equiv[CNode]493) = AllReduce(%7) {instance name: forward_op_4025687080669949636} primitive_attrs: {group: 4-6301172352641561019, fusion: 0, op: sum, group_ranks: 0-1-2-3, index: 0}
      : (&lt;Tensor[Float32], (32, 64)&gt;) -&gt; (&lt;Tensor[Float32], (32, 64)&gt;)
  %9(equiv[CNode]492) = StridedSlice(%8, (0, 0), (32, 16), (1, 1)) {instance name: redistribution_op_145462406996255498StridedSlice} primitive_attrs: {new_axis_mask: 0, shrink_axis_mask: 0, end_mask: 0, input_names: [x, begin, end, strides], output_names: [output], keep_value_node_input: true, begin_mask: 0, ellipsis_mask: 0}
      : (&lt;Tensor[Float32], (32, 64)&gt;, &lt;Tuple[Int64*2]&gt;, &lt;Tuple[Int64*2]&gt;, &lt;Tuple[Int64*2]&gt;) -&gt; (&lt;Tensor[Float32], (32, 16)&gt;)
  %10(equiv[CNode]449) = Load(%para6_dense2.bias, U)
      : (&lt;Ref[Tensor(F32)], (16)&gt;, &lt;UMonad&gt;) -&gt; (&lt;Tensor[Float32], (16)&gt;)
  %11(equivx) = Add(%9, %10) {instance name: add} primitive_attrs: {output_names: [output], input_names: [x, y]}
 {in_strategy: ((2, 4), (4))}      : (&lt;Tensor[Float32], (32, 16)&gt;, &lt;Tensor[Float32], (16)&gt;) -&gt; (&lt;Tensor[Float32], (32, 16)&gt;)
...
</pre></div>
</div>
</section>
</section>
<section id="配置算子切分策略的经验性原则">
<h2>配置算子切分策略的经验性原则<a class="headerlink" href="#配置算子切分策略的经验性原则" title="Permalink to this headline"></a></h2>
<p>给定一个新模型，从用户的角度，关键问题是配置哪些算子的切分策略来获得较好的性能。由于策略传播的目标是最小化张量重排布的代价，而非最小化端到端的迭代时间，因此，为“关键算子”配置合适的切分策略是十分重要的。然而，并不存在明确的规定约束哪些算子是必须配置切分策略的。尽管如此，基于我们训练大模型的经验，确实有一些原则可以用来指导新用户配置并行策略。这里，我们列出3条经验性的原则。</p>
<section id="配置涉及权重的算子">
<h3>配置涉及权重的算子<a class="headerlink" href="#配置涉及权重的算子" title="Permalink to this headline"></a></h3>
<p>参数权重的切分策略是十分重要的，尤其对大模型来说，因为参数权重引起的内存消耗占据模型训练总内存消耗的大部分。因此，涉及权重的算子通常需要显式地配置切分策略。在下图的两个例子中，涉及权重的Gather和MatMul算子配置了切分策略，而其他算子没有配置。这分别对应<a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r2.0.0-alpha/mindspore/python/mindspore/nn/transformer">Transformer</a>中的数据并行Embedding层和混合并行FeedForward层。</p>
<p><img alt="sp_case1_zh" src="../_images/sp_case1_zh.png" /></p>
</section>
<section id="配置维度改变的算子">
<h3>配置维度改变的算子<a class="headerlink" href="#配置维度改变的算子" title="Permalink to this headline"></a></h3>
<p>深度学习框架的算子大致可以分为两类：语义简单的维度保持的算子；会改变输入张量维度的算子。对于维度保持算子，策略传播算法可以较容易地将切分策略传播出去。但是，对于维度改变算子，显式地配置切分策略才能更好地表达用户的初始想法，避免策略传播算法推导出非用户期望的切分策略。在下图的例子中，ReduceMean和MatMul是维度改变算子，它们被配置了切分策略。</p>
<p><img alt="sp_case2_zh" src="../_images/sp_case2_zh.png" /></p>
</section>
<section id="配置并行方式改变的边界算子">
<h3>配置并行方式改变的边界算子<a class="headerlink" href="#配置并行方式改变的边界算子" title="Permalink to this headline"></a></h3>
<p>对于类似ResNet类的模型，模型的不同部分偏好的并行方式不同：前半部分使用数据并行，后半部分使用模型并行，以此获得最优的迭代性能。这可以通过为并行方式改变的边界算子配置策略来实现。在下图的例子中，第一个MatMul配置了数据并行的策略，它会将数据并行的策略向前传播到模型的前半部分；第二个MatMul配置了模型并行的策略，它会将模型并行的策略向后传播到模型的后半部分。</p>
<p><img alt="sp_case3_zh" src="../_images/sp_case3_zh.png" /></p>
<p>用户在用策略传播时不仅需要对其传播算法本身有一定的了解，还要对要训练的模型的并行方式有一定的理解。如果存在某个由策略传播算法决定的算子的并行策略不符合用户的期望，那总可以通过多配置一个算子并行策略的方式解决。实际中，对于一个新模型，确实需要尝试几次才能获得性能较优的整体并行配置。</p>
<p>[1]：注：实际上需要插入AllGather算子和Concat算子。</p>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="other_features.html" class="btn btn-neutral float-left" title="其他特性" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="parameter_server_training.html" class="btn btn-neutral float-right" title="Parameter Server模式" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>