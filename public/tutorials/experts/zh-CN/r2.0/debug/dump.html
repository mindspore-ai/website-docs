<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Dump功能调试 &mdash; MindSpore master documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="PyNative 调试" href="pynative_debug.html" />
    <link rel="prev" title="查看中间文件" href="mindir.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">数据处理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dataset/augment.html">自动数据增强</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/cache.html">单节点数据缓存</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset/optimize.html">数据处理性能优化</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">图编译</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../network/control_flow.html">流程控制语句</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/op_overload.html">静态图网络编译性能优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/jit_class.html">调用自定义类</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/constexpr.html">网络内构造常量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../network/dependency_control.html">依赖控制</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型训练优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../optimize/execution_opt.html">下沉模式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/gradient_accumulation.html">梯度累积</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/adaptive_summation.html">自适应梯度求和算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/dimention_reduce_training.html">降维训练算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimize/thor.html">二阶优化</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">自定义算子</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom.html">自定义算子（基于Custom表达）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/ms_kernel.html">MindSpore Hybrid 语法规范</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operation/op_custom_adv.html">自定义算子进阶用法</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">自动向量化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../vmap/vmap.html">自动向量化Vmap</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../infer/inference.html">模型推理总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/model_compression.html">模型压缩</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">调试调优</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="function_debug.html">功能调试</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="error_analyze.html">错误分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_debug.html">自定义调试信息</a></li>
<li class="toctree-l2"><a class="reference internal" href="mindir.html">查看中间文件</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Dump功能调试</a></li>
<li class="toctree-l2"><a class="reference internal" href="pynative_debug.html">PyNative 调试</a></li>
<li class="toctree-l2"><a class="reference internal" href="pynative.html">动态图模式应用</a></li>
<li class="toctree-l2"><a class="reference internal" href="fixing_randomness.html">固定随机性以复现脚本运行结果</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="performance_optimization.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference external" href="https://mindspore.cn/mindinsight/docs/zh-CN/r2.0/accuracy_problem_preliminary_location.html">精度调优↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">分布式并行</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../parallel/introduction.html">分布式并行总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/parallel_training_quickstart.html">快速入门分布式并行训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/communicate_ops.html">分布式集合通信原语</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/distributed_case.html">分布式案例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/distributed_inference.html">分布式推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/save_load.html">保存和加载模型（HyBrid Parallel模式）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/fault_recover.html">分布式故障恢复</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/multi_dimensional.html">多维度混合并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/resilience_train_and_predict.html">分布式弹性训练与推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel/other_features.html">其他特性</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">环境变量</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../env/env_var_list.html">环境变量</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="function_debug.html">功能调试</a> &raquo;</li>
      <li>Dump功能调试</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/debug/dump.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="dump功能调试">
<h1>Dump功能调试<a class="headerlink" href="#dump功能调试" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r2.0/tutorials/experts/source_zh_cn/debug/dump.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0/resource/_static/logo_source.png"></a></p>
<section id="概述">
<h2>概述<a class="headerlink" href="#概述" title="Permalink to this headline"></a></h2>
<p>为了对训练过程进行分析，用户需要感知训练过程中算子的输入和输出数据。</p>
<ul class="simple">
<li><p>对于静态图模式，MindSpore提供了Dump功能，用来将模型训练中的图以及算子的输入输出数据保存到磁盘文件。</p></li>
<li><p>对于动态图模式，Dump功能仅支持Ascend后端的溢出检测能力。要想查看非溢出节点，可以使用Python原生执行能力，用户可以在网络脚本运行过程中查看记录相应的输入输出。</p></li>
</ul>
<section id="调试过程">
<h3>调试过程<a class="headerlink" href="#调试过程" title="Permalink to this headline"></a></h3>
<p>使用Dump来帮助调试分为两个步骤：1、数据准备；2、数据分析。</p>
<section id="数据准备">
<h4>数据准备<a class="headerlink" href="#数据准备" title="Permalink to this headline"></a></h4>
<p>数据准备阶段使用同步Dump或异步Dump来生成Dump数据。使用方法详见<span class="xref myst">同步Dump操作步骤</span>和<span class="xref myst">异步Dump操作步骤</span>。</p>
<p>在准备数据时，您可以参考以下最佳实践：</p>
<ol class="arabic simple">
<li><p>设置<code class="docutils literal notranslate"><span class="pre">iteration</span></code>参数，仅保存出现问题的迭代和前一个迭代这两个迭代的数据。例如，要分析的问题会在第10个迭代（从1开始数）出现，则可以这样设置：<code class="docutils literal notranslate"><span class="pre">&quot;iteration&quot;:</span> <span class="pre">&quot;8|9&quot;</span></code>。请注意<code class="docutils literal notranslate"><span class="pre">iteration</span></code>参数从0开始计算迭代数。保存上述两个迭代的数据能够支撑大多数场景的问题分析。</p></li>
<li><p>在出现问题的迭代执行完毕后，建议您通过<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r2.0/api_python/train/mindspore.train.RunContext.html#mindspore.train.RunContext.request_stop">run_context.request_stop()</a>等方法提前结束训练。</p></li>
</ol>
</section>
<section id="数据分析">
<h4>数据分析<a class="headerlink" href="#数据分析" title="Permalink to this headline"></a></h4>
<p>如果用户已经安装了MindSpore Insight, 可以使用MindSpore Insight的离线调试器来分析。离线调试器的使用方法详见<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r2.0/debugger_offline.html">使用离线调试器</a> 。</p>
<p>如果没有安装MindSpore Insight，需要通过以下步骤来分析数据。</p>
<ol class="arabic">
<li><p>从脚本找到对应的算子</p>
<p>使用Dump功能将自动生成最终执行图的IR文件（IR文件中包含了算子全名，和算子在计算图中输入和输出的依赖，也包含从算子到相应脚本代码的Trace信息)，IR文件可以用<code class="docutils literal notranslate"><span class="pre">vi</span></code>命令查看，Dump功能的配置见<span class="xref myst">同步Dump操作步骤</span>和<span class="xref myst">异步Dump操作步骤</span>，Dump输出的目录结构见<span class="xref myst">同步Dump数据对象目录</span>和<span class="xref myst">异步Dump数据对象目录</span>。然后通过图文件找到脚本中代码对应的算子，参考<span class="xref myst">同步Dump数据分析样例</span>和<span class="xref myst">异步Dump数据分析样例</span>。</p>
</li>
<li><p>从算子到Dump数据</p>
<p>在了解脚本和算子的映射关系后，可以确定想要分析的算子名称，从而找到算子对应的dump文件，参考<span class="xref myst">同步Dump数据对象目录</span>和<span class="xref myst">异步Dump数据对象目录</span>。</p>
</li>
<li><p>分析Dump数据</p>
<p>通过解析Dump数据，可以与其他第三方框架进行对比。同步Dump数据格式参考<span class="xref myst">同步Dump数据文件介绍</span>，异步Dump数据格式参考<span class="xref myst">异步Dump数据文件介绍</span>。</p>
</li>
</ol>
</section>
</section>
<section id="适用场景">
<h3>适用场景<a class="headerlink" href="#适用场景" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>静态图算子结果分析。</p>
<p>通过Dump功能获得的IR图，可以了解脚本代码与执行算子的映射关系（详情见<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r2.0/design/mindir.html#%E7%AE%80%E4%BB%8B">MindSpore IR简介</a>）。结合执行算子的输入和输出数据，可以分析训练过程中可能存在的溢出、梯度爆炸与消失等问题，反向跟踪到脚本中可能存在问题的代码。</p>
</li>
<li><p>特征图分析。</p>
<p>通过获取图层的输出数据，分析特征图的信息。</p>
</li>
<li><p>模型迁移。</p>
<p>在将模型从第三方框架（TensorFlow、PyTorch）迁移到MindSpore的场景中，通过比对相同位置算子的输出数据，分析第三方框架和MindSpore对于同一模型的训练结果是否足够接近，来定位模型的精度问题。</p>
</li>
</ol>
</section>
</section>
<section id="dump功能说明">
<h2>Dump功能说明<a class="headerlink" href="#dump功能说明" title="Permalink to this headline"></a></h2>
<p>MindSpore提供了同步Dump与异步Dump两种模式：</p>
<ul class="simple">
<li><p>同步Dump的机制是在网络训练过程中每个step执行结束后， Host侧发起Dump动作，从Device上拷贝算子地址里面的数据到Host，并保存文件。同步Dump会默认关闭算子间的内存复用，避免读到脏数据。</p></li>
<li><p>异步Dump是专门针对Ascend整图下沉而开发的功能，可以一边执行算子一边dump数据，一个算子执行结束后立即dump数据，因此开启内存复用也可以生成正确的数据，但是相应的网络训练的速度会较慢。</p></li>
</ul>
<p>不同模式所需要的配置文件和dump出来的数据格式不同：</p>
<ul class="simple">
<li><p>在Ascend上开启同步Dump的时候，待Dump的算子会自动关闭内存复用。</p></li>
<li><p>同步Dump目前支持Ascend、GPU和CPU上的图模式，暂不支持PyNative模式。</p></li>
<li><p>异步Dump全量功能只支持Ascend上的图模式，异步Dump溢出检测功能只支持Ascend上的图模式和PyNative模式。开启异步Dump的时候不会关闭内存复用。</p></li>
<li><p>默认使用用异步Dump模式，如果要使用同步Dump模式，需要在配置文件中设置”e2e_dump_settings”。</p></li>
<li><p>Dump暂不支持异构训练，如果在异构训练场景启用Dump，生成的Dump数据对象目录可能不符合预期的目录结构。</p></li>
</ul>
</section>
<section id="同步dump">
<h2>同步Dump<a class="headerlink" href="#同步dump" title="Permalink to this headline"></a></h2>
<section id="同步dump操作步骤">
<h3>同步Dump操作步骤<a class="headerlink" href="#同步dump操作步骤" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>创建json格式的配置文件，JSON文件的名称和位置可以自定义设置。</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;common_dump_settings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;dump_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;/absolute_path&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;net_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ResNet50&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;iteration&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0|5-8|100-120&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;saved_data&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tensor&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;input_output&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;kernels&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;Default/Conv-op12&quot;</span><span class="p">],</span>
<span class="w">        </span><span class="nt">&quot;support_device&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">]</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;e2e_dump_settings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enable&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;trans_flag&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dump_mode</span></code>：设置成0，表示Dump出该网络中的所有算子数据；设置成1，表示Dump<code class="docutils literal notranslate"><span class="pre">&quot;kernels&quot;</span></code>里面指定的算子数据或算子类型数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>：Dump保存数据的绝对路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>：自定义的网络名称，例如：”ResNet50”。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration</span></code>：指定需要Dump数据的迭代。类型为str，用“|”分离要保存的不同区间的step的数据。如”0|5-8|100-120”表示Dump第1个，第6个到第9个， 第101个到第121个step的数据。指定“all”，表示Dump所有迭代的数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">saved_data</span></code>: 指定Dump的数据。类型为str，取值成”tensor”，表示Dump出完整张量数据；取值成”statistic”，表示只Dump张量的统计信息；取值”full”代表两种都要。同步Dump统计信息现只支持GPU场景，CPU或Ascend场景若选”statistic”或”full”便会错误退出。默认取值为”tensor”。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output</span></code>：设置成0，表示Dump出算子的输入和算子的输出；设置成1，表示Dump出算子的输入；设置成2，表示Dump出算子的输出。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernels</span></code>：该项可以配置两种格式：</p>
<ol class="arabic simple">
<li><p>算子的名称列表。开启IR保存开关<code class="docutils literal notranslate"><span class="pre">set_context(save_graphs=2)</span></code>并执行用例，从生成的IR文件<code class="docutils literal notranslate"><span class="pre">trace_code_graph_{graph_id}</span></code>中获取算子名称。详细说明可以参照教程：<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r2.0/debug/mindir.html#%E5%A6%82%E4%BD%95%E4%BF%9D%E5%AD%98ir">如何保存IR</a>。
需要注意的是，是否设置<code class="docutils literal notranslate"><span class="pre">set_context(save_graphs=2)</span></code>可能会导致同一个算子的id不同，所以在Dump指定算子时要在获取算子名称之后保持这一项设置不变。或者也可以在Dump保存的<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code>文件中获取算子名称，参考<span class="xref myst">同步Dump数据对象目录</span>。</p></li>
<li><p>还可以指定算子类型。当字符串中不带算子scope信息和算子id信息时，后台则认为其为算子类型，例如：”conv”。算子类型的匹配规则为：当发现算子名中包含算子类型字符串时，则认为匹配成功（不区分大小写），例如：”conv” 可以匹配算子 “Conv2D-op1234”、”Conv3D-op1221”。</p></li>
</ol>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">support_device</span></code>：支持的设备，默认设置成0到7即可；在分布式训练场景下，需要dump个别设备上的数据，可以只在<code class="docutils literal notranslate"><span class="pre">support_device</span></code>中指定需要Dump的设备Id。该配置参数在CPU上无效，因为CPU下没有device这个概念，但是在json格式的配置文件中仍需保留该字段。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">enable</span></code>：设置成true，表示开启同步Dump；设置成false时，在Ascend上会使用异步Dump，在GPU上仍然使用同步Dump。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trans_flag</span></code>：开启格式转换。将设备上的数据格式转换成NCHW格式。若为<code class="docutils literal notranslate"><span class="pre">True</span></code>，则数据会以Host侧的4D格式（NCHW）格式保存；若为<code class="docutils literal notranslate"><span class="pre">False</span></code>，则保留Device侧的数据格式。该配置参数在CPU上无效，因为CPU上没有format转换，但是在json格式的配置文件中仍需保留该字段。</p></li>
</ul>
</li>
<li><p>设置Dump环境变量。</p>
<p>指定Dump的json配置文件。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_DUMP_CONFIG</span><span class="o">=</span><span class="si">${</span><span class="nv">xxx</span><span class="si">}</span>
</pre></div>
</div>
<p>其中”xxx”为配置文件的绝对路径，如：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_DUMP_CONFIG</span><span class="o">=</span>/path/to/data_dump.json
</pre></div>
</div>
<p>如果Dump配置文件没有设置<code class="docutils literal notranslate"><span class="pre">path</span></code>字段或者设置为空字符串，还需要配置环境变量<code class="docutils literal notranslate"><span class="pre">MS_DIAGNOSTIC_DATA_PATH</span></code>。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MS_DIAGNOSTIC_DATA_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">yyy</span><span class="si">}</span>
</pre></div>
</div>
<p>则“$MS_DIAGNOSTIC_DATA_PATH/debug_dump”就会被当做<code class="docutils literal notranslate"><span class="pre">path</span></code>的值。若Dump配置文件中设置了<code class="docutils literal notranslate"><span class="pre">path</span></code>字段，则仍以该字段的实际取值为准。</p>
<p>注意：</p>
<ul class="simple">
<li><p>在网络脚本执行前，设置好环境变量；网络脚本执行过程中设置将会不生效。</p></li>
<li><p>在分布式场景下，Dump环境变量需要在调用<code class="docutils literal notranslate"><span class="pre">mindspore.communication.init</span></code>之前配置。</p></li>
</ul>
</li>
<li><p>启动网络训练脚本。</p>
<p>训练启动后，若正确配置了<code class="docutils literal notranslate"><span class="pre">MINDSPORE_DUMP_CONFIG</span></code>环境变量，则会读取配置文件的内容，并按照Dump配置中指定的数据保存路径保存算子数据。
同步模式下，GPU环境如果要Dump数据，必须采用非数据下沉模式（设置<code class="docutils literal notranslate"><span class="pre">model.train</span></code>或<code class="docutils literal notranslate"><span class="pre">DatasetHelper</span></code>中的<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code>参数为<code class="docutils literal notranslate"><span class="pre">False</span></code>），以保证可以获取每个step的Dump数据。
若脚本中都不调用<code class="docutils literal notranslate"><span class="pre">model.train</span></code>或<code class="docutils literal notranslate"><span class="pre">DatasetHelper</span></code>，则默认为非数据下沉模式。使用Dump功能将自动生成最终执行图的IR文件。</p>
<p>可以在训练脚本中设置<code class="docutils literal notranslate"><span class="pre">set_context(reserve_class_name_in_scope=False)</span></code>，避免Dump文件名称过长导致Dump数据文件生成失败。</p>
</li>
<li><p>通过<code class="docutils literal notranslate"><span class="pre">numpy.load</span></code>读取和解析同步Dump数据，参考<span class="xref myst">同步Dump数据文件介绍</span>。</p></li>
</ol>
</section>
<section id="同步dump数据对象目录">
<h3>同步Dump数据对象目录<a class="headerlink" href="#同步dump数据对象目录" title="Permalink to this headline"></a></h3>
<p>启动训练后，同步Dump保存的数据对象包括最终执行图（<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code>文件）以及图中算子的输入和输出数据，数据目录结构如下所示：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{path}/
    - rank_{rank_id}/
        - .dump_metadata/
        - {net_name}/
            - {graph_id}/
                - {iteration_id}/
                    statistic.csv
                    {op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}.{input_output_index}.{slot}.{format}.npy
                - constants/
                    Parameter.data-{data_id}.0.0.{timestamp}.output.0.DefaultFormat.npy
            ...
        - graphs/
            ms_output_trace_code_graph_{graph_id}.pb
            ms_output_trace_code_graph_{graph_id}.ir
        - execution_order/
            ms_execution_order_graph_{graph_id}.csv
            ms_global_execution_order_graph_{graph_id}.csv
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>：<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>配置文件中设置的绝对路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rank_id</span></code>： 逻辑卡号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>：<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>配置文件中设置的网络名称。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">graph_id</span></code>：训练的图标号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration_id</span></code>：训练的轮次。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_type</span></code>：算子类型。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_name</span></code>：算子名称。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">task_id</span></code>：任务标号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">stream_id</span></code>：流标号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">timestamp</span></code>：时间戳。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output_index</span></code>：输入或输出标号，例如<code class="docutils literal notranslate"><span class="pre">output.0</span></code>表示该文件是该算子的第1个输出Tensor的数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">slot</span></code>：slot标号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">format</span></code>: 数据格式。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data_id</span></code>: 常量数据标号。</p></li>
</ul>
<p>对于多图网络，由于存在控制流，某些子图可能不会被执行，Dump只保存执行过的节点，所以graphs目录下<code class="docutils literal notranslate"><span class="pre">.pb</span></code>文件名中的{graph_id}并不一定在{net_name}下存在对应的{graph_id}目录。</p>
<p>只当<code class="docutils literal notranslate"><span class="pre">saved_data</span></code>为”statistic”或者”full”时，才会生成<code class="docutils literal notranslate"><span class="pre">statistic.csv</span></code>，当<code class="docutils literal notranslate"><span class="pre">saved_data</span></code>为”tensor”或者”full”时，才会生成<code class="docutils literal notranslate"><span class="pre">{op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}.{input_output_index}.{slot}.{format}.npy</span></code>命名的完整张量信息。</p>
</section>
<section id="同步dump数据文件介绍">
<h3>同步Dump数据文件介绍<a class="headerlink" href="#同步dump数据文件介绍" title="Permalink to this headline"></a></h3>
<p>同步Dump生成的数据文件是后缀名为<code class="docutils literal notranslate"><span class="pre">.npy</span></code>的文件，文件命名格式为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}.{input_output_index}.{slot}.{format}.npy
</pre></div>
</div>
<p>同步Dump生成的常量数据文件与其他数据文件格式相同，而所有常量数据的{op_type}，{task_id}，{stream_id}，{input_output_index}，{slot}，{format}不变。注意，非Tensor类型数据不会被生成数据文件。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Parameter.data-{data_id}.0.0.{timestamp}.output.0.DefaultFormat.npy
</pre></div>
</div>
<p>可以用Numpy的<code class="docutils literal notranslate"><span class="pre">numpy.load</span></code>接口读取数据。</p>
<p>同步Dump生成的统计数据文件名为<code class="docutils literal notranslate"><span class="pre">statistic.csv</span></code>，此文件存有相同目录下所有落盘张量（文件名为<code class="docutils literal notranslate"><span class="pre">{op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}.{input_output_index}.{slot}.{format}.npy</span></code>）的统计信息。每个张量一行，每行有张量的 Op Type，Op Name，Task ID，Stream ID，Timestamp，IO，Slot，Data Size，Data Type，Shape，Max Value，Min Value，Avg Value，Count，Negative Zero Count，Positive Zero Count，NaN Count，Negative Inf Count，Positive Inf Count，Zero Count。注意，如果用Excel来打开此文件，数据可能无法正确显示。请用<code class="docutils literal notranslate"><span class="pre">vi</span></code>、<code class="docutils literal notranslate"><span class="pre">cat</span></code>等命令查看，或者使用Excel自文本导入csv查看。</p>
<p>同步Dump生成的最终执行图文件后缀名分别为<code class="docutils literal notranslate"><span class="pre">.pb</span></code>和<code class="docutils literal notranslate"><span class="pre">.ir</span></code>，文件命名格式为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ms_output_trace_code_graph_{graph_id}.pb
ms_output_trace_code_graph_{graph_id}.ir
</pre></div>
</div>
<p>其中以<code class="docutils literal notranslate"><span class="pre">.ir</span></code>为后缀的文件可以通过<code class="docutils literal notranslate"><span class="pre">vi</span></code>命令打开查看。</p>
<p>同步Dump生成的节点执行序文件后缀名为<code class="docutils literal notranslate"><span class="pre">.csv</span></code>，文件命名格式为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ms_execution_order_graph_{graph_id}.csv
</pre></div>
</div>
<p>图执行历史文件的后缀为<code class="docutils literal notranslate"><span class="pre">.csv</span></code>，文件名格式为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ms_global_execution_order_graph_{graph_id}.csv
</pre></div>
</div>
<p>此文件记录该图在训练过程中的执行轮次历史。图编译过程中，一张根图可能产生多张子图，但子图与根图具有相同的执行轮次历史。故与图执行序文件不同，此处仅保存根图的图执行历史文件。</p>
<p><code class="docutils literal notranslate"><span class="pre">.dump_metadata</span></code>记录了训练的原信息，其中<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>保存了用户设置的dump配置。</p>
</section>
<section id="同步dump数据分析样例">
<h3>同步Dump数据分析样例<a class="headerlink" href="#同步dump数据分析样例" title="Permalink to this headline"></a></h3>
<p>为了更好地展示使用Dump来保存数据并分析数据的流程，我们提供了一套<a class="reference external" href="https://gitee.com/mindspore/docs/tree/r2.0/docs/sample_code/dump">完整样例脚本</a> ，同步Dump只需要执行 <code class="docutils literal notranslate"><span class="pre">bash</span> <span class="pre">run_sync_dump.sh</span></code>。</p>
<p>在通过Dump功能将脚本对应的图保存到磁盘上后，会产生最终执行图文件<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code>。该文件中保存了对应的图中每个算子的堆栈信息，记录了算子对应的生成脚本。</p>
<p>以<a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.0/docs/sample_code/dump/train_alexnet.py">AlexNet脚本</a>为例 ：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">):</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span>
                     <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                     <span class="n">weight_init</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="n">pad_mode</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">fc_with_initialize</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">weight_variable</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">TruncatedNormal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">AlexNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Alexnet</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlexNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv5</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">MaxPool</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">*</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The construct function.</span>

<span class="sd">        Args:</span>
<span class="sd">           x(int): Input of the network.</span>

<span class="sd">        Returns:</span>
<span class="sd">           Tensor, the output of the network.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv5</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
<span class="o">...</span>
</pre></div>
</div>
<p>如果用户想查看脚本中第175行的代码：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>执行完训练网络后，可以从最终执行图（<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code>文件）中查找到该行代码所对应的多个算子信息，例如Conv2D-op12对应的文件内容如下所示：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  %20(equivoutput) = Conv2D(%17, %19) {instance name: conv2d} primitive_attrs: {IsFeatureMapInputList: (0), kernel_size: (3, 3), mode: 1, out_channel: 384, input_names: [
x, w],    pri_format: NC1HWC0, pad: (0, 0, 0, 0), visited: true, pad_mod: same, format: NCHW,  pad_list: (1, 1, 1, 1), precision_flag: reduce, groups: 1, output_used_num:
(1), stream_id:     0, stride: (1, 1, 1, 1), group: 1, dilation: (1, 1, 1, 1), output_names: [output], IsFeatureMapOutput: true, ms_function_graph: true}
       : (&lt;Tensor[Float32], (32, 256, 13, 13)&gt;, &lt;Tensor[Float32], (384, 256, 3, 3)&gt;) -&gt; (&lt;Tensor[Float32], (32, 384, 13, 13)&gt;)
       : (&lt;Float16xNC1HWC0[const vector][32, 16, 13, 13, 16]&gt;, &lt;Float16xFracZ[const vector][144, 24, 16, 16]&gt;) -&gt; (&lt;Float32xNC1HWC0[const vector][32, 24, 13, 13, 16]&gt;)
       : full_name_with_scope: (Default/network-WithLossCell/_backbone-AlexNet/conv3-Conv2d/Conv2D-op12)
       ...
       # In file ./tain_alexnet.py(175)/        x = self.conv3(x)/
       ...
</pre></div>
</div>
<p>以上所示文件内容的各行所表示的含义如下：</p>
<ul>
<li><p>算子在Host侧（第一行）和Device侧（第二行，有些算子可能不存在）的输入输出情况。从执行图可知，该算子有两个输入（箭头左侧），一个输出（箭头右侧）。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>   : (&lt;Tensor[Float32], (32, 256, 13, 13)&gt;, &lt;Tensor[Float32], (384, 256, 3, 3)&gt;) -&gt; (&lt;Tensor[Float32], (32, 384, 13, 13)&gt;)
   : (&lt;Float16xNC1HWC0[const vector][32, 16, 13, 13, 16]&gt;, &lt;Float16xFracZ[const vector][144, 24, 16, 16]&gt;) -&gt; (&lt;Float32xNC1HWC0[const vector][32, 24, 13, 13, 16]&gt;)
</pre></div>
</div>
</li>
<li><p>算子名称。从执行图可知，该算子在最终执行图中的完整名称为<code class="docutils literal notranslate"><span class="pre">Default/network-WithLossCell/_backbone-AlexNet/conv3-Conv2d/Conv2D-op12</span></code>。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>: (Default/network-WithLossCell/_backbone-AlexNet/conv3-Conv2d/Conv2D-op12)
</pre></div>
</div>
</li>
<li><p>算子对应的训练脚本代码。通过搜索要查询的训练脚本代码，可以找到多个匹配的算子。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># In file {Absolute path of model_zoo}/official/cv/alexnet/src/alexnet.py(175)/        x = self.conv3(x)/
</pre></div>
</div>
</li>
</ul>
<p>通过算子名称和输入输出信息，可以查找到唯一对应的Tensor数据文件。比如，若要查看Conv2D-op12算子的第1个输出数据对应的Dump文件，可获取以下信息：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">operator_name</span></code>：<code class="docutils literal notranslate"><span class="pre">Conv2D-op12</span></code>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output_index</span></code>：<code class="docutils literal notranslate"><span class="pre">output.0</span></code>表示该文件是该算子的第1个输出Tensor的数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">slot</span></code>：0，该算子的输出只有一个slot。</p></li>
</ul>
<p>在Dump保存的数据对象文件目录下搜索到相应的文件名：
<code class="docutils literal notranslate"><span class="pre">Conv2D.Conv2D-op12.0.0.1623124369613540.output.0.DefaultFormat.npy</span></code>。</p>
<p>还原数据的时候，通过执行：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;Conv2D.Conv2D-op12.0.0.1623124369613540.output.0.DefaultFormat.npy&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>生成numpy.array数据。</p>
</section>
</section>
<section id="异步dump">
<h2>异步Dump<a class="headerlink" href="#异步dump" title="Permalink to this headline"></a></h2>
<p>大型网络（如Bert Large）使用同步Dump时会导致内存溢出，MindSpore通过异步Dump提供了大型网络的调试能力。</p>
<section id="异步dump操作步骤">
<h3>异步Dump操作步骤<a class="headerlink" href="#异步dump操作步骤" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>创建配置文件<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>。</p>
<p>JSON文件的名称和位置可以自定义设置。</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;common_dump_settings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;dump_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;/absolute_path&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;net_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ResNet50&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;iteration&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0|5-8|100-120&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;saved_data&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tensor&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;input_output&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;kernels&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;Default/Conv-op12&quot;</span><span class="p">],</span>
<span class="w">        </span><span class="nt">&quot;support_device&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">],</span>
<span class="w">        </span><span class="nt">&quot;op_debug_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;file_format&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;npy&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dump_mode</span></code>：设置成0，表示Dump出该网络中的所有算子数据；设置成1，表示Dump<code class="docutils literal notranslate"><span class="pre">&quot;kernels&quot;</span></code>里面指定的算子数据或算子类型数据；设置成2，表示Dump脚本中通过<code class="docutils literal notranslate"><span class="pre">set_dump</span></code>指定的算子数据，<code class="docutils literal notranslate"><span class="pre">set_dump</span></code>的使用详见<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r2.0/api_python/mindspore/mindspore.set_dump.html">mindspore.set_dump</a> 。开启溢出检测时，此字段的设置失效，Dump只会保存溢出节点的数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>：Dump保存数据的绝对路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>：自定义的网络名称，例如：”ResNet50”。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration</span></code>：指定需要Dump的迭代。类型为str，用“|”分离要保存的不同区间的step的数据。如”0|5-8|100-120”表示Dump第1个，第6个到第9个， 第101个到第121个step的数据。指定“all”，表示Dump所有迭代的数据。PyNative模式开启溢出检测时，必须设置为”all”。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">saved_data</span></code>: 指定Dump的数据。类型为str，取值成”tensor”，表示Dump出完整张量数据；取值成”statistic”，表示只Dump张量的统计信息；取值”full”代表两种都要。异步Dump统计信息只有在<code class="docutils literal notranslate"><span class="pre">file_format</span></code>设置为<code class="docutils literal notranslate"><span class="pre">npy</span></code>时可以成功，若在<code class="docutils literal notranslate"><span class="pre">file_format</span></code>设置为<code class="docutils literal notranslate"><span class="pre">bin</span></code>时选”statistic”或”full”便会错误退出。默认取值为”tensor”。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output</span></code>：设置成0，表示Dump出算子的输入和算子的输出；设置成1，表示Dump出算子的输入；设置成2，表示Dump出算子的输出。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernels</span></code>：该项可以配置两种格式：</p>
<ol class="arabic simple">
<li><p>算子的名称列表。开启IR保存开关<code class="docutils literal notranslate"><span class="pre">set_context(save_graphs=2)</span></code>并执行用例，从生成的IR文件<code class="docutils literal notranslate"><span class="pre">trace_code_graph_{graph_id}</span></code>中获取算子名称。详细说明可以参照教程：<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r2.0/debug/mindir.html#%E5%A6%82%E4%BD%95%E4%BF%9D%E5%AD%98ir">如何保存IR</a>。
需要注意的是，是否设置<code class="docutils literal notranslate"><span class="pre">set_context(save_graphs=2)</span></code>可能会导致同一个算子的id不同，所以在Dump指定算子时要在获取算子名称之后保持这一项设置不变。或者也可以在Dump保存的<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code>文件中获取算子名称，参考<span class="xref myst">同步Dump数据对象目录</span>。</p></li>
<li><p>还可以指定算子类型。当字符串中不带算子scope信息和算子id信息时，后台则认为其为算子类型，例如：”conv”。算子类型的匹配规则为：当发现算子名中包含算子类型字符串时，则认为匹配成功（不区分大小写），例如：”conv” 可以匹配算子 “Conv2D-op1234”、”Conv3D-op1221”。</p></li>
</ol>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">support_device</span></code>：支持的设备，默认设置成0到7即可；在分布式训练场景下，需要dump个别设备上的数据，可以只在<code class="docutils literal notranslate"><span class="pre">support_device</span></code>中指定需要Dump的设备Id。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_debug_mode</span></code>：该属性用于算子溢出调试，设置成0，表示不开启溢出；设置成1，表示开启AiCore溢出检测；设置成2，表示开启Atomic溢出检测；设置成3，表示开启全部溢出检测功能。在Dump数据的时候请设置成0，若设置成其他值，则只会Dump溢出算子的数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">file_format</span></code>: dump数据的文件类型，只支持<code class="docutils literal notranslate"><span class="pre">npy</span></code>和<code class="docutils literal notranslate"><span class="pre">bin</span></code>两种取值。设置成<code class="docutils literal notranslate"><span class="pre">npy</span></code>，则dump出的算子张量数据将为host侧格式的npy文件；设置成<code class="docutils literal notranslate"><span class="pre">bin</span></code>，则dump出的数据将为device侧格式的protobuf文件，需要借助转换工具进行处理，详细步骤请参考<span class="xref myst">异步Dump数据分析样例</span>。默认取值为<code class="docutils literal notranslate"><span class="pre">bin</span></code>。</p></li>
</ul>
</li>
<li><p>设置数据Dump的环境变量。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_DUMP_CONFIG</span><span class="o">=</span><span class="si">${</span><span class="nv">Absolute</span><span class="p"> path of data_dump.json</span><span class="si">}</span>
</pre></div>
</div>
<p>如果Dump配置文件没有设置<code class="docutils literal notranslate"><span class="pre">path</span></code>字段或者设置为空字符串，还需要配置环境变量<code class="docutils literal notranslate"><span class="pre">MS_DIAGNOSTIC_DATA_PATH</span></code>。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MS_DIAGNOSTIC_DATA_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">yyy</span><span class="si">}</span>
</pre></div>
</div>
<p>则“$MS_DIAGNOSTIC_DATA_PATH/debug_dump”就会被当做<code class="docutils literal notranslate"><span class="pre">path</span></code>的值。若Dump配置文件中设置了<code class="docutils literal notranslate"><span class="pre">path</span></code>字段，则仍以该字段的实际取值为准。</p>
<ul class="simple">
<li><p>在网络脚本执行前，设置好环境变量；网络脚本执行过程中设置将会不生效。</p></li>
<li><p>在分布式场景下，Dump环境变量需要在调用<code class="docutils literal notranslate"><span class="pre">mindspore.communication.init</span></code>之前配置。</p></li>
</ul>
</li>
<li><p>执行用例Dump数据。</p>
<p>可以在训练脚本中设置<code class="docutils literal notranslate"><span class="pre">set_context(reserve_class_name_in_scope=False)</span></code>，避免Dump文件名称过长导致Dump数据文件生成失败。</p>
</li>
<li><p>参考<span class="xref myst">异步Dump数据分析样例</span>解析Dump数据文件。</p></li>
</ol>
<p>注意：</p>
<ul class="simple">
<li><p>若需要dump全量或部分算子，则可以修改json配置文件中的<code class="docutils literal notranslate"><span class="pre">dump_mode</span></code>选项为0或1。</p></li>
<li><p>对于通信算子（<code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>、<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>、<code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code>、<code class="docutils literal notranslate"><span class="pre">Broadcast</span></code>、<code class="docutils literal notranslate"><span class="pre">NeighborExchange</span></code>、<code class="docutils literal notranslate"><span class="pre">NeighborExchange2</span></code>、<code class="docutils literal notranslate"><span class="pre">AlltoAll</span></code>），由于在设备上执行时输入地址会被输出覆盖，异步Dump不能直接保存其输入数据，而是会保存其输入算子的输出数据。可以通过ir图查看通信算子的输入算子。</p></li>
<li><p>使用Dump功能将自动生成最终执行图的IR文件。</p></li>
</ul>
</section>
<section id="异步dump数据对象目录">
<h3>异步Dump数据对象目录<a class="headerlink" href="#异步dump数据对象目录" title="Permalink to this headline"></a></h3>
<p>若配置文件中<code class="docutils literal notranslate"><span class="pre">file_format</span></code>值设置为<code class="docutils literal notranslate"><span class="pre">npy</span></code>，则数据对象目录参考<span class="xref myst">同步Dump数据对象目录</span> 。</p>
<p>若未配置<code class="docutils literal notranslate"><span class="pre">file_format</span></code>值或<code class="docutils literal notranslate"><span class="pre">file_format</span></code>值为<code class="docutils literal notranslate"><span class="pre">bin</span></code>，数据对象目录为以下结构。</p>
<p>异步Dump保存的数据对象包括了最终执行图（<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code>文件）以及图中算子的输入和输出数据。 如果开启溢出检测，还会在检测到溢出时保存溢出文件（<code class="docutils literal notranslate"><span class="pre">Opdebug.Node_OpDebug.{task_id}.{stream_id}.{timestamp}</span></code>文件）。</p>
<p>图模式的Dump目录结构如下所示：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{path}/
    - rank_{rank_id}/
        - .dump_metadata/
        - debug_files （仅在动态shape或者非任务下沉场景开启溢出检测时会有）/
            - {iteration_id}/
                Opdebug.Node_OpDebug.{task_id}.{stream_id}.{timestamp}
                ...
        - {net_name}/
            - {graph_id}/
                - {iteration_id}/
                    statistic.csv
                    {op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}
                    Opdebug.Node_OpDebug.{task_id}.{stream_id}.{timestamp} （仅在任务下沉场景开启溢出检测时会有）
                    mapping.csv
                - constants/
                    Parameter.data-{data_id}.0.0.{timestamp}.output.0.DefaultFormat.npy
            ...
        - graphs/
            ms_output_trace_code_graph_{graph_id}.pb
            ms_output_trace_code_graph_{graph_id}.ir
        - execution_order/
            ms_execution_order_graph_{graph_id}.csv
            ms_global_execution_order_graph_{graph_id}.csv
</pre></div>
</div>
<p>PyNative模式的Dump目录结构如下所示：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{path}/
    - rank_{rank_id}/
        - .dump_metadata/
        - debug_files/
            Opdebug.Node_OpDebug.{task_id}.{stream_id}.{timestamp}
            ...
        - {net_name}/
            - {graph_id}/
                - {iteration_id}/
                    statistic.csv
                    {op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}
                    mapping.csv
                - constants/
                    Parameter.data-{data_id}.0.0.{timestamp}.output.0.DefaultFormat.npy
            ...
        - graphs/
            ms_output_trace_code_graph_{graph_id}.pb
            ms_output_trace_code_graph_{graph_id}.ir
        - execution_order/
            ms_execution_order_graph_{graph_id}.csv
            ms_global_execution_order_graph_{graph_id}.csv
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>：<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>配置文件中设置的绝对路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rank_id</span></code>： 逻辑卡号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>：<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>配置文件中设置的网络名称。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">graph_id</span></code>：训练的图标号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration_id</span></code>：训练的轮次。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_type</span></code>：算子类型。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_name</span></code>：算子名称。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">task_id</span></code>：任务标号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">stream_id</span></code>：流标号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">timestamp</span></code>：时间戳。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data_id</span></code>: 常量数据标号。</p></li>
</ul>
<p>由于存在控制流，某些子图可能不会被执行，Dump只保存执行过的节点，所以graphs目录下<code class="docutils literal notranslate"><span class="pre">.pb</span></code>文件名中的{graph_id}并不一定在{net_name}下存在对应的{graph_id}目录。</p>
<p>对于多图网络，例如动态shape的场景，每张卡上所有计算图的轮次统一计数。</p>
<p>如果按命名规则定义的张量文件名称长度超过了OS文件名称长度限制（一般是255个字符），则会将该张量文件重命名为一串随机数字，映射关系会保存在同目录下的“mapping.csv”。</p>
<p>对于PyNative模式，由于没有前向图，只保存了反向图和优化图，可能出现溢出节点找不到对应的图文件的情况。</p>
</section>
<section id="异步dump数据文件介绍">
<h3>异步Dump数据文件介绍<a class="headerlink" href="#异步dump数据文件介绍" title="Permalink to this headline"></a></h3>
<p>若配置文件中<code class="docutils literal notranslate"><span class="pre">file_format</span></code>值设置为<code class="docutils literal notranslate"><span class="pre">npy</span></code>，则数据文件介绍参考<span class="xref myst">同步Dump数据文件介绍</span> 。</p>
<p>若未配置<code class="docutils literal notranslate"><span class="pre">file_format</span></code>值或<code class="docutils literal notranslate"><span class="pre">file_format</span></code>值为<code class="docutils literal notranslate"><span class="pre">bin</span></code>，启动训练后，异步Dump生成的原始数据文件或溢出检测生成的溢出文件是protobuf格式的文件，需要用到海思Run包中自带的数据解析工具进行解析，详见<a class="reference external" href="https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/63RC1alpha002/developmenttools/devtool/atlasaccuracy_16_0061.html">如何查看dump数据文件</a> 。</p>
<p>数据在Device侧的格式可能和Host侧计算图中的定义不同，异步Dump的数据格式为Device侧格式，如果想要转为Host侧格式，可以参考<a class="reference external" href="https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/63RC1alpha002/developmenttools/devtool/atlasaccuracy_16_0060.html">如何进行dump数据文件Format转换</a> 。</p>
<p>异步Dump生成的数据文件是<code class="docutils literal notranslate"><span class="pre">bin</span></code>文件时，文件命名格式为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}
</pre></div>
</div>
<p>以AlexNet网络的Conv2D-op12为例：<code class="docutils literal notranslate"><span class="pre">Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802</span></code>，其中<code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>是<code class="docutils literal notranslate"><span class="pre">{op_type}</span></code>，<code class="docutils literal notranslate"><span class="pre">Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12</span></code>是<code class="docutils literal notranslate"><span class="pre">{op_name}</span></code>，<code class="docutils literal notranslate"><span class="pre">2</span></code>是<code class="docutils literal notranslate"><span class="pre">{task_id}</span></code>，<code class="docutils literal notranslate"><span class="pre">7</span></code>是<code class="docutils literal notranslate"><span class="pre">{stream_id}</span></code>，<code class="docutils literal notranslate"><span class="pre">161243956333802</span></code>是<code class="docutils literal notranslate"><span class="pre">{timestamp}</span></code>。</p>
<p>如果<code class="docutils literal notranslate"><span class="pre">op_type</span></code>和<code class="docutils literal notranslate"><span class="pre">op_name</span></code>中出现了“.”、“/”、“\”、空格时，会转换为下划线表示。</p>
<p>Dump生成的原始数据文件也可以使用MindSpore Insight的数据解析工具DumpParser解析，DumpParser的使用方式详见<a class="reference external" href="https://gitee.com/mindspore/mindinsight/tree/r2.0/mindinsight/parser">DumpParser介绍</a> 。MindSpore Insight解析出来的数据格式与同步dump的数据格式完全相同。</p>
<p>若配置<code class="docutils literal notranslate"><span class="pre">file_format</span></code>值为<code class="docutils literal notranslate"><span class="pre">npy</span></code>，则启用异步dump生成的数据文件命名规则与同步Dump相同，可以参考<span class="xref myst">同步Dump数据文件介绍</span>，溢出检测生成的溢出文件是<code class="docutils literal notranslate"><span class="pre">json</span></code>格式，溢出文件内容解析可参考<a class="reference external" href="https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/63RC1alpha002/tfmoddevg/tfmigr1/atlasmprtg_13_9073.html">解析算子溢出数据文件</a> 。</p>
<p>选项<code class="docutils literal notranslate"><span class="pre">saved_data</span></code>只有在<code class="docutils literal notranslate"><span class="pre">file_format</span></code>为”npy”的时候生效。如<code class="docutils literal notranslate"><span class="pre">saved_data</span></code>是”statistic”或者”full”。张量统计数据会落盘到<code class="docutils literal notranslate"><span class="pre">statistic.csv</span></code>。如<code class="docutils literal notranslate"><span class="pre">saved_data</span></code>是”tensor”或者”full”完整张量数据会落盘到<code class="docutils literal notranslate"><span class="pre">{op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}.{input_output_index}.{slot}.{format}.npy</span></code>。<code class="docutils literal notranslate"><span class="pre">statistic.csv</span></code>的格式与同步Dump相同，可以参考<span class="xref myst">同步Dump数据文件介绍</span>。</p>
<p>异步Dump生成的常量数据文件，最终执行图文件和执行序文件命名规则与同步Dump相同，可以参考<span class="xref myst">同步Dump数据文件介绍</span>。</p>
</section>
<section id="异步dump数据分析样例">
<h3>异步Dump数据分析样例<a class="headerlink" href="#异步dump数据分析样例" title="Permalink to this headline"></a></h3>
<p>为了更好地展示使用Dump来保存数据并分析数据的流程，我们提供了一套<a class="reference external" href="https://gitee.com/mindspore/docs/tree/r2.0/docs/sample_code/dump">完整样例脚本</a> ，异步Dump执行 <code class="docutils literal notranslate"><span class="pre">bash</span> <span class="pre">run_async_dump.sh</span></code> 即可。用户可以自行下载体验。</p>
<p>通过异步Dump的功能，获取到算子异步Dump生成的数据文件。如果异步Dump配置文件中设置的<code class="docutils literal notranslate"><span class="pre">file_format</span></code>为”npy”，可以跳过以下步骤中的1、2，如果没有设置<code class="docutils literal notranslate"><span class="pre">file_format</span></code>，或者设置为”bin”，需要先转换成<code class="docutils literal notranslate"><span class="pre">.npy</span></code>格式的文件。</p>
<ol class="arabic">
<li><p>使用run包中提供的<code class="docutils literal notranslate"><span class="pre">msaccucmp.py</span></code>解析Dump出来的文件。不同的环境上<code class="docutils literal notranslate"><span class="pre">msaccucmp.py</span></code>文件所在的路径可能不同，可以通过<code class="docutils literal notranslate"><span class="pre">find</span></code>命令进行查找：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>find<span class="w"> </span><span class="si">${</span><span class="nv">run_path</span><span class="si">}</span><span class="w"> </span>-name<span class="w"> </span><span class="s2">&quot;msaccucmp.py&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">run_path</span></code>：run包的安装路径。</p></li>
</ul>
</li>
<li><p>找到<code class="docutils literal notranslate"><span class="pre">msaccucmp.py</span></code>后，到<code class="docutils literal notranslate"><span class="pre">/absolute_path</span></code>目录下，运行如下命令解析Dump数据：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span><span class="si">${</span><span class="nv">The</span><span class="p"> absolute path of msaccucmp.py</span><span class="si">}</span><span class="w"> </span>convert<span class="w"> </span>-d<span class="w"> </span><span class="o">{</span>file<span class="w"> </span>path<span class="w"> </span>of<span class="w"> </span>dump<span class="o">}</span><span class="w"> </span>-out<span class="w"> </span><span class="o">{</span>file<span class="w"> </span>path<span class="w"> </span>of<span class="w"> </span>output<span class="o">}</span>
</pre></div>
</div>
<p>{file path of dump} 可以是单个<code class="docutils literal notranslate"><span class="pre">.bin</span></code>文件的路径，也可以是包含<code class="docutils literal notranslate"><span class="pre">.bin</span></code>文件的文件夹路径。</p>
<p>若需要转换数据格式，可参考使用说明链接<a class="reference external" href="https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/63RC1alpha002/developmenttools/devtool/atlasaccuracy_16_0060.html">https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/63RC1alpha002/developmenttools/devtool/atlasaccuracy_16_0060.html</a> 。</p>
<p>如Dump生成的数据文件为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802
</pre></div>
</div>
<p>则执行：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3.7.5<span class="w"> </span>msaccucmp.py<span class="w"> </span>convert<span class="w"> </span>-d<span class="w"> </span>/path/to/Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802<span class="w"> </span>-out<span class="w"> </span>./output<span class="w"> </span>-f<span class="w"> </span>NCHW<span class="w"> </span>-t<span class="w"> </span>npy
</pre></div>
</div>
<p>则可以在<code class="docutils literal notranslate"><span class="pre">./output</span></code>下生成该算子的所有输入输出数据。每个数据以<code class="docutils literal notranslate"><span class="pre">.npy</span></code>后缀的文件保存，数据格式为<code class="docutils literal notranslate"><span class="pre">NCHW</span></code>。生成结果如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802.input.0.32x256x13x13.npy
Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802.input.1.384x256x3x3.npy
Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802.output.0.32x384x13x13.npy
</pre></div>
</div>
<p>在文件名的末尾可以看到该文件是算子的第几个输入或输出，以及数据的维度信息。例如，通过第一个<code class="docutils literal notranslate"><span class="pre">.npy</span></code>文件名</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802.input.0.32x256x13x13.npy
</pre></div>
</div>
<p>可知该文件是算子的第0个输入，数据的维度信息是<code class="docutils literal notranslate"><span class="pre">32x256x13x13</span></code>。</p>
</li>
<li><p>通过<code class="docutils literal notranslate"><span class="pre">numpy.load(&quot;file_name&quot;)</span></code>可以读取到对应数据。例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3-Conv2d_Conv2D-op12.2.7.161243956333802.input.0.32x256x13x13.npy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindir.html" class="btn btn-neutral float-left" title="查看中间文件" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="pynative_debug.html" class="btn btn-neutral float-right" title="PyNative 调试" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>