<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>回调机制 Callback &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      
      
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" /><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script><script src="../../_static/jquery.js"></script>
        <script src="../../_static/js/theme.js"></script><script src="../../_static/underscore.js"></script><script src="../../_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/mathjax/MathJax-3.2.2/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="模块自定义" href="../modules.html" />
    <link rel="prev" title="Model基本使用" href="model.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">初学教程</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introduction.html">基本介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/quick_start.html">快速入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/tensor.html">张量 Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/dataset.html">数据集 Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/transforms.html">数据变换 Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/model.html">网络构建</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/autograd.html">函数式自动微分</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/train.html">模型训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/save_load.html">保存与加载</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">进阶教程</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../model.html">高阶封装：Model</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="metric.html">评价指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="model.html">Model基本使用</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">回调机制 Callback</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#callback介绍">Callback介绍</a></li>
<li class="toctree-l3"><a class="reference internal" href="#常用的内置回调函数">常用的内置回调函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#modelcheckpoint">ModelCheckpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="#lossmonitor">LossMonitor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#timemonitor">TimeMonitor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#自定义回调机制">自定义回调机制</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#自定义终止训练">自定义终止训练</a></li>
<li class="toctree-l4"><a class="reference internal" href="#自定义阈值保存模型">自定义阈值保存模型</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">模块自定义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset.html">高级数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../derivation.html">高级自动微分</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compute_graph.html">计算图</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../model.html">高阶封装：Model</a> &raquo;</li>
      <li>回调机制 Callback</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/advanced/model/callback.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="回调机制-callback">
<h1>回调机制 Callback<a class="headerlink" href="#回调机制-callback" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://openi.pcl.ac.cn/MindSpore/docs/src/branch/r1.10/tutorials/source_zh_cn/advanced/model/callback.ipynb?card=2&amp;image=MindSpore1.8.1"><img alt="在OpenI运行" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/resource/_static/logo_openi.png" /></a> <a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/r1.10/tutorials/zh_cn/advanced/model/mindspore_callback.ipynb"><img alt="下载Notebook" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/resource/_static/logo_notebook.png" /></a>  <a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/r1.10/tutorials/zh_cn/advanced/model/mindspore_callback.py"><img alt="下载样例代码" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/resource/_static/logo_download_code.png" /></a>  <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.10/tutorials/source_zh_cn/advanced/model/callback.ipynb"><img alt="查看源文件" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/resource/_static/logo_source.png" /></a></p>
<p>在深度学习训练过程中，为及时掌握网络模型的训练状态、实时观察网络模型各参数的变化情况和实现训练过程中用户自定义的一些操作，MindSpore提供了回调机制（Callback）来实现上述功能。</p>
<p>Callback回调机制一般用在网络模型训练过程<code class="docutils literal notranslate"><span class="pre">Model.train</span></code>中，MindSpore的<code class="docutils literal notranslate"><span class="pre">Model</span></code>会按照Callback列表<code class="docutils literal notranslate"><span class="pre">callbacks</span></code>顺序执行回调函数，用户可以通过设置不同的回调类来实现在训练过程中或者训练后执行的功能。</p>
<blockquote>
<div><p>更多内置回调类的信息及使用方式请参考<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.10/api_python/mindspore/mindspore.Callback.html#mindspore.Callback">API文档</a>。</p>
</div></blockquote>
<section id="callback介绍">
<h2>Callback介绍<a class="headerlink" href="#callback介绍" title="Permalink to this headline"></a></h2>
<p>当聊到回调Callback的时候，大部分用户都会觉得很难理解，是不是需要堆栈或者特殊的调度方式，实际上我们简单的理解回调：</p>
<p>假设函数A有一个参数，这个参数是个函数B，当函数A执行完以后执行函数B，那么这个过程就叫回调。</p>
<p><code class="docutils literal notranslate"><span class="pre">Callback</span></code>是回调的意思，MindSpore中的回调函数实际上不是一个函数而是一个类，用户可以使用回调机制来<strong>观察训练过程中网络内部的状态和相关信息，或在特定时期执行特定动作</strong>。</p>
<p>例如监控损失函数Loss、保存模型参数ckpt、动态调整参数lr、提前终止训练任务等。下面我们继续以手写体识别模型为例，介绍常见的内置回调函数和自定义回调函数。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">download</span> <span class="kn">import</span> <span class="n">download</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset</span> <span class="kn">import</span> <span class="n">vision</span><span class="p">,</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">MnistDataset</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">Normal</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/&quot;</span> \
      <span class="s2">&quot;notebook/datasets/MNIST_Data.zip&quot;</span>

<span class="c1"># 下载MNIST数据集</span>
<span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="s2">&quot;./&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;zip&quot;</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># 数据处理</span>
<span class="k">def</span> <span class="nf">proc_dataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">MnistDataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># define map operations</span>
    <span class="n">image_transforms</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.3081</span><span class="p">,)),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="p">]</span>

    <span class="n">label_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">label_transform</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">)</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">image_transforms</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">)</span>
    <span class="n">mnist_ds</span> <span class="o">=</span> <span class="n">mnist_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mnist_ds</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">proc_dataset</span><span class="p">(</span><span class="s1">&#39;MNIST_Data/train&#39;</span><span class="p">)</span>

<span class="c1"># 定义LeNet-5网络模型</span>
<span class="k">class</span> <span class="nc">LeNet5</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_class</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet5</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_channel</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="n">num_class</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">create_model</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
    <span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
    <span class="n">net_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">net_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">net_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">()})</span>
    <span class="k">return</span> <span class="n">trainer</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Downloading data from https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/MNIST_Data.zip (10.3 MB)

file_sizes: 100%|██████████████████████████| 10.8M/10.8M [00:00&lt;00:00, 23.8MB/s]
Extracting zip file...
Successfully downloaded / unzipped to ./
</pre></div></div>
</div>
</section>
<section id="常用的内置回调函数">
<h2>常用的内置回调函数<a class="headerlink" href="#常用的内置回调函数" title="Permalink to this headline"></a></h2>
<p>MindSpore提供<code class="docutils literal notranslate"><span class="pre">Callback</span></code>能力，支持用户在训练/推理的特定阶段，插入自定义的操作。</p>
<section id="modelcheckpoint">
<h3>ModelCheckpoint<a class="headerlink" href="#modelcheckpoint" title="Permalink to this headline"></a></h3>
<p>用于保存训练后的网络模型和参数，方便进行再推理或再训练，MindSpore提供了<a class="reference external" href="https://mindspore.cn/docs/zh-CN/r1.10/api_python/mindspore/mindspore.ModelCheckpoint.html?highlight=modelcheckpoint#mindspore.ModelCheckpoint">ModelCheckpoint</a>接口，一般与配置保存信息接口<a class="reference external" href="https://mindspore.cn/docs/zh-CN/r1.10/api_python/mindspore/mindspore.CheckpointConfig.html#mindspore.CheckpointConfig">CheckpointConfig</a>配合使用。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">ModelCheckpoint</span>

<span class="c1"># 设置保存模型的配置信息</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="mi">1875</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="c1"># 实例化保存模型回调接口，定义保存路径和前缀名</span>
<span class="n">ckpt_callback</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;mnist&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;./checkpoint&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

<span class="c1"># 开始训练，加载保存模型和参数回调函数</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ckpt_callback</span><span class="p">])</span>
</pre></div>
</div>
</div>
<p>上面代码运行后，生成的Checkpoint文件目录结构如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./checkpoint/
├── mnist-1_1875.ckpt # 保存参数文件
└── mnist-graph.meta # 编译后的计算图
</pre></div>
</div>
</section>
<section id="lossmonitor">
<h3>LossMonitor<a class="headerlink" href="#lossmonitor" title="Permalink to this headline"></a></h3>
<p>用于监控训练或测试过程中的损失函数值Loss变化情况，可设置<code class="docutils literal notranslate"><span class="pre">per_print_times</span></code>控制打印Loss值的间隔。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">LossMonitor</span>

<span class="n">loss_monitor</span> <span class="o">=</span> <span class="n">LossMonitor</span><span class="p">(</span><span class="mi">1875</span><span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">loss_monitor</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
epoch: 1 step: 1875, loss is 0.008795851841568947
epoch: 2 step: 1875, loss is 0.007240554317831993
epoch: 3 step: 1875, loss is 0.0036914246156811714
</pre></div></div>
</div>
<p>训练场景下，LossMonitor监控训练的Loss值；边训练边推理场景下，监控训练的Loss值和推理的Metrics值。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_dataset</span> <span class="o">=</span> <span class="n">proc_dataset</span><span class="p">(</span><span class="s1">&#39;MNIST_Data/test&#39;</span><span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">loss_monitor</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
epoch: 1 step: 1875, loss is 0.0026960039976984262
Eval result: epoch 1, metrics: {&#39;Accuracy&#39;: 0.9888822115384616}
epoch: 2 step: 1875, loss is 0.00038617433165200055
Eval result: epoch 2, metrics: {&#39;Accuracy&#39;: 0.9877804487179487}
</pre></div></div>
</div>
</section>
<section id="timemonitor">
<h3>TimeMonitor<a class="headerlink" href="#timemonitor" title="Permalink to this headline"></a></h3>
<p>用于监控训练或测试过程的执行时间。可设置<code class="docutils literal notranslate"><span class="pre">data_size</span></code>控制打印执行时间的间隔。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">TimeMonitor</span>

<span class="n">time_monitor</span> <span class="o">=</span> <span class="n">TimeMonitor</span><span class="p">(</span><span class="mi">1875</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">time_monitor</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train epoch time: 3876.302 ms, per step time: 2.067 ms
</pre></div></div>
</div>
</section>
</section>
<section id="自定义回调机制">
<h2>自定义回调机制<a class="headerlink" href="#自定义回调机制" title="Permalink to this headline"></a></h2>
<p>MindSpore不仅有功能强大的内置回调函数，当用户有自己的特殊需求时，还可以基于<code class="docutils literal notranslate"><span class="pre">Callback</span></code>基类自定义回调类。</p>
<p>用户可以基于<code class="docutils literal notranslate"><span class="pre">Callback</span></code>基类，根据自身的需求，实现自定义<code class="docutils literal notranslate"><span class="pre">Callback</span></code>。<code class="docutils literal notranslate"><span class="pre">Callback</span></code>基类定义如下所示：</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Callback</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Callback base class&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called once before the network executing.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called before each epoch beginning.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called after each epoch finished.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called before each step beginning.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called after each step finished.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called once after network training.&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<p>回调机制可以把训练过程中的重要信息记录下来，通过把一个字典类型变量<code class="docutils literal notranslate"><span class="pre">RunContext.original_args()</span></code>，传递给Callback对象，使得用户可以在各个自定义的Callback中获取到相关属性，执行自定义操作，也可以自定义其他变量传递给<code class="docutils literal notranslate"><span class="pre">RunContext.original_args()</span></code>对象。</p>
<p><code class="docutils literal notranslate"><span class="pre">RunContext.original_args()</span></code>中的常用属性有：</p>
<ul class="simple">
<li><p>epoch_num：训练的epoch的数量</p></li>
<li><p>batch_num：一个epoch中step的数量</p></li>
<li><p>cur_epoch_num：当前的epoch数</p></li>
<li><p>cur_step_num：当前的step数</p></li>
<li><p>loss_fn：损失函数</p></li>
<li><p>optimizer：优化器</p></li>
<li><p>train_network：训练的网络</p></li>
<li><p>train_dataset：训练的数据集</p></li>
<li><p>net_outputs：网络的输出结果</p></li>
<li><p>parallel_mode：并行模式</p></li>
<li><p>list_callback：所有的Callback函数</p></li>
</ul>
<p>通过下面两个场景，我们可以增加对自定义Callback回调机制功能的了解。</p>
<section id="自定义终止训练">
<h3>自定义终止训练<a class="headerlink" href="#自定义终止训练" title="Permalink to this headline"></a></h3>
<p>实现在规定时间内终止训练功能。用户可以设定时间阈值，当训练时间达到这个阈值后就终止训练过程。</p>
<p>下面代码中，通过<code class="docutils literal notranslate"><span class="pre">run_context.original_args</span></code>方法可以获取到<code class="docutils literal notranslate"><span class="pre">cb_params</span></code>字典，字典里会包含前文描述的主要属性信息。</p>
<p>同时可以对字典内的值进行修改和添加，在<code class="docutils literal notranslate"><span class="pre">begin</span></code>函数中定义一个<code class="docutils literal notranslate"><span class="pre">init_time</span></code>对象传递给<code class="docutils literal notranslate"><span class="pre">cb_params</span></code>字典。每个数据迭代结束<code class="docutils literal notranslate"><span class="pre">step_end</span></code>之后会进行判断，当训练时间大于设置的时间阈值时，会向run_context传递终止训练的信号，提前终止训练，并打印当前的epoch、step、loss的值。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Callback</span>

<span class="k">class</span> <span class="nc">StopTimeMonitor</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_time</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;定义初始化过程&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StopTimeMonitor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">run_time</span> <span class="o">=</span> <span class="n">run_time</span>            <span class="c1"># 定义执行时间</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;开始训练时的操作&quot;&quot;&quot;</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">cb_params</span><span class="o">.</span><span class="n">init_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>   <span class="c1"># 获取当前时间戳作为开始训练时间</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Begin training, time is: </span><span class="si">{</span><span class="n">cb_params</span><span class="o">.</span><span class="n">init_time</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;每个step结束后执行的操作&quot;&quot;&quot;</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">epoch_num</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span>  <span class="c1"># 获取epoch值</span>
        <span class="n">step_num</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span>    <span class="c1"># 获取step值</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">net_outputs</span>         <span class="c1"># 获取损失值loss</span>
        <span class="n">cur_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>               <span class="c1"># 获取当前时间戳</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">cur_time</span> <span class="o">-</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">init_time</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_time</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End training, time: </span><span class="si">{</span><span class="n">cur_time</span><span class="si">}</span><span class="s2">, epoch: </span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="s2">, step: </span><span class="si">{</span><span class="n">step_num</span><span class="si">}</span><span class="s2">, loss:</span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">run_context</span><span class="o">.</span><span class="n">request_stop</span><span class="p">()</span>       <span class="c1"># 停止训练</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">proc_dataset</span><span class="p">(</span><span class="s1">&#39;MNIST_Data/train&#39;</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LossMonitor</span><span class="p">(),</span> <span class="n">StopTimeMonitor</span><span class="p">(</span><span class="mi">4</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Begin training, time is: 1673515004.6783535
epoch: 1 step: 1875, loss is 0.0006050781812518835
End training, time: 1673515009.1824663, epoch: 1, step: 1875, loss:0.0006050782
</pre></div></div>
</div>
<p>从上面的打印结果可以看出，运行时间到达了阈值后就结束了训练。</p>
</section>
<section id="自定义阈值保存模型">
<h3>自定义阈值保存模型<a class="headerlink" href="#自定义阈值保存模型" title="Permalink to this headline"></a></h3>
<p>该回调机制实现当loss小于设定的阈值时，保存网络模型权重ckpt文件。</p>
<p>示例代码如下：</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">save_checkpoint</span>

<span class="c1"># 定义保存ckpt文件的回调接口</span>
<span class="k">class</span> <span class="nc">SaveCkptMonitor</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;定义初始化过程&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SaveCkptMonitor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span>  <span class="c1"># 定义损失值阈值</span>

    <span class="k">def</span> <span class="nf">on_train_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;定义step结束时的执行操作&quot;&quot;&quot;</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">cur_loss</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">net_outputs</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span> <span class="c1"># 获取当前损失值</span>

        <span class="c1"># 如果当前损失值小于设定的阈值就停止训练</span>
        <span class="k">if</span> <span class="n">cur_loss</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">:</span>
            <span class="c1"># 自定义保存文件名</span>
            <span class="n">file_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;./checkpoint/</span><span class="si">{</span><span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span><span class="si">}</span><span class="s2">.ckpt&quot;</span>
            <span class="c1"># 保存网络模型</span>
            <span class="n">save_checkpoint</span><span class="p">(</span><span class="n">save_obj</span><span class="o">=</span><span class="n">cb_params</span><span class="o">.</span><span class="n">train_network</span><span class="p">,</span> <span class="n">ckpt_file_name</span><span class="o">=</span><span class="n">file_name</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Saved checkpoint, loss:</span><span class="si">{:8.7f}</span><span class="s2">, current step num:</span><span class="si">{:4}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cur_loss</span><span class="p">,</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span><span class="p">))</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">proc_dataset</span><span class="p">(</span><span class="s1">&#39;MNIST_Data/train&#39;</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LossMonitor</span><span class="p">(),</span> <span class="n">SaveCkptMonitor</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
epoch: 1 step: 1875, loss is 0.15191984176635742
epoch: 2 step: 1875, loss is 0.14701086282730103
epoch: 3 step: 1875, loss is 0.0020134493242949247
Saved checkpoint, loss:0.0020134, current step num:5625.
epoch: 4 step: 1875, loss is 0.018305214121937752
epoch: 5 step: 1875, loss is 0.00019801077723968774
Saved checkpoint, loss:0.0001980, current step num:9375.
</pre></div></div>
</div>
<p>最终，损失值小于设定阈值的网络权重被保存在<code class="docutils literal notranslate"><span class="pre">./checkpoint/</span></code>目录下。</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="model.html" class="btn btn-neutral float-left" title="Model基本使用" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../modules.html" class="btn btn-neutral float-right" title="模块自定义" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>