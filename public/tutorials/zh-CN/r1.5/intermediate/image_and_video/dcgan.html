<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>深度卷积对抗生成网络 &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="自然语言" href="../../text.html" />
    <link rel="prev" title="对抗示例生成" href="adversarial_example_generation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">入门教程</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">基本介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quick_start.html">初学入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor.html">张量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dataset.html">数据加载及处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model.html">建立神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autograd.html">自动微分</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization.html">训练模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../save_load_model.html">保存及加载模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linear_regression.html">简单线性函数拟合</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">进阶教程</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../mid_low_level_api.html">中低阶API实现深度学习</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data.html">高级数据集管理</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../image_and_video.html">图像处理</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="transfer_learning.html">图像分类迁移学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="adversarial_example_generation.html">对抗示例生成</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">深度卷积对抗生成网络</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#概述">概述</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#GAN（生成对抗网络）">GAN（生成对抗网络）</a></li>
<li class="toctree-l4"><a class="reference internal" href="#DCGAN（深度卷积对抗生成网络）">DCGAN（深度卷积对抗生成网络）</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#准备环节">准备环节</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#导入模块">导入模块</a></li>
<li class="toctree-l4"><a class="reference internal" href="#配置环境">配置环境</a></li>
<li class="toctree-l4"><a class="reference internal" href="#准备数据">准备数据</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#数据处理">数据处理</a></li>
<li class="toctree-l3"><a class="reference internal" href="#创建网络">创建网络</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#权重初始化">权重初始化</a></li>
<li class="toctree-l4"><a class="reference internal" href="#生成器">生成器</a></li>
<li class="toctree-l4"><a class="reference internal" href="#判别器">判别器</a></li>
<li class="toctree-l4"><a class="reference internal" href="#连接网络和损失函数">连接网络和损失函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="#损失函数和优化器">损失函数和优化器</a></li>
<li class="toctree-l4"><a class="reference internal" href="#训练">训练</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#结果">结果</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../text.html">自然语言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pynative_mode_and_graph_mode.html">动态图与静态图</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed_training.html">分布式训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inference_and_deploy.html">推理与部署</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../image_and_video.html">图像处理</a> &raquo;</li>
      <li>深度卷积对抗生成网络</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/intermediate/image_and_video/dcgan.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="深度卷积对抗生成网络">
<h1>深度卷积对抗生成网络<a class="headerlink" href="#深度卷积对抗生成网络" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">进阶</span></code> <code class="docutils literal notranslate"><span class="pre">计算机视觉</span></code> <code class="docutils literal notranslate"><span class="pre">全流程</span></code></p>
<p><a class="reference external" href="https://authoring-modelarts-cnnorth4.huaweicloud.com/console/lab?share-url-b64=aHR0cHM6Ly9taW5kc3BvcmUtd2Vic2l0ZS5vYnMuY24tbm9ydGgtNC5teWh1YXdlaWNsb3VkLmNvbS9ub3RlYm9vay9yMS41L3R1dG9yaWFscy96aF9jbi9taW5kc3BvcmVfZGNnYW4uaXB5bmI=&amp;imageid=59a6e9f5-93c0-44dd-85b0-82f390c5d53b"><img alt="image0" src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_modelarts.png" /></a> <a class="reference external" href="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/r1.5/tutorials/zh_cn/mindspore_dcgan.ipynb"><img alt="image1" src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_notebook.png" /></a> <a class="reference external" href="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/r1.5/tutorials/zh_cn/mindspore_dcgan.py"><img alt="image2" src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_download_code.png" /></a> <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.5/tutorials/source_zh_cn/intermediate/image_and_video/dcgan.ipynb"><img alt="image3" src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source.png" /></a></p>
<section id="概述">
<h2>概述<a class="headerlink" href="#概述" title="Permalink to this headline"></a></h2>
<section id="GAN（生成对抗网络）">
<h3>GAN（生成对抗网络）<a class="headerlink" href="#GAN（生成对抗网络）" title="Permalink to this headline"></a></h3>
<p>生成对抗网络（GAN, Generative Adversarial Networks ）是一种深度学习模型，是近年来复杂分布上无监督学习最具前景的方法之一。最初，GAN由Ian Goodfellow 于2014年发明，并在论文<a class="reference external" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">Generative Adversarial
Nets</a>中首次进行了描述。GAN由两个不同的模型组成：<em>生成器</em>和<em>判别器</em>。生成器的任务是生成看起来像训练图像的“假”图像。判别器需要判断从生成器输出的图像是真实的训练图像还是生成的假图像。在训练过程中，生成器会不断尝试通过生成更好的假图像来骗过判别器，而判别器在这过程中也会逐步提升判别能力。这种博弈的平衡点是，当生成器生成的假图像看起来像训练数据时，判别器拥有50%的真假判断置信度。</p>
<blockquote>
<div><p>本篇基于GPU/Ascend环境运行。</p>
</div></blockquote>
<p>在教程开始前，首先定义一些在整个过程中需要用到的符号：</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span>：代表图像的数据。</p></li>
<li><p><span class="math notranslate nohighlight">\(D(x)\)</span>：判别器网络，给出图像判定为真实图像的概率，其中<span class="math notranslate nohighlight">\(x\)</span>来自于训练数据而非生成器。 由于我们在判别过程中需要处理图像，因此要为<span class="math notranslate nohighlight">\(D(x)\)</span>提供CHW格式且大小为3x64x64的图像。当<span class="math notranslate nohighlight">\(x\)</span>来自训练数据时，<span class="math notranslate nohighlight">\(D(x)\)</span>数值应该为高，而当<span class="math notranslate nohighlight">\(x\)</span>来自生成器时，<span class="math notranslate nohighlight">\(D(x)\)</span>数值应该为低。 因此<span class="math notranslate nohighlight">\(D(x)\)</span>也可以被认为是传统的二分类器。</p></li>
</ul>
<p>接下来我们来定义生成器的表示方法：</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(z\)</span>：标准正态分布中提取出的隐向量。</p></li>
<li><p><span class="math notranslate nohighlight">\(G(z)\)</span>：表示将隐向量<span class="math notranslate nohighlight">\(z\)</span>映射到数据空间的生成器函数。</p>
<p>函数<span class="math notranslate nohighlight">\(G(z)\)</span>的目标是将一个随机高斯噪声<span class="math notranslate nohighlight">\(z\)</span>通过一个生成网络生成一个和真实数据分布<span class="math notranslate nohighlight">\(pdata(x)\)</span>差不多的数据分布，其中<span class="math notranslate nohighlight">\(θ\)</span>是网络参数，我们希望找到<span class="math notranslate nohighlight">\(θ\)</span>使得<span class="math notranslate nohighlight">\(pG(x;θ)\)</span>和<span class="math notranslate nohighlight">\(pdata(x)\)</span>尽可能的接近。</p>
</li>
<li><p><span class="math notranslate nohighlight">\(D(G(z))\)</span>是生成器<span class="math notranslate nohighlight">\(G\)</span>生成的假图像被判定为真实图像的概率。</p></li>
</ul>
<p>如<a class="reference external" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">Goodfellow 的论文</a>中所述，<code class="docutils literal notranslate"><span class="pre">D</span></code>和<code class="docutils literal notranslate"><span class="pre">G</span></code>在进行一场博弈，<code class="docutils literal notranslate"><span class="pre">D</span></code>想要最大程度的正确分类真图像与假图像，也就是参数<span class="math notranslate nohighlight">\(log D(x)\)</span>；而<code class="docutils literal notranslate"><span class="pre">G</span></code>试图欺骗<code class="docutils literal notranslate"><span class="pre">D</span></code>来最小化假图像被识别到的概率，也就是参数<span class="math notranslate nohighlight">\(log(1−D(G(z)))\)</span>。GAN的损失函数为：</p>
<div class="math notranslate nohighlight">
\[\min_{G}\max_{D}V(D,G)=E_{x\sim_Pdata(x)}[log(D(x))]+E_{z\sim_Pz(z)}[log(1-D(G(z)))]\]</div>
<p>从理论上讲，此博弈游戏的平衡点是<span class="math notranslate nohighlight">\(pG(x;θ) = pdata(x)\)</span>，此时判别器会随机猜测输入是真图像还是假图像。然而，GAN的收敛可行性仍在研究当中，在实际场景中模型并不会被训练到这一步。</p>
</section>
<section id="DCGAN（深度卷积对抗生成网络）">
<h3>DCGAN（深度卷积对抗生成网络）<a class="headerlink" href="#DCGAN（深度卷积对抗生成网络）" title="Permalink to this headline"></a></h3>
<p>DCGAN是上述GAN的直接扩展。不同之处在于，DCGAN会分别在判别器和生成器中使用卷积和卷积转置层。它最早由Radford等人在论文<a class="reference external" href="https://arxiv.org/pdf/1511.06434.pdf">Unsupervised Representation Learning With Deep Convolutional Generative Adversarial
Networks</a>中进行描述。判别器由分层的卷积层、BatchNorm层和LeakyReLU激活层组成。输入是3x64x64的图像，输出是该图像为真图像的概率。生成器则是由转置卷积层、BatchNorm层和ReLU激活层组成。输入是标准正态分布中提取出的隐向量<span class="math notranslate nohighlight">\(z\)</span>，输出是3x64x64的RGB图像。在下面的教程中，提供了有关如何设置优化器、如何计算损失函数以及如何初始化模型权重的说明。</p>
<p>本教程将使用真实名人的照片来训练一个生成对抗网络（GAN），接着产生虚假名人图片。</p>
<p>为了节省运行时间，建议用户使用GPU/Ascend来运行本实验。</p>
</section>
</section>
<section id="准备环节">
<h2>准备环节<a class="headerlink" href="#准备环节" title="Permalink to this headline"></a></h2>
<section id="导入模块">
<h3>导入模块<a class="headerlink" href="#导入模块" title="Permalink to this headline"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision.c_transforms</span> <span class="k">as</span> <span class="nn">vision</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">Initializer</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">ops</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
</pre></div>
</div>
</div>
</section>
<section id="配置环境">
<h3>配置环境<a class="headerlink" href="#配置环境" title="Permalink to this headline"></a></h3>
<p>本教程我们在Ascend环境下，使用图模式运行实验。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="准备数据">
<h3>准备数据<a class="headerlink" href="#准备数据" title="Permalink to this headline"></a></h3>
<p>在本教程中，我们将使用<a class="reference external" href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">Celeb-A Faces
数据集</a>，该数据集为人脸属性数据集，其包含10,177个名人身份的202,599张人脸图片。官网提供了多个下载链接，我们选择<code class="docutils literal notranslate"><span class="pre">Align&amp;Cropped</span> <span class="pre">Images</span></code>下的<code class="docutils literal notranslate"><span class="pre">img_align_celeba.zip</span></code>，是202,599张经过人脸对齐和裁剪了的图像。因数据集较大，本教程为了节省下载和训练时间，所以采用了部分的数据集。为了完整流畅地运行程序，需要在当前路径下创建一个<code class="docutils literal notranslate"><span class="pre">data</span></code>目录，并在<code class="docutils literal notranslate"><span class="pre">data</span></code>目录下创建一个名为<code class="docutils literal notranslate"><span class="pre">celeba</span></code>的目录，并将压缩文件解压缩到该目录中。最后，将此教程的<code class="docutils literal notranslate"><span class="pre">dataroot</span></code>输入设置为刚创建的<code class="docutils literal notranslate"><span class="pre">celeba</span></code>目录。</p>
<p>在Jupyter Notebook中执行如下命令下载并解压数据集。<code class="docutils literal notranslate"><span class="pre">img_align_celeba.zip</span></code>是从Celeb-A Faces 数据集中选取了5000张图片压缩成的数据集，解压时不打印详细的解压信息，需要1~2分钟完成数据集的解压。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>mkdir<span class="w"> </span>-p<span class="w"> </span>./data/celeba
<span class="o">!</span>wget<span class="w"> </span>-NP<span class="w"> </span>./<span class="w"> </span>https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/intermediate/img_align_celeba.zip
<span class="o">!</span>unzip<span class="w"> </span>-qqo<span class="w"> </span>./img_align_celeba.zip<span class="w"> </span>-d<span class="w"> </span>./data/celeba/
</pre></div>
</div>
</div>
<p>目录结构如下：</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">data</span><span class="o">/</span><span class="n">celeba</span>
    <span class="o">-&gt;</span> <span class="n">img_align_celeba</span>
        <span class="o">-&gt;</span> <span class="mf">188242.</span><span class="n">jpg</span>
        <span class="o">-&gt;</span> <span class="mf">173822.</span><span class="n">jpg</span>
        <span class="o">-&gt;</span> <span class="mf">284702.</span><span class="n">jpg</span>
        <span class="o">-&gt;</span> <span class="mf">537394.</span><span class="n">jpg</span>
           <span class="o">...</span>
</pre></div>
</div>
</section>
</section>
<section id="数据处理">
<h2>数据处理<a class="headerlink" href="#数据处理" title="Permalink to this headline"></a></h2>
<p>首先为执行过程定义一些输入：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dataroot</span></code>：数据集文件夹根目录；</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">workers</span></code>：加载数据的线程数；</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batch_size</span></code>：训练中使用的批量大小，DCGAN论文使用的批量大小为128；</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">image_size</span></code>：训练图像的大小，此实现默认为<code class="docutils literal notranslate"><span class="pre">64x64</span></code>，如果需要其他尺寸，则必须同时更改<code class="docutils literal notranslate"><span class="pre">D</span></code>和<code class="docutils literal notranslate"><span class="pre">G</span></code>的结构；</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nc</span></code>：输入图像中的彩色通道数，因为此次是彩色图像所以设为3；</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nz</span></code>：隐向量的长度；</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ngf</span></code>：设置通过生成器的特征图的深度；</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ndf</span></code>：设置通过判别器传播的特征图的深度；</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">num_epochs</span></code>：要运行的训练周期数，训练更长的时间可能会导致更好的结果，但也会花费更长的时间；</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lr</span></code>：训练的学习率，如DCGAN论文中所述，此数字应为0.0001；</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">beta1</span></code>：Adam优化器的<code class="docutils literal notranslate"><span class="pre">beta1</span></code>超参数。如DCGAN论文所述，该数字应为0.5；</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 数据集根目录</span>
<span class="n">dataroot</span> <span class="o">=</span> <span class="s2">&quot;./data&quot;</span>

<span class="c1"># 载入数据线程数</span>
<span class="n">workers</span> <span class="o">=</span> <span class="mi">4</span>

<span class="c1"># 批量大小</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>

<span class="c1"># 训练图像空间大小，所有图像都将调整为该大小</span>
<span class="n">image_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># 图像彩色通道数，对于彩色图像为3</span>
<span class="n">nc</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1"># 隐向量的长度</span>
<span class="n">nz</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># 特征图在生成器中的大小</span>
<span class="n">ngf</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># 特征图在判别器中的大小</span>
<span class="n">ndf</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># 训练周期数</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># 学习率</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.0001</span>

<span class="c1"># Beta1 超参数</span>
<span class="n">beta1</span> <span class="o">=</span> <span class="mf">0.5</span>
</pre></div>
</div>
</div>
<ul class="simple">
<li><p>定义<code class="docutils literal notranslate"><span class="pre">create_dataset_imagenet</span></code>函数对数据进行处理和增强操作。</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_dataset_imagenet</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># 数据加载</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">ImageFolderDataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># 数据增强操作</span>
    <span class="n">transform_img</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="p">]</span>

    <span class="c1"># 数据映射操作</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">,</span> <span class="n">operations</span><span class="o">=</span><span class="n">transform_img</span><span class="p">,</span>
                            <span class="n">output_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">)</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">,</span>
                            <span class="n">operations</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="mi">255</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">))</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
        <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span>
        <span class="n">operations</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span>
            <span class="n">x</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">nz</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
        <span class="p">),</span>
        <span class="n">output_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;latent_code&quot;</span><span class="p">],</span>
        <span class="n">column_order</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;latent_code&quot;</span><span class="p">],</span>
        <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span>
    <span class="p">)</span>

    <span class="c1"># 批量操作</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">data_set</span>

<span class="c1"># 获取处理后的数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">create_dataset_imagenet</span><span class="p">(</span><span class="n">dataroot</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">workers</span><span class="p">)</span>

<span class="c1"># 获取数据集大小</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>
</pre></div>
</div>
</div>
<ul class="simple">
<li><p>通过<code class="docutils literal notranslate"><span class="pre">create_dict_iterator</span></code>函数将数据转换成字典迭代器，然后使用<code class="docutils literal notranslate"><span class="pre">matplotlib</span></code>模块可视化部分训练数据。</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_iter</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">))</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">data_iter</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># 可视化36张图片</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">images</span><span class="p">[:</span><span class="mi">36</span><span class="p">]:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
    <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/intermediate_image_and_video_dcgan_20_0.png" src="../../_images/intermediate_image_and_video_dcgan_20_0.png" />
</div>
</div>
</section>
<section id="创建网络">
<h2>创建网络<a class="headerlink" href="#创建网络" title="Permalink to this headline"></a></h2>
<p>当处理完数据后，就可以来进行网络的搭建了。网络搭建将以权重初始化策略为起点，逐一详细讨论生成器、判别器和损失函数。</p>
<section id="权重初始化">
<h3>权重初始化<a class="headerlink" href="#权重初始化" title="Permalink to this headline"></a></h3>
<p>教程遵循DCGAN论文中的内容，所有模型权重均应从<code class="docutils literal notranslate"><span class="pre">mean</span></code>为0，<code class="docutils literal notranslate"><span class="pre">sigma</span></code>为0.02的正态分布中随机初始化。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_assignment</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">num</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">():</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">arr</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">num</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">(())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">arr</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">num</span><span class="p">[:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">arr</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">num</span>
    <span class="k">return</span> <span class="n">arr</span>

<span class="k">class</span> <span class="nc">Normal</span><span class="p">(</span><span class="n">Initializer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;将模型权重从均值为0，标准差为0.02的正态分布中随机初始化&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Normal</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>

    <span class="k">def</span> <span class="nf">_initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arr</span><span class="p">):</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">999</span><span class="p">)</span>
        <span class="n">arr_normal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span><span class="p">,</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">_assignment</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">arr_normal</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="生成器">
<h3>生成器<a class="headerlink" href="#生成器" title="Permalink to this headline"></a></h3>
<p>生成器<code class="docutils literal notranslate"><span class="pre">G</span></code>的功能是将隐向量<code class="docutils literal notranslate"><span class="pre">z</span></code>映射到数据空间。由于数据是图像，这一过程也会创建与真实图像大小相同的 RGB 图像。在实践场景中，该功能是通过一系列<code class="docutils literal notranslate"><span class="pre">Conv2dTranspose</span></code>转置卷积层来完成的，每个层都与<code class="docutils literal notranslate"><span class="pre">BatchNorm2d</span></code>层和<code class="docutils literal notranslate"><span class="pre">ReLu</span></code>激活层配对，输出数据会经过<code class="docutils literal notranslate"><span class="pre">tanh</span></code>函数，使其返回<code class="docutils literal notranslate"><span class="pre">[-1,1]</span></code>的数据范围内。</p>
<p>DCGAN论文生成图像如下所示。</p>
<p><img alt="dcgangenerator" src="https://gitee.com/mindspore/docs/raw/r1.5/tutorials/source_zh_cn/intermediate/image_and_video/images/dcgan.png" /></p>
<blockquote>
<div><p>图片来源 <a class="reference external" href="https://arxiv.org/pdf/1511.06434.pdf">https://arxiv.org/pdf/1511.06434.pdf</a></p>
</div></blockquote>
<p>我们通过输入部分中设置的<code class="docutils literal notranslate"><span class="pre">nz</span></code>、<code class="docutils literal notranslate"><span class="pre">ngf</span></code>和<code class="docutils literal notranslate"><span class="pre">nc</span></code>来影响代码中的生成器结构。<code class="docutils literal notranslate"><span class="pre">nz</span></code>是隐向量<code class="docutils literal notranslate"><span class="pre">z</span></code>的长度，<code class="docutils literal notranslate"><span class="pre">ngf</span></code>与通过生成器传播的特征图的大小有关，<code class="docutils literal notranslate"><span class="pre">nc</span></code>是输出图像中的通道数。</p>
<p>以下是生成器的代码实现：</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">convt</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;pad&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;定义转置卷积层&quot;&quot;&quot;</span>
    <span class="n">weight_init</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2dTranspose</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span>
                              <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                              <span class="n">weight_init</span><span class="o">=</span><span class="n">weight_init</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="n">pad_mode</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">bn</span><span class="p">(</span><span class="n">num_features</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;定义BatchNorm2d层&quot;&quot;&quot;</span>
    <span class="n">gamma_init</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="n">num_features</span><span class="p">,</span> <span class="n">gamma_init</span><span class="o">=</span><span class="n">gamma_init</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;DCGAN网络生成器&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">convt</span><span class="p">(</span><span class="n">nz</span><span class="p">,</span> <span class="n">ngf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">convt</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">ngf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">convt</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">ngf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">convt</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">ngf</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn</span><span class="p">(</span><span class="n">ngf</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">convt</span><span class="p">(</span><span class="n">ngf</span><span class="p">,</span> <span class="n">nc</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<p>实例化生成器，并打印出生成器的结构。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">netG</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">netG</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Generator&lt;
  (generator): SequentialCell&lt;
    (0): Conv2dTranspose&lt;input_channels=100, output_channels=512, kernel_size=(4, 4),stride=(1, 1),  pad_mode=pad, padding=0, dilation=(1, 1), group=1, has_bias=False,weight_init=&lt;__main__.Normal object at 0x7fdaf3c14b50&gt;, bias_init=zeros&gt;
    (1): BatchNorm2d&lt;num_features=512, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=1.gamma, shape=(512,), dtype=Float32, requires_grad=True), beta=Parameter (name=1.beta, shape=(512,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=1.moving_mean, shape=(512,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=1.moving_variance, shape=(512,), dtype=Float32, requires_grad=False)&gt;
    (2): ReLU&lt;&gt;
    (3): Conv2dTranspose&lt;input_channels=512, output_channels=256, kernel_size=(4, 4),stride=(2, 2),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False,weight_init=&lt;__main__.Normal object at 0x7fdaf3bf8d90&gt;, bias_init=zeros&gt;
    (4): BatchNorm2d&lt;num_features=256, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=4.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=4.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=4.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=4.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)&gt;
    (5): ReLU&lt;&gt;
    (6): Conv2dTranspose&lt;input_channels=256, output_channels=128, kernel_size=(4, 4),stride=(2, 2),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False,weight_init=&lt;__main__.Normal object at 0x7fdaf18340d0&gt;, bias_init=zeros&gt;
    (7): BatchNorm2d&lt;num_features=128, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=7.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=7.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=7.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=7.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)&gt;
    (8): ReLU&lt;&gt;
    (9): Conv2dTranspose&lt;input_channels=128, output_channels=64, kernel_size=(4, 4),stride=(2, 2),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False,weight_init=&lt;__main__.Normal object at 0x7fdaf1844450&gt;, bias_init=zeros&gt;
    (10): BatchNorm2d&lt;num_features=64, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=10.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=10.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=10.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=10.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)&gt;
    (11): ReLU&lt;&gt;
    (12): Conv2dTranspose&lt;input_channels=64, output_channels=3, kernel_size=(4, 4),stride=(2, 2),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False,weight_init=&lt;__main__.Normal object at 0x7fdaf1844810&gt;, bias_init=zeros&gt;
    (13): Tanh&lt;&gt;
    &gt;
  &gt;
</pre></div></div>
</div>
</section>
<section id="判别器">
<h3>判别器<a class="headerlink" href="#判别器" title="Permalink to this headline"></a></h3>
<p>如前所述，判别器<code class="docutils literal notranslate"><span class="pre">D</span></code>是一个二分类网络模型，输出判定该图像为真实图的概率。通过一系列的<code class="docutils literal notranslate"><span class="pre">Conv2d</span></code>、<code class="docutils literal notranslate"><span class="pre">BatchNorm2d</span></code>和<code class="docutils literal notranslate"><span class="pre">LeakyReLU</span></code>层对其进行处理，最后通过<code class="docutils literal notranslate"><span class="pre">Sigmoid</span></code>激活函数得到最终概率。</p>
<p>DCGAN论文提到，使用卷积而不是通过池化来进行下采样是一个好习惯，因为它可以让网络学习自己的池化特征。</p>
<p>判别器的代码实现如下：</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;pad&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;定义卷积层&quot;&quot;&quot;</span>
    <span class="n">weight_init</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span>
                     <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                     <span class="n">weight_init</span><span class="o">=</span><span class="n">weight_init</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="n">pad_mode</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    DCGAN网络判别器</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">nc</span><span class="p">,</span> <span class="n">ndf</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">ndf</span><span class="p">,</span> <span class="n">ndf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn</span><span class="p">(</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">ndf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn</span><span class="p">(</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">ndf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn</span><span class="p">(</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>实例化判别器，并打印出判别器的结构。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">netD</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">netD</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Discriminator&lt;
  (discriminator): SequentialCell&lt;
    (0): Conv2d&lt;input_channels=3, output_channels=64, kernel_size=(4, 4),stride=(2, 2),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=&lt;__main__.Normal object at 0x7fdaf17989d0&gt;, bias_init=zeros, format=NCHW&gt;
    (1): LeakyReLU&lt;&gt;
    (2): Conv2d&lt;input_channels=64, output_channels=128, kernel_size=(4, 4),stride=(2, 2),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=&lt;__main__.Normal object at 0x7fdaf1798b90&gt;, bias_init=zeros, format=NCHW&gt;
    (3): BatchNorm2d&lt;num_features=128, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=3.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=3.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=3.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=3.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)&gt;
    (4): LeakyReLU&lt;&gt;
    (5): Conv2d&lt;input_channels=128, output_channels=256, kernel_size=(4, 4),stride=(2, 2),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=&lt;__main__.Normal object at 0x7fdaf18ba350&gt;, bias_init=zeros, format=NCHW&gt;
    (6): BatchNorm2d&lt;num_features=256, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=6.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=6.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=6.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=6.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)&gt;
    (7): LeakyReLU&lt;&gt;
    (8): Conv2d&lt;input_channels=256, output_channels=512, kernel_size=(4, 4),stride=(2, 2),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=&lt;__main__.Normal object at 0x7fdaf1798c10&gt;, bias_init=zeros, format=NCHW&gt;
    (9): BatchNorm2d&lt;num_features=512, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=9.gamma, shape=(512,), dtype=Float32, requires_grad=True), beta=Parameter (name=9.beta, shape=(512,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=9.moving_mean, shape=(512,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=9.moving_variance, shape=(512,), dtype=Float32, requires_grad=False)&gt;
    (10): LeakyReLU&lt;&gt;
    (11): Conv2d&lt;input_channels=512, output_channels=1, kernel_size=(4, 4),stride=(1, 1),  pad_mode=pad, padding=0, dilation=(1, 1), group=1, has_bias=Falseweight_init=&lt;__main__.Normal object at 0x7fdaf1798bd0&gt;, bias_init=zeros, format=NCHW&gt;
    (12): Sigmoid&lt;&gt;
    &gt;
  &gt;
</pre></div></div>
</div>
</section>
<section id="连接网络和损失函数">
<h3>连接网络和损失函数<a class="headerlink" href="#连接网络和损失函数" title="Permalink to this headline"></a></h3>
<p>MindSpore将损失函数、优化器等操作都封装到了Cell中，因为GAN结构上的特殊性，其损失是判别器和生成器的多输出形式，这就导致它和一般的分类网络不同。所以我们需要自定义<code class="docutils literal notranslate"><span class="pre">WithLossCell</span></code>类，将网络和Loss连接起来。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">WithLossCellG</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;连接生成器和损失&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">netD</span><span class="p">,</span> <span class="n">netG</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WithLossCellG</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">netD</span> <span class="o">=</span> <span class="n">netD</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">netG</span> <span class="o">=</span> <span class="n">netG</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_code</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;构建生成器损失计算结构&quot;&quot;&quot;</span>
        <span class="n">ones</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Ones</span><span class="p">()</span>
        <span class="n">fake_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netG</span><span class="p">(</span><span class="n">latent_code</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netD</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

<span class="k">class</span> <span class="nc">WithLossCellD</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;连接判别器和损失&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">netD</span><span class="p">,</span> <span class="n">netG</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WithLossCellD</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">netD</span> <span class="o">=</span> <span class="n">netD</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">netG</span> <span class="o">=</span> <span class="n">netG</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">real_data</span><span class="p">,</span> <span class="n">latent_code</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;构建判别器损失计算结构&quot;&quot;&quot;</span>
        <span class="n">ones</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Ones</span><span class="p">()</span>
        <span class="n">zeros</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Zeros</span><span class="p">()</span>

        <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netD</span><span class="p">(</span><span class="n">real_data</span><span class="p">)</span>
        <span class="n">label1</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="n">out1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">loss1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">out1</span><span class="p">,</span> <span class="n">label1</span><span class="p">)</span>

        <span class="n">fake_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netG</span><span class="p">(</span><span class="n">latent_code</span><span class="p">)</span>
        <span class="n">fake_data</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
        <span class="n">out2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netD</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
        <span class="n">label2</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">out2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">loss2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">out2</span><span class="p">,</span> <span class="n">label2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss1</span> <span class="o">+</span> <span class="n">loss2</span>
</pre></div>
</div>
</div>
</section>
<section id="损失函数和优化器">
<h3>损失函数和优化器<a class="headerlink" href="#损失函数和优化器" title="Permalink to this headline"></a></h3>
<p>当定义了<code class="docutils literal notranslate"><span class="pre">D</span></code>和<code class="docutils literal notranslate"><span class="pre">G</span></code>后，接下来将使用MindSpore中定义的二进制交叉熵损失函数<a class="reference external" href="https://www.mindspore.cn/docs/api/zh-CN/r1.5/api_python/nn/mindspore.nn.BCELoss.html">BCELoss</a> ，为<code class="docutils literal notranslate"><span class="pre">D</span></code>和<code class="docutils literal notranslate"><span class="pre">G</span></code>加上损失函数和优化器。</p>
<p>这里设置了两个单独的优化器，一个用于<code class="docutils literal notranslate"><span class="pre">D</span></code>，另一个用于<code class="docutils literal notranslate"><span class="pre">G</span></code>。这两个都是<code class="docutils literal notranslate"><span class="pre">lr</span> <span class="pre">=</span> <span class="pre">0.0002</span></code>和<code class="docutils literal notranslate"><span class="pre">beta1</span> <span class="pre">=</span> <span class="pre">0.5</span></code>的Adam优化器。为此将真实标签定义为1，将虚假标签定义为0，该标签在分别计算<code class="docutils literal notranslate"><span class="pre">D</span></code>和<code class="docutils literal notranslate"><span class="pre">G</span></code>的损失时使用。</p>
<p>为了跟踪生成器的学习进度，将生成一批固定的遵循高斯分布的隐向量 <code class="docutils literal notranslate"><span class="pre">fixed_noise</span></code>。在训练的过程中，定期将<code class="docutils literal notranslate"><span class="pre">fixed_noise</span></code>输入到<code class="docutils literal notranslate"><span class="pre">G</span></code>中，可以看到隐向量生成的图像。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 定义损失函数</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>

<span class="c1"># 创建一批隐向量用来观察G</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">fixed_noise</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">nz</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># 为生成器和判别器设置优化器</span>
<span class="n">optimizerD</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">netD</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="n">beta1</span><span class="p">)</span>
<span class="n">optimizerG</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">netG</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="n">beta1</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
</section>
<section id="训练">
<h3>训练<a class="headerlink" href="#训练" title="Permalink to this headline"></a></h3>
<p>训练分为两个主要部分：训练判别器和训练生成器。</p>
<ul>
<li><p>训练判别器</p>
<p>训练判别器的目的是最大程度地提高判别图像真伪的概率。按照Goodfellow的方法，是希望通过提高其随机梯度来更新判别器，所以我们要最大化<span class="math notranslate nohighlight">\(log D(x) + log(1 - D(G(z))\)</span>的值。</p>
</li>
<li><p>训练生成器</p>
<p>如DCGAN论文所述，我们希望通过最小化<span class="math notranslate nohighlight">\(log(1 - D(G(z)))\)</span>来训练生成器，以产生更好的虚假图像。</p>
<p>在这两个部分中，分别获取训练过程中的损失，并在每个周期结束时进行统计，将<code class="docutils literal notranslate"><span class="pre">fixed_noise</span></code>批量推送到生成器中，以直观地跟踪<code class="docutils literal notranslate"><span class="pre">G</span></code>的训练进度。</p>
</li>
</ul>
<p>下面进行训练：</p>
<ul class="simple">
<li><p>定义DCGAN网络。</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DCGAN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">myTrainOneStepCellForD</span><span class="p">,</span> <span class="n">myTrainOneStepCellForG</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DCGAN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">myTrainOneStepCellForD</span> <span class="o">=</span> <span class="n">myTrainOneStepCellForD</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">myTrainOneStepCellForG</span> <span class="o">=</span> <span class="n">myTrainOneStepCellForG</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">real_data</span><span class="p">,</span> <span class="n">latent_code</span><span class="p">):</span>
        <span class="n">output_D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">myTrainOneStepCellForD</span><span class="p">(</span><span class="n">real_data</span><span class="p">,</span> <span class="n">latent_code</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">netD_loss</span> <span class="o">=</span> <span class="n">output_D</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">output_G</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">myTrainOneStepCellForG</span><span class="p">(</span><span class="n">latent_code</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">netG_loss</span> <span class="o">=</span> <span class="n">output_G</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">netD_loss</span><span class="p">,</span> <span class="n">netG_loss</span>
</pre></div>
</div>
</div>
<ul class="simple">
<li><p>实例化生成器和判别器的<code class="docutils literal notranslate"><span class="pre">WithLossCell</span></code>和<code class="docutils literal notranslate"><span class="pre">TrainOneStepCell</span></code>。</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 实例化WithLossCell</span>
<span class="n">netD_with_criterion</span> <span class="o">=</span> <span class="n">WithLossCellD</span><span class="p">(</span><span class="n">netD</span><span class="p">,</span> <span class="n">netG</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
<span class="n">netG_with_criterion</span> <span class="o">=</span> <span class="n">WithLossCellG</span><span class="p">(</span><span class="n">netD</span><span class="p">,</span> <span class="n">netG</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>

<span class="c1"># 实例化TrainOneStepCell</span>
<span class="n">myTrainOneStepCellForD</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">netD_with_criterion</span><span class="p">,</span> <span class="n">optimizerD</span><span class="p">)</span>
<span class="n">myTrainOneStepCellForG</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">netG_with_criterion</span><span class="p">,</span> <span class="n">optimizerG</span><span class="p">)</span>
</pre></div>
</div>
</div>
<ul class="simple">
<li><p>循环训练网络，每经过50次迭代，就收集生成器和判别器的损失，以便于后面绘制训练过程中损失函数的图像。</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 实例化DCGAN网络</span>
<span class="n">dcgan</span> <span class="o">=</span> <span class="n">DCGAN</span><span class="p">(</span><span class="n">myTrainOneStepCellForD</span><span class="p">,</span> <span class="n">myTrainOneStepCellForG</span><span class="p">)</span>
<span class="n">dcgan</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>

<span class="c1">#创建迭代器</span>
<span class="n">data_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">)</span>
<span class="n">G_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">D_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">iters</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">image_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># 开始循环训练</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting Training Loop...&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="c1"># 为每轮训练读入数据</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
        <span class="n">real_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">])</span>
        <span class="n">latent_code</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;latent_code&quot;</span><span class="p">])</span>
        <span class="n">netD_loss</span><span class="p">,</span> <span class="n">netG_loss</span> <span class="o">=</span> <span class="n">dcgan</span><span class="p">(</span><span class="n">real_data</span><span class="p">,</span> <span class="n">latent_code</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># 输出训练记录</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[</span><span class="si">%d</span><span class="s1">/</span><span class="si">%d</span><span class="s1">][</span><span class="si">%d</span><span class="s1">/</span><span class="si">%d</span><span class="s1">]</span><span class="se">\t</span><span class="s1">Loss_D: </span><span class="si">%.4f</span><span class="se">\t</span><span class="s1">Loss_G: </span><span class="si">%.4f</span><span class="s1">&#39;</span><span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">netD_loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">netG_loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()))</span>
        <span class="n">D_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">netD_loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
        <span class="n">G_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">netG_loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">iters</span> <span class="o">%</span> <span class="mi">100</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="p">((</span><span class="n">epoch</span> <span class="o">==</span> <span class="n">num_epochs</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="n">size</span><span class="o">-</span><span class="mi">1</span><span class="p">)):</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">netG</span><span class="p">(</span><span class="n">fixed_noise</span><span class="p">)</span>
            <span class="n">image_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="n">iters</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[1/10][0/40]    Loss_D: 2.5023  Loss_G: 3.0074
[2/10][0/40]    Loss_D: 0.1312  Loss_G: 6.4204
[3/10][0/40]    Loss_D: 1.8660  Loss_G: 5.0743
[4/10][0/40]    Loss_D: 0.8460  Loss_G: 8.3941
[5/10][0/40]    Loss_D: 1.3889  Loss_G: 3.7475
[6/10][0/40]    Loss_D: 0.7514  Loss_G: 2.3104
[7/10][0/40]    Loss_D: 0.4962  Loss_G: 3.7203
[8/10][0/40]    Loss_D: 0.5417  Loss_G: 4.5572
[9/10][0/40]    Loss_D: 0.2741  Loss_G: 4.2247
[10/10][0/40]   Loss_D: 0.3801  Loss_G: 4.0097
</pre></div></div>
</div>
</section>
</section>
<section id="结果">
<h2>结果<a class="headerlink" href="#结果" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>运行下面代码，描绘<code class="docutils literal notranslate"><span class="pre">D</span></code>和<code class="docutils literal notranslate"><span class="pre">G</span></code>损失与训练迭代的关系图：</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Generator and Discriminator Loss During Training&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">G_losses</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;G&quot;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">D_losses</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;D&quot;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;iterations&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/intermediate_image_and_video_dcgan_45_0.png" src="../../_images/intermediate_image_and_video_dcgan_45_0.png" />
</div>
</div>
<ul class="simple">
<li><p>可视化训练过程中通过隐向量<code class="docutils literal notranslate"><span class="pre">fixed_noise</span></code>生成的图像，每次只取9张图像展示。</p></li>
</ul>
<p><img alt="gif" src="https://gitee.com/mindspore/docs/raw/r1.5/tutorials/source_zh_cn/intermediate/image_and_video/images/SDGIF_Rusult_1.gif" /></p>
<p>由上图可见训练过的网络成功生成了虚假名人图像。</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="adversarial_example_generation.html" class="btn btn-neutral float-left" title="对抗示例生成" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../text.html" class="btn btn-neutral float-right" title="自然语言" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>