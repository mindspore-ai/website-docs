

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>使用BERT网络实现智能写诗 &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script src="../../_static/js/training.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="动态图与静态图" href="../pynative_mode_and_graph_mode.html" />
    <link rel="prev" title="使用SentimentNet实现情感分类" href="sentimentnet.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">入门教程</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">基本介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quick_start.html">初学入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor.html">张量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dataset.html">数据加载及处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model.html">建立神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autograd.html">自动微分</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization.html">训练模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../save_load_model.html">保存及加载模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linear_regression.html">简单线性函数拟合</a></li>
</ul>
<p class="caption"><span class="caption-text">进阶教程</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../mid_low_level_api.html">中低阶API实现深度学习</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data.html">高级数据集管理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../image_and_video.html">图像处理</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../text.html">自然语言</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="rnn_classification.html">使用字符级RNN分类名称</a></li>
<li class="toctree-l2"><a class="reference internal" href="rnn_generation.html">使用字符级RNN生成名称</a></li>
<li class="toctree-l2"><a class="reference internal" href="sentimentnet.html">使用SentimentNet实现情感分类</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">使用BERT网络实现智能写诗</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">案例简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">模型介绍</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">模型训练</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pre-training">Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#fine-tuning">Fine-tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id4">模型修改</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id5">样例代码</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">实现步骤</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id7">基础信息</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8">数据准备</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id9">训练</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id10">推理验证</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id11">服务部署</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id12">参考文献</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../pynative_mode_and_graph_mode.html">动态图与静态图</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed_training.html">分布式训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inference_and_deploy.html">推理与部署</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../text.html">自然语言</a> &raquo;</li>
        
      <li>使用BERT网络实现智能写诗</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/intermediate/text/bert_poetry.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="bert">
<h1>使用BERT网络实现智能写诗<a class="headerlink" href="#bert" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">进阶</span></code> <code class="docutils literal notranslate"><span class="pre">自然语言处理</span></code> <code class="docutils literal notranslate"><span class="pre">全流程</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.6/tutorials/source_zh_cn/intermediate/text/bert_poetry.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.6/resource/_static/logo_source.png"></a></p>
<p>五千年历史孕育了深厚的中华文化，而诗词是中华文化不可或缺的一部分，欣赏过诗词就可以感受到当中纯净、辽阔的意境，极致的感性，恰恰弥补了节奏紧迫的现代生活带给我们的拥挤感、浮躁感，古语曰：熟读唐诗三百首，不会作诗也会吟，今天理科生MindSpore也来秀一秀文艺范儿！</p>
<div class="section" id="id1">
<h2>案例简介<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>通过MindSpore训练出智能写诗模型及部署预测服务，具体流程如下图所示：</p>
<p><img alt="introduce image" src="../../_images/introduce.PNG" /></p>
<p><em>图1：案例流程图</em></p>
<p>由于Bert预训练比较费时费力，在本案例中省略了预训练阶段，直接提供MindSpore预训练好的Bert-Base模型，经过Fine-tuning后训练获得最终的模型的训练全流程。</p>
</div>
<div class="section" id="id2">
<h2>模型介绍<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>和诗词打交道需要用NLP相关的网络，BERT作为NLP领域中里程碑式的模型，极大地推动了NLP社区的发展，BERT模型由Google提出，采用Transformer中的Encoder结构，通过若干层Encoder的堆叠并借由注意力机制，在多项GLUE（General Language Understanding Evaluation）任务中取得了SOTA（State Of The Art）的效果。</p>
<p>正是由于这种注意力的机制，不同于以往的循环神经网络的结构，可以做高度的并行计算，这样便可以充分发挥出Ascend 910AI处理器的强大算力，获得极佳的性能表现。</p>
</div>
<div class="section" id="id3">
<h2>模型训练<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>分为两个步骤，即Pre-training和Fine-tuning。首先在海量无标签的数据上进行Pre-training，希望通过此过程让模型掌握一般的人类语言语义机制，然后在Fine-tuning阶段会针对特定细分领域的有标签数据进行训练以完成特定任务。</p>
<div class="section" id="pre-training">
<h3>Pre-training<a class="headerlink" href="#pre-training" title="Permalink to this headline">¶</a></h3>
<p>Pre-training是在无标签数据上进行的自编码训练，因此训练任务的设计尤为重要，BERT中的Pre-training包含两项任务MLM(Masked Language Model)和NSP(Next Sentence Prediction)。</p>
<ul class="simple">
<li><p><strong>MLM任务</strong>是在输入时，随机将部分token置换为[MASK]标记，然后通过注意力机制，由其上下文预测出被遮挡位置的原始token。</p></li>
<li><p>BERT模型的输入是两“句”话：A与B，构造数据的时候会以50%的概率随机调换A、B的位置，<strong>NSP任务</strong>是预测A与B是否是相连的两“句”话。</p></li>
</ul>
<p>在MLM基础上再增加一个NSP任务，是考虑到实际任务中并没有MLM这种任务，增加一个更符合实际任务类型的预训练任务。</p>
<p>从上述描述中可以看出，Pre-training并不需要任务数据标签，这种MLM的训练任务本质上是去噪自编码模型，因此BERT可以利用海量的无标签数据来进行预训练。通过预训练阶段的任务设置，BERT可以从无标签数据中学到基础语义逻辑，然后配合Finetune过程完成特定任务训练。</p>
<p>BERT模型的结构如下图所示，输入两“句”话，如果是中文模型，那么每一个token对应一个汉字，[CLS]和[SEP]是插入的特殊标识位。</p>
<p><img alt="Teaser image" src="../../_images/bert_model.PNG" /></p>
<p><em>图2：Bert模型结构[1]</em></p>
</div>
<div class="section" id="fine-tuning">
<h3>Fine-tuning<a class="headerlink" href="#fine-tuning" title="Permalink to this headline">¶</a></h3>
<p>Fine-tuning是在BERT的预训练模型基础上，在最后增加一层适配实际任务，然后在有标签数据上进行少量的训练。</p>
<p>Fine-tuning的模式可以分为两大类，end-to-end Fine-tuning和feature-based approach，两者的区别在于Finetune阶段中是否修改BERT预训练模型中的参数，正常情况下都是使用end-to-end Fine-tuning。</p>
</div>
<div class="section" id="id4">
<h3>模型修改<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>BERT采用了Encoder结构，<code class="docutils literal notranslate"><span class="pre">attention_mask</span></code>为全1的向量，即每个token都可以看到其前后的token，此举帮助每一个token都可以了解到整句话信息从而加强语义理解能力，所以BERT天生就不是生成式模型。</p>
<p>语句生成任务中，在生成下一个token时，应当只能看到之前token的信息，而不应该看到全局信息，因此需要在修改<code class="docutils literal notranslate"><span class="pre">attention_mask</span></code>为下三角矩阵，这样当前token只能看到自己及之前的token信息。</p>
<p>用于Fine-tuning的数据是40000多首诗词，并无标签，因此构造Fine-tuning任务如下图所示，每一个token的输出要接近下一个标签token，使用交叉熵作为损失函数。</p>
<p><img alt="Teaser image" src="../../_images/finetune.PNG" /></p>
<p><em>图3：训练流程示意图</em></p>
</div>
</div>
<div class="section" id="id5">
<h2>样例代码<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h2>
<p>可以在这里下载完整的样例代码：<a class="reference external" href="https://gitee.com/mindspore/docs/tree/r1.6/docs/sample_code/bert_poetry">https://gitee.com/mindspore/docs/tree/r1.6/docs/sample_code/bert_poetry</a>，直接运行体验实现写诗效果，代码结构如下:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─bert_poetry
  ├── src
    ├── bert_for_pre_training.py           # 封装BERT-Base正反向网络类
    ├── bert_model.py                      # 定义BERT正向网络结构
    ├── finetune_config.py                 # Fine-tuning配置文件
    ├── fused_layer_norm.py                # 定义fused_layer_norm
    ├── __init__.py                        # __init__
    ├── utils.py                           # 定义Fine-tuning正向网络结构
    ├── poetry_utils.py                    # 分词器 Tokenizer
    └── poetry_dataset.py                  # 解析poetry.txt，生成所需dataset
  ├── serving
    ├── bert
      ├── 1
        ├── poetry.mindir                  # 导出的MindIR文件
      ├── servable_config.py               # Serving推理脚本
    ├── poetry_client.py                   # Serving用户脚本
    ├── serving_server.py                  # Serving服务器脚本
  ├── vocab.txt                            # 词汇表
  ├── generator.py                         # 推理生成诗句使用函数
  ├── poetry.py                            # 训练、推理、导出函数
</pre></div>
</div>
</div>
<div class="section" id="id6">
<h2>实现步骤<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id7">
<h3>基础信息<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>本例可在Ascend 910 AI处理器平台上进行训练及推理。</p>
</div>
<div class="section" id="id8">
<h3>数据准备<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>数据集为<a class="reference external" href="https://github.com/AaronJny/DeepLearningExamples/tree/master/keras-bert-poetry-generator">43030首诗词</a>其中的<code class="docutils literal notranslate"><span class="pre">poetry.txt</span></code>。</p>
<p>BERT-Base模型的预训练ckpt：可在<a class="reference external" href="https://www.mindspore.cn/resources/hub/details?MindSpore/ascend/1.0/bert_base_v1.0_cn-wiki">MindSpore官网</a>下载。</p>
</div>
<div class="section" id="id9">
<h3>训练<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>在<code class="docutils literal notranslate"><span class="pre">src/finetune_config.py</span></code>中修改<code class="docutils literal notranslate"><span class="pre">pre_training_ckpt</span></code>路径，加载预训练的ckpt，修改<code class="docutils literal notranslate"><span class="pre">batch_size</span></code>为bs，修改<code class="docutils literal notranslate"><span class="pre">dataset_path</span></code>为存放诗词的路径，默认的<code class="docutils literal notranslate"><span class="pre">BertConfig</span></code>为Base模型。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;dataset_path&#39;</span><span class="p">:</span> <span class="s1">&#39;/your/path/to/poetry.txt&#39;</span><span class="p">,</span>
<span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="n">bs</span><span class="p">,</span>
<span class="s1">&#39;pre_training_ckpt&#39;</span><span class="p">:</span> <span class="s1">&#39;/your/path/to/pre_training_ckpt&#39;</span><span class="p">,</span>
</pre></div>
</div>
<p>执行训练指令</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python poetry.py
</pre></div>
</div>
</div>
<div class="section" id="id10">
<h3>推理验证<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>修改<code class="docutils literal notranslate"><span class="pre">poetry.py</span></code>中<code class="docutils literal notranslate"><span class="pre">test_eval</span></code>函数来控制随机生成、续写诗句或是藏头诗。</p>
<p><code class="docutils literal notranslate"><span class="pre">generate_random_poetry</span></code>函数实现随机生成和续写诗句的功能，如果入参<code class="docutils literal notranslate"><span class="pre">s</span></code>为空则代表随机生成，<code class="docutils literal notranslate"><span class="pre">s</span></code>不为空则为续写诗句。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">generate_random_poetry</span><span class="p">(</span><span class="n">poetrymodel</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>         <span class="c1">#随机生成</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">generate_random_poetry</span><span class="p">(</span><span class="n">poetrymodel</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="s1">&#39;天下为公&#39;</span><span class="p">)</span>  <span class="c1">#续写诗句</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">generate_hidden</span></code>函数实现生成藏头诗的功能，入参<code class="docutils literal notranslate"><span class="pre">head</span></code>为隐藏的头部语句。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">generate_hidden</span><span class="p">(</span><span class="n">poetrymodel</span><span class="p">,</span> <span class="n">head</span><span class="o">=</span><span class="s2">&quot;人工智能&quot;</span><span class="p">)</span>  <span class="c1">#藏头诗</span>
</pre></div>
</div>
<p>执行推理指令</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python poetry.py --train<span class="o">=</span>False  --ckpt_path<span class="o">=</span>/your/ckpt/path
</pre></div>
</div>
<p>会打印出最终生成的诗句，脚本中默认生成一首随机生成、一首续写诗词、一首藏头诗，结果如下所示：</p>
<p>随机生成：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>大堤柳暗，
春深树根。
东望一望，
断回还家。
山色渐风雨，
东风多雨禾。
无情与去，
万里所思。
</pre></div>
</div>
<p>续写 【天下为公】:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>天下为公少，
唯君北向西。
远山无路见，
长水见人偏。
一路巴猿啸，
千峰楚客啼。
幽深有诗策，
无以话年华。
</pre></div>
</div>
<p>藏头诗 【人工智能】:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>人君离别难堪望，
工部张机自少年。
智士不知身没处，
能令圣德属何年。
</pre></div>
</div>
</div>
<div class="section" id="id11">
<h3>服务部署<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<p>通过MindSpore Serving将训练好的模型部署成推理服务。服务端部署包含以下3个步骤： MindIR导出、Serving服务器启动、Serving客户端启动；</p>
<p>客户端发送推理请求给服务器，服务器调用Serving服务进行模型推理，推理生成的诗句返回给客户端展示。注意，要先启动服务器再启动客户端。</p>
<ul>
<li><p>模型导出</p>
<p>在使用Serving部署服务前，需要导出MindIR文件，在<code class="docutils literal notranslate"><span class="pre">poetry.py</span></code>中提供了<code class="docutils literal notranslate"><span class="pre">export_net</span></code>函数负责导出MindIR模型，执行命令：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python poetry.py --export<span class="o">=</span>True --ckpt_path<span class="o">=</span>/your/ckpt/path
</pre></div>
</div>
<p>会在<code class="docutils literal notranslate"><span class="pre">serving/bert/1</span></code>路径下生成poetry.mindir文件。</p>
</li>
<li><p>Serving服务端启动</p>
<p>在服务器侧启动Serving服务，并加载导出的MindIR文件。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> serving
python serving_server.py
</pre></div>
</div>
</li>
<li><p>Serving客户端启动</p>
<p>在客户端启动Serving推理请求。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> serving
python poetry_client.py
</pre></div>
</div>
<p>此时在客户端输入指令，即可在远端服务器进行推理，返回生成的诗句。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>选择模式： 0-随机生成，1：续写，2：藏头诗
</pre></div>
</div>
<p>选择相应的模式，即可由Serving服务调用推理，将生成的诗句返回给客户端。</p>
</li>
</ul>
</div>
</div>
<div class="section" id="id12">
<h2>参考文献<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h2>
<p>[1] <a class="reference external" href="https://arxiv.org/abs/1810.04805">BERT:Pre-training of Deep Bidirectional Transformers for Language Understanding</a></p>
<p>[2] <a class="reference external" href="https://github.com/AaronJny/DeepLearningExamples/">https://github.com/AaronJny/DeepLearningExamples/</a></p>
<p>[3] <a class="reference external" href="https://github.com/bojone/bert4keras">https://github.com/bojone/bert4keras</a></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../pynative_mode_and_graph_mode.html" class="btn btn-neutral float-right" title="动态图与静态图" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="sentimentnet.html" class="btn btn-neutral float-left" title="使用SentimentNet实现情感分类" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>