<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>构建网络 &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/js/training.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="自动求导" href="derivation.html" />
    <link rel="prev" title="优化器" href="optim.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">初学教程</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introduction.html">基本介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/quick_start.html">快速入门：手写数字识别</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/tensor.html">张量 Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/dataset.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/model.html">创建网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/autograd.html">自动微分</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/train.html">模型训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/save_load.html">保存与加载</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/infer.html">推理与部署</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">进阶</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../linear_fitting.html">进阶案例：线性拟合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset.html">数据处理</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../network.html">网络构建</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="parameter.html">网络参数</a></li>
<li class="toctree-l2"><a class="reference internal" href="loss.html">损失函数</a></li>
<li class="toctree-l2"><a class="reference internal" href="optim.html">优化器</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">构建网络</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#网络基本单元-cell">网络基本单元 Cell</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#construct方法">construct方法</a></li>
<li class="toctree-l4"><a class="reference internal" href="#获取网络参数">获取网络参数</a></li>
<li class="toctree-l4"><a class="reference internal" href="#相关属性">相关属性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#构建网络-1">构建网络</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#ops算子构建网络">Ops算子构建网络</a></li>
<li class="toctree-l4"><a class="reference internal" href="#nn层构建网络">nn层构建网络</a></li>
<li class="toctree-l4"><a class="reference internal" href="#容器构建网络">容器构建网络</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#nn与ops关系">nn与ops关系</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="derivation.html">自动求导</a></li>
<li class="toctree-l2"><a class="reference internal" href="control_flow.html">流程控制语句</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../train.html">训练与评估</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pynative_graph.html">动态图与静态图</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../network.html">网络构建</a> &raquo;</li>
      <li>构建网络</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/advanced/network/forward.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="构建网络">
<h1>构建网络<a class="headerlink" href="#构建网络" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://authoring-modelarts-cnnorth4.huaweicloud.com/console/lab?share-url-b64=aHR0cHM6Ly9vYnMuZHVhbHN0YWNrLmNuLW5vcnRoLTQubXlodWF3ZWljbG91ZC5jb20vbWluZHNwb3JlLXdlYnNpdGUvbm90ZWJvb2svcjEuNy90dXRvcmlhbHMvemhfY24vYWR2YW5jZWQvbmV0d29yay9taW5kc3BvcmVfZm9yd2FyZC5pcHluYg==&amp;imageid=9d63f4d1-dc09-4873-b669-3483cea777c0"><img alt="在线运行" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.7/resource/_static/logo_modelarts.png" /></a> <a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/r1.7/tutorials/zh_cn/advanced/network/mindspore_forward.ipynb"><img alt="下载Notebook" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.7/resource/_static/logo_notebook.png" /></a> <a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/r1.7/tutorials/zh_cn/advanced/network/mindspore_forward.py"><img alt="下载样例代码" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.7/resource/_static/logo_download_code.png" /></a> <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.7/tutorials/source_zh_cn/advanced/network/forward.ipynb"><img alt="查看源文件" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.7/resource/_static/logo_source.png" /></a></p>
<p>MindSpore的<code class="docutils literal notranslate"><span class="pre">Cell</span></code>类是构建所有网络的基类，也是网络的基本单元。自定义网络时，需要继承<code class="docutils literal notranslate"><span class="pre">Cell</span></code>类，本章主要介绍网络基本单元<code class="docutils literal notranslate"><span class="pre">Cell</span></code>和自定义前向网络。</p>
<p>本章主要介绍前向网络模型的构建和网络模型的基本单元，因为不涉及到训练，因此没有反向传播和反向图。</p>
<p><img alt="learningrate.png" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.7/tutorials/source_zh_cn/advanced/network/images/introduction3.png" /></p>
<section id="网络基本单元-cell">
<h2>网络基本单元 Cell<a class="headerlink" href="#网络基本单元-cell" title="Permalink to this headline"></a></h2>
<p>当用户需要自定义网络时，需要继承<code class="docutils literal notranslate"><span class="pre">Cell</span></code>类，并重写<code class="docutils literal notranslate"><span class="pre">__init__</span></code>方法和<code class="docutils literal notranslate"><span class="pre">construct</span></code>方法。损失函数、优化器和模型层等本质上也属于网络结构，也需要继承<code class="docutils literal notranslate"><span class="pre">Cell</span></code>类才能实现功能，同样用户也可以根据业务需求自定义这部分内容。</p>
<p>下面介绍<code class="docutils literal notranslate"><span class="pre">Cell</span></code>的关键成员函数。</p>
<section id="construct方法">
<h3>construct方法<a class="headerlink" href="#construct方法" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Cell</span></code>类重写了<code class="docutils literal notranslate"><span class="pre">__call__</span></code>方法，在<code class="docutils literal notranslate"><span class="pre">Cell</span></code>类的实例被调用时，会执行<code class="docutils literal notranslate"><span class="pre">construct</span></code>方法。网络结构在<code class="docutils literal notranslate"><span class="pre">construct</span></code>方法里面定义。</p>
<p>如下样例中，构建了一个简单的卷积网络，卷积网络在<code class="docutils literal notranslate"><span class="pre">__init__</span></code>中定义，在<code class="docutils literal notranslate"><span class="pre">construct</span></code>方法传入输入数据<code class="docutils literal notranslate"><span class="pre">x</span></code>执行卷积计算，并返回计算结果。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</section>
<section id="获取网络参数">
<h3>获取网络参数<a class="headerlink" href="#获取网络参数" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">nn.Cell</span></code>中返回参数的方法有<code class="docutils literal notranslate"><span class="pre">parameters_dict</span></code>、<code class="docutils literal notranslate"><span class="pre">get_parameters</span></code>和<code class="docutils literal notranslate"><span class="pre">trainable_params</span></code>。</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">parameters_dict</span></code>：获取网络结构中所有参数，返回一个以key为参数名，value为参数值的OrderedDict。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_parameters</span></code>：获取网络结构中的所有参数，返回Cell中Parameter的迭代器。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainable_params</span></code>：获取Parameter中<code class="docutils literal notranslate"><span class="pre">requires_grad</span></code>为True的属性，返回可训参数的列表。</p></li>
</ul>
<p>如下示例分别使用上述方法获取网络参数并打印。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>

<span class="c1"># 获取网络结构中的所有参数</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters_dict</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;parameters_dict of result:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>

<span class="c1"># 获取网络结构中的所有参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">get_parameters of result:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

<span class="c1"># 获取可训练参数列表</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">trainable_params of result:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
parameters_dict of result:
 OrderedDict([(&#39;conv.weight&#39;, Parameter (name=conv.weight, shape=(20, 10, 3, 3), dtype=Float32, requires_grad=True)), (&#39;conv.bias&#39;, Parameter (name=conv.bias, shape=(20,), dtype=Float32, requires_grad=True))])

get_parameters of result:
Parameter (name=conv.weight, shape=(20, 10, 3, 3), dtype=Float32, requires_grad=True)
Parameter (name=conv.bias, shape=(20,), dtype=Float32, requires_grad=True)

trainable_params of result:
 [Parameter (name=conv.weight, shape=(20, 10, 3, 3), dtype=Float32, requires_grad=True), Parameter (name=conv.bias, shape=(20,), dtype=Float32, requires_grad=True)]
</pre></div></div>
</div>
</section>
<section id="相关属性">
<h3>相关属性<a class="headerlink" href="#相关属性" title="Permalink to this headline"></a></h3>
<ol class="arabic simple">
<li><p>cells_and_names</p></li>
</ol>
<p><code class="docutils literal notranslate"><span class="pre">cells_and_names</span></code>方法是一个迭代器，返回网络中每个<code class="docutils literal notranslate"><span class="pre">Cell</span></code>的名字和它的内容本身。代码样例如下：</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(&#39;&#39;, Net&lt;
  (conv): Conv2d&lt;input_channels=10, output_channels=20, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW&gt;
  &gt;)
(&#39;conv&#39;, Conv2d&lt;input_channels=10, output_channels=20, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW&gt;)
</pre></div></div>
</div>
<ol class="arabic simple" start="2">
<li><p>set_grad</p></li>
</ol>
<p><code class="docutils literal notranslate"><span class="pre">set_grad</span></code>用于指定网络是否需要计算梯度。在不传入参数调用时，默认设置<code class="docutils literal notranslate"><span class="pre">requires_grad</span></code>为True，在执行前向网络时将会构建用于计算梯度的反向网络。<code class="docutils literal notranslate"><span class="pre">TrainOneStepCell</span></code>和<code class="docutils literal notranslate"><span class="pre">GradOperation</span></code>接口，无需使用<code class="docutils literal notranslate"><span class="pre">set_grad</span></code>，其内部已实现。若用户需要自定义此类训练功能的接口，需要在其内部或者外部设置<code class="docutils literal notranslate"><span class="pre">set_grad</span></code>。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CustomTrainOneStepCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">sens</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;入参有三个：训练网络，优化器和反向传播缩放比例&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CustomTrainOneStepCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>      <span class="c1"># 前向网络</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">set_grad</span><span class="p">()</span>     <span class="c1"># 构建计算梯度的反向网络</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>  <span class="c1"># 优化器</span>
</pre></div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">CustomTrainOneStepCell</span></code>代码详细内容可参见<a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r1.7/advanced/train/train_eval.html#自定义训练网络">自定义训练与评估网络</a></p>
<ol class="arabic simple" start="3">
<li><p>set_train</p></li>
</ol>
<p><code class="docutils literal notranslate"><span class="pre">set_train</span></code>接口指定模型是否为训练模式，在不传入参数调用时，默认设置的<code class="docutils literal notranslate"><span class="pre">mode</span></code>属性为True。</p>
<p>在实现训练和推理结构不同的网络时可以通过<code class="docutils literal notranslate"><span class="pre">training</span></code>属性区分训练和推理场景，当<code class="docutils literal notranslate"><span class="pre">mode</span></code>设置为True时，为训练场景；当<code class="docutils literal notranslate"><span class="pre">mode</span></code>设置为False时，为推理场景。</p>
<p>MindSpore中的<code class="docutils literal notranslate"><span class="pre">nn.Dropout</span></code>算子，根据<code class="docutils literal notranslate"><span class="pre">Cell</span></code>的<code class="docutils literal notranslate"><span class="pre">mode</span></code>属性区分了两种执行逻辑，<code class="docutils literal notranslate"><span class="pre">mode</span></code>为False时直接返回输入，<code class="docutils literal notranslate"><span class="pre">mode</span></code>为True时执行算子。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">keep_prob</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="c1"># 执行训练</span>
<span class="n">net</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;training result:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>

<span class="c1"># 执行推理</span>
<span class="n">net</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">infer result:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
training result:
 [[[1.4285715 1.4285715 1.4285715]
  [1.4285715 0.        0.       ]]

 [[1.4285715 1.4285715 1.4285715]
  [1.4285715 1.4285715 1.4285715]]]

infer result:
 [[[1. 1. 1.]
  [1. 1. 1.]]

 [[1. 1. 1.]
  [1. 1. 1.]]]
</pre></div></div>
</div>
<ol class="arabic simple" start="4">
<li><p>to_float</p></li>
</ol>
<p><code class="docutils literal notranslate"><span class="pre">to_float</span></code>接口递归地在配置了当前<code class="docutils literal notranslate"><span class="pre">Cell</span></code>和所有子<code class="docutils literal notranslate"><span class="pre">Cell</span></code>的强制转换类型，以使当前网络结构以使用特定的Float类型运行，通常在混合精度场景使用。</p>
<p>如下示例分别对<code class="docutils literal notranslate"><span class="pre">nn.dense</span></code>层使用float32类型和float16类型进行运算，并打印输出结果的数据类型。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>

<span class="c1"># float32进行计算</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

<span class="c1"># float16进行计算</span>
<span class="n">net1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">net1</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Float32
Float16
</pre></div></div>
</div>
</section>
</section>
<section id="构建网络-1">
<h2>构建网络<a class="headerlink" href="#构建网络-1" title="Permalink to this headline"></a></h2>
<p>构建网络时，可以继承<code class="docutils literal notranslate"><span class="pre">nn.Cell</span></code>类，在<code class="docutils literal notranslate"><span class="pre">__init__</span></code>构造函数中申明各个层的定义，在<code class="docutils literal notranslate"><span class="pre">construct</span></code>中实现层之间的连接关系，完成神经网络的前向构造。</p>
<p><code class="docutils literal notranslate"><span class="pre">mindspore.ops</span></code>模块提供了基础算子的实现，如神经网络算子、数组算子和数学算子等。</p>
<p><code class="docutils literal notranslate"><span class="pre">mindspore.nn</span></code>模块实现了对基础算子的进一步封装，用户可以根据需要，灵活使用不同的算子。</p>
<p>同时，为了更好地构建和管理复杂的网络，<code class="docutils literal notranslate"><span class="pre">mindspore.nn</span></code>提供了两种容器对网络中的子模块或模型层进行管理，分别为<code class="docutils literal notranslate"><span class="pre">nn.CellList</span></code>和<code class="docutils literal notranslate"><span class="pre">nn.SequentialCell</span></code>两种方式。</p>
<section id="ops算子构建网络">
<h3>Ops算子构建网络<a class="headerlink" href="#ops算子构建网络" title="Permalink to this headline"></a></h3>
<p><a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.ops.html">mindspore.ops</a>模块提供了基础算子的实现，如神经网络算子、数组算子和数学算子等。</p>
<p>用户可使用<code class="docutils literal notranslate"><span class="pre">mindspore.ops</span></code>中的算子来构建一个简单的算法 <span class="math notranslate nohighlight">\(f(x)=x^2+w\)</span>，示例如下：</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">ops</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mul</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Mul</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Add</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[ 3.  6. 11.]
</pre></div></div>
</div>
</section>
<section id="nn层构建网络">
<h3>nn层构建网络<a class="headerlink" href="#nn层构建网络" title="Permalink to this headline"></a></h3>
<p>尽管<code class="docutils literal notranslate"><span class="pre">mindspore.ops</span></code>模块提供的多样算子可以基本满足网络构建的诉求，但为了在复杂的深度网络中提供更方便易用的接口，<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.nn.html#">mindspore.nn</a>对<code class="docutils literal notranslate"><span class="pre">mindspore.ops</span></code>算子进行了进一步的封装。</p>
<p><code class="docutils literal notranslate"><span class="pre">mindspore.nn</span></code>模块主要包括神经网络（neural network）中常用的卷积层（如<code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code>）、池化层（<code class="docutils literal notranslate"><span class="pre">nn.MaxPool2d</span></code>）、非线性激活函数（如<code class="docutils literal notranslate"><span class="pre">nn.ReLU</span></code>）、损失函数（如<code class="docutils literal notranslate"><span class="pre">nn.LossBase</span></code>）、优化器（如<code class="docutils literal notranslate"><span class="pre">nn.Momentum</span></code>）等，为用户的使用提供了便利。</p>
<p>下面示例代码中，使用<code class="docutils literal notranslate"><span class="pre">mindspore.nn</span></code>模块构建一个Conv + Batch Normalization + ReLu模型网络。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">ConvBNReLU</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConvBNReLU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">ConvBNReLU</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
ConvBNReLU&lt;
  (conv): Conv2d&lt;input_channels=3, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW&gt;
  (bn): BatchNorm2d&lt;num_features=64, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=bn.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=bn.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=bn.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=bn.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)&gt;
  (relu): ReLU&lt;&gt;
  &gt;
</pre></div></div>
</div>
</section>
<section id="容器构建网络">
<h3>容器构建网络<a class="headerlink" href="#容器构建网络" title="Permalink to this headline"></a></h3>
<p>为了便于管理和组成更复杂的网络，<code class="docutils literal notranslate"><span class="pre">mindspore.nn</span></code>提供了容器对网络中的子模型块或模型层进行管理，有<code class="docutils literal notranslate"><span class="pre">nn.CellList</span></code>和<code class="docutils literal notranslate"><span class="pre">nn.SequentialCell</span></code>两种方式。</p>
<ol class="arabic simple">
<li><p>CellList构建网络</p></li>
</ol>
<p>使用<code class="docutils literal notranslate"><span class="pre">nn.CellList</span></code>构造的Cell既可以是模型层，也可以是构建的网络子块。<code class="docutils literal notranslate"><span class="pre">nn.CellList</span></code>支持<code class="docutils literal notranslate"><span class="pre">append</span></code>、<code class="docutils literal notranslate"><span class="pre">extend</span></code>方法和<code class="docutils literal notranslate"><span class="pre">insert</span></code>方法三种方法。</p>
<p>在运行网络时，可以在construct方法里，使用for循环，运行输出结果。</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">append(cell)</span></code>：在列表末尾添加一个cell。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">extend（cells)</span></code>：将cells添加至列表末尾。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">insert(index,</span> <span class="pre">cell)</span></code>：在列表给定的索引之前插入给定的cell。</p></li>
</ul>
<p>如下使用<code class="docutils literal notranslate"><span class="pre">nn.CellList</span></code>构建并执行一个网络，依次包含一个之前定义的模型子块ConvBNReLU、一个Conv2d层、一个BatchNorm2d层和一个ReLU层：</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">MyNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">ConvBNReLU</span><span class="p">()]</span>
        <span class="c1"># 使用CellList对网络进行管理</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build_block</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CellList</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

        <span class="c1"># 使用append方法添加Conv2d层和ReLU层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build_block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build_block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

        <span class="c1"># 使用insert方法在Conv2d层和ReLU层中间插入BatchNorm2d</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build_block</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># for循环执行网络</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_block</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">MyNet</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
MyNet&lt;
  (build_block): CellList&lt;
    (0): ConvBNReLU&lt;
      (conv): Conv2d&lt;input_channels=3, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW&gt;
      (bn): BatchNorm2d&lt;num_features=64, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=build_block.0.bn.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=build_block.0.bn.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=build_block.0.bn.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=build_block.0.bn.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)&gt;
      (relu): ReLU&lt;&gt;
      &gt;
    (1): Conv2d&lt;input_channels=64, output_channels=4, kernel_size=(4, 4), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW&gt;
    (2): BatchNorm2d&lt;num_features=4, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=build_block.2.gamma, shape=(4,), dtype=Float32, requires_grad=True), beta=Parameter (name=build_block.2.beta, shape=(4,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=build_block.2.moving_mean, shape=(4,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=build_block.2.moving_variance, shape=(4,), dtype=Float32, requires_grad=False)&gt;
    (3): ReLU&lt;&gt;
    &gt;
  &gt;
</pre></div></div>
</div>
<p>把数据输入到网络模型中：</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(1, 4, 64, 32)
</pre></div></div>
</div>
<ol class="arabic simple" start="2">
<li><p>SequentialCell构建网络</p></li>
</ol>
<p>使用<code class="docutils literal notranslate"><span class="pre">nn.SequentialCell</span></code>构造Cell顺序容器，支持子模块以List或OrderedDict格式作为输入。</p>
<p>不同于<code class="docutils literal notranslate"><span class="pre">nn.CellList</span></code>的是，<code class="docutils literal notranslate"><span class="pre">nn.SequentialCell</span></code>类内部实现了<code class="docutils literal notranslate"><span class="pre">construct</span></code>方法，可以直接输出结果。</p>
<p>如下示例使用<code class="docutils literal notranslate"><span class="pre">nn.SequentialCell</span></code>构建一个网络，输入为List，网络结构依次包含一个之前定义的模型子块ConvBNReLU、一个Conv2d层、一个BatchNorm2d层和一个ReLU层：</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">MyNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">ConvBNReLU</span><span class="p">()]</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
                       <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
                       <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build_block</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>  <span class="c1"># 使用SequentialCell对网络进行管理</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">MyNet</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
MyNet&lt;
  (build_block): SequentialCell&lt;
    (0): ConvBNReLU&lt;
      (conv): Conv2d&lt;input_channels=3, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW&gt;
      (bn): BatchNorm2d&lt;num_features=64, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=build_block.0.bn.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=build_block.0.bn.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=build_block.0.bn.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=build_block.0.bn.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)&gt;
      (relu): ReLU&lt;&gt;
      &gt;
    (1): Conv2d&lt;input_channels=64, output_channels=4, kernel_size=(4, 4), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW&gt;
    (2): BatchNorm2d&lt;num_features=4, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=build_block.2.gamma, shape=(4,), dtype=Float32, requires_grad=True), beta=Parameter (name=build_block.2.beta, shape=(4,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=build_block.2.moving_mean, shape=(4,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=build_block.2.moving_variance, shape=(4,), dtype=Float32, requires_grad=False)&gt;
    (3): ReLU&lt;&gt;
    &gt;
  &gt;
</pre></div></div>
</div>
<p>把数据输入到网络模型中：</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(1, 4, 64, 32)
</pre></div></div>
</div>
<p>如下示例使用<code class="docutils literal notranslate"><span class="pre">nn.SequentialCell</span></code>构建一个网络，输入为OrderedDict：</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>

<span class="k">class</span> <span class="nc">MyNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>

        <span class="c1"># 将cells加入字典</span>
        <span class="n">layers</span><span class="p">[</span><span class="s2">&quot;ConvBNReLU&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ConvBNReLU</span><span class="p">()</span>
        <span class="n">layers</span><span class="p">[</span><span class="s2">&quot;conv&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="n">layers</span><span class="p">[</span><span class="s2">&quot;norm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
        <span class="n">layers</span><span class="p">[</span><span class="s2">&quot;relu&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="c1"># 使用SequentialCell对网络进行管理</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build_block</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">MyNet</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

<span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
MyNet&lt;
  (build_block): SequentialCell&lt;
    (ConvBNReLU): ConvBNReLU&lt;
      (conv): Conv2d&lt;input_channels=3, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW&gt;
      (bn): BatchNorm2d&lt;num_features=64, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=build_block.ConvBNReLU.bn.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=build_block.ConvBNReLU.bn.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=build_block.ConvBNReLU.bn.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=build_block.ConvBNReLU.bn.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)&gt;
      (relu): ReLU&lt;&gt;
      &gt;
    (conv): Conv2d&lt;input_channels=64, output_channels=4, kernel_size=(4, 4), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW&gt;
    (norm): BatchNorm2d&lt;num_features=4, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=build_block.norm.gamma, shape=(4,), dtype=Float32, requires_grad=True), beta=Parameter (name=build_block.norm.beta, shape=(4,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=build_block.norm.moving_mean, shape=(4,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=build_block.norm.moving_variance, shape=(4,), dtype=Float32, requires_grad=False)&gt;
    (relu): ReLU&lt;&gt;
    &gt;
  &gt;
(1, 4, 64, 32)
</pre></div></div>
</div>
</section>
</section>
<section id="nn与ops关系">
<h2>nn与ops关系<a class="headerlink" href="#nn与ops关系" title="Permalink to this headline"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">mindspore.nn</span></code>模块是Python实现的模型组件，对低阶API的封装，主要包括神经网络模型相关的各种模型层、损失函数、优化器等。</p>
<p>同时<code class="docutils literal notranslate"><span class="pre">mindspore.nn</span></code>也提供了部分与<code class="docutils literal notranslate"><span class="pre">mindspore.ops</span></code>算子同名的接口，主要作用是对<code class="docutils literal notranslate"><span class="pre">mindspore.ops</span></code>算子进行进一步封装，为用户提供更友好的API。用户也可使用<code class="docutils literal notranslate"><span class="pre">mindspore.ops</span></code>算子根据实际场景实现自定义的网络。</p>
<p>如下示例使用<code class="docutils literal notranslate"><span class="pre">mindspore.ops.Conv2D</span></code>算子实现卷积计算功能，即<code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code>算子功能。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Parameter</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">initializer</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2d</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias_add</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">BiasAdd</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span>
            <span class="n">initializer</span><span class="p">(</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">]),</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv.weight&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">out_channels</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv.bias&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;输入数据x&quot;&quot;&quot;</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="optim.html" class="btn btn-neutral float-left" title="优化器" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="derivation.html" class="btn btn-neutral float-right" title="自动求导" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
        <script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>