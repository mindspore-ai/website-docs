

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>æ–‡æœ¬æ•°æ®åŠ è½½ä¸å¢å¼º &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/js/training.js"></script>
        
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="å›¾æ•°æ®åŠ è½½ä¸å¤„ç†" href="augment_graph_data.html" />
    <link rel="prev" title="å›¾åƒæ•°æ®åŠ è½½ä¸å¢å¼º" href="augment_image_data.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">åˆå­¦æ•™ç¨‹</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introduction.html">åŸºæœ¬ä»‹ç»</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/quick_start.html">å¿«é€Ÿå…¥é—¨ï¼šæ‰‹å†™æ•°å­—è¯†åˆ«</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/tensor.html">å¼ é‡ Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/dataset.html">æ•°æ®å¤„ç†</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/model.html">åˆ›å»ºç½‘ç»œ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/autograd.html">è‡ªåŠ¨å¾®åˆ†</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/train.html">æ¨¡å‹è®­ç»ƒ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/save_load.html">ä¿å­˜ä¸åŠ è½½</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/infer.html">æ¨ç†ä¸éƒ¨ç½²</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">è¿›é˜¶æ•™ç¨‹</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../linear_fitting.html">è¿›é˜¶æ¡ˆä¾‹ï¼šçº¿æ€§æ‹Ÿåˆ</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../dataset.html">æ•°æ®å¤„ç†</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="sampler.html">æ•°æ®é‡‡æ ·</a></li>
<li class="toctree-l2"><a class="reference internal" href="transform.html">æ•°æ®å¤„ç†</a></li>
<li class="toctree-l2"><a class="reference internal" href="iterator.html">æ•°æ®è¿­ä»£</a></li>
<li class="toctree-l2"><a class="reference internal" href="record.html">æ ¼å¼è½¬æ¢</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom.html">è‡ªå®šä¹‰æ•°æ®é›†</a></li>
<li class="toctree-l2"><a class="reference internal" href="augment_common_data.html">é€šç”¨æ•°æ®åŠ è½½ä¸å¢å¼º</a></li>
<li class="toctree-l2"><a class="reference internal" href="augment_image_data.html">å›¾åƒæ•°æ®åŠ è½½ä¸å¢å¼º</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">æ–‡æœ¬æ•°æ®åŠ è½½ä¸å¢å¼º</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#åŠ è½½æ–‡æœ¬æ•°æ®">åŠ è½½æ–‡æœ¬æ•°æ®</a></li>
<li class="toctree-l3"><a class="reference internal" href="#æ–‡æœ¬æ•°æ®å¢å¼º">æ–‡æœ¬æ•°æ®å¢å¼º</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#æ„é€ ä¸ä½¿ç”¨è¯æ±‡è¡¨">æ„é€ ä¸ä½¿ç”¨è¯æ±‡è¡¨</a></li>
<li class="toctree-l4"><a class="reference internal" href="#åˆ†è¯å™¨">åˆ†è¯å™¨</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="augment_graph_data.html">å›¾æ•°æ®åŠ è½½ä¸å¤„ç†</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../network.html">ç½‘ç»œæ„å»º</a></li>
<li class="toctree-l1"><a class="reference internal" href="../train.html">è®­ç»ƒä¸è¯„ä¼°</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pynative_graph.html">åŠ¨æ€å›¾ä¸é™æ€å›¾</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../dataset.html">æ•°æ®å¤„ç†</a> &raquo;</li>
      <li>æ–‡æœ¬æ•°æ®åŠ è½½ä¸å¢å¼º</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/advanced/dataset/augment_text_data.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="æ–‡æœ¬æ•°æ®åŠ è½½ä¸å¢å¼º">
<h1>æ–‡æœ¬æ•°æ®åŠ è½½ä¸å¢å¼º<a class="headerlink" href="#æ–‡æœ¬æ•°æ®åŠ è½½ä¸å¢å¼º" title="Permalink to this headline">ïƒ</a></h1>
<p><a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/r1.8/tutorials/zh_cn/advanced/dataset/mindspore_augment_text_data.ipynb"><img alt="ä¸‹è½½Notebook" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_notebook.png" /></a>â€ƒ <a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/r1.8/tutorials/zh_cn/advanced/dataset/mindspore_augment_text_data.py"><img alt="ä¸‹è½½æ ·ä¾‹ä»£ç " src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_download_code.png" /></a>â€ƒ <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.8/tutorials/source_zh_cn/advanced/dataset/augment_text_data.ipynb"><img alt="æŸ¥çœ‹æºæ–‡ä»¶" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/resource/_static/logo_source.png" /></a></p>
<p>éšç€å¯è·å¾—çš„æ–‡æœ¬æ•°æ®é€æ­¥å¢å¤šï¼Œå¯¹æ–‡æœ¬æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œä»¥ä¾¿è·å¾—å¯ç”¨äºç½‘ç»œè®­ç»ƒæ‰€éœ€å¹²å‡€æ•°æ®çš„è¯‰æ±‚ä¹Ÿæ›´ä¸ºè¿«åˆ‡ã€‚æ–‡æœ¬æ•°æ®é›†é¢„å¤„ç†é€šå¸¸åŒ…æ‹¬æ–‡æœ¬æ•°æ®é›†åŠ è½½ä¸æ•°æ®å¢å¼ºä¸¤éƒ¨åˆ†ã€‚</p>
<p>æ–‡æœ¬æ•°æ®åŠ è½½é€šå¸¸åŒ…å«ä»¥ä¸‹ä¸‰ç§æ–¹å¼ï¼š</p>
<ol class="arabic simple">
<li><p>é€šè¿‡æ–‡æœ¬è¯»å–çš„Datasetæ¥å£å¦‚<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/dataset/mindspore.dataset.CLUEDataset.html#mindspore.dataset.CLUEDataset">ClueDataset</a>ã€<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/dataset/mindspore.dataset.TextFileDataset.html#mindspore.dataset.TextFileDataset">TextFileDataset</a>è¿›è¡Œè¯»å–ã€‚</p></li>
<li><p>å°†æ•°æ®é›†è½¬æˆæ ‡å‡†æ ¼å¼ï¼ˆå¦‚MindRecordæ ¼å¼ï¼‰ï¼Œå†é€šè¿‡å¯¹åº”æ¥å£ï¼ˆå¦‚<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/dataset/mindspore.dataset.MindDataset.html#mindspore.dataset.MindDataset">MindDataset</a>ï¼‰è¿›è¡Œè¯»å–ã€‚</p></li>
<li><p>é€šè¿‡GeneratorDatasetæ¥å£ï¼Œæ¥æ”¶ç”¨æˆ·è‡ªå®šä¹‰çš„æ•°æ®é›†åŠ è½½å‡½æ•°ï¼Œè¿›è¡Œæ•°æ®åŠ è½½ï¼Œç”¨æ³•å¯å‚è€ƒ<a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r1.8/advanced/dataset/custom.html">è‡ªå®šä¹‰æ•°æ®é›†åŠ è½½</a>ç« èŠ‚ã€‚</p></li>
</ol>
<section id="åŠ è½½æ–‡æœ¬æ•°æ®">
<h2>åŠ è½½æ–‡æœ¬æ•°æ®<a class="headerlink" href="#åŠ è½½æ–‡æœ¬æ•°æ®" title="Permalink to this headline">ïƒ</a></h2>
<p>ä¸‹é¢æˆ‘ä»¬ä»¥ä»TXTæ–‡ä»¶ä¸­è¯»å–æ•°æ®ä¸ºä¾‹ï¼Œä»‹ç»<code class="docutils literal notranslate"><span class="pre">TextFileDataset</span></code>çš„ä½¿ç”¨æ–¹å¼ï¼Œæ›´å¤šæ–‡æœ¬æ•°æ®é›†åŠ è½½ç›¸å…³ä¿¡æ¯å¯å‚è€ƒ<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore.dataset.html#æ–‡æœ¬">APIæ–‡æ¡£</a>ã€‚</p>
<ol class="arabic simple">
<li><p>å‡†å¤‡æ–‡æœ¬æ•°æ®ï¼Œå†…å®¹å¦‚ä¸‹ï¼š</p></li>
</ol>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Welcome to Beijing
åŒ—äº¬æ¬¢è¿æ‚¨ï¼
æˆ‘å–œæ¬¢China!
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>åˆ›å»º<code class="docutils literal notranslate"><span class="pre">tokenizer.txt</span></code>æ–‡ä»¶å¹¶å¤åˆ¶æ–‡æœ¬æ•°æ®åˆ°è¯¥æ–‡ä»¶ä¸­ï¼Œå°†è¯¥æ–‡ä»¶å­˜æ”¾åœ¨./datasetsè·¯å¾„ä¸‹ã€‚æ‰§è¡Œå¦‚ä¸‹ä»£ç ï¼š</p></li>
</ol>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">&#39;./datasets&#39;</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s1">&#39;./datasets&#39;</span><span class="p">)</span>

<span class="c1"># æŠŠä¸Šé¢çš„æ–‡æœ¬æ•°æ®å†™å…¥æ–‡ä»¶tokenizer.txt</span>
<span class="n">file_handle</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;./datasets/tokenizer.txt&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">)</span>
<span class="n">file_handle</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;Welcome to Beijing </span><span class="se">\n</span><span class="s1">åŒ—äº¬æ¬¢è¿æ‚¨ï¼ </span><span class="se">\n</span><span class="s1">æˆ‘å–œæ¬¢China! </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">file_handle</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>ä¸Šé¢çš„ä»£ç æ‰§è¡Œå®Œåï¼Œæ•°æ®é›†ç»“æ„ä¸ºï¼š</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./datasets
â””â”€â”€ tokenizer.txt
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>ä»TXTæ–‡ä»¶ä¸­åŠ è½½æ•°æ®é›†å¹¶æ‰“å°ã€‚ä»£ç å¦‚ä¸‹ï¼š</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.text</span> <span class="k">as</span> <span class="nn">text</span>

<span class="c1"># å®šä¹‰æ–‡æœ¬æ•°æ®é›†çš„åŠ è½½è·¯å¾„</span>
<span class="n">DATA_FILE</span> <span class="o">=</span> <span class="s1">&#39;./datasets/tokenizer.txt&#39;</span>

<span class="c1"># ä»tokenizer.txtä¸­åŠ è½½æ•°æ®é›†</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">TextFileDataset</span><span class="p">(</span><span class="n">DATA_FILE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Welcome to Beijing
åŒ—äº¬æ¬¢è¿æ‚¨ï¼
æˆ‘å–œæ¬¢China!
</pre></div></div>
</div>
</section>
<section id="æ–‡æœ¬æ•°æ®å¢å¼º">
<h2>æ–‡æœ¬æ•°æ®å¢å¼º<a class="headerlink" href="#æ–‡æœ¬æ•°æ®å¢å¼º" title="Permalink to this headline">ïƒ</a></h2>
<p>é’ˆå¯¹æ–‡æœ¬æ•°æ®å¢å¼ºï¼Œå¸¸ç”¨æ“ä½œåŒ…å«æ–‡æœ¬åˆ†è¯ã€è¯æ±‡è¡¨æŸ¥æ‰¾ç­‰ï¼š</p>
<ul class="simple">
<li><p>æ–‡æœ¬åˆ†è¯ï¼šå°†åŸå§‹ä¸€é•¿ä¸²å¥å­åˆ†å‰²æˆå¤šä¸ªåŸºæœ¬çš„è¯æ±‡ã€‚</p></li>
<li><p>è¯æ±‡è¡¨æŸ¥æ‰¾ï¼šæŸ¥æ‰¾åˆ†å‰²åå„è¯æ±‡å¯¹åº”çš„idï¼Œå¹¶å°†å¥å­ä¸­åŒ…å«çš„idç»„æˆè¯å‘é‡ä¼ å…¥ç½‘ç»œè¿›è¡Œè®­ç»ƒã€‚</p></li>
</ul>
<p>ä¸‹é¢å¯¹æ•°æ®å¢å¼ºè¿‡ç¨‹ä¸­ç”¨åˆ°çš„åˆ†è¯åŠŸèƒ½ã€è¯æ±‡è¡¨æŸ¥æ‰¾ç­‰åŠŸèƒ½è¿›è¡Œä»‹ç»ï¼Œæ›´å¤šå…³äºæ–‡æœ¬å¤„ç†APIçš„ä½¿ç”¨è¯´æ˜ï¼Œå¯ä»¥å‚è€ƒ<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore.dataset.text.html">APIæ–‡æ¡£</a>ã€‚</p>
<section id="æ„é€ ä¸ä½¿ç”¨è¯æ±‡è¡¨">
<h3>æ„é€ ä¸ä½¿ç”¨è¯æ±‡è¡¨<a class="headerlink" href="#æ„é€ ä¸ä½¿ç”¨è¯æ±‡è¡¨" title="Permalink to this headline">ïƒ</a></h3>
<p>è¯æ±‡è¡¨æä¾›äº†å•è¯ä¸idå¯¹åº”çš„æ˜ å°„å…³ç³»ï¼Œé€šè¿‡è¯æ±‡è¡¨ï¼Œè¾“å…¥å•è¯èƒ½æ‰¾åˆ°å¯¹åº”çš„å•è¯idï¼Œåä¹‹ä¾æ®å•è¯idä¹Ÿèƒ½è·å–å¯¹åº”çš„å•è¯ã€‚</p>
<p>MindSporeæä¾›äº†å¤šç§æ„é€ è¯æ±‡è¡¨ï¼ˆVocabï¼‰çš„æ–¹æ³•ï¼Œå¯ä»¥ä»å­—å…¸ã€æ–‡ä»¶ã€åˆ—è¡¨ä»¥åŠDatasetå¯¹è±¡ä¸­è·å–åŸå§‹æ•°æ®ï¼Œä»¥ä¾¿æ„é€ è¯æ±‡è¡¨ï¼Œå¯¹åº”çš„æ¥å£ä¸ºï¼š<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/dataset_text/mindspore.dataset.text.Vocab.html#mindspore.dataset.text.Vocab.from_dict">from_dict</a>ã€<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/dataset_text/mindspore.dataset.text.Vocab.html#mindspore.dataset.text.Vocab.from_file">from_file</a>ã€<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/dataset_text/mindspore.dataset.text.Vocab.html#mindspore.dataset.text.Vocab.from_list">from_list</a>ã€<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/dataset_text/mindspore.dataset.text.Vocab.html#mindspore.dataset.text.Vocab.from_dataset">from_dataset</a>ã€‚</p>
<p>ä»¥from_dictä¸ºä¾‹ï¼Œæ„é€ Vocabçš„æ–¹å¼å¦‚ä¸‹ï¼Œä¼ å…¥çš„dictä¸­åŒ…å«å¤šç»„å•è¯å’Œidå¯¹ã€‚</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.dataset</span> <span class="kn">import</span> <span class="n">text</span>

<span class="c1"># æ„é€ è¯æ±‡è¡¨</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">Vocab</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s2">&quot;home&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;behind&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;the&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;world&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s2">&quot;&lt;unk&gt;&quot;</span><span class="p">:</span> <span class="mi">6</span><span class="p">})</span>
</pre></div>
</div>
</div>
<p>Vocabæä¾›äº†å•è¯ä¸idä¹‹é—´ç›¸äº’æŸ¥è¯¢çš„æ–¹æ³•ï¼Œå³ï¼š<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/dataset_text/mindspore.dataset.text.Vocab.html#mindspore.dataset.text.Vocab.tokens_to_ids">tokens_to_ids</a>å’Œ<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/dataset_text/mindspore.dataset.text.Vocab.html#mindspore.dataset.text.Vocab.ids_to_tokens">ids_to_tokens</a>æ–¹æ³•ï¼Œç”¨æ³•å¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># æ ¹æ®å•è¯æŸ¥æ‰¾id</span>
<span class="n">ids</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">tokens_to_ids</span><span class="p">([</span><span class="s2">&quot;home&quot;</span><span class="p">,</span> <span class="s2">&quot;world&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ids: &quot;</span><span class="p">,</span> <span class="n">ids</span><span class="p">)</span>

<span class="c1"># æ ¹æ®idæŸ¥æ‰¾å•è¯</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">ids_to_tokens</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;tokens: &quot;</span><span class="p">,</span> <span class="n">tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
ids:  [3, 5]
tokens:  [&#39;behind&#39;, &#39;world&#39;]
</pre></div></div>
</div>
<p>ä»ä¸Šé¢æ‰“å°çš„ç»“æœå¯ä»¥çœ‹å‡ºï¼š</p>
<ul class="simple">
<li><p>å•è¯<code class="docutils literal notranslate"><span class="pre">&quot;home&quot;</span></code>å’Œ<code class="docutils literal notranslate"><span class="pre">&quot;world&quot;</span></code>çš„idåˆ†åˆ«ä¸º<code class="docutils literal notranslate"><span class="pre">3</span></code>å’Œ<code class="docutils literal notranslate"><span class="pre">5</span></code>ï¼›</p></li>
<li><p>idä¸º<code class="docutils literal notranslate"><span class="pre">2</span></code>çš„å•è¯ä¸º<code class="docutils literal notranslate"><span class="pre">&quot;behind&quot;</span></code>ï¼Œidä¸º<code class="docutils literal notranslate"><span class="pre">5</span></code>çš„å•è¯ä¸º<code class="docutils literal notranslate"><span class="pre">&quot;world&quot;</span></code>ï¼›</p></li>
</ul>
<p>è¿™ä¸€ç»“æœä¹Ÿä¸è¯æ±‡è¡¨ä¸€è‡´ã€‚æ­¤å¤–Vocabä¹Ÿæ˜¯å¤šç§åˆ†è¯å™¨ï¼ˆå¦‚WordpieceTokenizerï¼‰çš„å¿…è¦å…¥å‚ï¼Œåˆ†è¯æ—¶ä¼šå°†å¥å­ä¸­å­˜åœ¨äºè¯æ±‡è¡¨çš„å•è¯ï¼Œå‰ååˆ†å‰²å¼€ï¼Œå˜æˆå•ç‹¬çš„ä¸€ä¸ªè¯æ±‡ï¼Œä¹‹åé€šè¿‡æŸ¥æ‰¾è¯æ±‡è¡¨èƒ½å¤Ÿè·å–å¯¹åº”çš„è¯æ±‡idã€‚</p>
</section>
<section id="åˆ†è¯å™¨">
<h3>åˆ†è¯å™¨<a class="headerlink" href="#åˆ†è¯å™¨" title="Permalink to this headline">ïƒ</a></h3>
<p>åˆ†è¯å°±æ˜¯å°†è¿ç»­çš„å­—åºåˆ—æŒ‰ç…§ä¸€å®šçš„è§„èŒƒåˆ’åˆ†æˆè¯åºåˆ—çš„è¿‡ç¨‹ï¼Œåˆç†çš„åˆ†è¯æœ‰åŠ©äºè¯­ä¹‰ç†è§£ã€‚</p>
<p>MindSporeæä¾›äº†å¤šç§ä¸åŒç”¨é€”çš„åˆ†è¯å™¨ï¼Œå¦‚BasicTokenizerã€BertTokenizerã€JiebaTokenizerç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·é«˜æ€§èƒ½åœ°å¤„ç†æ–‡æœ¬ã€‚ç”¨æˆ·å¯ä»¥æ„å»ºè‡ªå·±çš„å­—å…¸ï¼Œä½¿ç”¨é€‚å½“çš„æ ‡è®°å™¨å°†å¥å­æ‹†åˆ†ä¸ºä¸åŒçš„æ ‡è®°ï¼Œå¹¶é€šè¿‡æŸ¥æ‰¾æ“ä½œè·å–å­—å…¸ä¸­æ ‡è®°çš„ç´¢å¼•ã€‚æ­¤å¤–ï¼Œç”¨æˆ·ä¹Ÿå¯ä»¥æ ¹æ®éœ€è¦å®ç°è‡ªå®šä¹‰çš„åˆ†è¯å™¨ã€‚</p>
<blockquote>
<div><p>ä¸‹é¢ä»‹ç»å‡ ç§å¸¸ç”¨åˆ†è¯å™¨çš„ä½¿ç”¨æ–¹æ³•ï¼Œæ›´å¤šåˆ†è¯å™¨ç›¸å…³ä¿¡æ¯è¯·å‚è€ƒ<a class="reference external" href="https://mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore.dataset.text.html">APIæ–‡æ¡£</a>ã€‚</p>
</div></blockquote>
<section id="berttokenizer">
<h4>BertTokenizer<a class="headerlink" href="#berttokenizer" title="Permalink to this headline">ïƒ</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">BertTokenizer</span></code>æ“ä½œæ˜¯é€šè¿‡è°ƒç”¨<code class="docutils literal notranslate"><span class="pre">BasicTokenizer</span></code>å’Œ<code class="docutils literal notranslate"><span class="pre">WordpieceTokenizer</span></code>æ¥è¿›è¡Œåˆ†è¯çš„ã€‚</p>
<p>ä¸‹é¢çš„æ ·ä¾‹é¦–å…ˆæ„å»ºäº†ä¸€ä¸ªæ–‡æœ¬æ•°æ®é›†å’Œå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œç„¶åé€šè¿‡<code class="docutils literal notranslate"><span class="pre">BertTokenizer</span></code>å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯ï¼Œå¹¶å±•ç¤ºäº†åˆ†è¯å‰åçš„æ–‡æœ¬ç»“æœã€‚</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.text</span> <span class="k">as</span> <span class="nn">text</span>

<span class="c1"># æ„é€ å¾…åˆ†è¯æ•°æ®</span>
<span class="n">input_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;åºŠå‰æ˜æœˆå…‰&quot;</span><span class="p">,</span> <span class="s2">&quot;ç–‘æ˜¯åœ°ä¸Šéœœ&quot;</span><span class="p">,</span> <span class="s2">&quot;ä¸¾å¤´æœ›æ˜æœˆ&quot;</span><span class="p">,</span> <span class="s2">&quot;ä½å¤´æ€æ•…ä¹¡&quot;</span><span class="p">,</span> <span class="s2">&quot;I am making small mistakes during working hours&quot;</span><span class="p">,</span>
              <span class="s2">&quot;ğŸ˜€å˜¿å˜¿ğŸ˜ƒå“ˆå“ˆğŸ˜„å¤§ç¬‘ğŸ˜å˜»å˜»&quot;</span><span class="p">,</span> <span class="s2">&quot;ç¹é«”å­—&quot;</span><span class="p">]</span>

<span class="c1"># åŠ è½½æ–‡æœ¬æ•°æ®é›†</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">input_list</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------before tokenization----------------------------&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
------------------------before tokenization----------------------------
åºŠå‰æ˜æœˆå…‰
ç–‘æ˜¯åœ°ä¸Šéœœ
ä¸¾å¤´æœ›æ˜æœˆ
ä½å¤´æ€æ•…ä¹¡
I am making small mistakes during working hours
ğŸ˜€å˜¿å˜¿ğŸ˜ƒå“ˆå“ˆğŸ˜„å¤§ç¬‘ğŸ˜å˜»å˜»
ç¹é«”å­—
</pre></div></div>
</div>
<p>ä¸Šé¢ä¸ºæ•°æ®é›†æœªè¢«åˆ†è¯å‰çš„æ•°æ®æ‰“å°æƒ…å†µï¼Œä¸‹é¢ä½¿ç”¨<code class="docutils literal notranslate"><span class="pre">BertTokenizer</span></code>åˆ†è¯å™¨å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯ã€‚</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># æ„å»ºè¯æ±‡è¡¨</span>
<span class="n">vocab_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;åºŠ&quot;</span><span class="p">,</span> <span class="s2">&quot;å‰&quot;</span><span class="p">,</span> <span class="s2">&quot;æ˜&quot;</span><span class="p">,</span> <span class="s2">&quot;æœˆ&quot;</span><span class="p">,</span> <span class="s2">&quot;å…‰&quot;</span><span class="p">,</span> <span class="s2">&quot;ç–‘&quot;</span><span class="p">,</span> <span class="s2">&quot;æ˜¯&quot;</span><span class="p">,</span> <span class="s2">&quot;åœ°&quot;</span><span class="p">,</span> <span class="s2">&quot;ä¸Š&quot;</span><span class="p">,</span> <span class="s2">&quot;éœœ&quot;</span><span class="p">,</span> <span class="s2">&quot;ä¸¾&quot;</span><span class="p">,</span> <span class="s2">&quot;å¤´&quot;</span><span class="p">,</span> <span class="s2">&quot;æœ›&quot;</span><span class="p">,</span> <span class="s2">&quot;ä½&quot;</span><span class="p">,</span> <span class="s2">&quot;æ€&quot;</span><span class="p">,</span> <span class="s2">&quot;æ•…&quot;</span><span class="p">,</span> <span class="s2">&quot;ä¹¡&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ç¹&quot;</span><span class="p">,</span> <span class="s2">&quot;é«”&quot;</span><span class="p">,</span> <span class="s2">&quot;å­—&quot;</span><span class="p">,</span> <span class="s2">&quot;å˜¿&quot;</span><span class="p">,</span> <span class="s2">&quot;å“ˆ&quot;</span><span class="p">,</span> <span class="s2">&quot;å¤§&quot;</span><span class="p">,</span> <span class="s2">&quot;ç¬‘&quot;</span><span class="p">,</span> <span class="s2">&quot;å˜»&quot;</span><span class="p">,</span> <span class="s2">&quot;i&quot;</span><span class="p">,</span> <span class="s2">&quot;am&quot;</span><span class="p">,</span> <span class="s2">&quot;mak&quot;</span><span class="p">,</span> <span class="s2">&quot;make&quot;</span><span class="p">,</span> <span class="s2">&quot;small&quot;</span><span class="p">,</span> <span class="s2">&quot;mistake&quot;</span><span class="p">,</span>
    <span class="s2">&quot;##s&quot;</span><span class="p">,</span> <span class="s2">&quot;during&quot;</span><span class="p">,</span> <span class="s2">&quot;work&quot;</span><span class="p">,</span> <span class="s2">&quot;##ing&quot;</span><span class="p">,</span> <span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;ğŸ˜€&quot;</span><span class="p">,</span> <span class="s2">&quot;ğŸ˜ƒ&quot;</span><span class="p">,</span> <span class="s2">&quot;ğŸ˜„&quot;</span><span class="p">,</span> <span class="s2">&quot;ğŸ˜&quot;</span><span class="p">,</span> <span class="s2">&quot;+&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="s2">&quot;=&quot;</span><span class="p">,</span> <span class="s2">&quot;12&quot;</span><span class="p">,</span>
    <span class="s2">&quot;28&quot;</span><span class="p">,</span> <span class="s2">&quot;40&quot;</span><span class="p">,</span> <span class="s2">&quot;16&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;I&quot;</span><span class="p">,</span> <span class="s2">&quot;[CLS]&quot;</span><span class="p">,</span> <span class="s2">&quot;[SEP]&quot;</span><span class="p">,</span> <span class="s2">&quot;[UNK]&quot;</span><span class="p">,</span> <span class="s2">&quot;[PAD]&quot;</span><span class="p">,</span> <span class="s2">&quot;[MASK]&quot;</span><span class="p">,</span> <span class="s2">&quot;[unused1]&quot;</span><span class="p">,</span> <span class="s2">&quot;[unused10]&quot;</span><span class="p">]</span>

<span class="c1"># åŠ è½½è¯æ±‡è¡¨</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">Vocab</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="n">vocab_list</span><span class="p">)</span>

<span class="c1"># ä½¿ç”¨BertTokenizeråˆ†è¯å™¨å¯¹æ–‡æœ¬æ•°æ®é›†è¿›è¡Œåˆ†è¯æ“ä½œ</span>
<span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">BertTokenizer</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------after tokenization-----------------------------&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
------------------------after tokenization-----------------------------
[&#39;åºŠ&#39; &#39;å‰&#39; &#39;æ˜&#39; &#39;æœˆ&#39; &#39;å…‰&#39;]
[&#39;ç–‘&#39; &#39;æ˜¯&#39; &#39;åœ°&#39; &#39;ä¸Š&#39; &#39;éœœ&#39;]
[&#39;ä¸¾&#39; &#39;å¤´&#39; &#39;æœ›&#39; &#39;æ˜&#39; &#39;æœˆ&#39;]
[&#39;ä½&#39; &#39;å¤´&#39; &#39;æ€&#39; &#39;æ•…&#39; &#39;ä¹¡&#39;]
[&#39;I&#39; &#39;am&#39; &#39;mak&#39; &#39;##ing&#39; &#39;small&#39; &#39;mistake&#39; &#39;##s&#39; &#39;during&#39; &#39;work&#39; &#39;##ing&#39;
 &#39;hour&#39; &#39;##s&#39;]
[&#39;ğŸ˜€&#39; &#39;å˜¿&#39; &#39;å˜¿&#39; &#39;ğŸ˜ƒ&#39; &#39;å“ˆ&#39; &#39;å“ˆ&#39; &#39;ğŸ˜„&#39; &#39;å¤§&#39; &#39;ç¬‘&#39; &#39;ğŸ˜&#39; &#39;å˜»&#39; &#39;å˜»&#39;]
[&#39;ç¹&#39; &#39;é«”&#39; &#39;å­—&#39;]
</pre></div></div>
</div>
<p>ä»ä¸Šé¢ä¸¤æ¬¡çš„æ‰“å°ç»“æœå¯ä»¥çœ‹å‡ºï¼Œæ•°æ®é›†ä¸­çš„å¥å­ã€è¯è¯­å’Œè¡¨æƒ…ç¬¦å·ç­‰éƒ½è¢«<code class="docutils literal notranslate"><span class="pre">BertTokenizer</span></code>åˆ†è¯å™¨ä»¥è¯æ±‡è¡¨ä¸­çš„è¯æ±‡ä¸ºæœ€å°å•å…ƒè¿›è¡Œäº†åˆ†å‰²ï¼Œâ€œæ•…ä¹¡â€è¢«åˆ†å‰²æˆäº†â€˜æ•…â€™å’Œâ€˜ä¹¡â€™ï¼Œâ€œæ˜æœˆâ€è¢«åˆ†å‰²æˆäº†â€˜æ˜â€™å’Œâ€˜æœˆâ€™ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œâ€œmistakesâ€è¢«åˆ†å‰²æˆäº†â€˜mistakeâ€™å’Œâ€˜##sâ€™ã€‚</p>
</section>
<section id="jiebatokenizer">
<h4>JiebaTokenizer<a class="headerlink" href="#jiebatokenizer" title="Permalink to this headline">ïƒ</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">JiebaTokenizer</span></code>æ“ä½œæ˜¯åŸºäºjiebaçš„ä¸­æ–‡åˆ†è¯ã€‚</p>
<p>ä»¥ä¸‹ç¤ºä¾‹ä»£ç å®Œæˆä¸‹è½½å­—å…¸æ–‡ä»¶<code class="docutils literal notranslate"><span class="pre">hmm_model.utf8</span></code>å’Œ<code class="docutils literal notranslate"><span class="pre">jieba.dict.utf8</span></code>ï¼Œå¹¶å°†å…¶æ”¾åˆ°æŒ‡å®šä½ç½®ã€‚</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindvision.dataset</span> <span class="kn">import</span> <span class="n">DownLoad</span>

<span class="c1"># å­—å…¸æ–‡ä»¶å­˜æ”¾è·¯å¾„</span>
<span class="n">dl_path</span> <span class="o">=</span> <span class="s2">&quot;./dictionary&quot;</span>

<span class="c1"># è·å–å­—å…¸æ–‡ä»¶æº</span>
<span class="n">dl_url_hmm</span> <span class="o">=</span> <span class="s2">&quot;https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/datasets/hmm_model.utf8&quot;</span>
<span class="n">dl_url_jieba</span> <span class="o">=</span> <span class="s2">&quot;https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/datasets/jieba.dict.utf8&quot;</span>

<span class="c1"># ä¸‹è½½å­—å…¸æ–‡ä»¶</span>
<span class="n">dl</span> <span class="o">=</span> <span class="n">DownLoad</span><span class="p">()</span>
<span class="n">dl</span><span class="o">.</span><span class="n">download_url</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">dl_url_hmm</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="n">dl_path</span><span class="p">)</span>
<span class="n">dl</span><span class="o">.</span><span class="n">download_url</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">dl_url_jieba</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="n">dl_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>ä¸‹è½½çš„æ–‡ä»¶æ”¾ç½®çš„ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./dictionary/
â”œâ”€â”€ hmm_model.utf8
â””â”€â”€ jieba.dict.utf8
</pre></div>
</div>
<p>ä¸‹é¢çš„æ ·ä¾‹é¦–å…ˆæ„å»ºäº†ä¸€ä¸ªæ–‡æœ¬æ•°æ®é›†ï¼Œç„¶åä½¿ç”¨HMMä¸MPå­—å…¸æ–‡ä»¶åˆ›å»º<code class="docutils literal notranslate"><span class="pre">JiebaTokenizer</span></code>å¯¹è±¡ï¼Œå¹¶å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯ï¼Œæœ€åå±•ç¤ºäº†åˆ†è¯å‰åçš„æ–‡æœ¬ç»“æœã€‚</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.text</span> <span class="k">as</span> <span class="nn">text</span>

<span class="c1"># æ„é€ å¾…åˆ†è¯æ•°æ®</span>
<span class="n">input_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;æ˜å¤©å¤©æ°”å¤ªå¥½äº†æˆ‘ä»¬ä¸€èµ·å»å¤–é¢ç©å§&quot;</span><span class="p">]</span>

<span class="c1"># åŠ è½½æ•°æ®é›†</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">input_list</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------before tokenization----------------------------&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
------------------------before tokenization----------------------------
æ˜å¤©å¤©æ°”å¤ªå¥½äº†æˆ‘ä»¬ä¸€èµ·å»å¤–é¢ç©å§
</pre></div></div>
</div>
<p>ä¸Šé¢ä¸ºæ•°æ®é›†æœªè¢«åˆ†è¯å‰çš„æ•°æ®æ‰“å°æƒ…å†µï¼Œä¸‹é¢ä½¿ç”¨<code class="docutils literal notranslate"><span class="pre">JiebaTokenizer</span></code>åˆ†è¯å™¨å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯ã€‚</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">HMM_FILE</span> <span class="o">=</span> <span class="s2">&quot;./dictionary/hmm_model.utf8&quot;</span>
<span class="n">MP_FILE</span> <span class="o">=</span> <span class="s2">&quot;./dictionary/jieba.dict.utf8&quot;</span>

<span class="c1"># ä½¿ç”¨JiebaTokenizeråˆ†è¯å™¨å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯</span>
<span class="n">jieba_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">JiebaTokenizer</span><span class="p">(</span><span class="n">HMM_FILE</span><span class="p">,</span> <span class="n">MP_FILE</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">jieba_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------after tokenization-----------------------------&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
------------------------after tokenization-----------------------------
[&#39;æ˜å¤©&#39; &#39;å¤©æ°”&#39; &#39;å¤ªå¥½äº†&#39; &#39;æˆ‘ä»¬&#39; &#39;ä¸€èµ·&#39; &#39;å»&#39; &#39;å¤–é¢&#39; &#39;ç©å§&#39;]
</pre></div></div>
</div>
<p>ä»ä¸Šé¢ä¸¤æ¬¡æ‰“å°ç»“æœæ¥çœ‹ï¼Œæ•°æ®é›†ä¸­çš„å¥å­è¢«<code class="docutils literal notranslate"><span class="pre">JiebaTokenizer</span></code>åˆ†è¯å™¨ä»¥è¯è¯­ä¸ºæœ€å°å•å…ƒè¿›è¡Œäº†åˆ’åˆ†ã€‚</p>
</section>
<section id="sentencepiecetokenizer">
<h4>SentencePieceTokenizer<a class="headerlink" href="#sentencepiecetokenizer" title="Permalink to this headline">ïƒ</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">SentencePieceTokenizer</span></code>æ“ä½œæ˜¯åŸºäºå¼€æºè‡ªç„¶è¯­è¨€å¤„ç†å·¥å…·åŒ…<a class="reference external" href="https://github.com/google/sentencepiece">SentencePiece</a>å°è£…çš„åˆ†è¯å™¨ã€‚</p>
<p>ä»¥ä¸‹ç¤ºä¾‹ä»£ç å°†ä¸‹è½½æ–‡æœ¬æ•°æ®é›†æ–‡ä»¶<code class="docutils literal notranslate"><span class="pre">botchan.txt</span></code>ï¼Œå¹¶å°†å…¶æ”¾ç½®åˆ°æŒ‡å®šä½ç½®ã€‚</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># æ•°æ®é›†å­˜æ”¾ä½ç½®</span>
<span class="n">dl_path</span> <span class="o">=</span> <span class="s2">&quot;./datasets&quot;</span>

<span class="c1"># è·å–è¯­æ–™æ•°æ®æº</span>
<span class="n">dl_url_botchan</span> <span class="o">=</span> <span class="s2">&quot;https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/datasets/botchan.txt&quot;</span>

<span class="c1"># ä¸‹è½½è¯­æ–™æ•°æ®</span>
<span class="n">dl</span><span class="o">.</span><span class="n">download_url</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">dl_url_botchan</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="n">dl_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>ä¸‹è½½çš„æ–‡ä»¶æ”¾ç½®çš„ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./datasets/
â””â”€â”€ botchan.txt
</pre></div>
</div>
<p>ä¸‹é¢çš„æ ·ä¾‹é¦–å…ˆæ„å»ºäº†ä¸€ä¸ªæ–‡æœ¬æ•°æ®é›†ï¼Œç„¶åä»<code class="docutils literal notranslate"><span class="pre">vocab_file</span></code>æ–‡ä»¶ä¸­æ„å»ºä¸€ä¸ª<code class="docutils literal notranslate"><span class="pre">vocab</span></code>å¯¹è±¡ï¼Œå†é€šè¿‡<code class="docutils literal notranslate"><span class="pre">SentencePieceTokenizer</span></code>å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯ï¼Œå¹¶å±•ç¤ºäº†åˆ†è¯å‰åçš„æ–‡æœ¬ç»“æœã€‚</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.text</span> <span class="k">as</span> <span class="nn">text</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset.text</span> <span class="kn">import</span> <span class="n">SentencePieceModel</span><span class="p">,</span> <span class="n">SPieceTokenizerOutType</span>

<span class="c1"># æ„é€ å¾…åˆ†è¯æ•°æ®</span>
<span class="n">input_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Nothing in the world is difficult for one who sets his mind on it.&quot;</span><span class="p">]</span>

<span class="c1"># åŠ è½½æ•°æ®é›†</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">input_list</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------before tokenization----------------------------&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
------------------------before tokenization----------------------------
Nothing in the world is difficult for one who sets his mind on it.
</pre></div></div>
</div>
<p>ä¸Šé¢ä¸ºæ•°æ®é›†æœªè¢«åˆ†è¯å‰çš„æ•°æ®æ‰“å°æƒ…å†µï¼Œä¸‹é¢ä½¿ç”¨<code class="docutils literal notranslate"><span class="pre">SentencePieceTokenizer</span></code>åˆ†è¯å™¨å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯ã€‚</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># è¯­æ–™æ•°æ®æ–‡ä»¶å­˜æ”¾è·¯å¾„</span>
<span class="n">vocab_file</span> <span class="o">=</span> <span class="s2">&quot;./datasets/botchan.txt&quot;</span>

<span class="c1"># ä»è¯­æ–™æ•°æ®ä¸­å­¦ä¹ æ„å»ºè¯æ±‡è¡¨</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">SentencePieceVocab</span><span class="o">.</span><span class="n">from_file</span><span class="p">([</span><span class="n">vocab_file</span><span class="p">],</span> <span class="mi">5000</span><span class="p">,</span> <span class="mf">0.9995</span><span class="p">,</span> <span class="n">SentencePieceModel</span><span class="o">.</span><span class="n">WORD</span><span class="p">,</span> <span class="p">{})</span>

<span class="c1"># ä½¿ç”¨SentencePieceTokenizeråˆ†è¯å™¨å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯</span>
<span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">SentencePieceTokenizer</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">SPieceTokenizerOutType</span><span class="o">.</span><span class="n">STRING</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------after tokenization-----------------------------&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
------------------------after tokenization-----------------------------
[&#39;â–Nothing&#39; &#39;â–in&#39; &#39;â–the&#39; &#39;â–world&#39; &#39;â–is&#39; &#39;â–difficult&#39; &#39;â–for&#39; &#39;â–one&#39; &#39;â–who&#39;
 &#39;â–sets&#39; &#39;â–his&#39; &#39;â–mind&#39; &#39;â–on&#39; &#39;â–it.&#39;]
</pre></div></div>
</div>
<p>ä»ä¸Šé¢ä¸¤æ¬¡æ‰“å°ç»“æœæ¥çœ‹ï¼Œæ•°æ®é›†ä¸­çš„å¥å­è¢«<code class="docutils literal notranslate"><span class="pre">SentencePieceTokenizer</span></code>åˆ†è¯å™¨ä»¥è¯è¯­ä¸ºæœ€å°å•å…ƒè¿›è¡Œäº†åˆ’åˆ†ã€‚åœ¨<code class="docutils literal notranslate"><span class="pre">SentencePieceTokenizer</span></code>åˆ†è¯å™¨çš„å¤„ç†è¿‡ç¨‹ä¸­ï¼Œç©ºæ ¼ä½œä¸ºæ™®é€šç¬¦å·å¤„ç†ï¼Œå¹¶ä½¿ç”¨ä¸‹åˆ’çº¿æ ‡è®°ç©ºæ ¼ã€‚</p>
</section>
<section id="unicodechartokenizer">
<h4>UnicodeCharTokenizer<a class="headerlink" href="#unicodechartokenizer" title="Permalink to this headline">ïƒ</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">UnicodeCharTokenizer</span></code>æ“ä½œæ˜¯æ ¹æ®Unicodeå­—ç¬¦é›†æ¥åˆ†è¯çš„ã€‚</p>
<p>ä¸‹é¢çš„æ ·ä¾‹é¦–å…ˆæ„å»ºäº†ä¸€ä¸ªæ–‡æœ¬æ•°æ®é›†ï¼Œç„¶åé€šè¿‡<code class="docutils literal notranslate"><span class="pre">UnicodeCharTokenizer</span></code>å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯ï¼Œå¹¶å±•ç¤ºäº†åˆ†è¯å‰åçš„æ–‡æœ¬ç»“æœã€‚</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.text</span> <span class="k">as</span> <span class="nn">text</span>

<span class="c1"># æ„é€ å¾…åˆ†è¯æ•°æ®</span>
<span class="n">input_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Welcome to Beijing!&quot;</span><span class="p">,</span> <span class="s2">&quot;åŒ—äº¬æ¬¢è¿æ‚¨ï¼&quot;</span><span class="p">,</span> <span class="s2">&quot;æˆ‘å–œæ¬¢China!&quot;</span><span class="p">]</span>

<span class="c1"># åŠ è½½æ•°æ®é›†</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">input_list</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------before tokenization----------------------------&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
------------------------before tokenization----------------------------
Welcome to Beijing!
åŒ—äº¬æ¬¢è¿æ‚¨ï¼
æˆ‘å–œæ¬¢China!
</pre></div></div>
</div>
<p>ä¸Šé¢ä¸ºæ•°æ®é›†æœªè¢«åˆ†è¯å‰çš„æ•°æ®æ‰“å°æƒ…å†µï¼Œä¸‹é¢ä½¿ç”¨<code class="docutils literal notranslate"><span class="pre">UnicodeCharTokenizer</span></code>åˆ†è¯å™¨å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯ã€‚</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ä½¿ç”¨UnicodeCharTokenizeråˆ†è¯å™¨å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯</span>
<span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">UnicodeCharTokenizer</span><span class="p">()</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------after tokenization-----------------------------&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
------------------------after tokenization-----------------------------
[&#39;W&#39;, &#39;e&#39;, &#39;l&#39;, &#39;c&#39;, &#39;o&#39;, &#39;m&#39;, &#39;e&#39;, &#39; &#39;, &#39;t&#39;, &#39;o&#39;, &#39; &#39;, &#39;B&#39;, &#39;e&#39;, &#39;i&#39;, &#39;j&#39;, &#39;i&#39;, &#39;n&#39;, &#39;g&#39;, &#39;!&#39;]
[&#39;åŒ—&#39;, &#39;äº¬&#39;, &#39;æ¬¢&#39;, &#39;è¿&#39;, &#39;æ‚¨&#39;, &#39;ï¼&#39;]
[&#39;æˆ‘&#39;, &#39;å–œ&#39;, &#39;æ¬¢&#39;, &#39;C&#39;, &#39;h&#39;, &#39;i&#39;, &#39;n&#39;, &#39;a&#39;, &#39;!&#39;]
</pre></div></div>
</div>
<p>ä»ä¸Šé¢ä¸¤æ¬¡æ‰“å°ç»“æœå¯ä»¥çœ‹å‡ºï¼Œæ•°æ®é›†ä¸­çš„å¥å­è¢«<code class="docutils literal notranslate"><span class="pre">UnicodeCharTokenizer</span></code>åˆ†è¯å™¨è¿›è¡Œåˆ†å‰²ï¼Œä¸­æ–‡ä»¥å•ä¸ªæ±‰å­—ä¸ºæœ€å°å•å…ƒï¼Œè‹±æ–‡ä»¥å•ä¸ªå­—æ¯ä¸ºæœ€å°å•å…ƒã€‚</p>
</section>
<section id="whitespacetokenizer">
<h4>WhitespaceTokenizer<a class="headerlink" href="#whitespacetokenizer" title="Permalink to this headline">ïƒ</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">WhitespaceTokenizer</span></code>æ“ä½œæ˜¯æ ¹æ®ç©ºæ ¼æ¥è¿›è¡Œåˆ†è¯çš„ã€‚</p>
<p>ä¸‹é¢çš„æ ·ä¾‹é¦–å…ˆæ„å»ºäº†ä¸€ä¸ªæ–‡æœ¬æ•°æ®é›†ï¼Œç„¶åé€šè¿‡<code class="docutils literal notranslate"><span class="pre">WhitespaceTokenizer</span></code>å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯ï¼Œå¹¶å±•ç¤ºäº†åˆ†è¯å‰åçš„æ–‡æœ¬ç»“æœã€‚</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.text</span> <span class="k">as</span> <span class="nn">text</span>

<span class="c1"># æ„é€ å¾…åˆ†è¯æ•°æ®</span>
<span class="n">input_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Welcome to Beijing!&quot;</span><span class="p">,</span> <span class="s2">&quot;åŒ—äº¬æ¬¢è¿æ‚¨ï¼&quot;</span><span class="p">,</span> <span class="s2">&quot;æˆ‘å–œæ¬¢China!&quot;</span><span class="p">,</span> <span class="s2">&quot;åºŠå‰æ˜æœˆå…‰ï¼Œç–‘æ˜¯åœ°ä¸Šéœœã€‚&quot;</span><span class="p">]</span>

<span class="c1"># åŠ è½½æ•°æ®é›†</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">input_list</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------before tokenization----------------------------&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
------------------------before tokenization----------------------------
Welcome to Beijing!
åŒ—äº¬æ¬¢è¿æ‚¨ï¼
æˆ‘å–œæ¬¢China!
åºŠå‰æ˜æœˆå…‰ï¼Œç–‘æ˜¯åœ°ä¸Šéœœã€‚
</pre></div></div>
</div>
<p>ä¸Šé¢ä¸ºæ•°æ®é›†æœªè¢«åˆ†è¯å‰çš„æ•°æ®æ‰“å°æƒ…å†µï¼Œä¸‹é¢ä½¿ç”¨<code class="docutils literal notranslate"><span class="pre">WhitespaceTokenizer</span></code>åˆ†è¯å™¨å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯ã€‚</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ä½¿ç”¨WhitespaceTokenizeråˆ†è¯å™¨å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯</span>
<span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">WhitespaceTokenizer</span><span class="p">()</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------after tokenization-----------------------------&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
------------------------after tokenization-----------------------------
[&#39;Welcome&#39;, &#39;to&#39;, &#39;Beijing!&#39;]
[&#39;åŒ—äº¬æ¬¢è¿æ‚¨ï¼&#39;]
[&#39;æˆ‘å–œæ¬¢China!&#39;]
[&#39;åºŠå‰æ˜æœˆå…‰ï¼Œç–‘æ˜¯åœ°ä¸Šéœœã€‚&#39;]
</pre></div></div>
</div>
<p>ä»ä¸Šé¢ä¸¤æ¬¡æ‰“å°ç»“æœå¯ä»¥çœ‹å‡ºï¼Œæ•°æ®é›†ä¸­çš„å¥å­è¢«<code class="docutils literal notranslate"><span class="pre">WhitespaceTokenizer</span></code>åˆ†è¯å™¨ä»¥ç©ºæ ¼ä¸ºåˆ†éš”ç¬¦è¿›è¡Œåˆ†å‰²ã€‚</p>
</section>
<section id="wordpiecetokenizer">
<h4>WordpieceTokenizer<a class="headerlink" href="#wordpiecetokenizer" title="Permalink to this headline">ïƒ</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">WordpieceTokenizer</span></code>æ“ä½œæ˜¯åŸºäºå•è¯é›†æ¥è¿›è¡Œåˆ’åˆ†çš„ï¼Œåˆ’åˆ†ä¾æ®å¯ä»¥æ˜¯å•è¯é›†ä¸­çš„å•ä¸ªå•è¯ï¼Œæˆ–è€…å¤šä¸ªå•è¯çš„ç»„åˆå½¢å¼ã€‚</p>
<p>ä¸‹é¢çš„æ ·ä¾‹é¦–å…ˆæ„å»ºäº†ä¸€ä¸ªæ–‡æœ¬æ•°æ®é›†ï¼Œç„¶åä»å•è¯åˆ—è¡¨ä¸­æ„å»º<code class="docutils literal notranslate"><span class="pre">vocab</span></code>å¯¹è±¡ï¼Œé€šè¿‡<code class="docutils literal notranslate"><span class="pre">WordpieceTokenizer</span></code>å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯ï¼Œå¹¶å±•ç¤ºäº†åˆ†è¯å‰åçš„æ–‡æœ¬ç»“æœã€‚</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.text</span> <span class="k">as</span> <span class="nn">text</span>

<span class="c1"># æ„é€ å¾…åˆ†è¯æ•°æ®</span>
<span class="n">input_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;My&quot;</span><span class="p">,</span> <span class="s2">&quot;favorite&quot;</span><span class="p">,</span> <span class="s2">&quot;book&quot;</span><span class="p">,</span> <span class="s2">&quot;is&quot;</span><span class="p">,</span> <span class="s2">&quot;love&quot;</span><span class="p">,</span> <span class="s2">&quot;during&quot;</span><span class="p">,</span> <span class="s2">&quot;the&quot;</span><span class="p">,</span> <span class="s2">&quot;cholera&quot;</span><span class="p">,</span> <span class="s2">&quot;era&quot;</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;what&quot;</span><span class="p">,</span>
              <span class="s2">&quot;æˆ‘&quot;</span><span class="p">,</span> <span class="s2">&quot;æœ€&quot;</span><span class="p">,</span> <span class="s2">&quot;å–œ&quot;</span><span class="p">,</span> <span class="s2">&quot;æ¬¢&quot;</span><span class="p">,</span> <span class="s2">&quot;çš„&quot;</span><span class="p">,</span> <span class="s2">&quot;ä¹¦&quot;</span><span class="p">,</span> <span class="s2">&quot;æ˜¯&quot;</span><span class="p">,</span> <span class="s2">&quot;éœ&quot;</span><span class="p">,</span> <span class="s2">&quot;ä¹±&quot;</span><span class="p">,</span> <span class="s2">&quot;æ—¶&quot;</span><span class="p">,</span> <span class="s2">&quot;æœŸ&quot;</span><span class="p">,</span> <span class="s2">&quot;çš„&quot;</span><span class="p">,</span> <span class="s2">&quot;çˆ±&quot;</span><span class="p">,</span> <span class="s2">&quot;æƒ…&quot;</span><span class="p">,</span> <span class="s2">&quot;ã€‚&quot;</span><span class="p">,</span> <span class="s2">&quot;å¥½&quot;</span><span class="p">]</span>

<span class="c1"># æ„é€ è‹±æ–‡è¯æ±‡è¡¨</span>
<span class="n">vocab_english</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;book&quot;</span><span class="p">,</span> <span class="s2">&quot;cholera&quot;</span><span class="p">,</span> <span class="s2">&quot;era&quot;</span><span class="p">,</span> <span class="s2">&quot;favor&quot;</span><span class="p">,</span> <span class="s2">&quot;##ite&quot;</span><span class="p">,</span> <span class="s2">&quot;My&quot;</span><span class="p">,</span> <span class="s2">&quot;is&quot;</span><span class="p">,</span> <span class="s2">&quot;love&quot;</span><span class="p">,</span> <span class="s2">&quot;dur&quot;</span><span class="p">,</span> <span class="s2">&quot;##ing&quot;</span><span class="p">,</span> <span class="s2">&quot;the&quot;</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">]</span>

<span class="c1"># æ„é€ ä¸­æ–‡è¯æ±‡è¡¨</span>
<span class="n">vocab_chinese</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;æˆ‘&#39;</span><span class="p">,</span> <span class="s1">&#39;æœ€&#39;</span><span class="p">,</span> <span class="s1">&#39;å–œ&#39;</span><span class="p">,</span> <span class="s1">&#39;æ¬¢&#39;</span><span class="p">,</span> <span class="s1">&#39;çš„&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¹¦&#39;</span><span class="p">,</span> <span class="s1">&#39;æ˜¯&#39;</span><span class="p">,</span> <span class="s1">&#39;éœ&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¹±&#39;</span><span class="p">,</span> <span class="s1">&#39;æ—¶&#39;</span><span class="p">,</span> <span class="s1">&#39;æœŸ&#39;</span><span class="p">,</span> <span class="s1">&#39;çˆ±&#39;</span><span class="p">,</span> <span class="s1">&#39;æƒ…&#39;</span><span class="p">,</span> <span class="s1">&#39;ã€‚&#39;</span><span class="p">]</span>

<span class="c1"># åŠ è½½æ•°æ®é›†</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">input_list</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------before tokenization----------------------------&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
------------------------before tokenization----------------------------
My
favorite
book
is
love
during
the
cholera
era
.
what
æˆ‘
æœ€
å–œ
æ¬¢
çš„
ä¹¦
æ˜¯
éœ
ä¹±
æ—¶
æœŸ
çš„
çˆ±
æƒ…
ã€‚
å¥½
</pre></div></div>
</div>
<p>ä¸Šé¢ä¸ºæ•°æ®é›†æœªè¢«åˆ†è¯å‰çš„æ•°æ®æ‰“å°æƒ…å†µï¼Œæ­¤å¤„ç‰¹æ„æ„é€ äº†è¯æ±‡è¡¨ä¸­æ²¡æœ‰çš„å•è¯â€œwhatâ€å’Œâ€œå¥½â€ï¼Œä¸‹é¢ä½¿ç”¨<code class="docutils literal notranslate"><span class="pre">WordpieceTokenizer</span></code>åˆ†è¯å™¨å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯ã€‚</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ä½¿ç”¨WordpieceTokenizeråˆ†è¯å™¨å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">Vocab</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="n">vocab_english</span><span class="o">+</span><span class="n">vocab_chinese</span><span class="p">)</span>
<span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">WordpieceTokenizer</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------after tokenization-----------------------------&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
------------------------after tokenization-----------------------------
[&#39;My&#39;]
[&#39;favor&#39; &#39;##ite&#39;]
[&#39;book&#39;]
[&#39;is&#39;]
[&#39;love&#39;]
[&#39;dur&#39; &#39;##ing&#39;]
[&#39;the&#39;]
[&#39;cholera&#39;]
[&#39;era&#39;]
[&#39;.&#39;]
[&#39;[UNK]&#39;]
[&#39;æˆ‘&#39;]
[&#39;æœ€&#39;]
[&#39;å–œ&#39;]
[&#39;æ¬¢&#39;]
[&#39;çš„&#39;]
[&#39;ä¹¦&#39;]
[&#39;æ˜¯&#39;]
[&#39;éœ&#39;]
[&#39;ä¹±&#39;]
[&#39;æ—¶&#39;]
[&#39;æœŸ&#39;]
[&#39;çš„&#39;]
[&#39;çˆ±&#39;]
[&#39;æƒ…&#39;]
[&#39;ã€‚&#39;]
[&#39;[UNK]&#39;]
</pre></div></div>
</div>
<p>ä»ä¸Šé¢ä¸¤æ¬¡æ‰“å°ç»“æœå¯ä»¥çœ‹å‡ºï¼Œæ•°æ®é›†ä¸­çš„è¯è¯­è¢«<code class="docutils literal notranslate"><span class="pre">WordpieceTokenizer</span></code>åˆ†è¯å™¨ä»¥æ„é€ çš„è¯æ±‡è¡¨è¿›è¡Œåˆ†è¯ï¼Œâ€œMyâ€ä»ç„¶è¢«åˆ†ä¸ºâ€œMyâ€ï¼Œâ€œloveâ€ä»ç„¶è¢«åˆ†ä¸ºâ€œloveâ€ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œâ€œfavoriteâ€è¢«åˆ†ä¸ºäº†â€œfavorâ€å’Œâ€œ##iteâ€ï¼Œç”±äºâ€œwordâ€å’Œâ€œå¥½â€åœ¨è¯æ±‡è¡¨ä¸­æœªæ‰¾åˆ°ï¼Œæ‰€ä»¥ä½¿ç”¨[UNK]è¡¨ç¤ºã€‚</p>
</section>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="augment_image_data.html" class="btn btn-neutral float-left" title="å›¾åƒæ•°æ®åŠ è½½ä¸å¢å¼º" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="augment_graph_data.html" class="btn btn-neutral float-right" title="å›¾æ•°æ®åŠ è½½ä¸å¤„ç†" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>