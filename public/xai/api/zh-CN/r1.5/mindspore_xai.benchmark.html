<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore_xai.benchmark &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="mindspore_xai.explanation" href="mindspore_xai.explanation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mindspore_xai.runner.html">mindspore_xai.runner</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_xai.explanation.html">mindspore_xai.explanation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindspore_xai.benchmark</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>mindspore_xai.benchmark</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/mindspore_xai.benchmark.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-mindspore_xai.benchmark">
<span id="mindspore-xai-benchmark"></span><h1>mindspore_xai.benchmark<a class="headerlink" href="#module-mindspore_xai.benchmark" title="Permalink to this headline"></a></h1>
<p>Predefined XAI metrics.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore_xai.benchmark.ClassSensitivity">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_xai.benchmark.</span></span><span class="sig-name descname"><span class="pre">ClassSensitivity</span></span><a class="reference internal" href="_modules/mindspore_xai/benchmark/attribution/class_sensitivity.html#ClassSensitivity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore_xai.benchmark.ClassSensitivity" title="Permalink to this definition"></a></dt>
<dd><p>Class sensitivity metric used to evaluate attribution-based explanations.</p>
<p>Reasonable atrribution-based explainers are expected to generate distinct saliency maps for different labels,
especially for labels of highest confidence and low confidence. ClassSensitivity evaluates the explainer through
computing the correlation between saliency maps of highest-confidence and lowest-confidence labels. Explainer with
better class sensitivity will receive lower correlation score. To make the evaluation results intuitive, the
returned score will take negative on correlation and normalize.</p>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore_xai.benchmark.ClassSensitivity.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">explainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/benchmark/attribution/class_sensitivity.html#ClassSensitivity.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore_xai.benchmark.ClassSensitivity.evaluate" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate class sensitivity on a single data sample.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>explainer</strong> (<em>Explanation</em>) – The explainer to be evaluated, see <cite>mindspore_xai.explanation</cite>.</p></li>
<li><p><strong>inputs</strong> (<em>Tensor</em>) – A data sample, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, 1D array of shape <span class="math notranslate nohighlight">\((N,)\)</span>, result of class sensitivity evaluated on <cite>explainer</cite>.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – Be raised for any argument type problem.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.benchmark</span> <span class="kn">import</span> <span class="n">ClassSensitivity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.explanation</span> <span class="kn">import</span> <span class="n">Gradient</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The detail of LeNet5 is shown in model_zoo.official.cv.lenet.src.lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># prepare your explainer to be evaluated, e.g., Gradient.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gradient</span> <span class="o">=</span> <span class="n">Gradient</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">class_sensitivity</span> <span class="o">=</span> <span class="n">ClassSensitivity</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">class_sensitivity</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">input_x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1,)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_xai.benchmark.Faithfulness">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_xai.benchmark.</span></span><span class="sig-name descname"><span class="pre">Faithfulness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NaiveFaithfulness'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/benchmark/attribution/faithfulness.html#Faithfulness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore_xai.benchmark.Faithfulness" title="Permalink to this definition"></a></dt>
<dd><p>Provides evaluation on faithfulness on XAI explanations.</p>
<p>Three specific metrics to obtain quantified results are supported: “NaiveFaithfulness”, “DeletionAUC”, and
“InsertionAUC”.</p>
<p>For metric “NaiveFaithfulness”, a series of perturbed images are created by modifying pixels
on original image. Then the perturbed images will be fed to the model and a series of output probability drops can
be obtained. The faithfulness is then quantified as the correlation between the propability drops and the saliency
map values on the same pixels (we normalize the correlation further to make them in range of [0, 1]).</p>
<p>For metric “DeletionAUC”, a series of perturbed images are created by accumulatively modifying pixels of the
original image to a base value (e.g. a constant). The perturbation starts from pixels with high saliency values
to pixels with low saliency values. Feeding the perturbed images into the model in order, an output probability
drop curve can be obtained. “DeletionAUC” is then obtained as the area under this probability drop curve.</p>
<p>For metric “InsertionAUC”, a series of perturbed images are created by accumulatively inserting pixels of the
original image to a reference image (e.g. a black image). The insertion starts from pixels with high saliency
values to pixels with low saliency values. Feeding the perturbed images into the model in order, an output
probability increase curve can be obtained. “InsertionAUC” is then obtained as the area under this curve.</p>
<p>For all the three metrics, higher value indicates better faithfulness.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_labels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of labels.</p></li>
<li><p><strong>activation_fn</strong> (<em>Cell</em>) – The activation layer that transforms logits to prediction probabilities. For
single label classification tasks, <cite>nn.Softmax</cite> is usually applied. As for multi-label classification
tasks, <cite>nn.Sigmoid</cite> is usually be applied. Users can also pass their own customized <cite>activation_fn</cite> as long
as when combining this function with network, the final output is the probability of the input.</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – The specifi metric to quantify faithfulness.
Options: “DeletionAUC”, “InsertionAUC”, “NaiveFaithfulness”.
Default: ‘NaiveFaithfulness’.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – Be raised for any argument type problem.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore_xai.benchmark.Faithfulness.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">explainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">saliency</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/benchmark/attribution/faithfulness.html#Faithfulness.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore_xai.benchmark.Faithfulness.evaluate" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate faithfulness on a single data sample.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Currently only single sample (<span class="math notranslate nohighlight">\(N=1\)</span>) at each call is supported.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>explainer</strong> (<em>Explanation</em>) – The explainer to be evaluated, see <cite>mindspore_xai.explanation</cite>.</p></li>
<li><p><strong>inputs</strong> (<em>Tensor</em>) – A data sample, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>targets</strong> (<em>Tensor</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The label of interest. It should be a 1D or 0D tensor, or an integer.
If <cite>targets</cite> is a 1D tensor, its length should be the same as <cite>inputs</cite>.</p></li>
<li><p><strong>saliency</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – The saliency map to be evaluated, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span>.
If it is None, the parsed <cite>explainer</cite> will generate the saliency map with <cite>inputs</cite> and <cite>targets</cite> and
continue the evaluation. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, 1D array of shape <span class="math notranslate nohighlight">\((N,)\)</span>, result of faithfulness evaluated on <cite>explainer</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.benchmark</span> <span class="kn">import</span> <span class="n">Faithfulness</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.explanation</span> <span class="kn">import</span> <span class="n">Gradient</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># init a `Faithfulness` object</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_labels</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric</span> <span class="o">=</span> <span class="s2">&quot;InsertionAUC&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">faithfulness</span> <span class="o">=</span> <span class="n">Faithfulness</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">activation_fn</span><span class="p">,</span> <span class="n">metric</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The detail of LeNet5 is shown in model_zoo.official.cv.lenet.src.lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gradient</span> <span class="o">=</span> <span class="n">Gradient</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">targets</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># usage 1: input the explainer and the data to be explained,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># faithfulness is a Faithfulness instance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">faithfulness</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># usage 2: input the generated saliency map</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">faithfulness</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">saliency</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1,)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_xai.benchmark.Localization">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_xai.benchmark.</span></span><span class="sig-name descname"><span class="pre">Localization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PointingGame'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/benchmark/attribution/localization.html#Localization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore_xai.benchmark.Localization" title="Permalink to this definition"></a></dt>
<dd><p>Provides evaluation on the localization capability of XAI methods.</p>
<p>Three specific metrics to obtain quantified results are supported: “PointingGame”, and “IoSR”
(Intersection over Salient Region).</p>
<p>For metric “PointingGame”, the localization capability is calculated as the ratio of data in which the max position
of their saliency maps lies within the bounding boxes. Specifically, for a single datum, given the saliency map and
its bounding box, if the max point of its saliency map lies within the bounding box, the evaluation result is 1
otherwise 0.</p>
<p>For metric “IoSR” (Intersection over Salient Region), the localization capability is calculated as the intersection
of the bounding box and the salient region over the area of the salient region. The salient region is defined as
the region whose value exceeds <span class="math notranslate nohighlight">\(\theta * \max{saliency}\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_labels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of classes in the dataset.</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – Specific metric to calculate localization capability.
Options: “PointingGame”, “IoSR”. Default: “PointingGame”.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – Be raised for any argument type problem.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore_xai.benchmark.Localization.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">explainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">saliency</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/benchmark/attribution/localization.html#Localization.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore_xai.benchmark.Localization.evaluate" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate localization on a single data sample.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Currently only single sample (<span class="math notranslate nohighlight">\(N=1\)</span>) at each call is supported.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>explainer</strong> (<em>Explanation</em>) – The explainer to be evaluated, see <cite>mindspore_xai.explanation</cite>.</p></li>
<li><p><strong>inputs</strong> (<em>Tensor</em>) – A data sample, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>targets</strong> (<em>Tensor</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The label of interest. It should be a 1D or 0D tensor, or an integer.
If <cite>targets</cite> is a 1D tensor, its length should be the same as <cite>inputs</cite>.</p></li>
<li><p><strong>saliency</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – The saliency map to be evaluated, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span>.
If it is None, the parsed <cite>explainer</cite> will generate the saliency map with <cite>inputs</cite> and <cite>targets</cite> and
continue the evaluation. Default: None.</p></li>
<li><p><strong>mask</strong> (<em>Tensor</em><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Ground truth bounding box/masks for the inputs w.r.t targets, a 4D tensor
or numpy.ndarray of shape <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, 1D array of shape <span class="math notranslate nohighlight">\((N,)\)</span>, result of localization evaluated on <cite>explainer</cite>.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Be raised for any argument value problem.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.explanation</span> <span class="kn">import</span> <span class="n">Gradient</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.benchmark</span> <span class="kn">import</span> <span class="n">Localization</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_labels</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">localization</span> <span class="o">=</span> <span class="n">Localization</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="s2">&quot;PointingGame&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The detail of LeNet5 is shown in model_zoo.official.cv.lenet.src.lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gradient</span> <span class="o">=</span> <span class="n">Gradient</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">masks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">masks</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">10</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">:</span> <span class="mi">20</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">targets</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># usage 1: input the explainer and the data to be explained,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># localization is a Localization instance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">localization</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">masks</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># usage 2: input the generated saliency map</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">localization</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">saliency</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">masks</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1,)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_xai.benchmark.Robustness">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_xai.benchmark.</span></span><span class="sig-name descname"><span class="pre">Robustness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/benchmark/attribution/robustness.html#Robustness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore_xai.benchmark.Robustness" title="Permalink to this definition"></a></dt>
<dd><p>Robustness perturbs the inputs by adding random noise and choose the maximum sensitivity as evaluation score from
the perturbations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_labels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of classes in the dataset.</p></li>
<li><p><strong>activation_fn</strong> (<em>Cell</em>) – The activation layer that transforms logits to prediction probabilities. For
single label classification tasks, <cite>nn.Softmax</cite> is usually applied. As for multi-label classification
tasks, <cite>nn.Sigmoid</cite> is usually be applied. Users can also pass their own customized <cite>activation_fn</cite> as long
as when combining this function with network, the final output is the probability of the input.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – Be raised for any argument type problem.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore_xai.benchmark.Robustness.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">explainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">saliency</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/benchmark/attribution/robustness.html#Robustness.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore_xai.benchmark.Robustness.evaluate" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate robustness on single sample.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Currently only single sample (<span class="math notranslate nohighlight">\(N=1\)</span>) at each call is supported.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>explainer</strong> (<em>Explanation</em>) – The explainer to be evaluated, see <cite>mindspore_xai.explanation</cite>.</p></li>
<li><p><strong>inputs</strong> (<em>Tensor</em>) – A data sample, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>targets</strong> (<em>Tensor</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The label of interest. It should be a 1D or 0D tensor, or an integer.
If <cite>targets</cite> is a 1D tensor, its length should be the same as <cite>inputs</cite>.</p></li>
<li><p><strong>saliency</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – The saliency map to be evaluated, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span>.
If it is None, the parsed <cite>explainer</cite> will generate the saliency map with <cite>inputs</cite> and <cite>targets</cite> and
continue the evaluation. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, 1D array of shape <span class="math notranslate nohighlight">\((N,)\)</span>, result of localization evaluated on <cite>explainer</cite>.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If batch_size is larger than 1.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.explanation</span> <span class="kn">import</span> <span class="n">Gradient</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.benchmark</span> <span class="kn">import</span> <span class="n">Robustness</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Initialize a Robustness benchmarker passing num_labels of the dataset.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_labels</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">robustness</span> <span class="o">=</span> <span class="n">Robustness</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">activation_fn</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The detail of LeNet5 is shown in model_zoo.official.cv.lenet.src.lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># prepare your explainer to be evaluated, e.g., Gradient.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gradient</span> <span class="o">=</span> <span class="n">Gradient</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_label</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># robustness is a Robustness instance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">robustness</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">input_x</span><span class="p">,</span> <span class="n">target_label</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1,)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindspore_xai.explanation.html" class="btn btn-neutral float-left" title="mindspore_xai.explanation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
        <script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>