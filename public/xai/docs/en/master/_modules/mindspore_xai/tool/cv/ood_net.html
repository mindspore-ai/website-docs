

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore_xai.tool.cv.ood_net &mdash; MindSpore master documentation</title>
  

  
   
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/language_data.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../installation.html">MindSpore XAI Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../using_cv_explainers.html">Using CV Explainers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../using_cv_benchmarks.html">Using CV Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../using_tabular_explainers.html">Using Tabular Explainers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../using_tabsim.html">Using TabSim Data Simulator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../using_tbnet.html">Using TB-Net Whitebox Recommendation Model</a></li>
</ul>
<p class="caption"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../mindspore_xai.explainer.html">mindspore_xai.explainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mindspore_xai.benchmark.html">mindspore_xai.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mindspore_xai.tool.html">mindspore_xai.tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mindspore_xai.visual.html">mindspore_xai.visual</a></li>
</ul>
<p class="caption"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../troubleshoot.html">Troubleshooting</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>mindspore_xai.tool.cv.ood_net</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for mindspore_xai.tool.cv.ood_net</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2021 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ============================================================================</span>
<span class="sd">&quot;&quot;&quot;Out Of Distribution Network.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span><span class="p">,</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">HeNormal</span>
<span class="kn">from</span> <span class="nn">mindspore.train._utils</span> <span class="kn">import</span> <span class="n">check_value_type</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">Callback</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">LearningRateScheduler</span>


<span class="k">class</span> <span class="nc">_GradNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Network for gradient calculation.</span>

<span class="sd">    Args:</span>
<span class="sd">        network (Cell): The network to generate backpropagated gradients.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_GradNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grad_op</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">GradOperation</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get backpropgated gradients.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, output gradients.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">grad_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_op</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">grad_func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<div class="viewcode-block" id="OoDNet"><a class="viewcode-back" href="../../../../mindspore_xai.tool.html#mindspore_xai.tool.cv.OoDNet">[docs]</a><span class="k">class</span> <span class="nc">OoDNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Out of distribution network.</span>

<span class="sd">    OoDNet takes an underlying classifier and outputs the out of distribution scores of samples.</span>

<span class="sd">    Note:</span>
<span class="sd">        A training of OoDNet is required with the classifier&#39;s training dataset inorder to give the correct OoD scores.</span>

<span class="sd">    Args:</span>
<span class="sd">        underlying (Cell): The underlying classifier, it must has the `num_features` (int) and `output_features`</span>
<span class="sd">            (bool) attributes, please check the example code for the details.</span>
<span class="sd">        num_classes (int): The number of classes for the classifier.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, classification logits (if `set_train(True)` was called) or OoD scores (if `set_train(False)` was</span>
<span class="sd">        called). In the shape of :math:`(N, L)` (L is number of classes).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: Be raised for any argument or input type problem.</span>
<span class="sd">        ValueError: Be raised for any input value problem.</span>
<span class="sd">        AttributeError: Be raised for `underlying` is missing any required attribute.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import nn, set_context, PYNATIVE_MODE</span>
<span class="sd">        &gt;&gt;&gt; from mindspore_xai.tool.cv import OoDNet</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.common.initializer import Normal</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; class MyLeNet5(nn.Cell):</span>
<span class="sd">        ...    def __init__(self, num_class, num_channel):</span>
<span class="sd">        ...        super(MyLeNet5, self).__init__()</span>
<span class="sd">        ...</span>
<span class="sd">        ...        # must add the following 2 attributes to your model</span>
<span class="sd">        ...        self.num_features = 84 # no. of features, int</span>
<span class="sd">        ...        self.output_features = False # output features flag, bool</span>
<span class="sd">        ...</span>
<span class="sd">        ...        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode=&#39;valid&#39;)</span>
<span class="sd">        ...        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode=&#39;valid&#39;)</span>
<span class="sd">        ...        self.relu = nn.ReLU()</span>
<span class="sd">        ...        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)</span>
<span class="sd">        ...        self.flatten = nn.Flatten()</span>
<span class="sd">        ...        self.fc1 = nn.Dense(16 * 5 * 5, 120, weight_init=Normal(0.02))</span>
<span class="sd">        ...        self.fc2 = nn.Dense(120, self.num_features, weight_init=Normal(0.02))</span>
<span class="sd">        ...        self.fc3 = nn.Dense(self.num_features, num_class, weight_init=Normal(0.02))</span>
<span class="sd">        ...</span>
<span class="sd">        ...    def construct(self, x):</span>
<span class="sd">        ...        x = self.conv1(x)</span>
<span class="sd">        ...        x = self.relu(x)</span>
<span class="sd">        ...        x = self.max_pool2d(x)</span>
<span class="sd">        ...        x = self.conv2(x)</span>
<span class="sd">        ...        x = self.relu(x)</span>
<span class="sd">        ...        x = self.max_pool2d(x)</span>
<span class="sd">        ...        x = self.flatten(x)</span>
<span class="sd">        ...        x = self.relu(self.fc1(x))</span>
<span class="sd">        ...        x = self.relu(self.fc2(x))</span>
<span class="sd">        ...</span>
<span class="sd">        ...        # return the features tensor if output_features is True</span>
<span class="sd">        ...        if self.output_features:</span>
<span class="sd">        ...            return x</span>
<span class="sd">        ...</span>
<span class="sd">        ...        x = self.fc3(x)</span>
<span class="sd">        ...        return x</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; set_context(mode=PYNATIVE_MODE)</span>
<span class="sd">        &gt;&gt;&gt; # prepare classifier</span>
<span class="sd">        &gt;&gt;&gt; net = MyLeNet5(10, num_channel=3)</span>
<span class="sd">        &gt;&gt;&gt; # prepare OoD network</span>
<span class="sd">        &gt;&gt;&gt; ood_net = OoDNet(net, 10)</span>
<span class="sd">        &gt;&gt;&gt; inputs = ms.Tensor(np.random.rand(1, 3, 32, 32), ms.float32)</span>
<span class="sd">        &gt;&gt;&gt; ood_map = ood_net(inputs)</span>
<span class="sd">        &gt;&gt;&gt; print(ood_map.shape)</span>
<span class="sd">        (1, 10)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">underlying</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OoDNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">check_value_type</span><span class="p">(</span><span class="s1">&#39;num_classes&#39;</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_classes</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;num_classes is less then 1!&#39;</span><span class="p">)</span>
        <span class="n">check_value_type</span><span class="p">(</span><span class="s1">&#39;underlying&#39;</span><span class="p">,</span> <span class="n">underlying</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">check_value_type</span><span class="p">(</span><span class="s1">&#39;underlying.num_features&#39;</span><span class="p">,</span> <span class="n">underlying</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">underlying</span><span class="o">.</span><span class="n">num_features</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;underlying.num_features is less then 1!&#39;</span><span class="p">)</span>
            <span class="n">check_value_type</span><span class="p">(</span><span class="s1">&#39;underlying.output_features&#39;</span><span class="p">,</span> <span class="n">underlying</span><span class="o">.</span><span class="n">output_features</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span>
            <span class="n">underlying</span><span class="o">.</span><span class="n">output_features</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># assignment test</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s1">&#39;underlying has no num_features or output_features attribute!&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_underlying</span> <span class="o">=</span> <span class="n">underlying</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_h</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_underlying</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span>
                           <span class="n">out_channels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
                           <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                           <span class="n">weight_init</span><span class="o">=</span><span class="n">HeNormal</span><span class="p">(</span><span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_expand_dims</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ExpandDims</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_g_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_underlying</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># BatchNorm1d is not working on GPU, workaround with BatchNorm2d</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_g_bn2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_g_squeeze</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_g_sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_matmul_weight</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="n">transpose_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Norm</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_transpose</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Transpose</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_underlying</span><span class="o">.</span><span class="n">num_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tile</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tile</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reduce_max</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceMax</span><span class="p">(</span><span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ge</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">GreaterEqual</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_grad_net</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_max_score</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_train</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_grad</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">underlying</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the underlying classifier.</span>

<span class="sd">        Returns:</span>
<span class="sd">            nn.Cell, the underlying classifier.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_underlying</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_classes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the number of classes.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int, the number of classes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_classes</span>

<div class="viewcode-block" id="OoDNet.set_train"><a class="viewcode-back" href="../../../../mindspore_xai.tool.html#mindspore_xai.tool.cv.OoDNet.set_train">[docs]</a>    <span class="k">def</span> <span class="nf">set_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set training mode.</span>

<span class="sd">        Args:</span>
<span class="sd">            mode (bool, optional): It is in training mode. Default: ``True``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OoDNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_train</span> <span class="o">=</span> <span class="n">mode</span></div>

<div class="viewcode-block" id="OoDNet.construct"><a class="viewcode-back" href="../../../../mindspore_xai.tool.html#mindspore_xai.tool.cv.OoDNet.construct">[docs]</a>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward inferences the classification logits or OOD scores.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (Tensor): Input tensor for the underlying classifier.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, logits of softmax with temperature (if `set_train(True)` was called) or OOD scores</span>
<span class="sd">            (if `set_train(False)` was called). In the shape of :math:`(N, L)` (L is number of classes).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_underlying</span><span class="o">.</span><span class="n">output_features</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_underlying</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_underlying</span><span class="o">.</span><span class="n">output_features</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">feat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The underlying output features is not 2 dimensional!&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">feat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_features</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The underlying output feature count:</span><span class="si">{</span><span class="n">feat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> is different &#39;</span>
                             <span class="sa">f</span><span class="s1">&#39;from underlying.num_features:</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_features</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ood_scores</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_train</span><span class="p">:</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_g_fc</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_expand_dims</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_expand_dims</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_g_bn2d</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_g_squeeze</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>

            <span class="c1"># logits of softmax with temperature</span>
            <span class="n">temperature</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_g_sigmoid</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">scores</span> <span class="o">/</span> <span class="n">temperature</span>
            <span class="k">return</span> <span class="n">logits</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_max_score</span><span class="p">:</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce_max</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">scores</span></div>

<div class="viewcode-block" id="OoDNet.get_train_parameters"><a class="viewcode-back" href="../../../../mindspore_xai.tool.html#mindspore_xai.tool.cv.OoDNet.get_train_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">get_train_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_underlying</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the training parameters.</span>

<span class="sd">        Args:</span>
<span class="sd">            train_underlying (bool, optional): Set to ``True`` to include the underlying classifier parameters.</span>
<span class="sd">                Default: ``False``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list[Parameter], parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">train_underlying</span><span class="p">:</span>
            <span class="n">parameters</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_underlying</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">parameters</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">parameters</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_h</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">())</span>
        <span class="n">parameters</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_g_fc</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">parameters</span></div>

<div class="viewcode-block" id="OoDNet.prepare_train"><a class="viewcode-back" href="../../../../mindspore_xai.tool.html#mindspore_xai.tool.cv.OoDNet.prepare_train">[docs]</a>    <span class="k">def</span> <span class="nf">prepare_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                      <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                      <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                      <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span>
                      <span class="n">lr_base_factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                      <span class="n">lr_epoch_denom</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
                      <span class="n">train_underlying</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates necessities for training.</span>

<span class="sd">        Args:</span>
<span class="sd">            learning_rate (float, optional): The optimizer learning rate. Default: ``0.1``.</span>
<span class="sd">            momentum (float, optional): The optimizer momentum. Default: ``0.9``.</span>
<span class="sd">            weight_decay (float, optional): The optimizer weight decay. Default: ``0.0001``.</span>
<span class="sd">            lr_base_factor (float, optional): The base scaling factor of learning rate scheduler. Default: ``0.1``.</span>
<span class="sd">            lr_epoch_denom (int, optional): The epoch denominator of learning rate scheduler. Default: ``30``.</span>
<span class="sd">            train_underlying (bool, optional): ``True`` to train the underlying classifier as well.Default: ``False``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            - Optimizer, optimizer.</span>
<span class="sd">            - LearningRateScheduler, learning rate scheduler.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_train_parameters</span><span class="p">(</span><span class="n">train_underlying</span><span class="p">)</span>
        <span class="n">scheduler</span> <span class="o">=</span> <span class="n">_EpochLrScheduler</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">lr_base_factor</span><span class="p">,</span> <span class="n">lr_epoch_denom</span><span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span></div>

<div class="viewcode-block" id="OoDNet.train"><a class="viewcode-back" href="../../../../mindspore_xai.tool.html#mindspore_xai.tool.cv.OoDNet.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
              <span class="n">dataset</span><span class="p">,</span>
              <span class="n">loss_fn</span><span class="p">,</span>
              <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">epoch</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains this OoD net.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset (Dataset): The training dataset, expecting (data, one-hot label) items.</span>
<span class="sd">            loss_fn (Cell): The loss function, if the classifier&#39;s activation function is `nn.Softmax`, then use</span>
<span class="sd">                `nn.SoftmaxCrossEntropyWithLogits`, if the activation function is `nn.Sigmoid`, then use</span>
<span class="sd">                `nn.BCEWithLogitsLoss`.</span>
<span class="sd">            callbacks (Callback, optional): The train callbacks. Default: ``None``.</span>
<span class="sd">            epoch (int, optional): The number of epochs to be trained. Default: ``90``.</span>
<span class="sd">            optimizer (Optimizer, optional): The optimizer. The one from `prepare_train()` will be used if which is set</span>
<span class="sd">                to ``None``. Default: ``None``.</span>
<span class="sd">            scheduler (LearningRateScheduler, optional): The learning rate scheduler. The one from `prepare_train()`</span>
<span class="sd">                will be used if which is set to None. Default: ``None``.</span>
<span class="sd">            **kwargs (any, optional): Keyword arguments for `prepare_train()`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_grad</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">scheduler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">auto_optimizer</span><span class="p">,</span> <span class="n">auto_scheduler</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_train</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">auto_optimizer</span>
            <span class="k">if</span> <span class="n">scheduler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">scheduler</span> <span class="o">=</span> <span class="n">auto_scheduler</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">callbacks</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">scheduler</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">callbacks_</span> <span class="o">=</span> <span class="p">[</span><span class="n">scheduler</span><span class="p">]</span>
            <span class="n">callbacks_</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">callbacks</span><span class="p">)</span>
            <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks_</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">Callback</span><span class="p">):</span>
            <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">scheduler</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;invalid callbacks type&#39;</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_grad</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_ood_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward inferences the OOD scores.&quot;&quot;&quot;</span>
        <span class="n">norm_f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
        <span class="n">norm_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_h</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_matmul_weight</span><span class="p">(</span><span class="n">norm_f</span><span class="p">,</span> <span class="n">norm_w</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">scores</span>

    <span class="k">def</span> <span class="nf">_normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalizes an tensor.&quot;&quot;&quot;</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">tiled_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tile</span><span class="p">((</span><span class="n">norm</span> <span class="o">+</span> <span class="mf">1e-4</span><span class="p">),</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">tiled_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transpose</span><span class="p">(</span><span class="n">tiled_norm</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">/</span> <span class="n">tiled_norm</span>
        <span class="k">return</span> <span class="n">x</span></div>


<span class="k">class</span> <span class="nc">_EpochLrScheduler</span><span class="p">(</span><span class="n">LearningRateScheduler</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Epoch based learning rate scheduler.</span>

<span class="sd">    Args:</span>
<span class="sd">        base_lr (float): The base learning rate.</span>
<span class="sd">        base_factor (float): The base scaling factor.</span>
<span class="sd">        denominator (int): The epoch denominator.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_lr</span><span class="p">,</span> <span class="n">base_factor</span><span class="p">,</span> <span class="n">denominator</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_EpochLrScheduler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_lr_function</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_lr</span> <span class="o">=</span> <span class="n">base_lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_factor</span> <span class="o">=</span> <span class="n">base_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">denominator</span> <span class="o">=</span> <span class="n">denominator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cur_epoch_num</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;On an epoch was ended.&quot;&quot;&quot;</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cur_epoch_num</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span>

    <span class="k">def</span> <span class="nf">_lr_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">cur_step_num</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the dynamic learning rate.&quot;&quot;&quot;</span>
        <span class="k">del</span> <span class="n">lr</span>
        <span class="k">del</span> <span class="n">cur_step_num</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_lr</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_factor</span> <span class="o">**</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cur_epoch_num</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">denominator</span><span class="p">))</span>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>