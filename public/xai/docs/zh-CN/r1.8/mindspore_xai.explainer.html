<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore_xai.explainer &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="mindspore_xai.benchmark" href="mindspore_xai.benchmark.html" />
    <link rel="prev" title="使用 TB-Net 白盒推荐模型" href="using_tbnet.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">安装 MindSpore XAI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">使用指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="using_cv_explainers.html">使用CV类解释器</a></li>
<li class="toctree-l1"><a class="reference internal" href="using_cv_benchmarks.html">使用CV类度量方法</a></li>
<li class="toctree-l1"><a class="reference internal" href="using_tabular_explainers.html">使用表格类解释器</a></li>
<li class="toctree-l1"><a class="reference internal" href="using_tabsim.html">使用 TabSim 数据模拟器</a></li>
<li class="toctree-l1"><a class="reference internal" href="using_tbnet.html">使用 TB-Net 白盒推荐模型</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API参考</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindspore_xai.explainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_xai.benchmark.html">mindspore_xai.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_xai.tool.html">mindspore_xai.tool</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="troubleshoot.html">故障排除</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>mindspore_xai.explainer</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/mindspore_xai.explainer.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="mindspore-xai-explainer">
<h1>mindspore_xai.explainer<a class="headerlink" href="#mindspore-xai-explainer" title="Permalink to this headline"></a></h1>
<p>深度神经网络解释器。</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore_xai.explainer.Gradient">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_xai.explainer.</span></span><span class="sig-name descname"><span class="pre">Gradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/explainer/backprop/gradient.html#Gradient"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_xai.explainer.Gradient" title="Permalink to this definition"></a></dt>
<dd><p><cite>Gradient</cite> 解释方法。</p>
<p><cite>Gradient</cite> 是最简单的归因方法，它使用输出对输入的梯度作为解释。</p>
<div class="math notranslate nohighlight">
\[attribution = \frac{\partial{y}}{\partial{x}}\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>解析后的 <cite>network</cite> 将通过 <cite>network.set_grad(False)</cite> 和 <cite>network.set_train(False)</cite> 设为eval模式。如果想在之后训练 <cite>network</cite>，请通过相反的方式将其重置为训练模式。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>network</strong> (Cell) - 要解释的黑盒模型。</p></li>
</ul>
<p><strong>输入：</strong></p>
<ul class="simple">
<li><p><strong>inputs</strong> (Tensor) - 要解释的输入数据，shape为 <span class="math notranslate nohighlight">\((N, C, H, W)\)</span> 的4D Tensor。</p></li>
<li><p><strong>targets</strong> (Tensor, int, tuple, list) - 目标分类，1D/Scalar Tensor或integer，或integer类型的tuple/list。如果是1D Tensor、tuple或list，其长度应为 <span class="math notranslate nohighlight">\(N\)</span>。</p></li>
<li><p><strong>ret</strong> (str) - 返回对象的类型。’tensor’表示返回Tensor ，而’image’代表返回PIL.Image.Image的list。默认值： <cite>tensor</cite>。</p></li>
<li><p><strong>show</strong> (bool, 可选) - 显示热力图， <cite>None</cite> 代表自动，只会在JupyterLab上显示。默认值： <cite>None</cite> 。</p></li>
</ul>
<p><strong>输出：</strong></p>
<p>Tensor，shape为 <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span> 的4D Tensor，热力图。如果 <cite>ret</cite> 设为’image’，输出list[list[PIL.Image.Image]]，归一化热力图。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 参数或输入类型错误。</p></li>
<li><p><strong>ValueError</strong> - 输入值错误。</p></li>
</ul>
<dl class="simple">
<dt>支持平台：</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">set_context</span><span class="p">,</span> <span class="n">PYNATIVE_MODE</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.explainer</span> <span class="kn">import</span> <span class="n">Gradient</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The detail of LeNet5 is shown in model_zoo.official.cv.lenet.src.lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gradient</span> <span class="o">=</span> <span class="n">Gradient</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">saliency</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1, 1, 32, 32)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_xai.explainer.Deconvolution">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_xai.explainer.</span></span><span class="sig-name descname"><span class="pre">Deconvolution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/explainer/backprop/modified_relu.html#Deconvolution"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_xai.explainer.Deconvolution" title="Permalink to this definition"></a></dt>
<dd><p><cite>Deconvolution</cite> 解释方法。</p>
<p><cite>Deconvolution</cite> 方法是梯度方法的改进版本，它把要解释的网络的 <cite>ReLU</cite> 传播规则由直接反向传播梯度修改为反向传播正梯度。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>解析后的 <cite>network</cite> 将通过 <cite>network.set_grad(False)</cite> 和 <cite>network.set_train(False)</cite> 设为eval模式。如果想在之后训练 <cite>network</cite> ，请通过相反的方式将其重置为训练模式。在使用 <cite>Deconvolution</cite> 时，网络中的 <cite>ReLU</cite> 必须用 <cite>mindspore.nn.Cell</cite> 类来实现，而不是用 <cite>mindspore.ops.Operations.ReLU</cite> ，否则，将会导致错误结果。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>network</strong> (Cell) - 要解释的黑盒模型。</p></li>
</ul>
<p><strong>输入：</strong></p>
<ul class="simple">
<li><p><strong>inputs</strong> (Tensor) - 要解释的输入数据，shape为 <span class="math notranslate nohighlight">\((N, C, H, W)\)</span> 的4D Tensor。</p></li>
<li><p><strong>targets</strong> (Tensor, int, tuple, list) - 目标分类，1D/Scalar Tensor、integer，或integer类型的tuple/list。如果是1D Tensor、tuple或list，其长度应与 <cite>inputs</cite> 一致。</p></li>
<li><p><strong>ret</strong> (str) - 返回对象的类型。’tensor’代表返回 Tensor，而’image’代表返回PIL.Image.Image的list。默认值： <cite>tensor</cite>。</p></li>
<li><p><strong>show</strong> (bool, 可选) - 显示热力图， <cite>None</cite> 代表自动，只会在JupyterLab上显示。默认值： <cite>None</cite> 。</p></li>
</ul>
<p><strong>输出：</strong></p>
<p>Tensor，shape为 <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span> 的 4D Tensor。如果 <cite>ret</cite> 设为’image’，输出list[list[PIL.Image.Image]]，归一化热力图。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 参数或输入类型错误。</p></li>
<li><p><strong>ValueError</strong> - 输入值错误。</p></li>
</ul>
<dl class="simple">
<dt>支持平台：</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">set_context</span><span class="p">,</span> <span class="n">PYNATIVE_MODE</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.explainer</span> <span class="kn">import</span> <span class="n">Deconvolution</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The detail of LeNet5 is shown in model_zoo.official.cv.lenet.src.lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">deconvolution</span> <span class="o">=</span> <span class="n">Deconvolution</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># parse data and the target label to be explained and get the saliency map</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">deconvolution</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">saliency</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1, 1, 32, 32)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_xai.explainer.GuidedBackprop">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_xai.explainer.</span></span><span class="sig-name descname"><span class="pre">GuidedBackprop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/explainer/backprop/modified_relu.html#GuidedBackprop"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_xai.explainer.GuidedBackprop" title="Permalink to this definition"></a></dt>
<dd><p><cite>GuidedBackprop</cite> 解释方法。</p>
<p><cite>GuidedBackprop</cite> 方法是梯度方法的扩展。在要解释的网络的原 <cite>ReLU</cite> 上，它引入了另一个 <cite>ReLU</cite> 来过滤反向传播期间的负梯度。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>解析后的 <cite>network</cite> 将通过 <cite>network.set_grad(False)</cite> 和 <cite>network.set_train(False)</cite> 设为eval模式。如果想在之后训练 <cite>network</cite> ，请通过相反的方式将其重置为训练模式。要使用 <cite>GuidedBackprop</cite> 时，网络中的 <cite>ReLU</cite> 必须用 <cite>mindspore.nn.Cell</cite> 类来实现，而不是用 <cite>mindspore.ops.Operations.ReLU</cite> ，否则，将会导致错误结果。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>network</strong> (Cell) - 要解释的黑盒模型。</p></li>
</ul>
<p><strong>输入：</strong></p>
<ul class="simple">
<li><p><strong>inputs</strong> (Tensor) - 要解释的输入数据，shape为 <span class="math notranslate nohighlight">\((N, C, H, W)\)</span> 的4D Tensor。</p></li>
<li><p><strong>targets</strong> (Tensor, int, tuple, list) - 目标分类，1D/Scalar Tensor、integer，或integer类型的tuple/list。如果是1D Tensor、tuple或list，其长度应为 <span class="math notranslate nohighlight">\(N\)</span> 。</p></li>
<li><p><strong>ret</strong> (str) - 返回对象的类型。’tensor’代表返回Tensor，而’image’代表返回PIL.Image.Image的list。默认值： <cite>tensor</cite>。</p></li>
<li><p><strong>show</strong> (bool, 可选) - 显示热力图， <cite>None</cite> 代表自动，只会在JupyterLab上显示。默认值： <cite>None</cite> 。</p></li>
</ul>
<p><strong>输出：</strong></p>
<p>Tensor，shape为 <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span> 的4D Tensor，热力图。如果 <cite>ret</cite> 设为’image’，输出list[list[PIL.Image.Image]]，归一化热力图。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 参数或输入类型错误。</p></li>
<li><p><strong>ValueError</strong> - 输入值错误。</p></li>
</ul>
<dl class="simple">
<dt>支持平台：</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.explainer</span> <span class="kn">import</span> <span class="n">GuidedBackprop</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">set_context</span><span class="p">,</span> <span class="n">PYNATIVE_MODE</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The detail of LeNet5 is shown in model_zoo.official.cv.lenet.src.lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gbp</span> <span class="o">=</span> <span class="n">GuidedBackprop</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># feed data and the target label to be explained and get the saliency map</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">gbp</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">saliency</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1, 1, 32, 32)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_xai.explainer.GradCAM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_xai.explainer.</span></span><span class="sig-name descname"><span class="pre">GradCAM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/explainer/backprop/gradcam.html#GradCAM"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_xai.explainer.GradCAM" title="Permalink to this definition"></a></dt>
<dd><p><cite>GradCAM</cite> 解释方法。</p>
<p><cite>GradCAM</cite> 会在中间层生成热力图。属性获取方式为：</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\alpha_k^c = \frac{1}{Z} \sum_i \sum_j \frac{\partial{y^c}}{\partial{A_{i,j}^k}}\\attribution = ReLU(\sum_k \alpha_k^c A^k)\end{aligned}\end{align} \]</div>
<p>有关更多详情，请参考原始论文：<a class="reference external" href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf">GradCAM</a>。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>解析后的 <cite>network</cite> 将通过 <cite>network.set_grad(False)</cite> 和 <cite>network.set_train(False)</cite> 设为eval模式。如果想在之后训练 <cite>network</cite> ，请通过相反的方式将其重置为训练模式。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>network</strong> (Cell) - 要解释的黑盒模型。</p></li>
<li><p><strong>layer</strong> (str, 可选) - 生成解释的层名称，最好的方法是选择最后一个卷积层。如果设为’’，将在输入层生成解释。默认值：’’。</p></li>
</ul>
<p><strong>输入：</strong></p>
<ul class="simple">
<li><p><strong>inputs</strong> (Tensor) - 要解释的输入数据，shape为 <span class="math notranslate nohighlight">\((N, C, H, W)\)</span> 的4D Tensor。</p></li>
<li><p><strong>targets</strong> (Tensor, int, tuple, list) - 目标分类，1D/Scalar Tensor、integer，或integer类型的tuple/list。如果是1D Tensor、tuple或list，其长度应为 <span class="math notranslate nohighlight">\(N\)</span>。</p></li>
<li><p><strong>ret</strong> (str) - 返回对象的类型。’tensor’代表返回Tensor，而’image’代表返回PIL.Image.Image的list。默认值： <cite>tensor</cite>。</p></li>
<li><p><strong>show</strong> (bool, 可选) - 显示热力图， <cite>None</cite> 代表自动，只会在JupyterLab上显示。默认值： <cite>None</cite> 。</p></li>
</ul>
<p><strong>输出：</strong></p>
<p>Tensor，shape为 <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span> 的4D Tensor，热力图。如果 <cite>ret</cite> 设为’image’，输出list[list[PIL.Image.Image]]，归一化热力图。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 参数或输入类型错误。</p></li>
<li><p><strong>ValueError</strong> - 输入值错误。</p></li>
</ul>
<dl class="simple">
<dt>支持平台：</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.explainer</span> <span class="kn">import</span> <span class="n">GradCAM</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">set_context</span><span class="p">,</span> <span class="n">PYNATIVE_MODE</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The detail of LeNet5 is shown in model_zoo.official.cv.lenet.src.lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># specify a layer name to generate explanation, usually the layer can be set as the last conv layer.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">layer_name</span> <span class="o">=</span> <span class="s1">&#39;conv2&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># init GradCAM with a trained network and specify the layer to obtain attribution</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gradcam</span> <span class="o">=</span> <span class="n">GradCAM</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="n">layer_name</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">gradcam</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">saliency</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1, 1, 32, 32)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_xai.explainer.SHAPGradient">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_xai.explainer.</span></span><span class="sig-name descname"><span class="pre">SHAPGradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_neighbours</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/explainer/shap/gradient.html#SHAPGradient"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_xai.explainer.SHAPGradient" title="Permalink to this definition"></a></dt>
<dd><p><cite>SHAP gradient</cite> 解释方法。</p>
<p>使用预期梯度，即为集成梯度的扩展，以解释网络。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>解析后的 <cite>network</cite> 将通过 <cite>network.set_grad(False)</cite> 和 <cite>network.set_train(False)</cite> 设为eval模式。如果想在之后训练 <cite>network</cite> ，请通过相反的方式将其重置为训练模式。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>network</strong> (Cell) - 要解释的 MindSpore cell。分类模型接受shape为 <span class="math notranslate nohighlight">\((N, K)\)</span> 的2D Tensor作为输入，并输出shape为 <span class="math notranslate nohighlight">\((N, L)\)</span> 的2D Tensor。而回归模型接受shape为 <span class="math notranslate nohighlight">\((N, K)\)</span> 的2D Tensor作为输入，并输出shape为 <span class="math notranslate nohighlight">\((N)\)</span> 的1D Tensor。</p></li>
<li><p><strong>features</strong> (Tensor) - shape为 <span class="math notranslate nohighlight">\((N, K)\)</span> 的2DTensor，N是样本数，而K是特征数。用于集成特征的背景数据集，接受全部或部分的训练数据集。</p></li>
<li><p><strong>feature_names</strong> (list, 可选) - 训练数据中的列的名称（string）的list。默认值： <cite>None</cite> 。</p></li>
<li><p><strong>class_names</strong> (list, 可选) - 类名的list，排序根据分类器的类名排序。如果没有，类名会设为’0’、’1’、… 默认值： <cite>None</cite> 。</p></li>
<li><p><strong>num_neighbours</strong> (int, 可选) - 用于估计shap数值的子集数。默认值：200。</p></li>
<li><p><strong>max_features</strong> (int, 可选) - 最多解释多少个特征。默认值：10。</p></li>
</ul>
<p><strong>输入：</strong></p>
<ul class="simple">
<li><p><strong>inputs</strong> (Tensor) - 要解释的输入数据，shape为 <span class="math notranslate nohighlight">\((N, K)\)</span> 的 2D float Tensor。</p></li>
<li><p><strong>targets</strong> (Tensor, numpy.ndarray, list, int, 可选) - 要解释的目标分类。当 <cite>target</cite> 是integer时，生成该目标的归因图(attribution map)。而当 <cite>targets</cite> 为Tensor、numpy数组或list时，shape会是 <span class="math notranslate nohighlight">\((N, L)\)</span> ，L是每个样本的标签数量， <span class="math notranslate nohighlight">\((N,)\)</span> 或者 <span class="math notranslate nohighlight">\(()\)</span> 。默认值：0。</p></li>
<li><p><strong>show</strong> (bool, 可选) - 显示解释图像，<cite>None</cite> 代表自动，只会在JupyterLab上显示。默认值： <cite>None</cite> 。</p></li>
</ul>
<p><strong>输出：</strong></p>
<p>Tensor，shape为 <span class="math notranslate nohighlight">\((N, L, K)\)</span> 的3D Tensor。第一个维度代表输入。第二个维度代表目标。第三个维度代表特征的权重。</p>
<dl class="simple">
<dt>支持平台：</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">set_context</span><span class="p">,</span> <span class="n">PYNATIVE_MODE</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.explainer</span> <span class="kn">import</span> <span class="n">SHAPGradient</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Linear classification model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">LinearNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_class</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">LinearNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_class</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">())</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LinearNet</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># use iris data as example</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sepal length (cm)&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width (cm)&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length (cm)&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width (cm)&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;setosa&#39;</span><span class="p">,</span> <span class="s1">&#39;versicolor&#39;</span><span class="p">,</span> <span class="s1">&#39;virginica&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">training_data</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shap</span> <span class="o">=</span> <span class="n">SHAPGradient</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">targets</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">exps</span> <span class="o">=</span> <span class="n">shap</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">exps</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(2, 2, 4)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_xai.explainer.SHAPKernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_xai.explainer.</span></span><span class="sig-name descname"><span class="pre">SHAPKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_neighbours</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/explainer/shap/kernel.html#SHAPKernel"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_xai.explainer.SHAPKernel" title="Permalink to this definition"></a></dt>
<dd><p><cite>Kernel SHAP</cite> 解释方法。</p>
<p>使用Kernel SHAP方法解释任何函数的输出。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>predictor</strong> (Callable) - 要解释的黑盒模型，一个可调用的函数。分类模型接受shape为 <span class="math notranslate nohighlight">\((N, K)\)</span> 的2D 数组/Tensor作为输入，并输出shape为 <span class="math notranslate nohighlight">\((N, L)\)</span> 的2D数组/Tensor。而回归模型接受shape为 <span class="math notranslate nohighlight">\((N, K)\)</span> 的2D数组/Tensor作为输入，并输出shape为 <span class="math notranslate nohighlight">\((N)\)</span> 的1D数组/Tensor。</p></li>
<li><p><strong>features</strong> (Tensor, numpy.ndarray) - 2D Tensor或 <span class="math notranslate nohighlight">\((N, K)\)</span> 的2D numpy数组，N是样本数，而K是特征数。用于集成特征的背景数据集，接受全部或部分的训练数据集。</p></li>
<li><p><strong>feature_names</strong> (list, 可选) - 训练数据中的列的名称（string）的list。默认值： <cite>None</cite> 。</p></li>
<li><p><strong>class_names</strong> (list, 可选) - 类名的 list，排序根据分类器的类名排序。如果没有，类名会设为‘0’、‘1’、… 默认值： <cite>None</cite> 。</p></li>
<li><p><strong>num_neighbours</strong> (int, 可选) - 用于估计shap数值的子集数。默认值：5000。</p></li>
<li><p><strong>max_features</strong> (int, 可选) - 最多解释多少个特征。默认值：10。</p></li>
</ul>
<p><strong>输入：</strong></p>
<ul class="simple">
<li><p><strong>inputs</strong> (Tensor, numpy.ndarray) - 要解释的输入数据，2D float Tensor或shape为 <span class="math notranslate nohighlight">\((N, K)\)</span> 的2D float numpy数组。</p></li>
<li><p><strong>targets</strong> (Tensor, numpy.ndarray, list, int, 可选) - 要解释的目标分类。当 <cite>targets</cite> 是integer时，生成该目标的归因图。而当 <cite>target</cite> 是一个Tensor、numpy数组或list时，shape会是 <span class="math notranslate nohighlight">\((N, L)\)</span> ，L是每个样本的标签数量， <span class="math notranslate nohighlight">\((N,)\)</span> 或者 <span class="math notranslate nohighlight">\(()\)</span> 。默认值：0。</p></li>
<li><p><strong>show</strong> (bool, 可选) - 显示解释图像，<cite>None</cite> 代表自动，只会在JupyterLab上显示。默认值：<cite>None</cite> 。</p></li>
</ul>
<p><strong>输出：</strong></p>
<p>Tensor，shape为 <span class="math notranslate nohighlight">\((N, L, K)\)</span> 的3D Tensor。第一个维度代表输入。第二个维度代表目标。第三个维度代表特征的权重。</p>
<dl class="simple">
<dt>支持平台：</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.explainer</span> <span class="kn">import</span> <span class="n">SHAPKernel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Linear classification model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">LinearNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_class</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">LinearNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_class</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">())</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LinearNet</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># use iris data as example</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sepal length (cm)&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width (cm)&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length (cm)&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width (cm)&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;setosa&#39;</span><span class="p">,</span> <span class="s1">&#39;versicolor&#39;</span><span class="p">,</span> <span class="s1">&#39;virginica&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">training_data</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shap</span> <span class="o">=</span> <span class="n">SHAPKernel</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">targets</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">exps</span> <span class="o">=</span> <span class="n">shap</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">exps</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(2, 2, 4)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_xai.explainer.Occlusion">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_xai.explainer.</span></span><span class="sig-name descname"><span class="pre">Occlusion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbation_per_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/explainer/perturb/occlusion.html#Occlusion"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_xai.explainer.Occlusion" title="Permalink to this definition"></a></dt>
<dd><p><cite>Occlusion</cite> 解释方法。</p>
<p><cite>Occlusion</cite> 使用滑动窗口将像素换为一个参考值，例如常数，并计算新输出与原输出的差异。像素的重要性就是这些滑动窗口所引致的平均输出差异。</p>
<p>有关更多详情，请参考原始论文：<a class="reference external" href="https://arxiv.org/abs/1311.2901">Visualizing and Understanding Convolutional Networks</a> 。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>目前，每个调用仅支持单个样本（ <span class="math notranslate nohighlight">\(N=1\)</span> ）。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>network</strong> (Cell) - 要解释的黑盒模型。</p></li>
<li><p><strong>activation_fn</strong> (Cell) - 将logits转换为预测概率的激活层。单标签分类任务通常使用 <cite>nn.Softmax</cite> ，而多标签分类任务较常使用 <cite>nn.Sigmoid</cite> 。用户也可以将自定义的 <cite>activation_fn</cite> 与网络结合，最终输出便是输入的概率。</p></li>
<li><p><strong>perturbation_per_eval</strong> （int，可选） - 在推理扰动样本期间，每次推理的扰动数。在内存容许情况下，通常此数字越大，便越快得到解释。默认值：32。</p></li>
</ul>
<p><strong>输入：</strong></p>
<ul class="simple">
<li><p><strong>inputs</strong> (Tensor) - 要解释的输入数据，shape为 <span class="math notranslate nohighlight">\((N, C, H, W)\)</span> 的4D Tensor 。</p></li>
<li><p><strong>targets</strong> (Tensor, int, tuple, list) - 目标分类，1D/Scalar Tensor、integer或integer的tuple/list。如果是1D Tensor、tuple 或 list，其长度应为 <span class="math notranslate nohighlight">\(N\)</span>。</p></li>
<li><p><strong>ret</strong> (str) - 返回对象类型。’tensor’代表返回Tensor，而’image’代表返回PIL.Image.Image的list。默认值： <cite>tensor</cite>。</p></li>
<li><p><strong>show</strong> (bool, 可选) - 显示热力图， <cite>None</cite> 代表自动，只会在JupyterLab上显示。默认值： <cite>None</cite> 。</p></li>
</ul>
<p><strong>输出：</strong></p>
<p>Tensor，shape为 <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span> 的4D Tensor，热力图。如果 <cite>ret</cite> 设为’image’，输出list[list[PIL.Image.Image]]，归一化热力图。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 参数或输入类型错误。</p></li>
<li><p><strong>ValueError</strong> - 输入值错误。</p></li>
</ul>
<dl class="simple">
<dt>支持平台：</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.explainer</span> <span class="kn">import</span> <span class="n">Occlusion</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">set_context</span><span class="p">,</span> <span class="n">PYNATIVE_MODE</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The detail of LeNet5 is shown in model_zoo.official.cv.lenet.src.lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize Occlusion explainer with the pretrained model and activation function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span> <span class="c1"># softmax layer is applied to transform logits to probabilities</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">occlusion</span> <span class="o">=</span> <span class="n">Occlusion</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">activation_fn</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">occlusion</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">saliency</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1, 1, 32, 32)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_xai.explainer.RISE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_xai.explainer.</span></span><span class="sig-name descname"><span class="pre">RISE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbation_per_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/explainer/perturb/rise.html#RISE"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_xai.explainer.RISE" title="Permalink to this definition"></a></dt>
<dd><p><cite>RISE</cite> 解释方法：用随机输入采样来解释黑盒模型。</p>
<p><cite>RISE</cite> 是一种基于扰动的方法，通过在多个随机二进制掩码上采样来生成归因图。原始图像 <span class="math notranslate nohighlight">\(I\)</span> 被随机屏蔽，然后输入到黑盒模型以获取预测概率，最后的归因图便是这些随机掩码 <span class="math notranslate nohighlight">\(M_i\)</span> 的加权和，而权重是目标节点上的相应输出：</p>
<div class="math notranslate nohighlight">
\[attribution = \sum_{i}f_c(I\odot M_i)  M_i\]</div>
<p>有关更多详情，请参考原始论文：<a class="reference external" href="https://arxiv.org/abs/1806.07421">RISE</a> 。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>network</strong> (Cell) - 要解释的黑盒模型。</p></li>
<li><p><strong>activation_fn</strong> (Cell) - 将logits转换为预测概率的激活层。单标签分类任务通常使用 <cite>nn.Softmax</cite> ，而多标签分类任务较常使用 <cite>nn.Sigmoid</cite> 。用户也可以将自定义的 <cite>activation_fn</cite> 与网络结合，最终输出便是输入的概率。</p></li>
<li><p><strong>perturbation_per_eval</strong> (int, 可选) - 推理扰动样本期间，每次推理的扰动数。在内存容许情况下，通常此数字越大，便越快得到解释。默认值：32。</p></li>
</ul>
<p><strong>输入：</strong></p>
<ul class="simple">
<li><p><strong>inputs</strong> (Tensor) - 要解释的输入数据，shape为 <span class="math notranslate nohighlight">\((N, C, H, W)\)</span> 的 4D Tensor。</p></li>
<li><p><strong>targets</strong> (Tensor, int) - 目标分类。当 <cite>targets</cite> 是integer时，生成该目标的归因图。而当 <cite>targets</cite> 是Tensor时，shape会是 <span class="math notranslate nohighlight">\((N, L)\)</span> ，L是每个样本的标签数量，或 <span class="math notranslate nohighlight">\((N,)\)</span> <span class="math notranslate nohighlight">\(()\)</span>。</p></li>
<li><p><strong>ret</strong> (str) - 返回对象类型。’tensor’代表返回Tensor，’image’代表返回PIL.Image.Image的list。默认值： <cite>tensor</cite>。</p></li>
<li><p><strong>show</strong> (bool, 可选) - 显示热力图， <cite>None</cite> 代表自动，只会在JupyterLab上显示。默认值： <cite>None</cite> 。</p></li>
</ul>
<p><strong>输出：</strong></p>
<p>Tensor，4D Tensor，当目标是shape为 <span class="math notranslate nohighlight">\((N, L)\)</span> 的Tensor时，输出的shape便会是 <span class="math notranslate nohighlight">\((N, L, H, W)\)</span> ，否则会是 <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span> ，热力图。如果 <cite>ret</cite> 设为’image’，输出 list[list[PIL.Image.Image]]，归一化热力图。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 参数或输入类型错误。</p></li>
<li><p><strong>ValueError</strong> - 输入值错误。</p></li>
</ul>
<dl class="simple">
<dt>支持平台：</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.explainer</span> <span class="kn">import</span> <span class="n">RISE</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">set_context</span><span class="p">,</span> <span class="n">PYNATIVE_MODE</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The detail of LeNet5 is shown in model_zoo.official.cv.lenet.src.lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize RISE explainer with the pretrained model and activation function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span> <span class="c1"># softmax layer is applied to transform logits to probabilities</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rise</span> <span class="o">=</span> <span class="n">RISE</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">activation_fn</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># given an instance of RISE, saliency map can be generate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># when `targets` is an integer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">targets</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">rise</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">saliency</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(2, 1, 32, 32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># `targets` can also be a 2D tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">targets</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">rise</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">saliency</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(2, 1, 32, 32)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_xai.explainer.RISEPlus">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_xai.explainer.</span></span><span class="sig-name descname"><span class="pre">RISEPlus</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ood_net</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbation_per_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/explainer/perturb/riseplus.html#RISEPlus"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_xai.explainer.RISEPlus" title="Permalink to this definition"></a></dt>
<dd><p><cite>RISEPlus</cite> 解释方法。</p>
<p><cite>RISEPlus</cite> 是一种基于扰动的方法，通过在多个随机二进制掩码上采样来生成归因图。它采用分布外检测器来产生”inlier 分数”，并用于估计从分布生成样本的概率，然后将”inlier 分数”聚合到随机掩码的加权和，而权重是目标节点上的相应输出：</p>
<div class="math notranslate nohighlight">
\[attribution = \sum_{i}s_if_c(I\odot M_i)  M_i\]</div>
<p>有关更多详情，请参考原始论文： <a class="reference external" href="https://arxiv.org/abs/2107.14000">Resisting Out-of-Distribution Data Problem in Perturbation of XAI</a> 。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>ood_net</strong> (<a class="reference external" href="https://www.mindspore.cn/xai/docs/zh-CN/master/mindspore_xai.tool.html">OoDNet</a>) - 用于生成”inlier 分数”的 OoD 网络。</p></li>
<li><p><strong>network</strong> (Cell) - 要解释的黑盒模型。</p></li>
<li><p><strong>activation_fn</strong> (Cell) - 将logits转换为预测概率的激活层。单标签分类任务通常使用 <cite>nn.Softmax</cite> ，而多标签分类任务较常使用 <cite>nn.Sigmoid</cite> 。用户还可以将自己自定义的 <cite>activation_fn</cite> 与网络结合，最终输出便是输入的概率。</p></li>
<li><p><strong>perturbation_per_eval</strong> (int, 可选) - 在推理扰动样本期间，每次推理的扰动数。在内存容许情况下，通常此数字越大，便越快得到解释。默认值：32。</p></li>
</ul>
<p><strong>输入：</strong></p>
<ul class="simple">
<li><p><strong>inputs</strong> (Tensor) - 要解释的输入数据，shape为 <span class="math notranslate nohighlight">\((N, C, H, W)\)</span> 的4D Tensor。</p></li>
<li><p><strong>targets</strong> (Tensor, int) - 要解释的目标分类。当 <cite>targets</cite> 是integer时，生成该目标的归因图。而当 <cite>targets</cite> 是Tensor时，shape为 <span class="math notranslate nohighlight">\((N, L)\)</span> ，L是每个样本的标签数量，或 <span class="math notranslate nohighlight">\((N,)\)</span> <span class="math notranslate nohighlight">\(()\)</span>。</p></li>
<li><p><strong>ret</strong> (str) - 返回对象类型。’tensor’代表返回Tensor，’image’代表返回PIL.Image.Image的list。默认值： <cite>tensor</cite>。</p></li>
<li><p><strong>show</strong> (bool, 可选) - 显示热力图， <cite>None</cite> 代表自动，只会在JupyterLab上显示。默认值： <cite>None</cite> 。</p></li>
</ul>
<p><strong>输出：</strong></p>
<p>Tensor，4D Tensor，当目标是shape为 <span class="math notranslate nohighlight">\((N, L)\)</span> 的Tensor时，输出的shape便会是 <span class="math notranslate nohighlight">\((N, L, H, W)\)</span>，否则会是 <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span>，热力图。如果 <cite>ret</cite> 设为’image’，输出list[list[PIL.Image.Image]]，归一化热力图。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 参数或输入类型错误。</p></li>
<li><p><strong>ValueError</strong> - 输入值错误。</p></li>
</ul>
<dl class="simple">
<dt>支持平台：</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">set_context</span><span class="p">,</span> <span class="n">PYNATIVE_MODE</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">Normal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.explainer</span> <span class="kn">import</span> <span class="n">RISEPlus</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.tool.cv</span> <span class="kn">import</span> <span class="n">OoDNet</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">MyLeNet5</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>   <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_class</span><span class="p">,</span> <span class="n">num_channel</span><span class="p">):</span>
<span class="gp">... </span>       <span class="nb">super</span><span class="p">(</span><span class="n">MyLeNet5</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">...</span>
<span class="gp">... </span>       <span class="c1"># must add the following 2 attributes to your model</span>
<span class="gp">... </span>       <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">=</span> <span class="mi">84</span> <span class="c1"># no. of features, int</span>
<span class="gp">... </span>       <span class="bp">self</span><span class="o">.</span><span class="n">output_features</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># output features flag, bool</span>
<span class="gp">...</span>
<span class="gp">... </span>       <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_channel</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="gp">... </span>       <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="gp">... </span>       <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>       <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>       <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
<span class="gp">... </span>       <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>
<span class="gp">... </span>       <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>
<span class="gp">... </span>       <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span> <span class="n">num_class</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>
<span class="gp">...</span>
<span class="gp">... </span>   <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>       <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>       <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>       <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>       <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>       <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>       <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>       <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>       <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">... </span>       <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">...</span>
<span class="gp">... </span>       <span class="c1"># return the features tensor if output_features is True</span>
<span class="gp">... </span>       <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_features</span><span class="p">:</span>
<span class="gp">... </span>           <span class="k">return</span> <span class="n">x</span>
<span class="gp">...</span>
<span class="gp">... </span>       <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>       <span class="k">return</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># prepare trained classifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">MyLeNet5</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># prepare OoD network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ood_net</span> <span class="o">=</span> <span class="n">OoDNet</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize RISEPlus explainer with the pretrained model and activation function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span> <span class="c1"># softmax layer is applied to transform logits to probabilities</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">riseplus</span> <span class="o">=</span> <span class="n">RISEPlus</span><span class="p">(</span><span class="n">ood_net</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">activation_fn</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># given an instance of RISEPlus, saliency map can be generate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># when `targets` is an integer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">targets</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">riseplus</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">saliency</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(2, 1, 32, 32)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore_xai.explainer.LIMETabular">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore_xai.explainer.</span></span><span class="sig-name descname"><span class="pre">LIMETabular</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_feat_stats</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_features_indexes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_perturbs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/explainer/perturb/lime.html#LIMETabular"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_xai.explainer.LIMETabular" title="Permalink to this definition"></a></dt>
<dd><p><cite>Lime Tabular</cite> 解释方法。</p>
<p>解释表格（即矩阵）数据的预测。数值特征会根据训练数据中的平均值和标准差，从 Normal(0,1) 分布中采样并以逆向均值中心化和缩放来进行扰动。而分类特征会根据训练分布采样进行扰动，当采样值与被解释的样本相同时，将生成一个数值为1的二进制特征。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>predictor</strong> (Callable) - 要解释的黑盒模型，一个可调用的函数。分类模型接受shape为 <span class="math notranslate nohighlight">\((N, K)\)</span> 的2D 数组/Tensor作为输入，并输出shape为 <span class="math notranslate nohighlight">\((N, L)\)</span> 的2D数组/Tensor。而回归模型接受shape为 <span class="math notranslate nohighlight">\((N, K)\)</span> 的2D 数组/Tensor作为输入，并输出shape为 <span class="math notranslate nohighlight">\((N)\)</span> 的1D数组/Tensor。</p></li>
<li><p><strong>train_feat_stats</strong> (dict) - 含有训练数据统计详细信息的dict对象。统计信息可以使用静态方法 <cite>LIMETabular.to_feat_stats(training_data)</cite> 生成。</p></li>
<li><p><strong>feature_names</strong> (list, 可选) - 训练数据中的名称（string）的list。默认值： <cite>None</cite> 。</p></li>
<li><p><strong>categorical_features_indexes</strong> (list, 可选) - 分类列的索引（ints）的list，这些列中的值必须是integer。其他列将被视为连续的。默认值： <cite>None</cite> 。</p></li>
<li><p><strong>class_names</strong> (list, 可选) - 类名的list，排序根据分类器的类名排序。如果没有，类名会设为’0’、’1’、… 默认值： <cite>None</cite> 。</p></li>
<li><p><strong>num_perturbs</strong> (int, 可选) - 学习线性模型的邻域大小。默认值：5000。</p></li>
<li><p><strong>max_features</strong> (int, 可选) - 最多解释多少个特征。默认值：10。</p></li>
</ul>
<p><strong>输入：</strong></p>
<ul class="simple">
<li><p><strong>inputs</strong> (Tensor, numpy.ndarray) - 要解释的输入数据，2D float Tensor或shape为 <span class="math notranslate nohighlight">\((N, K)\)</span> 的2D float numpy 数组。</p></li>
<li><p><strong>targets</strong> (Tensor, numpy.ndarray, list, int, 可选) - 要解释的目标分类。当 <cite>targets</cite> 是integer时，生成该目标的归因图。而当 <cite>targets</cite> 是Tensor、numpy数组或list时，shape会是 <span class="math notranslate nohighlight">\((N, L)\)</span>，L是每个样本的标签数量， <span class="math notranslate nohighlight">\((N,)\)</span>。对于回归模型，此参数将被忽略。默认值：0。</p></li>
<li><p><strong>show</strong> (bool, 可选) - 显示解释图像，<cite>None</cite> 代表自动，只会在JupyterLab上显示。默认值： <cite>None</cite> 。</p></li>
</ul>
<p><strong>输出：</strong></p>
<p>list[list[list[(str, float)]]]，一个tuple类的3D list。第一个维度代表输入。第二个维度代表目标。第三个维度代表特征。tuple代表特征的描述和权重。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 参数或输入类型错误。</p></li>
<li><p><strong>ValueError</strong> - 输入值错误。</p></li>
</ul>
<dl class="simple">
<dt>支持平台：</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore_xai.explainer</span> <span class="kn">import</span> <span class="n">LIMETabular</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Linear classification model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">LinearNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_class</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">LinearNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_class</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">())</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LinearNet</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># use iris data as example</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sepal length (cm)&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width (cm)&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length (cm)&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width (cm)&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;setosa&#39;</span><span class="p">,</span> <span class="s1">&#39;versicolor&#39;</span><span class="p">,</span> <span class="s1">&#39;virginica&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span> <span class="o">=</span> <span class="n">LIMETabular</span><span class="o">.</span><span class="n">to_feat_stats</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lime</span> <span class="o">=</span> <span class="n">LIMETabular</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">stats</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">targets</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">exps</span> <span class="o">=</span> <span class="n">lime</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># output is a 3-dimension list of tuple</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">exps</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">exps</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">len</span><span class="p">(</span><span class="n">exps</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])))</span>
<span class="go">(2, 2, 4)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore_xai.explainer.LIMETabular.load_feat_stats">
<span class="sig-name descname"><span class="pre">load_feat_stats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/explainer/perturb/lime.html#LIMETabular.load_feat_stats"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_xai.explainer.LIMETabular.load_feat_stats" title="Permalink to this definition"></a></dt>
<dd><p>从文件加载特征统计信息。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>file</strong> (str, Path, IOBase) - 文件路径或流。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>dict，训练数据统计信息</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore_xai.explainer.LIMETabular.save_feat_stats">
<span class="sig-name descname"><span class="pre">save_feat_stats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stats</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/explainer/perturb/lime.html#LIMETabular.save_feat_stats"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_xai.explainer.LIMETabular.save_feat_stats" title="Permalink to this definition"></a></dt>
<dd><p>将特征统计信息保存到文件。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>stats</strong> (dict) - 训练数据统计信息。</p></li>
<li><p><strong>file</strong> (str, Path, IOBase) - 文件路径或流。</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore_xai.explainer.LIMETabular.to_feat_stats">
<span class="sig-name descname"><span class="pre">to_feat_stats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_features_indexes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mindspore_xai/explainer/perturb/lime.html#LIMETabular.to_feat_stats"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore_xai.explainer.LIMETabular.to_feat_stats" title="Permalink to this definition"></a></dt>
<dd><p>将特征转换为特征统计信息。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>features</strong> (Tensor, numpy.ndarray) - 训练数据。</p></li>
<li><p><strong>feature_names</strong> (list, 可选) - 特征名称。默认值： <cite>None</cite> 。</p></li>
<li><p><strong>categorical_features_indexes</strong> (list, 可选) - 分类列的索引（ints）的list，这些列中的值必须是integer。其他列将被视为连续的。默认值：<cite>None</cite> 。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>dict，训练数据统计信息。</p>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="using_tbnet.html" class="btn btn-neutral float-left" title="使用 TB-Net 白盒推荐模型" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindspore_xai.benchmark.html" class="btn btn-neutral float-right" title="mindspore_xai.benchmark" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>