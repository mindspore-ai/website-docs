

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Service Deployment with Multiple Subgraphs and Stateful Model &mdash; MindSpore master documentation</title>
  

  
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="mindspore_serving.server" href="server.html" />
    <link rel="prev" title="Servable Provided Through Model Configuration" href="serving_model.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="serving_install.html">MindSpore Serving Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="serving_example.html">MindSpore Serving-based Inference Service Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_distributed_example.html">MindSpore Serving-based Distributed Inference Service Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_grpc.html">gRPC-based MindSpore Serving Access</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_restful.html">RESTful-based MindSpore Serving Access</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_model.html">Servable Provided Through Model Configuration</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Service Deployment with Multiple Subgraphs and Stateful Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#environment-preparation">Environment Preparation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloading-the-example">Downloading the Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="#exporting-a-multi-graph-model">Exporting a Multi-Graph Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deploying-inference-services">Deploying Inference Services</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#configuring-the-service">Configuring the Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="#starting-the-service">Starting the Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#executing-inference">Executing Inference</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="server.html">mindspore_serving.server</a></li>
<li class="toctree-l1"><a class="reference internal" href="client.html">mindspore_serving.client</a></li>
</ul>
<p class="caption"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Service Deployment with Multiple Subgraphs and Stateful Model</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/serving_multi_subgraphs.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="service-deployment-with-multiple-subgraphs-and-stateful-model">
<h1>Service Deployment with Multiple Subgraphs and Stateful Model<a class="headerlink" href="#service-deployment-with-multiple-subgraphs-and-stateful-model" title="Permalink to this headline">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/master/docs/serving/docs/source_en/serving_multi_subgraphs.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png"></a></p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>MindSpore allows a model to generate multiple subgraphs. Such a model is generally a stateful model. Multiple subgraps can share weights and cooperate with each other to achieve performance optimization. For example, in the Pengcheng·Pangu Model network scenario,  based on a sentence, a sentence is generated through multiple inferences, where each inference generates one word. Two graphs are generated for different input lengths. The first graph processes the text with variable length for the first time and only needs to be executed one time. The second graph processes the word generated last time and needs to be executed multiple time. Compared with that before optimization, only the first graph is executed multiple times, the inference service performance can be improved by 5 to 6 times.</p>
<p>MindSpore Serving supports scheduling multi-subgraph model, improving the inference service performance in specific scenarios.</p>
<p>The following uses a simple single-chip model scenario as an example to describe the multi-subgraph model deployment process. For the detail about the distributed scenario, see <a class="reference external" href="https://gitee.com/mindspore/models/tree/master/official/nlp/Pangu_alpha#serving">Pengcheng·Pangu Model model Serving deployment</a></p>
<div class="section" id="environment-preparation">
<h3>Environment Preparation<a class="headerlink" href="#environment-preparation" title="Permalink to this headline">¶</a></h3>
<p>Before running the sample network, ensure that MindSpore Serving has been properly installed and the environment variables are configured. To install and configure MindSpore Serving on your PC, go to the <a class="reference external" href="https://www.mindspore.cn/serving/docs/en/master/serving_install.html">MindSpore Serving installation page</a>.</p>
</div>
<div class="section" id="downloading-the-example">
<h3>Downloading the Example<a class="headerlink" href="#downloading-the-example" title="Permalink to this headline">¶</a></h3>
<p>Please download the <a class="reference external" href="https://gitee.com/mindspore/serving/tree/master/example/matmul_multi_subgraphs/">example</a> first.</p>
</div>
<div class="section" id="exporting-a-multi-graph-model">
<h3>Exporting a Multi-Graph Model<a class="headerlink" href="#exporting-a-multi-graph-model" title="Permalink to this headline">¶</a></h3>
<p>In the directory <code class="docutils literal notranslate"><span class="pre">export_model</span></code>, use <a class="reference external" href="https://gitee.com/mindspore/serving/blob/master/example/matmul_multi_subgraphs/export_model/export_matmul.py">export_matmul.py</a> to build a network with the Matmul and ReduceSum operator and export the MindSpore inference deployment model based on two different inputs.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">copyfile</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Cell</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Net&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">matmul_size</span><span class="p">,</span> <span class="n">init_val</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;init&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">matmul_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">matmul_size</span><span class="p">,</span> <span class="n">init_val</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">matmul_weight</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">matmul_np</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">matmul</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="n">transpose_a</span><span class="o">=</span><span class="n">transpose_a</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="n">transpose_b</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;construct&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul_weight</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">export_net</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Export matmul net , and copy output model `matmul_0.mindir` and `matmul_1.mindir` to directory ../matmul/1&quot;&quot;&quot;</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">matmul_size</span><span class="o">=</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">init_val</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="c1"># subgraph 0: 128,96 matmul 16,96 -&gt; 128,16 reduce sum axis 0-&gt; 16</span>
    <span class="n">predict_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">96</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1"># pylint: disable=protected-access</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">predict_data</span><span class="p">),</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">&quot;matmul_0&quot;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s2">&quot;MINDIR&quot;</span><span class="p">)</span>

    <span class="c1"># subgraph 1: 8,96 matmul 16,96 -&gt; 8,16 reduce sum axis 0-&gt; 16</span>
    <span class="n">predict_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">96</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1"># pylint: disable=protected-access</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">predict_data</span><span class="p">),</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">&quot;matmul_1&quot;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s2">&quot;MINDIR&quot;</span><span class="p">)</span>

    <span class="n">dst_dir</span> <span class="o">=</span> <span class="s1">&#39;../matmul/1&#39;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">dst_dir</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">OSError</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="n">dst_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dst_dir</span><span class="p">,</span> <span class="s1">&#39;matmul_0.mindir&#39;</span><span class="p">)</span>
    <span class="n">copyfile</span><span class="p">(</span><span class="s1">&#39;matmul_0.mindir&#39;</span><span class="p">,</span> <span class="n">dst_file</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;copy matmul_0.mindir to &quot;</span> <span class="o">+</span> <span class="n">dst_dir</span> <span class="o">+</span> <span class="s2">&quot; success&quot;</span><span class="p">)</span>

    <span class="n">dst_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dst_dir</span><span class="p">,</span> <span class="s1">&#39;matmul_1.mindir&#39;</span><span class="p">)</span>
    <span class="n">copyfile</span><span class="p">(</span><span class="s1">&#39;matmul_1.mindir&#39;</span><span class="p">,</span> <span class="n">dst_file</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;copy matmul_1.mindir to &quot;</span> <span class="o">+</span> <span class="n">dst_dir</span> <span class="o">+</span> <span class="s2">&quot; success&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">export_net</span><span class="p">()</span>
</pre></div>
</div>
<p>To use MindSpore for neural network definition, inherit <code class="docutils literal notranslate"><span class="pre">mindspore.nn.Cell</span></code>. (A <code class="docutils literal notranslate"><span class="pre">Cell</span></code> is a base class of all neural networks.) Define each layer of a neural network in the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> method in advance, and then define the <code class="docutils literal notranslate"><span class="pre">construct</span></code> method to complete the forward construction of the neural network. Use <code class="docutils literal notranslate"><span class="pre">export</span></code> of the <code class="docutils literal notranslate"><span class="pre">mindspore</span></code> module to export the model file.
For more detailed examples, see <a class="reference external" href="https://www.mindspore.cn/tutorials/en/master/beginner/quick_start.html">Quick Start for Beginners</a>.</p>
<p>Execute the <code class="docutils literal notranslate"><span class="pre">export_matmul.py</span></code> script to generate the <code class="docutils literal notranslate"><span class="pre">matmul_0.mindir</span></code> and <code class="docutils literal notranslate"><span class="pre">matmul_1.mindir</span></code> files. The inputs shapes of these subgraphs are [128,96] and [8,96].</p>
</div>
<div class="section" id="deploying-inference-services">
<h3>Deploying Inference Services<a class="headerlink" href="#deploying-inference-services" title="Permalink to this headline">¶</a></h3>
<div class="section" id="configuring-the-service">
<h4>Configuring the Service<a class="headerlink" href="#configuring-the-service" title="Permalink to this headline">¶</a></h4>
<p>Start Serving with the following files:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>matmul_multi_subgraphs
├── matmul/
│   │── servable_config.py
│   └── 1/
│       │── matmul_0.mindir
│       └── matmul_1.mindir
└── serving_server.py
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">serving_server.py</span></code>: Script file for starting the service.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">matmul</span></code>: Model folder, which is named after the model name.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">matmul_0.mindir</span></code> and <code class="docutils literal notranslate"><span class="pre">matmul_1.mindir</span></code>: Model files generated by the network in the previous step, which is stored in folder 1 (the number indicates the version number). Different versions are stored in different folders. The version number must be a string of digits. By default, the latest model file is started.</p></li>
<li><p><a class="reference external" href="https://gitee.com/mindspore/serving/blob/master/example/tensor_add/add/servable_config.py">servable_config.py</a>: <a class="reference external" href="https://www.mindspore.cn/serving/docs/en/master/serving_model.html">Model configuration file</a>, which defines the model processing functions, in which method <code class="docutils literal notranslate"><span class="pre">predict</span></code> is defined.</p></li>
</ul>
<p>Content of the configuration file:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">distributed</span>
<span class="kn">from</span> <span class="nn">mindspore_serving.server</span> <span class="kn">import</span> <span class="n">register</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">declare_model</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;matmul_0.mindir&quot;</span><span class="p">,</span> <span class="s2">&quot;matmul_1.mindir&quot;</span><span class="p">],</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;MindIR&quot;</span><span class="p">,</span>
                               <span class="n">with_batch_dim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">process</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">z1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">subgraph</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 128,96 matmul 16,96 -&gt; reduce sum axis 0-&gt; 16</span>
    <span class="n">z2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">subgraph</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 8,96 matmul 16,96 -&gt; reduce sum axis 0-&gt; 16</span>
    <span class="k">return</span> <span class="n">z1</span> <span class="o">+</span> <span class="n">z2</span>


<span class="nd">@register</span><span class="o">.</span><span class="n">register_method</span><span class="p">(</span><span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;z&quot;</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">register</span><span class="o">.</span><span class="n">add_stage</span><span class="p">(</span><span class="n">process</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">outputs_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">z</span>
</pre></div>
</div>
<p>If a model is stateful, multiple calls to the model need to performed in a Python function stage to avoid mutual interference between multiple instances. A mutli-subgraph model generally a stateful model.</p>
<p>In this example, the <code class="docutils literal notranslate"><span class="pre">process</span></code> function invokes the two subgraphs through the interface <code class="docutils literal notranslate"><span class="pre">Model.call</span></code>, and the <code class="docutils literal notranslate"><span class="pre">subgraph</span></code> parameter of <code class="docutils literal notranslate"><span class="pre">Model.call</span></code> specifies the graph index, which starts from 0. The number is the sequence number for loading graphs. In a standalone system, the number corresponds to the sequence number in the <code class="docutils literal notranslate"><span class="pre">model_file</span></code> parameter list of the <code class="docutils literal notranslate"><span class="pre">declare_model</span></code> interface. In a distributed system, this number corresponds to the sequence number in the <code class="docutils literal notranslate"><span class="pre">model_files</span></code> parameter list of the <code class="docutils literal notranslate"><span class="pre">startup_agents</span></code> interface.</p>
</div>
<div class="section" id="starting-the-service">
<h4>Starting the Service<a class="headerlink" href="#starting-the-service" title="Permalink to this headline">¶</a></h4>
<p>Run the <a class="reference external" href="https://gitee.com/mindspore/serving/blob/master/example/matmul_multi_subgraphs/serving_server.py">serving_server.py</a> script to start the Serving server:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">mindspore_serving</span> <span class="kn">import</span> <span class="n">server</span>


<span class="k">def</span> <span class="nf">start</span><span class="p">():</span>
    <span class="n">servable_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">realpath</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

    <span class="n">servable_config</span> <span class="o">=</span> <span class="n">server</span><span class="o">.</span><span class="n">ServableStartConfig</span><span class="p">(</span><span class="n">servable_directory</span><span class="o">=</span><span class="n">servable_dir</span><span class="p">,</span> <span class="n">servable_name</span><span class="o">=</span><span class="s2">&quot;matmul&quot;</span><span class="p">,</span>
                                                 <span class="n">device_ids</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">server</span><span class="o">.</span><span class="n">start_servables</span><span class="p">(</span><span class="n">servable_config</span><span class="p">)</span>

    <span class="n">server</span><span class="o">.</span><span class="n">start_grpc_server</span><span class="p">(</span><span class="s2">&quot;127.0.0.1:5500&quot;</span><span class="p">)</span>
    <span class="n">server</span><span class="o">.</span><span class="n">start_restful_server</span><span class="p">(</span><span class="s2">&quot;127.0.0.1:1500&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">start</span><span class="p">()</span>
</pre></div>
</div>
<p>The above startup script will load and run two inference copies of <code class="docutils literal notranslate"><span class="pre">matmul</span></code> on devices 0 and 1, and the inference requests from the client will be split to the two inference copies.</p>
<p>If the server prints the <code class="docutils literal notranslate"><span class="pre">Serving</span> <span class="pre">gRPC</span> <span class="pre">server</span> <span class="pre">start</span> <span class="pre">success,</span> <span class="pre">listening</span> <span class="pre">on</span> <span class="pre">127.0.0.1:5500</span></code> log, the Serving gRPC service has started successfully and the inference model has already loaded successfully.</p>
</div>
</div>
<div class="section" id="executing-inference">
<h3>Executing Inference<a class="headerlink" href="#executing-inference" title="Permalink to this headline">¶</a></h3>
<p>To access the inference service through gRPC, you need to specify the network address of the gRPC server on the client. Execute <a class="reference external" href="https://gitee.com/mindspore/serving/blob/master/example/matmul_multi_subgraphs/serving_client.py">serving_client.py</a> to call the <code class="docutils literal notranslate"><span class="pre">predict</span></code> method of the MatMul Servable.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore_serving.client</span> <span class="kn">import</span> <span class="n">Client</span>


<span class="k">def</span> <span class="nf">run_matmul</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run client of distributed matmul&quot;&quot;&quot;</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s2">&quot;localhost:5500&quot;</span><span class="p">,</span> <span class="s2">&quot;matmul&quot;</span><span class="p">,</span> <span class="s2">&quot;predict&quot;</span><span class="p">)</span>
    <span class="n">instance</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)}</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;result:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
    <span class="k">assert</span> <span class="s2">&quot;z&quot;</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">run_matmul</span><span class="p">()</span>
</pre></div>
</div>
<p>If the following information is displayed, the Serving inference service has correctly executed the multi-subgraph inference:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>result:
 [{&#39;z&#39;: array([6528.， 6528.， 6528.， 6528.， 6528.， 6528.， 6528.， 6528.， 6528.，
       6528.， 6528.， 6528.， 6528.， 6528.， 6528.， 6528.], }]
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="server.html" class="btn btn-neutral float-right" title="mindspore_serving.server" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="serving_model.html" class="btn btn-neutral float-left" title="Servable Provided Through Model Configuration" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>