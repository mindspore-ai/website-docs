

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Seq2Seq模型实现文本翻译 &mdash; MindSpore master 文档</title>
  

  
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/translations.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="GAN图像生成" href="../generative/gan.html" />
    <link rel="prev" title="LSTM+CRF序列标注" href="sequence_labeling.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">计算机视觉</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cv/resnet50.html">ResNet50图像分类</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/transfer_learning.html">ResNet50迁移学习</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/fgsm.html">FGSM网络对抗攻击</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/vit.html">Vision Transformer图像分类</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/cnnctc.html">CNN+CTC图像文本识别</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/fcn8s.html">FCN图像语义分割</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/shufflenet.html">ShuffleNet图像分类</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/ssd.html">SSD目标检测</a></li>
</ul>
<p class="caption"><span class="caption-text">自然语言处理</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="sentiment_analysis.html">RNN实现情感分类</a></li>
<li class="toctree-l1"><a class="reference internal" href="sequence_labeling.html">LSTM+CRF序列标注</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Seq2Seq模型实现文本翻译</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#概述">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#数据准备">数据准备</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#数据下载模块">数据下载模块</a></li>
<li class="toctree-l3"><a class="reference internal" href="#数据预处理">数据预处理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#数据加载器">数据加载器</a></li>
<li class="toctree-l4"><a class="reference internal" href="#词典">词典</a></li>
<li class="toctree-l4"><a class="reference internal" href="#数据迭代器">数据迭代器</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#模型构建">模型构建</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#编码器encoder">编码器（Encoder）</a></li>
<li class="toctree-l3"><a class="reference internal" href="#注意力层attention">注意力层（Attention）</a></li>
<li class="toctree-l3"><a class="reference internal" href="#解码器decoder">解码器（Decoder）</a></li>
<li class="toctree-l3"><a class="reference internal" href="#seq2seq">Seq2Seq</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#模型训练">模型训练</a></li>
<li class="toctree-l2"><a class="reference internal" href="#模型推理">模型推理</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bleu得分">BLEU得分</a></li>
<li class="toctree-l2"><a class="reference internal" href="#参考文献">参考文献</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">生成式</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../generative/gan.html">GAN图像生成</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generative/dcgan.html">DCGAN生成漫画头像</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generative/pix2pix.html">Pix2Pix实现图像转换</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generative/cyclegan.html">CycleGAN图像风格迁移互换</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generative/diffusion.html">扩散模型</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Seq2Seq模型实现文本翻译</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/nlp/sequence_to_sequence.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="seq2seq模型实现文本翻译">
<h1>Seq2Seq模型实现文本翻译<a class="headerlink" href="#seq2seq模型实现文本翻译" title="永久链接至标题">¶</a></h1>
<p><a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/master/tutorials/application/zh_cn/nlp/mindspore_sequence_to_sequence.ipynb"><img alt="下载Notebook" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_notebook.png" /></a> <a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/master/tutorials/application/zh_cn/nlp/mindspore_sequence_to_sequence.py"><img alt="下载样例代码" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_download_code.png" /></a> <a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/tutorials/application/source_zh_cn/nlp/sequence_to_sequence.ipynb"><img alt="查看源文件" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.png" /></a></p>
<div class="section" id="概述">
<h2>概述<a class="headerlink" href="#概述" title="永久链接至标题">¶</a></h2>
<p>序列到序列模型（sequence to sequence model），又名Seq2Seq模型。它是一种循环神经网络（Recurrent Neural Network，RNN）的变种，突破了原本RNN模型对于输入和输出序列长度的限制，做到将输入序列映射到另一个长度不同的输出序列，因此常用于机器翻译的任务。</p>
<p>Seq2Seq模型一般结构为编码器（encoder）+ 解码器（decoder），前者负责把输入序列编码成一个固定长度的向量，后者将这个向量转化为可变长度的向量。</p>
<p><img alt="avatar1" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/application/source_zh_cn/nlp/images/seq2seq_1.png" /></p>
<blockquote>
<div><p>图片来源：</p>
<p><a class="reference external" href="https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb">https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb</a></p>
</div></blockquote>
<p>后来，人们在encoder-decoder的基础上引入了注意力机制（attention），使模型在各个任务中的表现更为出色。</p>
</div>
<div class="section" id="数据准备">
<h2>数据准备<a class="headerlink" href="#数据准备" title="永久链接至标题">¶</a></h2>
<p>我们本次使用的数据集为<strong>Multi30K数据集</strong>，它是一个大规模的图像-文本数据集，包含30K+图片，每张图片对应两类不同的文本描述：</p>
<ul class="simple">
<li><p>英语描述，及对应的德语翻译；</p></li>
<li><p>五个独立的、非翻译而来的英语和德语描述，描述中包含的细节并不相同；</p></li>
</ul>
<p>因其收集的不同语言对于图片的描述相互独立，所以训练出的模型可以更好地适用于有噪声的多模态内容。</p>
<p><img alt="avatar2" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/application/source_zh_cn/nlp/images/seq2seq_2.png" /></p>
<blockquote>
<div><p>图片来源：</p>
<p>Elliott, D., Frank, S., Sima’an, K., &amp; Specia, L. (2016). Multi30K: Multilingual English-German Image Descriptions. CoRR, 1605.00459.</p>
</div></blockquote>
<p>首先，我们需要安装如下依赖：</p>
<ul class="simple">
<li><p>BLEU Score计算：<code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">nltk</span></code></p></li>
</ul>
<div class="section" id="数据下载模块">
<h3>数据下载模块<a class="headerlink" href="#数据下载模块" title="永久链接至标题">¶</a></h3>
<p>使用<code class="docutils literal notranslate"><span class="pre">download</span></code>进行数据下载，并将<code class="docutils literal notranslate"><span class="pre">tar.gz</span></code>文件解压到指定文件夹。</p>
<p>下载好的数据集目录结构如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>home_path/.mindspore_examples
├─test
│      test2016.de
│      test2016.en
│      test2016.fr
│
├─train
│      train.de
│      train.en
│
└─valid
        val.de
        val.en
</pre></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">download</span> <span class="kn">import</span> <span class="n">download</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># 训练、验证、测试数据集下载地址</span>
<span class="n">urls</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/training.tar.gz&#39;</span><span class="p">,</span>
    <span class="s1">&#39;valid&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/validation.tar.gz&#39;</span><span class="p">,</span>
    <span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.quest.dcs.shef.ac.uk/wmt17_files_mmt/mmt_task1_test2016.tar.gz&#39;</span>
<span class="p">}</span>

<span class="c1"># 指定保存路径为 `home_path/.mindspore_examples`</span>
<span class="n">cache_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="o">.</span><span class="n">home</span><span class="p">()</span> <span class="o">/</span> <span class="s1">&#39;.mindspore_examples&#39;</span>

<span class="n">train_path</span> <span class="o">=</span> <span class="n">download</span><span class="p">(</span><span class="n">urls</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;tar.gz&#39;</span><span class="p">)</span>
<span class="n">valid_path</span> <span class="o">=</span> <span class="n">download</span><span class="p">(</span><span class="n">urls</span><span class="p">[</span><span class="s1">&#39;valid&#39;</span><span class="p">],</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">,</span> <span class="s1">&#39;valid&#39;</span><span class="p">),</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;tar.gz&#39;</span><span class="p">)</span>
<span class="n">test_path</span> <span class="o">=</span> <span class="n">download</span><span class="p">(</span><span class="n">urls</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">),</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;tar.gz&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="数据预处理">
<h3>数据预处理<a class="headerlink" href="#数据预处理" title="永久链接至标题">¶</a></h3>
<p>在使用数据进行模型训练等操作时，我们需要对数据进行预处理，流程如下：</p>
<ol class="arabic simple">
<li><p>加载数据集，目前数据为句子形式的文本，需要进行分词，即将句子拆解为单独的词元（token，可以为字符或者单词）；</p></li>
<li><p>将每个词元映射到从0开始的数字索引中（为节约存储空间，可过滤掉词频低的词元），词元和数字索引所构成的集合叫做词典（vocabulary）；</p></li>
<li><p>添加特殊占位符，标明序列的起始与结束，统一序列长度，并创建数据迭代器；</p></li>
</ol>
<div class="section" id="数据加载器">
<h4>数据加载器<a class="headerlink" href="#数据加载器" title="永久链接至标题">¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>


<span class="k">class</span> <span class="nc">Multi30K</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multi30K数据集加载器</span>

<span class="sd">    加载Multi30K数据集并处理为一个Python迭代对象。</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>

        <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
            <span class="c1"># 对句子进行分词，统一大小写</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">tok</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\w+|[^\w\s]&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)]</span>

        <span class="c1"># 读取Multi30K数据，并进行分词</span>
        <span class="n">members</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">)}</span>
        <span class="n">de_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">members</span><span class="p">[</span><span class="s1">&#39;de&#39;</span><span class="p">])</span>
        <span class="n">en_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">members</span><span class="p">[</span><span class="s1">&#39;en&#39;</span><span class="p">])</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">de_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">de_file</span><span class="p">:</span>
            <span class="n">de</span> <span class="o">=</span> <span class="n">de_file</span><span class="o">.</span><span class="n">readlines</span><span class="p">()[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">de</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenize</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">de</span><span class="p">]</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">en_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">en_file</span><span class="p">:</span>
            <span class="n">en</span> <span class="o">=</span> <span class="n">en_file</span><span class="o">.</span><span class="n">readlines</span><span class="p">()[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">en</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenize</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">en</span><span class="p">]</span>

        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">de</span><span class="p">,</span> <span class="n">en</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">Multi30K</span><span class="p">(</span><span class="n">train_path</span><span class="p">),</span> <span class="n">Multi30K</span><span class="p">(</span><span class="n">valid_path</span><span class="p">),</span> <span class="n">Multi30K</span><span class="p">(</span><span class="n">test_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>对解压和分词结果进行测试，打印测试数据集第一组英德语文本，可以看到每一个单词和标点符号已经被单独分离出来。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">de</span><span class="p">,</span> <span class="n">en</span> <span class="ow">in</span> <span class="n">test_dataset</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;de = </span><span class="si">{</span><span class="n">de</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;en = </span><span class="si">{</span><span class="n">en</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
de = [&#39;ein&#39;, &#39;mann&#39;, &#39;mit&#39;, &#39;einem&#39;, &#39;orangefarbenen&#39;, &#39;hut&#39;, &#39;,&#39;, &#39;der&#39;, &#39;etwas&#39;, &#39;anstarrt&#39;, &#39;.&#39;]
en = [&#39;a&#39;, &#39;man&#39;, &#39;in&#39;, &#39;an&#39;, &#39;orange&#39;, &#39;hat&#39;, &#39;starring&#39;, &#39;at&#39;, &#39;something&#39;, &#39;.&#39;]
</pre></div></div>
</div>
</div>
<div class="section" id="词典">
<h4>词典<a class="headerlink" href="#词典" title="永久链接至标题">¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Vocab</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;通过词频字典，构建词典&quot;&quot;&quot;</span>

    <span class="n">special_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&lt;unk&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;bos&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word_count_dict</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2idx</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">tok</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">special_tokens</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2idx</span><span class="p">[</span><span class="n">tok</span><span class="p">]</span> <span class="o">=</span> <span class="n">idx</span>

        <span class="c1"># 过滤低词频的词元</span>
        <span class="n">filted_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">w</span><span class="p">:</span> <span class="n">c</span>
            <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">word_count_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">c</span> <span class="o">&gt;=</span> <span class="n">min_freq</span>
        <span class="p">}</span>
        <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">filted_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2idx</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word2idx</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">idx2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">idx</span><span class="p">:</span> <span class="n">word</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2idx</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">bos_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2idx</span><span class="p">[</span><span class="s1">&#39;&lt;bos&gt;&#39;</span><span class="p">]</span>  <span class="c1"># 特殊占位符：序列开始</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eos_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2idx</span><span class="p">[</span><span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">]</span>  <span class="c1"># 特殊占位符：序列结束</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2idx</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">]</span>  <span class="c1"># 特殊占位符：补充字符</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unk_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2idx</span><span class="p">[</span><span class="s1">&#39;&lt;unk&gt;&#39;</span><span class="p">]</span>  <span class="c1"># 特殊占位符：低词频词元或未曾出现的词元</span>

    <span class="k">def</span> <span class="nf">_word2idx</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;单词映射至数字索引&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2idx</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">unk_idx</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2idx</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_idx2word</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;数字索引映射至单词&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">idx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx2word</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;input index is not in vocabulary.&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx2word</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word_or_list</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;将单个单词或单词数组映射至单个数字索引或数字索引数组&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">word_or_list</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_word2idx</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">word_or_list</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_word2idx</span><span class="p">(</span><span class="n">word_or_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx_or_list</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;将单个数字索引或数字索引数组映射至单个单词或单词数组&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx_or_list</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_idx2word</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx_or_list</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_idx2word</span><span class="p">(</span><span class="n">idx_or_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word2idx</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>通过自定义词频字典进行测试，我们可以看到词典已去除词频少于2的词元c，并加入了默认的四个特殊占位符，故词典整体长度为：4 - 1 + 4 = 7</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">word_count</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span><span class="mi">20</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">}</span>

<span class="n">vocab</span> <span class="o">=</span> <span class="n">Vocab</span><span class="p">(</span><span class="n">word_count</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
7
</pre></div></div>
</div>
<p>使用<code class="docutils literal notranslate"><span class="pre">collections</span></code>中的<code class="docutils literal notranslate"><span class="pre">Counter</span></code>和<code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code>统计英/德语每个单词在整体文本中出现的频率。构建词频字典，然后再将词频字典转为词典。</p>
<p>在分配数字索引时有一个小技巧：常用的词元对应数值较小的索引，这样可以节约空间。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">OrderedDict</span>

<span class="k">def</span> <span class="nf">build_vocab</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="n">de_words</span><span class="p">,</span> <span class="n">en_words</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">de</span><span class="p">,</span> <span class="n">en</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
        <span class="n">de_words</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">de</span><span class="p">)</span>
        <span class="n">en_words</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">en</span><span class="p">)</span>

    <span class="n">de_count_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">de_words</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">en_count_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">en_words</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">Vocab</span><span class="p">(</span><span class="n">de_count_dict</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">Vocab</span><span class="p">(</span><span class="n">en_count_dict</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span> <span class="o">=</span> <span class="n">build_vocab</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Unique tokens in de vocabulary:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">de_vocab</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Unique tokens in de vocabulary: 7882
</pre></div></div>
</div>
</div>
<div class="section" id="数据迭代器">
<h4>数据迭代器<a class="headerlink" href="#数据迭代器" title="永久链接至标题">¶</a></h4>
<p>数据预处理的最后一步是创建数据迭代器，我们在进一步处理数据（包括批处理，添加起始和终止符号，统一序列长度）后，将数据以张量的形式返回。</p>
<p>创建数据迭代器需要如下参数：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dataset</span></code>：分词后的数据集</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">de_vocab</span></code>：德语词典</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">en_vocab</span></code>：英语词典</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batch_size</span></code>：批量大小，即一个batch中包含多少个序列</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_len</span></code>：序列最大长度，为最长有效文本长度 + 2（序列开始、序列结束占位符），如不满则补齐，如超过则丢弃</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">drop_remainder</span></code>：是否在最后一个batch未满时，丢弃该batch</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>

<span class="k">class</span> <span class="nc">Iterator</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;创建数据迭代器&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">drop_reminder</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">de_vocab</span> <span class="o">=</span> <span class="n">de_vocab</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">en_vocab</span> <span class="o">=</span> <span class="n">en_vocab</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">=</span> <span class="n">max_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop_reminder</span> <span class="o">=</span> <span class="n">drop_reminder</span>

        <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">len</span> <span class="o">=</span> <span class="n">length</span> <span class="k">if</span> <span class="n">drop_reminder</span> <span class="k">else</span> <span class="n">length</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># 批量数量</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">pad</span><span class="p">(</span><span class="n">idx_list</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">max_len</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;统一序列长度，并记录有效长度&quot;&quot;&quot;</span>
            <span class="n">idx_pad_list</span><span class="p">,</span> <span class="n">idx_len</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
            <span class="c1"># 当前序列度超过最大长度时，将超出的部分丢弃；当前序列长度小于最大长度时，用占位符补齐</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx_list</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_len</span> <span class="o">-</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">idx_pad_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">vocab</span><span class="o">.</span><span class="n">bos_idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">i</span><span class="p">[:</span><span class="n">max_len</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">vocab</span><span class="o">.</span><span class="n">eos_idx</span><span class="p">]</span>
                    <span class="p">)</span>
                    <span class="n">idx_len</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">max_len</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">idx_pad_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">vocab</span><span class="o">.</span><span class="n">bos_idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="p">[</span><span class="n">vocab</span><span class="o">.</span><span class="n">eos_idx</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">idx_len</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">idx_pad_list</span><span class="p">,</span> <span class="n">idx_len</span>

        <span class="k">def</span> <span class="nf">sort_by_length</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;对德/英语的字段长度进行排序&quot;&quot;&quot;</span>
            <span class="n">data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">return</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>

        <span class="k">def</span> <span class="nf">encode_and_pad</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">max_len</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;将批量中的文本数据转换为数字索引，并统一每个序列的长度&quot;&quot;&quot;</span>
            <span class="c1"># 将当前批量数据中的词元转化为索引</span>
            <span class="n">src_data</span><span class="p">,</span> <span class="n">trg_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch_data</span><span class="p">)</span>
            <span class="n">src_idx</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">de_vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">src_data</span><span class="p">]</span>
            <span class="n">trg_idx</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">en_vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">trg_data</span><span class="p">]</span>

            <span class="c1"># 统一序列长度</span>
            <span class="n">src_idx</span><span class="p">,</span> <span class="n">trg_idx</span> <span class="o">=</span> <span class="n">sort_by_length</span><span class="p">(</span><span class="n">src_idx</span><span class="p">,</span> <span class="n">trg_idx</span><span class="p">)</span>
            <span class="n">src_idx_pad</span><span class="p">,</span> <span class="n">src_len</span> <span class="o">=</span> <span class="n">pad</span><span class="p">(</span><span class="n">src_idx</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
            <span class="n">trg_idx_pad</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pad</span><span class="p">(</span><span class="n">trg_idx</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">src_idx_pad</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg_idx_pad</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">len</span><span class="p">):</span>
            <span class="c1"># 获取当前批量的数据</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">len</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_reminder</span><span class="p">:</span>
                <span class="n">batch_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">batch_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>

            <span class="n">src_idx</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg_idx</span> <span class="o">=</span> <span class="n">encode_and_pad</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span><span class="p">)</span>
            <span class="c1"># 将序列数据转换为tensor</span>
            <span class="k">yield</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">src_idx</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> \
                <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">src_len</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> \
                <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">trg_idx</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">len</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_iterator</span> <span class="o">=</span> <span class="n">Iterator</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">drop_reminder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">valid_iterator</span> <span class="o">=</span> <span class="n">Iterator</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">drop_reminder</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">test_iterator</span> <span class="o">=</span> <span class="n">Iterator</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">drop_reminder</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="模型构建">
<h2>模型构建<a class="headerlink" href="#模型构建" title="永久链接至标题">¶</a></h2>
<div class="section" id="编码器encoder">
<h3>编码器（Encoder）<a class="headerlink" href="#编码器encoder" title="永久链接至标题">¶</a></h3>
<p>在编码器中，我们输入一个序列<span class="math notranslate nohighlight">\(X=\{x_1, x_2, ..., x_T\}\)</span>，在embedding层将其转化为向量，循环计算隐藏状态<span class="math notranslate nohighlight">\(H=\{h_1, h_2, ..., h_T\}\)</span>，并在最后的隐藏状态中返回上下文向量<span class="math notranslate nohighlight">\(z=h_T\)</span>。</p>
<p>实现编码器的方式有很多种，在这里我们使用的是门控循环单元模型（Gated Rrecurrent Units, GRU）。它在原始RNN的基础上引入了门机制（gate mechanism），用以控制输入隐藏状态和从隐藏状态输出的信息。其中，更新门（update gate， 又称记忆门，一般用<span class="math notranslate nohighlight">\(z_t\)</span>表示）用于控制前一时刻的状态信息<span class="math notranslate nohighlight">\(h_{t-1}\)</span>被带入到当前状态<span class="math notranslate nohighlight">\(h_t\)</span>中的程度。重置门（reset gate，一般用<span class="math notranslate nohighlight">\(r_t\)</span>表示）控制前一状态<span class="math notranslate nohighlight">\(h_t\)</span>有多少信息被写入到当前候选集<span class="math notranslate nohighlight">\(n_t\)</span>上。</p>
<div class="math notranslate nohighlight">
\[h_t = \text{RNN}(e(x_t), h_{t-1})\]</div>
<p>在进行文本翻译类任务时，我们一般使用双向GRU，即在训练中同时考虑当前词语之前及之后的文本内容。双向GRU的每层由两个RNN构成，前向RNN由左至右循环计算隐藏状态，反向RNN从右至左计算隐藏状态，公式表达如下：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
h_t^\rightarrow &amp;= \text{EncoderGRU}^\rightarrow(e(x_t^\rightarrow),h_{t-1}^\rightarrow)\\
h_t^\leftarrow &amp;= \text{EncoderGRU}^\leftarrow(e(x_t^\leftarrow),h_{t-1}^\leftarrow)
\end{align*}\end{split}\]</div>
<p>每个RNN网络在观察到句子中的最后一个词后，输出一个上下文向量，前向RNN的输出为<span class="math notranslate nohighlight">\(z^\rightarrow=h_T^\rightarrow\)</span>，反向RNN的输出为<span class="math notranslate nohighlight">\(z^\leftarrow=h_T^\leftarrow\)</span>。</p>
<p><img alt="avatar3" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/application/source_zh_cn/nlp/images/seq2seq_3.png" /></p>
<blockquote>
<div><p>图片来源：</p>
<p><a class="reference external" href="https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb">https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb</a></p>
</div></blockquote>
<p>编码器最终会返回两项：<code class="docutils literal notranslate"><span class="pre">outputs</span></code>和<code class="docutils literal notranslate"><span class="pre">hidden</span></code>。</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">outputs</span></code>为双向GRU最上层隐藏状态，形状为[max_len, batch_size, hid_dim * num_directions]。以<span class="math notranslate nohighlight">\(t=1\)</span>时刻为例，其对应的output为前向RNN中<span class="math notranslate nohighlight">\(t=1\)</span>时刻最上层隐藏状态和反向RNN中<span class="math notranslate nohighlight">\(t=T\)</span>时刻的结合，即<span class="math notranslate nohighlight">\(h_1 = [h_1^\rightarrow; h_{T}^\leftarrow]\)</span>；</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hidden</span></code>表示每层的最终隐藏状态，即上文提到的上下文向量。后续将作为编码器初始时刻的隐藏状态<span class="math notranslate nohighlight">\(s_0\)</span>，但由于编码器（decoder）的结构并不是双向的，仅仅需要一个上下文向量<span class="math notranslate nohighlight">\(z\)</span>，为了与之对应，我们将编码器中的两个向量组合起来，放入全连接层<span class="math notranslate nohighlight">\(g\)</span>中，并最后使用激活函数<span class="math notranslate nohighlight">\(tanh\)</span>；</p></li>
</ul>
<div class="math notranslate nohighlight">
\[z=\tanh(g(h_T^\rightarrow, h_T^\leftarrow)) = \tanh(g(z^\rightarrow, z^\leftarrow)) = s_0\]</div>
<p>MindSpore为大家提供了GRU的接口，可以在编码器搭建中直接调用，通过设置参数<code class="docutils literal notranslate"><span class="pre">bidirectional=True</span></code>使用双向GRU。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="n">enc_hid_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">)</span>  <span class="c1"># Embedding层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">emb_dim</span><span class="p">,</span> <span class="n">enc_hid_dim</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># 双向GRU层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">enc_hid_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">compute_dtype</span><span class="p">)</span>  <span class="c1"># 全连接层</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="o">-</span><span class="n">dropout</span><span class="p">)</span>  <span class="c1"># dropout，防止过拟合</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;构建编码器</span>

<span class="sd">        Args:</span>
<span class="sd">            src: 源序列，为已经转换为数字索引并统一长度的序列；shape = [src len, batch_size]</span>
<span class="sd">            src_len: 有效长度；shape = [batch_size, ]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># 将输入源序列转化为向量，并进行暂退（dropout）</span>
        <span class="c1"># shape = [src len, batch size, emb dim]</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">src</span><span class="p">))</span>
        <span class="c1"># 计算输出</span>
        <span class="c1"># shape = [src len, batch size, enc hid dim*2]</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">seq_length</span><span class="o">=</span><span class="n">src_len</span><span class="p">)</span>
        <span class="c1"># 为适配解码器，合并两个上下文函数</span>
        <span class="c1"># shape = [batch size, dec hid dim]</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">hidden</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span> <span class="n">hidden</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>

        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">hidden</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="注意力层attention">
<h3>注意力层（Attention）<a class="headerlink" href="#注意力层attention" title="永久链接至标题">¶</a></h3>
<p>在机器翻译中，每个生成的词可能对应源句子中不同的词，而传统的无注意力机制的Seq2Seq模型更偏向于关注句子中的最后一个词。为了进一步优化模型，我们引入了注意力机制。</p>
<p>注意力机制便是赋予源句子和目标句子中对应的词以更高的权重，它整合了我们目前为止编码与解码的所有信息，并输出一个表示注意力权重的向量<span class="math notranslate nohighlight">\(a_t\)</span>，用来决定在下一步的预测<span class="math notranslate nohighlight">\(\hat{y}_{t+}\)</span>中应该给予哪些词更高的关注度。</p>
<p><img alt="avatar4" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/application/source_zh_cn/nlp/images/seq2seq_4.png" /></p>
<blockquote>
<div><p>图片来源：</p>
<p><a class="reference external" href="https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb">https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb</a></p>
</div></blockquote>
<p>首先，我们需要明确编码器中的每一个隐藏状态和解码器中上一个时刻隐藏状态之间的匹配程度<span class="math notranslate nohighlight">\(E_t\)</span>。</p>
<p>截止到当前的时刻<span class="math notranslate nohighlight">\(t\)</span>，编码器（encoder）中的所有信息为全部前向和后向RNN的隐藏状态的组合<span class="math notranslate nohighlight">\(H\)</span>，是一个有<span class="math notranslate nohighlight">\(T\)</span>个张量的序列；解码器（decoder）中的所有信息为上一时刻的隐藏状态<span class="math notranslate nohighlight">\(s_{t-1}\)</span>，是一个单独的张量。为了统一二者的维度，我们需要将解码器中上一时刻的隐藏状态<span class="math notranslate nohighlight">\(s_{t-1}\)</span>重复<span class="math notranslate nohighlight">\(T\)</span>次，接着把处理好的解码器信息与编码器信息堆叠起来，并输入到线性层<code class="docutils literal notranslate"><span class="pre">att</span></code>和激活函数<span class="math notranslate nohighlight">\(\text{tanh}\)</span>中，计算编码器与解码器隐藏状态之间的能量<span class="math notranslate nohighlight">\(E_t\)</span>。</p>
<div class="math notranslate nohighlight">
\[E_t = \tanh(\text{attn}(s_{t-1}, H))\]</div>
<p>当前<span class="math notranslate nohighlight">\(E_t\)</span>的每个batch中tensor的形状为[dec hid dim, src len]，但是注意最终的注意力权重是需要作用在源序列之上的，所以注意力权重的维度也应该与源句子的维度[src len]相对应。为此，我们引入了一个可学习的张量<span class="math notranslate nohighlight">\(v\)</span>。</p>
<div class="math notranslate nohighlight">
\[\hat{a}_t = v E_t\]</div>
<p>我们可以将<span class="math notranslate nohighlight">\(v\)</span>看作是所有编码器隐藏状态的加权和的权重，简单来说便是对源序列中的每个词的关注程度。<span class="math notranslate nohighlight">\(v\)</span>的参数是随机初始化的，它会在反向传播中与模型的其余部分一起学习。此外，<span class="math notranslate nohighlight">\(v\)</span>并不依赖于时间，所以在解码中每个时间步长使用的<span class="math notranslate nohighlight">\(v\)</span>是一致的。</p>
<p>最终，我们使用<span class="math notranslate nohighlight">\(\text{softmax}\)</span>函数，来保证注意力向量<span class="math notranslate nohighlight">\(a_t\)</span>中每一个元素的大小都在0-1之间，并且所有元素加和为1。</p>
<div class="math notranslate nohighlight">
\[a_t = \text{softmax}(\hat{a_t})\]</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hid_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># attention线性层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">((</span><span class="n">enc_hid_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">dec_hid_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">compute_dtype</span><span class="p">)</span>
        <span class="c1"># v， 用不带有bias的线性层表示</span>
        <span class="c1"># shape = [1, dec hid dim]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">dec_hid_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">compute_dtype</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Attention层</span>

<span class="sd">        Args:</span>
<span class="sd">            hidden: 解码器上一个时刻的隐藏状态；shape = [batch size, dec hid dim]</span>
<span class="sd">            encoder_outputs: 编码器的输出，前向与反向RNN的隐藏状态；shape = [src len, batch size, enc hid dim * 2]</span>
<span class="sd">            mask: 将&lt;pad&gt;占位符的注意力权重替换为0或者很小的数值；shape = [batch size, src len]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">src_len</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># 重复解码器隐藏状态src len次，对齐维度</span>
        <span class="c1"># shape = [batch size, src len, dec hid dim]</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">hidden</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># 将编码器输出中的第1、2维度进行交换，对齐维度</span>
        <span class="c1"># shape = [batch size, src len, enc hid dim*2]</span>
        <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># 计算E_t</span>
        <span class="c1"># shape = [batch size, src len, dec hid dim]</span>
        <span class="n">energy</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)))</span>

        <span class="c1"># 计算v * E_t</span>
        <span class="c1"># shape = [batch size, src len]</span>
        <span class="n">attention</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">(</span><span class="n">energy</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># 不需要考虑序列中&lt;pad&gt;占位符的注意力权重</span>
        <span class="n">attention</span> <span class="o">=</span> <span class="n">attention</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1e10</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attention</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="解码器decoder">
<h3>解码器（Decoder）<a class="headerlink" href="#解码器decoder" title="永久链接至标题">¶</a></h3>
<p>解码器中包含了上述的注意力层，在获得注意力权重向量<span class="math notranslate nohighlight">\(a_t\)</span>后，我们将其应用在编码器的隐藏状态<span class="math notranslate nohighlight">\(H\)</span>上，得到一个表示编码器隐藏状态加权和的向量<span class="math notranslate nohighlight">\(w_t\)</span>。</p>
<div class="math notranslate nohighlight">
\[w_t = a_t H\]</div>
<p>我们将该向量<span class="math notranslate nohighlight">\(w_t\)</span>，连同embedding后的输入<span class="math notranslate nohighlight">\(d(y_t)\)</span>，上一时刻的隐藏状态<span class="math notranslate nohighlight">\(s_{t-1}\)</span>，一起放入编码器的RNN网络中，并将输出送入线性层<span class="math notranslate nohighlight">\(f\)</span>，得到关于目标句子中下一时刻出现的单词的预测。</p>
<div class="math notranslate nohighlight">
\[s_t = \text{DecoderGRU}(d(y_t), w_t, s_{t-1})\]</div>
<div class="math notranslate nohighlight">
\[\hat{y}_{t+1} = f(d(y_t), w_t, s_t)\]</div>
<p><img alt="avatar5" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/application/source_zh_cn/nlp/images/seq2seq_5.png" /></p>
<blockquote>
<div><p>图片来源：</p>
<p><a class="reference external" href="https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb">https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb</a></p>
</div></blockquote>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="n">enc_hid_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">attention</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">attention</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">((</span><span class="n">enc_hid_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">((</span><span class="n">enc_hid_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">dec_hid_dim</span> <span class="o">+</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">compute_dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="o">-</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;构建解码器</span>

<span class="sd">        Args:</span>
<span class="sd">            input: 输入的单词；shape = [batch size]</span>
<span class="sd">            hidden: 解码器上一时刻的隐藏状态；shape = [batch size, dec hid dim]</span>
<span class="sd">            encoder_outputs: 编码器的输出，前向与反向RNN的隐藏状态；shape = [src len, batch size, enc hid dim * 2]</span>
<span class="sd">            mask: 将&lt;pad&gt;占位符的注意力权重替换为0或者很小的数值；shape = [batch size, src len]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># 为输入增加额外维度</span>
        <span class="c1"># shape = [1, batch size]</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># 输入词的embedding输出， d(y_t)</span>
        <span class="c1"># shape = [1, batch size, emb dim]</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>

        <span class="c1"># 注意力权重向量, a_t</span>
        <span class="c1"># shape = [batch size, src len]</span>
        <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

        <span class="c1"># 为注意力权重增加额外维度</span>
        <span class="c1"># shape = [batch size, 1, src len]</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 将编码器隐藏状态中的第1、2维度进行交换</span>
        <span class="c1"># shape = [batch size, src len, enc hid dim * 2]</span>
        <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># 计算w_t</span>
        <span class="c1"># shape = [batch size, 1, enc hid dim * 2]</span>
        <span class="n">weighted</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>

        <span class="c1"># 将w_t的第1、2维度进行交换</span>
        <span class="c1"># shape = [1, batch size, enc hid dim * 2]</span>
        <span class="n">weighted</span> <span class="o">=</span> <span class="n">weighted</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># 将emdedded与weighted堆叠在一起，后输入进RNN层</span>
        <span class="c1"># rnn_input shape = [1, batch size, (enc hid dim * 2) + emb dim]</span>
        <span class="c1"># output shape = [seq len = 1, batch size, dec hid dim * n directions]</span>
        <span class="c1"># hidden shape = [n layers (1) * n directions (1) = 1, batch size, dec hid dim]</span>
        <span class="n">rnn_input</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">embedded</span><span class="p">,</span> <span class="n">weighted</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">rnn_input</span><span class="p">,</span> <span class="n">hidden</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

        <span class="c1"># 去除多余的第1维度</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="n">embedded</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">weighted</span> <span class="o">=</span> <span class="n">weighted</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># 将embedded，weighted和hidden堆叠起来，并输入线性层，预测下一个词</span>
        <span class="c1"># shape = [batch size, output dim]</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_out</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">output</span><span class="p">,</span> <span class="n">weighted</span><span class="p">,</span> <span class="n">embedded</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">hidden</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">a</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="seq2seq">
<h3>Seq2Seq<a class="headerlink" href="#seq2seq" title="永久链接至标题">¶</a></h3>
<p>Seq2Seq封装器将我们之前创建的编码器与解码器合并起来。</p>
<p>简单梳理一下整体过程：</p>
<ol class="arabic simple">
<li><p>初始化空数列<code class="docutils literal notranslate"><span class="pre">outputs</span></code>，用于储存每次的预测结果；</p></li>
<li><p>源序列<span class="math notranslate nohighlight">\(X\)</span>作为编码器的输入，输出<span class="math notranslate nohighlight">\(z\)</span>和<span class="math notranslate nohighlight">\(H\)</span>；</p></li>
<li><p>解码器初始时刻的隐藏状态为编码器中输出的上下文向量，即编码器最后时刻的隐藏状态，<span class="math notranslate nohighlight">\(s_0 = z = h_T\)</span>；</p></li>
<li><p>解码器最开始的输入<span class="math notranslate nohighlight">\(y_1\)</span>为表示序列开始的占位符&lt;bos&gt;;</p></li>
<li><p>重复以下步骤：</p>
<ul class="simple">
<li><p>将此时刻<span class="math notranslate nohighlight">\(t\)</span>的输入<span class="math notranslate nohighlight">\(y_t\)</span>，上一时刻的隐藏状态<span class="math notranslate nohighlight">\(s_{t-1}\)</span>，编码器中的所有隐藏状态<span class="math notranslate nohighlight">\(H\)</span>作为输入；</p></li>
<li><p>输出对下一时刻的预测<span class="math notranslate nohighlight">\(\hat{y}_{t+1}\)</span>，以及新的隐藏状态<span class="math notranslate nohighlight">\(s_t\)</span>；</p></li>
<li><p>将预测结果存入<code class="docutils literal notranslate"><span class="pre">outputs</span></code>中</p></li>
<li><p>确定是否使用teacher forcing，如是，<span class="math notranslate nohighlight">\(y_{t+1} = \hat{y}_{t+1}\)</span>，如否，下一时刻的输入为目标序列中的词；</p></li>
</ul>
</li>
</ol>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="k">class</span> <span class="nc">Seq2Seq</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">src_pad_idx</span><span class="p">,</span> <span class="n">teacher_forcing_ratio</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">src_pad_idx</span> <span class="o">=</span> <span class="n">src_pad_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">teacher_forcing_ratio</span> <span class="o">=</span> <span class="n">teacher_forcing_ratio</span>  <span class="c1"># 使用teacher forcing的可能性</span>

    <span class="k">def</span> <span class="nf">create_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;标记出每个序列中&lt;pad&gt;占位符的位置&quot;&quot;&quot;</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">src</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">src_pad_idx</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mask</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg</span><span class="p">,</span> <span class="n">trg_len</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;构建seq2seq模型</span>

<span class="sd">        Args:</span>
<span class="sd">            src: 源序列；shape = [src len, batch size]</span>
<span class="sd">            src_len: 源序列长度；shape = [batch size]</span>
<span class="sd">            trg: 目标序列；shape = [trg len, batch size]</span>
<span class="sd">            trg_len: 目标序列长度；shape = [trg len, batch size]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">trg_len</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">trg_len</span> <span class="o">=</span> <span class="n">trg</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1">#存储解码器输出</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># 编码器（encoder）：</span>
        <span class="c1"># 输入：源序列、源序列长度</span>
        <span class="c1"># 输出1：编码器中所有前向与反向RNN 的隐藏状态 encoder_outputs</span>
        <span class="c1"># 输出2：编码器中前向与反向RNN中最后时刻的隐藏状态放入线性层后的输出 hidden</span>
        <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">)</span>

        <span class="c1">#解码器的第一个输入是表示序列开始的占位符&lt;bos&gt;</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># 标记源序列中&lt;pad&gt;占位符的位置</span>
        <span class="c1"># shape = [batch size, src len]</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_mask</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">trg_len</span><span class="p">):</span>

            <span class="c1"># 解码器（decoder）：</span>
            <span class="c1"># 输入：源句子序列 inputs、前一时刻的隐藏状态 hidden、编码器所有前向与反向RNN的隐藏状态</span>
            <span class="c1"># 标明每个句子中的&lt;pad&gt;，方便计算注意力权重时忽略该部分</span>
            <span class="c1"># 输出：预测结果 output、新的隐藏状态 hidden、注意力权重（忽略）</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

            <span class="c1"># 将预测结果放入之前的存储中</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

            <span class="c1">#找出对应预测概率最大的词元</span>
            <span class="n">top1</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="c1">#如果目前为模型训练状态，则按照之前设定的概率使用teacher forcing</span>
                <span class="n">minval</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="n">maxval</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="n">teacher_force</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">teacher_forcing_ratio</span>
                <span class="c1"># 如使用teacher forcing，则将目标序列中对应的词元作为下一个输入</span>
                <span class="c1"># 如不使用teacher forcing，则将预测结果作为下一个输入</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">if</span> <span class="n">teacher_force</span> <span class="k">else</span> <span class="n">top1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">top1</span>

        <span class="c1"># 将所有输出整合为tensor</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="模型训练">
<h2>模型训练<a class="headerlink" href="#模型训练" title="永久链接至标题">¶</a></h2>
<p>模型参数，编码器，注意力层，解码器以及Seq2Seq网络初始化。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">de_vocab</span><span class="p">)</span>  <span class="c1"># 输入维度</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">en_vocab</span><span class="p">)</span>  <span class="c1"># 输出维度</span>
<span class="n">enc_emb_dim</span> <span class="o">=</span> <span class="mi">256</span>  <span class="c1"># Encoder Embedding层维度</span>
<span class="n">dec_emb_dim</span> <span class="o">=</span> <span class="mi">256</span>  <span class="c1"># Decoder Embedding层维度</span>
<span class="n">enc_hid_dim</span> <span class="o">=</span> <span class="mi">512</span>  <span class="c1"># Encoder 隐藏层维度</span>
<span class="n">dec_hid_dim</span> <span class="o">=</span> <span class="mi">512</span>  <span class="c1"># Decoder 隐藏层维度</span>
<span class="n">enc_dropout</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Encoder Dropout</span>
<span class="n">dec_dropout</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Decoder Dropout</span>
<span class="n">src_pad_idx</span> <span class="o">=</span> <span class="n">de_vocab</span><span class="o">.</span><span class="n">pad_idx</span>  <span class="c1"># 德语词典中pad占位符的数字索引</span>
<span class="n">trg_pad_idx</span> <span class="o">=</span> <span class="n">en_vocab</span><span class="o">.</span><span class="n">pad_idx</span>  <span class="c1"># 英语词典中pad占位符的数字索引</span>

<span class="n">compute_dtype</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span>  <span class="c1"># 计算中数据的类型</span>
<span class="n">dtype</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span>  <span class="c1"># 返回数据的类型</span>

<span class="n">attn</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">enc_hid_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">enc_emb_dim</span><span class="p">,</span> <span class="n">enc_hid_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">,</span> <span class="n">enc_dropout</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">dec_emb_dim</span><span class="p">,</span> <span class="n">enc_hid_dim</span><span class="p">,</span> <span class="n">dec_hid_dim</span><span class="p">,</span> <span class="n">dec_dropout</span><span class="p">,</span> <span class="n">attn</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Seq2Seq</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">src_pad_idx</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>损失函数、优化器初始化。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>  <span class="c1"># 损失函数</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="n">trg_pad_idx</span><span class="p">)</span>  <span class="c1"># 优化器</span>
</pre></div>
</div>
</div>
<p>注意在模型训练中，可能会出现权重更新过大的情况。这会导致数值上溢或者下溢，最终造成梯度爆炸（gradient explosion）。为解决这个问题，我们需要在反向传播计算梯度之后，使用梯度裁剪(gradient clipping)，再将裁剪后的梯度传入优化器进行网络更新。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="k">def</span> <span class="nf">clip_by_norm</span><span class="p">(</span><span class="n">clip_norm</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;给定张量t和裁剪参数clip_norm，对t进行正则化</span>

<span class="sd">    使得t在axes维度上的L2-norm小于等于clip_norm。</span>

<span class="sd">    Args:</span>
<span class="sd">        t: tensor，数据类型为float</span>
<span class="sd">        clip_norm: scalar，数值需大于0；梯度裁剪阈值，数据类型为float</span>
<span class="sd">        axis: Union[None, int, tuple(int)]，数据类型为int32；计算L2-norm参考的维度，如为Norm，则参考所有维度</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># 计算L2-norm</span>
    <span class="n">t2</span> <span class="o">=</span> <span class="n">t</span> <span class="o">*</span> <span class="n">t</span>
    <span class="n">l2sum</span> <span class="o">=</span> <span class="n">t2</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">l2sum</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="c1"># 将加和中等于0的元素替换为1，避免后续出现NaN</span>
    <span class="n">l2sum_safe</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">l2sum</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">l2sum</span><span class="p">))</span>
    <span class="n">l2norm</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">l2sum_safe</span><span class="p">),</span> <span class="n">l2sum</span><span class="p">)</span>
    <span class="c1"># 比较L2-norm和clip_norm，如L2-norm超过阈值，进行裁剪</span>
    <span class="c1"># 剪裁方法：output(x) = (x * clip_norm)/max(|x|, clip_norm)</span>
    <span class="n">intermediate</span> <span class="o">=</span> <span class="n">t</span> <span class="o">*</span> <span class="n">clip_norm</span>
    <span class="n">cond</span> <span class="o">=</span> <span class="n">l2norm</span> <span class="o">&gt;</span> <span class="n">clip_norm</span>
    <span class="n">t_clip</span> <span class="o">=</span> <span class="n">intermediate</span> <span class="o">/</span> <span class="n">ops</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">l2norm</span><span class="p">,</span> <span class="n">clip_norm</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">t_clip</span>
<br/></pre></div>
</div>
</div>
<p>模型训练，训练途中使用验证数据集进行验证评估，并保存效果最好的模型。</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward_fn</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;前向网络&quot;&quot;&quot;</span>
    <span class="n">src</span> <span class="o">=</span> <span class="n">src</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">trg</span> <span class="o">=</span> <span class="n">trg</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg</span><span class="p">)</span>
    <span class="n">output_dim</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
    <span class="n">trg</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">trg</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span>


<span class="c1"># 反向传播计算梯度</span>
<span class="n">grad_fn</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">forward_fn</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg</span><span class="p">,</span> <span class="n">clip</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;单步训练&quot;&quot;&quot;</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">grad_fn</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg</span><span class="p">)</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">HyperMap</span><span class="p">()(</span><span class="n">ops</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">clip_by_norm</span><span class="p">,</span> <span class="n">clip</span><span class="p">),</span> <span class="n">grads</span><span class="p">)</span>  <span class="c1"># 梯度裁剪</span>
    <span class="n">opt</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>  <span class="c1"># 更新网络参数</span>

    <span class="k">return</span> <span class="n">loss</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span> <span class="n">clip</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;模型训练&quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># 所有batch训练loss的累加</span>
    <span class="n">total_steps</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># 训练步数</span>

    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">num_batches</span><span class="p">)</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
        <span class="n">t</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg</span> <span class="ow">in</span> <span class="n">iterator</span><span class="p">():</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">train_step</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg</span><span class="p">,</span> <span class="n">clip</span><span class="p">)</span>  <span class="c1"># 当前batch的loss</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
            <span class="n">total_steps</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">curr_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">total_steps</span>  <span class="c1"># 当前的平均loss</span>
            <span class="n">t</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">curr_loss</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">})</span>
            <span class="n">t</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">total_steps</span>


<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">iterator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;模型验证&quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># 所有batch训练loss的累加</span>
    <span class="n">total_steps</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># 训练步数</span>

    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">num_batches</span><span class="p">)</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg</span> <span class="ow">in</span> <span class="n">iterator</span><span class="p">():</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">forward_fn</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg</span><span class="p">)</span>  <span class="c1"># 当前batch的loss</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
            <span class="n">total_steps</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">curr_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">total_steps</span>  <span class="c1"># 当前的平均loss</span>
            <span class="n">t</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">curr_loss</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">})</span>
            <span class="n">t</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">total_steps</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">save_checkpoint</span>

<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># 训练迭代数</span>
<span class="n">clip</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># 梯度裁剪阈值</span>
<span class="n">best_valid_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>  <span class="c1"># 当前最佳验证损失</span>
<span class="n">ckpt_file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">,</span> <span class="s1">&#39;seq2seq.ckpt&#39;</span><span class="p">)</span>  <span class="c1"># 模型保存路径</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="c1"># 模型训练，网络权重更新</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">train_iterator</span><span class="p">,</span> <span class="n">clip</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="c1"># 网络权重更新后对模型进行验证</span>
    <span class="n">valid_loss</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">valid_iterator</span><span class="p">)</span>

    <span class="c1"># 保存当前效果最好的模型</span>
    <span class="k">if</span> <span class="n">valid_loss</span> <span class="o">&lt;</span> <span class="n">best_valid_loss</span><span class="p">:</span>
        <span class="n">best_valid_loss</span> <span class="o">=</span> <span class="n">valid_loss</span>
        <span class="n">save_checkpoint</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ckpt_file_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch: 0: 100%|██████████| 226/226 [04:17&lt;00:00,  1.14s/it, loss=4.90]
100%|██████████| 8/8 [00:06&lt;00:00,  1.24it/s, loss=4.74]
Epoch: 1: 100%|██████████| 226/226 [02:45&lt;00:00,  1.37it/s, loss=3.88]
100%|██████████| 8/8 [00:01&lt;00:00,  4.60it/s, loss=3.98]
Epoch: 2: 100%|██████████| 226/226 [02:46&lt;00:00,  1.36it/s, loss=3.19]
100%|██████████| 8/8 [00:01&lt;00:00,  4.54it/s, loss=3.63]
Epoch: 3: 100%|██████████| 226/226 [02:47&lt;00:00,  1.35it/s, loss=2.73]
100%|██████████| 8/8 [00:01&lt;00:00,  4.49it/s, loss=3.46]
Epoch: 4: 100%|██████████| 226/226 [02:48&lt;00:00,  1.34it/s, loss=2.40]
100%|██████████| 8/8 [00:01&lt;00:00,  4.56it/s, loss=3.38]
Epoch: 5: 100%|██████████| 226/226 [02:47&lt;00:00,  1.35it/s, loss=2.12]
100%|██████████| 8/8 [00:01&lt;00:00,  4.50it/s, loss=3.37]
Epoch: 6: 100%|██████████| 226/226 [02:45&lt;00:00,  1.37it/s, loss=1.91]
100%|██████████| 8/8 [00:01&lt;00:00,  4.55it/s, loss=3.40]
Epoch: 7: 100%|██████████| 226/226 [02:45&lt;00:00,  1.36it/s, loss=1.74]
100%|██████████| 8/8 [00:01&lt;00:00,  4.60it/s, loss=3.44]
Epoch: 8: 100%|██████████| 226/226 [02:45&lt;00:00,  1.37it/s, loss=1.59]
100%|██████████| 8/8 [00:01&lt;00:00,  4.54it/s, loss=3.44]
Epoch: 9: 100%|██████████| 226/226 [02:44&lt;00:00,  1.37it/s, loss=1.47]
100%|██████████| 8/8 [00:01&lt;00:00,  4.57it/s, loss=3.50]
</pre></div></div>
</div>
</div>
<div class="section" id="模型推理">
<h2>模型推理<a class="headerlink" href="#模型推理" title="永久链接至标题">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">translate_sentence</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;给定德语句子，返回英文翻译&quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># 对输入句子进行分词</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">tok</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\w+|[^\w\s]&#39;</span><span class="p">,</span> <span class="n">sentence</span><span class="o">.</span><span class="n">rstrip</span><span class="p">())]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">]</span>

    <span class="c1"># 补充起始、终止占位符，统一序列长度</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_len</span> <span class="o">-</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">src_len</span> <span class="o">=</span> <span class="n">max_len</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&lt;bos&gt;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">tokens</span><span class="p">[:</span><span class="n">max_len</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">src_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&lt;bos&gt;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">tokens</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_len</span> <span class="o">-</span> <span class="n">src_len</span><span class="p">)</span>

    <span class="c1"># 将德语单词转化为数字索引</span>
    <span class="n">src</span> <span class="o">=</span> <span class="n">de_vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
    <span class="n">src</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">src_len</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">src_len</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">trg</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">en_vocab</span><span class="o">.</span><span class="n">bos_idx</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># 获得预测结果，并将其转化为英语单词</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_len</span><span class="p">,</span> <span class="n">trg</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
    <span class="n">trg_indexes</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>
    <span class="n">eos_idx</span> <span class="o">=</span> <span class="n">trg_indexes</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">en_vocab</span><span class="o">.</span><span class="n">eos_idx</span><span class="p">)</span> <span class="k">if</span> <span class="n">en_vocab</span><span class="o">.</span><span class="n">eos_idx</span> <span class="ow">in</span> <span class="n">trg_indexes</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">trg_tokens</span> <span class="o">=</span> <span class="n">en_vocab</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">trg_indexes</span><span class="p">[:</span><span class="n">eos_idx</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">trg_tokens</span>
</pre></div>
</div>
</div>
<p>使用测试数据集中的任意一组文本数据进行预测。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>

<span class="c1"># 加载之前训练好的模型</span>
<span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">ckpt_file_name</span><span class="p">)</span>
<span class="n">load_param_into_net</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>

<span class="c1"># 以测试数据集中的第一组语句为例，进行测试</span>
<span class="n">example_idx</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">src</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="p">[</span><span class="n">example_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">trg</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="p">[</span><span class="n">example_idx</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;src = </span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;trg = </span><span class="si">{</span><span class="n">trg</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
src = [&#39;ein&#39;, &#39;mann&#39;, &#39;mit&#39;, &#39;einem&#39;, &#39;orangefarbenen&#39;, &#39;hut&#39;, &#39;,&#39;, &#39;der&#39;, &#39;etwas&#39;, &#39;anstarrt&#39;, &#39;.&#39;]
trg = [&#39;a&#39;, &#39;man&#39;, &#39;in&#39;, &#39;an&#39;, &#39;orange&#39;, &#39;hat&#39;, &#39;starring&#39;, &#39;at&#39;, &#39;something&#39;, &#39;.&#39;]
</pre></div></div>
</div>
<p>查看预测结果。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">translation</span> <span class="o">=</span> <span class="n">translate_sentence</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;predicted trg = </span><span class="si">{</span><span class="n">translation</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
predicted trg = [&#39;a&#39;, &#39;man&#39;, &#39;in&#39;, &#39;an&#39;, &#39;orange&#39;, &#39;hat&#39;, &#39;,&#39;, &#39;something&#39;, &#39;.&#39;]
</pre></div></div>
</div>
</div>
<div class="section" id="bleu得分">
<h2>BLEU得分<a class="headerlink" href="#bleu得分" title="永久链接至标题">¶</a></h2>
<p>双语替换评测得分（bilingual evaluation understudy，BLEU）为衡量文本翻译模型生成出来的语句好坏的一种算法，它的核心在于评估机器翻译的译文 <span class="math notranslate nohighlight">\(\text{pred}\)</span> 与人工翻译的参考译文 <span class="math notranslate nohighlight">\(\text{label}\)</span> 的相似度。通过对机器译文的片段与参考译文进行比较，计算出各个片段的的分数，并配以权重进行加和，基本规则为：</p>
<ol class="arabic simple">
<li><p>惩罚过短的预测，即如果机器翻译出来的译文相对于人工翻译的参考译文过于短小，则命中率越高，需要施加更多的惩罚；</p></li>
<li><p>对长段落匹配更高的权重，即如果出现长段落的完全命中，说明机器翻译的译文更贴近人工翻译的参考译文；</p></li>
</ol>
<p>BLEU的公式如下：</p>
<div class="math notranslate nohighlight">
\[exp(min(0, 1-\frac{len(\text{label})}{len(\text{pred})})\Pi^k_{n=1}p_n^{1/2^n})\]</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">len(label)</span></code>：人工翻译的译文长度</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">len(pred)</span></code>：机器翻译的译文长度</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">p_n</span></code>：n-gram的精度</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.translate.bleu_score</span> <span class="kn">import</span> <span class="n">corpus_bleu</span>

<span class="k">def</span> <span class="nf">calculate_bleu</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
    <span class="n">trgs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">pred_trgs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>

        <span class="n">src</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># 源语句：德语</span>
        <span class="n">trg</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># 目标语句：英语</span>

        <span class="c1"># 获取模型预测结果</span>
        <span class="n">pred_trg</span> <span class="o">=</span> <span class="n">translate_sentence</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
        <span class="n">pred_trgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_trg</span><span class="p">)</span>
        <span class="n">trgs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">trg</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">corpus_bleu</span><span class="p">(</span><span class="n">trgs</span><span class="p">,</span> <span class="n">pred_trgs</span><span class="p">)</span>

<span class="c1"># 计算BLEU Score</span>
<span class="n">bleu_score</span> <span class="o">=</span> <span class="n">calculate_bleu</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">de_vocab</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;BLEU score = </span><span class="si">{</span><span class="n">bleu_score</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
BLEU score = 31.54
</pre></div></div>
</div>
</div>
<div class="section" id="参考文献">
<h2>参考文献<a class="headerlink" href="#参考文献" title="永久链接至标题">¶</a></h2>
<p>Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../generative/gan.html" class="btn btn-neutral float-right" title="GAN图像生成" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="sequence_labeling.html" class="btn btn-neutral float-left" title="LSTM+CRF序列标注" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>